{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":115403844,"authorName":"John Arrowwood","from":"&quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"djQu44GxRcsl50ohKZB-bdC9YK7TD-fAO5a5w5Xf2nNfm3eTn89fcWceNQzDOW7vLueQdzremLHdXgsZ7FU0YE3J-uehqR5JNoFa2-ix","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [neat] Re: Project Info","postDate":"1076608315","msgId":377,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBWTItRjEyNGtYcWJwWmRKQ2wwMDAzOWU5OUBob3RtYWlsLmNvbT4="},"prevInTopic":376,"nextInTopic":378,"prevInTime":376,"nextInTime":378,"topicId":371,"numMessagesInTopic":22,"msgSnippet":"... The bigger problem for the moment is extracting the training data within this lifetime. :)  My first attempt was only processing at a rate of about 25","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 46202 invoked from network); 12 Feb 2004 17:51:57 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m4.grp.scd.yahoo.com with QMQP; 12 Feb 2004 17:51:57 -0000\r\nReceived: from unknown (HELO hotmail.com) (65.54.247.124)\n  by mta3.grp.scd.yahoo.com with SMTP; 12 Feb 2004 17:51:57 -0000\r\nReceived: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\n\t Thu, 12 Feb 2004 09:51:55 -0800\r\nReceived: from 64.122.44.102 by by2fd.bay2.hotmail.msn.com with HTTP;\n\tThu, 12 Feb 2004 17:51:55 GMT\r\nX-Originating-Email: [jarrowwx@...]\r\nX-Sender: jarrowwx@...\r\nTo: neat@yahoogroups.com\r\nBcc: \r\nDate: Thu, 12 Feb 2004 09:51:55 -0800\r\nMime-Version: 1.0\r\nContent-Type: text/plain; format=flowed\r\nMessage-ID: &lt;BAY2-F124kXqbpZdJCl00039e99@...&gt;\r\nX-OriginalArrivalTime: 12 Feb 2004 17:51:55.0699 (UTC) FILETIME=[E7705830:01C3F190]\r\nX-eGroups-Remote-IP: 65.54.247.124\r\nFrom: &quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;\r\nReply-To: john@...\r\nSubject: RE: [neat] Re: Project Info\r\nX-Yahoo-Group-Post: member; u=115403844\r\nX-Yahoo-Profile: jarrowwx\r\n\r\n&gt;John, thanks for the nice explanation of image enlargment, something I\n&gt;knew little about!  One thing that may be a challenge in this domain\n&gt;is the high number of inputs and outputs.\n\nThe bigger problem for the moment is extracting the training data within \nthis lifetime. :)  My first attempt was only processing at a rate of about \n25 samples per second.  Rough estimates indicated that I have about 8 \nbillion available to me...  Hopefully a lot of duplicates I can eliminate.\n\nI optimized it and got it up to about 700/sec.  Problem is, once the disk \ncache was full and it started having to hit the disk, it started thrashing.  \nIt went from an estimated 10 hours to probably several days.  I&#39;d never get \nit done!  So now I&#39;m looking at optimizing memory usage and disk I/O so that \nI can write out the training data in a more optimal way.  It makes my brain \nhurt... ;)\n\n&gt;The problem, which comes up\n&gt;often with NEAT, is that starting out with a large number of of inputs\n&gt;and outputs means starting with a very large number of starting\n&gt;connections, and hence violating the spirit of the principle of\n&gt;starting minimally.  Thus, it may be necessary to start evolution in a\n&gt;more sophisticated way, such as letting NEAT decide which inputs\n&gt;and/or outputs to use,\n\nI was thinking that I would start out with only connections between the one \npixel that represents the average of the output pixels in the same area.  \nThat would be one connection per output node for a total of 64 connections \nonly involving 4 inputs.  The rest of the inputs would be initially ignored.\n\n&gt;or perhaps using an &quot;eye&quot; like Darren Izzard (in this group) did.\n\nHmm...  What does that mean, exactly?\n\n&gt;The main concern is that if you start out with\n&gt;too many connections to begin with, you don&#39;t get the full power of\n&gt;NEAT, which is meant to start in a low-dimensional space.\n\nWell, I can&#39;t really get any simpler than one connection per output node, \nright?  Or maybe that&#39;s too simple.  Is there such a thing?  If the topology \nis so simple that it can&#39;t stand a chance of performing well, that won&#39;t be \na problem, right?  It just means that those that develop new nodes or \nconnections develop an advantage quickly, yes?\n\n_________________________________________________________________\nCreate your own personal Web page with the info you use most, at My MSN. \nhttp://click.atdmt.com/AVE/go/onm00200364ave/direct/01/\n\n\n"}}