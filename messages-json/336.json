{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":34004016,"authorName":"Derek James","from":"&quot;Derek James&quot; &lt;blue5432@...&gt;","profile":"blue5432","replyTo":"LIST","senderId":"E51UUgEgt_Q-y7gnG00L42Mn5gACd6I0FDqMK-mQhCHt3sPcIgrgsrujv1ji90fPXa-rnh_2mAJvdO_TfzQfVAmAUXNI0DCHDA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Applying NEAT to Tic-Tac-Toe","postDate":"1075151288","msgId":336,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGJ2M3ZqbysxMGFlOUBlR3JvdXBzLmNvbT4="},"prevInTopic":0,"nextInTopic":337,"prevInTime":335,"nextInTime":337,"topicId":336,"numMessagesInTopic":27,"msgSnippet":"Hello all, Philip and I are still doing some testing and continued development on our Java NEAT implementation, and very soon we ll start doing our first","rawEmail":"Return-Path: &lt;blue5432@...&gt;\r\nX-Sender: blue5432@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 15675 invoked from network); 26 Jan 2004 21:09:20 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m16.grp.scd.yahoo.com with QMQP; 26 Jan 2004 21:09:20 -0000\r\nReceived: from unknown (HELO n33.grp.scd.yahoo.com) (66.218.66.101)\n  by mta6.grp.scd.yahoo.com with SMTP; 26 Jan 2004 21:09:20 -0000\r\nReceived: from [66.218.67.160] by n33.grp.scd.yahoo.com with NNFMP; 26 Jan 2004 21:08:14 -0000\r\nDate: Mon, 26 Jan 2004 21:08:08 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;bv3vjo+10ae9@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 6543\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.101\r\nFrom: &quot;Derek James&quot; &lt;blue5432@...&gt;\r\nSubject: Applying NEAT to Tic-Tac-Toe\r\nX-Yahoo-Group-Post: member; u=34004016\r\nX-Yahoo-Profile: blue5432\r\n\r\nHello all,\n\nPhilip and I are still doing some testing and continued development \non our Java NEAT implementation, and very soon we&#39;ll start doing our \nfirst experiments in the domain of Tic-Tac-Toe.\n\nI had a few questions for the group, though.  First of all, what do \nyou think the best way to evaluate the strength of an evolved Tic-Tac-\nToe-playing network is?\n\nI was curious about how this was handled in Joseph&#39;s modular-NEAT \npaper, in which he uses Tic-Tac-Toe as a domain.  First, here&#39;s \nJoseph&#39;s explanation of how games and players are represented and \nimplemented:\n\n&quot;For this domain, the network architecture is always \n9 input neurons and 9 output neurons, representing the vector of the \nboard space. At each step of the game, the network is given the \ncurrent layout of the board, and using this input, the highest valued \noutput is chosen as the location where the network will play. In the \ncase that that square is already occupied, the next highest value is \nchosen, and so on. Removing the requirement that the network must \nlearn legal moves makes it signi\fcantly easier to analyze the results \nsince Modular NEAT converges faster. Each square on the board can \nhave three states: a value of -1 indicates the opponent occupies the \nparticular square, while 1 denotes the computer&#39;s own piece and 0 \ndenotes an empty space.&quot;\n\nWe&#39;re using exactly the same approach.  But I&#39;m a bit confused about \nhow the evaluations are carried out:\n\n&quot;Two modes of evaluation are used depending on the data being \ngathered: strict evaluation and loose evaluation. Networks scored \nusing strict evaluation play a total of 10 games against a perfect \ntic-tac-toe playing opponent. The first nine games are started by the \nopponent, one game for each different starting location. The last \ngame is started by the network. With this form of evaluation, the \nnetwork&#39;s assigned fitness will be the same no matter how often it is \nscored. In contrast, under loose evaluation, the network \nplays a total of 40 games, one round of strict evaluation followed by \n30 games against a randomly moving opponent. In this case, the \nnetwork&#39;s ability to actually play the game is more accurately \nanalyzed, at the cost of consistency (two separate loose evaluations \nof the same network can yield different final fitness scores). Often \nnetworks trained using strict evaluation could be defeated easily if \nthe opponent played sub-optimally (as it was never trained on those \ncases), whereas networks trained using loose evaluation were more \nlikely to be able to adapt since their ability to play random games \nis a factor in their fitness. \nUnless otherwise stated, all data gathered from the tic-tac-toe \ndomain is scored using strict evaluation.&quot;\n\nYou say that the evaluation methods differ, but note that &quot;loose&quot; \nevaluation more accurately analyzes the strength of a player.  You \nnote that players evolved using &quot;strict&quot; evaluation are easily \ndefeated by a sub-optimal player (such as a random player).  Why then \ndid you use &quot;strict&quot; evaluation as your primary mode of evaluation?  \nTime?  Computing resources?\n\nThis makes me question the language in the following paragraph:\n\n&quot;This example network solves tic-tac- toe, only missing one game out \nof 10 against the perfect opponent (the genetic algorithm converged \non the perfect solution 200 generations later).&quot;\n\nYou say that the network &quot;solves&quot; Tic-Tac-Toe, but it&#39;s only being \nevaluated against a perfect player.  And by &quot;missing one game out of \n10&quot;, I&#39;m assuming that you mean the evolved player lost 1 and tied 9 \nagainst the perfect player.  Is that right?  \n\nMy main question is, if a network can tie 90% of its games against an \noptimal player, would we say it has solved Tic-Tac-Toe?  What if the \nsame network loses 85% of its games against a random player?\n\nI&#39;ve found this in informal experiments I&#39;ve run so far...networks \nthat learn blocking behavior don&#39;t necessarily learn the behavior \nneeded to complete winning moves, and a network that performs well \nagainst a perfect player often performs poorly against a random \nmover, and vice versa.\n\nI like the way Angeline and Pollack tested the strength of their Tic-\nTac-Toe AIs (modular LISP programs) in this 1993 paper:\n\nhttp://citeseer.nj.nec.com/cache/papers/cs/1362/http:zSzzSzwww.cis.ohi\no-state.eduzSzlairzSzTechReportszSzijcai93.pdf/angeline93learning.pdf\n\nThey evolved their programs directly against three hard-coded players:\n\nRAND - a random mover\nBEST - a perfect player\nNEAR - a BEST player that is susceptible to &quot;forking&quot;, or allowing \nits opponent to make a move that produces two winning moves their \nnext turn\n\nThey compared these direct evolutionary runs with a form of single-\npopulation coevolution, using a simple Single-Elimination Tournament.\n\nThey then played the evolved champions against each type of player \n(2000 games) to test their relative strengths, producing results that \nlook like this:\n\nChampion evolved against RAND:\n\nWins vs. RAND: 1125\nDraws vs. RAND: 0\nWins vs. NEAR: 0\nDraws vs. NEAR: 0\nDraws vs. BEST: 0\n\nChampion evolved against NEAR:\n\nWins vs. RAND: 802\nDraws vs. RAND: 104\nWins vs. NEAR: 144\nDraws vs. NEAR: 123\nDraws vs. BEST: 0\n\nChampion evolved against BEST:\n\nWins vs. RAND: 310\nDraws vs. RAND: 535\nWins vs. NEAR: 0\nDraws vs. NEAR: 360\nDraws vs. BEST: 0\n\nChampion from Single-Elimination Tournament Coevolution:\n\nWins vs. RAND: 781\nDraws vs. RAND: 471\nWins vs. NEAR: 61\nDraws vs. NEAR: 588\nDraws vs. BEST: 481\n\nThus they have a way of comparing the resulting networks against a \ncross-section of strategies/opponents, giving a reasonable estimate \nof the network&#39;s strength.\n\nFor our experiments, I planned on using a similar technique to \nevaluate the performance of evolved networks.  I&#39;d planned on using \nthree strategies, like Angeline and Pollack, a RAND, BEST, and CENTER \n(a player that always plays in the center if it is open, and \notherwise plays randomly...this seemed a good strategy between RAND \nand BEST because it is one of the first strategic concepts a human \nchild learns when playing the game.)\n\nDoes anyone have a better suggestion on how to evaluate the strength \nof evolved Tic-Tac-Toe players?  Is there a definite method for \ndetermining that a network has solved the game?\n\nWhen I play large samples of RAND vs. BEST, BEST wins about 90% and \nties RAND about 10%.  If a network ties BEST 100% of the time and \nbeats RAND 90% of the time, would you say that is the standard for \nsolving Tic-Tac-Toe?  If not, what would be a better measure?\n\nDerek\n\n\n\n\n\n"}}