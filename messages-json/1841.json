{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":186151300,"authorName":"gbravoescobar","from":"&quot;gbravoescobar&quot; &lt;gbravoescobar@...&gt;","profile":"gbravoescobar","replyTo":"LIST","senderId":"yum3R85Uy0okuAQjE95uUXPi-cpZKXcgep8495giCAsiKGLbA5n_bNqW8UKQvxWWksqYj9zTY6OTgA6T-nURyjKbGoMgV5CLwMY7likkiw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Symmetry, concepts and data buses in the brain","postDate":"1106825888","msgId":1841,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGN0YWpyMCs1OHE1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQxRjJBRjYzLjcwNzA4MDJAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":1840,"nextInTopic":1842,"prevInTime":1840,"nextInTime":1842,"topicId":1698,"numMessagesInTopic":40,"msgSnippet":"Hi Colin, Let me add some ideas: I have a hypothesis about brain that I think is enough consistent with NEAT and other ANNs, besides it seems to match same of","rawEmail":"Return-Path: &lt;gbravoescobar@...&gt;\r\nX-Sender: gbravoescobar@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 15617 invoked from network); 27 Jan 2005 11:38:27 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m5.grp.scd.yahoo.com with QMQP; 27 Jan 2005 11:38:27 -0000\r\nReceived: from unknown (HELO n3a.bulk.scd.yahoo.com) (66.94.237.37)\n  by mta1.grp.scd.yahoo.com with SMTP; 27 Jan 2005 11:38:27 -0000\r\nReceived: from [66.218.69.2] by n3.bulk.scd.yahoo.com with NNFMP; 27 Jan 2005 11:38:23 -0000\r\nReceived: from [66.218.66.99] by mailer2.bulk.scd.yahoo.com with NNFMP; 27 Jan 2005 11:38:23 -0000\r\nDate: Thu, 27 Jan 2005 11:38:08 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ctajr0+58q5@...&gt;\r\nIn-Reply-To: &lt;41F2AF63.7070802@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Length: 14137\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.94.237.37\r\nFrom: &quot;gbravoescobar&quot; &lt;gbravoescobar@...&gt;\r\nSubject: Re: Symmetry, concepts and data buses in the brain\r\nX-Yahoo-Group-Post: member; u=186151300\r\nX-Yahoo-Profile: gbravoescobar\r\n\r\n\n\nHi Colin,\n    \n Let me add some ideas:\n\nI have a hypothesis about brain t=\r\nhat I think is enough consistent with\nNEAT and other ANNs, besides it seems=\r\n to match same of the observed\nbrain behaviour.\n\n\tAlthough probably &quot;Visual=\r\n Cortex&quot; and other parts of the brain are\ndifferent, I believe that some of=\r\n the working issues of the first\ncould be related to the second. \n\nLet&#39;s do=\r\n a little summary of first stage of the primate visual\nsystems: there are b=\r\nasically the next different steps: \n1) ON-OFF cells: It goal is to extract =\r\nedges from Retina image. \n2) Gabor Filters: Neurons have an orientation pre=\r\nference; each &quot;edge&quot;\nof the image is separated in different &quot;maps&quot; dependin=\r\ng of orientation.\n3) Area V1: Basic shapes can be extracted from before ste=\r\np. For\nexample: A vertical square would have activation in 4 Gabor maps.\nTh=\r\nerefore, a square in the visual field would have an activation of\ngrouped c=\r\nells in the Area V1, I mean, like one pixel in the squares\nfeature map.\n\n\tI=\r\nf we see the visual system structure we can say:\n\n- Each step is a feature =\r\nextractor: edges, orientation, shape.\n- There are different levels of abstr=\r\naction like a pyramid.\n\nNow image a hypothetical primate that since was bor=\r\nn it lived in a\nworld of squares, one day I introduce circles in its world.=\r\n Would it\nsee the circles?. Well, I have done experiments with a program th=\r\nat\nsimulate the different maps of visual system and the answer is &quot;yes&quot;.\nIf=\r\n we see the circles through square feature extractor map we see\npoints of d=\r\nifferent strength in the map, odds figures that always has\nthe same shape a=\r\nnd each one represent a circle &quot;from a square point of\nview!!!&quot;.\n\n\tFrom an =\r\n&quot;economy&quot; point of view it would be easier to learn the new\ncircle feature =\r\nmap from the square feature map than begin without any\nrelationship. This i=\r\ns something that we do every day: we learn a new\nconcept relating it to old=\r\n concepts. For example if you listen some\nword of a different language you =\r\nnever have spoken before with\ndifferent kind of sounds and you try to repea=\r\nt, as your brain is tuned\nfor your sounds and words (notice that they are t=\r\nwo different\nabstraction level feature maps) you will say something similar=\r\n but it\nwill sound different to the original sound (of course, your spoken\n=\r\nbrain area is tuned to pronounce a limited set of sounds too, close to\nsour=\r\n language).\n\nNow Image that our brain is made of features maps organized li=\r\nke an\nabstraction pyramid either in perception or in actuation. In\npercepti=\r\non the pyramid goes from sensations (sensors) to concepts and\nin actuation =\r\nit goes from concepts to electrical signals to muscles\n(or motors). In a hi=\r\ngh abstraction level both pyramid are mixed. (I\nknow this an old representa=\r\ntion of the brain for neurobiologist).\nProbably in a high abstraction level=\r\n there exist abstract features\nmaps with no sense and some kind of feature =\r\nprocessor.\n\n  As you see, for me, the unit of the brain are features. Proba=\r\nbly, at\nthe beginning of life brain is structured with some feature maps (f=\r\nor\nexample a baby is able to recognize faces with no learn), even for\nhighe=\r\nst abstraction levels some kind of structure is set at the first\nof life. \n=\r\n\n\tI would like to point that modularity as we have been discussing:\nmodules=\r\n that are able to process different concepts are related to the\nanalogy and=\r\n metaphor. This is a capacity that in human being has only\nrecently acquire=\r\nd in the evolution, Neanderthal man had not. \n\n\tTherefore, in this model an=\r\n idea would be a holistic representation\nof the strongest activation featur=\r\ne maps in different parts of the\nbrain. Also, a mental state would be an ac=\r\ntivation of related ideas\nwhere each of them is activated as a holistic rep=\r\nresentation of\nsignals in different brain areas. Through an attentional pro=\r\ncess\n(managed with other signals) we would be able to modify such state or\n=\r\nrandomly activate other maps to create new concepts and new ideas.\n\n   I co=\r\nnsequence of this model would be that we can compare concepts\nof different =\r\nnature and different abstraction level that never have\nbeen joined in any p=\r\nast experience as they have a similar &quot;response&quot;\nin different feature maps.=\r\n That shared maps could be grouped in\ndifferent ways, so different concepts=\r\n (relationships) could be extracted.\n\t\n\nLet&#39;s land in NEAT:\n\n       If we a=\r\nre able to separate in different abstraction levels\ncreating that&#39;s double =\r\npyramid (Perception &gt; Abstraction &lt; Actuation),\nbut not only with formal me=\r\naning concepts, as well with no formal\nfeature maps, possibly we will be ab=\r\nle to create more intelligent\nANNs.    \n\n      But, how to guide the evolut=\r\nion to create a abstract feature map?\n\nI think the answer is in vision syst=\r\nem again; algorithm &quot;Cascade\nAdaboost&quot;. This algorithm is used today as one=\r\n of the fastest and less\nresource consumer of images recognitions. Particul=\r\narly it is well\nsuited for face recognition. \nThe goal of the algorithm is =\r\nto be able to classify images. In faces\nthe goal is to identify what images=\r\n are faces a what are no faces. \n\n  To simplify the problem let explain wit=\r\nh faces recognition process:\nThe classification is separated in different s=\r\ntages (weak classifier).\nIn each of them the weak classifier is trained to =\r\ndiscard roughly 50%\nof total negative images (no faces) . It has a very low=\r\n error of\npositive Images discarded (0.05%). So, after a lot of   stages (f=\r\naces\nclassifier uses nearly 17 stages), the cascade of weak classifiers are=\r\n\nable to identify what are faces a what are not. Only the images that\nare a=\r\nble to arrive to last stage without being discarded are face.\n\n  Before lea=\r\nrn, each weak classifier is able to use finite number of\nfeature maps (in f=\r\nace recognition it use brighter-darker areas\nrelationship maps). After lear=\r\nn, each weak classifier has chosen the\nright feature map and it ponders ove=\r\nr weights in the final activation\nvalue of this weak classifier.\n\n   Each w=\r\neak classifier can be considered as a &quot;feature map&quot;. In each\nstage the goal=\r\n is to extract one right feature that share all the\nfaces and that discard =\r\na lot of no faces. Finally,  only the\nintersection of different useful feat=\r\nures identify a face, and that\ncombination form the feature map of faces.\n\n=\r\nTherefore:\n\n1) Why not to create feature maps through ANNs as a whole of we=\r\nak\nclassifers?.\n2) Why not to create abstraction concepts and letting reuse=\r\n that weak\nclassifiers through abstraction pyramid in higher and higher lev=\r\nels.\nIt would be as an evolution process where we give some concepts and we=\r\n\nlet the net to develop useful feature maps? \n\n\tIn any way we would &quot;tune&quot; =\r\nour ANN to concepts we teach and it would\nbe easy to grow our ANN to close =\r\nconcepts.\n\nGerm=E1n.\n\n\n--- In neat@yahoogroups.com, Colin Green &lt;cgreen@d..=\r\n.&gt; wrote:\n&gt; Hi,\n&gt; \n&gt; I&#39;ve just been catching up on this thread, and althoug=\r\nh I haven&#39;t \n&gt; necessarily followed all of the details I get the gist of it=\r\n.\n&gt; \n&gt; It seems to me Ian that you&#39;re dealing with very big questions that =\r\nare \n&gt; closely related to the mechanics behind conciousness, awareness, \n&gt; =\r\nunderstanding, etc.  I would expect there to be some clues about how \n&gt; inf=\r\normation moves around the brain in neurology literature, which is\nnot \n&gt; an=\r\n area I personally keep abreast of. The papers I /have/ seen\ntended to \n&gt; b=\r\ne unpenetrable to my mind, often I can&#39;t even determine which\nbranch of \n&gt; =\r\nneuroology thay are meant to be covering let alone understand the\ndetails.\n=\r\n&gt; \n&gt; However, I think the central question you&#39;ve put forward (how\nfunction=\r\nal \n&gt; modules in the brain are arranged and how they communicate) is a simp=\r\nle \n&gt; one to understand (from a big picture point of view). And I agree tha=\r\nt \n&gt; speculating on what mechanisms and structures might be in play may giv=\r\ne \n&gt; some insight into neuro-evolution and related areas. With this in mind=\r\n \n&gt; I&#39;ll try elucidate my thoughts on the subject, although I&#39;m sure these =\r\n\n&gt; ideas aren&#39;t anything knew.\n&gt; \n&gt; I think considering specific problems s=\r\nuch as playing chess, and \n&gt; analysing your own thought processes whilst pl=\r\naying can give some \n&gt; insight into what is going on. Actually if we are ta=\r\nlking about \n&gt; capitalising on symmetry I prefer to consider the game of Go=\r\n, since \n&gt; (personally) I tend to always consider a chess board from one si=\r\nde -\nthe \n&gt; side I am playing from. Whereas Go doesn&#39;t have this inherent s=\r\nidedness \n&gt; and it is therefore probably more useful to rotate and translat=\r\ne the \n&gt; board in your mind when playing. Having said that I&#39;m fairly usele=\r\nss at \n&gt; both games, so what do I know ;)\n&gt; \n&gt; The first thing to note is t=\r\nhat I home in on small groups of pieces and \n&gt; consider them in isolation o=\r\nf the rest of the board. When detecting \n&gt; patterns I won&#39;t always mentally=\r\n rotate the pieces, usually I need\nto do \n&gt; this at first but then learn to=\r\n recognise the various patterns in their \n&gt; different rotations directly. S=\r\necondly, the high level process of \n&gt; identifying interesting groups, rotat=\r\ning them and deciding if they are \n&gt; interesting is a concious process (sta=\r\nte the obvious alert!), \n&gt; undoubtedly there is a heck of a lot of sub-conc=\r\nious activity (e.g. \n&gt; visual cortex) but  I see that as mostly being much =\r\nlower level \n&gt; processes such as building a mental model of the board from =\r\nthe visual \n&gt; input - which is not what we&#39;re discussing.\n&gt; \n&gt; So I can per=\r\ncieve a group of pieces, the lines they form and their \n&gt; overall shape. I =\r\nmay then have a memory of the shape with and an \n&gt; associated memory of a g=\r\nood move (or moves) to play, or I may recall \n&gt; that this is a shape that i=\r\ns no use to me (no good moves) and will then \n&gt; move on to analysing other =\r\ngroups. Or I may have no memory at all of \n&gt; this pattern, in which case I =\r\nhave to analyse it keeping in mind the \n&gt; rules of the game and perhaps mem=\r\nories of similar patterns that may \n&gt; apply, considering each in turn and d=\r\niscounting them or flagging\nthem as \n&gt; possible options.\n&gt; \n&gt; Some perhaps =\r\nobvious notes to make at this point:\n&gt; \n&gt; 1) My concious thought can genera=\r\nlly only focus on one thing at a time. \n&gt; I can quickly switch back to very=\r\n recent thoughts (short term memory), \n&gt; allowing me to consider, say,  a n=\r\number of different moves and how well \n&gt; they relate to each other. But I c=\r\nannot consider them concurrently.\nAs I \n&gt; consider each one I am assigning =\r\na sort of rating to it, while also \n&gt; trying to keep in mind the best rated=\r\n move so far.\n&gt; \n&gt; 2) My capacity to keep each of these seperate thoughts i=\r\nn mind is \n&gt; limited. This becomes particularly obvious (for me) when perfo=\r\nrming \n&gt; mental arithmetic, forgetting earlier calculated values, or forget=\r\nting \n&gt; which part of the calculation they relate to. Some people seem\nbett=\r\ner at \n&gt; maintaining short term memory than others, although in the case of=\r\n \n&gt; arithmetic there is also the factor of some people memorising far more =\r\n\n&gt; answers than others(e.g. multiplication tables), thus reducing the need =\r\n\n&gt; to keep loads of figures in short term memory (sub-calculations).\n&gt; \n&gt; S=\r\no it seems to me that the concious part of the brain is loading in \n&gt; singl=\r\ne thoughts from the short and long term memory and acting a little \n&gt; like =\r\na CPU loading and executing single instructions at a time. Only \n&gt; instead =\r\nof a simple instruction, the conciousness loads a chunck or\nunit \n&gt; of thou=\r\nght. These units I would expect to have a consistent\nstructure to \n&gt; them s=\r\no that they can be read/written to memory and passed around the \n&gt; brain us=\r\ning the same communication channels. This includes all\nthoughts, \n&gt; from si=\r\nmple sensory based information such as images, sounds, taste and \n&gt; sensati=\r\non, but also including all other types of thoughts such as\nfacts, \n&gt; langua=\r\nge elements, concepts such as magnitude, orientation, momentum, \n&gt; hardness=\r\n, the list goes on.\n&gt; \n&gt; Actually language is quite an interesting thing to=\r\n consider. If I hear \n&gt; some phrase and remember it I would assume that I d=\r\non&#39;t remember it\nas a \n&gt; chunk of audio like some mental equivalent of a WA=\r\nV file, instead I am \n&gt; remembering the sequence of (recognised) words. Whi=\r\nch leads to the \n&gt; question - am I remebering a copy of each word&#39;s unit re=\r\npresentation as \n&gt; recalled from the language part of the brain, or am I re=\r\nmembering a\nsort \n&gt; of pointer to each word?\n&gt; \n&gt; Also consider how differe=\r\nnt facts, ideas and concepts (thought units) \n&gt; become related in the brain=\r\n. Most of the time these thought units are \n&gt; just sitting in long term mem=\r\nory and not taking part in concious \n&gt; thought. e.g. If I say to you &quot;think=\r\n of a yellow submarine&quot; you&#39;ve just \n&gt; recalled what a submarine is, and pr=\r\nobably some related thoughts about \n&gt; The Beatles. Previously those thought=\r\ns were sitting dormant in your \n&gt; memory. So is there a direct physical con=\r\nnection between the phrase \n&gt; yellow-submarine, the concept of a submarine =\r\nthat is yellow and the \n&gt; beatles memory? or do these memories respond to t=\r\nhe same stimulus, e.g. \n&gt; they had all been &#39;indexed&#39; under yellow-sub but =\r\nnot physically \n&gt; connected.  I suppose something like the later approach m=\r\nakes sense, \n&gt; otherwise you might have two unrelated memories in physicall=\r\ny seperate \n&gt; parts of the hippocampus (or wherever memory is), which would=\r\n make \n&gt; physically connecting at some later time difficult if say some new=\r\n fact \n&gt; was introduced that linked the two.\n&gt; \n&gt; So I would hazard a guess=\r\n that thoughts are packaged up and passed \n&gt; around the brain via something=\r\n analogous to a data bus. As for modules \n&gt; that perform different function=\r\ns - well perhaps these are analogous to \n&gt; the various execution circuits i=\r\nn a CPU and as such they would be fixed \n&gt; structures that operate on whate=\r\nver data that is passed to them. This \n&gt; might explain how we can apply the=\r\nse funtions in different contexts. \n&gt; Although I strongly suspect that the =\r\n&#39;execution units&#39; are highly \n&gt; abstract and that new skills that are learn=\r\ned are actually just new \n&gt; memories that cause a given chain of thought un=\r\nits to get recalled, \n&gt; perhaps some thought units specify how to combine o=\r\nther thoughts with \n&gt; the execution units to achieve a result.\n&gt; \n&gt; The are=\r\na of the brain where thought units are retrieved to and\nprocessed \n&gt; could =\r\nthen be said to be where conciousness lies, but that would \n&gt; probably be a=\r\n gross oversimplification.\n&gt; \n&gt; Colin\n\n\n\n\n"}}