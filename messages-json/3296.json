{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"FD7FeklDbJbERgTL4Yl8foQ96rL2D76x_54Fmj2rXMnlNOgKnZhXMschi1ZReF_y7HYd9lQIRbbq_rAFEmrUSeI","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Placement of conceptually different inputs in HyperNEAT?","postDate":"1179344723","msgId":3296,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYyZm4waityYnBkQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGYyZmxndCtvbWFnQGVHcm91cHMuY29tPg=="},"prevInTopic":3295,"nextInTopic":3297,"prevInTime":3295,"nextInTime":3297,"topicId":3278,"numMessagesInTopic":20,"msgSnippet":"As an example, consider a variation on Thomas s poker implementation. Same as previously defined except duplicate the 2d & 3d nodes as hidden nodes so as to","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 55513 invoked from network); 16 May 2007 19:46:16 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m50.grp.scd.yahoo.com with QMQP; 16 May 2007 19:46:16 -0000\r\nReceived: from unknown (HELO n25a.bullet.sp1.yahoo.com) (209.131.38.237)\n  by mta10.grp.scd.yahoo.com with SMTP; 16 May 2007 19:46:16 -0000\r\nReceived: from [216.252.122.219] by n25.bullet.sp1.yahoo.com with NNFMP; 16 May 2007 19:45:25 -0000\r\nReceived: from [209.73.164.83] by t4.bullet.sp1.yahoo.com with NNFMP; 16 May 2007 19:45:24 -0000\r\nReceived: from [66.218.67.195] by t7.bullet.scd.yahoo.com with NNFMP; 16 May 2007 19:45:24 -0000\r\nDate: Wed, 16 May 2007 19:45:23 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f2fn0j+rbpd@...&gt;\r\nIn-Reply-To: &lt;f2flgt+omag@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Placement of conceptually different inputs in HyperNEAT?\r\nX-Yahoo-Group-Post: member; u=281645563; y=T1gWHyko6UkvCfVc1TGnxOpdf7pgJemykaqyu-LpUqhOXg\r\nX-Yahoo-Profile: afcarl2\r\n\r\nAs an example, consider a variation on Thomas&#39;s poker implementation. \nSame=\r\n as previously defined except duplicate the 2d & 3d nodes as \nhidden nodes =\r\nso as to capture substrate input (SI) to substrate \noutput (SO), SI-to-SI, =\r\nSO-to-SI, and SO-to-SO interactions, since \ntrue input nodes can only have =\r\none input and contain no activation \nfunction. In this particular case, the=\r\nse &quot;hidden&quot; nodes are \nnot &quot;true&quot; hidden nodes in that the each have a rati=\r\nonal basis of \ndimensionality (i.e. same as the corresponding original node=\r\n).\n\nIn this instance, the hypercube input &quot;from&quot; node could be either 2d \no=\r\nr 3d, and the hypercube input &quot;to&quot; node could be either 2d or 3d, \ngiving t=\r\nhe following possibilities (&quot;from&quot; + &quot;to&quot;):\n(1) 2d + 2d\n(2) 2d + 3d\n(3) 3d =\r\n+ 2d\n(4) 3d + 3d\n\nThe question is: How do you deal with the variation in th=\r\ne hypercube \ninput topology, as you loop over all of the possible links in =\r\nthe \nsubstrate network computing the associated weight with the hypercube \n=\r\nnetwork, for the variations in dimensionality listed above in (1) \nthrough =\r\n(4)?\n\nThanks,\n   Andy Carl\n\n\n--- In neat@yahoogroups.com, &quot;petar_chervenski=\r\n&quot; \n&lt;petar_chervenski@...&gt; wrote:\n&gt;\n&gt; What about the general theory behind C=\r\nPPNs? The dimensionality of \nthe \n&gt; CPPN input/output space is ALWAYS the s=\r\name, assuming that the \n&gt; dimensionality of the substrate space is known. I=\r\nf the substrate \n&gt; space is 2D, the simplest connective CPPN (without addit=\r\nional \ninputs \n&gt; to boost the evolution) will have 5 inputs (bias node (1.0=\r\n) \ncounted), \n&gt; in 3D the inputs will be 7. And this is enough to achieve A=\r\nNY \n&gt; functionality within the substrate, since the CPPNs complexify. The \n=\r\n&gt; basic coordinate frames (x1, y1, x2, y2) are passed through more \nand \n&gt; =\r\nmore coordinate frames, creating very complex connective patterns. \n&gt; The s=\r\nubstrate can have any number of inputs/hidden/outputs, no \nmatter \n&gt; what t=\r\nhe topology of the CPPN is or the CPPN&#39;s input/output \n&gt; dimensionality. Th=\r\ne substrate can scale up to millions of \n&gt; nodes/connections, but its CPPN =\r\nis still the same. \n&gt; There are 2 spaces in general - the phenotype space (=\r\nthe neural \n&gt; substrate) and the genotype space (CPPN). I believe it is the=\r\n \n&gt; phenotype space, that you call &quot;design space&quot;. (Am I wrong?)\n&gt; The inpu=\r\nts provided in the substrate should be chosen as wise as in \n&gt; ordinary ANN=\r\n experiment. But in the HyperNEAT case, you can provide \n&gt; geometric inform=\r\nation like a bonus to the evolutionary algorithm. \nAll \n&gt; inputs/outputs ar=\r\ne problem specific, of course :) \n&gt; Your explanation looks like the CPPN ca=\r\nn depend on the substrate in \n&gt; some way. I don&#39;t think this is possible. \n=\r\n&gt; Maybe I didn&#39;t understand you correctly, I don&#39;t know. Can you give \n&gt; me=\r\n some specific example to clear out what you exactly mean? \n&gt; \n&gt; Peter\n&gt; \n&gt;=\r\n \n&gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Peter,\n=\r\n&gt; &gt; \n&gt; &gt; Given an arbitrary point &quot;P&quot; in design space, comprised of the \n&gt; =\r\n&gt; following:\n&gt; &gt; (a) problem specific inputs (PSIs);\n&gt; &gt; (b) auxiliary addi=\r\ntional parameters associated w/ PSIs;\n&gt; &gt; (c) problem specific outputs (PSO=\r\ns);\n&gt; &gt; (d) auxiliary additional parameters associated w/ PSOs;\n&gt; &gt; \n&gt; &gt; Su=\r\nbstrate Inputs: comprised of PSIs, &quot;a&quot; above;\n&gt; &gt; Substrate Outputs: compri=\r\nsed of PSOs, &quot;c&quot; above;\n&gt; &gt; \n&gt; &gt; Hypercube Inputs: comprised of auxiliary a=\r\ndditional parameters \n&gt; &gt; associated w/ PSIs & PSOs, &quot;b&quot; & &quot;d&quot; above;\n&gt; &gt; H=\r\nypercube Output: weight between current pair of substrate nodes\n&gt; &gt; \n&gt; &gt; If=\r\n:\n&gt; &gt; (1) the dimensionality of the hypercube input &quot;from&quot; node is \n&gt; &gt; dif=\r\nferent in number and/or nature as the links in the substrate \n&gt; &gt; network a=\r\nre looped over, or\n&gt; &gt; (2)  the dimensionality of the hypercube input &quot;to&quot; =\r\nnode is \n&gt; different \n&gt; &gt; in number and/or nature as the links in the subst=\r\nrate network are \n&gt; &gt; looped over,\n&gt; &gt; \n&gt; &gt; ...then the topology of the hyp=\r\nercube inputs are different/change \n&gt; as \n&gt; &gt; you loop over the substrate l=\r\ninks, while computing the current \nlink \n&gt; &gt; weight with the hypercube netw=\r\nork.\n&gt; &gt; \n&gt; &gt;    The examples and explanations provided to date do not addr=\r\ness \n&gt; this \n&gt; &gt; more general condition.\n&gt; &gt; \n&gt; &gt;    Does this explain the =\r\nissue in question better?\n&gt; &gt; \n&gt; &gt; Thanks,\n&gt; &gt;    Andy Carl\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; -=\r\n-- In neat@yahoogroups.com, &quot;petar_chervenski&quot; \n&gt; &gt; &lt;petar_chervenski@&gt; wro=\r\nte:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi Andy, \n&gt; &gt; &gt; \n&gt; &gt; &gt; I am sorry, but I didn&#39;t understand =\r\nwhat you mean by &quot;hypercube \n&gt; &gt; input \n&gt; &gt; &gt; topology&quot;? \n&gt; &gt; &gt; As far as I=\r\n know, this is simply a CPPN taking 2 points from \nthe \n&gt; &gt; &gt; substrate spa=\r\nce (connective CPPN) instead of only one (spatial \n&gt; &gt; CPPN). \n&gt; &gt; &gt; The co=\r\nordinates of this points in the substrate space are the \n&gt; &gt; inputs \n&gt; &gt; &gt; =\r\nto this CPPN and the output is the weight/point intensity. \n&gt; &gt; &gt; The topol=\r\nogy between these inputs and the output node is \nevolved \n&gt; &gt; with \n&gt; &gt; &gt; t=\r\nhe regular NEAT method. The evolved topology and the weights \nare \n&gt; &gt; the =\r\n\n&gt; &gt; &gt; most important thing to consider. \n&gt; &gt; &gt; I guess this topology can c=\r\nhange? Maybe in time (leaky neurons) \n&gt; or \n&gt; &gt; &gt; with recurrent connection=\r\ns?\n&gt; &gt; &gt; The idea of changing input topology for the CPPN is like \n&gt; &gt; &gt; Hy=\r\nperHyperNEAT :) CPPNs that further create CPPNs..\n&gt; &gt; &gt; \n&gt; &gt; &gt; Peter\n&gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; Ken,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;    It appears that you keep attempting to recast =\r\nthe \nsubstrate \n&gt; &gt; &gt; inputs \n&gt; &gt; &gt; &gt; and outputs such that the hypercube i=\r\nnput topology remains \n&gt; &gt; &gt; constant. \n&gt; &gt; &gt; &gt; Not taking anything away fr=\r\nom HyperNEAT&#39;s ability to exploit \n&gt; &gt; &gt; 1d/2d/3d \n&gt; &gt; &gt; &gt; geometry in whic=\r\nh the hypercube input topology remains \n&gt; constant, \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; mor=\r\ne general question of when the hypercube input topology is \n&gt; not \n&gt; &gt; &gt; &gt; =\r\nconstant, what do you do? Please address this specific issue. \n&gt; The \n&gt; &gt; &gt;=\r\n &gt; answer to this question will help to identify the \n&gt; &gt; &gt; &gt; applicability=\r\n/limitations of HyperNEAT.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt;    Andy Carl\n&gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kst=\r\nanley@&gt; \n&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Thomas, this is a great question that=\r\n highlights an \nimportant \n&gt; &gt; &gt; area \n&gt; &gt; &gt; &gt; for \n&gt; &gt; &gt; &gt; &gt; further resea=\r\nrch.  We can speculate on the right approach \nin \n&gt; &gt; this \n&gt; &gt; &gt; &gt; case \n&gt;=\r\n &gt; &gt; &gt; &gt; (and I have my hunches) but we won&#39;t know until we do some \n&gt; &gt; &gt; =\r\n&gt; experiments \n&gt; &gt; &gt; &gt; &gt; and try ideas out.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; To give so=\r\nme of my thoughts, perhaps the most obvious thing \n&gt; is \n&gt; &gt; &gt; &gt; similar \n&gt;=\r\n &gt; &gt; &gt; &gt; to what you suggest:  Have two separate input sets, one for \n&gt; &gt; &gt;=\r\n &gt; the &quot;type A \n&gt; &gt; &gt; &gt; &gt; info&quot; and one for &quot;type B info.&quot;  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; &gt; &gt; The way this would look is e.g. if A was 2D and B was 2D \nthen \n&gt; &gt; =\r\nthe \n&gt; &gt; &gt; &gt; CPPN \n&gt; &gt; &gt; &gt; &gt; would have 4 inputs, 2 represent A source node=\r\ns and 2 \n&gt; &gt; &gt; representing \n&gt; &gt; &gt; &gt; B \n&gt; &gt; &gt; &gt; &gt; soource nodes.\n&gt; &gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; &gt; Then, I would still have only one set of outputs.  I am \nstill \n=\r\n&gt; a \n&gt; &gt; &gt; &gt; little \n&gt; &gt; &gt; &gt; &gt; unclear on why you say the outputs are from =\r\nthe second \n&gt; &gt; &gt; substrate?  \n&gt; &gt; &gt; &gt; In \n&gt; &gt; &gt; &gt; &gt; my understanding, this=\r\n is still all one substrate, it&#39;s \njust \n&gt; &gt; that \n&gt; &gt; &gt; &gt; it \n&gt; &gt; &gt; &gt; &gt; co=\r\nllects inputs from two different sources.  But it can \nstill \n&gt; &gt; &gt; exist \n=\r\n&gt; &gt; &gt; &gt; &gt; with only one set of outputs.  So if the outputs are 2D, \nthe \n&gt; =\r\n&gt; CPPN \n&gt; &gt; &gt; &gt; would \n&gt; &gt; &gt; &gt; &gt; have 2 more inputs representing the output=\r\n area for a total \n&gt; of \n&gt; &gt; 6 \n&gt; &gt; &gt; &gt; inputs \n&gt; &gt; &gt; &gt; &gt; (and one output r=\r\nepresenting the weight of a connection in \n&gt; the \n&gt; &gt; &gt; &gt; &gt; substrate).\n&gt; &gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; If there was a hidden layer you could have it exist in \ne=\r\nither \n&gt; &gt; the \n&gt; &gt; &gt; &gt; same \n&gt; &gt; &gt; &gt; &gt; geometry as A, the same geometry as=\r\n B, or the same geometry \n&gt; as \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; outputs.  (For example=\r\n by introducing a z dimension to any \nof \n&gt; &gt; &gt; &gt; these)  \n&gt; &gt; &gt; &gt; &gt; Or you=\r\n could have each kind of hidden layer all at once.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Of =\r\ncourse, as you note, there are a lot of ways to do \n&gt; something \n&gt; &gt; &gt; &gt; li=\r\nke \n&gt; &gt; &gt; &gt; &gt; this.  I think it will be a great issue to explore, but it \n&gt;=\r\n may \n&gt; &gt; &gt; &gt; require \n&gt; &gt; &gt; &gt; &gt; starting with a very simple domain that is=\r\nolates the issue \n&gt; &gt; (i.e. \n&gt; &gt; &gt; &gt; &gt; orthogonal input types) so we can co=\r\nncentrate on that \nrather \n&gt; &gt; than \n&gt; &gt; &gt; &gt; on a \n&gt; &gt; &gt; &gt; &gt; specific domai=\r\nn with its own complications.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; One other issue to note =\r\nis that even if two sets of inputs \n&gt; are \n&gt; &gt; in \n&gt; &gt; &gt; &gt; &gt; effect unrelat=\r\ned, it may not necessarily hurt antyhing to \nput \n&gt; &gt; &gt; them \n&gt; &gt; &gt; &gt; in \n&gt;=\r\n &gt; &gt; &gt; &gt; the same geometry.  For example, they could be two separate \n&gt; &gt; &gt;=\r\n planes \n&gt; &gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; &gt; the same cube.  On the face of it, it seems =\r\nlike that could \n&gt; &gt; cause \n&gt; &gt; &gt; &gt; &gt; problems, but we don&#39;t yet know wheth=\r\ner the situation is \nthat \n&gt; &gt; &gt; &gt; difficult \n&gt; &gt; &gt; &gt; &gt; to deal with in pra=\r\nctice.  There could also be hidden \n&gt; &gt; &gt; relationships \n&gt; &gt; &gt; &gt; &gt; that are=\r\n not obvious but still exploitable in a surprising \n&gt; way.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; --- In neat@=\r\nyahoogroups.com, &quot;Thomas Johnson&quot; \n&gt; &gt; &lt;thomas.j.johnson@&gt; \n&gt; &gt; &gt; &gt; &gt; wrote=\r\n:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; HyperNEAT folks,\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; What&#39;s =\r\nthe recommended strategy for handling inputs that \n&gt; &gt; &gt; &gt; represent \n&gt; &gt; &gt;=\r\n &gt; &gt; concepts\n&gt; &gt; &gt; &gt; &gt; &gt; that are not geometrically related? For instance,=\r\n \nconsider \n&gt; &gt; &gt; &gt; something \n&gt; &gt; &gt; &gt; &gt; like a\n&gt; &gt; &gt; &gt; &gt; &gt; poker game wher=\r\ne we want to input both players&#39; actions \nand \n&gt; &gt; the \n&gt; &gt; &gt; &gt; cards \n&gt; &gt; =\r\n&gt; &gt; &gt; we\n&gt; &gt; &gt; &gt; &gt; &gt; see. We might be able to come up with geometric encodi=\r\nngs \n&gt; for \n&gt; &gt; &gt; &gt; either \n&gt; &gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; these individually, bu=\r\nt there&#39;s no obvious spacial \n&gt; &gt; relationship \n&gt; &gt; &gt; &gt; &gt; between\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; cards and actions.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}