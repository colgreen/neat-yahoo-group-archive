{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234280965,"authorName":"Daniel Larkin","from":"Daniel Larkin &lt;larkind@...&gt;","profile":"daniel.larkin","replyTo":"LIST","senderId":"GA9UBA9jNyklmRFVYURW-g6GUGQ7Yu7K10FZRD1dVSTd0jU-Murx1NstlHRBljdApdTpfb0JXh47z4sNnC5m6AI26SdQaEU3EbM","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Parallel NEAT","postDate":"1159178829","msgId":2764,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1MTdBQTRELjUwNDAxMDZAZWVuZy5kY3UuaWU+","inReplyToHeader":"PDIwMDYwOTIwMjE1NzMxLjgxMzQxLnFtYWlsQHdlYjYxMjI1Lm1haWwueWFob28uY29tPg==","referencesHeader":"PDIwMDYwOTIwMjE1NzMxLjgxMzQxLnFtYWlsQHdlYjYxMjI1Lm1haWwueWFob28uY29tPg=="},"prevInTopic":2762,"nextInTopic":2765,"prevInTime":2763,"nextInTime":2765,"topicId":2753,"numMessagesInTopic":7,"msgSnippet":"Hi Sidhant, I ve done some work on hardware implementations of the neural network evaluations in NEAT. The classical implementations of neural networks in ","rawEmail":"Return-Path: &lt;larkind@...&gt;\r\nX-Sender: larkind@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 32403 invoked from network); 25 Sep 2006 10:07:54 -0000\r\nReceived: from unknown (66.218.67.34)\n  by m36.grp.scd.yahoo.com with QMQP; 25 Sep 2006 10:07:54 -0000\r\nReceived: from unknown (HELO pine.eeng.dcu.ie) (136.206.35.46)\n  by mta8.grp.scd.yahoo.com with SMTP; 25 Sep 2006 10:07:54 -0000\r\nReceived: from [136.206.26.172] (helo=[136.206.26.172])\n\tby pine.eeng.dcu.ie with esmtp (Exim 4.20)\n\tid 1GRnIs-0007HB-Eu\n\tfor neat@yahoogroups.com; Mon, 25 Sep 2006 11:03:10 +0100\r\nMessage-ID: &lt;4517AA4D.5040106@...&gt;\r\nDate: Mon, 25 Sep 2006 11:07:09 +0100\r\nUser-Agent: Mozilla Thunderbird 1.0.6 (X11/20050716)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;20060920215731.81341.qmail@...&gt;\r\nIn-Reply-To: &lt;20060920215731.81341.qmail@...&gt;\r\nX-Enigmail-Version: 0.90.1.0\r\nX-Enigmail-Supports: pgp-inline, pgp-mime\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Daniel Larkin &lt;larkind@...&gt;\r\nSubject: Re: [neat] Parallel NEAT\r\nX-Yahoo-Group-Post: member; u=234280965; y=Gfu8UmnDAyeXu99cyDNoXTKsG-is-Q7fTuEFvVNUim2fnuLHSCWj7A\r\nX-Yahoo-Profile: daniel.larkin\r\n\r\nHi Sidhant,\n\nI&#39;ve done some work on hardware implementations of the neural network\nevaluations in NEAT. The classical implementations of neural networks in\nhardware use systolic arrays, which are hugely beneficial for a memory\nbound problem such as ANNs. You can then use as many processing elements\nas is necessary to reach your required throughput. However, this assumes\na fully connected and ideally a feedforward layered network. The issue\nas I see it, is that sparse networks (such as that which will be\nfavoured naturally by NEAT) disrupts the dataflow through the array.\nWhilst not terminal, the efficiency per logic gate drops off\ndramatically then with a systolic array and sparse network. But (in my\nopinion) the greater problem with using a systolic array architecture is\nthat the potential for an evolved solution with forward, recurrent, and\nlooped recurrent synaptic connections in a non layered topology  will\nresult in considerable routing and mux&#39;ing, in addition to far from\ntrivial control logic.\n\nAn alternative is a design which in some way looks like a very wide SIMD\nprocessor datapath, whereby multiple synaptic calculations are\ncalculated per clock cycle. But then memory bandwidth becomes an issue\nfor really parallizing the task for really high throughput.\n\nIf anyone has any other opinions I&#39;d be delighted to hear them\n\n\nDaniel\n\nSidhant Dash wrote:\n&gt; \n&gt; \n&gt; Hi all,\n&gt;  \n&gt; I wanted to know if there are any parallel implementations of NEAT that\n&gt; may be available for use. Sometime ago I remember seeing something on\n&gt; the group about some hardware thats optimised to run a parallel version\n&gt; of NEAT (it was something like this, cant be sure though). Has some\n&gt; version of NEAT been built along these lines?\n&gt;  \n&gt; thanks,\n&gt; Sidhant\n&gt;  \n&gt; \n&gt; \n&gt; Fear is only as deep as the mind allows.\n&gt; --Japanese proverb\n&gt; \n&gt; My blog &lt;http://sidhantdash.blogspot.com&gt;  \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; Get your own web address for just $1.99/1st yr &lt;\n&gt; http://us.rd.yahoo.com/evt=43290/*http://smallbusiness.yahoo.com/domains&gt;.\n&gt; We&#39;ll help. Yahoo! Small Business\n&gt; &lt;http://us.rd.yahoo.com/evt=41244/*http://smallbusiness.yahoo.com/&gt;.\n&gt; \n\n"}}