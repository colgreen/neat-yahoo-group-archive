{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"53yU10NDPJz_q8rV4KIZI0bQDo0L1Lw101ZUetEJtYVH_veFHG86Z6sc832DEvV1xTq_O4u1jBkmvyG_-Lo3eqxfBUfT","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HyperNEAT Tutorial?","postDate":"1260304996","msgId":4985,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhmbWRwNCtlaXFpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM3M0MwREY2LjJFRDYzJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4970,"nextInTopic":5084,"prevInTime":4984,"nextInTime":4986,"topicId":4884,"numMessagesInTopic":21,"msgSnippet":"We re still thinking about whether to provide a wiki or try to provide more something more static.  The wiki presents several possible challenges.  For","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 46177 invoked from network); 8 Dec 2009 20:43:18 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m1.grp.sp2.yahoo.com with QMQP; 8 Dec 2009 20:43:18 -0000\r\nX-Received: from unknown (HELO n42b.bullet.mail.sp1.yahoo.com) (66.163.168.156)\n  by mta3.grp.re1.yahoo.com with SMTP; 8 Dec 2009 20:43:18 -0000\r\nX-Received: from [69.147.65.174] by n42.bullet.mail.sp1.yahoo.com with NNFMP; 08 Dec 2009 20:43:17 -0000\r\nX-Received: from [98.137.35.12] by t12.bullet.mail.sp1.yahoo.com with NNFMP; 08 Dec 2009 20:43:17 -0000\r\nDate: Tue, 08 Dec 2009 20:43:16 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hfmdp4+eiqi@...&gt;\r\nIn-Reply-To: &lt;C73C0DF6.2ED63%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: HyperNEAT Tutorial?\r\nX-Yahoo-Group-Post: member; u=54567749; y=1HxfWVdAHeSSS5d6ytt6JNfrvWJHRTA5JMNIPTi3QMQN-HtOUPQ-\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nWe&#39;re still thinking about whether to provide a wiki or try to provide mo=\r\nre something more static.  The wiki presents several possible challenges.  =\r\nFor example, it could turn out sparse or die out if not enough people add t=\r\no it.  On the other hand, it could fill up with inaccurate information or e=\r\nven spam, which would require policing.  At the moment we are considering m=\r\nore static tutorial-like introductions but a wiki is a possibility.  If peo=\r\nple have thoughts on the Wiki idea I am happy to hear them. \n\nken\n\n--- In n=\r\neat@yahoogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello all-\n&gt; \n&gt; I l=\r\nike the idea of a tutorial, especially with respect to the many HyperNEAT\n&gt;=\r\n (NEAT) parameters. For example, I just had a question internally about wha=\r\nt\n&gt; the SpeciesSizeTarget would be, and had to search around for a while to=\r\n find\n&gt; the thread on the NEAT list where I had previously asked about this=\r\n\n&gt; parameter (and Ken provided a helpful answer, pasted below).\n&gt; \n&gt; It wou=\r\nld be great to capture this knowledge in a wiki, instead of just in\n&gt; this =\r\nforum, and let people add their own thoughts. That way, a researcher\n&gt; coul=\r\nd read a paragraph or three about the parameter they are wondering\n&gt; about,=\r\n which can help them understand it and possibly optimize it for their\n&gt; pro=\r\nblem. It would probably also highlight which parameters we have not yet\n&gt; h=\r\nad discussions about, so people can fill in their own rules of thumb for\n&gt; =\r\nthat parameter. \n&gt; \n&gt; Here was Ken&#39;s reply about SpeciesSizeTarget:\n&gt; &gt;&gt;&gt; I=\r\n haven&#39;t seen any explicit studies on population size in NEAT\n&gt; &gt;&gt;&gt; specifi=\r\ncally, but there have been such studies for genetic algorithms\n&gt; &gt;&gt;&gt; in gen=\r\neral. I think Kenneth De Jong&#39;s textbook, &quot;Evolutionary\n&gt; &gt;&gt;&gt; Computation: =\r\nA Unified Perspective&quot; examines it.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; However, of course as peopl=\r\ne have pointed out in NEAT it&#39;s not just a\n&gt; &gt;&gt;&gt; question of a healthy popu=\r\nlation but of healthy species, since each\n&gt; &gt;&gt;&gt; species is like its own lit=\r\ntle population. In other words, the\n&gt; &gt;&gt;&gt; species need enough internal dive=\r\nrsity to drive their own\n&gt; &gt;&gt;&gt; explorations. My own rule of thumb has been =\r\na minimum of 15 members\n&gt; &gt;&gt;&gt; per species (on average) to keep them healthy=\r\n. I&#39;m sure 30 is even\n&gt; &gt;&gt;&gt; safer.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; Another thing to note is tha=\r\nt the population size you need can vary\n&gt; &gt;&gt;&gt; wildly by problem and it can =\r\nbe surprising. For pole balancing, it\n&gt; &gt;&gt;&gt; turns out that you can solve it=\r\n fastest with a minuscule population of\n&gt; &gt;&gt;&gt; size under 20 total (that&#39;s f=\r\nor the whole population!). That is\n&gt; &gt;&gt;&gt; because smaller populations are gr=\r\needier (they concentrate resources\n&gt; &gt;&gt;&gt; on a small part of the search spac=\r\ne) and apparently pole balancing\n&gt; &gt;&gt;&gt; benefits greatly from greedy search.=\r\n However, that is a specific\n&gt; &gt;&gt;&gt; property of pole balancing and I would n=\r\not expect it to carry over to\n&gt; &gt;&gt;&gt; more significant domains. Surely in som=\r\ne domains having a population\n&gt; &gt;&gt;&gt; over 1000 would lead to the most intere=\r\nsting results, if only you can\n&gt; &gt;&gt;&gt; afford the luxury of the added computa=\r\ntional cost of a large population.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Cheers,\n&gt; Jeff Clune\n&gt; \n&gt; =\r\nDigital Evolution Lab, Michigan State University\n&gt; jclune@...\n&gt; www.msu.edu=\r\n/~jclune\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; &gt; From: Ken &lt;kstanley@...&gt;\n&gt; &gt; Reply-To: &quot;neat@yahoo=\r\ngroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; Date: Sat, 28 Nov 2009 22:00:25 -000=\r\n0\n&gt; &gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; Subject: [neat]=\r\n Re: HyperNEAT Tutorial?\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Anthony,\n&gt; &gt; \n&gt; &gt; We are hoping=\r\n to make the HyperNEAT Users Page at\n&gt; &gt; http://eplex.cs.ucf.edu/hyperNEATp=\r\nage/HyperNEAT.html into a place where people\n&gt; &gt; can have questions like yo=\r\nurs answered.  The &quot;Introduction / What is\n&gt; &gt; HyperNEAT?&quot; section on that =\r\npage is intended to provide some general answers\n&gt; &gt; to beginners without h=\r\naving to read a research paper.  Did that section help\n&gt; &gt; you at all?  I&#39;d=\r\n like to make the page as useful as possible and we will\n&gt; &gt; continue to im=\r\nprove it.\n&gt; &gt; \n&gt; &gt; To answer your question, HyperNEAT is a significant step=\r\n beyond NEAT so it\n&gt; &gt; involves a lot of new ideas that aren&#39;t part of the =\r\noriginal NEAT.  Some of\n&gt; &gt; those concepts can theoretically be applied on =\r\ntop of non-NEAT methods.  For\n&gt; &gt; example, in the following paper, NEAT is =\r\nsubstituted with GP to create a\n&gt; &gt; &quot;HyperGP,&quot; in which GP evolves the CPPN=\r\n:\n&gt; &gt; \n&gt; &gt; Buk Z., Koutn=EDk J., =8Anorek M., NEAT in HyperNEAT Substituted=\r\n with Genetic\n&gt; &gt; Programming, In: ICANNGA 2009.\n&gt; &gt; http://cig.felk.cvut.c=\r\nz/research/publications/hypergp.pdf\n&gt; &gt; \n&gt; &gt; That said, HyperNEAT addresses=\r\n a limitation of NEAT, which is a limitation of\n&gt; &gt; all direct encodings:  =\r\nIn NEAT, there is one gene for every connection in the\n&gt; &gt; network.  Even w=\r\nith complexification, that kind of representation cannot hope\n&gt; &gt; to scale =\r\nto networks with millions or more connections, because such networks\n&gt; &gt; wo=\r\nuld have millions or more genes, which is an astronomical search space.\n&gt; &gt;=\r\n \n&gt; &gt; However, there are in fact 100 trillion connections in the human brai=\r\nn, which\n&gt; &gt; means that in principle it is possible to evolve such structur=\r\nes.  Yet there\n&gt; &gt; are only about 30,000 genes in the human genome, which s=\r\nuggests that any\n&gt; &gt; evolutionary approach to evolving large-scale neural n=\r\networks must encode the\n&gt; &gt; connection weights in a compressed description,=\r\n which is called an indirect\n&gt; &gt; encoding.\n&gt; &gt; \n&gt; &gt; In HyperNEAT, the indir=\r\nect encoding is the CPPN, which encodes the\n&gt; &gt; connectivity of a network a=\r\ns a pattern across its geometry.  HyperNEAT\n&gt; &gt; combines the idea of indire=\r\nct encoding with a strong notion of geometry and\n&gt; &gt; builds on our understa=\r\nnding of encoding patterns to produce an algorithm that\n&gt; &gt; encodes large-s=\r\ncale topographies (i.e. connection weights across a geometry).\n&gt; &gt; Thus it =\r\nextends NEAT by giving it the power of indirect encoding, thereby\n&gt; &gt; great=\r\nly expanding the scope of networks it can evolve.\n&gt; &gt; \n&gt; &gt; Of course NEAT i=\r\ns still there under the hood.  NEAT is evolving the CPPNs,\n&gt; &gt; which in tur=\r\nn encode neural networks (called substrates in HyperNEAT).  The\n&gt; &gt; CPPNs t=\r\nhemselves are still complexifying.  However, that complexification is\n&gt; &gt; n=\r\no longer literally adding one connection at a time to a neural network.\n&gt; &gt;=\r\n Rather it is adding *information* to the encoding, so that it can encode m=\r\nore\n&gt; &gt; complex *holistic* connectivity patterns.  In other words, HyperNEA=\r\nT means\n&gt; &gt; that evolution is no longer limited by the dimensionality of th=\r\ne inputs and\n&gt; &gt; outputs but rather can search for the correct implicit pro=\r\nblem complexity,\n&gt; &gt; whatever that may be, inside the CPPN.  The substrate =\r\n(which the CPPN encodes)\n&gt; &gt; will then have as many connections as it needs=\r\n, in principle up to millions or\n&gt; &gt; even trillions (with enough CPU power)=\r\n.\n&gt; &gt; \n&gt; &gt; It is true that geometry may be vague or difficult to decide in =\r\nsome problems.\n&gt; &gt; Those may be more difficult for users to approach with H=\r\nyperNEAT.  Yet I think\n&gt; &gt; most if not all problems can ultimately be posed=\r\n within some geometry, even if\n&gt; &gt; it is abstract or conceptual.  As Jeff C=\r\nlune has shown\n&gt; &gt; (https://www.msu.edu/~jclune/webfiles/publications/Clune=\r\n-HyperNEATSensitivityT\n&gt; &gt; oGeometry.pdf), geometry does not need to be per=\r\nfect, or necessarily even\n&gt; &gt; close to perfect, for HyperNEAT to still find=\r\n some regularities to exploit, so\n&gt; &gt; while it may be an imperfect art, geo=\r\nmetry is still ultimately a useful tool\n&gt; &gt; for conveying exploitable infor=\r\nmation about a domain.\n&gt; &gt; \n&gt; &gt; I hope that provides some insight,\n&gt; &gt; \n&gt; &gt;=\r\n ken\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Anthony Ison&quot; &lt;anthony.iso=\r\nn@&gt; wrote:\n&gt; &gt;&gt; \n&gt; &gt;&gt; I&#39;d like to add my vote to some kind of non-research =\r\nstyle tutorial -\n&gt; &gt;&gt; especially towards the HyperNEAT methodology.\n&gt; &gt;&gt; \n&gt;=\r\n &gt;&gt;  \n&gt; &gt;&gt; \n&gt; &gt;&gt; Is there somewhere I can get an overview of how the CPPN i=\r\ns actually\n&gt; &gt;&gt; used and what it does?  I&#39;ve looked through a number of pap=\r\ners on the\n&gt; &gt;&gt; main HyperNEAT site, but I feel like I&#39;m missing something.=\r\n  I have read\n&gt; &gt;&gt; that HyperNEAT is the future of NEAT - does this apply t=\r\no problems where\n&gt; &gt;&gt; there is no useful input geometry?  I understand how =\r\nNEAT grows a\n&gt; &gt;&gt; network by adding nodes and connections and overall I lov=\r\ne the concept.\n&gt; &gt;&gt; It makes sense that a learning network can adjust itsel=\r\nf to improve its\n&gt; &gt;&gt; performance.  What I don&#39;t really understand is how a=\r\n CPPN is involved\n&gt; &gt;&gt; in this process.\n&gt; &gt;&gt; \n&gt; &gt;&gt;  \n&gt; &gt;&gt; \n&gt; &gt;&gt; Is anyone a=\r\nble to give a short overview on what HyperNEAT offers over\n&gt; &gt;&gt; NEAT?\n&gt; &gt;&gt; =\r\n\n&gt; &gt;&gt;  \n&gt; &gt;&gt; \n&gt; &gt;&gt; Cheers,\n&gt; &gt;&gt; \n&gt; &gt;&gt; Anthony\n&gt; &gt;&gt; \n&gt; &gt;&gt;  \n&gt; &gt;&gt; \n&gt; &gt;&gt;  \n&gt; &gt;=\r\n&gt; \n&gt; &gt;&gt; From: dkuppitz [mailto:daniel_kuppitz@]\n&gt; &gt;&gt; Sent: Monday, 23 Novem=\r\nber 2009 9:08 AM\n&gt; &gt;&gt; To: neat@yahoogroups.com\n&gt; &gt;&gt; Subject: [neat] Re: Hyp=\r\nerNEAT Tutorial?\n&gt; &gt;&gt; \n&gt; &gt;&gt;  \n&gt; &gt;&gt; \n&gt; &gt;&gt;   \n&gt; &gt;&gt; \n&gt; &gt;&gt; Hello Ken,\n&gt; &gt;&gt; \n&gt; &gt;=\r\n&gt; here&#39;s just another vote for a tutorial, with the difference that I\n&gt; &gt;&gt; =\r\nwould prefer it for HyperSharpNEAT.\n&gt; &gt;&gt; \n&gt; &gt;&gt; It would be great to see som=\r\nething like a HOL (Hands on Labs) where a\n&gt; &gt;&gt; new experiment is created fr=\r\nom the scratch. Parameters should be\n&gt; &gt;&gt; explained in detail, for example:=\r\n Which impact has the parameter\n&gt; &gt;&gt; Treshold, which impact has WeightRange=\r\n, etc.? How are the values for\n&gt; &gt;&gt; each parameter determined, what is take=\r\nn into account when you set the\n&gt; &gt;&gt; values? There are so many unanswered q=\r\nuestions for those who are new to\n&gt; &gt;&gt; HyperNEAT and I think most people (i=\r\nncluding me) have a really great\n&gt; &gt;&gt; interest in this topic, but not the t=\r\nime to read (and understand) all\n&gt; &gt;&gt; the technical papers. So any tutorial=\r\n should target beginners and\n&gt; &gt;&gt; explain things that have become self-evid=\r\nent for intermediates.\n&gt; &gt;&gt; \n&gt; &gt;&gt; I think one such &quot;official&quot; tutorial that=\r\n explains every step in detail\n&gt; &gt;&gt; should be enough, more will surely foll=\r\now from the growing community.\n&gt; &gt;&gt; \n&gt; &gt;&gt; Cheers,\n&gt; &gt;&gt; Daniel\n&gt; &gt;&gt; \n&gt; &gt;&gt; --=\r\n- In neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.com&gt; , &quot;Ken&quot;\n&gt; &gt;&gt; &lt;kst=\r\nanley@&gt; wrote:\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; Andrei, which version of HyperNEA=\r\nT are you interested in and what\n&gt; &gt;&gt; references have you looked at so far?=\r\n We can potentially improve the\n&gt; &gt;&gt; documentation based on your comments (=\r\nand a tutorial is a good idea),\n&gt; &gt;&gt; but first I want to understand which &quot;=\r\ncomment-less examples&quot; you are\n&gt; &gt;&gt; referring to.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; Note that se=\r\nveral experiments with complete source code are available\n&gt; &gt;&gt; in two exist=\r\ning HyperNEAT releases of which I am aware. These and a\n&gt; &gt;&gt; variety of pub=\r\nlications from several groups are linked from the\n&gt; &gt;&gt; HyperNEAT Users Page=\r\n, which also provides a brief introduction:\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; http://eplex.cs.uc=\r\nf.edu/hyperNEATpage/HyperNEAT.html\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; I understand you may have a=\r\nlready been through this site and its\n&gt; &gt;&gt; associated software and papers, =\r\nbut I wanted to point it out in case you\n&gt; &gt;&gt; had not been aware of it.\n&gt; &gt;=\r\n&gt;&gt; \n&gt; &gt;&gt;&gt; We want to make the algorithm as accessible as possible so your\n&gt;=\r\n &gt;&gt; comments are appreciated.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; ken\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; --- In neat@yah=\r\noogroups.com &lt;mailto:neat%40yahoogroups.com&gt; , &quot;Andrei&quot;\n&gt; &gt;&gt; &lt;andrei.rusu@&gt;=\r\n wrote:\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Can anyone please recommend some HyperNEAT documenta=\r\ntion, a\n&gt; &gt;&gt; tutorial, diagram, some clue, or anything that does not mean r=\r\neverse\n&gt; &gt;&gt; engineering the comment-less examples ?\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Thanks! =\r\nAndrei.\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}