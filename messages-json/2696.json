{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"8fvMPBIK4ZmHt8CcJx80XFpObLL5txBWWKoAWjVFY0M8LCha32UGIliPjLcANFAGlwumvfR79-KhGalxn2WrZP3O3I4TL5zkXjC67y86Ln4N","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: NEAT enhancements","postDate":"1155032133","msgId":2696,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGViOW84NSttbmlyQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDYwODAzMTg1MDUyLjc3Njk1LnFtYWlsQHdlYjYxMjE1Lm1haWwueWFob28uY29tPg=="},"prevInTopic":2692,"nextInTopic":2697,"prevInTime":2695,"nextInTime":2697,"topicId":2684,"numMessagesInTopic":17,"msgSnippet":"Sidhant, I have to say that your paper is a great accomplishment for a 3-month undergraduate research project. The scope of this project and amount of","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 91435 invoked from network); 8 Aug 2006 10:24:08 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m28.grp.scd.yahoo.com with QMQP; 8 Aug 2006 10:24:08 -0000\r\nReceived: from unknown (HELO n14a.bullet.scd.yahoo.com) (66.94.237.28)\n  by mta1.grp.scd.yahoo.com with SMTP; 8 Aug 2006 10:24:08 -0000\r\nReceived: from [66.218.66.59] by n14.bullet.scd.yahoo.com with NNFMP; 08 Aug 2006 10:15:33 -0000\r\nReceived: from [66.218.66.87] by t8.bullet.scd.yahoo.com with NNFMP; 08 Aug 2006 10:15:33 -0000\r\nDate: Tue, 08 Aug 2006 10:15:33 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;eb9o85+mnir@...&gt;\r\nIn-Reply-To: &lt;20060803185052.77695.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: NEAT enhancements\r\nX-Yahoo-Group-Post: member; u=54567749; y=tQpDmjLSaLdyKIjW-6eU1rgP8BZzZti3ARJkOjcsauu9bkfOM0js\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nSidhant, I have to say that your paper is a great accomplishment for\na 3-mo=\r\nnth undergraduate research project. The scope of this project\nand amount of=\r\n technical work involved is enormous. It is\nfurthermore impressive that thi=\r\ns was your first attempt at technical\nwriting (Sidhant told me this in sepa=\r\nrate email), since I found it\nto be more clear than many papers I have to r=\r\neview for scientific\njournals.\n\nFor anyone who is interested in time series=\r\n prediction with NEAT\n(including financial time series), I highly recommend=\r\n this work. It\nis a bit long, but I was able to read it in one sitting sinc=\r\ne it was\nso clear and well-organized. I would even recommend this to people=\r\n\nwho have no interest or experience in this area, since it makes\nquite a go=\r\nod tutorial on a number of technologies outside NEAT\nitself, including conj=\r\nugate gradient descent, elman networks, RTRL\nnetworks, boosting, and ensemb=\r\nle methods. Sidhant, how did you\nprogram all this stuff in 3 months?\n\nThe w=\r\nork is furthermore creative in that it modifies NEAT to evolve\nnew kinds of=\r\n NNs (Elman and RTRL), and comes up with ways to keep\nall 3 types of nets (=\r\nthe new ones plus MLPs) in the population at\nonce.\n\nSome of the people in t=\r\nhis group know that I am not generally in\nfavor of combining numerous metho=\r\nds simply for the sake of combining\nthem, but in this case the combinations=\r\n seem to have been selected\ncleverly, making for a compelling case for a ve=\r\nry effective overall\nmethod for time series predicition.\n\nI do have a few q=\r\nuestions for Sidhant: The primary issue that I\ndon&#39;t understand is why the =\r\nruns in the financial time series only\nlasted under 20 generations? How muc=\r\nh structure can even evolve in\nsuch a short time? It appears in one case th=\r\nat 6 new hidden nodes\nwere added, but in only 20 generations? That seems pe=\r\nrhaps\nunnecessarily fast in terms of structural mutation rate. Maybe you\nwo=\r\nuld have gotten even better results with a lower node-\naddition/link-additi=\r\non rate and a run of 100 or more generations,\ngiving NEAT more time to weig=\r\nht-optimize each new structural\naddition.\n\nFinally, out of curiosity, is th=\r\nis level of predicition financially \nprofitable or useful to trading compan=\r\nies?\n\nOverall, excellent work; thank you for sharing! I suggest that you\nco=\r\nnsider publishing this work in a conference or journal.\n\nken\n\n--- In neat@y=\r\nahoogroups.com, Sidhant Dash &lt;sidhantdash@...&gt; wrote:\n&gt;\n&gt; As part of an und=\r\nergraduate research project, I did implement \nsomething on those lines. \n&gt; =\r\n   \n&gt;   I worked on a NEAT based approach to predicting a noisy \nfinancial =\r\ntime series (Yen-USD exchange rate). The original NEAT \nalgorithm was modif=\r\nied to start with an initial population of 3 \ndifferent neural network arch=\r\nitectures, which included Elman \nnetworks and MLPs apart from the normal re=\r\ncurrent networks that NEAT \nbegins with. The networks (winners) produced by=\r\n NEAT were then put \nthrough a conjugate gradient based optimization proces=\r\ns, and finally \nthe optimized networks were combined using an ensembling te=\r\nchnique \nto produce the final results. \n&gt;    \n&gt;   I personally think the lo=\r\ncal optimization is necessary when we \nare using NEAT to produce networks t=\r\no accomplish tasks that require \na high degree of precision. It kind of fin=\r\ne tunes the performance of \nthe networks. Ensembling then is one of the sta=\r\nndard tools in the ML \nrepertoire to produce results that none of NEAT&#39;s &#39;w=\r\ninner&#39; networks \ncould individually produce. \n&gt;    \n&gt;   A detailed project =\r\nreport is posted in the Files section.\n&gt;    \n&gt;   regards\n&gt;   Sidhant\n&gt; \n&gt; a=\r\nklein07 &lt;a.klein@...&gt; wrote:\n&gt;           All,\n&gt; \n&gt; Ken&#39;s papers mention (at=\r\n least I think that they do) that \n(dynamic) \n&gt; annealing of mutation rates=\r\n might be advantageous in order to \nconfine \n&gt; global searching after a whi=\r\nle to a promising region in search \nspace. \n&gt; Having read some papers, I al=\r\nso found indications that a hybrid \n&gt; weight training algorithm (global sea=\r\nrch by means of genetic \n&gt; algorithms and local search using some gradient =\r\ndescent algorithm) \n&gt; might be able to produce better results than genetic =\r\nalgorithm \nsearch \n&gt; alone. The reason is, that each type of algorithm perf=\r\norms well \n&gt; mostly only in its specific field. Has anyone further insights=\r\n \ninto \n&gt; this topic ? Has anyone tried to implement any of the approaches =\r\n\n&gt; mentioned ? \n&gt; \n&gt; Also time delay network connections might provide impr=\r\novements for \n&gt; some model estimation tasks. Has anyone tested / implemente=\r\nd yet \nany \n&gt; of these ideas ?\n&gt; \n&gt; Thanks for any comments,\n&gt; Achim\n&gt; \n&gt; \n=\r\n&gt; \n&gt;          \n&gt; \n&gt; \n&gt; Fear is only as deep as the mind allows. \n&gt; --Japane=\r\nse proverb \n&gt; \n&gt; My blog   \n&gt; \n&gt;  \t\t\n&gt; ---------------------------------\n&gt; =\r\nGroups are talking. We&acute;re listening. Check out the handy \nchanges to =\r\nYahoo! Groups.\n&gt;\n\n\n\n\n\n"}}