{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"oDQNj1zaEB1kl9DigriWlnCbcf5QzGsUoq0bT3dGPt3p08FDWHpUHZCnIWUzZWgZ6icQzGmxl9oqcUBDxxHCvGnwfs3cNmRUyMoNclUiMZkj","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Benchmarks for Artificial Embryogeny Systems","postDate":"1219186202","msgId":4282,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGc4ZmltcSs2bTg4QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDE5YjEwZDUxMDgwODE2MTA1NGpmNTkwYWM4cDZjNWQ2MTUyNzU5NDMwNDRAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":4281,"nextInTopic":4285,"prevInTime":4281,"nextInTime":4283,"topicId":4244,"numMessagesInTopic":20,"msgSnippet":"... There is a Picbreeder user named Robert who seems to have set out to answer that question!  He kind of launched a large-scale study of simple shapes. ","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 84611 invoked from network); 19 Aug 2008 22:50:05 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m46.grp.scd.yahoo.com with QMQP; 19 Aug 2008 22:50:05 -0000\r\nX-Received: from unknown (HELO n35b.bullet.mail.sp1.yahoo.com) (66.163.168.149)\n  by mta17.grp.scd.yahoo.com with SMTP; 19 Aug 2008 22:50:05 -0000\r\nX-Received: from [216.252.122.219] by n35.bullet.mail.sp1.yahoo.com with NNFMP; 19 Aug 2008 22:50:03 -0000\r\nX-Received: from [209.73.164.86] by t4.bullet.sp1.yahoo.com with NNFMP; 19 Aug 2008 22:50:03 -0000\r\nX-Received: from [66.218.66.76] by t8.bullet.scd.yahoo.com with NNFMP; 19 Aug 2008 22:50:02 -0000\r\nDate: Tue, 19 Aug 2008 22:50:02 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g8fimq+6m88@...&gt;\r\nIn-Reply-To: &lt;19b10d510808161054jf590ac8p6c5d615275943044@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Benchmarks for Artificial Embryogeny Systems\r\nX-Yahoo-Group-Post: member; u=54567749; y=UuW3mmdFCcl9jNUR6YyEfRV4pNWvRc20oV2UZFUTwlMDBaK0_k4q\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n--- In neat@yahoogroups.com, &quot;Derek James&quot; &lt;djames@...&gt; wrote:\n&gt;\n&gt; On Wed, =\r\nAug 13, 2008 at 11:46 AM, Kenneth Stanley\n&gt; &lt;kstanley@...&gt; wrote:\n&gt; &gt; Derek=\r\n, it took me a little time to respond but I did want to address\n&gt; &gt; some of=\r\n your points..\n&gt; \n&gt; Thanks for responding, Ken. I do think it&#39;s an interest=\r\ning discussion.\n&gt; \n&gt; &gt; Yes I agree, it&#39;s the general case of getting stuck.=\r\n Which is why I\n&gt; &gt; think benchmarks are a tricky business in any field, no=\r\nt just in AE.\n&gt; &gt; However, I do not think it is particularly important if a=\r\n particular\n&gt; &gt; candidate (which I guess means a run of evolution) fails to=\r\n represent\n&gt; &gt; a simple target. Just because it doesn&#39;t do it does not mean=\r\n that it\n&gt; &gt; cannot do it, and if the fitness function does not reward the =\r\nproper\n&gt; &gt; stepping stones, then it doesn&#39;t seem very significant for the\n&gt;=\r\n &gt; encoding that it did or did not end up hitting a target in one run.\n&gt; \n&gt;=\r\n Right, which is why you&#39;d want to do many runs, and even then you&#39;d\n&gt; want=\r\n to be careful about categorically claiming what the AE system\n&gt; cannot rep=\r\nresent.\n&gt; \n&gt; I think it would be particularly interesting to carry out some=\r\n of the\n&gt; benchmarks you suggested in your paper in the context of artifici=\r\nal\n&gt; selection. For example, evolving an n-pointed star by having a user or=\r\n\n&gt; multiple users start with a simple configuration and then iteratively\n&gt; =\r\nchoose patterns that more closely resembled the target pattern. Do you\n&gt; ha=\r\nve any sense of how difficult/easy it is to evolve particular simple\n&gt; shap=\r\nes with picbreeder?\n&gt; \n\nThere is a Picbreeder user named &quot;Robert&quot; who seems=\r\n to have set out to\nanswer that question!  He kind of launched a large-scal=\r\ne study of\nsimple shapes.  \n\nHere&#39;s one of his many triangles: \nhttp://picb=\r\nreeder.org/search/showgenome.php?sid=3D1942\n\nA hexagon: http://picbreeder.o=\r\nrg/search/showgenome.php?sid=3D2106\n\nAnd, coincidentally, a 6-point star: \n=\r\nhttp://picbreeder.org/search/showgenome.php?sid=3D2330\n\nHere&#39;s a &quot;plus sign=\r\n&quot; type of shape:\nhttp://picbreeder.org/search/showgenome.php?sid=3D1918\n\nIt=\r\n is interesting that many of Robert&#39;s simple shapes are genetically\nrelated=\r\n to each other.  \n\nPerhaps it does say something that a variety of such sha=\r\npes could be\nevolved with CPPNs.  I agree with you that I would be interest=\r\ned to\nsee if it can be done with other encodings as well.\n\n&gt; &gt; Yes I think =\r\nwe are not disagreeing that much. If you want to be able\n&gt; &gt; to evolve bila=\r\nteral symmetry then of course you want an encoding that\n&gt; &gt; has a high prob=\r\nability of doing so. However, the problem is that\n&gt; &gt; &quot;bilateral symmetry&quot; =\r\nis not a single target pattern, but rather a\n&gt; &gt; large set of patterns. The=\r\nrefore, if you choose say five arbitrary\n&gt; &gt; bilaterally symmetric patterns=\r\n and the encoding doesn&#39;t hit them, it\n&gt; &gt; doesn&#39;t necessarily mean that it=\r\n has any intrinsic problem with\n&gt; &gt; bilateral symmetry. Even if you chose a=\r\n kind of general target, like\n&gt; &gt; &quot;anything bilaterally symmetric,&quot; you sti=\r\nll have to ask whether the\n&gt; &gt; fitness function actually rewards the steppi=\r\nng stones towards that\n&gt; &gt; goal, or whether perhaps the probability of hitt=\r\ning it is totally\n&gt; &gt; orthogonal to the fitness function (and hence the tar=\r\nget).\n&gt; &gt;\n&gt; &gt; In some cases (such as CPPNs), it will be a priori obvious ho=\r\nw often\n&gt; &gt; you will tend to get bilateral symmetry without even needing to=\r\n run a\n&gt; &gt; benchmark because you know how the encoding works. With CPPNs, i=\r\nf you\n&gt; &gt; know the mutation rate then you know that probability of adding\n&gt;=\r\n &gt; Gaussian in front of x or y, and then you have right away an idea\n&gt; &gt; ab=\r\nout the probabilities. Thus benchmarks don&#39;t really add much in\n&gt; &gt; such a =\r\ncase.\n&gt; \n&gt; That makes sense. And if your system included primitives like ri=\r\nngs,\n&gt; then you&#39;d know what the probability of one or more rings emerging\n&gt;=\r\n would be. So we&#39;d agree that benchmarks are only meaningful for the\n&gt; type=\r\ns of patterns that aren&#39;t explicit in the encoding, but have to\n&gt; emerge as=\r\n a result of evolutionary processes.\n&gt; \n\nHowever, it&#39;s important to ask, wh=\r\nat exactly is &quot;explicit in the\nencoding?&quot;  For example, if I want to evolve=\r\n an isosceles triangle,\nthen clearly symmetry is a prerequisite.  If I know=\r\n that there is a\ncertain chance of symmetry arising, then I know that the c=\r\nhance of a\ntrue symmetric triangle is not going to be higher than the chanc=\r\ne of\ndiscovering symmetry.  Let&#39;s say the chance of instantiating symmetry\n=\r\nis 50% in any given run.  Then that means I will only discover perfect\nisos=\r\nceles triangles in under 50% of the runs.  If I ran the experiment\nthat&#39;s w=\r\nhat I&#39;d find.  Is that result good or bad?  Would we say,\n&quot;Well, he can&#39;t f=\r\nind the target in more than 50% of the runs, and\nthat&#39;s not very good?&quot;  \n\n=\r\nThen if I wanted to look better, consider that I could simply up the\nmutati=\r\non rate for the kind of regularity that I want if I already know\nthat I wan=\r\nt an isosceles triangles.  But wouldn&#39;t that be cheating? \nBut then again, =\r\nnot to cheat is seemingly equally disingenuous when I\nknow that I am condem=\r\nning the system to a reduced probability a priori.  \n\nGoing further, once I=\r\n see a triangle, I can know how functions compose\nto create a triangle beyo=\r\nnd just the ground-level symmetry.  Then I\ncould do all kinds of ad hoc thi=\r\nngs to make such compositions more\nlikely with the particular encoding.  Wh=\r\nat would that show in general\nabout the capabilities of the encoding?\n\nI th=\r\nink the answer is actually that it *does* show something.  It\nshows that we=\r\n understand the encoding enough to manipulate its bias. \nAnd actually, that=\r\n may be more important than arbitrary benchmark\nattempts.  My guess is that=\r\n what will be really important with\nindirect encodings is not that they are=\r\n inherently awesome at\nvirtually anything, but that the most useful ones ca=\r\nn be biased in a\nfairly straightforward way to produce certain classes of s=\r\ntructures\nover other classes of structures because we understand clearly ho=\r\nw\nsuch bias-able encodings work internally.\n\nSo I&#39;m thinking that the bench=\r\nmark result is less important than the\ncomprehension of how the encoding bu=\r\nilt its results.  CPPNs have the\nnice property that they are fairly straigh=\r\ntforward.  You can look at\neach hidden node and look at the intermediate st=\r\nructure that it\nproduces.  In e.g. a GRN-based system, on the other hand, i=\r\nt&#39;s\nsignificantly more opaque and difficult to explain, and therefore more\n=\r\ndifficult to bias.\n\n&gt; &gt; I think some experiments like that would be interes=\r\nting, so I agree.\n&gt; &gt; I&#39;m just saying you have to be cautious about drawing=\r\n conclusions. If\n&gt; &gt; system A evolves a star and system B doesn&#39;t, what doe=\r\ns it actually\n&gt; &gt; tell us about which system to use in any situation aside =\r\nfrom one in\n&gt; &gt; which that exact star is needed with that exact fitness fun=\r\nction? It\n&gt; &gt; may tell us something, but we need to think about what that w=\r\nould be.\n&gt; &gt;\n&gt; &gt; By the way, my concern with benchmark comparisons is broad=\r\ner than just\n&gt; &gt; AE. The whole field of machine learning abuses benchmarks =\r\nto no end,\n&gt; &gt; and benchmarks get a lot more credit than they deserve. Whil=\r\ne they\n&gt; &gt; are by no means worthless, at this moment in time, what benchmar=\r\nk\n&gt; &gt; comparisons could use is a healthy dose of criticism. What I&#39;m saying=\r\n\n&gt; &gt; is that while they can certainly be defended rationally, right now\n&gt; &gt;=\r\n they don&#39;t really need much defending because everyone automatically\n&gt; &gt; a=\r\nssumes that they are the be all and end all of machine learning\n&gt; &gt; researc=\r\nh anyway. In other words, the pendulum can spare to swing a\n&gt; &gt; little back=\r\n the other way.\n&gt; &gt;\n&gt; &gt; What I think we need to consider in AI and machine =\r\nlearning that\n&gt; &gt; benchmark comparisons have made us forget is that a lot o=\r\nf them time,\n&gt; &gt; our own personal ability to analyze and intuit the value o=\r\nf an\n&gt; &gt; approach through our intellect often should trump benchmark\ncompar=\r\nisons.\n&gt; &gt;\n&gt; &gt; As I said to Jeff at GECCO, it would be interesting to see a=\r\nn AI\n&gt; &gt; journal that explicitly prohibits reviewers from basing their acce=\r\npt\n&gt; &gt; or reject decisions on experimental results in submitted papers.\n&gt; &gt;=\r\n Instead, they would be forced to evaluate the merits of an approach\n&gt; &gt; in=\r\ntellectually. Papers would not even be required to present any\n&gt; &gt; results =\r\nat all. While it is a radical idea, if we had world-class\n&gt; &gt; reviewers and=\r\n took the policy seriously, we would get a rapid\n&gt; &gt; exploration of the spa=\r\nce of interesting ideas- something AI is\n&gt; &gt; handicapped from doing right n=\r\now because of its obsession with\n&gt; &gt; benchmarks. Benchmarks have become an =\r\nexcuse not to think deeply. We\n&gt; &gt; should not get rid of them, but they can=\r\n spare a little pruning in the\n&gt; &gt; current environment.\n&gt; \n&gt; It kind of sou=\r\nnds like you&#39;re advocating a greater role for\n&gt; subjectivity in evaluating =\r\nresearch, by not focusing on experimental\n&gt; results or benchmarks. Is this =\r\nwhat you&#39;re advocating?\n&gt; \n&gt; I admit that the images produced by Picbreeder=\r\n are complex and\n&gt; interesting, but if I&#39;m trying to solve a particular pro=\r\nblem, and I\n&gt; need to choose between System A and System B, wouldn&#39;t it be =\r\nbetter if\n&gt; I had more solid quantitative data to support my decision, rath=\r\ner than\n&gt; relying on some sort of subjective evaluation?\n&gt; \n\nI think the an=\r\nswer is that &quot;solid quantitative results&quot; are not\ngenerally better (nor are=\r\n they generally worse) than subjective\nevaluation but I also need to be car=\r\neful about trapping myself into\nsounding like I am dismissing benchmarks en=\r\ntirely.  I support\nbenchmarks 100%.  They can be useful.  I&#39;m just saying t=\r\nhat they can\nbenefit from a little more scrutiny as the supposed unassailab=\r\nle\nwindow to inherent quality than they typically get.  I&#39;m not trying to\ng=\r\net rid of them.\n\nBut part of that scrutiny means recognizing that no, they =\r\ndon&#39;t\nnecessarily help you any more than subjective evaluation.  Sometimes\n=\r\nthey might, but sometimes they won&#39;t, and there is certainly nothing\nintrin=\r\nsic about benchmarks that makes them any better than a\nsubjective demonstra=\r\ntion for predicting what will work in the future.\n I would venture that Pic=\r\nbreeder tells you a lot more about CPPNs than\nany set of benchmarks could h=\r\nope to tell.  \n\nOf course, generating 5,000 interactively-evolved images is=\r\n not always\na viable option for testing an encoding, and benchmarks should =\r\nindeed\nplay a role (and like I said, I&#39;d definitely like to see if other\nen=\r\ncodings can evolve a star or other shapes), but interactive\nevolution is a =\r\nhighly underutilized tool to understanding encoding\nproperties.\n\nken\n\n\n\n"}}