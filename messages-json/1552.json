{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":183620858,"authorName":"Derek James","from":"Derek James &lt;djames@...&gt;","profile":"blue5432","replyTo":"LIST","senderId":"oYaIqRMUBaokyK5rk9tnG4XmkwYGZGBCqBeWrywTbmYhc0oMPbjqHiJFOppUWk4PIwfzXC2xNZRsl1rNEKleSiME1dBA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Image Sampling for Scaling","postDate":"1095529183","msgId":1552,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDE5YjEwZDUxMDQwOTE4MTAzOTM1OTM0YUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":0,"nextInTopic":1558,"prevInTime":1551,"nextInTime":1553,"topicId":1552,"numMessagesInTopic":7,"msgSnippet":"Hi all, We continue to work on our active vision implementation for object recognition.  We ve formalized some experiments and are aiming to write a paper for","rawEmail":"Return-Path: &lt;djames@...&gt;\r\nX-Sender: djames@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 80230 invoked from network); 18 Sep 2004 17:39:44 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m11.grp.scd.yahoo.com with QMQP; 18 Sep 2004 17:39:44 -0000\r\nReceived: from unknown (HELO mproxy.gmail.com) (64.233.170.201)\n  by mta6.grp.scd.yahoo.com with SMTP; 18 Sep 2004 17:39:44 -0000\r\nReceived: by mproxy.gmail.com with SMTP id 73so383675rnk\n        for &lt;neat@yahoogroups.com&gt;; Sat, 18 Sep 2004 10:39:43 -0700 (PDT)\r\nReceived: by 10.38.162.40 with SMTP id k40mr369771rne;\n        Sat, 18 Sep 2004 10:39:43 -0700 (PDT)\r\nReceived: by 10.38.181.49 with HTTP; Sat, 18 Sep 2004 10:39:43 -0700 (PDT)\r\nMessage-ID: &lt;19b10d51040918103935934a@...&gt;\r\nDate: Sat, 18 Sep 2004 12:39:43 -0500\r\nTo: neat@yahoogroups.com\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=US-ASCII\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 64.233.170.201\r\nFrom: Derek James &lt;djames@...&gt;\r\nReply-To: Derek James &lt;djames@...&gt;\r\nSubject: Image Sampling for Scaling\r\nX-Yahoo-Group-Post: member; u=183620858\r\nX-Yahoo-Profile: blue5432\r\n\r\nHi all,\n\nWe continue to work on our active vision implementation for object\nrecognition.  We&#39;ve formalized some experiments and are aiming to\nwrite a paper for a special edition of Pattern Recogition Letters (the\ndeadline is October 31st).\n\nBut we have an issue we thought we&#39;d open to the group.  Our\nimplementation has a zoom feature, and if for example the eye is fully\nzoomed out and centered on the canvas, there are a number of ways of\nsampling or filtering the image for input into the neural network.\n\nIf the canvas is 100x100, for example, and the eye resolution is 5x5,\nthen if the eye is fully zoomed out and centered, there are 25 20x20\nregions.  So how do you get the value for each region to input into\neach visual input in your eye?\n\nStandard interpolation methods include nearest neighber, bilinear, and\nbicubic, which sample either a single pixel in the field, an average\nof two, or an average of four, respectively.  The problem with these\napproximations is, there is often loss of information.  We thought a\nmethod that averaged every pixel in a given region would be best, but\nit is very computationally expensive.\n\nIn the Kato/Floreano paper which evolved networks to discriminate\nbetween triangles and squares, the network can has an output which can\nchoose the sampling method for each timestep.  The two sampling\nmethods are: 1) take the value of the upper-leftmost pixel, 2) full\narea averaging.  Their paper reports that given the choice, the\nnetworks use the first, simpler form of sampling 61% of the time. \nThey speculate that harsher, blockier edges are easier to discern than\nfuzzy, grey ones.\n\nThis seems to correlate with some of the ad hoc experiments we&#39;re\ndoing.  Simpler sampling methods seem to provide better results for\nthe task than area averaging.  This seems a little counterintuitive,\nsince the simpler method results in loss of information and worse\ndistortion of the image at higher zoom factors.\n\nAnybody have any thoughts on this?\n\nThanks,\nDerek\n\n"}}