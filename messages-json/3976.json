{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"6rAMsURgmzZdWTqo8HxPtwdSq1cYarAZ2jpkW0jMGsXpa-P6cfJTwOkC3ng0ajQYeW7qpZ54Xvmtvvqcm3FMO1qdUWKsAzAmowSGpHEPGhFb","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Another New Paper:  Multiagent HyperNEAT","postDate":"1209017132","msgId":3976,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ1cDd2YytoazJiQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM0MzU1NEIyLjIyNjI0JWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":3975,"nextInTopic":3977,"prevInTime":3975,"nextInTime":3977,"topicId":3955,"numMessagesInTopic":49,"msgSnippet":"Jeff, those are good questions.  Actually, David can correct me if I am wrong, but I believe we never did try to run these experiments without providing the","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 52472 invoked from network); 24 Apr 2008 06:05:33 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m55.grp.scd.yahoo.com with QMQP; 24 Apr 2008 06:05:33 -0000\r\nX-Received: from unknown (HELO n37d.bullet.mail.sp1.yahoo.com) (66.163.168.191)\n  by mta15.grp.scd.yahoo.com with SMTP; 24 Apr 2008 06:05:33 -0000\r\nX-Received: from [216.252.122.216] by n37.bullet.mail.sp1.yahoo.com with NNFMP; 24 Apr 2008 06:05:33 -0000\r\nX-Received: from [209.73.164.83] by t1.bullet.sp1.yahoo.com with NNFMP; 24 Apr 2008 06:05:33 -0000\r\nX-Received: from [66.218.66.73] by t7.bullet.scd.yahoo.com with NNFMP; 24 Apr 2008 06:05:33 -0000\r\nDate: Thu, 24 Apr 2008 06:05:32 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fup7vc+hk2b@...&gt;\r\nIn-Reply-To: &lt;C43554B2.22624%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Another New Paper:  Multiagent HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=I_3SOkOo3sCLfrAnSd16pkegR2QprbDnMeBpy-9GCfsYih-lo1fK\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, those are good questions.  Actually, David can correct me if I\nam wro=\r\nng, but I believe we never did try to run these experiments\nwithout providi=\r\nng the repeating coordinate frame.  It is interesting\nthat you see that as =\r\na natural first step, since our thinking unfolded\nin a different order:\n\nTh=\r\ne idea originated from the thought that it is an advantage of\nHyperNEAT tha=\r\nt we can describe to it a priori the locations of\ndifferent agents on the s=\r\nubstrate and that way convey to it that there\nare variations on a theme fro=\r\nm the start.  Also, we thought it was\ntidy that we can perfectly express to=\r\n the learner from the start\nexactly where those agents&#39; networks begin and =\r\nend, leaving no room\nfor ambiguity or misalignment.\n\nPerhaps one way to exp=\r\nlain why we thought about that first is to\nconsider that one important phil=\r\nosophical motivation behind HyperNEAT\nis that machine learning needs a way =\r\nfor humans to convey to the\nlearner a priori known domain geometry.  In eff=\r\nect, we are running\naway from the black box of No Free Lunch (which is a na=\r\nsty trap) by\nfinding new ways to convey critical a priori domain informatio=\r\nn. \nWhile arguments can be made that because certain techniques align with\n=\r\ncertain problem classes we should not pay too much heed to NFL, why\nwould w=\r\ne purposefully move *towards* the black box when we don&#39;t have\nto?  The rea=\r\nl excitement, I think, is to find very general techniques\nfor conveying to =\r\nthe learner standard kinds of a priori practical\ninformation (or bias), e.g=\r\n. geometry.\n\nThat said, if you really did start without the repeating coord=\r\ninate\nframes, I am guessing it would perform worse as you predict, though I=\r\n\ndon&#39;t know by how much.  It is probably worth doing just to see what\nhappe=\r\nns.  Yet my personal view is that there would not be a very deep\ninsight to=\r\n gain from such a result.  After all, why would we expect it\nto consistentl=\r\ny discover the right regularity simply by chance every\ntime?  Remember that=\r\n early in evolution, simply discovering this\nregularity may not even be rew=\r\narded; just because it somehow gets\nlucky and figures out exactly the right=\r\n repeating frame of reference,\nthat does not necessarily mean that within t=\r\nhose coordinate frames it\nis doing anything useful (i.e. it could be a repe=\r\ntition of a bad\npolicy), so the discovery is likely to go unnoticed and die=\r\n out, just\nas easily as it might be leveraged and elaborated properly.\n\nThi=\r\ns problem is related to that discussion we had a while back about\n&quot;target-b=\r\nased evolution&quot; and the phenomena of Picbreeder.  Often the\nstepping stones=\r\n (such as discovering the right basic regularity) are\nnot recognized by the=\r\n ultimate objective function, so it&#39;s pretty much\nup to luck to find them a=\r\nnd keep them around long enough to take\nadvantage of them.  My feeling is t=\r\nhat it is not fruitful for any\nindirect encoding to try to solve that probl=\r\nem, because it is not a\nproblem with the encoding per say but rather with t=\r\nhe way fitness is\nassigned.\n\nWith this dilemma in mind, I think it is perha=\r\nps most useful to point\nout that we can simply tell it the regularity that =\r\nis important and\nsee if it can exploit that effectively, which shows that w=\r\ne can\nprovide powerful domain bias.  \n\nken\n\n--- In neat@yahoogroups.com, Je=\r\nff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello-\n&gt; \n&gt; I enjoyed reading this. Thanks=\r\n for posting it.\n&gt; \n&gt; A question: how did HyperNEAT perform when you did no=\r\nt provide it\nwith the\n&gt; repeating coordinate frame for each agent? As you m=\r\nention in the\npaper, this\n&gt; is something that HyperNEAT could learn on its =\r\nown. I assume from\nthe fact\n&gt; that you added it that HyperNEAT was not doin=\r\ng a good job of\nlearning this.\n&gt; \n&gt; If that assumption is right, how bad wa=\r\ns it at learning this problem\n&gt; decomposition? One of the touted benefits o=\r\nf HyperNEAT, and generative\n&gt; encodings in general, is the ability to evolv=\r\ne a module and reuse it\nmany\n&gt; times (potentially with variation).  Here th=\r\ne modularity of the\nproblem was\n&gt; cleanly divided, and should have been rel=\r\natively easy for HyperNEAT to\n&gt; discover. Do you find it disconcerting that=\r\n it couldn&#39;t do so?\n&gt; \n&gt; \n&gt; \n&gt; Cheers,\n&gt; Jeff Clune\n&gt; \n&gt; Digital Evolution =\r\nLab, Michigan State University\n&gt; \n&gt; jclune@...\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; &gt; From: Kennet=\r\nh Stanley &lt;kstanley@...&gt;\n&gt; &gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogr=\r\noups.com&gt;\n&gt; &gt; Date: Wed, 16 Apr 2008 22:48:44 -0000\n&gt; &gt; To: &quot;neat@yahoogrou=\r\nps.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; Subject: [neat] Another New Paper:  Mult=\r\niagent HyperNEAT\n&gt; &gt; \n&gt; &gt; David D&#39;Ambrosio and I discuss the potential for =\r\nHyperNEAT\n&gt; &gt; controlling multiple heterogeneous agents in this new\n&gt; &gt; pap=\r\ner, &quot;Generative Encoding for Multiagent Learning,&quot; to appear at\n&gt; &gt; GECCO 2=\r\n008:\n&gt; &gt; \n&gt; &gt; http://eplex.cs.ucf.edu/index.php?\n&gt; &gt; option=3Dcom_content&t=\r\nask=3Dview&id=3D14&Itemid=3D28#dambrosio.gecco08\n&gt; &gt; \n&gt; &gt; Direct Link:\n&gt; &gt; =\r\n\n&gt; &gt; http://eplex.cs.ucf.edu/papers/dambrosio_gecco08.pdf\n&gt; &gt; \n&gt; &gt; We also =\r\nhave a nice sample of videos that depict various evolved\n&gt; &gt; teams in actio=\r\nn:\n&gt; &gt; \n&gt; &gt; http://eplex.cs.ucf.edu/multiagenthyperneat\n&gt; &gt; \n&gt; &gt; The intere=\r\nsting idea in this paper is that just as a single\n&gt; &gt; connective CPPN can e=\r\nncode how a single network varies over space,\n&gt; &gt; it can also encode how a =\r\n*set* of networks (each representing the\n&gt; &gt; policy of one agent on the tea=\r\nm) varies over space.  In this way,\n&gt; &gt; HyperNEAT can learn an expression t=\r\nhat encodes how policies vary\n&gt; &gt; over the team geometry.  For example, in =\r\na soccer team agents vary\n&gt; &gt; from defensive to offensive as you move away =\r\nfrom the goal.  Part of\n&gt; &gt; the power of this approach is that it means bas=\r\nic skills can be\n&gt; &gt; learned and shared among the whole team, since the CPP=\r\nN encodes how\n&gt; &gt; those skills vary across the field.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt;\n&gt;\n\n\n=\r\n\n"}}