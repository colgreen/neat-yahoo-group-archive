{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"_y-XdRy0f__SrWl_C1eHLAVFV8u2z3_UEGiBIC6xwCIIDd3tYkfhetdYrE2i28U0L4oZ0JhmMejVtDSXrnwdO3weo_L2","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: GECCO Paper on HyperNEAT","postDate":"1372264714","msgId":6158,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtxZjVlYSt1dDJ1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtxYmVkcitpZHFjQGVHcm91cHMuY29tPg=="},"prevInTopic":6157,"nextInTopic":6159,"prevInTime":6157,"nextInTime":6159,"topicId":6085,"numMessagesInTopic":14,"msgSnippet":"Hi Shimon, I sense from your saying, I am only saying that I am not aware of any result which gives good reason to abandon hope in developing methods... that","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 70670 invoked from network); 26 Jun 2013 16:38:38 -0000\r\nX-Received: from unknown (98.137.63.205)\n  by m14.grp.sp2.yahoo.com with QMQP; 26 Jun 2013 16:38:38 -0000\r\nX-Received: from unknown (HELO ng2-ip6.bullet.mail.bf1.yahoo.com) (98.139.165.2)\n  by mtaq6.grp.sp2.yahoo.com with SMTP; 26 Jun 2013 16:38:37 -0000\r\nX-Received: from [98.139.164.126] by ng2.bullet.mail.bf1.yahoo.com with NNFMP; 26 Jun 2013 16:38:36 -0000\r\nX-Received: from [98.137.34.36] by tg7.bullet.mail.bf1.yahoo.com with NNFMP; 26 Jun 2013 16:38:36 -0000\r\nDate: Wed, 26 Jun 2013 16:38:34 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kqf5ea+ut2u@...&gt;\r\nIn-Reply-To: &lt;kqbedr+idqc@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: GECCO Paper on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=8NPBITs5-5Lw0sTOlNxZHFDMJsz4F-1sBhjEH_rCKt_9BoKxbReG\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Shimon,\n\nI sense from your saying, &quot;I am only saying that I am not awa=\r\nre of any result which gives good reason to abandon hope in developing meth=\r\nods...&quot; that you are being very careful to remain as safely agnostic as pos=\r\nsible.  But I would guess that you (or at least most people) wouldn&#39;t be wo=\r\nrking on finding &quot;...methods that work with indirect encodings and excel on=\r\n &#39;regular&#39; FFs&quot; unless you actually believed they exist (which would indeed=\r\n be a bold hypothesis).  Or maybe you really do choose research directions =\r\nwith no confidence in them beyond total neutrality, but sometimes there&#39;s n=\r\no harm in throwing your hat in the ring and seeing where your hopes (i.e. h=\r\nypotheses) lead you.  In any case, since you say you aren&#39;t aware of any, I=\r\n&#39;d like to offer a number of published results that do support (not prove, =\r\nbut certainly support) doubting the hypothesis that such methods exist.  \n\n=\r\nFirst, the most obvious is my paper with Brian Woolley (http://eplex.cs.ucf=\r\n.edu/papers/woolley_gecco11.pdf) on re-evolving Picbreeder images as target=\r\ns.  That of course goes straight to the heart of the issue we are discussin=\r\ng, which is whether it will be possible to evolve to particular targets wit=\r\nh regular FFs.  In that paper, the answer is a resounding &quot;no,&quot; although Pi=\r\ncbreeder users routinely evolve such images (meaning images as complex and =\r\ninteresting as the Skull or Butterfly), yet not as targets.  Of course that=\r\n does not prove that some other indirect encoding does not exist that can e=\r\nvolve to such images as targets, but what should be worrisome is the extrem=\r\ne disparity in that work:  Picbreeder images that are evolved in only a few=\r\n dozen generations (with a population of 15) cannot be re-evolved effective=\r\nly in 30,000 generations!  I mean, you could logically say &quot;there is no pro=\r\nof that a method better than NEAT+CPPNs at evolving to targets does not exi=\r\nst,&quot; but surely NEAT+CPPNs aren&#39;t *that* terrible of a combination - they&#39;d=\r\n have to be abjectly terrible for there to be hope that something can handi=\r\nly substitute in the face of such abysmal failure.  So the seed of doubt is=\r\n reasonably planted.  At the same time, we see in the same Picbreeder syste=\r\nm (with NEAT+CPPNs) routine discovery of such images as non-objectives in o=\r\nnly a few generations.  That&#39;s interesting.\n\nSecond, the novelty search and=\r\n behavioral diversity results (from our group and others; see http://eplex.=\r\ncs.ucf.edu/noveltysearch/userspage/) deserve to be counted as evidence (not=\r\n proof) supporting my hypothesis.  We see there many examples of a non-obje=\r\nctive search easily solving problems that are difficult or impossible for p=\r\nurely target-based searches with various algorithms.  Certainly after some =\r\ntime all that accumulated evidence is enough to raise doubt as to whether t=\r\nhere exists some kind of magical target-driven algorithm that always gives =\r\nyou what you want.  But it&#39;s easy to misinterpret the lesson in novelty sea=\r\nrch&#39;s results.  It&#39;s not its successes that are most important to the curre=\r\nnt discussion; rather it&#39;s the *failures* of the target-driven variants tha=\r\nt are most suggestive:  We are talking about a situation in which entirely =\r\nreasonable target-based setups that follow well accepted practices from dec=\r\nades of research are being squashed by a ridiculous setup that doesn&#39;t even=\r\n know what it&#39;s trying to do!  Rather than celebrating the &quot;success&quot; of nov=\r\nelty search, we should be sweating with anxiety over this disconcerting fai=\r\nlure of the very paradigm over which you are saying &quot;there is no reason for=\r\n despair.&quot;  Perhaps not yet despair, but doubt - certainly.\n\nThird, sometim=\r\nes just thinking a problem through is worth a few cents.  Take the example =\r\nof evolving the pattern of a face.  If an indirect encoding is to evolve a =\r\nface properly, then logic suggests that it simply must discover symmetry ea=\r\nrly on.  It is true that it could theoretically discover a face by discover=\r\ning both sides separately, but that is not what I am calling &quot;healthy&quot; beca=\r\nuse any mutation of such a perverse representation will destroy the face-ne=\r\nss of the face (which means it cannot lead to new faces).  It also would be=\r\n inefficient because it would require finding both sides independently when=\r\n they are not independent.  In fact, the more complex each side of the face=\r\n is, the worse this misadventure becomes.  At an extreme, if each side is a=\r\ns complex as a human brain, forget it, the need to make an astronomically u=\r\nnlikely sequence of discoveries twice is an absolute deal-breaker.  \n\nNow t=\r\nhe question is, how can there possibly be any magical target-based algorith=\r\nm or encoding that &quot;realizes&quot; that symmetry needs to be rewarded early on w=\r\nhen symmetry on its own does not even remotely resemble a face?  Of course =\r\nif there is special knowledge, like if we know that faces require symmetry,=\r\n we could try to incorporate that knowledge into the FF, but that&#39;s not wha=\r\nt you&#39;re suggesting - you&#39;re suggesting there may exist some method that do=\r\nesn&#39;t need to know the stepping stones but magically rewards them anyway si=\r\nmply by virtue of rewarding only the target.  Once again, the possibility r=\r\nemains, but the reason for doubt here is significant.  \n\nFinally, the idea =\r\nthat the products of nature are indeed impressive is not mere conjecture.  =\r\nFor example, see our publication on the topic of impressiveness (which also=\r\n establishes a connection between novelty and impressiveness): \nhttp://eple=\r\nx.cs.ucf.edu/papers/lehman_alife12b.pdf\n\nNow I&#39;m not taking an extreme posi=\r\ntion here.  I&#39;m not saying a target can&#39;t be anywhere in the mix whatsoever=\r\n (so I leave plenty of room e.g. for the behavioral diversity combination t=\r\nhat Stef and JBM have developed over the years).  I&#39;m just saying there is =\r\ngood reason to doubt the clarion call for pure target-based FFs leading us =\r\nto the promised land.  And as an extra bonus in the name of hope for the no=\r\nn-objective alternative, we have the fact that Einstein did evolve.  That i=\r\ns, I didn&#39;t mean in my previous post to say that Einstein is a proof that n=\r\non-objective evolution is the only way; rather my point is that it is a pro=\r\nof-of-concept that it *can* work.  Your alternative on the other hand boast=\r\ns no such proof of concept.  We don&#39;t have any evidence it can or did work =\r\nat finding human-level intelligence, ever, anthropic concern or not.\n\nSo we=\r\n&#39;ve got publications, we&#39;ve got results, we&#39;ve got reasoning, we&#39;ve got nat=\r\nural precedent, all consistent with my hypothesis, and it continues to accu=\r\nmulate.  And for what I believe is your hypothesis (i.e. that powerful targ=\r\net-based methods exist) we have little support beyond that there is no proo=\r\nf that that it isn&#39;t true.\n\nAnyway, by all means, don&#39;t despair.  But do em=\r\nbrace your position and consider what it implies.  For example, try to imag=\r\nine a way any conceivable indirect encoding with a target can commit to an =\r\nambiguous yet essential symmetry before it discovers its target.  It&#39;s a re=\r\nally interesting question.  Of course, like you say, just because you can&#39;t=\r\n think of it doesn&#39;t mean it doesn&#39;t exist, but even so it sure would be re=\r\nassuring if you could think of it.\n\nBest,\n\nken\n\n\n--- In neat@...=\r\nm, &quot;shimonw&quot; &lt;shimon@...&gt; wrote:\n&gt;\n&gt; Hi Ken,\n&gt; \n&gt; Yes, I agree that this co=\r\nnversation is exposing some of our fundamental assumptions, and it is alway=\r\ns good to examine and question such assumptions.\n&gt; \n&gt; However, if you think=\r\n that our hypotheses are equally bold, then I fear my main point has been m=\r\nisunderstood.  I am not actually hypothesizing that an algorithm with any p=\r\narticular qualities exists.  I am only saying that I am not aware of any re=\r\nsult which gives good reason to abandon hope in developing methods that wor=\r\nk with indirect encodings and excel on &quot;regular&quot; FFs.  This is actually not=\r\n a hypothesis at all; it is an incontrovertible fact. Of course, it doesn&#39;t=\r\n prove that such a result doesn&#39;t exist and I certainly don&#39;t claim a compr=\r\nehensive mastery of the literature.  But if such a result does exist (thoug=\r\nh it&#39;s hard to imagine it would), anyone is free to simply point it out to =\r\nme.\n&gt; \n&gt; By contrast, your hypothesis was that &quot;an unhappy and unhealthy in=\r\ndirect encoding is one with only a strict target to which to aspire.&quot;  I co=\r\nntinue to maintain that this quite a bold claim.  You suggested that the &quot;s=\r\nuccess&quot; of natural evolution provides a proof of concept to support your hy=\r\npothesis, but I find this highly problematic.  Firstly, it&#39;s unclear that e=\r\nvolution was &quot;successful&quot; in any meaningful way because there&#39;s an anthropi=\r\nc principle at work here: we are human and so we find humans impressive.  T=\r\nhe success of evolution is thus a self-fulfilling prophecy.  Secondly, and =\r\nmore importantly, even if we accept that evolution is successful, this actu=\r\nally does not validate your hypothesis at all.  Showing that there&#39;s a nice=\r\n algorithm that works without a target is not the same as showing that ther=\r\ne are *no* algorithms that work with a target, which is what your hypothesi=\r\ns claims.\n&gt; \n&gt; That&#39;s why I think it&#39;s not correct to describe our &quot;hypothe=\r\nses&quot; as equally bold.  In my case, there is nothing to prove: there&#39;s just =\r\na simple fact.  In your case, validating the hypothesis requires proving a =\r\nnegative (and quite a sweeping one at that), which is notoriously difficult=\r\n to do.\n&gt; \n&gt; Finally, I sense from your defense of PicBreeder that I may ha=\r\nve been misunderstood in another way.  I&#39;m in no way trying to criticize Pi=\r\ncBreeder or suggest that research into it is misguided.  I think it&#39;s a ver=\r\ny cool and intriguing result, possibly a highly significant one.  You and I=\r\n may disagree about *why* it&#39;s significant, but we definitely agree that it=\r\n&#39;s useful to study further and has the potential to yield important insight=\r\ns.  \n&gt; \n&gt; I&#39;m just saying that, in the complementary search for optimizatio=\r\nn methods that use indirect encodings and can excel on hard FFs, there&#39;s re=\r\nally no reason for despair.\n&gt; \n&gt; Cheers,\n&gt; Shimon\n&gt; \n&gt; --- In neat@yahoogro=\r\nups.com, &quot;Ken&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Shimon,\n&gt; &gt; \n&gt; &gt; The nice thin=\r\ng about this type of conversation is that it pushes us\n&gt; &gt; towards realizin=\r\ng our fundamental assumptions.  In that spirit, a few\n&gt; &gt; other thoughts in=\r\n response:\n&gt; &gt; \n&gt; &gt; Many top biologists and EC researchers would call the b=\r\nehavior of the\n&gt; &gt; organism in the world (i.e. its interactions with the wo=\r\nrld) the\n&gt; &gt; &quot;phenotype.&quot;  David Fogel once sent me a long and forceful def=\r\nense of\n&gt; &gt; such a position, quoting a number of famous biologists.  In tha=\r\nt\n&gt; &gt; context, whether you map CPPN-&gt;pattern or CPPN-&gt;behavior, a target is=\r\n\n&gt; &gt; still a target and the neural network is not the phenotype.\n&gt; &gt; \n&gt; &gt; I=\r\nn any case, I guess we both hold bold hypotheses in some sense.  Your\n&gt; &gt; h=\r\nypothesis that there exist methods that can solve hard FFs almost\n&gt; &gt; deter=\r\nministically as targets (up to and even beyond delivering us an\n&gt; &gt; Einstei=\r\nn-level brain) seems boldly optimistic to me.  But the big\n&gt; &gt; difference b=\r\netween our hypotheses is that you have no proof of concept\n&gt; &gt; for your app=\r\nroach while I do.  In your approach, you will set a target\n&gt; &gt; of Einstein =\r\nand almost magically the algorithm will then deliver us\n&gt; &gt; Einstein, which=\r\n no method has yet shown even the faintest sign of\n&gt; &gt; achieving.  In my ap=\r\nproach, Einstein is not the target of the search\n&gt; &gt; process but instead  a=\r\nppears as a byproduct of a search without any\n&gt; &gt; explicit target, which is=\r\n (amazingly) actually what happened in the real\n&gt; &gt; world!  It may be tempt=\r\ning to dismiss that distinction, but think about\n&gt; &gt; it, the fact that any =\r\nprocess actually *did* produce Einstein is beyond\n&gt; &gt; incredible.  We shoul=\r\nd learn from that as much as we can before\n&gt; &gt; insisting &quot;there&#39;s got to be=\r\n a better way.&quot;\n&gt; &gt; \n&gt; &gt; Of course, it&#39;s great that you&#39;re searching for a =\r\nbetter way (it sure\n&gt; &gt; would be nice if we could just set Einstein&#39;s IQ as=\r\n a fitness target),\n&gt; &gt; but the things is, there will always be a ton of pe=\r\nople trying to follow\n&gt; &gt; that path because it&#39;s such a clean and intuitive=\r\nly appealing notion. \n&gt; &gt; So it hardly needs a vigorous argument to convinc=\r\ne someone that it&#39;s\n&gt; &gt; important to try.  The danger is instead  that in s=\r\nuch a rush of\n&gt; &gt; enthusiasm for intuitively appealing approaches, we sweep=\r\n aside the much\n&gt; &gt; more delicate yet equally critical attempt to harness e=\r\nvolution on its\n&gt; &gt; own terms, which leads to things like novelty search, i=\r\nndirect encoding,\n&gt; &gt; and behavioral diversity.  The power of this process =\r\nmay not be as clean\n&gt; &gt; and simple  as the optimization crowd is hoping; my=\r\n argument here guards\n&gt; &gt; against that danger.\n&gt; &gt; \n&gt; &gt; I think something s=\r\nimilar is going on in our fracture argument: In\n&gt; &gt; Picbreeder (and to some=\r\n extent Endlessforms too, which also uses CPPNs)\n&gt; &gt; we have perhaps the on=\r\nly massive proof-of-concept that exists of\n&gt; &gt; fracture evolving through an=\r\n artificial encoding.  Picbreeder is a\n&gt; &gt; treasure trove of almost 10,000 =\r\nexamples, each one with its own lesson\n&gt; &gt; to teach us on fracture.  And my=\r\n argument is, since we are fortunate\n&gt; &gt; enough to have this example right =\r\nin front of us (like the example of\n&gt; &gt; natural evolution evolving Einstein=\r\n), let&#39;s learn everything we can from\n&gt; &gt; it before looking away and saying=\r\n hastily, &quot;there must be something\n&gt; &gt; better.&quot;  Picbreeder is a fortuitous=\r\n goldmine of data that is very hard\n&gt; &gt; to  reproduce; it took several year=\r\ns and the contributions of hundreds\n&gt; &gt; of  people to accumulate its result=\r\ns.  Let&#39;s scrub every last bit of\n&gt; &gt; wisdom  from that windfall that we ca=\r\nn.  It&#39;s not a question of better\n&gt; &gt; for me, it&#39;s a question of learning f=\r\nrom the only evidence we have.  How\n&gt; &gt; do you expect to really develop a b=\r\netter encoding of fracture if you\n&gt; &gt; ignore the thousands of examples of f=\r\nracture that already exist?  You\n&gt; &gt; will just end up reinventing the wheel=\r\n.\n&gt; &gt; \n&gt; &gt; The danger of that is evident in some of the assumptions you hol=\r\nd\n&gt; &gt; already about how CPPNs encode fracture.  For example, you are worrie=\r\nd\n&gt; &gt; that it may not do so efficiently, but you have only constructed a\n&gt; =\r\n&gt; single thought experiment (your figure 13) instead of taking a measured\n&gt;=\r\n &gt; look at the thousands of examples in front of us.  In fact, while indeed=\r\n\n&gt; &gt; I don&#39;t think 6 nodes is particularly much, it&#39;s easy enough to find\n&gt;=\r\n &gt; fracture in Picbreeder represented in under 6 nodes.  For example, the\n&gt;=\r\n &gt; pattern below has at least 3 distinct fractured regions (which I\n&gt; &gt; num=\r\nbered for clarity): a pinkish region, an ovular inner region, and a\n&gt; &gt; con=\r\nic lower region.  However, the CPPN that encodes it (shown to its\n&gt; &gt; left)=\r\n only uses 4 nodes to encode these 3 fractured regions (notice that\n&gt; &gt; two=\r\n of the displayed hidden nodes have outgoing weights of zero, so they\n&gt; &gt; a=\r\nre not contributing to the output pattern, leaving only the 4 nodes). \n&gt; &gt; =\r\nThat&#39;s a respectable 1.3 nodes per fractured region:\n&gt; &gt; \n&gt; &gt; (this image i=\r\ns also available at\n&gt; &gt; http://eplex.cs.ucf.edu/hyperNEATpage/content/four-=\r\nnode-fracture.jpg\n&gt; &gt; &lt;http://eplex.cs.ucf.edu/hyperNEATpage/content/four-n=\r\node-fracture.jpg&gt; \n&gt; &gt; )\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; We could argue about the d=\r\nefinition of fracture, and perhaps you&#39;d want\n&gt; &gt; to refine the definition =\r\nto argue that the above example doesn&#39;t really\n&gt; &gt; have three fractured reg=\r\nions.  Or you could argue that the &quot;d&quot; input\n&gt; &gt; should be counted as a 5th=\r\n node (to encode the 3 regions, which is still\n&gt; &gt; a respectable 1.7 nodes =\r\nper region).  But even those would be healthy\n&gt; &gt; discussions that we could=\r\n not begin to have without first referring to\n&gt; &gt; the examples that we alre=\r\nady have.  Of course (intuitively) more complex\n&gt; &gt; fracture will require m=\r\nore nodes (maybe at some point 6!), as it should.\n&gt; &gt; All I&#39;m saying is I t=\r\nhink this kind of speculation about whether it&#39;s\n&gt; &gt; efficient or not is ju=\r\nmping the gun:  Let&#39;s understand it first before\n&gt; &gt; we worry about fixing =\r\nit.\n&gt; &gt; \n&gt; &gt; So I think there&#39;s a difference of philosophies ultimately at =\r\nwork here.\n&gt; &gt; Because the road ahead to AI is so vast, I&#39;m more motivated =\r\nby\n&gt; &gt; maximizing our information than doing &quot;better.&quot;  For example, that&#39;s=\r\n the\n&gt; &gt; motivation behind Picbreeder - obviously it is not quantifiably be=\r\ntter\n&gt; &gt; than anything in particular, but it increased our understanding of=\r\n a\n&gt; &gt; number of important phenomena, including fracture, representation, a=\r\nnd\n&gt; &gt; non-objective search, by providing useful information.  So I say, le=\r\nt&#39;s\n&gt; &gt; see where this takes us - there&#39;s still a ton left to learn.  But y=\r\nou\n&gt; &gt; are already itching to start anew and fix things that are not clearl=\r\ny\n&gt; &gt; broken just when we have hit a goldmine of untapped information.\n&gt; &gt; =\r\n\n&gt; &gt; Without question, neither of our perspectives is definitively superior=\r\n;\n&gt; &gt; we are both merely speculating about where time is best invested, and=\r\n\n&gt; &gt; obviously neither of us can predict the future.  This argument is only=\r\n\n&gt; &gt; my own case for my perspective.\n&gt; &gt; \n&gt; &gt; Best,\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; \n=\r\n&gt; &gt; --- In neat@yahoogroups.com, &quot;shimonw&quot;  wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi Ken,\n&gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; If I may, I&#39;d like to offer a couple reactions to your latest messa=\r\nge.\n&gt; &gt; This is indeed an interesting discussion that touches on many\n&gt; &gt; p=\r\notentially important issues.  I hope I can offer a useful perspective\n&gt; &gt; o=\r\nn these topics.\n&gt; &gt; &gt;\n&gt; &gt; &gt; You are right that in a target-based scenario t=\r\nhere can be many CPPNs\n&gt; &gt; that generate the same phenotype.  But the CPPN =\r\nis a genotype, not a\n&gt; &gt; phenotype. In what I&#39;m calling &quot;regular&quot; FFs, ther=\r\ne are potentially many\n&gt; &gt; *phenotypes* that solve the problem, and for eac=\r\nh of them potentially\n&gt; &gt; many genotypes.  So in my mind, there is still a =\r\nuseful distinction\n&gt; &gt; between target based FFs and regular FFs, though the=\r\ny are perhaps best\n&gt; &gt; seen as different points on a spectrum.\n&gt; &gt; &gt;\n&gt; &gt; &gt; =\r\nIf I understand correctly, you are suggesting that the important\n&gt; &gt; distin=\r\nction is how the FF interacts with the search process.  But to me,\n&gt; &gt; this=\r\n is a difficult criterion to use because the search process could be\n&gt; &gt; an=\r\nything.  The space of possible black-box optimization methods is huge,\n&gt; &gt; =\r\nand what encourages piecewise incremental progress for one method may\n&gt; &gt; n=\r\not for another.\n&gt; &gt; &gt;\n&gt; &gt; &gt; I don&#39;t pretend to know what kind of algorithm =\r\nwould generate\n&gt; &gt; Einstein-level intelligence (I don&#39;t even know if this i=\r\ns a useful\n&gt; &gt; goal). But as a researcher I highly respect once told me, &quot;y=\r\nour failure\n&gt; &gt; to imagine it does not constitute a proof that it cannot be=\r\n done.&quot;\n&gt; &gt; &gt;\n&gt; &gt; &gt; That&#39;s why I think your hypothesis is quite a bold one,=\r\n because it\n&gt; &gt; looks at the limitations of a specific class of black-box o=\r\nptimization\n&gt; &gt; methods and generalizes them to all possible black-box opti=\r\nmization\n&gt; &gt; methods.\n&gt; &gt; &gt;\n&gt; &gt; &gt; To give just one example of the possibili=\r\nties here: algorithms for\n&gt; &gt; continuous-armed bandits, such as X-armed ban=\r\ndits and Bayesian\n&gt; &gt; optimization methods such as GP-UCB, can be applied t=\r\no black-box\n&gt; &gt; optimization.  These methods avoid the problem of local opt=\r\nima in a\n&gt; &gt; principled way, by maintaining a posterior distribution over t=\r\nhe global\n&gt; &gt; FF, and using optimism in the face of uncertainty to ensure s=\r\nufficient\n&gt; &gt; exploration of the solution space.  As a result, these method=\r\ns have very\n&gt; &gt; nice theoretical properties, like guaranteed convergence to=\r\n the global\n&gt; &gt; optimum in the limit and logarithmic regret bounds along th=\r\ne way.\n&gt; &gt; &gt;\n&gt; &gt; &gt; As far as I know, no one has tried to develop versions o=\r\nf these\n&gt; &gt; methods that can discover NN topologies, and which would thus b=\r\ne\n&gt; &gt; suitable for optimizing CPPNs or other indirect encodings.  But there=\r\n&#39;s\n&gt; &gt; no a priori reason to think it can&#39;t be done.  I&#39;m not saying this w=\r\nould\n&gt; &gt; necessarily work or even that it&#39;s the most promising approach to\n=\r\n&gt; &gt; explore.  I&#39;m just saying it&#39;s one example of a principled approach tha=\r\nt\n&gt; &gt; could avoid all the difficulties you mention and which we currently h=\r\nave\n&gt; &gt; no strong reason to eliminate from contention.\n&gt; &gt; &gt;\n&gt; &gt; &gt; So I thi=\r\nnk it&#39;s quite likely that these hard FFs are not unsolvable,\n&gt; &gt; but just t=\r\nhat current methods cannot solve them.  Rather than giving up\n&gt; &gt; on them, =\r\nin my opinion we should be focusing on developing better\n&gt; &gt; methods for th=\r\nem.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Regarding whether 6 nodes is a lot to represent fracture, I=\r\n think the\n&gt; &gt; same point applies: just because we can&#39;t think of a better =\r\nway to do\n&gt; &gt; it, doesn&#39;t mean it doesn&#39;t exist.  Our paper establishes 6 a=\r\ns an upper\n&gt; &gt; bound, which can be easily done by example.  If I understand=\r\n correctly,\n&gt; &gt; you are suggesting that 6 may be a lower bound, which is mu=\r\nch more\n&gt; &gt; difficult to demonstrate.\n&gt; &gt; &gt;\n&gt; &gt; &gt; I could definitely imagin=\r\ne that a different type of network, or one\n&gt; &gt; with a different set of acti=\r\nvation functions, might be able to make\n&gt; &gt; better use of 6 nodes.  Even if=\r\n it&#39;s true that there&#39;s a trade-off, and\n&gt; &gt; using fewer nodes means less f=\r\nlexibility, there may be many cases where\n&gt; &gt; that&#39;s a favorable trade-off.=\r\n  We should at least be open to the\n&gt; &gt; possibility that it some cases the =\r\nsweet spot is not a representation\n&gt; &gt; that requires 6 nodes for fracture.\n=\r\n&gt; &gt; &gt;\n&gt; &gt; &gt; I&#39;m looking forward to chatting more about this at GECCO.\n&gt; &gt; &gt;=\r\n\n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; Shimon\n&gt; &gt; &gt;\n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Ken&quot; =\r\nkstanley@ wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hi Shimon,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; These are some =\r\nreally interesting and deep issues we&#39;re getting\n&gt; &gt; into.  I\n&gt; &gt; &gt; &gt; am su=\r\nre they will be the foundation of great discussions at GECCO. \n&gt; &gt; I&#39;ll\n&gt; &gt;=\r\n &gt; &gt; try to keep my response more brief than before.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 1) Ind=\r\need recent quadruped results are not in the same setup as in\n&gt; &gt; your\n&gt; &gt; &gt;=\r\n &gt; work; that is a legitimate qualification and they do not constitute\n&gt; &gt; =\r\na\n&gt; &gt; &gt; &gt; proof that in your particular setup HyperNEAT would succeed. \n&gt; &gt;=\r\n However,\n&gt; &gt; &gt; &gt; they are arguably at least comparably complex.  For examp=\r\nle, the\n&gt; &gt; CTRNN\n&gt; &gt; &gt; &gt; in\n&gt; &gt; &gt; &gt; http://eplex.cs.ucf.edu/papers/risi_ge=\r\ncco13b.pdf\n&gt; &gt; &gt; &gt;    is a complicated\n&gt; &gt; &gt; &gt; structure and the CPPN that =\r\nencodes it is required not only to\n&gt; &gt; generate\n&gt; &gt; &gt; &gt; a controller for a =\r\nsingle quadruped morphology, but to generate\n&gt; &gt; multiple\n&gt; &gt; &gt; &gt; controlle=\r\nrs for multiple morphologies, all from the same CPPN.  A\n&gt; &gt; video\n&gt; &gt; &gt; &gt; =\r\nof three controllers all from the same CPPN is here:\n&gt; &gt; &gt; &gt; http://youtu.b=\r\ne/oLSSt5GyHNk\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 2) I think the question of what is &quot;target-ba=\r\nsed&quot; can actually be\n&gt; &gt; &gt; &gt; interesting, but I completely agree that the s=\r\nemantic side of the\n&gt; &gt; &gt; &gt; argument isn&#39;t really important.  But what I do=\r\n find interesting is\n&gt; &gt; the\n&gt; &gt; &gt; &gt; idea that these two scenarios differ s=\r\nubstantively in your mind (as\n&gt; &gt; you\n&gt; &gt; &gt; &gt; put it):\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &quot;the=\r\nre is an important difference between FFs that require a single\n&gt; &gt; &gt; &gt; spe=\r\ncific phenotype and FFs that require only that some goal be\n&gt; &gt; achieved&quot;\n&gt;=\r\n &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I think by &quot;single specific phenotype&quot; you mean pattern-matc=\r\nhing\n&gt; &gt; (i.e.\n&gt; &gt; &gt; &gt; image-matching).  But I think this distinction doesn=\r\n&#39;t really exist:\n&gt; &gt; &gt; &gt; There are an unlimited number of networks (i.e. CP=\r\nPNs) that can\n&gt; &gt; encode a\n&gt; &gt; &gt; &gt; particular two-dimensional image, just a=\r\ns there are an unlimited\n&gt; &gt; number\n&gt; &gt; &gt; &gt; of CPPNs that can encode a part=\r\nicular behavior or goal (such as\n&gt; &gt; &gt; &gt; following a line).\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n What makes both target-based and fundamentally the same is not the\n&gt; &gt; &gt; &gt;=\r\n number of ways they can be solved, but rather the way the fitness\n&gt; &gt; &gt; &gt; =\r\nfunction interacts with the search process.  The problem is that\n&gt; &gt; &gt; &gt; ta=\r\nrget-based fitness encourages piece-wise incremental progress,\n&gt; &gt; which\n&gt; =\r\n&gt; &gt; &gt; tends to be highly deceptive.  For example, with an image, matching\n&gt;=\r\n &gt; a\n&gt; &gt; &gt; &gt; single pixel can raise fitness even if the function that cause=\r\ns that\n&gt; &gt; &gt; &gt; pixel to be matched has no relationship whatsoever to the ov=\r\nerall\n&gt; &gt; &gt; &gt; regularities in the target pattern.  The same is true in cont=\r\nrol\n&gt; &gt; tasks:\n&gt; &gt; &gt; &gt; A mutation that causes a quadruped to lunge forward =\r\nclumsily is\n&gt; &gt; rewarded\n&gt; &gt; &gt; &gt; for the slight improvement in fitness, whe=\r\nreas an important\n&gt; &gt; underlying\n&gt; &gt; &gt; &gt; regularity (e.g. oscillation) nece=\r\nssary to get really good at the\n&gt; &gt; task\n&gt; &gt; &gt; &gt; is never established.  Non=\r\n-target-based fitness (or what I call\n&gt; &gt; &gt; &gt; &quot;non-objective&quot;) avoids these=\r\n problems because it *does* reward\n&gt; &gt; &gt; &gt; establishing regularities: it ap=\r\npreciates new regularities even if\n&gt; &gt; they\n&gt; &gt; &gt; &gt; don&#39;t immediately raise=\r\n fitness.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; But what&#39;s most interesting to me is your intuiti=\r\non that there is\n&gt; &gt; some\n&gt; &gt; &gt; &gt; way to sidestep the tradeoff in combining=\r\n indirect encodings with\n&gt; &gt; &gt; &gt; target-based fitness functions.  That is, =\r\nyou suspect there may\n&gt; &gt; exist an\n&gt; &gt; &gt; &gt; indirect encoding that can both =\r\nelaborate regularities\n&gt; &gt; compositionally\n&gt; &gt; &gt; &gt; over very many generatio=\r\nns and also almost deterministically satisfy\n&gt; &gt; an\n&gt; &gt; &gt; &gt; arbitrary targe=\r\nt-based objective.  I am convinced that is not the\n&gt; &gt; case\n&gt; &gt; &gt; &gt; (it wou=\r\nld be too good to be true), but you rightly point out that my\n&gt; &gt; &gt; &gt; posit=\r\nion is a hypothesis.   However, just as a thought experiment,\n&gt; &gt; can\n&gt; &gt; &gt;=\r\n &gt; you really imagine any neural network encoding (including DNA) that\n&gt; &gt; =\r\n&gt; &gt; would give you Einstein-level intelligence if the target was simply\n&gt; &gt;=\r\n to\n&gt; &gt; &gt; &gt; score maximally on an IQ test?  It is plain to me that the step=\r\nping\n&gt; &gt; &gt; &gt; stones to human level cannot be crossed in the presence of a\n&gt;=\r\n &gt; &gt; &gt; target-based objective (or any one conceivable).  However,\n&gt; &gt; &gt; &gt; i=\r\nnterestingly, that does not mean that such a neural network does\n&gt; &gt; not\n&gt; =\r\n&gt; &gt; &gt; exist in the search space.  It just means a target won&#39;t get you\n&gt; &gt; =\r\nthere.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 3) We apparently disagree on whether 6 is a big numb=\r\ner (for nodes\n&gt; &gt; needed\n&gt; &gt; &gt; &gt; to represent fracture).  If you try to dev=\r\nise an encoding that\n&gt; &gt; &gt; &gt; represents fracture with fewer than that, my i=\r\nntuition is that you\n&gt; &gt; would\n&gt; &gt; &gt; &gt; be sacrificing an enormous breadth o=\r\nf flexibility in the kinds of\n&gt; &gt; &gt; &gt; fracture (and patterns in general) th=\r\nat you can represent.  Think\n&gt; &gt; about\n&gt; &gt; &gt; &gt; the number of &quot;degrees of fr=\r\needom&quot; in fracture: it&#39;s not really\n&gt; &gt; &gt; &gt; well-defined, but a single line=\r\n of fracture has a lot of dimensions:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; -position\n&gt; &gt; &gt; &gt; -or=\r\nientation\n&gt; &gt; &gt; &gt; -curvature (which can be arbitrarily complex)\n&gt; &gt; &gt; &gt; -fr=\r\nacture gradient (that is, one region can smoothly transition into\n&gt; &gt; &gt; &gt; a=\r\nnother in a kind of interpolated transitional zone)\n&gt; &gt; &gt; &gt; -embedding (fra=\r\ncture can potentially be hierarchical or regular,\n&gt; &gt; i.e.\n&gt; &gt; &gt; &gt; dependen=\r\nt on higher-level containing regions)\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; The idea that all of =\r\nthat can be encoded in anything less than about\n&gt; &gt; 6\n&gt; &gt; &gt; &gt; simple functi=\r\nons seems optimistic.  Of course, if you are willing to\n&gt; &gt; &gt; &gt; sacrifice s=\r\nome of those degrees of freedom, then you can get fewer\n&gt; &gt; &gt; &gt; nodes, but =\r\nthe exquisite minutia of such patterns would be lost (and\n&gt; &gt; &gt; &gt; you&#39;d mov=\r\ne more towards direct encoding, like the wavelets do).\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; By t=\r\nhe way, here are some cool examples of complicated kinds of\n&gt; &gt; fracture\n&gt; =\r\n&gt; &gt; &gt; from Picbreeder (such as fractured periodic zones, but even more\n&gt; &gt; =\r\ncomplex\n&gt; &gt; &gt; &gt; than even that):\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Nontrivial color patterns =\r\nin each zone:\n&gt; &gt; &gt; &gt; http://picbreeder.org/search/showgenome.php?sid=3D113=\r\n28\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Very complex brush-stroke pattern inside the app=\r\nle vs. outside (the\n&gt; &gt; DNA\n&gt; &gt; &gt; &gt; for this one is fascinating):\n&gt; &gt; &gt; &gt; h=\r\nttp://picbreeder.org/search/showgenome.php?sid=3D7109\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n &gt;\n&gt; &gt; &gt; &gt; Fractured regions covering a distorted surface, giving a remarka=\r\nble\n&gt; &gt; &gt; &gt; underlying curvature:\n&gt; &gt; &gt; &gt; http://picbreeder.org/search/show=\r\ngenome.php?sid=3D2684\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; A color variant:\n&gt; &gt; http://p=\r\nicbreeder.org/search/showgenome.php?sid=3D6652\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; When=\r\n I see so many remarkable examples like these on Picbreeder, the\n&gt; &gt; &gt; &gt; me=\r\nssage to me is that we have only scratched the surface of what\n&gt; &gt; CPPN\n&gt; &gt;=\r\n &gt; &gt; encoding can teach us about representation.  That&#39;s why I think it&#39;s\n&gt;=\r\n &gt; &gt; &gt; premature (in the face of such a treasure trove of evidence) to be\n&gt;=\r\n &gt; &gt; &gt; worrying about whether we can represent some subcomponent of such\n&gt; =\r\n&gt; &gt; &gt; patterns with less than 6 nodes.  At present I&#39;m amazed they can be\n&gt;=\r\n &gt; &gt; &gt; represented at all, let alone with under 6 nodes.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Th=\r\nanks very much for raising these issues in any case - it&#39;s a great\n&gt; &gt; &gt; &gt; =\r\ndebate to have about representation and search and goes to the heart\n&gt; &gt; of=\r\n\n&gt; &gt; &gt; &gt; the field of GDS/indirect encoding.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Best,\n&gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;shimonw&quot;  wrote:\n=\r\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Thanks for your interesting=\r\n and thought-provoking comments.  I&#39;ll\n&gt; &gt; give\n&gt; &gt; &gt; &gt; some brief reaction=\r\ns here, and I hope we can have a productive\n&gt; &gt; &gt; &gt; discussion about it at =\r\nGECCO.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 1) I won&#39;t comment for now on the new experiment=\r\ns you&#39;ve been\n&gt; &gt; running\n&gt; &gt; &gt; &gt; because the details are not available yet=\r\n.  Instead, I will just\n&gt; &gt; comment\n&gt; &gt; &gt; &gt; on the various walking gait dom=\r\nains, because the details of the\n&gt; &gt; &gt; &gt; additional results you mentioned a=\r\nre in that case already available,\n&gt; &gt; in\n&gt; &gt; &gt; &gt; newly published GECCO pap=\r\ners.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; FIrst of all, these are very cool results, and nic=\r\ne success\n&gt; &gt; stories\n&gt; &gt; &gt; &gt; for HyperNEAT.  It&#39;s great to see that the GD=\r\nS community is\n&gt; &gt; continuing\n&gt; &gt; &gt; &gt; the push the envelope in terms of rob=\r\not locomotion, which seems to\n&gt; &gt; be\n&gt; &gt; &gt; &gt; emerging as a nice application=\r\n for indirect encodings.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; However, I would simply cautio=\r\nn against placing all these\n&gt; &gt; variations\n&gt; &gt; &gt; &gt; on the walking gait task=\r\n on a one-dimensional spectrum of\n&gt; &gt; difficulty.\n&gt; &gt; &gt; &gt; In our paper, we =\r\ntook the orignal walking gait task and made only\n&gt; &gt; one\n&gt; &gt; &gt; &gt; change (in=\r\ncreasing the mass of the torso) which clearly makes the\n&gt; &gt; task\n&gt; &gt; &gt; &gt; ha=\r\nrder.  In the papers Ken mentioned, there are other differences,\n&gt; &gt; e.g.,\n=\r\n&gt; &gt; &gt; &gt; the use of an SUPG encoding, the use of CTRNNs, the use of a\n&gt; &gt; di=\r\nfferent\n&gt; &gt; &gt; &gt; substrate topology, and varying the length of the legs.\n&gt; &gt;=\r\n &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; It&#39;s completely legitimate to make these changes and they =\r\ndon&#39;t\n&gt; &gt; &gt; &gt; detract from the results at all.   But they are confounding f=\r\nactors\n&gt; &gt; when\n&gt; &gt; &gt; &gt; it comes to comparing HyperNEAT&#39;s performance on wa=\r\nlking gait tasks\n&gt; &gt; of\n&gt; &gt; &gt; &gt; different difficulties.  Some of these chan=\r\nges may make the task\n&gt; &gt; harder\n&gt; &gt; &gt; &gt; in some ways but other changes may=\r\n make it easier in others ways,\n&gt; &gt; and so\n&gt; &gt; &gt; &gt; far we don&#39;t have experi=\r\nmental results that control for these\n&gt; &gt; factors.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 2) I=\r\n hope to avoid a semantic debate about what is a\n&gt; &gt; &quot;target-based&quot;\n&gt; &gt; &gt; &gt;=\r\n FF.  If you want to include what I was calling a &quot;regular&quot; FF in the\n&gt; &gt; &gt;=\r\n &gt; scope of target-based FFs, I won&#39;t object.  But my point is that,\n&gt; &gt; &gt; =\r\n&gt; regardless of what you call them, there is an important difference\n&gt; &gt; &gt; =\r\n&gt; between FFs that require a single specific phenotype and FFs that\n&gt; &gt; &gt; &gt;=\r\n require only that some goal be achieved.  For the latter, there may\n&gt; &gt; be=\r\n\n&gt; &gt; &gt; &gt; many ways to skin the cat, though in any interesting problem, good=\r\n\n&gt; &gt; &gt; &gt; solutions are still quite rare.  The distinction is important\n&gt; &gt; =\r\nbecause,\n&gt; &gt; &gt; &gt; while the former category is arguably only of theoretical =\r\ninterest,\n&gt; &gt; the\n&gt; &gt; &gt; &gt; second category corresponds to what I consider th=\r\ne most interesting\n&gt; &gt; and\n&gt; &gt; &gt; &gt; important class of FFs, because these ar=\r\ne the FFs that naturally\n&gt; &gt; arise\n&gt; &gt; &gt; &gt; in a very large number of real-w=\r\norld optimization problems.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; So, using your terminology,=\r\n I agree it is reasonable to say\n&gt; &gt; &gt; &gt; HyperNEAT&#39;s difficulties with frac=\r\nture are probably limited to\n&gt; &gt; &gt; &gt; &quot;target-based&quot; FFs.  But for me, this =\r\nis a potentially serious\n&gt; &gt; &gt; &gt; restriction, since target-based FFs includ=\r\ne not just pathological\n&gt; &gt; FFs\n&gt; &gt; &gt; &gt; but a large class of real-world FFs=\r\n.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Regarding the wavelet method, I would still definitel=\r\ny call this\n&gt; &gt; an\n&gt; &gt; &gt; &gt; indirect encoding, but it is in some sense &quot;less=\r\n indirect&quot; because\n&gt; &gt; it\n&gt; &gt; &gt; &gt; lacks the compositional functions of Hype=\r\nrNEAT. It&#39;s a perfectly\n&gt; &gt; &gt; &gt; reasonable hypothesis that such composition=\r\nality is advantageous in\n&gt; &gt; some\n&gt; &gt; &gt; &gt; ways.  However, if that&#39;s true, t=\r\nhen we should be able to\n&gt; &gt; demonstrate\n&gt; &gt; &gt; &gt; that by finding tasks wher=\r\ne HyperNEAT outperforms the wavelet method\n&gt; &gt; &gt; &gt; (FYI, in the extended an=\r\nalysis Thomas is conducting for his master&#39;s\n&gt; &gt; &gt; &gt; thesis, we have found =\r\none variation of the line-following task where\n&gt; &gt; &gt; &gt; this is the case).  =\r\nSo in that sense, the wavelet method is a useful\n&gt; &gt; &gt; &gt; baseline, which is=\r\n the whole reason we introduced it.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 3) If it&#39;s true tha=\r\nt it takes ~6 nodes to represent fracture, then\n&gt; &gt; I\n&gt; &gt; &gt; &gt; think this a =\r\npotentially important point.  On regular FFs, it could\n&gt; &gt; &gt; &gt; contribute t=\r\no the difficulty of discovering fracture, since\n&gt; &gt; &gt; &gt; representations tha=\r\nt have only some of the necessary components may\n&gt; &gt; not\n&gt; &gt; &gt; &gt; be rewarde=\r\nd (I think you would call this &quot;deception&quot;).  In\n&gt; &gt; &gt; &gt; Picbreeder-like ta=\r\nsks, we already see that fracture can evolve\n&gt; &gt; anyway,\n&gt; &gt; &gt; &gt; but this d=\r\noesn&#39;t mean it wouldn&#39;t do it even better if fracture\n&gt; &gt; required\n&gt; &gt; &gt; &gt; =\r\nfewer nodes to represent.  If we think that the solutions to many\n&gt; &gt; &gt; &gt; i=\r\nnteresting problems require fracture, then I think it&#39;s at least\n&gt; &gt; &gt; &gt; po=\r\nssible that one could devise a better representation for such\n&gt; &gt; problems\n=\r\n&gt; &gt; &gt; &gt; than the CPPNs used in HyperNEAT.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; As I understa=\r\nnd it, your approach to dealing with &quot;regular&quot; FFs is\n&gt; &gt; to\n&gt; &gt; &gt; &gt; reform=\r\nulate them &quot;in a way that respects the need for phenotypic\n&gt; &gt; &gt; &gt; diversit=\r\ny and open-endedness.&quot;  That&#39;s a very interesting approach\n&gt; &gt; and I\n&gt; &gt; &gt; =\r\n&gt; think it has a lot of merit, but I don&#39;t think it will solve all our\n&gt; &gt; =\r\n&gt; &gt; problems because it presupposes that such a reformulation is\n&gt; &gt; possib=\r\nle\n&gt; &gt; &gt; &gt; (or that the prior knowledge it requires is available).  In some=\r\n\n&gt; &gt; cases,\n&gt; &gt; &gt; &gt; I think we are just stuck with hard FFs and we need to =\r\ndevelop\n&gt; &gt; better\n&gt; &gt; &gt; &gt; methods to deal with them.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; R=\r\negarding the idea that &quot;an unhappy and unhealthy indirect\n&gt; &gt; encoding is\n&gt;=\r\n &gt; &gt; &gt; one with only a strict target to which to aspire&quot;: this is a very\n&gt; =\r\n&gt; &gt; &gt; intriguing hypothesis, but to me it is only a hypothesis.  I think\n&gt; =\r\n&gt; it&#39;s\n&gt; &gt; &gt; &gt; true of existing indirect encodings, but that for me does no=\r\nt in any\n&gt; &gt; way\n&gt; &gt; &gt; &gt; rule out the possibility of developing a different=\r\n indirect encoding\n&gt; &gt; for\n&gt; &gt; &gt; &gt; which that is not true, and I think that=\r\n&#39;s one thing we should be\n&gt; &gt; &gt; &gt; working on.   One of the reasons that I&#39;m=\r\n interested in indirect\n&gt; &gt; &gt; &gt; encodings is that I strongly believe this c=\r\nan be done.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; &gt; &gt; Shimon\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}