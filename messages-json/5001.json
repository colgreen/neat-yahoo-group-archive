{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":37465196,"authorName":"Ken Lloyd","from":"&quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;","profile":"kalloyd2","replyTo":"LIST","senderId":"rO-Mpcqm1rXUUW-Qs2Gqmhhav5NAQ_gjdQRepyCVzhq34BE-lOk52qL6Wknox1fo0c9JzyPhjpa7X0jbYk9ZlroavgF-A5cS","spamInfo":{"isSpam":false,"reason":"12"},"subject":"RE: [neat] Re: solution for NEAT on CUDA","postDate":"1260460760","msgId":5001,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDk5NzE3ODkyQjY1MzRCREI5MEQ1NzdDQkRBRTA3Nzc0QHdhdHRwND4=","inReplyToHeader":"PGhmcjIzNitkdXFpQGVHcm91cHMuY29tPg==","referencesHeader":"PGhmb2xzcytjMmJ1QGVHcm91cHMuY29tPiA8aGZyMjM2K2R1cWlAZUdyb3Vwcy5jb20+"},"prevInTopic":5000,"nextInTopic":5002,"prevInTime":5000,"nextInTime":5002,"topicId":4995,"numMessagesInTopic":8,"msgSnippet":"Andrei and all, CUDA 3.0 is on the horizon, as is NVidia s Fermi GPU architecture.  This will make implementing HyperNEAT much easier on GPUs (not to mention ","rawEmail":"Return-Path: &lt;kalloyd@...&gt;\r\nX-Sender: kalloyd@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 4709 invoked from network); 10 Dec 2009 15:59:30 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m13.grp.re1.yahoo.com with QMQP; 10 Dec 2009 15:59:30 -0000\r\nX-Received: from unknown (HELO QMTA08.emeryville.ca.mail.comcast.net) (76.96.30.80)\n  by mta2.grp.sp2.yahoo.com with SMTP; 10 Dec 2009 15:59:30 -0000\r\nX-Received: from OMTA16.emeryville.ca.mail.comcast.net ([76.96.30.72])\n\tby QMTA08.emeryville.ca.mail.comcast.net with comcast\n\tid FTjk1d0041ZMdJ4A8TzXwT; Thu, 10 Dec 2009 15:59:31 +0000\r\nX-Received: from wattp4 ([174.56.66.94])\n\tby OMTA16.emeryville.ca.mail.comcast.net with comcast\n\tid FTzw1d002221HGW8cU03S4; Thu, 10 Dec 2009 16:00:03 +0000\r\nTo: &lt;neat@yahoogroups.com&gt;\r\nReferences: &lt;hfolss+c2bu@...&gt; &lt;hfr236+duqi@...&gt;\r\nDate: Thu, 10 Dec 2009 08:59:20 -0700\r\nMessage-ID: &lt;99717892B6534BDB90D577CBDAE07774@wattp4&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_0123_01CA7977.15211840&quot;\r\nX-Mailer: Microsoft Office Outlook 11\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.5579\r\nThread-Index: Acp5qXYF9fhE75EOQ/iJ+xpJBTwHegAB86hg\r\nIn-Reply-To: &lt;hfr236+duqi@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;\r\nSubject: RE: [neat] Re: solution for NEAT on CUDA\r\nX-Yahoo-Group-Post: member; u=37465196; y=DeBO1lc-z2pWxO0CCkBNZvsJRLoIuLhcQ-fngc-9BV3z540\r\nX-Yahoo-Profile: kalloyd2\r\n\r\n\r\n------=_NextPart_000_0123_01CA7977.15211840\r\nContent-Type: text/plain;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: 7bit\r\n\r\nAndrei and all,\n \nCUDA 3.0 is on the horizon, as is NVidia&#39;s Fermi GPU architecture.  This\nwill make implementing HyperNEAT much easier on GPUs (not to mention\nfaster).  Hopefully, I&#39;ll be able to provide something substantive after the\nfirst of the year.\n \nKen Lloyd\n\n\n  _____  \n\nFrom: neat@yahoogroups.com [mailto:neat@yahoogroups.com] On Behalf Of Andrei\nSent: Thursday, December 10, 2009 7:55 AM\nTo: neat@yahoogroups.com\nSubject: [neat] Re: solution for NEAT on CUDA\n\n\n  \n\nCUDA is extremely appropriate for a numerous, but very specific set of\nproblems, namely highly parallel, vector computation driven problems.\nWhenever the treads have to do very different work, CUDA programs don&#39;t\nprovide much speed-up, because the hardware scheduler has to serialise\noperations. Many times though, you can implement serial programs in CUDA and\nstill get impressive speed-ups. \n\nI implemented an adapted version of the Conjugate Gradient sparse system\nsolver you can find on Wikipedia in CUDA, and it was still 10x faster than\nthe GMM++ version. This is an iterative algorithm, but some subroutines can\nbe done very efficiently on a GPU, hence the speed-up. I am talking FLOAT\noperations, not double, the latter are much slower than the former on\ncurrent GPUs. \n\nThe key is to implement very large portions of your program in CUDA, things\nthat would take the CPU minutes, to give a reference. Just calling a GPU\nmatrix multiplication will make you program slower many times, unless we are\ntalking huge matrices. \n\nI have to warn you, getting performance out of CUDA does take considerably\nlonger, and it&#39;s painfully more difficult to program and debug WELL,\ncompared to CPU programming. I would also recommend a GTX200 to have enough\nmemory and speed. \n\nThat being said, I am looking forward to CUDA projects for the summer break!\n\nCheers!\nAndrei\n\n--- In neat@yahoogroups. &lt;mailto:neat%40yahoogroups.com&gt; com, &quot;openmind767&quot;\n&lt;openmind767@...&gt; wrote:\n&gt;\n&gt; Hi, I use NEAT these days. Although I have add parallel for \n&gt; EvaluateNetwork and SSE for sigmoid, the performance\n&gt; is still not well. Maybe performance will never be satisfied.\n&gt; The performance profile show 90% cpu time is used in \n&gt; Matrix-Vector Multiplication and sigmoid.\n&gt; \n&gt; CUDA maybe is the best solution for the performance now. But\n&gt; CUDA program is not like normal program. I don&#39;t have any \n&gt; experience with CUDA. As I think, in most case single network \n&gt; structure is not too big. When Calling CUDA do Matrix-Vector \n&gt; Multiplication and sigmoid for one network, CUDA memory latency \n&gt; will not be hidden. so it wont gain too much performance for \n&gt; single network. Join all networks of population into one big \n&gt; network, and call CUDA to do this big network, CUDA memory latency\n&gt; will be hidden well. Maybe this is good solution for NEAT on CUDA.\n&gt; Any suggestion and experience is welcome.\n&gt; \n&gt; Thanks,\n&gt; Baihi\n&gt;\n\n\n\n\n\n\r\n------=_NextPart_000_0123_01CA7977.15211840\r\nContent-Type: text/html;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;=\r\n\n&lt;META content=3D&quot;text/html; charset=3Dus-ascii&quot; http-equiv=3DContent-Type&gt;=\r\n\n&lt;META name=3DGENERATOR content=3D&quot;MSHTML 8.00.6001.18854&quot;&gt;&lt;/HEAD&gt;\n&lt;BODY st=\r\nyle=3D&quot;BACKGROUND-COLOR: #fff&quot;&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D1=\r\n67005615-10122009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial&gt;Andrei and a=\r\nll,&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D167005615=\r\n-10122009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;=\r\n&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D167005615-10122009&gt;&lt;FONT c=\r\nolor=3D#0000ff \nsize=3D2 face=3DArial&gt;CUDA 3.0 is on the horizon, as is&nbs=\r\np;NVidia&#39;s&nbsp;Fermi GPU \narchitecture.&nbsp; This will make implementing =\r\nHyperNEAT much easier on GPUs \n(not to mention faster).&nbsp; Hopefully, I&#39;=\r\nll be able to provide something \nsubstantive after the first of the year.&lt;/=\r\nFONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D167005615-1012=\r\n2009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV=\r\n&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D167005615-10122009&gt;&lt;FONT color=\r\n=3D#0000ff \nsize=3D2 face=3DArial&gt;Ken Lloyd&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;&lt;BR&gt;\n&lt;BLOCKQ=\r\nUOTE \nstyle=3D&quot;BORDER-LEFT: #0000ff 2px solid; PADDING-LEFT: 5px; MARGIN-LE=\r\nFT: 5px; MARGIN-RIGHT: 0px&quot;&gt;\n  &lt;DIV dir=3Dltr lang=3Den-us class=3DOutlookM=\r\nessageHeader align=3Dleft&gt;\n  &lt;HR tabIndex=3D-1&gt;\n  &lt;FONT size=3D2 face=3DTah=\r\noma&gt;&lt;B&gt;From:&lt;/B&gt; neat@yahoogroups.com \n  [mailto:neat@yahoogroups.com] &lt;B&gt;O=\r\nn Behalf Of &lt;/B&gt;Andrei&lt;BR&gt;&lt;B&gt;Sent:&lt;/B&gt; \n  Thursday, December 10, 2009 7:55 =\r\nAM&lt;BR&gt;&lt;B&gt;To:&lt;/B&gt; \n  neat@yahoogroups.com&lt;BR&gt;&lt;B&gt;Subject:&lt;/B&gt; [neat] Re: solu=\r\ntion for NEAT on \n  CUDA&lt;BR&gt;&lt;/FONT&gt;&lt;BR&gt;&lt;/DIV&gt;\n  &lt;DIV&gt;&lt;/DIV&gt;&lt;SPAN style=3D&quot;D=\r\nISPLAY: none&quot;&gt;&nbsp;&lt;/SPAN&gt; \n  &lt;DIV id=3Dygrp-text&gt;\n  &lt;P&gt;CUDA is extremely =\r\nappropriate for a numerous, but very specific set of \n  problems, namely hi=\r\nghly parallel, vector computation driven problems. Whenever \n  the treads h=\r\nave to do very different work, CUDA programs don&#39;t provide much \n  speed-up=\r\n, because the hardware scheduler has to serialise operations. Many \n  times=\r\n though, you can implement serial programs in CUDA and still get \n  impress=\r\nive speed-ups. &lt;BR&gt;&lt;BR&gt;I implemented an adapted version of the \n  Conjugate=\r\n Gradient sparse system solver you can find on Wikipedia in CUDA, and \n  it=\r\n was still 10x faster than the GMM++ version. This is an iterative \n  algor=\r\nithm, but some subroutines can be done very efficiently on a GPU, hence \n  =\r\nthe speed-up. I am talking FLOAT operations, not double, the latter are muc=\r\nh \n  slower than the former on current GPUs. &lt;BR&gt;&lt;BR&gt;The key is to implemen=\r\nt very \n  large portions of your program in CUDA, things that would take th=\r\ne CPU \n  minutes, to give a reference. Just calling a GPU matrix multiplica=\r\ntion will \n  make you program slower many times, unless we are talking huge=\r\n matrices. \n  &lt;BR&gt;&lt;BR&gt;I have to warn you, getting performance out of CUDA d=\r\noes take \n  considerably longer, and it&#39;s painfully more difficult to progr=\r\nam and debug \n  WELL, compared to CPU programming. I would also recommend a=\r\n GTX200 to have \n  enough memory and speed. &lt;BR&gt;&lt;BR&gt;That being said, I am l=\r\nooking forward to CUDA \n  projects for the summer break!&lt;BR&gt;&lt;BR&gt;Cheers!&lt;BR&gt;=\r\nAndrei&lt;BR&gt;&lt;BR&gt;--- In &lt;A \n  href=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yaho=\r\nogroups.&lt;WBR&gt;com&lt;/A&gt;, \n  &quot;openmind767&quot; &lt;openmind767@&lt;WBR&gt;...&gt; wrote:&lt;=\r\nBR&gt;&gt;&lt;BR&gt;&gt; Hi, I use \n  NEAT these days. Although I have add parallel =\r\nfor &lt;BR&gt;&gt; EvaluateNetwork and \n  SSE for sigmoid, the performance&lt;BR&gt;&gt=\r\n; is still not well. Maybe performance \n  will never be satisfied.&lt;BR&gt;&gt; =\r\nThe performance profile show 90% cpu time is \n  used in &lt;BR&gt;&gt; Matrix-Vec=\r\ntor Multiplication and sigmoid.&lt;BR&gt;&gt; &lt;BR&gt;&gt; \n  CUDA maybe is the best =\r\nsolution for the performance now. But&lt;BR&gt;&gt; CUDA \n  program is not like n=\r\normal program. I don&#39;t have any &lt;BR&gt;&gt; experience with \n  CUDA. As I thin=\r\nk, in most case single network &lt;BR&gt;&gt; structure is not too \n  big. When C=\r\nalling CUDA do Matrix-Vector &lt;BR&gt;&gt; Multiplication and sigmoid \n  for one=\r\n network, CUDA memory latency &lt;BR&gt;&gt; will not be hidden. so it wont \n  ga=\r\nin too much performance for &lt;BR&gt;&gt; single network. Join all networks of \n=\r\n  population into one big &lt;BR&gt;&gt; network, and call CUDA to do this big \n =\r\n network, CUDA memory latency&lt;BR&gt;&gt; will be hidden well. Maybe this is go=\r\nod \n  solution for NEAT on CUDA.&lt;BR&gt;&gt; Any suggestion and experience is \n=\r\n  welcome.&lt;BR&gt;&gt; &lt;BR&gt;&gt; Thanks,&lt;BR&gt;&gt; Baihi&lt;BR&gt;&gt;&lt;BR&gt;&lt;BR&gt;&lt;/P&gt;&lt;/DIV&gt;=\r\n&lt;!-- end group email --&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_0123_01CA7977.15211840--\r\n\n"}}