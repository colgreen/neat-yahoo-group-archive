{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"bDaJi-UVgzYjb5htNvjfb9lOLcJUp4D5Q9ktmCd5EMHdD_RxDhaFrlBDzi7wNYlRDPzJumK3d86_AQhg3QMNy-zytNMF","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: New paper on why modules evolve, and how to evolve modular artif","postDate":"1362734020","msgId":6019,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtoY2E0NCtjdTdtQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtoN2dzNCtuYmxiQGVHcm91cHMuY29tPg=="},"prevInTopic":6018,"nextInTopic":6020,"prevInTime":6018,"nextInTime":6020,"topicId":6011,"numMessagesInTopic":10,"msgSnippet":"Hi Stef, I think I should clarify a couple points based on your thoughts.  I really have not intended to suggest that JBM, Jeff, and Hod s paper is somehow","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 41990 invoked from network); 8 Mar 2013 09:13:42 -0000\r\nX-Received: from unknown (10.193.84.168)\n  by m3.grp.bf1.yahoo.com with QMQP; 8 Mar 2013 09:13:42 -0000\r\nX-Received: from unknown (HELO ng4-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.135)\n  by mta6.grp.bf1.yahoo.com with SMTP; 8 Mar 2013 09:13:41 -0000\r\nX-Received: from [98.138.217.177] by ng4.bullet.mail.ne1.yahoo.com with NNFMP; 08 Mar 2013 09:13:41 -0000\r\nX-Received: from [10.193.94.109] by tg2.bullet.mail.ne1.yahoo.com with NNFMP; 08 Mar 2013 09:13:41 -0000\r\nDate: Fri, 08 Mar 2013 09:13:40 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;khca44+cu7m@...&gt;\r\nIn-Reply-To: &lt;kh7gs4+nblb@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New paper on why modules evolve, and how to evolve modular artif\r\nX-Yahoo-Group-Post: member; u=54567749; y=SJxHDeLieC8lbNYa5C6InRhG_pOmY601B48FwrN-ymoQ6s62mU1Y\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Stef, \n\nI think I should clarify a couple points based on your thought=\r\ns.  I really have not intended to suggest that JBM, Jeff, and Hod&#39;s paper i=\r\ns somehow insignificant or unhelpful.  I think it&#39;s an important contributi=\r\non to highlight the role of connection length in modularity.  I really appr=\r\neciate how it also suggests the prior &quot;modularly varying goals&quot; hypothesis =\r\nmay not always be necessary.  I brought up the issue of encoding simply to =\r\nmake the point that there remain questions about the different ways that su=\r\nch a connection length bias can be achieved, but more broadly to make the p=\r\noint that there will often be such encoding vs. pressure questions in many =\r\nareas of EC and biology too, beyond only the question of modularity.  It wa=\r\ns not intended as an attack on the value of the paper&#39;s contribution, thoug=\r\nh perhaps it started to seem that way as the debate became more intense.\n\nI=\r\n also want to distance myself from the idea that anything I said is anti-MO=\r\nEA.  If you notice in my latest response, I said almost nothing about MOEAs=\r\n.  My point is about fitness pressure, whether applied through an MOEA or n=\r\not.  The same questions would come up even without an MOEA.  In fact, MOEAs=\r\n can be used elegantly to create an open-ended dynamic without &quot;pressures.&quot;=\r\n  For example, one objective can be novelty and the other genetic diversity=\r\n.  I think the pros and cons of MOEAs as practical search algorithms are la=\r\nrgely orthogonal to the discussion about fitness pressure.\n\nFinally, I thin=\r\nk we should treat fitness-pressure-based explanations from biologists with =\r\nskepticism.  As you point out, of course biologists like such explanations =\r\n(for bird wings, legs, etc.), but if biologists really had a full explanati=\r\non of why certain features emerge, then EC would be much more successful th=\r\nan it is.  \n\nMy feeling is that fitness pressure in nature accounts for opt=\r\nimization (e.g. gazelles getting faster) but not for novelty (e.g. an entir=\r\nely new organ or appendage emerging).   Because of that, &quot;explanations&quot; of =\r\nwhy certain traits arose are very confusing - are they explaining how the t=\r\nrait first appeared, or how it was optimized after it appeared?  Interestin=\r\ng, it is possible to argue that the higher the fitness pressure, the less t=\r\nhe chance for novelty (because fitness pressure is about closing off paths)=\r\n, so the fitness pressure would be in direct opposition to the kinds of eme=\r\nrgent traits that it is often used to explain - but we miss that point beca=\r\nuse it explains everything about that trait *except* its origination.\n\nHowe=\r\nver, as I said to Martin, I do acknowledge your concern with entirely remov=\r\ning fitness pressure.  It would be unsettling if that were the only way we =\r\ncould get evolution to do something interesting.  But I think we have to di=\r\ngest this bitter pill before we can cure it, and digesting it requires ackn=\r\nowledging a bunch of uncomfortable facts.  But my hope is still aligned wit=\r\nh yours in the end and like you I do not believe much useful will come from=\r\n doing only 100% open-ended searches and simply wishing for them to solve e=\r\nvery problem in robotics.  However, they can still be very useful for our r=\r\nesearch in learning how such searches work in the meantime.\n\nBest,\n\nken \n\n-=\r\n-- In neat@yahoogroups.com, &quot;stephane.doncieux&quot; &lt;stephane.doncieux@...&gt; wro=\r\nte:\n&gt;\n&gt; Hi Ken,\n&gt; \n&gt; We are getting closer to the point.\n&gt; \n&gt; I think one a=\r\nmbiguity comes with the expectations of models like that of Jean-Baptiste, =\r\nJeff and Hod. I agree that it does not answer the whole question of open-en=\r\nded evolution (even with regards to modularity), but I don&#39;t think it was t=\r\nheir intention (I haven&#39;t seen such claims in the paper). I don&#39;t believe i=\r\nn a global model that would take into account every single aspect of natura=\r\nl evolution, at least not until every piece of the puzzle has been well und=\r\nerstood. This is the classical reductionnist approach to try to separate ea=\r\nch aspect. It is clearly not easy to apply such a methodology for these que=\r\nstions as many different aspects are dependent one from the other. It anywa=\r\ny remains a classical and efficient approach in Science. Succeeding in isol=\r\nating a single effect is, for me, a major breakthrough because of the diffi=\r\nculty to do it. It should actually be what we are looking for, because the =\r\ncontribution is then highly localized and it makes it easier to build upon =\r\nit and this is really what I like in Jeff, JB and Hod work.\n&gt; \n&gt; The questi=\r\non of knowing to what extent multi-objective evolutionary algorithms are a =\r\ngood model of natural (i.e. open-ended) evolution is not critical in the wo=\r\nrk we are talking about. MOEA have interesting features, but also drawbacks=\r\n, as you have mentionned, Ken. Jeff, JB and Hod have proposed a mechanism t=\r\no adress these limitations with their stochastic domination and I think it =\r\nis enough to address their problem. The results of the article should not b=\r\ne overestimated as well as it should not be underestimated. What it shows i=\r\ns that a pressure towards a low connectivity (i.e. a goal independent selec=\r\ntion pressure) has the nice side effect of creating more modular structures=\r\n. This is an interesting and valuable result. How to use such pressures in =\r\nan open-ended perspective is another (and in my opinion different and also =\r\ninteresting) question. I completely agree with you Ken when you say that th=\r\nis question is not properly adressed by the model, but once more I am not s=\r\nure that it is their point. \n&gt; \n&gt; I agree with your point Ken that a consta=\r\nnt fitness pressure that remains the same all over the course of evolution =\r\nis very unlikely to lead to a truly open-ended evolution. By the way, it se=\r\nems to me that you suggest to discard all fitness pressures (i.e. all goal-=\r\noriented objectives, may it be constant or not). It is in line with novelty=\r\n search, but I don&#39;t think that it is a good idea. You will have solved one=\r\n part of the problem, but also introduced other limitations. One of them is=\r\n related to the size of the search space. If your behavior space is large e=\r\nnough, you will just begin to do something interesting and switch to someth=\r\ning else without trying to push what you have discovered to its limits. \n&gt; =\r\n\n&gt; Lots of biologists actually think in terms of fitness pressures and try =\r\nto find what fitness pressure has favored a given transition (apparition of=\r\n an organ, of a particular bone, etc). Lots of those pressures have been pr=\r\noposed in the litterature to explain the evolution of birds wings, legs etc=\r\n. Does it mean that such pressures were the same during all evolution ? Of =\r\ncourse not. It does not mean either that it hasn&#39;t played a critical role a=\r\nt some time along evolution. Thinking in terms of fitness pressures is no m=\r\nore than a convenient way to model what happens in evolution at a relativel=\r\ny local scale. You are true Ken to say that most of our work remains local.=\r\n If I were to study open-ended evolution, I would try to study under what c=\r\nonditions these fitness pressures changes do occur and I would propose algo=\r\nrithms to reproduce it. In this perspective, any meaningful fitness pressur=\r\ne is interesting and is a potentially significant piece of the puzzle. From=\r\n your point of view, I guess that your research program is different. Which=\r\n one will lead to a better understanding of natural evolution is a question=\r\n that we cannot decide now. Interestingly your work on novelty search with =\r\nlocal competion is actually a nice way to combine both aspects.\n&gt; \n&gt; By the=\r\n way, I really think that it is useless to work on the encoding without als=\r\no studying selection pressures that would take the best of it (may they be =\r\nconstant or not, goal-oriented or goal-independent). So that is why I disag=\r\nree with the dichotomy you make between encoding and fitness pressures. Any=\r\nway considering all the work you have made in the field on both aspects, I =\r\nguess that it is more a question of terminology than a deep disagreement.\n&gt;=\r\n \n&gt; Best,\n&gt; \n&gt; stef\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Ken&quot; &lt;kstanley@&gt; wro=\r\nte:\n&gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Hi Jeff, Stef, and Martin, I hope you don&#39;t mind sinc=\r\ne all of you addressed me if I try to reply to all of you at once to keep t=\r\nhe thread (and my brain) from branching in three directions.  Many of your =\r\npoints follow a similar theme so I think it makes sense to respond collecti=\r\nvely.  This response is practically an article, but oh well, it&#39;s nice to g=\r\net the ideas down even if it&#39;s a bit too long (it just shows you are asking=\r\n me great questions that are challenging).\n&gt; &gt; \n&gt; &gt; Martin offers a good un=\r\nifying question: &quot;My question to Ken would be here: what is the additional =\r\ningredient that makes a\n&gt; &gt; bias in the encoding better / more plausible th=\r\nan *any* implementation of the bias in the fitness function?&quot;\n&gt; &gt; \n&gt; &gt; Afte=\r\nr some thought, I believe one of the difficulties in this discussion is tha=\r\nt we often conflate artificial EC-style fitness-based experiments with open=\r\n-ended scenarios when these are entirely different situations (I take blame=\r\n myself as well for this tendency).  That is, when we talk about something =\r\nbeing &quot;better&quot; or &quot;solving&quot; a problem, we are often talking about artificia=\r\nl and unnatural experimental setups that have little relationship to open-e=\r\nnded evolutionary scenarios like nature.  \n&gt; &gt; \n&gt; &gt; Why does that matter?  =\r\nIt matters because in discussions that try to dovetail engineering-oriented=\r\n mechanisms (like a connectivity penalty) with explanations of what happene=\r\nd in nature (such as the emergence of modular connectivity), it cannot simp=\r\nly be ignored that nature in fact is first and foremost an open-ended evolu=\r\ntionary system, and that that open-ended dynamic is a significant factor in=\r\n the explanation of its products.   What that means to me is that if you th=\r\nink your proposed mechanism actually *explains* something that happened in =\r\nnature, then it is essential that the explanation speaks to the question of=\r\n how the particular mechanism you are advancing combined historically with =\r\nthe open-ended evolutionary dynamics in nature to produce the result you ex=\r\npect.\n&gt; &gt; \n&gt; &gt; But because we conflate very closed-ended artificial scenari=\r\nos with monumentally open-ended searches like nature, it leads to a lot of =\r\ndangerous inferences.   So ideas that would make sense in one context end u=\r\np sounding reasonable when they don&#39;t really make any sense in the other co=\r\nntext.  The difficulty of squaring fitness-pressure objectives with nature =\r\nis more serious when you consider it in this perspective.  (Note that I am =\r\ndefining &quot;fitness pressure&quot; as selection based on relative performance to o=\r\nther organisms on a measure of some property that varies over a range of po=\r\nssible values, such as degree of connectivity.)\n&gt; &gt; \n&gt; &gt; The problem is tha=\r\nt fitness pressures that preserve a degenerate niche for eternity are defin=\r\nitively not like nature, so whether they work or not, or whether I am someh=\r\now indicting them or not, should not be the issue.  The issue should be tha=\r\nt we should be worried that nature does not use a mechanism even remotely l=\r\nike that yet still achieves the &quot;same&quot; result (i.e. beautiful variations of=\r\n pseudo-modular design).  If you are advancing the hypothesis that this kin=\r\nd of constant &quot;pressure&quot; is somehow essential to the emergence of modularit=\r\ny in nature, then you must somehow explain why you needed to use a setup wi=\r\nth these bizarre and unnatural side effects (like eternal degenerate niches=\r\n) instead of whatever nature actually supposedly does use.\n&gt; &gt; \n&gt; &gt; And the=\r\n fact that you cannot come up with anything similar to what nature does, i.=\r\ne. something that does not involve creating such a deadweight pocket, reaso=\r\nnably may suggest that your hypothesis about nature could be wrong.  That i=\r\ns, it may not be this endless &quot;fitness pressure&quot; after all that explains wh=\r\nat is happening there, because fitness pressure in general in EC is almost =\r\nalways creating some kind of unintended deadweight niche.\n&gt; &gt; \n&gt; &gt; I think =\r\nit is particularly fascinating that in fact nature obtains not really the s=\r\name result, but a far more awesome result (in terms of modularity or anythi=\r\nng else), without such an ad hoc mechanism. \n&gt; &gt; If you think about it, as =\r\nlong as you insist on cheering for fitness pressure, it prevents you from a=\r\nsking how this could be - how is it possible that you can get these kinds o=\r\nf results without such an unnatural side effect?\n&gt; &gt; \n&gt; &gt; I need to emphasi=\r\nze here the difference between being a better engineering mechanism and a b=\r\netter explanation.  I am focusing now primarily on the explanatory power of=\r\n the proposed mechanism.  But because nature is so much more accomplished t=\r\nhan anything artificial, the explanatory gap here implies a dangerous poten=\r\ntial to overlook what will ultimately amount also to a major engineering ga=\r\np as well.  There is no evidence that anything except nature in its open-en=\r\nded way can create anything like the connectivity of natural brains.\n&gt; &gt; \n&gt;=\r\n &gt; Furthermore, it is always important to acknowledge nuance and subtlety i=\r\nn nature, which has not really been acknowledged yet in this conversation. =\r\n Nature is almost never all one way.  So it is misleading and potentially c=\r\nonfusing to talk about brains as simply modular or not.  The recent discuss=\r\nion on the Connectionists list, where scientists have been giving all kinds=\r\n of subtle and conflicting perspectives on modularity in natural brains in =\r\nresponse to Jeff and JBM&#39;s article,  echoes this nuance.   The beauty of th=\r\ne human brain to me is not that it is modular, but that it is modular to an=\r\n extent, but not entirely so, and what modularity there is is hard to pin d=\r\nown.  This kind of nuance is not to me a mere footnote to the achievement o=\r\nf nature, but the central point of it:  what nature achieves in spades is n=\r\nuance. \n&gt; &gt; \n&gt; &gt; And the idea of a constant pressure of any kind is directl=\r\ny in conflict with the achievement of nuance, because nuance is a delicate =\r\nbalancing act that is easily tipped off its perch if constant pressure in *=\r\nany* direction is applied without relief.  Jeff is concerned with short-ter=\r\nm versus long-term issues (which isn&#39;t really as clearly defined in an open=\r\n-ended context), but even if we honor that concern, it is potentially na=EF=\r\nve to believe that pressure in either direction from the start, or even an =\r\nencoding bias in either direction from the start, is somehow going to direc=\r\ntly align with the level of nuance observed millions of years in the future=\r\n.  However, while fitness pressure is eternal, encoding bias is malleable, =\r\nso pushing in the &quot;right&quot; direction from the start is not essential for enc=\r\noding.  It&#39;s more like a hint to get you started, whereas fitness pressure =\r\nis more like a gun forever pointed at your back.\n&gt; &gt; \n&gt; &gt; For example, who =\r\nis to say that we should not have the opposite short-term worry as Jeff doe=\r\ns =96 he worries that an encoding bias towards low connectivity &quot;might evol=\r\nve away because of fitness pressure,&quot; but can&#39;t we just as easily worry abo=\r\nut *too much* modularity?  In that case, Jeff&#39;s evil twin &quot;opposite-Jeff&quot; m=\r\night be worried that an initial encoding bias towards *high* connectivity m=\r\night evolve away.  It is not clear nor established fact (see Connectionists=\r\n) that the exact form of the final &quot;solution&quot; is particularly modular or no=\r\nn-modular.  What it is, is subtle and somewhere in the middle.  So none of =\r\nthis kind of panicking about what nature &quot;needs&quot; to harass it into such an =\r\nastronomically complex future configuration makes much sense.  We cannot sa=\r\ny definitively the extent to which the final structure is &quot;closer&quot; to modul=\r\nar or non-modular, whatever that even means.  Fortunately, an encoding that=\r\n begins with a bias towards modularity can tone it down as needed, or ramp =\r\nit up even more.\n&gt; &gt; \n&gt; &gt; Yet Jeff also worries about about the radiation o=\r\nf evolutionary lineages being blocked because of implicit penalties: He say=\r\ns, &quot;You assume that evolution will branch out and explore all these options=\r\n even in the face of fitness penalties for that exploration. But that is no=\r\nt how evolution works.&quot;\n&gt; &gt; \n&gt; &gt; But branching out and exploring many (not =\r\nnecessarily all of course) of the options is the only way that natural evol=\r\nution works.  That&#39;s what open-endedness is (unless you don&#39;t believe natur=\r\nal evolution to be open-ended).  The tree of life is ever-branching.  The w=\r\norry about &quot;fitness penalties&quot; here is a red herring because it originates =\r\nfrom closed-ended artificial EC experiments where you can end up on the wro=\r\nng path.  But nature does not have any single &quot;fitness penalty&quot; or &quot;right p=\r\nath&quot; throughout its run because the landscape is always changing as it bran=\r\nches and branches.  For example, before trees, being an extremely tall herb=\r\nivore would incur a fitness penalty, but after trees giraffes were perfectl=\r\ny viable.  The penalty is not consistent.\n&gt; &gt; \n&gt; &gt; More generally, how can =\r\nthere be what you call a &quot;default fitness penalty&quot; if there is no final goa=\r\nl?  Penalty with respect to what?  Keep in mind here that the origin of pse=\r\nudo-modular organization in nature likely predates the emergence even of ne=\r\nurons.  The first neural structures piggy-backed on previously evolved orga=\r\nnizational structure that likely influenced the subtle pseudo-modularity of=\r\n connectivity from the start for reasons entirely unrelated to connection c=\r\nost because these organizational conventions evolved long before neurons ev=\r\nen existed:  the bias in the encoding was in part already there.\n&gt; &gt; \n&gt; &gt; W=\r\nhich brings me back to the origin of all such conventions - canalization - =\r\nwhich is the key here.   Stephane talks about a bias that exists &quot;all along=\r\n&quot; in evolution, but ultimately the ability to *change* bias eclipses choosi=\r\nng one up front.  Again, in the context of artificial scenarios, it&#39;s a goo=\r\nd engineering hack to force in some kind of bias into the encoding or into =\r\nfitness that you expect to control things for a moderate number of generati=\r\nons.  But in nature the scope is so vast that it can&#39;t be the final word; i=\r\nt&#39;s only the initial hint.  While that hint can help, nature in the long te=\r\nrm needs to choose and commit to its own biases, and to slither out of them=\r\n from time to time, and only encoding offers that potential.  Canalization =\r\nis the way nature can make long-term (though not necessarily permanent) com=\r\nmitments.  It&#39;s how conventions are established in specific lineages.\n&gt; &gt; \n=\r\n&gt; &gt; In a genuine open-ended scenario like nature, modularity will emerge an=\r\nd proliferate over vast stretches of time only if modularity leads to more =\r\nspecies emerging.  Of course, the species we observe at the end are the con=\r\nsequence of organizational principles that supported generating many specie=\r\ns (which is almost tautological).   So it need not relate to being better o=\r\nr worse, or &quot;solving&quot; anything.  It has to do with open-ended dynamics.  Ai=\r\nr will escape a hole in a balloon if you wait long enough.  If that hole le=\r\nads to a whole other world, you will eventually see that other world.  Modu=\r\nlarity, to the extent it actually exists in nature, has served as such a ho=\r\nle.  But the only way such a hole can be exploited, the only way you can ke=\r\nep focused on that area, is if it can be canalized.  An encoding that can b=\r\ne canalized allows you to maintain the subtle convention that is responsibl=\r\ne for spreading diversity.   \n&gt; &gt; \n&gt; &gt; Stef nevertheless reminds me that &quot;s=\r\nelection pressure has strong impact,&quot; and I entirely agree of course.  But =\r\nthere are two very different classes of selection pressure.  One is about p=\r\nushing you towards the new, and the other is about forcing you to commit to=\r\n the old.  There are many ways to push towards the new, and novelty search =\r\nis just one.  In contrast, these things we call &quot;fitness pressures&quot; (whethe=\r\nr part of a MOEA or not) are the opposite =96 they are toxic strait jackets=\r\n applied for eternity.  They presume that we know what we need with no nuan=\r\nce whatsoever eons before anything remotely related has appeared.   Again, =\r\nin engineering, fair enough =96 it can work.  But it is not an *explanation=\r\n* of the products of open-ended evolution in nature, and likely is not a go=\r\nod way to produce open-endedness artificially either.  \n&gt; &gt; \n&gt; &gt; So the onl=\r\ny escape I see here from my argument is if you can argue somehow that you c=\r\nan do all these amazing things *without* open-ended evolution.  Then all yo=\r\nur pressures and constraints might make sense.  But I don&#39;t think you can a=\r\nrgue that, which, to finally circle back to Martin&#39;s broad question, is why=\r\n encoding is ultimately superior.  A canalizeable encoding is the perfect p=\r\nartner for an open-ended process.  But it is not (as Martin puts it) becaus=\r\ne it makes a particular &quot;bias in the encoding better.&quot;  Rather, it is becau=\r\nse encoding lets evolution delicately modify its own biases on the fly and =\r\nexplore all of them in parallel.  That is, the ability to change, the abili=\r\nty to flexible, to commit but to uncommit in increments of subtlety, to rad=\r\niate diversity while still committing to certain biases in certain chains, =\r\nis the power that made everything happen.  Any forced competition, any cons=\r\ntant bias, any eternal relative judgment, which are all things that constan=\r\nt fitness pressure offers, will diminish that flexibility.  It will not nec=\r\nessarily destroy the open-ended process, but it will reduce its power and u=\r\nltimately therefore cannot explain or account for it.\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Best,\n&gt;=\r\n &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;martin_pyka&quot; &lt;marti=\r\nn.pyka@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; I just would like to point out that, in my opin=\r\nion, part of the disagreement between you and Jeff and Ken comes from the f=\r\nact that Ken somehow made the statement &quot;it is better to implement the bias=\r\n in the encoding than in the fitness function&quot; but in actual fact argues fo=\r\nr a specific type of implementation in the encoding.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Thus, I t=\r\nhing the discussion should not center around the general question whether a=\r\n bias should be incorporated in the fitness or in the encoding because in b=\r\noth areas there are better and worse ways to do it. The question is more, w=\r\nhy a specific implementation (that Ken has obviously in mind, my impression=\r\n was he thought about approaches similar to LEO) is better than another.\n&gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; My question to Ken would be here: what is the additional ingredi=\r\nent that makes a bias in the encoding better / more plausible than *any* im=\r\nplementation of the bias in the fitness function?\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}