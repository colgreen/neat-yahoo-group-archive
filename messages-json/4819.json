{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"R_Mzyw5BLydIf4VsgU7D3fXlW8zUizRQSCjY0EgmdB3QteTYYyNpO8CBlmqGlirQozdRbptAGmn5bWwvhxyOmxQS","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: HybrID: A Hybridization of Indirect and Direct Encodings for Evolutionary Computation","postDate":"1250039644","msgId":4819,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM2QTc4RjlDLjJCREYyJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGg1YWRlOSszMGJrQGVHcm91cHMuY29tPg=="},"prevInTopic":4803,"nextInTopic":4829,"prevInTime":4818,"nextInTime":4820,"topicId":4772,"numMessagesInTopic":19,"msgSnippet":"Hello Ken- ... Out of curiosity, have you tried that? It would be a great anecdote to have in the quiver if your guess (which I agree with) is confirmed that","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 22089 invoked from network); 12 Aug 2009 01:15:32 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m4.grp.re1.yahoo.com with QMQP; 12 Aug 2009 01:15:32 -0000\r\nX-Received: from unknown (HELO mail-yx0-f173.google.com) (209.85.210.173)\n  by mta3.grp.re1.yahoo.com with SMTP; 12 Aug 2009 01:15:32 -0000\r\nX-Received: by yxe3 with SMTP id 3so5994981yxe.29\n        for &lt;neat@yahoogroups.com&gt;; Tue, 11 Aug 2009 18:14:11 -0700 (PDT)\r\nX-Received: by 10.100.95.15 with SMTP id s15mr6237384anb.88.1250039651420;\n        Tue, 11 Aug 2009 18:14:11 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?192.168.1.102? (c-68-41-195-245.hsd1.mi.comcast.net [68.41.195.245])\n        by mx.google.com with ESMTPS id b29sm747352ana.11.2009.08.11.18.14.07\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Tue, 11 Aug 2009 18:14:09 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.13.0.080930\r\nDate: Tue, 11 Aug 2009 21:14:04 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C6A78F9C.2BDF2%jclune@...&gt;\r\nThread-Topic: [neat] Re: HybrID: A Hybridization of Indirect and Direct\n Encodings for Evolutionary Computation\r\nThread-Index: Acoa6i6ah6b5RNPSz0GpVF8jwNPF6w==\r\nIn-Reply-To: &lt;h5ade9+30bk@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-transfer-encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: HybrID: A Hybridization of Indirect and Direct\n Encodings for Evolutionary Computation\r\nX-Yahoo-Group-Post: member; u=211599040; y=C0tqBN_4EmUHKztXWmgQ1yr4Nj_a_7IIxxsIh4xiUfXYudi19At6\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nHello Ken-\n\n...\n\n&gt;  After all, there are numerous\n&gt; pictures on Picbreeder that NEAT with CPPNs would be terrible at evolving if\n&gt; they were made the objective, yet we know that they in fact are from CPPNs!\n\nOut of curiosity, have you tried that? It would be a great anecdote to have\nin the quiver if your guess (which I agree with) is confirmed that CPPNs\nhave trouble matching CPPN-produced images.\n\n...\n\n&gt; Nevertheless, I still spent time thinking about what it all means assuming\n&gt; that there is a need for better expression of exceptions.  It&#39;s definitely\n&gt; still worth considering.  And I started thinking that the issue may be less\n&gt; about irregularity than about *independence*.  That is, your direct encoding\n&gt; is entirely independent of your indirect encoding.  Is it the fact that the\n&gt; direct encoding is irregular, or is it the fact that it is independent that\n&gt; matters?\n&gt; \n&gt; Here is an interesting experiment:  What if you ran the usual evolution with\n&gt; the quadruped with a CPPN, and then, when you would have switched to direct\n&gt; encoding, instead you start evolving a *second* CPPN (for each individual)\n&gt; whose output is simply added to the first.  The second CPPN would then be\n&gt; completely independent of the motifs and symmetries in the first.  That way,\n&gt; when its output is added to the first, it will appear irregular (because it\n&gt; does not follows its conventions), even though the CPPN itself is still biased\n&gt; towards its own independent irregularities.\n\nIt&#39;s funny you mentioned that. I had thought of the exact same idea while\nwriting my last response to you in this thread! However, I don&#39;t actually\nthink your HyperNEAT-&gt;HyperNEAT (H2H) algorithm would work, at least in the\nextreme cases, precisely because CPPNs tend to have global effects.\n\nLet&#39;s take the extreme example for clarity: Imagine that 99 of the weights\nin a network should be 1, except for one link that should be 0. The first H\n(in HybrID or H2H) gets the 99 but cannot get the 1. While HybrID would\neasily get the one, I don&#39;t think H2H would. You propose that H2H could get\nthe 1 because the second H is independent. However, think about the search\nspace. The vast majority of patterns produced by the second H will affect\nmany links, which is not what is needed. These effects will on the net be\ndeleterious, since all but one of the links are already at the optimal\nvalue. The only way for the second H to pick out the one link is to get\nlucky enough (with no gradient) to carve out just the geometric area wherein\nthe one exception link is situated. In 2D space, this requires mutations to\nget lucky in combining X and Y dimensions to select just this region, and it\nbecomes even more difficult as the dimensionality of the space goes up. For\nthis reason, I think your suggestion of adding RBF functions to HyperNEAT\nmight be a really good idea, and represents (in my opinion) the best way to\nfix this problem of exception-making within HyperNEAT. But in any case, I\ndon&#39;t think independence is the key issue: whatever lucky combination of\nmutations is necessary to carve out the geometric area surrounding the\nexception-link should be just as likely likely to occur in the existing CPPN\nas in a new CPPN that gets added, no?\n\nSetting aside the extreme case, I think you are right that H2H will be able\nto produce certain types of variations more easily than HyperNEAT, so it may\nhelp in some cases. It would be interesting to try out. For example, it\nmight really help in my Hyena example where the front legs should be shorter\nthan the back legs.\n\nHave you ever thought about running some of these thought experiments on\npicbreeder? It might be cool to change the function set for picbreeder for a\nmonth and see how the images produced change. You could also use H2H for a\nbit and see what happens, etc. I am completely sold that looking at the\nimages produced is a great way to learn about what the encoding is doing.\n\nI&#39;m now curious to see what would happen if we tried H2H on the quadruped\nproblem. I may give that a shot if I can find some time. I&#39;ll let you know\nif I do. :-)\n\nThanks, as always, for the interesting exchange.\n\n-jeff\n\n&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;&gt; \n&gt;&gt;&gt; But is the quadruped really representative of &quot;real-world&quot; problems that\n&gt;&gt;&gt; nature solved?  I don&#39;t think the quadruped solution is anything like\n&gt;&gt;&gt; nature&#39;s\n&gt;&gt;&gt; solutions to quadruped walking.  The HybrID quadruped was allowed to\n&gt;&gt;&gt; *further*\n&gt;&gt;&gt; evolve to adjust to joint faults, whereas real-life quadrupeds would simply\n&gt;&gt;&gt; adapt during their lifetime, which is a major difference.  In fact, walking\n&gt;&gt;&gt; solutions in the real world are adaptive and malleable, not canned circuits\n&gt;&gt;&gt; that only produce a single gait.  If a dog hurts its knee, it changes how it\n&gt;&gt;&gt; walks.  The HyrbrID quadruped can&#39;t do that.  Even an insect that loses a\n&gt;&gt;&gt; leg\n&gt;&gt;&gt; can adjust and keep walking.\n&gt;&gt; \n&gt;&gt; You are correct that I overreached. I was trying to distance this problem\n&gt;&gt; from traditional EC toy problems only. Clearly there is a ton more to\n&gt;&gt; natural gaits (including intralife learning) than what we have shown.\n&gt;&gt; \n&gt;&gt;&gt; Thus my guess is that the underlying encoding in nature is regular after\n&gt;&gt;&gt; all,\n&gt;&gt;&gt; and the irregularity that may ultimately arise within the brain is because\n&gt;&gt;&gt; of\n&gt;&gt;&gt; changes that are guided by adaptive rules.  But what the DNA codes for are\n&gt;&gt;&gt; those *rules*, not the changes that the rules produce.  Thus the rules\n&gt;&gt;&gt; themselves can certainly be distributed in a regular pattern.  If an\n&gt;&gt;&gt; irregular\n&gt;&gt;&gt; fault then arises, the rules for how that local area should change will\n&gt;&gt;&gt; cause\n&gt;&gt;&gt; changes for that area.  In fact, the rules must be distributed in a mostly\n&gt;&gt;&gt; regular manner:  How could it be that you should somehow adapt differently\n&gt;&gt;&gt; to\n&gt;&gt;&gt; a right knee fault than to a left one?  The underlying concept of adaptation\n&gt;&gt;&gt; is symmetric.\n&gt;&gt; \n&gt;&gt; You make very interesting points. At this point it is speculation, but it\n&gt;&gt; seems we disagree in our guesses as to the amount of hard-wired irregularity\n&gt;&gt; there is in natural systems. For example, Hyenas have longer back legs than\n&gt;&gt; front legs: my guess is that there are some hard-wired differences in the\n&gt;&gt; neural controllers between the back and front legs. I am sure learning plays\n&gt;&gt; a huge role as well, but I wouldn&#39;t be surprised if (a la the Baldwin\n&gt;&gt; effect), some of the knowledge began to be encoded genetically. I guess only\n&gt;&gt; very advanced empirical studies will reveal which of us is right. Another\n&gt;&gt; issue, of course, is that we still do not have a good handle on how much\n&gt;&gt; variation on a theme HyperNEAT can produce. We know the extremes: it can\n&gt;&gt; produce some variation, on the one hand, and it has a hard time making\n&gt;&gt; exceptions for only one link in 100 on the other, but I still do not have a\n&gt;&gt; good feel for whether it could make exceptions in the case of the Hyena, for\n&gt;&gt; example, where it simply has to make two legs do something slightly\n&gt;&gt; different. In our HybrID imperfect joint experiments, throughout the entire\n&gt;&gt; run one of the joints (or a few) had a slight bit of error, and HyperNEAT\n&gt;&gt; did not do as well as HybrID. So to me that is some evidence that HyperNEAT\n&gt;&gt; currently would have a harder time with my Hyena example than HybrID, and it\n&gt;&gt; seems to me that we want an encoding that can deal with the Hyena example.\n&gt;&gt;  \n&gt;&gt; I would also like to point out that HybrID statistically significantly\n&gt;&gt; outperformed HyperNEAT on the simulated quadruped problem even when the\n&gt;&gt; quadruped did not have any imperfect joints. I think this shows that, in\n&gt;&gt; general, rigid regularity is not ideal, and the ability to make exceptions\n&gt;&gt; will be helpful in many cases, even on very regular problems. Then again, it\n&gt;&gt; could be that HybrID is overfitting, and thus would perform less well on\n&gt;&gt; more generalized tasks than HyperNEAT, or HyperNEAT+Learning. I think it is\n&gt;&gt; an interesting area of research.\n&gt;&gt; \n&gt;&gt;&gt; So I still do not see evidence that CPPNs, nor nature for that matter,\n&gt;&gt;&gt; should\n&gt;&gt;&gt; be expected to encode for ad hoc irregularities such as a creature that is\n&gt;&gt;&gt; born with a single gait attuned to an asymmetric body with a bad knee.  That\n&gt;&gt;&gt; is, creatures derive their gaits from their bodies, not vice-versa.  They\n&gt;&gt;&gt; sense their limbs once they are alive and adapt the way they move to the\n&gt;&gt;&gt; limbs\n&gt;&gt;&gt; with which they find themselves.  Hopefully those limbs are intact, but if\n&gt;&gt;&gt; not, or if they become disabled, they adapt.\n&gt;&gt; \n&gt;&gt; I do agree that it would be great if our evolved organisms were able to do\n&gt;&gt; all of these things. But those are alternate ways to produce necessary\n&gt;&gt; irregularities. My instincts tell me that we will want such variation on\n&gt;&gt; themes throughout the body (e.g. each rib is slightly different, as are\n&gt;&gt; fingers) and brain. This gets back to the issue of how well HyperNEAT can\n&gt;&gt; make variations on themes. Can it do ribs? Fingers? You see the picbreeder\n&gt;&gt; pics and conclude that it can. I see the results from my attempts to have it\n&gt;&gt; make exceptions and wonder if it is good enough on that front, and whether\n&gt;&gt; we should try to make it better.\n&gt;&gt; \n&gt;&gt;&gt; It certainly could be possible that some new set of activation functions or\n&gt;&gt;&gt; augmentations of CPPNs could be better at producing the kinds of\n&gt;&gt;&gt; regularities\n&gt;&gt;&gt; and exceptions that are most effective for building brains.  But I do think\n&gt;&gt;&gt; that it is incorrect to frame this issue as a problem with capturing\n&gt;&gt;&gt; exceptions.  I mean, I guess I don&#39;t accept the premise of the question of\n&gt;&gt;&gt; whether it is a zero-sum game.  That question assumes that somehow we need\n&gt;&gt;&gt; more exceptions, but I do not see evidence for that.  I can think of\n&gt;&gt;&gt; innumerable possible &quot;exceptions&quot; for animal body plans, but nature would be\n&gt;&gt;&gt; able to evolve virtually none of them, even with proper selection pressure.\n&gt;&gt;&gt; How about fingers coming out of one ear, or a tongue on the bottom of one\n&gt;&gt;&gt; foot?  Or maybe one half side of the body entirely covered in hair but the\n&gt;&gt;&gt; other bald?  Or maybe we could breed babies to be born with a nice\n&gt;&gt;&gt; smiley-face\n&gt;&gt;&gt; tattoo on one cheek?\n&gt;&gt;&gt; \n&gt;&gt;&gt; These are ridiculous, but I do not see any clear a priori distinction that\n&gt;&gt;&gt; you\n&gt;&gt;&gt; have articulated between what is ridiculous and what isn&#39;t.  You seem to\n&gt;&gt;&gt; have\n&gt;&gt;&gt; the intuition that what HybrID produces is exactly in the class of &quot;not\n&gt;&gt;&gt; ridiculous&quot; exceptions, but in my view just because something worked does\n&gt;&gt;&gt; not\n&gt;&gt;&gt; mean it has any relation to nature at all.  Still, ok, it doesn&#39;t have to be\n&gt;&gt;&gt; like nature, but the question is whether it somehow sets up a new ideal\n&gt;&gt;&gt; vision\n&gt;&gt;&gt; for indirect encodings.  And I don&#39;t see that because I think the quadruped\n&gt;&gt;&gt; born with the broken joint is no less arbitrary than a baby with a\n&gt;&gt;&gt; smiley-face\n&gt;&gt;&gt; tattoo.  \n&gt;&gt; \n&gt;&gt; The examples you raise are about as extreme as I can imagine. But I don&#39;t\n&gt;&gt; think the exceptions I was testing for in my HybrID paper are in any way as\n&gt;&gt; ridiculous. \n&gt;&gt; \n&gt;&gt; HybrID outperformed HyperNEAT even without imperfect joints. Thus, in the\n&gt;&gt; most regular version of a non-toy problem, there were exceptions/variations\n&gt;&gt; that helped. I think it is much more analogous to think of these as the\n&gt;&gt; kinds of variations on a theme that produce slightly different fingers, or\n&gt;&gt; back legs longer than front legs, than to think of these exceptions as\n&gt;&gt; similar to a finger sticking out of an ear. I was not comparing HyperNEAT to\n&gt;&gt; HybrID on a rigged problem where it was beneficial to make ridiculous\n&gt;&gt; exceptions. I tested it, in fact, on a problem that many have faulted for\n&gt;&gt; being too regular! Even then, exceptions (i.e., variations on a theme)\n&gt;&gt; helped out. I then went on to show that exceptions that I think are pretty\n&gt;&gt; reasonable (minor noise in joints of the body) are even more challenging for\n&gt;&gt; HyperNEAT, possibly because it is too biased toward regularity.\n&gt;&gt;  \n&gt;&gt;&gt; So you might wonder what irregularities I would think are not arbitrary.\n&gt;&gt;&gt; The\n&gt;&gt;&gt; things that are not arbitrary are those irregular motifs that I intuitively\n&gt;&gt;&gt; observe in nature such as imperfect symmetry (e.g. the heart on one side or\n&gt;&gt;&gt; right-handedness) and repetition with variation (e.g. receptive field\n&gt;&gt;&gt; patterns\n&gt;&gt;&gt; in the brain or fingers on the hand).\n&gt;&gt; \n&gt;&gt; We agree that producing such irregularities is a good thing. I guess we\n&gt;&gt; disagree on whether my results to date are evidence of ridiculous\n&gt;&gt; exceptions, or desirable variation. More tests on different problems with\n&gt;&gt; such desired variations (e.g. a robot with back legs longer than the front)\n&gt;&gt; will help us refine our picture.\n&gt;&gt; \n&gt;&gt;&gt; It&#39;s hard for me to think of major exceptions.  Maybe the lobster&#39;s claw?\n&gt;&gt;&gt; But\n&gt;&gt;&gt; of course in all the immensity of nature there will be here and there a\n&gt;&gt;&gt; bizarre occurrence, but those do not make a rule.  (And anyway, to my\n&gt;&gt;&gt; intuition the lobster&#39;s claw is more a kind of imperfect symmetry than an\n&gt;&gt;&gt; arbitrary exception.)\n&gt;&gt;&gt; \n&gt;&gt;&gt; Admittedly, a lot of what I&#39;m going on here is intuition rather than logic.\n&gt;&gt; \n&gt;&gt; Me too. I hope you don&#39;t mind that I am out in the world raising these\n&gt;&gt; issues. You know more than anyone that I think HyperNEAT is fantastic, and\n&gt;&gt; represents a huge leap forward in terms of evolving bodies and brains as\n&gt;&gt; complex as those in nature. As I said, I personally believe we can solve the\n&gt;&gt; issues I raise within the HyperNEAT framework.\n&gt;&gt; \n&gt;&gt;&gt;&gt; In fact, isn&#39;t HybrID an example of this? Mutation-selection balance aside,\n&gt;&gt;&gt;&gt; FT-NEAT should only make a change to a pattern HyperNEAT produced if the\n&gt;&gt;&gt;&gt; change helps fitness. I realize HybrID is not the long-term solution\n&gt;&gt;&gt;&gt; (partly\n&gt;&gt;&gt;&gt; because of the scaling issues you mentioned), but isn&#39;t it at least an\n&gt;&gt;&gt;&gt; example of how an algorithm can make advances on the exception-making front\n&gt;&gt;&gt;&gt; without losing much, if anything, on the producing-regularity front?\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; That&#39;s a really good question/argument, and it is worth thinking about.  But\n&gt;&gt;&gt; ultimately I would not draw that conclusion from HybrID.  Rather, I would\n&gt;&gt;&gt; say\n&gt;&gt;&gt; that it simply works in practice on lower-dimensional structures, and I\n&gt;&gt;&gt; would\n&gt;&gt;&gt; not draw any more general lesson from it on the potential for representing\n&gt;&gt;&gt; more exceptions.  My guess is that if such a power were available at much\n&gt;&gt;&gt; higher dimensionalities, it would add a kind of noise on top of whatever\n&gt;&gt;&gt; regularity might be discovered, thereby handicapping the ability to discover\n&gt;&gt;&gt; regularity.  That is, my guess is that the ability to make completely\n&gt;&gt;&gt; arbitrary regular exceptions probably would not scale well.  Since scaling\n&gt;&gt;&gt; to\n&gt;&gt;&gt; massive sizes is part of what interests me, I would need more evidence to\n&gt;&gt;&gt; convince me that there is a need for such exception-making at large scales.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Let me conclude by emphasizing that I am *not* suggesting that CPPNs in\n&gt;&gt;&gt; their\n&gt;&gt;&gt; present form are the best encoding we will ever get.  There may indeed be\n&gt;&gt;&gt; better ones (and it&#39;s worth investigating), but what I think would make them\n&gt;&gt;&gt; better is not trying to get &quot;more exceptions&quot; but rather trying to figure\n&gt;&gt;&gt; out\n&gt;&gt;&gt; what kinds of exceptions there should be and what kinds of regularities\n&gt;&gt;&gt; there\n&gt;&gt;&gt; should be and where they would all fit into the big picture.  That is, to me\n&gt;&gt;&gt; it is more a question of kind than a question of degree.  And unfortunately,\n&gt;&gt;&gt; arguments about kind are much more specific and hair-splitting than general\n&gt;&gt;&gt; arguments about degree.\n&gt;&gt; \n&gt;&gt; I agree with this sentiment fully. That is why I think it is interesting to\n&gt;&gt; conduct experiments like those in the HybrID paper, where we are learning\n&gt;&gt; about what kinds of irregularities HyperNEAT is capable of. As you have said\n&gt;&gt; to me in the past, one of the interesting things about the HybrID work is\n&gt;&gt; that it shows that there is some low hanging fruit left on the tree that\n&gt;&gt; HyperNEAT is not grabbing. It is an open and interesting question if that is\n&gt;&gt; fruit that we want our encodings to eat! Currently you and I have different\n&gt;&gt; guesses as to the answer to that question, but at least we think that it is\n&gt;&gt; worthwhile to continue to think about these issues and research them.\n&gt;&gt; \n&gt;&gt; Thanks again for the interesting discourse.\n&gt;&gt; \n&gt;&gt; \n&gt;&gt; -Jeff\n&gt;&gt; \n&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; ken \n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Thanks again for your interesting comments.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Digital Evolution Lab, Michigan State University\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; jclune@\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; From: Kenneth Stanley &lt;kstanley@&gt;\n&gt;&gt;&gt;&gt;&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt;&gt;&gt;&gt;&gt; Date: Sun, 26 Jul 2009 23:29:15 -0000\n&gt;&gt;&gt;&gt;&gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt;&gt;&gt;&gt;&gt; Subject: [neat] Re: HybrID: A Hybridization of Indirect and Direct\n&gt;&gt;&gt;&gt;&gt; Encodings\n&gt;&gt;&gt;&gt;&gt; for Evolutionary Computation\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; Jeff knows some of my thoughts on the issue of regularity vs. irregularity\n&gt;&gt;&gt;&gt;&gt; in\n&gt;&gt;&gt;&gt;&gt; neuroevolution and also that I recognize the nice results with HybrID, so\n&gt;&gt;&gt;&gt;&gt; this\n&gt;&gt;&gt;&gt;&gt; post is just my attempt to put out some thoughts on this important issue,\n&gt;&gt;&gt;&gt;&gt; rather than a challenge to the HybrID concept.  Basically, HybrID creates\n&gt;&gt;&gt;&gt;&gt; a\n&gt;&gt;&gt;&gt;&gt; good opportunity to discuss these issues.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; Taking a long term view, what I would like to question is the idea that\n&gt;&gt;&gt;&gt;&gt; there\n&gt;&gt;&gt;&gt;&gt; is a problem with a method that has &quot;trouble&quot; discovering arbitrary\n&gt;&gt;&gt;&gt;&gt; irregularities.  It important to note that HyperNEAT has no trouble\n&gt;&gt;&gt;&gt;&gt; representing &quot;irregularity&quot; in the general sense.  In my 2007 paper on\n&gt;&gt;&gt;&gt;&gt; CPPNs\n&gt;&gt;&gt;&gt;&gt; (http://eplex.cs.ucf.edu/hyperNEATpage/HyperNEAT.html), I included\n&gt;&gt;&gt;&gt;&gt; explicit\n&gt;&gt;&gt;&gt;&gt; examples of irregularities and how easy they are to represent.  For\n&gt;&gt;&gt;&gt;&gt; example,\n&gt;&gt;&gt;&gt;&gt; see the &quot;Warped Symmetry&quot; panel in figure 9 on page 24.  So I think the\n&gt;&gt;&gt;&gt;&gt; issue\n&gt;&gt;&gt;&gt;&gt; is definitively *not* that HyperNEAT (or more specifically, CPPNs with a\n&gt;&gt;&gt;&gt;&gt; certain set of activation functions) has trouble representing or\n&gt;&gt;&gt;&gt;&gt; discovering\n&gt;&gt;&gt;&gt;&gt; irregularity, but that it has trouble discovering *particular*\n&gt;&gt;&gt;&gt;&gt; irregularities.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; Yet such trouble may actually be a good thing.  If it were too easy to\n&gt;&gt;&gt;&gt;&gt; represent any arbitrary irregularity, then you would have an encoding that\n&gt;&gt;&gt;&gt;&gt; is\n&gt;&gt;&gt;&gt;&gt; poor at discovering regularities.  So this argument could go in circles.\n&gt;&gt;&gt;&gt;&gt; But\n&gt;&gt;&gt;&gt;&gt; it&#39;s important to recognize that we are looking at a trade-off.  Nature\n&gt;&gt;&gt;&gt;&gt; faces\n&gt;&gt;&gt;&gt;&gt; the same trade-off.  It is difficult to say for sure whether DNA is biased\n&gt;&gt;&gt;&gt;&gt; towards regularity or irregularity, but I would guess looking at\n&gt;&gt;&gt;&gt;&gt; biological\n&gt;&gt;&gt;&gt;&gt; organisms that regularity reigns, and that irregularities are of certain\n&gt;&gt;&gt;&gt;&gt; *types*, that is, you would be hard pressed to &quot;breed&quot; a human with a hand\n&gt;&gt;&gt;&gt;&gt; protruding from his or her right knee, no matter how many generations were\n&gt;&gt;&gt;&gt;&gt; available.  Yet we see things like the heart on one side,\n&gt;&gt;&gt;&gt;&gt; right-handedness,\n&gt;&gt;&gt;&gt;&gt; etc.  But those do not mean that the encoding can simply bend to the\n&gt;&gt;&gt;&gt;&gt; arbitrary\n&gt;&gt;&gt;&gt;&gt; whims of a random target.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; So I think what you need if you want to evolve a really interesting\n&gt;&gt;&gt;&gt;&gt; artifact\n&gt;&gt;&gt;&gt;&gt; is not an encoding that is entirely flexible with respect to irregularity.\n&gt;&gt;&gt;&gt;&gt; If\n&gt;&gt;&gt;&gt;&gt; a particular encoding would often fail to meet ad hoc irregular targets,\n&gt;&gt;&gt;&gt;&gt; that\n&gt;&gt;&gt;&gt;&gt; is probably a sign of its long term potential, rather something we&#39;d want\n&gt;&gt;&gt;&gt;&gt; to\n&gt;&gt;&gt;&gt;&gt; fix.  If we did &quot;fix&quot; it, we&#39;d be heading back towards the chaos and\n&gt;&gt;&gt;&gt;&gt; entropy\n&gt;&gt;&gt;&gt;&gt; of direct encoding.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; Therefore, we should be careful about whether we consider difficulty\n&gt;&gt;&gt;&gt;&gt; achieving\n&gt;&gt;&gt;&gt;&gt; specific irregularities a problem to solve or an asset in the long run.\n&gt;&gt;&gt;&gt;&gt; Certainly there should an ability to create &quot;repetition with variation,&quot;\n&gt;&gt;&gt;&gt;&gt; but\n&gt;&gt;&gt;&gt;&gt; CPPNs (as well as nature) exhibit that consistently.  So it&#39;s important to\n&gt;&gt;&gt;&gt;&gt; be\n&gt;&gt;&gt;&gt;&gt; careful what we consider to be a pathology versus an asset.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; That said, HybrID is a good practical idea.  It is clear that in some\n&gt;&gt;&gt;&gt;&gt; problems\n&gt;&gt;&gt;&gt;&gt; it is just what is needed to perfect solutions with particular irregular\n&gt;&gt;&gt;&gt;&gt; needs.  Of course, when the networks become really big, e.g. with millions\n&gt;&gt;&gt;&gt;&gt; of\n&gt;&gt;&gt;&gt;&gt; connections, HybrID might begin to lose some of its ability to cope with\n&gt;&gt;&gt;&gt;&gt; the\n&gt;&gt;&gt;&gt;&gt; very high dimensionality, even if it is just tweaking on top of\n&gt;&gt;&gt;&gt;&gt; preexisting\n&gt;&gt;&gt;&gt;&gt; regularities encoded by the CPPN.  Nevertheless, at lower\n&gt;&gt;&gt;&gt;&gt; dimensionalities,\n&gt;&gt;&gt;&gt;&gt; as\n&gt;&gt;&gt;&gt;&gt; Jeff&#39;s paper shows, it can really help.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; In any case, my main point is that the issue of what we actually *want* in\n&gt;&gt;&gt;&gt;&gt; an\n&gt;&gt;&gt;&gt;&gt; encoding with respect to regularity and irregularity is quite subtle and\n&gt;&gt;&gt;&gt;&gt; deserves considered contemplation.  The CPPN with the usual set of\n&gt;&gt;&gt;&gt;&gt; activation\n&gt;&gt;&gt;&gt;&gt; functions may not ultimately be the very best representation to bias\n&gt;&gt;&gt;&gt;&gt; towards\n&gt;&gt;&gt;&gt;&gt; what we want, but if there is something better, it would not be better by\n&gt;&gt;&gt;&gt;&gt; virtue of simply being able to capture irregularities more easily.\n&gt;&gt;&gt;&gt;&gt; Rather,\n&gt;&gt;&gt;&gt;&gt; any advantage would be gained through a much more subtle argument, which\n&gt;&gt;&gt;&gt;&gt; likely refers to both regularities and irregularities of certain types,\n&gt;&gt;&gt;&gt;&gt; and\n&gt;&gt;&gt;&gt;&gt; why they are appropriate for the kinds of neural structures we hope to\n&gt;&gt;&gt;&gt;&gt; evolve.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; ken\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Hello all-\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Recently I have shown that HyperNEAT has trouble making exceptions to the\n&gt;&gt;&gt;&gt;&gt;&gt; rules it discovers (Clune et al. PPSN 2008). I would like to introduce a\n&gt;&gt;&gt;&gt;&gt;&gt; new\n&gt;&gt;&gt;&gt;&gt;&gt; paper that will be at ECAL 2009 which shows one way to remedy this\n&gt;&gt;&gt;&gt;&gt;&gt; problem:\n&gt;&gt;&gt;&gt;&gt;&gt; combining a generative encoding (HyperNEAT in this case) with a direct\n&gt;&gt;&gt;&gt;&gt;&gt; encoding (FT-NEAT in this case).\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; The resulting algorithm, which we call HybrID (Hybridization of Indirect\n&gt;&gt;&gt;&gt;&gt;&gt; and\n&gt;&gt;&gt;&gt;&gt;&gt; Direct Encodings), combines the best of both encodings, and outperformed\n&gt;&gt;&gt;&gt;&gt;&gt; HyperNEAT on all of the problems we tested it on, sometimes by as much as\n&gt;&gt;&gt;&gt;&gt;&gt; 40%. \n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; I&#39;d be really interested to hear what the people on this list think of\n&gt;&gt;&gt;&gt;&gt;&gt; the\n&gt;&gt;&gt;&gt;&gt;&gt; work. For example, I&#39;ll bet there are interesting ways to remedy the\n&gt;&gt;&gt;&gt;&gt;&gt; problem\n&gt;&gt;&gt;&gt;&gt;&gt; of making exceptions within HyperNEAT, and it would be interesting for us\n&gt;&gt;&gt;&gt;&gt;&gt; as\n&gt;&gt;&gt;&gt;&gt;&gt; a community to explore them. But in the interim, if any of you are\n&gt;&gt;&gt;&gt;&gt;&gt; deploying\n&gt;&gt;&gt;&gt;&gt;&gt; HyperNEAT on some task and want a possible performance boost, HybrID is\n&gt;&gt;&gt;&gt;&gt;&gt; easy\n&gt;&gt;&gt;&gt;&gt;&gt; to implement and may lead to a significant improvement.\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Here is a link to the paper:\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt; https://www.msu.edu/~jclune/webfiles/publications/Clune-HybrID-ECAL-2009.pd&gt;&gt;\n&gt;&gt; &gt;&gt;\n&gt;&gt; f\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Here is the abstract from the paper:\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Evolutionary algorithms typically use direct encodings, where each\n&gt;&gt;&gt;&gt;&gt;&gt; element\n&gt;&gt;&gt;&gt;&gt;&gt; of the phenotype is specified independently in the genotype. Because\n&gt;&gt;&gt;&gt;&gt;&gt; direct\n&gt;&gt;&gt;&gt;&gt;&gt; encodings have difficulty evolving modular and symmetric phenotypes, some\n&gt;&gt;&gt;&gt;&gt;&gt; researchers use indirect encodings, wherein one genomic element can\n&gt;&gt;&gt;&gt;&gt;&gt; influence multiple parts of a phenotype. We have previously shown that\n&gt;&gt;&gt;&gt;&gt;&gt; HyperNEAT, an indirect encoding, outperforms FT-NEAT, a direct-encoding\n&gt;&gt;&gt;&gt;&gt;&gt; control, on many problems, especially as the regularity of the problem\n&gt;&gt;&gt;&gt;&gt;&gt; increases. However, HyperNEAT is no panacea; it had difficulty accounting\n&gt;&gt;&gt;&gt;&gt;&gt; for irregularities in problems. In this paper, we propose a new\n&gt;&gt;&gt;&gt;&gt;&gt; algorithm,\n&gt;&gt;&gt;&gt;&gt;&gt; a\n&gt;&gt;&gt;&gt;&gt;&gt; Hybridized Indirect and Direct encoding (HybrID), which discovers the\n&gt;&gt;&gt;&gt;&gt;&gt; regularity of a problem with an indirect encoding and accounts for\n&gt;&gt;&gt;&gt;&gt;&gt; irregularities via a direct encoding. In three different problem domains,\n&gt;&gt;&gt;&gt;&gt;&gt; HybrID outperforms HyperNEAT in most situations, with performance\n&gt;&gt;&gt;&gt;&gt;&gt; improvements as large as 40%. Our work suggests that hybridizing indirect\n&gt;&gt;&gt;&gt;&gt;&gt; and direct encodings can be an effective way to improve the performance\n&gt;&gt;&gt;&gt;&gt;&gt; of\n&gt;&gt;&gt;&gt;&gt;&gt; evolutionary algorithms.\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt;&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; Digital Evolution Lab, Michigan State University\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; jclune@\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt; \n&gt; \n&gt; \n\n\n\n"}}