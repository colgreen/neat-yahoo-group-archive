{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"3Q-ctkDDWo95vg5L_RvpzEsKA-DnXKf8e9YkLlQPYOCj5myk_mbiXHRhUCkSZwasdmEdw-ED19xOiNcKi8Pc4vOB65FTMdwZPp7jodXE2c0p","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: The Next Generation of Neural Networks - Geoff Hinton TechTalk","postDate":"1239574406","msgId":4624,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdydHAyNitvcmxsQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGdydG9xcityMmU5QGVHcm91cHMuY29tPg=="},"prevInTopic":4623,"nextInTopic":4625,"prevInTime":4623,"nextInTime":4625,"topicId":4620,"numMessagesInTopic":8,"msgSnippet":"Oops, I think yahoo compressed my nicely scrambled dot pattern example in some browsers, making it looks like just a square of dots :(  Please take my word for","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 90761 invoked from network); 12 Apr 2009 22:14:07 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m1.grp.sp2.yahoo.com with QMQP; 12 Apr 2009 22:14:07 -0000\r\nX-Received: from unknown (HELO n38b.bullet.mail.sp1.yahoo.com) (66.163.168.152)\n  by mta2.grp.re1.yahoo.com with SMTP; 12 Apr 2009 22:14:06 -0000\r\nX-Received: from [69.147.65.173] by n38.bullet.mail.sp1.yahoo.com with NNFMP; 12 Apr 2009 22:13:27 -0000\r\nX-Received: from [98.137.34.35] by t15.bullet.mail.sp1.yahoo.com with NNFMP; 12 Apr 2009 22:13:27 -0000\r\nDate: Sun, 12 Apr 2009 22:13:26 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;grtp26+orll@...&gt;\r\nIn-Reply-To: &lt;grtoqr+r2e9@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: The Next Generation of Neural Networks - Geoff Hinton TechTalk\r\nX-Yahoo-Group-Post: member; u=54567749; y=fPS-zpoeBlFuo7HbP5hrlUGFaGFZ4Sei3qhjhC0PaUOOuMqzux1R\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nOops, I think yahoo compressed my nicely scrambled dot pattern example in s=\r\nome browsers, making it looks like just a square of dots :(  Please take my=\r\n word for it that it was very messed up.\n\n\n--- In neat@yahoogroups.com, &quot;Ke=\r\nnneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Thomas, that&#39;s an interesting hypo=\r\nthesis that we would have no trouble with arbitrary dot patterns if we had =\r\ngrown up with them.  That hypothesis can&#39;t be directly tested since we didn=\r\n&#39;t grow up that way, but my guess is that if characters were just arbitrary=\r\n disconnected pixel patterns like:\n&gt; \n&gt;    .      .   .. ..     .\n&gt;  \n&gt;    =\r\n.     .  . .\n&gt;    ...           ..  . . .\n&gt;            ..      ...\n&gt;       =\r\n         .\n&gt;      .      .      . .  .\n&gt;        . . .   . .   \n&gt; \n&gt;   \n&gt; th=\r\nen life would be much much harder, and perhaps we would never learn any of =\r\nthem.  Note that no human writing system in the world (including braille ht=\r\ntp://www.afb.org/braillebug/braille_print.asp) employs arbitrary scrambles =\r\nof dots.  My guess is that there is a reason for that.\n&gt; \n&gt; And we know som=\r\nething about why that is too:  The human visual system is designed as a ser=\r\nies of ascending topographic maps that preserve adjacency relationships.  T=\r\nhat is, if two photoreceptors (i.e. &quot;pixels&quot;) are adjacent in the eye, then=\r\n the receptive field neurons associated with those locations in the visual =\r\ncortex are *also* near each other.  Thus the geometry is preserved as we mo=\r\nve up the processing hierarchy.  That&#39;s why the maps are called &quot;topographi=\r\nc.&quot;  This topographic arrangement allows us to exploit geometric relationsh=\r\nips like connectedness as a step in our visual perception.  In fact, identi=\r\nfying contiguous contours is a fundamental step in visual processing.  \n&gt; \n=\r\n&gt; These facts are not accidental:  Almost nothing in the natural world is a=\r\nn arbitrary scramble of dots.  Thus the visual system would not benefit fro=\r\nm a design that could learn such arbitrary scrambles, since they never come=\r\n up.  \n&gt; \n&gt; I am not certain that geometry is inherent in all problems, but=\r\n I would also not assume that it isn&#39;t.  In a time series, time itself can =\r\nbe exploited conceptually as a geometric dimension (as it often is when you=\r\n draw one).  Document classification involves semantics, and semantics are =\r\nconveniently expressible in terms of &quot;semantic maps.&quot;   For example, &quot;happy=\r\n&quot; is closer to &quot;contented&quot; (geometrically) than it is to &quot;sad.&quot;  In poker, =\r\nit is possible to visualize the state of one&#39;s hand as a configuration in a=\r\n multidimensional geometric space.   I have had conversations with others i=\r\nn the field in which we tried to think of concepts that are clearly entirel=\r\ny non-geometric, and it&#39;s not as easy as you would think to find something =\r\nlike that.\n&gt; \n&gt; The human brain is so topographic, especially in the neocor=\r\ntex (laminated, i.e. layered, structures tend to easily preserve topographi=\r\nc relationships), that it would not surprise me if geometry is the fundamen=\r\ntal conceptual building block below almost every concept.  Everything from =\r\ncounting (going up) to who is your boss (also going up) and who is your sub=\r\nordinate (going down) has a potential geometric valence.  In fact, anything=\r\n that has &quot;dimensions&quot; is conceivable as a geometry.  What has no dimension=\r\ns?\n&gt; \n&gt; While I cannot prove that everything requires a geometric perspecti=\r\nve, it is by no means clear that they do not, or at least that the vast maj=\r\nority of important things we learn are heavily dependent on their geometry.=\r\n  So I&#39;d be a little suspicious of any algorithm that entirely ignores geom=\r\netry, or is incapable of seeing it.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; --- In neat@y=\r\nahoogroups.com, Thomas Johnson &lt;thomas.j.johnson@&gt; wrote:\n&gt; &gt;\n&gt; &gt; But the o=\r\nnly reason they&#39;re now incomprehensible scrambles of dots from a\n&gt; &gt; human =\r\nperspective is because you and I haven&#39;t grown up with the concept of\n&gt; &gt; t=\r\nhose particular scrambles as representing particular digits. If we had,\n&gt; &gt;=\r\n then we would probably be as able to recognize those scrambles as easily a=\r\ns\n&gt; &gt; we recognize handwritten numbers.\n&gt; &gt; \n&gt; &gt; Now certainly geometry is =\r\nimportant for some (maybe even many) problems, but\n&gt; &gt; it doesn&#39;t lend an a=\r\ndvantage to every problem. And for other problems (e.g.,\n&gt; &gt; document class=\r\nification, non-board games like poker, time series analysis)\n&gt; &gt; it&#39;s not i=\r\nmmediately clear how to encode the problem domain in a geometric\n&gt; &gt; way, a=\r\nnd trying to force the problem domain into a geometric representation\n&gt; &gt; m=\r\nay be more work than the return it gives.\n&gt; &gt; \n&gt; &gt; On Sun, Apr 12, 2009 at =\r\n4:36 PM, Kenneth Stanley &lt;kstanley@&gt;wrote:\n&gt; &gt; \n&gt; &gt; &gt;\n&gt; &gt; &gt;  As a thought e=\r\nxperiment, let&#39;s imagine that we scrambled the order of the\n&gt; &gt; &gt; pixel arr=\r\nay that represents these characters. For example, we might map\n&gt; &gt; &gt; pixel =\r\n(0,0) to (4,2) (arbitrarily). Every other pixel is also mapped to a\n&gt; &gt; &gt; u=\r\nnique random location. Then assume that we use this same scrambled mapping\n=\r\n&gt; &gt; &gt; on every example, so they are all still consistent. Unrealistically,\n=\r\n&gt; &gt; &gt; assuming I understand the model, it will *still* learn the patterns j=\r\nust as\n&gt; &gt; &gt; effectively as before, irrespective of the fact that they are =\r\nnow completely\n&gt; &gt; &gt; incomprehensible scrambles of dots from a human perspe=\r\nctive.\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}