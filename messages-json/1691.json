{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"jrw4rPOTR6PbHNRd_EScbZpSCix-JUofp8BZuKXJnuhmHL6-wDYCE6F8xD2mBlBcP2IijapCmjEtZXIBbClIijPHbEs74yPZtQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Neuron functions","postDate":"1099607108","msgId":1691,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxOEFBQzQ0LjgwNDA4MDBAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PDYuMS4yLjAuMC4yMDA0MTEwMzE2MTY0Mi4wMjUwNmM2OEBwb3AubWFpbC55YWhvby5jby51az4=","referencesHeader":"PDQxODY0NDM3LjEwNTA2MDJAZHNsLnBpcGV4LmNvbT4gPDYuMS4yLjAuMC4yMDA0MTEwMjExNTgzMC4wMjUxNDcwOEBwb3AubWFpbC55YWhvby5jby51az4gPDQxODdGMjhDLjUwNTAxMDBAZHNsLnBpcGV4LmNvbT4gPDYuMS4yLjAuMC4yMDA0MTEwMzE2MTY0Mi4wMjUwNmM2OEBwb3AubWFpbC55YWhvby5jby51az4="},"prevInTopic":1686,"nextInTopic":1692,"prevInTime":1690,"nextInTime":1692,"topicId":1668,"numMessagesInTopic":20,"msgSnippet":"... So what you re saying here is that any given circuit is only made up of one type of neurone... ... I think I m reading you wrong, this seems to contradict","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 52542 invoked from network); 4 Nov 2004 22:25:33 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m14.grp.scd.yahoo.com with QMQP; 4 Nov 2004 22:25:33 -0000\r\nReceived: from unknown (HELO blaster.systems.pipex.net) (62.241.163.7)\n  by mta1.grp.scd.yahoo.com with SMTP; 4 Nov 2004 22:25:33 -0000\r\nReceived: from [10.0.0.10] (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby blaster.systems.pipex.net (Postfix) with ESMTP id BED44E00007A\n\tfor &lt;neat@yahoogroups.com&gt;; Thu,  4 Nov 2004 22:25:09 +0000 (GMT)\r\nMessage-ID: &lt;418AAC44.8040800@...&gt;\r\nDate: Thu, 04 Nov 2004 22:25:08 +0000\r\nUser-Agent: Mozilla Thunderbird 0.7.1 (Windows/20040626)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;41864437.1050602@...&gt; &lt;6.1.2.0.0.20041102115830.02514708@...&gt; &lt;4187F28C.5050100@...&gt; &lt;6.1.2.0.0.20041103161642.02506c68@...&gt;\r\nIn-Reply-To: &lt;6.1.2.0.0.20041103161642.02506c68@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.163.7\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Neuron functions\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nIan Badcoe wrote:\n\n&gt;&gt;On the other hand you could take the view that some functions are so\n&gt;&gt;fundamental, that incorporating them into the neuron makes sense for all\n&gt;&gt;NEAT variations, modular or otherwise. As I say, I think there&#39;s a\n&gt;&gt;balance between providing functions and increasing the parameter/search\n&gt;&gt;space, and not having so many and reducing the search space. Biological\n&gt;&gt;neural nets suggest the right balance might be towards adding functions.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Do they?  There are a few different types of neurones in biology, it is \n&gt;true, but in some ways it is more as if each type plays a different role, \n&gt;globally, rather than just being chosen for a different role in the local \n&gt;circuit.\n&gt;  \n&gt;\nSo what you&#39;re saying here is that any given circuit is only made up of \none type of neurone...\n\n&gt;  e.g. by this I mean the idea that a whole class of neurone can be \n&gt;labelled as (say) &quot;inhibitory&quot; and that it is always found to inhibit and \n&gt;further, it is localised to particular areas and also always attached to \n&gt;the neurones of some other class.\n&gt;  \n&gt;\nI think I&#39;m reading you wrong, this seems to contradict what you just said!\n\nI must admit I&#39;m using a small amount of knowledge and a lot of \nintuition and guesswork here. I *think* that all neurones start out the \nsame and of course grow dendrites which vary in strength but slowly \n&#39;harden&#39; if the strength doesn&#39;t ever change much. I suspect (and I may \nor may not have read this somewhere) that the functionality of a neuron \nmight be determined in a similar way. That model would be analagous to \nour parameterising of the activation function per neurone.\n\nOn the other hand we have this other model where all neurones are the \nsame, but their functionality is modified by the current chemical and \nelectrical state of the neurone. This seems like a far more powerful \nmodel in that the signals in the network can actually dramatically \nmodify the functionality that a network describes.\n\nI really need to do some reading on biological neurones, I suspect that \nboth models exist to some degree - a hybrid of the two models might be \neven more powerful.\n\n&gt;All that said, I&#39;m not disagreeing with you.  Just wondering if it is the \n&gt;whole story...\n&gt;  \n&gt;\nAlmost certainly not!&lt;&gt;\n\n&gt;&gt;&gt;        Did you consider making it an homologous pool of functions.  e.g.\n&gt;&gt;&gt;not distinguishing collectors from activators but allowing them to be\n&gt;&gt;&gt;plugged in any order.  That way if the system needs linearity through some\n&gt;&gt;&gt;sub-net, it does not need to select a whole load of &quot;linear&quot; activators, it\n&gt;&gt;&gt;just omits the activation functions altogether.  That would cover the leaky\n&gt;&gt;&gt;integrator as well...\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;I don&#39;t follow. One of the proposed activation functions is a\n&gt;&gt;straight-through/linear function, surely selecting that function has the\n&gt;&gt;same effect?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;True, but I guess I was getting towards the idea that for some sorts of \n&gt;net, activation functions might be the exception, rather than the rule...\n&gt;\n&gt;A completely homologous set of functions is also clearer for future \n&gt;expansion, because if you have something a bit different, like leaky \n&gt;integrator, it is still clear where it fits into the system.\n&gt;  \n&gt;\nI&#39;m not forming a clear idea of how this would work - apart from \npreviously mention idea of a set of functions each with a weighting \nfactor. You then have a choice of evolving the weight factor (model 1) \nor calculating it based on the signal on each function&#39;s input channel \n(model 2).\n\nIf I can find some research that says neurones exhibit N types of \nbehaviour, each brought on specific neuro-transmitters or combinations \nof neuro-transmitters, then I think that would be a clear signal as to \nwhich way to go.\n\n&gt;&gt;This is similar to an idea that I came across some years ago, whereby\n&gt;&gt;the output of a neuron could become a connection weight between two\n&gt;&gt;other neurons. Thus the dynamic connection weight acts like a switch,\n&gt;&gt;kind of like the base pin on a transistor. Unfortunately that project\n&gt;&gt;never got off the ground.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;That&#39;s another very interesting idea.  What that ultimately implies is the \n&gt;complete loss of weights, in favour of a type of neurone which can be \n&gt;inserted into the connection between two others, and which has the effect \n&gt;of weighting one of its inputs by the other.  If the second input is wired \n&gt;to the bias... oh, just a second, how do you put the weight on the bias \n&gt;connection :-) -- I guess you would always also need &quot;plain&quot; weights.\n&gt;  \n&gt;\nYes and I actually think the idea is just another way of looking at the \nmodel you suggested, but with different input channels - you have a \n&#39;weight&#39; channel that determines the weight you apply to signals on the \n&#39;signal&#39; channel. And if you have a mix of this type of neurones and \n&#39;normal&#39; neurones then you have a hybrid of our two models as I \ndescribed them above.\n\n&gt;&gt;&gt;        (scale and act are different in that when act is very low, the\n&gt;&gt;&gt;sigmoid becomes linear, but when scale is very low, the sigmoid just\n&gt;&gt;&gt;becomes very shallow)\n&gt;&gt;&gt;\n&gt;&gt;&gt;        Wiring Act and Scale just to the bias would be the same as having\n&gt;&gt;&gt;fixed, mutatable &quot;curve shape&quot; parameters on the node.  Wiring them to\n&gt;&gt;&gt;other inputs could give you potentiation/depotentiation (those are where X\n&gt;&gt;&gt;does not trigger Y but does increase the ability of Z to trigger Y).\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;I&#39;m not sure I fully understand what you are describing. We can\n&gt;&gt;parameterise activation using something like:\n&gt;&gt;\n&gt;&gt;y = 1 /  (1+exp(-x * activation))\n&gt;&gt;\n&gt;&gt;But if you then scale the whole thing:\n&gt;&gt;\n&gt;&gt;y = scale* (1/(1+exp(-x * activation)))\n&gt;&gt;\n&gt;&gt;then the function now outputs over the range 0.0 to scale, instead of\n&gt;&gt;0.0 to 1.0. Is this what you meant? And would this be beneficial?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;No, I meant two different control parameters on the activation curve (I \n&gt;need to draw this but don&#39;t have time just now) one controlling the Y-scale \n&gt;  \n&gt;\nerr, you mean the X-scale right?\n\n&gt;of the sigmoid (activation in your eqn) and one controlling the curviness \n&gt;of the sigmoid (so that if it were zero, the sgmoid would be a straight \n&gt;line).  I&#39;m not sure the exp-based eqn is easily adapted for that, but I&#39;ll \n&gt;think about it later....\n&gt;  \n&gt;\nAhh I see now. I was thinking that the curviness and the activation \n(above) where the same thing. But yeh that seems like a sound idea, I&#39;ll \nhave a play around in gnuplot.\n\n&gt;&gt;Also note that if either activation or scale are -ve then the sigmoid is\n&gt;&gt;flipped, which could well be useful. Another option is to translate the\n&gt;&gt;sigmoid, but I think values can be translated (on the x-axis) by passing\n&gt;&gt;through a neuron with a linear activation function and a bias input (the\n&gt;&gt;translation amount).\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Or just change the bias on the inputs...\n&gt;  \n&gt;\noh yeh :)\n\n&gt;Translation on the Y-axis, that&#39;s a different matter, but again is straying \n&gt;away from &quot;nerve-like&quot; behaviour.\n&gt;  \n&gt;\nYes, the signal strength is going to be limited in biology, but we might \nstill wish to do Y-axis translation within the allowable signal strength \nrange. This of course can be achieved by passing the signal through a \nnormal sigmoid and then adding a bias to the output, say, on another \nneurone with a linear activation function (getting deja vu here).\n\n&gt;&gt;So the main question that arises is - should we maintain an activation\n&gt;&gt;output range of 0.0 to 1.0 at all times, or is it beneficial to output\n&gt;&gt;over other ranges? I would resist this on the basis that keeping signals\n&gt;&gt;within the same range provides us with a sort of standardisation that\n&gt;&gt;aids compatibility of neurons, and thus aids evolution.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;And if connections weights are universal then every output gets it&#39;s own \n&gt;scaling anyway.\n&gt;\n&gt;OTOH, this does lead up to another point I&#39;ve been meaning to discuss for \n&gt;some time.  Which is how easy is it for NEAT to adjust scaling?  I thought \n&gt;about ti before in terms of input, but it applies just the same for \n&gt;output.  e.g. suppose we have a fit network, where to improve it we need to \n&gt;adjust the &quot;activation&quot; parameter (from your eqn) of one neurone.  The \n&gt;standard ANN scheme can do this, all you do is scale _all_ the input \n&gt;weights on the neurone by the same amount.  However, that is a set of a \n&gt;large number of linked mutations, and doing one of them in isolation might \n&gt;be unadaptive.  I see this as a very strong argument that neurones should \n&gt;have a mutatable &quot;activation&quot; (which I would call &quot;gain&quot;) parameter...\n&gt;  \n&gt;\nYes, what you say makes a lot of sense.\n\nGoing to go and search out some biological neurone research now.\n\nColin.\n\nP.S. Is a neurone just a posh neuron? :)\n\n\n"}}