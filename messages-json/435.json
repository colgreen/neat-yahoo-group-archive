{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"1E_Y7W831yp8SDHZ7BeMaTl5Csi-CVeWbOgCHhYl3QjC1ODoEBm0OaO-ALlgNXPfaUzp4F719Bn5vIck_wAX8cAYuGL034nRZKDOreYJlb33","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Training/testing subset selection","postDate":"1077856942","msgId":435,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGMxbWhyZStrMjlhQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEJBWTItRjI1RDk2ZG9DZWtwOHQwMDAwODFjMUBob3RtYWlsLmNvbT4="},"prevInTopic":433,"nextInTopic":437,"prevInTime":434,"nextInTime":436,"topicId":433,"numMessagesInTopic":9,"msgSnippet":"John, here are my thoughts: First, NEAT probably needs to be the one that decides who gets to reproduce, who is elite, etc...  I think it might make more sense","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 16423 invoked from network); 27 Feb 2004 04:42:24 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m10.grp.scd.yahoo.com with QMQP; 27 Feb 2004 04:42:24 -0000\r\nReceived: from unknown (HELO n12.grp.scd.yahoo.com) (66.218.66.67)\n  by mta3.grp.scd.yahoo.com with SMTP; 27 Feb 2004 04:42:23 -0000\r\nReceived: from [66.218.66.143] by n12.grp.scd.yahoo.com with NNFMP; 27 Feb 2004 04:42:23 -0000\r\nDate: Fri, 27 Feb 2004 04:42:22 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;c1mhre+k29a@...&gt;\r\nIn-Reply-To: &lt;BAY2-F25D96doCekp8t000081c1@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 6858\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.67\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Training/testing subset selection\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJohn, here are my thoughts:\n\nFirst, NEAT probably needs to be the one that decides who gets to\nreproduce, who is elite, etc...  I think it might make more sense for\nyou to use the scheme you describe except instead of trying to make\nspecific decisions about what &quot;type&quot; something is, try to assign them\na meaninful fitness number, so NEAT can then take those and do things\nthe way it likes.  In other words, those that you say &quot;should not\nreproduce,&quot; just assign to them some huge penalty.  And those that are\n&quot;elite&quot; you can give a really high fitness.  Then feed all those\nfinalized values back into NEAT and it will figure out how to handle\nreproduction.  That would also allow you to avoid having to use\nintermediate averages or things like that.  (I am assuming you don&#39;t\nintend to rewrite your own version of NEAT, right?)\n\nSecond, as much as possible, I would try to give the same random\nsample to different networks in the same generation.  The problem is\nthat you are going to come up against considerable noise if you start\ntaking different random samples.  Of course, in the limit evolution\ncan theoretically sort through that noise, but in practice a great\ndeal of noise can be insurmountable.  \n\nYou have a huge pool of examples so it will be interesting to see\nhow this experiment turns out.  \n\nken\n\n--- In neat@yahoogroups.com, &quot;John Arrowwood&quot; &lt;jarrowwx@h...&gt; wrote:\n&gt; I wanted to get some feedback on the evolutionary process, and how\nmuch \n&gt; evaluation is &#39;enough&#39;...\n&gt; \n&gt; I have analyzed 421 pictures so far (out of 3110).  That equates to \n&gt; 8,357,762,728 samples.  Yes, that&#39;s 8 billion.  I&#39;ve hashed the\nsamples so \n&gt; that each is represented as a 27 bit number, and I rotate and mirror\nand \n&gt; invert as necessary to get the smallest 27 bit number that is able\nto be \n&gt; represented by that sample.  This means that if two samples are\nalmost the \n&gt; same, just rotated, they will have the same hash value.  Now, after\nonly \n&gt; saving one sample per hash value, I find that I only have 8,442,727\nsamples. \n&gt;   As each picture is evaluated, more samples are added, but at a\nfairly slow \n&gt; rate.  I expect the final count to come in under 10 million. \nHowever, each \n&gt; of those samples can actually be represented 16 different ways,\nraising the \n&gt; count to closer to 160 million.\n&gt; \n&gt; Now, let&#39;s say I had a thousand genomes in a population, and\ncompared each \n&gt; to 160 million samples per epoch.  That&#39;s 160 billion evaluations. \nI \n&gt; wouldn&#39;t live to see my project complete!\n&gt; \n&gt; What I&#39;m contemplating is a fitness evaluation heuristic to limit\nthe amount \n&gt; of computation required.  The basic assumptions are these (correct\nme where \n&gt; I am wrong)\n&gt; \n&gt; 1.  Comparing the average fitness of two individuals does not\nrequire that \n&gt; each be evaluated on the same number of samples (by virtue of the\nfact that \n&gt; it is an average)\n&gt;   -- Therefore, it should be possible to have an imbalanced number\nof \n&gt; evaluations per specimen per epoch.\n&gt; \n&gt; 2.  The narrower the standard deviation of the fitness evaluations,\nthe \n&gt; higher the confidence there is in that average\n&gt;   -- Therefore, we can stop evaluating the specimen once its\nstatistical \n&gt; curve is well established\n&gt; \n&gt; 3.  Only some specimens will reproduce in a given generation\n&gt;   -- Therefore, once a specimen has shown that it is relatively\nunfit for \n&gt; propagation, further evaluations are unnecessary against it\n&gt;   -- And as soon as both non-reproducing and elite specimens are\nidentified, \n&gt; further evaluation is unnecessary for that species\n&gt; \n&gt; So the proposed algorithm would be something like this:\n&gt; \n&gt; Evaluate each member of a species on a sample\n&gt; Sort the results\n&gt; Divide the list into those that will reproduce, and those that\nwon&#39;t.  (If I \n&gt; can do that at this stage...can I?)\n&gt; Repeat until the list of those that will not reproduce doesn&#39;t\nchange for N \n&gt; evaluations\n&gt; While doing this, skip re-evaluating any whose fitness evaluation we\nare \n&gt; confident of\n&gt; If ALL those who will reproduce are also &#39;elites&#39; then we are\ndone...\n&gt; Otherwise, continue to evaluate only those that are expected to\nreproduce \n&gt; until the elites are identified in the same manner as the\nnon-reproducing \n&gt; specimens were identified.\n&gt; The process for a species completes as soon as we know the genetic\nmake up \n&gt; of those that will be propagating.\n&gt; \n&gt; Now, since the number of offspring that a species can have is a\nfunction of \n&gt; the fitness of the average population, the above may be a little\ndifficult, \n&gt; since we can&#39;t know ahead of time how many will reproduce and how\nmany will \n&gt; not, right?  Well, wait, we have an intermediate average species\nfitness \n&gt; value, which could be used to make that division.  As the average\nfitness \n&gt; changes, the number of allotted offspring will change.  That will\nchange the \n&gt; list of which can reproduce and which can not.  And since the\nalgorithm \n&gt; defines the stopping point as when the list remains the same over a\nperiod \n&gt; of time, then as long as the average is stabalizing, it will\ncontinue to \n&gt; evaluate.  Though some individual ones might stop evaluating early\nif the \n&gt; confidence in their fitness evaluation is high.\n&gt; \n&gt; That make sense?\n&gt; \n&gt; Now what concerns me is that what I want from the end result is a\nnetwork \n&gt; that has a high fitness evaluation for all 160  million samples.  So\nNOT \n&gt; evaluating against them all somewhat scares me.  But on the other\nhand, I \n&gt; know that I can&#39;t, so I need to rationalize myself out of that\nunhealthy \n&gt; desire... :)\n&gt; \n&gt; If the samples are randomized (which to a degree, they will be), and\nI only \n&gt; have one sample per hash value (which will be the case), then I\ndon&#39;t have \n&gt; to worry too much about statistical skew.  Over the course of many \n&gt; generations, the best specimens will have been evaluated against\nmore and \n&gt; more samples, with ever increasing fitness.  The chances of the\nhigher \n&gt; fitness against the later samples resulting in lower fitness for\nthings that \n&gt; were previously evaluated against are fairly low (I hope).  So\nevaluating \n&gt; each generation against different samples than the generation before\nshould \n&gt; be okay.\n&gt; \n&gt; However, fairness would dictate that all samples in a generation be\ncompared \n&gt; against the same samples, right?  At least until their low fitness \n&gt; disqualifies them for reproduction and thus further evaluation is \n&gt; unnecessary.  Or would it be okay, even potentially valuable, to\nperform \n&gt; every evaluation against a different sample?  (since there are so\nmany of \n&gt; them available to work with)\n&gt; \n&gt; Okay, so there are some thoughts.  Anybody have any feedback for me?\n&gt; \n&gt; Thanks!\n&gt; \n&gt; -- John\n&gt; \n&gt; _________________________________________________________________\n&gt; Find and compare great deals on Broadband access at the MSN\nHigh-Speed \n&gt; Marketplace. http://click.atdmt.com/AVE/go/onm00200360ave/direct/01/\n\n\n"}}