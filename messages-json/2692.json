{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":150579383,"authorName":"Sidhant Dash","from":"Sidhant Dash &lt;sidhantdash@...&gt;","profile":"sidhantdash","replyTo":"LIST","senderId":"QWUCYHgF_v-F96BylrY7JOKoOEVQyV4UTJy4joy2-Mygvrhmb-6T6rCIfuMFr6pc7_fSDE_yvnMgZs8LdnNsmH0b9pWBIGmRBv57","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] NEAT enhancements","postDate":"1154631052","msgId":2692,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDYwODAzMTg1MDUyLjc3Njk1LnFtYWlsQHdlYjYxMjE1Lm1haWwueWFob28uY29tPg==","inReplyToHeader":"PGVhbDlqNCtjNTNmQGVHcm91cHMuY29tPg=="},"prevInTopic":2691,"nextInTopic":2696,"prevInTime":2691,"nextInTime":2693,"topicId":2684,"numMessagesInTopic":17,"msgSnippet":"As part of an undergraduate research project, I did implement something on those lines. I worked on a NEAT based approach to predicting a noisy financial time","rawEmail":"Return-Path: &lt;sidhantdash@...&gt;\r\nX-Sender: sidhantdash@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 51764 invoked from network); 3 Aug 2006 18:51:54 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m30.grp.scd.yahoo.com with QMQP; 3 Aug 2006 18:51:54 -0000\r\nReceived: from unknown (HELO web61215.mail.yahoo.com) (209.73.179.64)\n  by mta5.grp.scd.yahoo.com with SMTP; 3 Aug 2006 18:51:53 -0000\r\nReceived: (qmail 77697 invoked by uid 60001); 3 Aug 2006 18:50:52 -0000\r\nMessage-ID: &lt;20060803185052.77695.qmail@...&gt;\r\nReceived: from [203.200.95.130] by web61215.mail.yahoo.com via HTTP; Thu, 03 Aug 2006 11:50:52 PDT\r\nDate: Thu, 3 Aug 2006 11:50:52 -0700 (PDT)\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;eal9j4+c53f@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;0-1473150866-1154631052=:76668&quot;\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Sidhant Dash &lt;sidhantdash@...&gt;\r\nSubject: Re: [neat] NEAT enhancements\r\nX-Yahoo-Group-Post: member; u=150579383; y=wEyDbNVzryUDbmuAWtHpgEh0t2pTnEWJDgnR27gjA4apQEnJ3LU\r\nX-Yahoo-Profile: sidhantdash\r\n\r\n\r\n--0-1473150866-1154631052=:76668\r\nContent-Type: text/plain; charset=iso-8859-1\r\nContent-Transfer-Encoding: 8bit\r\n\r\nAs part of an undergraduate research project, I did implement something on those lines. \n   \n  I worked on a NEAT based approach to predicting a noisy financial time series (Yen-USD exchange rate). The original NEAT algorithm was modified to start with an initial population of 3 different neural network architectures, which included Elman networks and MLPs apart from the normal recurrent networks that NEAT begins with. The networks (winners) produced by NEAT were then put through a conjugate gradient based optimization process, and finally the optimized networks were combined using an ensembling technique to produce the final results. \n   \n  I personally think the local optimization is necessary when we are using NEAT to produce networks to accomplish tasks that require a high degree of precision. It kind of fine tunes the performance of the networks. Ensembling then is one of the standard tools in the ML repertoire to produce results that none of NEAT&#39;s &#39;winner&#39; networks could individually produce. \n   \n  A detailed project report is posted in the Files section.\n   \n  regards\n  Sidhant\n\naklein07 &lt;a.klein@...&gt; wrote:\n          All,\n\nKen&#39;s papers mention (at least I think that they do) that (dynamic) \nannealing of mutation rates might be advantageous in order to confine \nglobal searching after a while to a promising region in search space. \nHaving read some papers, I also found indications that a hybrid \nweight training algorithm (global search by means of genetic \nalgorithms and local search using some gradient descent algorithm) \nmight be able to produce better results than genetic algorithm search \nalone. The reason is, that each type of algorithm performs well \nmostly only in its specific field. Has anyone further insights into \nthis topic ? Has anyone tried to implement any of the approaches \nmentioned ? \n\nAlso time delay network connections might provide improvements for \nsome model estimation tasks. Has anyone tested / implemented yet any \nof these ideas ?\n\nThanks for any comments,\nAchim\n\n\n\n         \n\n\nFear is only as deep as the mind allows. \n--Japanese proverb \n\nMy blog   \n\n \t\t\n---------------------------------\nGroups are talking. We&acute;re listening. Check out the handy changes to Yahoo! Groups. \r\n--0-1473150866-1154631052=:76668\r\nContent-Type: text/html; charset=iso-8859-1\r\nContent-Transfer-Encoding: 8bit\r\n\r\n&lt;div&gt;As part of an undergraduate research project, I did implement something on those lines. &lt;/div&gt;  &lt;div&gt;&nbsp;&lt;/div&gt;  &lt;DIV&gt;I worked on a NEAT based approach to predicting a noisy financial time series (Yen-USD exchange rate). The original NEAT algorithm was modified to start with an initial population of 3 different neural network architectures, which included Elman networks and MLPs apart from the normal recurrent networks that NEAT begins with. The networks (winners) produced by NEAT were then put through a conjugate gradient based optimization process, and finally the optimized networks were combined using an ensembling technique to produce the final results. &lt;/DIV&gt;  &lt;DIV&gt;&nbsp;&lt;/DIV&gt;  &lt;DIV&gt;I personally think the local optimization is necessary when we are using NEAT to produce networks to accomplish tasks that require a high degree of precision. It kind of fine tunes the performance of the networks. Ensembling then is one of the standard tools in the ML repertoire to\n produce results that none of NEAT&#39;s &#39;winner&#39; networks could individually produce. &lt;/DIV&gt;  &lt;div&gt;&nbsp;&lt;/div&gt;  &lt;div&gt;A detailed project report is posted in the Files section.&lt;/div&gt;  &lt;div&gt;&nbsp;&lt;/div&gt;  &lt;div&gt;regards&lt;/div&gt;  &lt;div&gt;Sidhant&lt;BR&gt;&lt;BR&gt;&lt;B&gt;&lt;I&gt;aklein07 &lt;a.klein@...&gt;&lt;/I&gt;&lt;/B&gt; wrote:&lt;/div&gt;  &lt;BLOCKQUOTE class=replbq style=&quot;PADDING-LEFT: 5px; MARGIN-LEFT: 5px; BORDER-LEFT: #1010ff 2px solid&quot;&gt;&lt;!-- Network content --&gt;  &lt;DIV id=ygrp-text&gt;  &lt;div&gt;All,&lt;BR&gt;&lt;BR&gt;Ken&#39;s papers mention (at least I think that they do) that (dynamic) &lt;BR&gt;annealing of mutation rates might be advantageous in order to confine &lt;BR&gt;global searching after a while to a promising region in search space. &lt;BR&gt;Having read some papers, I also\n found indications that a hybrid &lt;BR&gt;weight training algorithm (global search by means of genetic &lt;BR&gt;algorithms and local search using some gradient descent algorithm) &lt;BR&gt;might be able to produce better results than genetic algorithm search &lt;BR&gt;alone. The reason is, that each type of algorithm performs well &lt;BR&gt;mostly only in its specific field. Has anyone further insights into &lt;BR&gt;this topic ? Has anyone tried to implement any of the approaches &lt;BR&gt;mentioned ? &lt;BR&gt;&lt;BR&gt;Also time delay network connections might provide improvements for &lt;BR&gt;some model estimation tasks. Has anyone tested / implemented yet any &lt;BR&gt;of these ideas ?&lt;BR&gt;&lt;BR&gt;Thanks for any comments,&lt;BR&gt;Achim&lt;BR&gt;&lt;BR&gt;&lt;/div&gt;&lt;/DIV&gt;&lt;!--End group email --&gt;&lt;/BLOCKQUOTE&gt;&lt;BR&gt;&lt;BR&gt;&lt;BR&gt;&lt;DIV&gt;Fear is only as deep as the mind allows.\n &lt;BR&gt;--Japanese proverb &lt;BR&gt;&lt;BR&gt;&lt;A href=&quot;http://sidhantdash.blogspot.com&quot;&gt;My blog&lt;/A&gt;&nbsp;&nbsp; &lt;/DIV&gt;&lt;p&gt;&#32;\n\t\t&lt;hr size=1&gt;Groups are talking. We&acute;re listening. Check out the &lt;a href=&quot;http://pa.yahoo.com/*http://us.rd.yahoo.com/evt=41144/*http://groups.yahoo.com/local/newemail.html&quot;&gt;handy changes to Yahoo! Groups.&lt;/a&gt; \r\n--0-1473150866-1154631052=:76668--\r\n\n"}}