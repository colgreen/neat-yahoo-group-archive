{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"H8hEOrAbUDEIqK-0KgLvwfqjkCQWCxZGZV8zX2W6w3Mi6LmHOw0wkdguspWX6SJXlR1LNmGK8mLddS-hAX1YMgGTN60iUWql0V6HNd77keq1nRIF7XA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HyperNEAT coevolution","postDate":"1223255218","msgId":4346,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdjYm9iaSttNHNkQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGdjYjd0bCthMmcwQGVHcm91cHMuY29tPg=="},"prevInTopic":4343,"nextInTopic":4355,"prevInTime":4345,"nextInTime":4347,"topicId":40,"numMessagesInTopic":95,"msgSnippet":"Yes, I am planning to upgrade the program so that the substrate configuration and other things will be loaded from a configuration file. That way, combined","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 61052 invoked from network); 6 Oct 2008 01:07:00 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m42.grp.scd.yahoo.com with QMQP; 6 Oct 2008 01:07:00 -0000\r\nX-Received: from unknown (HELO n44d.bullet.mail.sp1.yahoo.com) (66.163.169.158)\n  by mta15.grp.scd.yahoo.com with SMTP; 6 Oct 2008 01:07:00 -0000\r\nX-Received: from [69.147.65.150] by n44.bullet.mail.sp1.yahoo.com with NNFMP; 06 Oct 2008 01:06:59 -0000\r\nX-Received: from [66.218.66.89] by t7.bullet.mail.sp1.yahoo.com with NNFMP; 06 Oct 2008 01:06:59 -0000\r\nDate: Mon, 06 Oct 2008 01:06:58 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gcbobi+m4sd@...&gt;\r\nIn-Reply-To: &lt;gcb7tl+a2g0@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: HyperNEAT coevolution\r\nX-Yahoo-Group-Post: member; u=283334584; y=ni2nQnCR2DQNsraCmTWMT4V-zwt-oQVWcd223OcsPyrakv5mL3MfEdO2gA\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nYes, I am planning to upgrade the program so that the substrate \nconfigurat=\r\nion and other things will be loaded from a configuration \nfile. That way, c=\r\nombined with the population saving and loading, a \nuser will be able to obs=\r\nerve the impact and do various experiments \n(for example removing the walls=\r\n, altering the physics constants, \netc.). I will probably upload the next v=\r\nersion in a day or two. \n\nI forgot to mention that the substrates are based=\r\n on leaky \nintegrators. This generally means that highly recurrent structur=\r\nes are \neasy to stabilize plus the benefit of complexification generating m=\r\nore \nand more complex patterns of the activations changing in the \nsubstrat=\r\ne. In fact I prefer to use CTRNN substrates in all of my \nexperiments with =\r\nHyperNEAT. The substrates activate with a timestep of \n0.02 and the time co=\r\nnstant range across the substrate is [0.25 .. \n2.5]. The weight and node-bi=\r\nas range across the substrate is [-4.0 .. \n4.0]. The activation function in=\r\n the hidden and output nodes in the \nsubstrate is Tanh. \n\nI didn&#39;t know the=\r\nre is a leak, thank you for telling me about it. \nPerhaps there is somethin=\r\ng wrong with the visualization code, I&#39;ll \ninvestigate that and I hope it w=\r\nill be fixed in the next release. \n\nI am not trying to do anything commerci=\r\nal with the particular NEAT \nimplementation. Or any. But it was developed w=\r\nhile I was working in a \nproject that did involve commercial application of=\r\n NNs evolved with \nNEAT. And anything I developed during that time falls un=\r\nder the NDA. \nMy side projects (like NEVH, the novelty search demos and thi=\r\ns one) \nare not protected, though. Well I can easily write another NEAT \nim=\r\nplementation but I don&#39;t want to waste time debugging stuff so I \njust go o=\r\nn with this one. \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;k=\r\nstanley@...&gt; wrote:\n&gt;\n&gt; Peter, \n&gt; \n&gt; Thank you for the details.  Is there a=\r\nny chance you could release a\n&gt; version that lets the user scale the networ=\r\nks and observe the \nimpact?\n&gt;  That would be very interesting.  You mention=\r\ned that it does \ngenerally\n&gt; work with some imperfections.\n&gt; \n&gt; Another int=\r\neresting thing about these substrates is that they appear\n&gt; to be highly re=\r\ncurrent.  Is that right?  The amount of recurrence\n&gt; suggests that the mech=\r\nanisms for action are likely quite different\n&gt; than what we see for example=\r\n in early generation regaular NEAT,\n&gt; because these substrate networks must=\r\n have ways of maintaining\n&gt; equilibrium and self-stabilizing cycling activa=\r\ntion.\n&gt; \n&gt; About the complexification,  I am sure there is some limit due t=\r\no \nthe\n&gt; finite nature of the substrate, although it will take a while to g=\r\net\n&gt; there.  However, of course, if you start with a bigger substrate the\n&gt;=\r\n limit is greater.\n&gt; \n&gt; By the way, I wonder if there is a memory leak or s=\r\nomething like \nthat?\n&gt;  I notice that after 100 generations or so the simul=\r\nation of the\n&gt; robots on the screen slowed down a lot.  However, I do not s=\r\nee a\n&gt; reason that it should slow down since the substrates are always the\n=\r\n&gt; same size.  Why would they simulate slower in one generation than \nanothe=\r\nr?\n&gt; \n&gt; Finally, just out of curiosity, why is your version of NEAT \nprotec=\r\nted\n&gt; behind an NDA?  Are you trying to do something commercial with it?\n&gt; =\r\n\n&gt; ken\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;petar_chervenski&quot; &lt;petar_cherv=\r\nenski@&gt;\n&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Ken, \n&gt; &gt; \n&gt; &gt; I am happy that you like my demo=\r\n. This particular experiment was \nset \n&gt; &gt; up to answer some questions I ha=\r\nd in mind. The first one is \nobvious, \n&gt; &gt; is there a geometric regularity =\r\nin the predator/prey task that \n&gt; &gt; HyperNEAT can possibly exploit. And the=\r\nre is. I can see some \n&gt; &gt; meaningful behaviors emerging with HyperNEAT as =\r\nearly as the 4th \nor \n&gt; &gt; 5th generation. My next question was, what is the=\r\n difference \nbetween \n&gt; &gt; the indirect encoding and the direct encoding. Le=\r\nt me make it more \n&gt; &gt; clear. In your experiments in the robot duel domain,=\r\n both robot \nNNs \n&gt; &gt; are encoded directly and complexifying. They elaborat=\r\ne on previous \n&gt; &gt; strategies by incrementally adding more structure, right=\r\n? \n&gt; &gt; What about HyperNEAT, does it preserve the same dynamics, where \nthe=\r\n \n&gt; &gt; CPPNs complexify but the substrate is fixed? Does it lead to \nendless=\r\n \n&gt; &gt; alteration of strategies instead of elaboration? I can predict \nthat =\r\n\n&gt; &gt; HyperNEAT can discover some complex connectivity patterns between \n&gt; &gt;=\r\n hidden nodes to develop some kind of &quot;intelligent&quot; behavior, but \nis \n&gt; &gt; =\r\nthat limited? \n&gt; &gt; Well this question is still not answered because, as you=\r\n \nmentioned, \n&gt; &gt; the predator/prey task is too easy to learn, though there=\r\n is room \nfor \n&gt; &gt; the predator and prey to learn tricks to fool each other=\r\n. For \nexample \n&gt; &gt; the prey can learn to hide behind walls, etc. \n&gt; &gt; Yes =\r\nI compared it to direct encoding NEAT and generally I can \nconclude \n&gt; &gt; th=\r\nat HyperNEAT develops strategies faster. Especially in the case \nof \n&gt; &gt; ma=\r\nny many inputs. Scaling works as well, but it is not perfect. \n&gt; &gt; Let me t=\r\nell you about the source code. Unfortunately the core NEAT \n&gt; &gt; library I w=\r\nrote and use is locked under an NDA but it is \nequivalent to \n&gt; &gt; the rtNEA=\r\nT modification I released with the NEVH project. The \n&gt; &gt; visualization rou=\r\ntines are basically the same there, there is \nnothing \n&gt; &gt; new at all. But =\r\nI can release the source code for the demos \n&gt; &gt; themselves. Please ask me =\r\nabout any details, I will be happy to \nhelp \n&gt; &gt; anyone. \n&gt; &gt; \n&gt; &gt; Peter\n&gt; =\r\n&gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; =\r\n&gt; &gt;\n&gt; &gt; &gt; Peter, thanks for this HyperNEAT coevolution demo.  I see some\n&gt; =\r\n&gt; &gt; interesting behaviors evolving, but I am curious about your own\n&gt; &gt; &gt; c=\r\nonclusions?  What did you learn from this experiment?  Did you \ntry\n&gt; &gt; &gt; c=\r\nomparing it to regular NEAT in the same domain?  I am not sure\n&gt; &gt; &gt; whethe=\r\nr the difference would be great since I am not sure if \nthis \n&gt; &gt; task\n&gt; &gt; =\r\n&gt; is sufficiently complex to exhibit a significant difference \nbetween\n&gt; &gt; =\r\n&gt; the methods.  That is, there is probably only so good that you \ncan \n&gt; &gt; =\r\nget\n&gt; &gt; &gt; before new skills stop really mattering in this domain.\n&gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; By the way, do you plan releasing source code for your various\n&gt; &gt; &gt; ex=\r\nperiments and AI code?  It seems like you have a nice system \nset \n&gt; &gt; up\n&gt;=\r\n &gt; &gt; and other people might like tinkering with it.  I especially \nlike \n&gt; =\r\n&gt; the\n&gt; &gt; &gt; real-time CPPN/substrate displays.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; --- In neat@yahoogroups.com, neat@yahoogroups.com wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; Hello,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; This email message is a notification to le=\r\nt you know that\n&gt; &gt; &gt; &gt; a file has been uploaded to the Files area of the n=\r\neat \n&gt; &gt; &gt; &gt; group.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;   File        : /HyperNEAT_PredatorPre=\r\ny.exe \n&gt; &gt; &gt; &gt;   Uploaded by : petar_chervenski &lt;petar_chervenski@&gt; \n&gt; &gt; &gt; =\r\n&gt;   Description : HyperNEAT applied to competetive predator-prey\n&gt; &gt; &gt; coev=\r\nolution task (with walls).  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; You can access this file at t=\r\nhe URL:\n&gt; &gt; &gt; &gt; \n&gt; &gt; \nhttp://groups.yahoo.com/group/neat/files/HyperNEAT_Pr=\r\nedatorPrey.exe \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; To learn more about file sharing for your =\r\ngroup, please visit:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; \n&gt; &gt; \nhttp://help.yahoo.com/l/us/yahoo/g=\r\nroups/original/members/web/index.htm\n&gt; &gt; lfiles\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Regards,\n&gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; petar_chervenski &lt;petar_chervenski@&gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n=\r\n\n\n"}}