{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"5aOqwj11n3Jy5PCv5WrRlMhy-zrG6tg2hWJgBVRLQ-45nBLbfIbeU9MmWdntTRgbbgPwCIvwIj3X-Usd21XX2p3wPXUS","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Practical Applications","postDate":"1259567273","msgId":4952,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhldnRiOSs4MGY1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGViNDRhMmQ3MDkxMTI5MjEzMGw2ZGJmNjE5Y2w2ZTg5YzcwZmY4ZWY2OGJiQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4950,"nextInTopic":4955,"prevInTime":4951,"nextInTime":4953,"topicId":4937,"numMessagesInTopic":10,"msgSnippet":"Daniel, of course the two issues are related (machine learning and evolving structure).  Evolving structure could be said to be a machine learning problem.","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 35576 invoked from network); 30 Nov 2009 07:48:20 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m11.grp.re1.yahoo.com with QMQP; 30 Nov 2009 07:48:20 -0000\r\nX-Received: from unknown (HELO n41b.bullet.mail.sp1.yahoo.com) (66.163.168.155)\n  by mta2.grp.sp2.yahoo.com with SMTP; 30 Nov 2009 07:48:20 -0000\r\nX-Received: from [69.147.65.172] by n41.bullet.mail.sp1.yahoo.com with NNFMP; 30 Nov 2009 07:47:54 -0000\r\nX-Received: from [98.137.34.34] by t14.bullet.mail.sp1.yahoo.com with NNFMP; 30 Nov 2009 07:47:54 -0000\r\nDate: Mon, 30 Nov 2009 07:47:53 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hevtb9+80f5@...&gt;\r\nIn-Reply-To: &lt;eb44a2d70911292130l6dbf619cl6e89c70ff8ef68bb@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Practical Applications\r\nX-Yahoo-Group-Post: member; u=54567749; y=Xv_GpIVwtuJA1Z0A8MauqOpGtR2Q5_9fJGN1OWICxbIJunPCi_YC\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nDaniel, of course the two issues are related (machine learning and evolvi=\r\nng structure).  Evolving structure could be said to be a machine learning p=\r\nroblem.  But I understand the gist of your question.\n\nWhat I like about NEA=\r\nT is that it provides enduring principles that will likely still apply even=\r\n as algorithms move beyond it.  At least I believe that the principles are =\r\nfundamental enough that they will still form a foundation for more advanced=\r\n approaches.  The idea of protecting innovation through speciation and the =\r\nidea of complexification seem fundamental to me (and also tied to each othe=\r\nr, since complexification is impeded without protecting innovation), and I =\r\nhave not felt that they are getting old even almost 10 years after they fir=\r\nst came to mind.  Historical marking is a bit different, since it is not re=\r\nally a fundamental principle so much as a neat trick that enables the other=\r\n two principles, but it is so convenient that I also believe it will remain=\r\n a good choice for what it does (especially for speciation) in the future.\n=\r\n\nHyperNEAT is a good example of how a new algorithm can be built on top of =\r\nthese principles.  HyperNEAT introduces some very new ideas that have almos=\r\nt nothing to do with NEAT, but it nevertheless runs seamlessly on top of NE=\r\nAT.  That tells me that NEAT indeed has some enduring intellectual value.\n\n=\r\nIn general what personally excites me in AI algorithms in general is the id=\r\nea that they provide a foundation for something new in the future to build =\r\nupon them.  While many people focus and obsess over benchmarks and benchmar=\r\nk performance in the present day, in the long run I believe the best contri=\r\nbutions to our field are stepping stones, rather than ends in themselves.  =\r\nTherefore, my instinct is to look for stepping stones that open up new dire=\r\nctions.\n\nHopefully one day a chain of such stepping stones will lead us clo=\r\nse to AI.\n\nken\n\n--- In neat@yahoogroups.com, Daniel Tuohy &lt;danielr2e@...&gt; w=\r\nrote:\n&gt;\n&gt; Ken, I have a more theoretical question along these lines:\n&gt; \n&gt; A=\r\nre you more confident in NEAT&#39;s strength as a machine learning technique or=\r\n\n&gt; as an approach for evolving structure?  Another way to ask this might be=\r\n:\n&gt; which capability are you more proud of?\n&gt; \n&gt; Daniel\n&gt; \n&gt; On Sun, Nov 29=\r\n, 2009 at 2:51 PM, Ken &lt;kstanley@...&gt; wrote:\n&gt; \n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; --- In =\r\nneat@yahoogroups.com &lt;neat%40yahoogroups.com&gt;, Richard Gong\n&gt; &gt; &lt;gongrichar=\r\nd@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; What real world problems have been successfully solv=\r\ned by NEAT?\n&gt; &gt; &gt;\n&gt; &gt; &gt; Like Colin Green, I have tried to apply NEAT to fin=\r\nance, but without\n&gt; &gt; &gt; success.\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt; One recent interesting real-=\r\nworld success is the most accurate measurement\n&gt; &gt; yet of the top quark mas=\r\ns at the Fermilab accelerator:\n&gt; &gt;\n&gt; &gt; Aaltonen et al. Measurement of the T=\r\nop Quark Mass with Dilepton Events\n&gt; &gt; Selected using Neuroevolution at CDF=\r\n. Physical Review Letters,\n&gt; &gt; 102(15):2001=962008, 2009.\n&gt; &gt; http://www-cd=\r\nf.fnal.gov/physics/preprints/cdf9235_dil_mtop_nn.pdf\n&gt; &gt;\n&gt; &gt; Believe it or =\r\nnot, NEAT is the method that was used to get the reading.\n&gt; &gt; Physical Revi=\r\new Letters is a top physics journal. If you search Google for :\n&gt; &gt; Top Qua=\r\nrk &quot;augmenting topologies&quot;\n&gt; &gt; you will see a lot written about it.\n&gt; &gt;\n&gt; &gt;=\r\n However, often such results say more about the ability of someone to choos=\r\ne\n&gt; &gt; the right problem for the method than it does about the method overal=\r\nl. AI\n&gt; &gt; and neural-inspired learning methods are clearly a work in progre=\r\nss, so a\n&gt; &gt; lot of the excitement is in the ideas and where they may lead,=\r\n rather than a\n&gt; &gt; particular application.\n&gt; &gt;\n&gt; &gt; Also, when it comes to f=\r\ninance, perhaps neurological accuracy is not the\n&gt; &gt; best basis for masteri=\r\nng it. After all, most people are not able to look at\n&gt; &gt; a graph of financ=\r\nial activity and know what will happen next, yet they are\n&gt; &gt; great at tyin=\r\ng their shoes. Of course, in the context of the recent\n&gt; &gt; financial meltdo=\r\nwn, it&#39;s not clear that anything or anyone is really good at\n&gt; &gt; finance.\n&gt;=\r\n &gt;\n&gt; &gt; ken\n&gt; &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt;\n\n\n\n"}}