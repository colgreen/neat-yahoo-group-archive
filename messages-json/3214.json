{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"SYCZwj4leik8VGkBt-JpvJ76E9W7otJanmS6wnTMk9vi0F1VZ1-h6yT32c4n1-ypOeeKzPq3qireZaOFZwVj5tT9KwvWzj9pAW80v95BweXL","spamInfo":{"isSpam":false,"reason":"6"},"subject":"A Few Thoughts on HyperNEAT","postDate":"1177879592","msgId":3214,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYxMzA3OCtsM2I4QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":3215,"prevInTime":3213,"nextInTime":3215,"topicId":3214,"numMessagesInTopic":27,"msgSnippet":"The recent discussion between Andy and Stephen has raised a few interesting issues.  One is the possibility of having additional types of activation functions","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 41631 invoked from network); 29 Apr 2007 20:48:08 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m49.grp.scd.yahoo.com with QMQP; 29 Apr 2007 20:48:08 -0000\r\nReceived: from unknown (HELO n29a.bullet.sp1.yahoo.com) (209.131.38.249)\n  by mta5.grp.scd.yahoo.com with SMTP; 29 Apr 2007 20:48:07 -0000\r\nReceived: from [216.252.122.217] by n29.bullet.sp1.yahoo.com with NNFMP; 29 Apr 2007 20:46:33 -0000\r\nReceived: from [66.218.69.3] by t2.bullet.sp1.yahoo.com with NNFMP; 29 Apr 2007 20:46:33 -0000\r\nReceived: from [66.218.66.86] by t3.bullet.scd.yahoo.com with NNFMP; 29 Apr 2007 20:46:33 -0000\r\nDate: Sun, 29 Apr 2007 20:46:32 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f13078+l3b8@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: A Few Thoughts on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=T5nPG75_3zF6mUyvLfk49l1YT_K0XKYL6vhaYdqhR703yQPBvaLN\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nThe recent discussion between Andy and Stephen has raised a few \ninterestin=\r\ng issues.  One is the possibility of having additional \ntypes of activation=\r\n functions in the CPPN, which could be useful if \ndone right.  The other is=\r\n the potential for evolving the substrate \nconfiguration (i.e. node placeme=\r\nnt) and with that how hidden nodes \nfigure into the picture.  I mostly want=\r\n to comment on the latter \nissue to give you my perspective.\n\nAs Jason just=\r\n mentioned, certainly we do envision evolving substrates \nwith hidden nodes=\r\n and have already had success evolving multilayer \nsubstrates in preliminar=\r\ny experiments.  Hopefully our initial \npublications do not leave the impres=\r\nsion that HyperNEAT is intended \nonly to evolve substrates connecting input=\r\ns to outputs directly.  Of \ncourse we started there as a way to prove the c=\r\noncept, but the \napproach is intended to go a lot farther.\n\nNote that Hyper=\r\nNEAT does evolve the topology (i.e. connectivity) of \nthe substrate.  What =\r\nHyperNEAT does not evolve, as has been \ndiscussed, is the node layout/confi=\r\nguration, that is, where the nodes \nare on the substrate.  Interestingly, t=\r\nhis issue does not even exist \nin regular NEAT because there is no concept =\r\nof &quot;location&quot; in a \nCartesian sense in regualar neuroevolution algorithms. =\r\n HyperNEAT \nalso does not evolve the maximum number of nodes (something tha=\r\nt \noriginal NEAT does not worry about).  At present, if a problem needed \nm=\r\nore nodes than the maximum in the substrate, the user would need to \nincrea=\r\nse node density on the substrate, which is a decision that a \nuser of origi=\r\nnal NEAT would not encounter.\n\nThus, while we have not yet run experiments =\r\nwherein the substrate \nnode layout/density evolves, as has been suggested, =\r\nit would be \ninteresting to explore automated ways to lay out or increase t=\r\nhe \ndensity of nodes.  So I do think that&#39;s a good direction.\n\nHowever, not=\r\ne that the problems for which HyperNEAT is designed are \nsignificantly larg=\r\ner (in terms of input/output dimensionality) and \nmore patterned than those=\r\n tackled by regular NEAT.  Therefore, simply \nbeing able to evolve anything=\r\n at all that handles such problems is an \nadvance.  Thus, while HyperNEAT c=\r\nurrently does require a certain a \npriori user decision where NEAT does not=\r\n, NEAT would usually have \nlittle hope of solving such a problem anyway.  \n=\r\n\nIn any case, this distinction in user involvement does illuminate the \nfac=\r\nt that HyperNEAT is not going to be a better approach for all \npossible pro=\r\nblems.  Problems with small input/output dimensionality \n(such as pole bala=\r\nncing), very little regularity, or few geometric \nrelationships are still b=\r\nest tackled by regular NEAT.  However, new \nkinds of problems for which NEA=\r\nT is less reliable now become \napproachable.  So it&#39;s important to pick the=\r\n right approach for the \nright problem.\n\nIn a larger context, it&#39;s evident =\r\nat this point in time that NEAT \nwill never be able to scale up to brain-si=\r\nzed ANNs (i.e. with \nmillions or more connections) one connection at a time=\r\n.  Therefore, \nif we ever want such structures to evolve, something like Hy=\r\nperNEAT \nis going to be necessary.  While it may sacrifice some of the blac=\r\nk-\nbox convenience of NEAT, it makes up for it with the ability to \nexploit=\r\n large-scale regularities that is going to be necessary as we \nscale to new=\r\n complexity levels.  \n\nWhile it may be viewed as a weakness that the user m=\r\nust decide the \nnode layout, my view is that it is actually quite a bonus, =\r\nbecause it \nmeans we have an opportuntiy to inject intuitive relationships =\r\ninto \nthe learning process from the get-go.  The most interesting \nconseque=\r\nnce of this ability is that HyperNEAT is not subject to the \nNo Free Lunch =\r\ntheorem when comparing to algorithms that do not allow \ninjecting such a pr=\r\niori knowledge, which justifies the expectation \nthat HyperNEAT actually ma=\r\ny be &quot;better&quot; for evolving very-large-scale \nbrains.  \n\nNo Free Lunch is a =\r\ntheorem showing that no single black-box search \nmethod can be better than =\r\nany other when averaged over all possible \nproblems.  However, HyperNEAT es=\r\ncapes this trap because it is no \nlonger a black box algorithm, thanks to t=\r\nhe ability to inject a \npriori relationships at the start.  In many cases t=\r\nhis a priori \nknowledge is very simple to include because it follows direct=\r\nly from \nthe obvious geometry of the task (such as a visual field or game \n=\r\nboard being Cartesian in an self-evident arrangement).  Yet the \nsignifican=\r\nce of such knowledge (as opposed to not having it) is \npriceless.  So havin=\r\ng the capacity to arrange sensors and outputs in \nthe way you want is quite=\r\n a powerful new capability.\n\nken\n\n\n\n"}}