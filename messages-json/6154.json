{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"Rmgb5JjXC3hDITirDzEx1QMImKVyYjzDDKOZDqzukeFjISZH226Kry06d3QSikj7hgUnDRCytBq1dsjGfBwEAvVp5D1-","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: GECCO Paper on HyperNEAT","postDate":"1371524476","msgId":6154,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtwb2locytsdjd1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtwbXRlYitlcWd2QGVHcm91cHMuY29tPg=="},"prevInTopic":6153,"nextInTopic":6156,"prevInTime":6153,"nextInTime":6155,"topicId":6085,"numMessagesInTopic":14,"msgSnippet":"Hi Shimon, The nice thing about this type of conversation is that it pushes us towards realizing our fundamental assumptions.  In that spirit, a few other","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 67729 invoked by uid 102); 18 Jun 2013 03:01:17 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m12.grp.bf1.yahoo.com with SMTP; 18 Jun 2013 03:01:17 -0000\r\nX-Received: (qmail 8360 invoked from network); 18 Jun 2013 03:01:17 -0000\r\nX-Received: from unknown (HELO ng12-vm0.bullet.mail.bf1.yahoo.com) (98.139.164.54)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 18 Jun 2013 03:01:17 -0000\r\nX-Received: from [98.139.164.121] by ng12.bullet.mail.bf1.yahoo.com with NNFMP; 18 Jun 2013 03:01:17 -0000\r\nX-Received: from [10.193.94.110] by tg2.bullet.mail.bf1.yahoo.com with NNFMP; 18 Jun 2013 03:01:17 -0000\r\nDate: Tue, 18 Jun 2013 03:01:16 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kpoihs+lv7u@...&gt;\r\nIn-Reply-To: &lt;kpmteb+eqgv@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;1-0999311798-9958642861=:2&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: GECCO Paper on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=wMfvyKJqL1WtHdffy3Sfllw_rFxEBmoT6zAGr1cEPyMBxiibeiqo\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\r\n--1-0999311798-9958642861=:2\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Shimon,\n\nThe nice thing about this type of conversation is that it pushe=\r\ns us\ntowards realizing our fundamental assumptions.  In that spirit, a few\n=\r\nother thoughts in response:\n\nMany top biologists and EC researchers would c=\r\nall the behavior of the\norganism in the world (i.e. its interactions with t=\r\nhe world) the\n&quot;phenotype.&quot;  David Fogel once sent me a long and forceful de=\r\nfense of\nsuch a position, quoting a number of famous biologists.  In that\nc=\r\nontext, whether you map CPPN-&gt;pattern or CPPN-&gt;behavior, a target is\nstill =\r\na target and the neural network is not the phenotype.\n\nIn any case, I guess=\r\n we both hold bold hypotheses in some sense.  Your\nhypothesis that there ex=\r\nist methods that can solve hard FFs almost\ndeterministically as targets (up=\r\n to and even beyond delivering us an\nEinstein-level brain) seems boldly opt=\r\nimistic to me.  But the big\ndifference between our hypotheses is that you h=\r\nave no proof of concept\nfor your approach while I do.  In your approach, yo=\r\nu will set a target\nof Einstein and almost magically the algorithm will the=\r\nn deliver us\nEinstein, which no method has yet shown even the faintest sign=\r\n of\nachieving.  In my approach, Einstein is not the target of the search\npr=\r\nocess but instead  appears as a byproduct of a search without any\nexplicit =\r\ntarget, which is (amazingly) actually what happened in the real\nworld!  It =\r\nmay be tempting to dismiss that distinction, but think about\nit, the fact t=\r\nhat any process actually *did* produce Einstein is beyond\nincredible.  We s=\r\nhould learn from that as much as we can before\ninsisting &quot;there&#39;s got to be=\r\n a better way.&quot;\n\nOf course, it&#39;s great that you&#39;re searching for a better w=\r\nay (it sure\nwould be nice if we could just set Einstein&#39;s IQ as a fitness t=\r\narget),\nbut the things is, there will always be a ton of people trying to f=\r\nollow\nthat path because it&#39;s such a clean and intuitively appealing notion.=\r\n \nSo it hardly needs a vigorous argument to convince someone that it&#39;s\nimpo=\r\nrtant to try.  The danger is instead  that in such a rush of\nenthusiasm for=\r\n intuitively appealing approaches, we sweep aside the much\nmore delicate ye=\r\nt equally critical attempt to harness evolution on its\nown terms, which lea=\r\nds to things like novelty search, indirect encoding,\nand behavioral diversi=\r\nty.  The power of this process may not be as clean\nand simple  as the optim=\r\nization crowd is hoping; my argument here guards\nagainst that danger.\n\nI th=\r\nink something similar is going on in our fracture argument: In\nPicbreeder (=\r\nand to some extent Endlessforms too, which also uses CPPNs)\nwe have perhaps=\r\n the only massive proof-of-concept that exists of\nfracture evolving through=\r\n an artificial encoding.  Picbreeder is a\ntreasure trove of almost 10,000 e=\r\nxamples, each one with its own lesson\nto teach us on fracture.  And my argu=\r\nment is, since we are fortunate\nenough to have this example right in front =\r\nof us (like the example of\nnatural evolution evolving Einstein), let&#39;s lear=\r\nn everything we can from\nit before looking away and saying hastily, &quot;there =\r\nmust be something\nbetter.&quot;  Picbreeder is a fortuitous goldmine of data tha=\r\nt is very hard\nto  reproduce; it took several years and the contributions o=\r\nf hundreds\nof  people to accumulate its results.  Let&#39;s scrub every last bi=\r\nt of\nwisdom  from that windfall that we can.  It&#39;s not a question of better=\r\n\nfor me, it&#39;s a question of learning from the only evidence we have.  How\nd=\r\no you expect to really develop a better encoding of fracture if you\nignore =\r\nthe thousands of examples of fracture that already exist?  You\nwill just en=\r\nd up reinventing the wheel.\n\nThe danger of that is evident in some of the a=\r\nssumptions you hold\nalready about how CPPNs encode fracture.  For example, =\r\nyou are worried\nthat it may not do so efficiently, but you have only constr=\r\nucted a\nsingle thought experiment (your figure 13) instead of taking a meas=\r\nured\nlook at the thousands of examples in front of us.  In fact, while inde=\r\ned\nI don&#39;t think 6 nodes is particularly much, it&#39;s easy enough to find\nfra=\r\ncture in Picbreeder represented in under 6 nodes.  For example, the\npattern=\r\n below has at least 3 distinct fractured regions (which I\nnumbered for clar=\r\nity): a pinkish region, an ovular inner region, and a\nconic lower region.  =\r\nHowever, the CPPN that encodes it (shown to its\nleft) only uses 4 nodes to =\r\nencode these 3 fractured regions (notice that\ntwo of the displayed hidden n=\r\nodes have outgoing weights of zero, so they\nare not contributing to the out=\r\nput pattern, leaving only the 4 nodes). \nThat&#39;s a respectable 1.3 nodes per=\r\n fractured region:\n\n(this image is also available at\nhttp://eplex.cs.ucf.ed=\r\nu/hyperNEATpage/content/four-node-fracture.jpg\n&lt;http://eplex.cs.ucf.edu/hyp=\r\nerNEATpage/content/four-node-fracture.jpg&gt; \n)\n\n\n\n\nWe could argue about the =\r\ndefinition of fracture, and perhaps you&#39;d want\nto refine the definition to =\r\nargue that the above example doesn&#39;t really\nhave three fractured regions.  =\r\nOr you could argue that the &quot;d&quot; input\nshould be counted as a 5th node (to e=\r\nncode the 3 regions, which is still\na respectable 1.7 nodes per region).  B=\r\nut even those would be healthy\ndiscussions that we could not begin to have =\r\nwithout first referring to\nthe examples that we already have.  Of course (i=\r\nntuitively) more complex\nfracture will require more nodes (maybe at some po=\r\nint 6!), as it should.\nAll I&#39;m saying is I think this kind of speculation a=\r\nbout whether it&#39;s\nefficient or not is jumping the gun:  Let&#39;s understand it=\r\n first before\nwe worry about fixing it.\n\nSo I think there&#39;s a difference of=\r\n philosophies ultimately at work here.\nBecause the road ahead to AI is so v=\r\nast, I&#39;m more motivated by\nmaximizing our information than doing &quot;better.&quot; =\r\n For example, that&#39;s the\nmotivation behind Picbreeder - obviously it is not=\r\n quantifiably better\nthan anything in particular, but it increased our unde=\r\nrstanding of a\nnumber of important phenomena, including fracture, represent=\r\nation, and\nnon-objective search, by providing useful information.  So I say=\r\n, let&#39;s\nsee where this takes us - there&#39;s still a ton left to learn.  But y=\r\nou\nare already itching to start anew and fix things that are not clearly\nbr=\r\noken just when we have hit a goldmine of untapped information.\n\nWithout que=\r\nstion, neither of our perspectives is definitively superior;\nwe are both me=\r\nrely speculating about where time is best invested, and\nobviously neither o=\r\nf us can predict the future.  This argument is only\nmy own case for my pers=\r\npective.\n\nBest,\n\nken\n\n\n--- In neat@yahoogroups.com, &quot;shimonw&quot;  wrote:\n&gt;\n&gt; H=\r\ni Ken,\n&gt;\n&gt; If I may, I&#39;d like to offer a couple reactions to your latest me=\r\nssage.\nThis is indeed an interesting discussion that touches on many\npotent=\r\nially important issues.  I hope I can offer a useful perspective\non these t=\r\nopics.\n&gt;\n&gt; You are right that in a target-based scenario there can be many =\r\nCPPNs\nthat generate the same phenotype.  But the CPPN is a genotype, not a\n=\r\nphenotype. In what I&#39;m calling &quot;regular&quot; FFs, there are potentially many\n*p=\r\nhenotypes* that solve the problem, and for each of them potentially\nmany ge=\r\nnotypes.  So in my mind, there is still a useful distinction\nbetween target=\r\n based FFs and regular FFs, though they are perhaps best\nseen as different =\r\npoints on a spectrum.\n&gt;\n&gt; If I understand correctly, you are suggesting tha=\r\nt the important\ndistinction is how the FF interacts with the search process=\r\n.  But to me,\nthis is a difficult criterion to use because the search proce=\r\nss could be\nanything.  The space of possible black-box optimization methods=\r\n is huge,\nand what encourages piecewise incremental progress for one method=\r\n may\nnot for another.\n&gt;\n&gt; I don&#39;t pretend to know what kind of algorithm wo=\r\nuld generate\nEinstein-level intelligence (I don&#39;t even know if this is a us=\r\neful\ngoal). But as a researcher I highly respect once told me, &quot;your failur=\r\ne\nto imagine it does not constitute a proof that it cannot be done.&quot;\n&gt;\n&gt; Th=\r\nat&#39;s why I think your hypothesis is quite a bold one, because it\nlooks at t=\r\nhe limitations of a specific class of black-box optimization\nmethods and ge=\r\nneralizes them to all possible black-box optimization\nmethods.\n&gt;\n&gt; To give =\r\njust one example of the possibilities here: algorithms for\ncontinuous-armed=\r\n bandits, such as X-armed bandits and Bayesian\noptimization methods such as=\r\n GP-UCB, can be applied to black-box\noptimization.  These methods avoid the=\r\n problem of local optima in a\nprincipled way, by maintaining a posterior di=\r\nstribution over the global\nFF, and using optimism in the face of uncertaint=\r\ny to ensure sufficient\nexploration of the solution space.  As a result, the=\r\nse methods have very\nnice theoretical properties, like guaranteed convergen=\r\nce to the global\noptimum in the limit and logarithmic regret bounds along t=\r\nhe way.\n&gt;\n&gt; As far as I know, no one has tried to develop versions of these=\r\n\nmethods that can discover NN topologies, and which would thus be\nsuitable =\r\nfor optimizing CPPNs or other indirect encodings.  But there&#39;s\nno a priori =\r\nreason to think it can&#39;t be done.  I&#39;m not saying this would\nnecessarily wo=\r\nrk or even that it&#39;s the most promising approach to\nexplore.  I&#39;m just sayi=\r\nng it&#39;s one example of a principled approach that\ncould avoid all the diffi=\r\nculties you mention and which we currently have\nno strong reason to elimina=\r\nte from contention.\n&gt;\n&gt; So I think it&#39;s quite likely that these hard FFs ar=\r\ne not unsolvable,\nbut just that current methods cannot solve them.  Rather =\r\nthan giving up\non them, in my opinion we should be focusing on developing b=\r\netter\nmethods for them.\n&gt;\n&gt; Regarding whether 6 nodes is a lot to represent=\r\n fracture, I think the\nsame point applies: just because we can&#39;t think of a=\r\n better way to do\nit, doesn&#39;t mean it doesn&#39;t exist.  Our paper establishes=\r\n 6 as an upper\nbound, which can be easily done by example.  If I understand=\r\n correctly,\nyou are suggesting that 6 may be a lower bound, which is much m=\r\nore\ndifficult to demonstrate.\n&gt;\n&gt; I could definitely imagine that a differe=\r\nnt type of network, or one\nwith a different set of activation functions, mi=\r\nght be able to make\nbetter use of 6 nodes.  Even if it&#39;s true that there&#39;s =\r\na trade-off, and\nusing fewer nodes means less flexibility, there may be man=\r\ny cases where\nthat&#39;s a favorable trade-off.  We should at least be open to =\r\nthe\npossibility that it some cases the sweet spot is not a representation\nt=\r\nhat requires 6 nodes for fracture.\n&gt;\n&gt; I&#39;m looking forward to chatting more=\r\n about this at GECCO.\n&gt;\n&gt; Cheers,\n&gt; Shimon\n&gt;\n&gt; --- In neat@yahoogroups.com,=\r\n &quot;Ken&quot; kstanley@ wrote:\n&gt; &gt;\n&gt; &gt; Hi Shimon,\n&gt; &gt;\n&gt; &gt; These are some really in=\r\nteresting and deep issues we&#39;re getting\ninto.  I\n&gt; &gt; am sure they will be t=\r\nhe foundation of great discussions at GECCO. \nI&#39;ll\n&gt; &gt; try to keep my respo=\r\nnse more brief than before.\n&gt; &gt;\n&gt; &gt; 1) Indeed recent quadruped results are =\r\nnot in the same setup as in\nyour\n&gt; &gt; work; that is a legitimate qualificati=\r\non and they do not constitute\na\n&gt; &gt; proof that in your particular setup Hyp=\r\nerNEAT would succeed. \nHowever,\n&gt; &gt; they are arguably at least comparably c=\r\nomplex.  For example, the\nCTRNN\n&gt; &gt; in\n&gt; &gt; http://eplex.cs.ucf.edu/papers/r=\r\nisi_gecco13b.pdf\n&gt; &gt;    is a complicated\n&gt; &gt; structure and the CPPN that en=\r\ncodes it is required not only to\ngenerate\n&gt; &gt; a controller for a single qua=\r\ndruped morphology, but to generate\nmultiple\n&gt; &gt; controllers for multiple mo=\r\nrphologies, all from the same CPPN.  A\nvideo\n&gt; &gt; of three controllers all f=\r\nrom the same CPPN is here:\n&gt; &gt; http://youtu.be/oLSSt5GyHNk\n&gt; &gt;\n&gt; &gt; 2) I thi=\r\nnk the question of what is &quot;target-based&quot; can actually be\n&gt; &gt; interesting, =\r\nbut I completely agree that the semantic side of the\n&gt; &gt; argument isn&#39;t rea=\r\nlly important.  But what I do find interesting is\nthe\n&gt; &gt; idea that these t=\r\nwo scenarios differ substantively in your mind (as\nyou\n&gt; &gt; put it):\n&gt; &gt;\n&gt; &gt;=\r\n &quot;there is an important difference between FFs that require a single\n&gt; &gt; sp=\r\necific phenotype and FFs that require only that some goal be\nachieved&quot;\n&gt; &gt;\n=\r\n&gt; &gt; I think by &quot;single specific phenotype&quot; you mean pattern-matching\n(i.e.\n=\r\n&gt; &gt; image-matching).  But I think this distinction doesn&#39;t really exist:\n&gt; =\r\n&gt; There are an unlimited number of networks (i.e. CPPNs) that can\nencode a\n=\r\n&gt; &gt; particular two-dimensional image, just as there are an unlimited\nnumber=\r\n\n&gt; &gt; of CPPNs that can encode a particular behavior or goal (such as\n&gt; &gt; fo=\r\nllowing a line).\n&gt; &gt;\n&gt; &gt; What makes both target-based and fundamentally the=\r\n same is not the\n&gt; &gt; number of ways they can be solved, but rather the way =\r\nthe fitness\n&gt; &gt; function interacts with the search process.  The problem is=\r\n that\n&gt; &gt; target-based fitness encourages piece-wise incremental progress,\n=\r\nwhich\n&gt; &gt; tends to be highly deceptive.  For example, with an image, matchi=\r\nng\na\n&gt; &gt; single pixel can raise fitness even if the function that causes th=\r\nat\n&gt; &gt; pixel to be matched has no relationship whatsoever to the overall\n&gt; =\r\n&gt; regularities in the target pattern.  The same is true in control\ntasks:\n&gt;=\r\n &gt; A mutation that causes a quadruped to lunge forward clumsily is\nrewarded=\r\n\n&gt; &gt; for the slight improvement in fitness, whereas an important\nunderlying=\r\n\n&gt; &gt; regularity (e.g. oscillation) necessary to get really good at the\ntask=\r\n\n&gt; &gt; is never established.  Non-target-based fitness (or what I call\n&gt; &gt; &quot;n=\r\non-objective&quot;) avoids these problems because it *does* reward\n&gt; &gt; establish=\r\ning regularities: it appreciates new regularities even if\nthey\n&gt; &gt; don&#39;t im=\r\nmediately raise fitness.\n&gt; &gt;\n&gt; &gt; But what&#39;s most interesting to me is your =\r\nintuition that there is\nsome\n&gt; &gt; way to sidestep the tradeoff in combining =\r\nindirect encodings with\n&gt; &gt; target-based fitness functions.  That is, you s=\r\nuspect there may\nexist an\n&gt; &gt; indirect encoding that can both elaborate reg=\r\nularities\ncompositionally\n&gt; &gt; over very many generations and also almost de=\r\nterministically satisfy\nan\n&gt; &gt; arbitrary target-based objective.  I am conv=\r\ninced that is not the\ncase\n&gt; &gt; (it would be too good to be true), but you r=\r\nightly point out that my\n&gt; &gt; position is a hypothesis.   However, just as a=\r\n thought experiment,\ncan\n&gt; &gt; you really imagine any neural network encoding=\r\n (including DNA) that\n&gt; &gt; would give you Einstein-level intelligence if the=\r\n target was simply\nto\n&gt; &gt; score maximally on an IQ test?  It is plain to me=\r\n that the stepping\n&gt; &gt; stones to human level cannot be crossed in the prese=\r\nnce of a\n&gt; &gt; target-based objective (or any one conceivable).  However,\n&gt; &gt;=\r\n interestingly, that does not mean that such a neural network does\nnot\n&gt; &gt; =\r\nexist in the search space.  It just means a target won&#39;t get you\nthere.\n&gt; &gt;=\r\n\n&gt; &gt; 3) We apparently disagree on whether 6 is a big number (for nodes\nneed=\r\ned\n&gt; &gt; to represent fracture).  If you try to devise an encoding that\n&gt; &gt; r=\r\nepresents fracture with fewer than that, my intuition is that you\nwould\n&gt; &gt;=\r\n be sacrificing an enormous breadth of flexibility in the kinds of\n&gt; &gt; frac=\r\nture (and patterns in general) that you can represent.  Think\nabout\n&gt; &gt; the=\r\n number of &quot;degrees of freedom&quot; in fracture: it&#39;s not really\n&gt; &gt; well-defin=\r\ned, but a single line of fracture has a lot of dimensions:\n&gt; &gt;\n&gt; &gt; -positio=\r\nn\n&gt; &gt; -orientation\n&gt; &gt; -curvature (which can be arbitrarily complex)\n&gt; &gt; -f=\r\nracture gradient (that is, one region can smoothly transition into\n&gt; &gt; anot=\r\nher in a kind of interpolated transitional zone)\n&gt; &gt; -embedding (fracture c=\r\nan potentially be hierarchical or regular,\ni.e.\n&gt; &gt; dependent on higher-lev=\r\nel containing regions)\n&gt; &gt;\n&gt; &gt; The idea that all of that can be encoded in =\r\nanything less than about\n6\n&gt; &gt; simple functions seems optimistic.  Of cours=\r\ne, if you are willing to\n&gt; &gt; sacrifice some of those degrees of freedom, th=\r\nen you can get fewer\n&gt; &gt; nodes, but the exquisite minutia of such patterns =\r\nwould be lost (and\n&gt; &gt; you&#39;d move more towards direct encoding, like the wa=\r\nvelets do).\n&gt; &gt;\n&gt; &gt; By the way, here are some cool examples of complicated =\r\nkinds of\nfracture\n&gt; &gt; from Picbreeder (such as fractured periodic zones, bu=\r\nt even more\ncomplex\n&gt; &gt; than even that):\n&gt; &gt;\n&gt; &gt; Nontrivial color patterns =\r\nin each zone:\n&gt; &gt; http://picbreeder.org/search/showgenome.php?sid=3D11328\n&gt;=\r\n &gt;\n&gt; &gt;\n&gt; &gt; Very complex brush-stroke pattern inside the apple vs. outside (=\r\nthe\nDNA\n&gt; &gt; for this one is fascinating):\n&gt; &gt; http://picbreeder.org/search/=\r\nshowgenome.php?sid=3D7109\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Fractured regions covering a dist=\r\norted surface, giving a remarkable\n&gt; &gt; underlying curvature:\n&gt; &gt; http://pic=\r\nbreeder.org/search/showgenome.php?sid=3D2684\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; A color variant:\nh=\r\nttp://picbreeder.org/search/showgenome.php?sid=3D6652\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; When I se=\r\ne so many remarkable examples like these on Picbreeder, the\n&gt; &gt; message to =\r\nme is that we have only scratched the surface of what\nCPPN\n&gt; &gt; encoding can=\r\n teach us about representation.  That&#39;s why I think it&#39;s\n&gt; &gt; premature (in =\r\nthe face of such a treasure trove of evidence) to be\n&gt; &gt; worrying about whe=\r\nther we can represent some subcomponent of such\n&gt; &gt; patterns with less than=\r\n 6 nodes.  At present I&#39;m amazed they can be\n&gt; &gt; represented at all, let al=\r\none with under 6 nodes.\n&gt; &gt;\n&gt; &gt; Thanks very much for raising these issues i=\r\nn any case - it&#39;s a great\n&gt; &gt; debate to have about representation and searc=\r\nh and goes to the heart\nof\n&gt; &gt; the field of GDS/indirect encoding.\n&gt; &gt;\n&gt; &gt; =\r\nBest,\n&gt; &gt;\n&gt; &gt; ken\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com, &quot;shimonw&quot;  wrote:\n&gt; =\r\n&gt; &gt;\n&gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt;\n&gt; &gt; &gt; Thanks for your interesting and thought-provo=\r\nking comments.  I&#39;ll\ngive\n&gt; &gt; some brief reactions here, and I hope we can =\r\nhave a productive\n&gt; &gt; discussion about it at GECCO.\n&gt; &gt; &gt;\n&gt; &gt; &gt; 1) I won&#39;t =\r\ncomment for now on the new experiments you&#39;ve been\nrunning\n&gt; &gt; because the =\r\ndetails are not available yet.  Instead, I will just\ncomment\n&gt; &gt; on the var=\r\nious walking gait domains, because the details of the\n&gt; &gt; additional result=\r\ns you mentioned are in that case already available,\nin\n&gt; &gt; newly published =\r\nGECCO papers.\n&gt; &gt; &gt;\n&gt; &gt; &gt; FIrst of all, these are very cool results, and ni=\r\nce success\nstories\n&gt; &gt; for HyperNEAT.  It&#39;s great to see that the GDS commu=\r\nnity is\ncontinuing\n&gt; &gt; the push the envelope in terms of robot locomotion, =\r\nwhich seems to\nbe\n&gt; &gt; emerging as a nice application for indirect encodings=\r\n.\n&gt; &gt; &gt;\n&gt; &gt; &gt; However, I would simply caution against placing all these\nvar=\r\niations\n&gt; &gt; on the walking gait task on a one-dimensional spectrum of\ndiffi=\r\nculty.\n&gt; &gt; In our paper, we took the orignal walking gait task and made onl=\r\ny\none\n&gt; &gt; change (increasing the mass of the torso) which clearly makes the=\r\n\ntask\n&gt; &gt; harder.  In the papers Ken mentioned, there are other differences=\r\n,\ne.g.,\n&gt; &gt; the use of an SUPG encoding, the use of CTRNNs, the use of a\ndi=\r\nfferent\n&gt; &gt; substrate topology, and varying the length of the legs.\n&gt; &gt; &gt;\n&gt;=\r\n &gt; &gt; It&#39;s completely legitimate to make these changes and they don&#39;t\n&gt; &gt; de=\r\ntract from the results at all.   But they are confounding factors\nwhen\n&gt; &gt; =\r\nit comes to comparing HyperNEAT&#39;s performance on walking gait tasks\nof\n&gt; &gt; =\r\ndifferent difficulties.  Some of these changes may make the task\nharder\n&gt; &gt;=\r\n in some ways but other changes may make it easier in others ways,\nand so\n&gt;=\r\n &gt; far we don&#39;t have experimental results that control for these\nfactors.\n&gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; 2) I hope to avoid a semantic debate about what is a\n&quot;target-bas=\r\ned&quot;\n&gt; &gt; FF.  If you want to include what I was calling a &quot;regular&quot; FF in th=\r\ne\n&gt; &gt; scope of target-based FFs, I won&#39;t object.  But my point is that,\n&gt; &gt;=\r\n regardless of what you call them, there is an important difference\n&gt; &gt; bet=\r\nween FFs that require a single specific phenotype and FFs that\n&gt; &gt; require =\r\nonly that some goal be achieved.  For the latter, there may\nbe\n&gt; &gt; many way=\r\ns to skin the cat, though in any interesting problem, good\n&gt; &gt; solutions ar=\r\ne still quite rare.  The distinction is important\nbecause,\n&gt; &gt; while the fo=\r\nrmer category is arguably only of theoretical interest,\nthe\n&gt; &gt; second cate=\r\ngory corresponds to what I consider the most interesting\nand\n&gt; &gt; important =\r\nclass of FFs, because these are the FFs that naturally\narise\n&gt; &gt; in a very =\r\nlarge number of real-world optimization problems.\n&gt; &gt; &gt;\n&gt; &gt; &gt; So, using you=\r\nr terminology, I agree it is reasonable to say\n&gt; &gt; HyperNEAT&#39;s difficulties=\r\n with fracture are probably limited to\n&gt; &gt; &quot;target-based&quot; FFs.  But for me,=\r\n this is a potentially serious\n&gt; &gt; restriction, since target-based FFs incl=\r\nude not just pathological\nFFs\n&gt; &gt; but a large class of real-world FFs.\n&gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; Regarding the wavelet method, I would still definitely call this\nan=\r\n\n&gt; &gt; indirect encoding, but it is in some sense &quot;less indirect&quot; because\nit\n=\r\n&gt; &gt; lacks the compositional functions of HyperNEAT. It&#39;s a perfectly\n&gt; &gt; re=\r\nasonable hypothesis that such compositionality is advantageous in\nsome\n&gt; &gt; =\r\nways.  However, if that&#39;s true, then we should be able to\ndemonstrate\n&gt; &gt; t=\r\nhat by finding tasks where HyperNEAT outperforms the wavelet method\n&gt; &gt; (FY=\r\nI, in the extended analysis Thomas is conducting for his master&#39;s\n&gt; &gt; thesi=\r\ns, we have found one variation of the line-following task where\n&gt; &gt; this is=\r\n the case).  So in that sense, the wavelet method is a useful\n&gt; &gt; baseline,=\r\n which is the whole reason we introduced it.\n&gt; &gt; &gt;\n&gt; &gt; &gt; 3) If it&#39;s true th=\r\nat it takes ~6 nodes to represent fracture, then\nI\n&gt; &gt; think this a potenti=\r\nally important point.  On regular FFs, it could\n&gt; &gt; contribute to the diffi=\r\nculty of discovering fracture, since\n&gt; &gt; representations that have only som=\r\ne of the necessary components may\nnot\n&gt; &gt; be rewarded (I think you would ca=\r\nll this &quot;deception&quot;).  In\n&gt; &gt; Picbreeder-like tasks, we already see that fr=\r\nacture can evolve\nanyway,\n&gt; &gt; but this doesn&#39;t mean it wouldn&#39;t do it even =\r\nbetter if fracture\nrequired\n&gt; &gt; fewer nodes to represent.  If we think that=\r\n the solutions to many\n&gt; &gt; interesting problems require fracture, then I th=\r\nink it&#39;s at least\n&gt; &gt; possible that one could devise a better representatio=\r\nn for such\nproblems\n&gt; &gt; than the CPPNs used in HyperNEAT.\n&gt; &gt; &gt;\n&gt; &gt; &gt; As I =\r\nunderstand it, your approach to dealing with &quot;regular&quot; FFs is\nto\n&gt; &gt; reform=\r\nulate them &quot;in a way that respects the need for phenotypic\n&gt; &gt; diversity an=\r\nd open-endedness.&quot;  That&#39;s a very interesting approach\nand I\n&gt; &gt; think it h=\r\nas a lot of merit, but I don&#39;t think it will solve all our\n&gt; &gt; problems bec=\r\nause it presupposes that such a reformulation is\npossible\n&gt; &gt; (or that the =\r\nprior knowledge it requires is available).  In some\ncases,\n&gt; &gt; I think we a=\r\nre just stuck with hard FFs and we need to develop\nbetter\n&gt; &gt; methods to de=\r\nal with them.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Regarding the idea that &quot;an unhappy and unhealthy=\r\n indirect\nencoding is\n&gt; &gt; one with only a strict target to which to aspire&quot;=\r\n: this is a very\n&gt; &gt; intriguing hypothesis, but to me it is only a hypothes=\r\nis.  I think\nit&#39;s\n&gt; &gt; true of existing indirect encodings, but that for me =\r\ndoes not in any\nway\n&gt; &gt; rule out the possibility of developing a different =\r\nindirect encoding\nfor\n&gt; &gt; which that is not true, and I think that&#39;s one th=\r\ning we should be\n&gt; &gt; working on.   One of the reasons that I&#39;m interested i=\r\nn indirect\n&gt; &gt; encodings is that I strongly believe this can be done.\n&gt; &gt; &gt;=\r\n\n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; Shimon\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\r\n--1-0999311798-9958642861=:2\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n\n\n\nHi Shimon,&lt;br&gt;&lt;br&gt;The nice thing about this type of conversation is that=\r\n it pushes us towards realizing our fundamental assumptions.&nbsp; In that =\r\nspirit, a few other thoughts in response:&lt;br&gt;&lt;br&gt;Many top biologists and EC=\r\n researchers would call the behavior of the organism in the world (i.e. its=\r\n interactions with the world) the &quot;phenotype.&quot;&nbsp; David Fogel =\r\nonce sent me a long and forceful defense of such a position, quoting a numb=\r\ner of famous biologists.&nbsp; In that context, whether you map CPPN-&gt;pa=\r\nttern or CPPN-&gt;behavior, a target is still a target and the neural netwo=\r\nrk is not the phenotype.&lt;br&gt;&lt;br&gt;In any case, I guess we both hold bold hypo=\r\ntheses in some sense.&nbsp; Your hypothesis that there exist methods that c=\r\nan solve hard FFs almost deterministically as targets (up to and even beyon=\r\nd delivering us an Einstein-level brain) seems boldly optimistic to me.&nbs=\r\np; But the big difference between our hypotheses is that you have no proof =\r\nof concept for your approach while I do.&nbsp; In your approach, you will s=\r\net a target of Einstein and almost magically the algorithm will then delive=\r\nr us Einstein, which no method has yet shown even the faintest sign of achi=\r\neving.&nbsp; In my approach, Einstein is not the target of the search proce=\r\nss but instead&nbsp; appears as a byproduct of a search without any explici=\r\nt target, which is (amazingly) actually what happened in the real world!&nb=\r\nsp; It may be tempting to dismiss that distinction, but think about it, the=\r\n fact that any process actually *did* produce Einstein is beyond incredible=\r\n.&nbsp; We should learn from that as much as we can before insisting &quot;=\r\nthere&#39;s got to be a better way.&quot;&nbsp; &lt;br&gt;&lt;br&gt;Of course, it&#39;s great t=\r\nhat you&#39;re searching for a better way (it sure would be nice if we could ju=\r\nst set Einstein&#39;s IQ as a fitness target), but the things is, there will al=\r\nways be a ton of people trying to follow that path because it&#39;s such a clea=\r\nn and intuitively appealing notion.&nbsp; So it hardly needs a vigorous arg=\r\nument to convince someone that it&#39;s important to try.&nbsp; The danger is i=\r\nnstead&nbsp; that in such a rush of enthusiasm for intuitively appealing ap=\r\nproaches, we sweep aside the much more delicate yet equally critical attemp=\r\nt to harness evolution on its own terms, which leads to things like novelty=\r\n search, indirect encoding, and behavioral diversity.&nbsp; The power of th=\r\nis process may not be as clean and simple&nbsp; as the optimization crowd i=\r\ns hoping; my argument here guards against that danger.&lt;br&gt;&lt;br&gt;I think somet=\r\nhing similar is going on in our fracture argument: In Picbreeder (and to so=\r\nme extent Endlessforms too, which also uses CPPNs) we have perhaps the only=\r\n massive proof-of-concept that exists of fracture evolving through an artif=\r\nicial encoding.&nbsp; Picbreeder is a treasure trove of almost 10,000 examp=\r\nles, each one with its own lesson to teach us on fracture.&nbsp; And my arg=\r\nument is, since we are fortunate enough to have this example right in front=\r\n of us (like the example of natural evolution evolving Einstein), let&#39;s lea=\r\nrn everything we can from it before looking away and saying hastily, &quot;=\r\nthere must be something better.&quot;&nbsp; Picbreeder is a fortuitous gold=\r\nmine of data that is very hard to \nreproduce; it took several years and the=\r\n contributions of hundreds of \npeople to accumulate its results.&nbsp; Let&#39;=\r\ns scrub every last bit of wisdom \nfrom that windfall that we can.&nbsp; It&#39;=\r\ns not a question of better for me, it&#39;s a question of learning from the onl=\r\ny evidence we have.&nbsp; How do you expect to really develop a better enco=\r\nding of fracture if you ignore the thousands of examples of fracture that a=\r\nlready exist?&nbsp; You will just end up reinventing the wheel.&nbsp;&nbsp;=\r\n &lt;br&gt;&lt;br&gt;The danger of that is evident in some of the assumptions you hold =\r\nalready about how CPPNs encode fracture.&nbsp; For example, you are worried=\r\n that it may not do so efficiently, but you have only constructed a single =\r\nthought experiment (your figure 13) instead of taking a measured look at th=\r\ne thousands of examples in front of us.&nbsp; In fact, while indeed I don&#39;t=\r\n think 6 nodes is particularly much, it&#39;s easy enough to find fracture in P=\r\nicbreeder represented in under 6 nodes.&nbsp; For example, the pattern belo=\r\nw has at least 3 distinct fractured regions (which I numbered for clarity):=\r\n a pinkish region, an ovular inner region, and a conic lower region.&nbsp; =\r\nHowever, the CPPN that encodes it (shown to its left) only uses &lt;b&gt;4 nodes =\r\nto encode these 3 fractured regions&lt;/b&gt; (notice that two of the displayed h=\r\nidden nodes have outgoing weights of zero, so they are not contributing to =\r\nthe output pattern, leaving only the 4 nodes).&nbsp; That&#39;s a respectable 1=\r\n.3 nodes per fractured region: &lt;br&gt;&lt;br&gt;(this image is also available at &lt;a =\r\nrel=3D&quot;nofollow&quot; target=3D&quot;_blank&quot; href=3D&quot;http://eplex.cs.ucf.edu/hyperNEA=\r\nTpage/content/four-node-fracture.jpg&quot;&gt;http://eplex.cs.ucf.edu/hyperNEATpage=\r\n/content/four-node-fracture.jpg&lt;/a&gt;&nbsp;)&lt;br&gt;&lt;br&gt;&lt;img src=3D&quot;http://eplex.=\r\ncs.ucf.edu/hyperNEATpage/content/four-node-fracture.jpg&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;We cou=\r\nld argue about the definition of fracture, and perhaps you&#39;d want to refine=\r\n the definition to argue that the above example doesn&#39;t really have three f=\r\nractured regions.&nbsp; Or you could argue that the &quot;d&quot; input sho=\r\nuld be counted as a 5th node (to encode the 3 regions, which is still a res=\r\npectable 1.7 nodes per region).&nbsp; But even those would be healthy discu=\r\nssions that we could not begin to have without first referring to the examp=\r\nles that we already have.&nbsp; Of course (intuitively) more complex fractu=\r\nre will require more nodes (maybe at some point 6!), as it should.&nbsp; Al=\r\nl I&#39;m saying is I think this kind of speculation about whether it&#39;s efficie=\r\nnt or not is jumping the gun:&nbsp; Let&#39;s understand it first before we wor=\r\nry about fixing it.&lt;br&gt;&lt;br&gt;So I think there&#39;s a difference of philosophies =\r\nultimately at work here.&nbsp; Because the road ahead to AI is so vast, I&#39;m=\r\n more motivated by maximizing our information than doing &quot;better.&quot=\r\n;&nbsp; For example, that&#39;s the motivation behind Picbreeder - obviously it=\r\n is not quantifiably better than anything in particular, but it increased o=\r\nur understanding of a number of important phenomena, including fracture, re=\r\npresentation, and non-objective search, by providing useful information.&nb=\r\nsp; So I say, let&#39;s see where this takes us - there&#39;s still a ton left to l=\r\nearn.&nbsp; But you are already itching to start anew and fix things that a=\r\nre not clearly broken just when we have hit a goldmine of untapped informat=\r\nion.&nbsp; &lt;br&gt;&lt;br&gt;Without question, neither of our perspectives is definit=\r\nively superior; we are both merely speculating about where time is best inv=\r\nested, and obviously neither of us can predict the future.&nbsp; This argum=\r\nent is only my own case for my perspective.&lt;br&gt;&lt;br&gt;Best,&lt;br&gt;&lt;br&gt;ken&lt;br&gt;&lt;br&gt;=\r\n&lt;br&gt;--- In neat@yahoogroups.com, &quot;shimonw&quot;  wrote:&lt;br&gt;&gt;&lt;br&gt;&gt=\r\n; Hi Ken,&lt;br&gt;&gt; &lt;br&gt;&gt; If I may, I&#39;d like to offer a couple reactions t=\r\no your latest message.  This is indeed an interesting discussion that touch=\r\nes on many potentially important issues.  I hope I can offer a useful persp=\r\nective on these topics.&lt;br&gt;&gt; &lt;br&gt;&gt; You are right that in a target-bas=\r\ned scenario there can be many CPPNs that generate the same phenotype.  But =\r\nthe CPPN is a genotype, not a phenotype. In what I&#39;m calling &quot;regular&=\r\nquot; FFs, there are potentially many *phenotypes* that solve the problem, =\r\nand for each of them potentially many genotypes.  So in my mind, there is s=\r\ntill a useful distinction between target based FFs and regular FFs, though =\r\nthey are perhaps best seen as different points on a spectrum.&lt;br&gt;&gt; &lt;br&gt;&=\r\ngt; If I understand correctly, you are suggesting that the important distin=\r\nction is how the FF interacts with the search process.  But to me, this is =\r\na difficult criterion to use because the search process could be anything. =\r\n The space of possible black-box optimization methods is huge, and what enc=\r\nourages piecewise incremental progress for one method may not for another.&lt;=\r\nbr&gt;&gt; &lt;br&gt;&gt; I don&#39;t pretend to know what kind of algorithm would gener=\r\nate Einstein-level intelligence (I don&#39;t even know if this is a useful goal=\r\n). But as a researcher I highly respect once told me, &quot;your failure to=\r\n imagine it does not constitute a proof that it cannot be done.&quot;&lt;br&gt;&g=\r\nt; &lt;br&gt;&gt; That&#39;s why I think your hypothesis is quite a bold one, because=\r\n it looks at the limitations of a specific class of black-box optimization =\r\nmethods and generalizes them to all possible black-box optimization methods=\r\n.  &lt;br&gt;&gt; &lt;br&gt;&gt; To give just one example of the possibilities here: al=\r\ngorithms for continuous-armed bandits, such as X-armed bandits and Bayesian=\r\n optimization methods such as GP-UCB, can be applied to black-box optimizat=\r\nion.  These methods avoid the problem of local optima in a principled way, =\r\nby maintaining a posterior distribution over the global FF, and using optim=\r\nism in the face of uncertainty to ensure sufficient exploration of the solu=\r\ntion space.  As a result, these methods have very nice theoretical properti=\r\nes, like guaranteed convergence to the global optimum in the limit and loga=\r\nrithmic regret bounds along the way. &lt;br&gt;&gt; &lt;br&gt;&gt; As far as I know, no=\r\n one has tried to develop versions of these methods that can discover NN to=\r\npologies, and which would thus be suitable for optimizing CPPNs or other in=\r\ndirect encodings.  But there&#39;s no a priori reason to think it can&#39;t be done=\r\n.  I&#39;m not saying this would necessarily work or even that it&#39;s the most pr=\r\nomising approach to explore.  I&#39;m just saying it&#39;s one example of a princip=\r\nled approach that could avoid all the difficulties you mention and which we=\r\n currently have no strong reason to eliminate from contention.&lt;br&gt;&gt; &lt;br&gt;=\r\n&gt; So I think it&#39;s quite likely that these hard FFs are not unsolvable, b=\r\nut just that current methods cannot solve them.  Rather than giving up on t=\r\nhem, in my opinion we should be focusing on developing better methods for t=\r\nhem.&lt;br&gt;&gt; &lt;br&gt;&gt; Regarding whether 6 nodes is a lot to represent fract=\r\nure, I think the same point applies: just because we can&#39;t think of a bette=\r\nr way to do it, doesn&#39;t mean it doesn&#39;t exist.  Our paper establishes 6 as =\r\nan upper bound, which can be easily done by example.  If I understand corre=\r\nctly, you are suggesting that 6 may be a lower bound, which is much more di=\r\nfficult to demonstrate.&lt;br&gt;&gt; &lt;br&gt;&gt; I could definitely imagine that a =\r\ndifferent type of network, or one with a different set of activation functi=\r\nons, might be able to make better use of 6 nodes.  Even if it&#39;s true that t=\r\nhere&#39;s a trade-off, and using fewer nodes means less flexibility, there may=\r\n be many cases where that&#39;s a favorable trade-off.  We should at least be o=\r\npen to the possibility that it some cases the sweet spot is not a represent=\r\nation that requires 6 nodes for fracture.&lt;br&gt;&gt; &lt;br&gt;&gt; I&#39;m looking forw=\r\nard to chatting more about this at GECCO.&lt;br&gt;&gt; &lt;br&gt;&gt; Cheers,&lt;br&gt;&gt; =\r\nShimon&lt;br&gt;&gt; &lt;br&gt;&gt; --- In neat@yahoogroups.com, &quot;Ken&quot; kstanl=\r\ney@ wrote:&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt; Hi Shimon,&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; =\r\nThese are some really interesting and deep issues we&#39;re getting into.  I&lt;br=\r\n&gt;&gt; &gt; am sure they will be the foundation of great discussions at GECC=\r\nO.  I&#39;ll&lt;br&gt;&gt; &gt; try to keep my response more brief than before.&lt;br&gt;&g=\r\nt; &gt; &lt;br&gt;&gt; &gt; 1) Indeed recent quadruped results are not in the sam=\r\ne setup as in your&lt;br&gt;&gt; &gt; work; that is a legitimate qualification an=\r\nd they do not constitute a&lt;br&gt;&gt; &gt; proof that in your particular setup=\r\n HyperNEAT would succeed.  However,&lt;br&gt;&gt; &gt; they are arguably at least=\r\n comparably complex.  For example, the CTRNN&lt;br&gt;&gt; &gt; in&lt;br&gt;&gt; &gt; h=\r\nttp://eplex.cs.ucf.edu/papers/risi_gecco13b.pdf&lt;br&gt;&gt; &gt;    is a compli=\r\ncated&lt;br&gt;&gt; &gt; structure and the CPPN that encodes it is required not o=\r\nnly to generate&lt;br&gt;&gt; &gt; a controller for a single quadruped morphology=\r\n, but to generate multiple&lt;br&gt;&gt; &gt; controllers for multiple morphologi=\r\nes, all from the same CPPN.  A video&lt;br&gt;&gt; &gt; of three controllers all =\r\nfrom the same CPPN is here:&lt;br&gt;&gt; &gt; http://youtu.be/oLSSt5GyHNk &lt;br&gt;&g=\r\nt; &gt; &lt;br&gt;&gt; &gt; 2) I think the question of what is &quot;target-based=\r\n&quot; can actually be&lt;br&gt;&gt; &gt; interesting, but I completely agree tha=\r\nt the semantic side of the&lt;br&gt;&gt; &gt; argument isn&#39;t really important.  B=\r\nut what I do find interesting is the&lt;br&gt;&gt; &gt; idea that these two scena=\r\nrios differ substantively in your mind (as you&lt;br&gt;&gt; &gt; put it):&lt;br&gt;&gt=\r\n; &gt; &lt;br&gt;&gt; &gt; &quot;there is an important difference between FFs tha=\r\nt require a single&lt;br&gt;&gt; &gt; specific phenotype and FFs that require onl=\r\ny that some goal be achieved&quot;&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; I think by &q=\r\nuot;single specific phenotype&quot; you mean pattern-matching (i.e.&lt;br&gt;&gt;=\r\n &gt; image-matching).  But I think this distinction doesn&#39;t really exist: =\r\n&lt;br&gt;&gt; &gt; There are an unlimited number of networks (i.e. CPPNs) that c=\r\nan encode a&lt;br&gt;&gt; &gt; particular two-dimensional image, just as there ar=\r\ne an unlimited number&lt;br&gt;&gt; &gt; of CPPNs that can encode a particular be=\r\nhavior or goal (such as&lt;br&gt;&gt; &gt; following a line).&lt;br&gt;&gt; &gt; &lt;br&gt;&g=\r\nt; &gt; What makes both target-based and fundamentally the same is not the&lt;=\r\nbr&gt;&gt; &gt; number of ways they can be solved, but rather the way the fitn=\r\ness&lt;br&gt;&gt; &gt; function interacts with the search process.  The problem i=\r\ns that&lt;br&gt;&gt; &gt; target-based fitness encourages piece-wise incremental =\r\nprogress, which&lt;br&gt;&gt; &gt; tends to be highly deceptive.  For example, wi=\r\nth an image, matching a&lt;br&gt;&gt; &gt; single pixel can raise fitness even if=\r\n the function that causes that&lt;br&gt;&gt; &gt; pixel to be matched has no rela=\r\ntionship whatsoever to the overall&lt;br&gt;&gt; &gt; regularities in the target =\r\npattern.  The same is true in control tasks: &lt;br&gt;&gt; &gt; A mutation that =\r\ncauses a quadruped to lunge forward clumsily is rewarded&lt;br&gt;&gt; &gt; for t=\r\nhe slight improvement in fitness, whereas an important underlying&lt;br&gt;&gt; &=\r\ngt; regularity (e.g. oscillation) necessary to get really good at the task&lt;=\r\nbr&gt;&gt; &gt; is never established.  Non-target-based fitness (or what I cal=\r\nl&lt;br&gt;&gt; &gt; &quot;non-objective&quot;) avoids these problems because it =\r\n*does* reward&lt;br&gt;&gt; &gt; establishing regularities: it appreciates new re=\r\ngularities even if they&lt;br&gt;&gt; &gt; don&#39;t immediately raise fitness.&lt;br&gt;&g=\r\nt; &gt; &lt;br&gt;&gt; &gt; But what&#39;s most interesting to me is your intuition t=\r\nhat there is some&lt;br&gt;&gt; &gt; way to sidestep the tradeoff in combining in=\r\ndirect encodings with&lt;br&gt;&gt; &gt; target-based fitness functions.  That is=\r\n, you suspect there may exist an&lt;br&gt;&gt; &gt; indirect encoding that can bo=\r\nth elaborate regularities compositionally&lt;br&gt;&gt; &gt; over very many gener=\r\nations and also almost deterministically satisfy an&lt;br&gt;&gt; &gt; arbitrary =\r\ntarget-based objective.  I am convinced that is not the case &lt;br&gt;&gt; &gt; =\r\n(it would be too good to be true), but you rightly point out that my&lt;br&gt;&gt=\r\n; &gt; position is a hypothesis.   However, just as a thought experiment, c=\r\nan&lt;br&gt;&gt; &gt; you really imagine any neural network encoding (including D=\r\nNA) that&lt;br&gt;&gt; &gt; would give you Einstein-level intelligence if the tar=\r\nget was simply to&lt;br&gt;&gt; &gt; score maximally on an IQ test?  It is plain =\r\nto me that the stepping&lt;br&gt;&gt; &gt; stones to human level cannot be crosse=\r\nd in the presence of a&lt;br&gt;&gt; &gt; target-based objective (or any one conc=\r\neivable).  However,&lt;br&gt;&gt; &gt; interestingly, that does not mean that suc=\r\nh a neural network does not&lt;br&gt;&gt; &gt; exist in the search space.  It jus=\r\nt means a target won&#39;t get you there.&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; 3) We appa=\r\nrently disagree on whether 6 is a big number (for nodes needed&lt;br&gt;&gt; &gt;=\r\n to represent fracture).  If you try to devise an encoding that&lt;br&gt;&gt; &gt=\r\n; represents fracture with fewer than that, my intuition is that you would&lt;=\r\nbr&gt;&gt; &gt; be sacrificing an enormous breadth of flexibility in the kinds=\r\n of&lt;br&gt;&gt; &gt; fracture (and patterns in general) that you can represent.=\r\n  Think about&lt;br&gt;&gt; &gt; the number of &quot;degrees of freedom&quot; in =\r\nfracture: it&#39;s not really&lt;br&gt;&gt; &gt; well-defined, but a single line of f=\r\nracture has a lot of dimensions:&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; -position&lt;br&gt;&g=\r\nt; &gt; -orientation&lt;br&gt;&gt; &gt; -curvature (which can be arbitrarily comp=\r\nlex)&lt;br&gt;&gt; &gt; -fracture gradient (that is, one region can smoothly tran=\r\nsition into&lt;br&gt;&gt; &gt; another in a kind of interpolated transitional zon=\r\ne)&lt;br&gt;&gt; &gt; -embedding (fracture can potentially be hierarchical or reg=\r\nular, i.e.&lt;br&gt;&gt; &gt; dependent on higher-level containing regions)&lt;br&gt;&g=\r\nt; &gt; &lt;br&gt;&gt; &gt; The idea that all of that can be encoded in anything =\r\nless than about 6&lt;br&gt;&gt; &gt; simple functions seems optimistic.  Of cours=\r\ne, if you are willing to&lt;br&gt;&gt; &gt; sacrifice some of those degrees of fr=\r\needom, then you can get fewer&lt;br&gt;&gt; &gt; nodes, but the exquisite minutia=\r\n of such patterns would be lost (and&lt;br&gt;&gt; &gt; you&#39;d move more towards d=\r\nirect encoding, like the wavelets do).&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; By the wa=\r\ny, here are some cool examples of complicated kinds of fracture&lt;br&gt;&gt; &gt=\r\n; from Picbreeder (such as fractured periodic zones, but even more complex&lt;=\r\nbr&gt;&gt; &gt; than even that):&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; Nontrivial color p=\r\natterns in each zone:&lt;br&gt;&gt; &gt; http://picbreeder.org/search/showgenome.=\r\nphp?sid=3D11328&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; Very complex brush=\r\n-stroke pattern inside the apple vs. outside (the DNA&lt;br&gt;&gt; &gt; for this=\r\n one is fascinating):&lt;br&gt;&gt; &gt; http://picbreeder.org/search/showgenome.=\r\nphp?sid=3D7109&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; Fract=\r\nured regions covering a distorted surface, giving a remarkable&lt;br&gt;&gt; &gt;=\r\n underlying curvature:&lt;br&gt;&gt; &gt; http://picbreeder.org/search/showgenome=\r\n.php?sid=3D2684&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; A color variant: h=\r\nttp://picbreeder.org/search/showgenome.php?sid=3D6652&lt;br&gt;&gt; &gt; &lt;br&gt;&gt;=\r\n &gt; &lt;br&gt;&gt; &gt; When I see so many remarkable examples like these on Pi=\r\ncbreeder, the&lt;br&gt;&gt; &gt; message to me is that we have only scratched the=\r\n surface of what CPPN&lt;br&gt;&gt; &gt; encoding can teach us about representati=\r\non.  That&#39;s why I think it&#39;s&lt;br&gt;&gt; &gt; premature (in the face of such a =\r\ntreasure trove of evidence) to be&lt;br&gt;&gt; &gt; worrying about whether we ca=\r\nn represent some subcomponent of such&lt;br&gt;&gt; &gt; patterns with less than =\r\n6 nodes.  At present I&#39;m amazed they can be&lt;br&gt;&gt; &gt; represented at all=\r\n, let alone with under 6 nodes.&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; Thanks very much=\r\n for raising these issues in any case - it&#39;s a great&lt;br&gt;&gt; &gt; debate to=\r\n have about representation and search and goes to the heart of&lt;br&gt;&gt; &gt;=\r\n the field of GDS/indirect encoding.&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; Best,&lt;br&gt;&g=\r\nt; &gt; &lt;br&gt;&gt; &gt; ken&lt;br&gt;&gt; &gt; &lt;br&gt;&gt; &gt; --- In neat@yahoogroup=\r\ns.com, &quot;shimonw&quot;  wrote:&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; Hi K=\r\nen,&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; Thanks for your interesting and tho=\r\nught-provoking comments.  I&#39;ll give&lt;br&gt;&gt; &gt; some brief reactions here,=\r\n and I hope we can have a productive&lt;br&gt;&gt; &gt; discussion about it at GE=\r\nCCO.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; 1) I won&#39;t comment for now on the =\r\nnew experiments you&#39;ve been running&lt;br&gt;&gt; &gt; because the details are no=\r\nt available yet.  Instead, I will just comment&lt;br&gt;&gt; &gt; on the various =\r\nwalking gait domains, because the details of the&lt;br&gt;&gt; &gt; additional re=\r\nsults you mentioned are in that case already available, in&lt;br&gt;&gt; &gt; new=\r\nly published GECCO papers.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; FIrst of all=\r\n, these are very cool results, and nice success stories&lt;br&gt;&gt; &gt; for Hy=\r\nperNEAT.  It&#39;s great to see that the GDS community is continuing&lt;br&gt;&gt; &g=\r\nt; the push the envelope in terms of robot locomotion, which seems to be&lt;br=\r\n&gt;&gt; &gt; emerging as a nice application for indirect encodings.&lt;br&gt;&gt; &=\r\ngt; &gt;&lt;br&gt;&gt; &gt; &gt; However, I would simply caution against placing =\r\nall these variations&lt;br&gt;&gt; &gt; on the walking gait task on a one-dimensi=\r\nonal spectrum of difficulty. &lt;br&gt;&gt; &gt; In our paper, we took the origna=\r\nl walking gait task and made only one&lt;br&gt;&gt; &gt; change (increasing the m=\r\nass of the torso) which clearly makes the task&lt;br&gt;&gt; &gt; harder.  In the=\r\n papers Ken mentioned, there are other differences, e.g.,&lt;br&gt;&gt; &gt; the =\r\nuse of an SUPG encoding, the use of CTRNNs, the use of a different&lt;br&gt;&gt; =\r\n&gt; substrate topology, and varying the length of the legs.&lt;br&gt;&gt; &gt; &=\r\ngt;&lt;br&gt;&gt; &gt; &gt; It&#39;s completely legitimate to make these changes and =\r\nthey don&#39;t&lt;br&gt;&gt; &gt; detract from the results at all.   But they are con=\r\nfounding factors when&lt;br&gt;&gt; &gt; it comes to comparing HyperNEAT&#39;s perfor=\r\nmance on walking gait tasks of&lt;br&gt;&gt; &gt; different difficulties.  Some o=\r\nf these changes may make the task harder&lt;br&gt;&gt; &gt; in some ways but othe=\r\nr changes may make it easier in others ways, and so&lt;br&gt;&gt; &gt; far we don=\r\n&#39;t have experimental results that control for these factors.&lt;br&gt;&gt; &gt; &=\r\ngt;&lt;br&gt;&gt; &gt; &gt; 2) I hope to avoid a semantic debate about what is a =\r\n&quot;target-based&quot;&lt;br&gt;&gt; &gt; FF.  If you want to include what I wa=\r\ns calling a &quot;regular&quot; FF in the&lt;br&gt;&gt; &gt; scope of target-base=\r\nd FFs, I won&#39;t object.  But my point is that,&lt;br&gt;&gt; &gt; regardless of wh=\r\nat you call them, there is an important difference&lt;br&gt;&gt; &gt; between FFs=\r\n that require a single specific phenotype and FFs that&lt;br&gt;&gt; &gt; require=\r\n only that some goal be achieved.  For the latter, there may be&lt;br&gt;&gt; &gt=\r\n; many ways to skin the cat, though in any interesting problem, good&lt;br&gt;&gt=\r\n; &gt; solutions are still quite rare.  The distinction is important becaus=\r\ne,&lt;br&gt;&gt; &gt; while the former category is arguably only of theoretical i=\r\nnterest, the&lt;br&gt;&gt; &gt; second category corresponds to what I consider th=\r\ne most interesting and&lt;br&gt;&gt; &gt; important class of FFs, because these a=\r\nre the FFs that naturally arise&lt;br&gt;&gt; &gt; in a very large number of real=\r\n-world optimization problems.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; So, using=\r\n your terminology, I agree it is reasonable to say&lt;br&gt;&gt; &gt; HyperNEAT&#39;s=\r\n difficulties with fracture are probably limited to&lt;br&gt;&gt; &gt; &quot;targ=\r\net-based&quot; FFs.  But for me, this is a potentially serious&lt;br&gt;&gt; &gt;=\r\n restriction, since target-based FFs include not just pathological FFs&lt;br&gt;&=\r\ngt; &gt; but a large class of real-world FFs.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt=\r\n; &gt; Regarding the wavelet method, I would still definitely call this an&lt;=\r\nbr&gt;&gt; &gt; indirect encoding, but it is in some sense &quot;less indirect=\r\n&quot; because it&lt;br&gt;&gt; &gt; lacks the compositional functions of HyperNE=\r\nAT. It&#39;s a perfectly&lt;br&gt;&gt; &gt; reasonable hypothesis that such compositi=\r\nonality is advantageous in some&lt;br&gt;&gt; &gt; ways.  However, if that&#39;s true=\r\n, then we should be able to demonstrate&lt;br&gt;&gt; &gt; that by finding tasks =\r\nwhere HyperNEAT outperforms the wavelet method&lt;br&gt;&gt; &gt; (FYI, in the ex=\r\ntended analysis Thomas is conducting for his master&#39;s&lt;br&gt;&gt; &gt; thesis, =\r\nwe have found one variation of the line-following task where&lt;br&gt;&gt; &gt; t=\r\nhis is the case).  So in that sense, the wavelet method is a useful&lt;br&gt;&gt;=\r\n &gt; baseline, which is the whole reason we introduced it.&lt;br&gt;&gt; &gt; &g=\r\nt;&lt;br&gt;&gt; &gt; &gt; 3) If it&#39;s true that it takes ~6 nodes to represent fr=\r\nacture, then I&lt;br&gt;&gt; &gt; think this a potentially important point.  On r=\r\negular FFs, it could&lt;br&gt;&gt; &gt; contribute to the difficulty of discoveri=\r\nng fracture, since&lt;br&gt;&gt; &gt; representations that have only some of the =\r\nnecessary components may not&lt;br&gt;&gt; &gt; be rewarded (I think you would ca=\r\nll this &quot;deception&quot;).  In&lt;br&gt;&gt; &gt; Picbreeder-like tasks, we =\r\nalready see that fracture can evolve anyway,&lt;br&gt;&gt; &gt; but this doesn&#39;t =\r\nmean it wouldn&#39;t do it even better if fracture required&lt;br&gt;&gt; &gt; fewer =\r\nnodes to represent.  If we think that the solutions to many&lt;br&gt;&gt; &gt; in=\r\nteresting problems require fracture, then I think it&#39;s at least&lt;br&gt;&gt; &gt=\r\n; possible that one could devise a better representation for such problems&lt;=\r\nbr&gt;&gt; &gt; than the CPPNs used in HyperNEAT.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &g=\r\nt; &gt; As I understand it, your approach to dealing with &quot;regular&quo=\r\nt; FFs is to&lt;br&gt;&gt; &gt; reformulate them &quot;in a way that respects the=\r\n need for phenotypic&lt;br&gt;&gt; &gt; diversity and open-endedness.&quot;  That=\r\n&#39;s a very interesting approach and I&lt;br&gt;&gt; &gt; think it has a lot of mer=\r\nit, but I don&#39;t think it will solve all our&lt;br&gt;&gt; &gt; problems because i=\r\nt presupposes that such a reformulation is possible&lt;br&gt;&gt; &gt; (or that t=\r\nhe prior knowledge it requires is available).  In some cases,&lt;br&gt;&gt; &gt; =\r\nI think we are just stuck with hard FFs and we need to develop better&lt;br&gt;&g=\r\nt; &gt; methods to deal with them.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; Rega=\r\nrding the idea that &quot;an unhappy and unhealthy indirect encoding is&lt;br&gt;=\r\n&gt; &gt; one with only a strict target to which to aspire&quot;: this is a=\r\n very&lt;br&gt;&gt; &gt; intriguing hypothesis, but to me it is only a hypothesis=\r\n.  I think it&#39;s&lt;br&gt;&gt; &gt; true of existing indirect encodings, but that =\r\nfor me does not in any way&lt;br&gt;&gt; &gt; rule out the possibility of develop=\r\ning a different indirect encoding for&lt;br&gt;&gt; &gt; which that is not true, =\r\nand I think that&#39;s one thing we should be&lt;br&gt;&gt; &gt; working on.   One of=\r\n the reasons that I&#39;m interested in indirect&lt;br&gt;&gt; &gt; encodings is that=\r\n I strongly believe this can be done.&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt; &gt; C=\r\nheers,&lt;br&gt;&gt; &gt; &gt; Shimon&lt;br&gt;&gt; &gt; &gt;&lt;br&gt;&gt; &gt;&lt;br&gt;&gt;&lt;br&gt;\n=\r\n\n\r\n--1-0999311798-9958642861=:2--\r\n\n"}}