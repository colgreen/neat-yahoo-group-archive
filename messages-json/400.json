{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":34004016,"authorName":"Derek James","from":"Derek James &lt;blue5432@...&gt;","profile":"blue5432","replyTo":"LIST","senderId":"WN2X4Qi6U6jZUU1DYF-LtVmFl3tYBae_1iSB3SsYkHKLoq48HN1sHcRyjImWRcHrPN_UGEcBE-Y7DWHFBAa7Jg4v1yCzRMk","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Re: Random Complexification","postDate":"1077144891","msgId":400,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDQwMjE4MjI1NDUxLjEyMTU2LnFtYWlsQHdlYjYwNTAxLm1haWwueWFob28uY29tPg==","inReplyToHeader":"PEJBWTItRjk3S2lJY04zVmtuSUQwMDAxOTE0NkBob3RtYWlsLmNvbT4="},"prevInTopic":399,"nextInTopic":401,"prevInTime":399,"nextInTime":401,"topicId":371,"numMessagesInTopic":22,"msgSnippet":"... As with complexification, I m not sure it s a matter of simplification being necessary .  The question is what features of an algorithm will tend to lead","rawEmail":"Return-Path: &lt;blue5432@...&gt;\r\nX-Sender: blue5432@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 77788 invoked from network); 18 Feb 2004 22:54:53 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m17.grp.scd.yahoo.com with QMQP; 18 Feb 2004 22:54:53 -0000\r\nReceived: from unknown (HELO web60501.mail.yahoo.com) (216.109.116.122)\n  by mta2.grp.scd.yahoo.com with SMTP; 18 Feb 2004 22:54:52 -0000\r\nMessage-ID: &lt;20040218225451.12156.qmail@...&gt;\r\nReceived: from [204.146.199.2] by web60501.mail.yahoo.com via HTTP; Wed, 18 Feb 2004 14:54:51 PST\r\nDate: Wed, 18 Feb 2004 14:54:51 -0800 (PST)\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;BAY2-F97KiIcN3VknID00019146@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nX-eGroups-Remote-IP: 216.109.116.122\r\nFrom: Derek James &lt;blue5432@...&gt;\r\nSubject: Re: [neat] Re: Random Complexification\r\nX-Yahoo-Group-Post: member; u=34004016\r\nX-Yahoo-Profile: blue5432\r\n\r\n--- John Arrowwood &lt;jarrowwx@...&gt; wrote:\n&gt; Just an observation:  These are evolutionary\n&gt; simplifications in a CHANGING \n&gt; environment.  When using NEAT on a fixed domain,\n&gt; simplification shouldn&#39;t be \n&gt; necessary, right?  \n\nAs with complexification, I&#39;m not sure it&#39;s a matter\nof simplification being &quot;necessary&quot;.  The question is\nwhat features of an algorithm will tend to lead toward\nthe best solution.  I happen to think that in more\ndifficult domains, especially real-time ones such as\nrobot control, efficiency will be more important, and\nit may be a good idea to include simplification as\npart of the algorithm.\n\nIt&#39;s also maps to real biology.  There are a number of\ndifferent types of mutation that act upon DNA.  There\ncan be insertion of novel genetic material, inversion\nof a strand of DNA, and of course, deletion or\ninactivation of genetic material.  A lot of &quot;junk&quot; DNA\nmay well be genes that were merely deactivated at some\npoint, but kept around for possible future\ninnovations.\n\nOf course, NEAT already has a similar feature, in that\nwhen a new node is added where an existing connection\nused to reside, that connection is deactivated, with\nthe potential for later reactivation.  But there are\nnot any mutations that, for example, randomly\ndeactivate connections or neurons and their\ncorresponding connections.\n\n&gt; On the other hand, with a sufficiently complex\n&gt; genome, features may develop \n&gt; that increase fitness, but render another feature\n&gt; irrelevant.  It may even \n&gt; render it inhibitory.  \n\nRight.\n\n&gt; Thus a balance of \n&gt; increasing AND decreasing complexity could prove\n&gt; beneficial, even in an \n&gt; unchanging environment.\n\nPersonally, I think it probably will.  I&#39;ve had\ndiscussion privately with Ken along these lines, and\nit&#39;s one of the experimental avenues I&#39;d definitely\nlike to pursue.\n\n&gt; But that really depends on the environment and the\n&gt; task.  \n\nI don&#39;t think it matters very much whether the\nenvironment is static or not.  Just doing small runs\nwith XOR, generational or run champions often mutate\nbeyond the minimal topology required to solve XOR. \nThe thing is, with NEAT, there is no way to prune an\narchitecture if needless topology is added.  With a\ntendency toward complexification, and a small bias\ntoward simplification, optimal topologies might be\nmore likely to evolve.\n\n&gt; But for most forms of simplification, simply\n&gt; reducing weights is \n&gt; functionally equivalent, is it not?  If you have a\n&gt; fixed number of inputs, \n&gt; some of which are not relevant, then learning a\n&gt; weight of 0 is equivalent to \n&gt; simplifying them out of the genome, right?\n\nYes, but this takes for granted that your algorithm\nallows weights to evolve completely to 0.  Also, if\nyour processor is still doing all that matrix\nmultiplication for values that are meaningless, you&#39;re\nwasting cycles.  You&#39;ve also got needlessly longer\ngenomes, which can adversely affect the efficiency of\nyour GA, bloat whatever you&#39;re persisting, etc.\n\nDerek\n\n__________________________________\nDo you Yahoo!?\nYahoo! Mail SpamGuard - Read only the mail you want.\nhttp://antispam.yahoo.com/tools\n\n"}}