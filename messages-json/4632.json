{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":344770313,"authorName":"Colin Green","from":"Colin Green &lt;colin.green1@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"6wQBh_TzywIjYJZ_VrWqneu6le5UkOGd6TQU-i68CAMJlyhg3QSUlMZF_w-yWsdMa3mhIy2qMdNF4ouV2RwP7G1WlVTl-r77ke_pJztFFFU","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: The Next Generation of Neural Networks - Geoff Hinton \tTechTalk","postDate":"1240183563","msgId":4632,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDcyN2E0MDZjMDkwNDE5MTYyNnYyMTU0NWE0YXAxZmIzOTNmMTFmM2FlYWRiQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PGdzMWFtYStxN25jQGVHcm91cHMuY29tPg==","referencesHeader":"PGdydXRsdCtlajdqQGVHcm91cHMuY29tPiA8Z3MxYW1hK3E3bmNAZUdyb3Vwcy5jb20+"},"prevInTopic":4626,"nextInTopic":0,"prevInTime":4631,"nextInTime":4633,"topicId":4620,"numMessagesInTopic":8,"msgSnippet":"Hi Ken, I agree with pretty much everything you ve said. In human vision much of the geometry part of the recognition problem is handled by succesive layers of","rawEmail":"Return-Path: &lt;colin.green1@...&gt;\r\nX-Sender: colin.green1@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 61870 invoked from network); 19 Apr 2009 23:27:14 -0000\r\nX-Received: from unknown (69.147.108.200)\n  by m7.grp.re1.yahoo.com with QMQP; 19 Apr 2009 23:27:14 -0000\r\nX-Received: from unknown (HELO mail-fx0-f163.google.com) (209.85.220.163)\n  by mta1.grp.re1.yahoo.com with SMTP; 19 Apr 2009 23:27:13 -0000\r\nX-Received: by fxm7 with SMTP id 7so1605157fxm.39\n        for &lt;neat@yahoogroups.com&gt;; Sun, 19 Apr 2009 16:26:04 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.103.107.1 with SMTP id j1mr2751557mum.30.1240183564074; Sun, \n\t19 Apr 2009 16:26:04 -0700 (PDT)\r\nIn-Reply-To: &lt;gs1ama+q7nc@...&gt;\r\nReferences: &lt;grutlt+ej7j@...&gt; &lt;gs1ama+q7nc@...&gt;\r\nDate: Mon, 20 Apr 2009 00:26:03 +0100\r\nMessage-ID: &lt;727a406c0904191626v21545a4ap1fb393f11f3aeadb@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Colin Green &lt;colin.green1@...&gt;\r\nSubject: Re: [neat] Re: The Next Generation of Neural Networks - Geoff Hinton \n\tTechTalk\r\nX-Yahoo-Group-Post: member; u=344770313; y=UYHZHyRHM1qLuwLMokZno7YiFOb_rEQ8rWgWkZ66cUAYPyEAUWvU\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nHi Ken,\n\nI agree with pretty much everything you&#39;ve said. In human vision much\nof the geometry part of the recognition problem is handled by\nsuccesive layers of recognition - e.g. line detection followed by\nshape detection - obviously it&#39;s a *lot* more complex than that, but\nthat&#39;s the general idea.\n\nBut now I&#39;m thinking that those layers (V1-V5 or whatever) are\npotentially learned through observation in our first days, weeks and\nmonths - there is very likely a genetic bias towards the geometry we\nall ultimately learn but I&#39;d be surprised if it was all encoded\ngenetically. Specifically I&#39;m thinking of that experiment where cats\nare raised in an environment with no horizontal lines and subsequently\nfall off tables because they can&#39;t see the edge  (I&#39;m probably\nmisremembering the details though).\n\nOnce you&#39;ve built V1-V5 based on the geometry of the world you find\nyourself in (including your retina and still growing optic nerves),\nfrom then on you can observe patterns in the environment through the\n&#39;filter&#39; of your visual system, which although not fixed it has\nsettled on a geometry at the broadest level.\n\nFrom this perspective then I wonder if Hinton&#39;s algorithm really isn&#39;t\nmissing anything - we train a few layers that represent basic geometry\n(equivalent to V1-V5), fix these layers and go on to learn high level\nfeatures and concepts by working with the feature detectors from v5 -\nwhich now represents features and their relationships within a real\nworld geometry. This is sort of what Hinton was doing except he was\nfixing the weights only temporarily to train the next layer rather\nthan permanently fixing the weights for a &#39;tranche&#39; of layers in order\nto move on to another &#39;tranche&#39;.\n\nThere&#39;s a lot more to it than all that otherwise Hinton would be able\nto recreate something with a similar power to the human visual system\ngiven enough computing power (which would be a a **lot**) - which\nno-one has yet come close matching.\n\nI see NEAT and HyperNEAT as complementary to this branch of research\ne.g. for creating controllers that perhaps use Hinton type models for\ninput and/or for discoverimg good topologies to train as RBMs. Pattern\nrecognition and modelling of the world is one thing, but encoding high\nlevel goals is quite another and something best left to evolutionary\napproaches for the foreseeable future I suspect. E.g. if you&#39;re a\ncomplex bipedal robot and your goal is to kick a football between to\ngoal posts avoiding opposing robots, then how do you train that with\nRBMs? - you&#39;d have to train to very high level features AND have some\nattention mechanisn for controlling the robot, which amounts to\nsolving strong AI.\n\nColin.\n\n"}}