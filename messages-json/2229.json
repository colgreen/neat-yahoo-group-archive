{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"m-tBlzoimrPye_pIDQOgSsAWRkJyHlTWbpuL8ozmWk1H8oBbZ5-mAnBVSenStwCD_-Mfj9vJrZOV9raZKsIHtP4FfzA4UlDB-cA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Introduction---recurrency question","postDate":"1125591145","msgId":2229,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMi4wLjE0LjAuMjAwNTA5MDExMjI0MjUuMDMyODQ5YjBAcG9wLm1haWwueWFob28uY28udWs+","inReplyToHeader":"PDUxN2ZhNmYxMDUwODMxMTcyNzc1OWU1Y2RjQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PGRmMzh1MCtkNGhvQGVHcm91cHMuY29tPiA8ZGY1MGtxK2UxMXJAZUdyb3Vwcy5jb20+IDw1MTdmYTZmMTA1MDgzMTE3Mjc3NTllNWNkY0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":2227,"nextInTopic":2230,"prevInTime":2228,"nextInTime":2230,"topicId":2209,"numMessagesInTopic":42,"msgSnippet":"Hi,\n         I m with John 100% on this, but I just thought I d try to give a \nsome more perspective on the two types of update.  Call them single value \nand","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 11444 invoked from network); 1 Sep 2005 16:19:44 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m34.grp.scd.yahoo.com with QMQP; 1 Sep 2005 16:19:44 -0000\r\nReceived: from unknown (HELO smtp005.mail.ukl.yahoo.com) (217.12.11.36)\n  by mta3.grp.scd.yahoo.com with SMTP; 1 Sep 2005 16:19:44 -0000\r\nReceived: (qmail 50280 invoked from network); 1 Sep 2005 16:14:04 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp005.mail.ukl.yahoo.com with SMTP; 1 Sep 2005 16:13:59 -0000\r\nMessage-Id: &lt;6.2.0.14.0.20050901122425.032849b0@...&gt;\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.2.0.14\r\nDate: Thu, 01 Sep 2005 17:12:25 +0100\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;517fa6f10508311727759e5cdc@...&gt;\r\nReferences: &lt;df38u0+d4ho@...&gt;\n &lt;df50kq+e11r@...&gt;\n &lt;517fa6f10508311727759e5cdc@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] Re: Introduction---recurrency question\r\nX-Yahoo-Group-Post: member; u=7192225; y=BisAbj2JqqwDS7K4SHaVXsAwZLRWPkrAyz_mwFZ8G1ocf_5YKg\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nHi,\n         I&#39;m with John 100% on this, but I just thought I&#39;d try to give a \nsome more perspective on the two types of update.  Call them single value \nand sink/source systems.\n\nSink-source simulates the process of _one_ neurone, taking care to insulate \nit from any questions of whether its neighbours have been updated yet or not.\n\nFor a non-recurrent network, there is no difference, provided you do enough \nupdates to propagate the inputs all the way to the output (by the _slowest_ \nroute).  Once this has happened, further updates will not change the output \nuntil the inputs are changed.  For a single-value system, if the nodes are \nevaluated in the right order, the result can get to the output in a single \npass.  A sink/source system could also do that, if you copy the sink \nstraight to the source after updating one node, but then it isn&#39;t really be \nacting as sink/source.  There is no need for sink/source in a non-recurrent \n(NR) network.  A single-value system evaluated in a different order will \ntake more updates but eventually get the same result to the output.\n\nNR-networks are state-functions of their inputs, e.g. (once the signal has \nreached the output)\n\noutput = F(inputs)\n\nAnd nothing will change the value of the output except new inputs.  If you \nwant to regard the inputs as varying over time, then we have:\n\noutput[t] = F(inputs[t], inputs[t-1], ..., inputs[t - n)\n\ne.g. the output responds to a range of time-slots in the inputs formed by a \nwindow stretching back from the present.  This is because the network \ncontains no &quot;memory&quot; but it can contain time delays.  The length of the \ntime-window (n) depends on the longest delay present in the network but is \nless according to how completely you update the network in each time \nstep.  If you update completely then n will be zero and the output will \ndepend only on the inputs[t].  OTOH, if it takes two passes to update your \nnetwork but you only run one in each time step, then you will have \ncontributions from inputs[t] and inputs[t-1] in the output.\n\n--\n\nFor a recurrent network, the problem is not that update is harder, it \nisn&#39;t, you can do it the same way as for non-recurrent if you like, the \nproblem is that the nature of update has changed.  The network no longer \nneed have a final update value to converge on.  e.g. it is perfectly \npossible to design an R-network that is an oscillator, even with no \ninput.  Thus you no longer have the option of running it to &quot;completely \nupdated&quot; because there is no such thing -- it might keep changing forever.\n\nThe choices you now have (after deciding on an update methodology) are:\n(i) how fast to run the network compared to the world.  e.g. N network \nupdates per input time step.  It doesn&#39;t make sense to run the network \nslower than the world, or rather it does but what you are actually doing is \ndiscarding some of the input data.\n(ii) whether to reinitialise the network before each timestep.  This is \nbasically saying &quot;and now erase any memories of previous steps&quot;...\n\nIan\n\nAt 01:27 01/09/2005, you wrote:\n&gt;Kevin,\n&gt;\n&gt;What you&#39;ve described here is far too complicated.  You&#39;re doing too\n&gt;much work.  Try this:\n&gt;\n&gt;For a given network topology, you only need to determine the firing\n&gt;order ONCE.  Save that list somewhere.  It will be consulted every\n&gt;time the network is activated, which may be thousands of times for a\n&gt;single fitness evaluation.  And of course a single network may be\n&gt;fitness evaluated multiple times with different scenarios presented to\n&gt;it during the course of a generation.  And if that topology survives\n&gt;into the next generation, you might as well take that list with it...\n&gt;\n&gt;When you are testing your network, you are testing it in a\n&gt;&#39;simulation&#39; where it checks the state of the world.  That determines\n&gt;the values of the &#39;input&#39; nodes.\n&gt;\n&gt;You zero out the state of all neurons only ONCE.  AT the beginning of\n&gt;the simulation.\n&gt;\n&gt;Then, for a single time-step, you fire each neuron in the order that\n&gt;it exists in the list.  The first time through, if a connection refers\n&gt;to a neuron that hasn&#39;t fired yet, the output of that neuron is 0, so\n&gt;the input value that is sent to the firing neuron is zero.\n&gt;\n&gt;At the end of that firing pass, you process the outputs, update the\n&gt;&#39;real world&#39; of the simulation, and alter the inputs accordingly.  DO\n&gt;NOT RESET ANYTHING INSIDE THE NETWORK!  This continues in an infinite\n&gt;loop until an exit condition is met, namely either failure of the\n&gt;network to meet its objective in a timely fashion, or success in\n&gt;accomplishing the desired goal.\n&gt;\n&gt;Make sense?  Again, you only reset neurons once, at the beginning of\n&gt;fitness testing (for a given scenario).  From that moment on, a\n&gt;neuron&#39;s value is retained for the next time it is accessed.\n&gt;\n&gt;Here&#39;s the difference between this approach and the &#39;canonical&#39;\n&gt;approach.  In the canonical approach you have two values for every\n&gt;neuron:  Last timestep&#39;s value, and this timestep&#39;s value.  Or\n&gt;&quot;beginning value&quot; and &quot;ending value&quot;.  For input neurons, they are\n&gt;always one and the same.  Whenever a neuron references the value of\n&gt;another neuron, it always inspects the OLD or beginning value.  Then,\n&gt;it doesn&#39;t matter what order you process the nodes in.  You process\n&gt;every node, one by one, always referencing the old value of that\n&gt;neuron.  And you write the new value of the node you are working on to\n&gt;the other or ending value.\n&gt;\n&gt;In a standard feed-forward network with 3 hidden layers, the first\n&gt;timestep will only propagate the signal one layer down.  At which\n&gt;point, in a &#39;simulation&#39;, the real world inputs may change.  Now, the\n&gt;value of the first hidden layer has been changed, so the second layer\n&gt;will be calculated using those modified values.  But the inputs may\n&gt;have changed, so the first layer will change.  But no matter, the\n&gt;second layer is being calculated using the values that were present in\n&gt;the first hidden layer at the end of the last time step.\n&gt;\n&gt;The &#39;optimized&#39; approach that I was advocating doesn&#39;t bother having a\n&gt;&#39;before&#39; and an &#39;after&#39; (or last and current) value.  It just has a\n&gt;value.  When another node references the value of a node, it\n&gt;references the current value of that node.  As soon as that node gets\n&gt;calculated, the value of the node changes.  In a recurrent network,\n&gt;some nodes my reference the value of a particular node BEFORE it was\n&gt;updated, and others may reference it AFTER.  For the puritan, that\n&gt;&#39;unpredictability&#39; would be undesirable.  But since you are evolving a\n&gt;network that WORKS, that argument becomes purely academic.\n&gt;\n&gt;Unless of course tests show that for a particular experiment it\n&gt;requires more topology to solve the same problem using the one firing\n&gt;mechanism over the other.  In that case, the academic argument against\n&gt;doing it does in fact hold weight.\n&gt;\n&gt;But again, it only matters for a controller, not for a classifier\n&gt;network that is non-recurrent.  So if you are evolving a non-recurrent\n&gt;classifier, and CPU time matters (both during evolution and in the\n&gt;final product), then this optimized routine is for you.  Otherwise,\n&gt;I&#39;d make both activation schemes available, and test evolve networks\n&gt;using both mechanisms, to find out whether or not it makes a\n&gt;difference in the ability to evolve a solution.\n&gt;\n&gt;Honestly, I can see that there might be pathological cases where this\n&gt;firing approach would hinder the evolution of a solution to a\n&gt;controller.  But only for a particular class of problem, and it would\n&gt;just mean that the successful topology will be different under the one\n&gt;approach than it would have been under the other approach.  The\n&gt;chances of it being possible to evolve a solution under one approach\n&gt;that is impossible to evolve using the other approach are very slim.\n&gt;But only experience can tell us if that is true or not.  :p\n&gt;\n&gt;On 8/31/05, maitrikaruna &lt;kevin@...&gt; wrote:\n&gt; &gt; John,\n&gt; &gt;\n&gt; &gt; thanks for the reply...wish we were all at a whiteboard together in\n&gt; &gt; which case we could come up with an elegant solution rather\n&gt; &gt; quickly...\n&gt; &gt;\n&gt; &gt; I understand all that you said, but it still creates problems.  The\n&gt; &gt; idea of recurrency is that it stores a memory that allows the net to\n&gt; &gt; anticipate and strategize based on a prior world state.\n&gt; &gt;\n&gt; &gt; Suppose I follow your idea of activating the net in several steps,\n&gt; &gt; moving my agent in those time steps if the net says to do it, but\n&gt; &gt; not checking the new world state.\n&gt; &gt;\n&gt; &gt; After these several timesteps, I assume I should re-initialize the\n&gt; &gt; inputs to all the neurons to zero.  Then I re-scan the &quot;world&quot;, get\n&gt; &gt; my inputs, and do it all again.  But this resetting and rescanning\n&gt; &gt; implies no memory of a prior world state since in our internal\n&gt; &gt; timesteps we did not consider the world inputs again until we were\n&gt; &gt; done with our net activation.  Does this make sense?\n&gt; &gt;\n&gt; &gt; I have come up with my own way to handle this and I&#39;m coding it\n&gt; &gt; as we speak.  Following is what I propose:\n&gt; &gt;\n&gt; &gt; 1) I do exactly what John suggested, I have a nice and tight\n&gt; &gt; recursive routine that quickly determines dependencies, which\n&gt; &gt; includes recursive dependencies\n&gt; &gt;\n&gt; &gt; 2) I then activate each neuron that has all its depedencies\n&gt; &gt; fulfilled/processed iteratively, unitl ALL neurons have been\n&gt; &gt; processed.  I also process recurrent links here, BUT if it is\n&gt; &gt; timestep 0, i store the recurrent value in its own place separate\n&gt; &gt; from the neurons non-recurrent, total inputs.  Importantly, at\n&gt; &gt; timestep 0 these recurrent weights are NOT considered in the\n&gt; &gt; firing/non-firing decision of the neuron.\n&gt; &gt;\n&gt; &gt; 3) if the output neurons tell the agent to move, it does so.\n&gt; &gt;\n&gt; &gt; 4) reset ALL the neurons...BUT, if its not timestep 0, then keep the\n&gt; &gt; recurrent totals in the neurons that had a recurrent link back to\n&gt; &gt; them..otherwise erset all neurons totals including recurrent totals\n&gt; &gt;\n&gt; &gt; 5) get the new state of the world..meaning read the input values..\n&gt; &gt;\n&gt; &gt; 6) process the net as above...if it is not timestep 0, then when\n&gt; &gt; making a fire/not-fire decision, we total the inputs for a neuron\n&gt; &gt; PLUS the recurrent values from the last net execution....so this is\n&gt; &gt; the memory of the prior state being used.\n&gt; &gt;\n&gt; &gt; 7) repeat all the above...\n&gt; &gt;\n&gt; &gt; This seems like a practical approach to me that should work,\n&gt; &gt; although I haven&#39;t got it working yet.. The code to fire the\n&gt; &gt; network, even knowing dependencies, is a little tricky.\n&gt; &gt;\n&gt; &gt; Hope this all makes some sense...hard to describe via written note...\n&gt; &gt;\n&gt; &gt; --Kevin\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt;\n\n\nIn fifteen minutes, everybody will be in the future.\n\n\n\n\t\t\n___________________________________________________________ \nTo help you stay safe and secure online, we&#39;ve developed the all new Yahoo! Security Centre. http://uk.security.yahoo.com\r\n\n"}}