{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":82117382,"authorName":"Jim O&#39;Flaherty, Jr.","from":"&quot;Jim O&#39;Flaherty, Jr.&quot; &lt;jim_oflaherty_jr@...&gt;","profile":"jim_oflaherty_jr","replyTo":"LIST","senderId":"V2rhR2xUuKoA0m5Q7gHEMmelmDxatI6qVjNblgvShU27wWhmtRcFqlqjq7Dy7wVaw6IdZOxffemk_V4czcWIq0bzgQTRiG7xh5lR01DS2mhjO5AJD-mnpmA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"An ANN design question...","postDate":"1090591494","msgId":1228,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDQwNzIzMTQwNDU0LjEyNzQ2LnFtYWlsQHdlYjUyODA2Lm1haWwueWFob28uY29tPg==","inReplyToHeader":"PEJBWTItRjY4Qmk4OVF0cGZUWVMwMDAwMDBiNEBob3RtYWlsLmNvbT4="},"prevInTopic":1227,"nextInTopic":1229,"prevInTime":1227,"nextInTime":1229,"topicId":1226,"numMessagesInTopic":19,"msgSnippet":"Ken, As I have written previously here, I am working on an optimized ANN implementation in Java which I have named SEMIANN (Sparsely Evaluated Matrix Interace","rawEmail":"Return-Path: &lt;jim_oflaherty_jr@...&gt;\r\nX-Sender: jim_oflaherty_jr@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 33437 invoked from network); 23 Jul 2004 14:04:56 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m4.grp.scd.yahoo.com with QMQP; 23 Jul 2004 14:04:56 -0000\r\nReceived: from unknown (HELO web52806.mail.yahoo.com) (206.190.39.170)\n  by mta2.grp.scd.yahoo.com with SMTP; 23 Jul 2004 14:04:56 -0000\r\nMessage-ID: &lt;20040723140454.12746.qmail@...&gt;\r\nReceived: from [205.158.160.209] by web52806.mail.yahoo.com via HTTP; Fri, 23 Jul 2004 07:04:54 PDT\r\nDate: Fri, 23 Jul 2004 07:04:54 -0700 (PDT)\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;BAY2-F68Bi89QtpfTYS000000b4@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nX-eGroups-Remote-IP: 206.190.39.170\r\nFrom: &quot;Jim O&#39;Flaherty, Jr.&quot; &lt;jim_oflaherty_jr@...&gt;\r\nSubject: An ANN design question...\r\nX-Yahoo-Group-Post: member; u=82117382\r\nX-Yahoo-Profile: jim_oflaherty_jr\r\n\r\nKen,\n\nAs I have written previously here, I am working on an optimized ANN implementation in Java which I\nhave named SEMIANN (Sparsely Evaluated Matrix Interace Artificial Neural Network).\n\nIn a meeting with Derek and Philip, we were reviewing my design and comparing it with the design\nthey are currently using derived from your NEAT ANN design.  What showed up was a small difference\nin how I am handling the input data versus how it is being handled in their NEAT implementation.\n\nIt is my understanding from the small number of ANN implementations I have seen (around 5)\nincluding that of David Fogel (author of book titled &quot;Blondie24&quot; from which I am duplicating\nexperiments), the input data is placed directly into the input node.  The data is not bounded\n(other than the actual limits of a float or double).  And the input node does *not* have an\nactivation function.  The unbounded data present in the input node is then used in the activation\nof the hidden nodes (simple 3 layer feed forward network).  Any sort of altering the input data is\nthen handled by the weight attached to that input node.  The GA process will then drift the\nweights around such that inputs which are not so valuable are muted with smaller weight values. \nAnd inputs which are important are magnified with higher weight values.  And all of these weights\nwill eventually form a function over which the input data is �normalized� based on each input�s\nrelative importance, a sort of first approximation of the input data�s inter-relatedness.\n\nIn contrast, Philip and Derek indicated an input data point entering their ANN implementation is\nactually being pushed through the input node&#39;s activation function.  Then the &quot;modified&quot; data\npoint is now placed into the input node.  It is then used in the activation of the &quot;hidden&quot; nodes.\n\nIn talking through the difference, we talked about how that might impact the efficacy of the\nevolving ANN.  In other words, by having the input data go through an activation function without\ntheir being a weight involved, it seems the input data is being skewed, meaningful data is lost \nwith no opportunity for the GA to compensate prior to the data loss.  Essentially, some data is\nlost.  In pure mathematical terms, this implmentation provides a weight of 1.0 multiplied by the\nunbounded input value which is then submitted to the input node&#39;s activation function with the\nresult of the function being placed into the input node.\n\nMy immediate response was this: the skewing seems like it would make it more difficult for the ANN\nto generate associations to the inputs that range outside of the bounds of the activation\nfunction.  For example, in replicating Fogel&#39;s experiments, I am using the hyperbolic tangent \nbounded -1..1, and the following input values are used: a red checker has the value of 1.0, a\nblack check has the value of -1.0, a red king has the value of 1.5, and a black king has the value\nof -1.5.\n\nNow, I know that Fogel was expecting the inputs to be related directly, as a ratio, as he\ndiscusses this at some length in his book.  He left it up to the GA/ANN to work out the optimal\nratio relationship.  Additionally, the king&#39;s value was a GA parameter which was bounded between\n1.0 and 3.0 and could randomly change by +/- 0.1 when a parent was generating a descendant.\n\nWith the approach Philip and Derek have taken (and they said theirs is modeled after your design),\nit seems like the ratio gets perverted by the activation function on the input node.  So as input\nvalues fall further and further from the activation function bounds, relationships between inputs\noutside of the bounds are eventually lost due to approximation/rounding errors in the IEEE float\nor double.  Or so it seems to me.\n\nSo my questions are this:\nA) What is the theoretical or mathematical explanation as to why the input values for NEAT are\npushed through an input node�s activation function as opposed to being used directly?\nB) Does some form of assumption exist in which to provide input to a NEAT ANN, the input data\npoint for each input node must be scaled such that the data point�s relevant range of values falls\nbetween the upper and lower bounds of the input node�s activation function?\nC) What kinds of different types of activation functions on an input node might possibly handle\nthis differently and/or more effectively?\n\nSidenote: In SEMIANN, I do not allow a connection to have a destination of an input node.  So\nthere is no need for an activation function at an input node.  And input node is treated as just\nan unbounded data point.  It was my understanding that if there was to be feedback to the �input�,\nit would occur as new nodes and connections around the hidden/output nodes from which the\nparticular input node was connected.\n\nWell, that sort of took much longer to present than I initially thought.  Hmmm�\n\nThank you for any clarification(s) you can offer on this.\n\n\nJim O�Flaherty, Jr.\n\n\n\n"}}