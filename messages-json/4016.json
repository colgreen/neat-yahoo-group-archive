{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"_DYtn1laUUAh_ljmO7-UPL7FlepfRu5nSX9Ga-Dxu2GsrES14JF9vdn78t-gHmiS8nyxE7UArNxjgbqx3kWYQMNSe2FGlUdvYO-yly28u1dR","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Machine Learning and the Long View of AI","postDate":"1209537066","msgId":4016,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ2OTNuYStsaXB1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PFdvcmxkQ2xpZW50LUYyMDA4MDQyOTA4MTQuQUExNDMxMDAyM0BvY3RhZ2F0ZS5jb20+"},"prevInTopic":4015,"nextInTopic":4017,"prevInTime":4015,"nextInTime":4017,"topicId":3955,"numMessagesInTopic":49,"msgSnippet":"Mattias, I respond below to your comments. ... on my ... able to ... nodes, ... Any implication I m making that NE will eventually produce a brain that","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 10916 invoked from network); 30 Apr 2008 06:31:09 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m50.grp.scd.yahoo.com with QMQP; 30 Apr 2008 06:31:09 -0000\r\nX-Received: from unknown (HELO n18d.bullet.scd.yahoo.com) (66.218.67.59)\n  by mta18.grp.scd.yahoo.com with SMTP; 30 Apr 2008 06:31:09 -0000\r\nX-Received: from [209.73.164.83] by n18.bullet.scd.yahoo.com with NNFMP; 30 Apr 2008 06:31:08 -0000\r\nX-Received: from [66.218.66.84] by t7.bullet.scd.yahoo.com with NNFMP; 30 Apr 2008 06:31:08 -0000\r\nDate: Wed, 30 Apr 2008 06:31:06 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fv93na+lipu@...&gt;\r\nIn-Reply-To: &lt;WorldClient-F200804290814.AA14310023@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Machine Learning and the Long View of AI\r\nX-Yahoo-Group-Post: member; u=54567749; y=IsDtsmVtrLEBLpQCb9sNIptVw9bx3WlA2WEHmKF3Xnut3cUfgsTp\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nMattias,\n\nI respond below to your comments.\n \n&gt; Ken, you&#39;re saying that NE =\r\nwill eventually be able to do what one might\n&gt; call symbolic reasoning? I c=\r\nan&#39;t wrap my head around that (a failing\non my\n&gt; part), any papers I should=\r\n read that broaches the subject? Clearly, our\n&gt; brain which does symbolic r=\r\neasoning can handle it, so NE should be\nable to\n&gt; do the same, but how to r=\r\nepresent it with input, output and hidden\nnodes,\n&gt; that&#39;s a little beyond m=\r\ne at the moment.\n\nAny implication I&#39;m making that NE will eventually produc=\r\ne a brain\nthat performs symbolic reasoning is just long-term speculation.  =\r\nI\nhave no idea how such a structure would work either.  However, I do\nbelie=\r\nve that it is theoretically possible (since I believe the human\nbrain is a =\r\nkind of neural network) and my feeling is that the most\npromising path to p=\r\nroducing anything with overall general intelligence\ninvolves a neuroevoluti=\r\nonary component.  However, I am speaking about\na process that could take 10=\r\n0 years, so it&#39;s just a philosophical\nhunch.  Still, the benefit of this ap=\r\nproach is that we end up never\nhaving to figure out how a neural network ca=\r\nn do symbolic reasoning\nbecause that would simply evolve on its own, assumi=\r\nng that I am\ncorrect.  But again, I am not expecting that any time soon.\n\n&gt;=\r\n \n&gt; One practical problem I have with HyperNEAT is that we&#39;re back to\ndecid=\r\ning\n&gt; the number of hidden node layers, and the number of nodes in each lay=\r\ner\n&gt; for the phenotype. Any thoughts on how to handle that gracefully? A\nbr=\r\nute\n&gt; force solution would simply be to provide each genotype with some\nkin=\r\nd of\n&gt; evolvable descriptor that would determine the hidden nodes. But\nmayb=\r\ne that\n&gt; could be represented within the genotype instead?\n&gt; \n\nI agree that=\r\n a method to automatically decide the configuration of\nnodes (particularly =\r\nhidden nodes) on the substrate is an attractive\nnext step.  I have some vag=\r\nue pre-algorithmic ideas how this might be\ndone, but I have not myself seen=\r\n nor thought of the kind of elegant\napproach that would make me feel like t=\r\nhe problem was solved.  As you\nsay, we could just add a kind of descriptor,=\r\n but that has an ad hoc\nfeeling to it that doesn&#39;t seem right.  I believe t=\r\nhere is a more\nimplicit, seamless way to do it that will turn out to be an\n=\r\nabstraction of the natural evolutionary mechanism that cause brains to\nincr=\r\nease in size and density (I want to read more about that topic). \nHowever, =\r\nI don&#39;t have the full idea of what that is yet.\n\n&gt; One very interesting exp=\r\neriment I&#39;d like to see done (or do myself); if\n&gt; the genotype decides the =\r\nhidden nodes, can HyperNEAT successfully cross\n&gt; two genotypes which differ=\r\nent hidden node targets? It should be\npossible,\n&gt; consider humans with our =\r\n46 chromosomes. There must have been a point\n&gt; where one person had say 44 =\r\nchromosomes but doubled up on one of them,\n&gt; ending up with 46. Then that p=\r\nerson mated with another person with the\n&gt; usual 44 chromosomes, and succes=\r\nsfully so. The reason it worked at\nall is\n&gt; probably because the chomosomes=\r\n were very similar, or even identical,\n&gt; making the evolutionary landscape =\r\n_fairly_ even when it comes to\n&gt; chromosome duplications (99.9999...% of al=\r\nl chromosome duplications must\n&gt; have resulted in abortion or sterility, bu=\r\nt still).\n&gt; \n&gt; Since HyperNEAT uses continuous functions to describe the co=\r\nnnection\n&gt; weights, that could possibly imply that the same evenness. It&#39;s\n=\r\nimpossible\n&gt; to know without testing, but if we could mate one individual w=\r\nith one\n&gt; hidden layer with another individual with two hidden layers and g=\r\net\nviable\n&gt; offspring (preferably stronger), that would be spectacular. Wel=\r\nl, I\nwould\n&gt; think so anyway ;)\n&gt; \n\nI think HyperNEAT could cross two indiv=\r\niduals with different numbers\nof hidden nodes on their substrates (I&#39;m assu=\r\nming you mean in the\nsubstrates as opposed to the CPPNs) and produce someth=\r\ning that still\nworks fine.  However, that idea still begs the question of w=\r\nhat\nmechanism decides the hidden node configuration on the offspring\nsubstr=\r\nate, since that is currently decided only by the user.  But no\nmatter what =\r\nthe mechanism, I believe it will sometimes work out fine\nas a cross, becaus=\r\ne the underlying patterns are compatible.  However,\nit will not work every =\r\ntime because radically different densities of\nnodes will be potentially too=\r\n far diverged from each other in the\npatterns that connect those nodes in p=\r\nractice.\n\nBy the way, I was a little unsure in your analogy whether we are\n=\r\ntalking about genotype or phenotype since chromosomes are in the\ngenotype b=\r\nut hidden nodes on the substrate are in the phenotype. \nHopefully I address=\r\ned what you meant to be suggesting.\n\n&gt; As for the 0.2 weight threshold bein=\r\ng arbitrary, sure it&#39;s\narbitrary, but\n&gt; it&#39;s the landscape that evolution w=\r\norks with, it&#39;s as arbitrary as g\n&gt; (gravity)=3D9.81, if g would have been =\r\nsay 5, animals would have been\n&gt; different but no less successfull. Thus us=\r\ning a weight threshold of\n&gt; 0.1-0.3 would probably not change the results s=\r\nignificantly -another\n&gt; interesting experiment though. Where are the limits=\r\n for the\nthreshold? Too\n&gt; close to 0 and the number of connections will exp=\r\nlode. To close to 1 and\n&gt; sigmoid nodes will have a hard time generating co=\r\nnnections, and their\n&gt; connection weight resolution would be seriously comp=\r\nromised.\n&gt; \n\nWe&#39;ve played with that threshold and just came to 0.2 as seemi=\r\nng to\nwork pretty well.  The truth is I&#39;m not sure if you even need a\nthres=\r\nhold in practice  (you could just let all connections be\ninstantiated), but=\r\n it seems nice at least in principle to let\nevolution exclude some connecti=\r\nons.  I agree though that the matter of\nthe threshold is not the most funda=\r\nmentally interesting.\n\nken\n\n\n\n\n"}}