{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":184928113,"authorName":"Evert Haasdijk","from":"Evert Haasdijk &lt;evert@...&gt;","profile":"evertwh2004","replyTo":"LIST","senderId":"8S5zLaV9bbhfoyLq-qxYJnMoHKoAMAg8cyN56Qsy7vG3Fre0cU4J89tPdhWC_ltpTJJbw9P1fPzSymo8P7s0YXbRYQx1tJaOZI8o-jxh","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New paper â€žHyperNEAT for Locomotio n Control in Modular Robots","postDate":"1277025886","msgId":5266,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEU2OEM2NUI0LTZBN0UtNDBEMy1BODlDLTQzQTFCOENGMzA5NEB6dWtrZXNwaWprZXJzLm5sPg==","inReplyToHeader":"PEM4NDI3ODM0LjMzNThDJWpjbHVuZUBtc3UuZWR1Pg==","referencesHeader":"PEM4NDI3ODM0LjMzNThDJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":5264,"nextInTopic":5269,"prevInTime":5265,"nextInTime":5267,"topicId":5251,"numMessagesInTopic":6,"msgSnippet":"Hi Jeff, Thanks for the interest and kind words. It was a fun experiment and we are enthusiastically moving forward with it. I ll try and get some videos out","rawEmail":"Return-Path: &lt;evert@...&gt;\r\nX-Sender: evert@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 81037 invoked from network); 20 Jun 2010 09:24:50 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m10.grp.re1.yahoo.com with QMQP; 20 Jun 2010 09:24:50 -0000\r\nX-Received: from unknown (HELO smtp-vbr1.xs4all.nl) (194.109.24.21)\n  by mta1.grp.sp2.yahoo.com with SMTP; 20 Jun 2010 09:24:49 -0000\r\nX-Received: from [192.168.42.46] (a82-95-199-237.adsl.xs4all.nl [82.95.199.237])\n\t(authenticated bits=0)\n\tby smtp-vbr1.xs4all.nl (8.13.8/8.13.8) with ESMTP id o5K9OmNI093767\n\t(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=NO)\n\tfor &lt;neat@yahoogroups.com&gt;; Sun, 20 Jun 2010 11:24:48 +0200 (CEST)\n\t(envelope-from evert@...)\r\nMime-Version: 1.0 (Apple Message framework v1078)\r\nContent-Type: multipart/alternative; boundary=Apple-Mail-1-218460012\r\nDate: Sun, 20 Jun 2010 11:24:46 +0200\r\nIn-Reply-To: &lt;C8427834.3358C%jclune@...&gt;\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;C8427834.3358C%jclune@...&gt;\r\nMessage-Id: &lt;E68C65B4-6A7E-40D3-A89C-43A1B8CF3094@...&gt;\r\nX-Mailer: Apple Mail (2.1078)\r\nX-Virus-Scanned: by XS4ALL Virus Scanner\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Evert Haasdijk &lt;evert@...&gt;\r\nSubject: =?windows-1252?Q?Re:_[neat]_New_paper_=84HyperNEAT_for_Locomotio?=\n =?windows-1252?Q?n_Control_in_Modular_Robots?=\r\nX-Yahoo-Group-Post: member; u=184928113; y=-gOAcv_8q8JfskLXo36CTwPyG_LQwJoDoIm1oygj9QiPVmKHU-c\r\nX-Yahoo-Profile: evertwh2004\r\n\r\n\r\n--Apple-Mail-1-218460012\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/plain;\n\tcharset=windows-1252\r\n\r\nHi Jeff,\n\nThanks for the interest and kind words. It was a fun experiment a=\r\nnd we are enthusiastically moving forward with it. I&#39;ll try and get some vi=\r\ndeos out this week.\n\n&gt; Your paper prompted a few questions in my mind:\n&gt; \n&gt;=\r\n 1) Why did you use the &#39;habituation&#39; model for inputs (where you only\n&gt; ge=\r\nnerate inputs values for new stimuli)? Did you only try this after the\n&gt; mo=\r\nre traditional way of doing it (just feeding the raw range-finder inputs\n&gt; =\r\ninto the network) did not work?\n\nAs you suggest, it was the result of some =\r\ntrial-and-error; it is fairly straightforward to achieve steady -i.e., non-=\r\nreactive- locomotion without any sensors. It proved much harder to get any =\r\nreactivity (i.e., negotiating obstacles) into the behaviour. Using raw rang=\r\ne-finder inputs didn&#39;t produce that, that led us to try the habituation mod=\r\nel. That being said, we&#39;re still working towards more prominent obstacle av=\r\noidance/negotiation.\n\n&gt; \n&gt; 2) I really liked your idea of having a default =\r\nbehavior (controlled by the\n&gt; biases in the output layer), with the rest of=\r\n the ANN only getting non-zero\n&gt; inputs when objects are sensed. Did you ev=\r\nolve the biases too, or hand code\n&gt; them in some way? If you evolved them, =\r\nwhat method did you use (what were\n&gt; the coordinates of the source/from nod=\r\ne fed into the CPPN when querying for\n&gt; a bias value)?\n\nAll the substrate w=\r\neights were determined by the evolved CPPN. I&#39;m not entirely sure about the=\r\n technical detail of the biases, I hope Andrei (who&#39;s on this mailing list =\r\nas well) will answer this one in more detail.\n\n&gt; \n&gt; 3) You say that the fac=\r\nt that some of the lines are different in figure 9\n&gt; indicates that the ANN=\r\n modules are different (in their wiring and function).\n&gt; But wouldn&#39;t you s=\r\nee different lines even with identical controllers in each\n&gt; module because=\r\n different modules are getting different inputs (e.g. when one\n&gt; leg moves =\r\nclose to a wall)?\n\nThe spikes in the graphs are caused by obstacles coming =\r\ninto or disappearing from sensor range. The base levels of the graphs (part=\r\nicularly different in 9c) differ only because of modular differentiation. I=\r\n think, but can&#39;t be certain without further analysis, that the direction a=\r\nnd magnitude of the spikes differs in part because of modular differentiati=\r\non, as well.\n\n\n&gt; \n&gt; 4) Did you see any symmetry (e.g. left-right) or other =\r\nform of regularity in\n&gt; the gaits (like I see in my HyperNEAT-evolved gaits=\r\n)?\n\nYes we did: typically, after a certain  amount of evolution, we would s=\r\nee symmetrical movement between the left and right legs. Not at all somethi=\r\nng that we pressed for; it just emerged.\n\nCheers,\n\nEvert\n\n&gt; \n&gt; Overall I lo=\r\nved the work and look forward to more. Thanks again for the kind\n&gt; acknowle=\r\ndgement. \n&gt; \n&gt; Best regards,\n&gt; Jeff Clune\n&gt; \n&gt; Digital Evolution Lab, Michi=\r\ngan State University\n&gt; jclune@...\n&gt; www.msu.edu/~jclune\n&gt; \n&gt; &gt; From: ev=\r\nertwh2004 &lt;evert@...&gt;\n&gt; &gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;ne=\r\nat@yahoogroups.com&gt;\n&gt; &gt; Date: Fri, 04 Jun 2010 15:00:34 -0000\n&gt; &gt; To: &quot;neat=\r\n@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; Subject: [neat] New paper =84H=\r\nyperNEAT for Locomotion Control in Modular Robots=89\n&gt; &gt; \n&gt; &gt; We are very p=\r\nleased to announce our new publication &quot;HyperNEAT for Locomotion\n&gt; &gt; Contro=\r\nl in Modular Robots,&quot; which will appear in the proceedings of the 9th\n&gt; &gt; I=\r\nnternational Conference on Evolvable Systems (ICES 2010). The manuscript is=\r\n\n&gt; &gt; available here:\n&gt; &gt; \n&gt; &gt; http://www.few.vu.nl/~ehaasdi/papers/Modular-=\r\nLocomotion.pdf\n&gt; &gt; \n&gt; &gt; In this paper we introduce the idea of modular diff=\r\nerentiation with HyperNEAT:\n&gt; &gt; we use a HyperNEAT encoding to generate hom=\r\nogeneous (in the literal sense) but\n&gt; &gt; varying neural network controllers =\r\nfor individual robot modules that are\n&gt; &gt; linked together into a larger `or=\r\nganism.&#39; These controllers allow the\n&gt; &gt; multi-robot to locomote purposeful=\r\nly and even somewhat reactively.\n&gt; &gt; This paper constitutes a proof of conc=\r\nept and we hope to expand on this work\n&gt; &gt; to allow HyperNEAT-based control=\r\n in arbitrary and ultimately developing\n&gt; &gt; multi-robot organisms.\n&gt; &gt; \n&gt; &gt;=\r\n We would like to thank Jeff Clune for pointing HyperNEAT out to us and\n&gt; &gt;=\r\n everyone on this list - Ken Stanley especially - for the fruitful\n&gt; &gt; disc=\r\nussions.\n&gt; &gt; \n&gt; \n&gt; \n\n\r\n--Apple-Mail-1-218460012\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/html;\n\tcharset=windows-1252\r\n\r\n&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode:=\r\n space; -webkit-line-break: after-white-space; &quot;&gt;Hi Jeff,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;di=\r\nv&gt;Thanks for the interest and kind words. It was a fun experiment and we ar=\r\ne enthusiastically moving forward with it. I&#39;ll try and get some videos out=\r\n this week.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div st=\r\nyle=3D&quot;background-color: rgb(255, 255, 255); position: static; z-index: aut=\r\no; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-ms=\r\ng&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;div&gt;Your paper prompted a f=\r\new questions in my mind:&lt;br&gt;\n&lt;br&gt;\n1) Why did you use the &#39;habituation&#39; mode=\r\nl for inputs (where you only&lt;br&gt;\ngenerate inputs values for new stimuli)? D=\r\nid you only try this after the&lt;br&gt;\nmore traditional way of doing it (just f=\r\needing the raw range-finder inputs&lt;br&gt;\ninto the network) did not work?&lt;br&gt;&lt;=\r\n/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As you sugges=\r\nt, it was the result of some trial-and-error; it is fairly straightforward =\r\nto achieve steady -i.e., non-reactive- locomotion without any sensors. It p=\r\nroved much harder to get any reactivity (i.e., negotiating obstacles) into =\r\nthe behaviour. Using raw range-finder inputs didn&#39;t produce that, that led =\r\nus to try the habituation model. That being said, we&#39;re still working towar=\r\nds more prominent obstacle avoidance/negotiation.&lt;/div&gt;&lt;br&gt;&lt;blockquote type=\r\n=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: sta=\r\ntic; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;=\r\ndiv id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;div&gt;\n&lt;br&gt;\n=\r\n2) I really liked your idea of having a default behavior (controlled by the=\r\n&lt;br&gt;\nbiases in the output layer), with the rest of the ANN only getting non=\r\n-zero&lt;br&gt;\ninputs when objects are sensed. Did you evolve the biases too, or=\r\n hand code&lt;br&gt;\nthem in some way? If you evolved them, what method did you u=\r\nse (what were&lt;br&gt;\nthe coordinates of the source/from node fed into the CPPN=\r\n when querying for&lt;br&gt;\na bias value)?&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/bl=\r\nockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the substrate weights were determined by t=\r\nhe evolved CPPN. I&#39;m not entirely sure about the technical detail of the bi=\r\nases, I hope Andrei (who&#39;s on this mailing list as well) will answer this o=\r\nne in more detail.&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;backgro=\r\nund-color: rgb(255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;=\r\nz-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;div&gt;\n&lt;br&gt;\n3) You say that the fact that=\r\n some of the lines are different in figure 9&lt;br&gt;\nindicates that the ANN mod=\r\nules are different (in their wiring and function).&lt;br&gt;\nBut wouldn&#39;t you see=\r\n different lines even with identical controllers in each&lt;br&gt;\nmodule because=\r\n different modules are getting different inputs (e.g. when one&lt;br&gt;\nleg move=\r\ns close to a wall)?&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;=\r\n&lt;/div&gt;&lt;div&gt;The spikes in the graphs are caused by obstacles coming into or =\r\ndisappearing from sensor range. The base levels of the graphs (particularly=\r\n different in 9c) differ only because of modular differentiation. I think, =\r\nbut can&#39;t be certain without further analysis, that the direction and magni=\r\ntude of the spikes differs in part because of modular differentiation, as w=\r\nell.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div styl=\r\ne=3D&quot;background-color: rgb(255, 255, 255); position: static; z-index: auto;=\r\n &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot;=\r\n style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;div&gt;\n&lt;br&gt;\n4) Did you see any =\r\nsymmetry (e.g. left-right) or other form of regularity in&lt;br&gt;\nthe gaits (li=\r\nke I see in my HyperNEAT-evolved gaits)?&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;=\r\n/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;Yes we did: typically, after a certain &nbsp;amo=\r\nunt of evolution, we would see symmetrical movement between the left and ri=\r\nght legs. Not at all something that we pressed for; it just emerged.&lt;/div&gt;&lt;=\r\ndiv&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cheers,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Evert&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;bl=\r\nockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); =\r\nposition: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position=\r\n:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text=\r\n&quot;&gt;&lt;div&gt;\n&lt;br&gt;\nOverall I loved the work and look forward to more. Thanks agai=\r\nn for the kind&lt;br&gt;\nacknowledgement.  &lt;br&gt;\n&lt;br&gt;\nBest regards,&lt;br&gt;\nJeff Clune=\r\n&lt;br&gt;\n&lt;br&gt;\nDigital Evolution Lab, Michigan State University&lt;br&gt;\n&lt;a href=3D&quot;m=\r\nailto:jclune%40msu.edu&quot;&gt;jclune@...&lt;/a&gt;&lt;br&gt;\n&lt;a href=3D&quot;http://www.msu.ed=\r\nu/~jclune&quot;&gt;www.msu.edu/~jclune&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&gt; From: evertwh2004 &lt;&lt;a h=\r\nref=3D&quot;mailto:evert%40zukkespijkers.nl&quot;&gt;evert@...&lt;/a&gt;&gt;&lt;br&gt;\n=\r\n&gt; Reply-To: &quot;&lt;a href=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.=\r\ncom&lt;/a&gt;&quot; &lt;&lt;a href=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.com=\r\n&lt;/a&gt;&gt;&lt;br&gt;\n&gt; Date: Fri, 04 Jun 2010 15:00:34 -0000&lt;br&gt;\n&gt; To: &quot;&lt;a hr=\r\nef=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.com&lt;/a&gt;&quot; &lt;&lt;a href=\r\n=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.com&lt;/a&gt;&gt;&lt;br&gt;\n&gt; Su=\r\nbject: [neat] New paper =84HyperNEAT for Locomotion Control in Modular Robo=\r\nts=89&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; We are very pleased to announce our new  publicati=\r\non &quot;HyperNEAT for Locomotion&lt;br&gt;\n&gt; Control in Modular Robots,&quot; which wil=\r\nl appear in the proceedings of the 9th&lt;br&gt;\n&gt; International Conference on=\r\n Evolvable Systems (ICES 2010). The manuscript is&lt;br&gt;\n&gt; available here:&lt;=\r\nbr&gt;\n&gt; &lt;br&gt;\n&gt; &lt;a href=3D&quot;http://www.few.vu.nl/~ehaasdi/papers/Modular-=\r\nLocomotion.pdf&quot;&gt;http://www.few.vu.nl/~ehaasdi/papers/Modular-Locomotion.pdf=\r\n&lt;/a&gt;&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; In this paper we introduce the idea of modular diff=\r\nerentiation with HyperNEAT:&lt;br&gt;\n&gt; we use a HyperNEAT encoding to generat=\r\ne homogeneous (in the literal sense) but&lt;br&gt;\n&gt; varying neural network co=\r\nntrollers for individual robot modules that are&lt;br&gt;\n&gt; linked together in=\r\nto a larger `organism.&#39; These controllers allow the&lt;br&gt;\n&gt; multi-robot to=\r\n locomote purposefully and even somewhat reactively.&lt;br&gt;\n&gt; This paper co=\r\nnstitutes a proof of concept and we hope to expand on this work&lt;br&gt;\n&gt; to=\r\n allow HyperNEAT-based control in arbitrary and ultimately developing&lt;br&gt;\n&=\r\ngt; multi-robot organisms.&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; We would like to thank Jeff C=\r\nlune for pointing HyperNEAT out to us and&lt;br&gt;\n&gt; everyone on this list  -=\r\n Ken Stanley especially - for the fruitful&lt;br&gt;\n&gt; discussions.&lt;br&gt;\n&gt; &lt;=\r\nbr&gt;\n&lt;br&gt;\n&lt;/div&gt;\n\n    &lt;/div&gt;\n     \n\n    \n\n&lt;/div&gt;\n\n\n\n&lt;!-- end group email --&gt;=\r\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\r\n--Apple-Mail-1-218460012--\r\n\n"}}