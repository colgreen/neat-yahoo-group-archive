{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"9nfoJ2Zk4zPCQyXF2S4oXlochWN0FT5xvyDTBc9wAKOa_zp23RdBW6fFXKSIEmFNzUWh4kDhjdZOSRvF04XZ6ica5VhpP9YDM9FzNEkBG69pXZ3Tkt8","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Evolving Substrates in HyperNEAT","postDate":"1209667436","msgId":4030,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ2ZDMxYythZHJwQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZ2Y3QxZyttYjRlQGVHcm91cHMuY29tPg=="},"prevInTopic":4029,"nextInTopic":4032,"prevInTime":4029,"nextInTime":4031,"topicId":4026,"numMessagesInTopic":10,"msgSnippet":"Hi Ken, I am happy that you find my thoughts interesting. I am trying to find a solution for this but not a constrained one like most. It has to be as general","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 64645 invoked from network); 1 May 2008 18:43:58 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m55.grp.scd.yahoo.com with QMQP; 1 May 2008 18:43:58 -0000\r\nX-Received: from unknown (HELO n30a.bullet.sp1.yahoo.com) (209.131.38.252)\n  by mta16.grp.scd.yahoo.com with SMTP; 1 May 2008 18:43:58 -0000\r\nX-Received: from [216.252.122.216] by n30.bullet.sp1.yahoo.com with NNFMP; 01 May 2008 18:43:58 -0000\r\nX-Received: from [209.73.164.86] by t1.bullet.sp1.yahoo.com with NNFMP; 01 May 2008 18:43:58 -0000\r\nX-Received: from [66.218.66.85] by t8.bullet.scd.yahoo.com with NNFMP; 01 May 2008 18:43:58 -0000\r\nDate: Thu, 01 May 2008 18:43:56 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fvd31c+adrp@...&gt;\r\nIn-Reply-To: &lt;fvct1g+mb4e@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Evolving Substrates in HyperNEAT\r\nX-Yahoo-Group-Post: member; u=283334584; y=z_o6U-4gjsI7en6wi5kiAlSkTaZiFAAilIoC5BjpHDBedkpvJCOEf7fYhQ\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi Ken, \n\nI am happy that you find my thoughts interesting. I am trying to =\r\nfind \na solution for this but not a constrained one like most. It has to be=\r\n \nas general as the whole CPPNs thing and NEAT. Basically I agree with \nyou=\r\nr comments. About the brain, where several different types of \nconnectivity=\r\n exist, it is close to mind that a CPPN can divide the \nspace into segments=\r\n or at least different parts and apply different \nconnectivity concepts for=\r\n each. So in fact it is already capable for \nthis. \n\nMore interesting is th=\r\ne other problem you mentioned about. Well \nfollowing the deeper phylosophy =\r\nbehind NEAT, it is clear that there \nshould not be a bound to complexity. W=\r\ne can easily map 0 to &quot;1 node&quot; \nand 1.0 to &quot;a billion of nodes&quot; but I don&#39;t=\r\n think that evolution \nshould be in that &quot;box&quot; so to say. Another option is=\r\n to use abs(x) as \nthe activation function for the outputting node. This wa=\r\ny it is \nunbounded [0 .. +infinity). Therefore, in order to get to the very=\r\n \nhigh substrate complexity, the weights to this outputting node should \nha=\r\nve very big magnitudes. Which in fact is a good thing since this \nraises th=\r\ne overall weight difference betweeen individuals as well and \nCPPNs with di=\r\nfferent substrate complexity will be in separate \nspecies. So such cases th=\r\nat a billon-nodes brain mating with a \nthousand-nodes brain will not happen=\r\n. \n\nThis reminds me of Mattias&#39;s question, but I can state it in a more \nge=\r\nneralized way: how individuals generating different substrates can \nmate in=\r\n a meaningful way so they do not produce bad offspring? \n\nOne suggestion I =\r\nhave is to change the way speciation is done. We \ncurrently compare genotyp=\r\nes to do speciation. What if we compare \n*phenotypes*? Maybe that is a stup=\r\nid idea, but.. I don&#39;t know. In \nbiology mating is done because the phenoty=\r\npes actually choose each \nother. And they do because they *look* like each =\r\nother. \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@..=\r\n.&gt; wrote:\n&gt;\n&gt; Peter, these are interesting thoughts and similar to the way =\r\nI think\n&gt; about it.  When I think about evolving the substrate, I usually \n=\r\nthink\n&gt; of a distribution of varying densities rather than strict layers or=\r\n\n&gt; preconceived architectures, which is closest to Jeff&#39;s option (c). \n&gt; On=\r\ne reference for me is the human brain:  It has dense masses that\n&gt; look dif=\r\nferent from each other architecturally and do not exist in\n&gt; layers with re=\r\nspect to each other (e.g. the cerebellum vs. the basal\n&gt; ganglia).  However=\r\n, *within* particular masses there is some \nlayering,\n&gt; such as in the neoc=\r\nortex, which is perhaps the most important for\n&gt; high-level intelligence.  =\r\nIt would be nice if all that could just\n&gt; arise on its own to suit the task=\r\n.\n&gt; \n&gt; What you said about CPPN complexity and substrate complexity\n&gt; incre=\r\nasing together is something I never thought of.  It&#39;s an\n&gt; interesting idea=\r\n to correlate the two.  You are right that in \ngeneral\n&gt; there is a problem=\r\n with letting the nodes evolve in the substrate\n&gt; because it is so easy to =\r\nexpress a massive number of nodes, which\n&gt; would not always be needed.\n&gt; \n&gt;=\r\n One problem I see is that we are talking about astronomical ranges, \nso\n&gt; =\r\nthe range in density may not really make sense to vary on a \ncontinuum.\n&gt;  =\r\nFor example, if you have a number between 0 and 1 that represents a\n&gt; densi=\r\nty somehow, then that density may range from several dozen\n&gt; neurons to sev=\r\neral billion (if we are talking about natural \nscales). \n&gt; Does this range =\r\nreally make sense on a continuum between 0 and 1? \n&gt; Maybe we need to scale=\r\n it exponentially or something like that, but\n&gt; still, then you end up with=\r\n a tiny mutation potentially increasing \nthe\n&gt; number of neurons by billion=\r\ns.  That seems odd.  In a way, we&#39;d like\n&gt; to not even be in a circumscribe=\r\nd range and just let increases keep\n&gt; happening indefinitely, but not too m=\r\nuch at a time.\n&gt; \n&gt; Finally, the inputs and outputs may be a special case. =\r\n We may want \nto\n&gt; preserve the current human control of the geometry there=\r\n and only \nlet\n&gt; evolution increase density or something like that.  \n&gt; \n&gt; =\r\nAnyway, this is a great topic and a completely untouched area of\n&gt; research=\r\n with plenty of things left to try.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; \n&gt; --- In neat@yahoogr=\r\noups.com, &quot;petar_chervenski&quot; &lt;petar_chervenski@&gt;\n&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hello Jef=\r\nf, \n&gt; &gt; \n&gt; &gt; I don&#39;t think that such assumptions about layered topology are=\r\n \nthe \n&gt; &gt; way to achieve this. There are two fundamental things associated=\r\n \nwith \n&gt; &gt; any substrate in 2D/3D. These are node presence and node densit=\r\ny. \nIn \n&gt; &gt; fact, skip the first, it just.. it can be thought of as spatial=\r\n \nCPPN \n&gt; &gt; output where the output means the overall node density at that =\r\n\nplace. \n&gt; &gt; And if the output there is less than 0.2, there are no nodes \n=\r\n(sounds \n&gt; &gt; familiar? :)). \n&gt; &gt; \n&gt; &gt; So the same connective CPPN is actual=\r\nly capable of representing \nits \n&gt; &gt; own substrate. But this approach would=\r\n generate too big \nsubstrates. \n&gt; &gt; Even the most simple CPPNs are able to =\r\ngenerate a substrate with \n&gt; &gt; 1000s of nodes and now imagine how many conn=\r\nections there could \nbe. \n&gt; &gt; And this is for the simplest (!) CPPN. That s=\r\nounds like a huge \nwaste \n&gt; &gt; of computational effort, doesn&#39;t it? ;) \n&gt; &gt; =\r\n\n&gt; &gt; So what is needed is a way to restrict the substrate complexity \nfor \n=\r\n&gt; &gt; small CPPNs. Of course more complex CPPNs can be allowed to \ngenerate \n=\r\n&gt; &gt; more complex/dense substrates. \n&gt; &gt; \n&gt; &gt; This is actually just like com=\r\nplexification. First the major \nconcepts \n&gt; &gt; are established on a substrat=\r\ne with very low resolution and as \nthe \n&gt; &gt; CPPNs complexify, the substrate=\r\n becomes more complex. In fact \neach \n&gt; &gt; CPPN will generate a substrate ba=\r\nsed on its complexity (say, \n&gt; &gt; num_nodes+num_links). Oh I think I mention=\r\ned that. \n&gt; &gt; \n&gt; &gt; What I am thinking is, if we actually allow substrates t=\r\no evolve, \n&gt; &gt; does this mean that humans cannot inject that priory geometr=\r\nic \n&gt; &gt; knowledge any more? Or only for the inputs/outputs? \n&gt; &gt; \n&gt; &gt; It es=\r\nsentialy becomes like.. like just a good indirect encoding. \n&gt; &gt; \n&gt; &gt; Peter=\r\n\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; Hello-\n&gt; &gt; &gt; \n&gt; &gt; &gt; Many of you have said that it would be nice if the =\r\nsubstrate \n&gt; &gt; configuration\n&gt; &gt; &gt; of HyperNEAT was not pre-defined. What e=\r\nlements of it do you \nthink \n&gt; &gt; are\n&gt; &gt; &gt; important to evolve?\n&gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; I can think of at least three options (am I missing any?)\n&gt; &gt; &gt; \n&gt; &gt; &gt; 1)=\r\n The number of hidden layers\n&gt; &gt; &gt; 2) The number of hidden nodes per layer\n=\r\n&gt; &gt; &gt; 3) The geometric placement of the nodes in every layer\n&gt; &gt; &gt; \n&gt; &gt; &gt; I=\r\nf you think all of them are important, how would you \nprioritize \n&gt; &gt; them?=\r\n In\n&gt; &gt; &gt; what order would you prefer researchers tackled them? I am just \n=\r\n&gt; &gt; curious what\n&gt; &gt; &gt; different people think about these questions.\n&gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; \n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; Jeff Clune\n&gt; &gt; &gt; \n&gt; &gt; &gt; Digital Evolution Lab, =\r\nMichigan State University\n&gt; &gt; &gt; \n&gt; &gt; &gt; jclune@\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}