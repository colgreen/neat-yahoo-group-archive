{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":130107745,"authorName":"Chad Bohannan","from":"&quot;Chad Bohannan&quot; &lt;chad@...&gt;","profile":"tailboom22","replyTo":"LIST","senderId":"gBNMUvoTIdbqm3zfRbUJTIcifOlEWkzCqWY13NaUWmKN-aC28yT1wbFlQT0Y-uBC8ncUX9ar8ItL6v85LavUUjtE2yb-v2cV1S0","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Human fitness function","postDate":"1086912770","msgId":1062,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDEyMmY2MDFjNDRmNDgkZDUxMDIwNjAkNzBjYjAxMGFAbWFpbDJ3b3JsZC5jb20+"},"prevInTopic":1061,"nextInTopic":1063,"prevInTime":1061,"nextInTime":1063,"topicId":1059,"numMessagesInTopic":5,"msgSnippet":"hmm. you want the network to do a comparison between two images. That does sound hard. I was thinking you would use the two image comparison to create a ","rawEmail":"Return-Path: &lt;chad@...&gt;\r\nX-Sender: chad@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 80582 invoked from network); 11 Jun 2004 00:19:42 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m24.grp.scd.yahoo.com with QMQP; 11 Jun 2004 00:19:42 -0000\r\nReceived: from unknown (HELO mwde08la.mail2world.com) (66.28.189.182)\n  by mta4.grp.scd.yahoo.com with SMTP; 11 Jun 2004 00:19:42 -0000\r\nReceived: from mail pickup service by mwde08la.mail2world.com with Microsoft SMTPSVC;\n\t Thu, 10 Jun 2004 17:12:52 -0700\r\nauth-sender:chad@...\r\nReceived: from 10.1.203.112 unverified ([10.1.203.112]) by mwde08la.mail2world.com with Mail2World SMTP Server,\n\tThu 10 Jun 2004 17:12:50 -07:00\r\nReceived: from [153.90.196.221] by bohannan.net with HTTP; 6/10/2004 5:12:50 PM PST\r\nthread-index: AcRPSNUNkjHqOrmCQDGlIitt6jpNSA==\r\nThread-Topic: [neat] Human fitness function\r\nTo: &lt;neat@yahoogroups.com&gt;\r\nDate: Thu, 10 Jun 2004 17:12:50 -0700\r\nMessage-ID: &lt;122f601c44f48$d5102060$70cb010a@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_122F7_01C44F0E.28B14860&quot;\r\nX-Mailer: Microsoft CDO for Exchange 2000\r\nContent-Class: urn:content-classes:message\r\nImportance: normal\r\nPriority: normal\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\r\nX-OriginalArrivalTime: 11 Jun 2004 00:12:52.0070 (UTC) FILETIME=[D60E0860:01C44F48]\r\nX-eGroups-Remote-IP: 66.28.189.182\r\nFrom: &quot;Chad Bohannan&quot; &lt;chad@...&gt;\r\nSubject: Re: [neat] Human fitness function\r\nX-Yahoo-Group-Post: member; u=130107745\r\nX-Yahoo-Profile: tailboom22\r\n\r\n\r\n------=_NextPart_000_122F7_01C44F0E.28B14860\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\n\r\nhmm. you want the network to do a comparison between two images. That\ndoes sound hard.\nI was thinking you would use the two image comparison to create a\nfitness gradient yourself, then the networks would just output a single\nfitness value from a single input picture after they were trained on\nthat input. It would essentially grade the picture from the data\ncollected from you using the comparsion, not actually make a comparison\nitself. Doing a comparison with a network does at least double your\nsearch dimension...\n\nchad\n\n&lt;-----Original Message-----&gt; \nFrom: John Arrowwood\nSent: 6/10/2004 6:10:30 PM\nTo: neat@yahoogroups.com\nSubject: Re: [neat] Human fitness function\n\n&gt;From: &quot;Chad Bohannan&quot; \n&gt;\n&gt;&gt; I&#39;d like to extract a bunch of &#39;characteristics&#39; from each image, and\n&gt;use\n&gt;&gt;those as inputs into a neural network, and use that data as the\n&gt;training\n&gt;&gt;data. Then, when I add a bunch of new pictures to the database, I can\n&gt;let\n&gt;&gt;the network pre-classify their relationship to the others. If the\n&gt;network\n&gt;&gt;doesn&#39;t have a CLEAR preference, it passes on the comparison. When it\n&gt;is\n&gt;&gt;done, the best pictures automatically end up near the top, the dogs\n&gt;&gt;automatically fall to the bottom.\n&gt;\n&gt;\n&gt;I&#39;ve thinking about how to do exactly that ( with the intention of\n&gt;processing motion picture data for a vision system ) and combining it\n&gt;with ideas from the emergent behaviour theory. If you develop a set of\n&gt;networks, one for each &#39;charachteristic&#39; your looking for, and all work\n&gt;in parrellel from the same input. They become the &#39;input layer of\n&gt;networks&#39; and then you can evolve a network who&#39;s input is from that\n&gt;input layer to actually judge the quality/fitness of the image, from\n&gt;those charachteristics.\n&gt;I havn&#39;t actually tried this approach yet, myself, but I&#39;m working\n&gt;toward it. The &quot;real job&quot; has been too much fun. If you go for this\n&gt;approach, there will be some decisions you have to make about how to\n&gt;decide if charachteristics exists or not, and I would really like to\nsee\n&gt;how you choose to filter for them. It could be as simple as having a\n&gt;list of pictures, with corrosponding values for magnitude of\n&gt;charachteristic. A sticky point is things like curves vs lines. Do you\n&gt;have two different networks, one to detect curves, the other lines? Or\n&gt;can one network decide that there are more lines than curves, and make\na\n&gt;decision....\n&gt;Quick question: what do you think your input resolution will be?\n\nI don&#39;t know. I don&#39;t know what characteristics to input. I might just \nfeed scaled-down pixel data for two images with a single 0/1 output. In \nwhich case, probably 256x256 pixels per image, times 2 for two images,\ntimes \n3 for RGB. That&#39;s a lot of inputs, though. It would take a long time to \nlearn to distinguish. But eventually, it would learn, I&#39;m sure of that. \nJust not necessarily in my lifetime. :)\n\nI&#39;ll do some research first, see what kinds of things I can do to an\nimage \nto help me determine useful and relevant characteristics. I know that\nsome \nof the important features are color, saturation, balance (both of colors\nand \nof content), focus, and stuff like that. But what I don&#39;t know (yet) is\nhow \nto extract those kinds of features from an image. Thus, the need for \nresearch.\n\n\n\n\n\n\nYahoo! Groups Links\n\n\n\n\n\n.\n\n\r\n------=_NextPart_000_122F7_01C44F0E.28B14860\r\nContent-Type: text/html\r\nContent-Transfer-Encoding: 7bit\r\n\r\n&lt;HTML&gt;\n&lt;BODY&gt;\nhmm. you want the network to do a comparison between two images. That does sound hard.&lt;br&gt;\nI was thinking you would use the two image comparison to create a fitness gradient yourself, then the networks would just output a single fitness value from a single input picture after they were trained on that input. It would essentially grade the picture from the data collected from you using the comparsion, not actually make a comparison itself. Doing a comparison with a network does at least double your search dimension...&lt;br&gt;\n&lt;br&gt;\nchad&lt;br&gt;\n&lt;br&gt;\n&lt;-----Original Message-----&gt; &lt;br&gt;\nFrom: John Arrowwood&lt;br&gt;\nSent: 6/10/2004 6:10:30 PM&lt;br&gt;\nTo: neat@yahoogroups.com&lt;br&gt;\nSubject: Re: [neat] Human fitness function&lt;br&gt;\n&lt;br&gt;\n&gt;From: &quot;Chad Bohannan&quot; &lt;chad@...&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&gt; I&#39;d like to extract a bunch of &#39;characteristics&#39; from each image, and&lt;br&gt;\n&gt;use&lt;br&gt;\n&gt;&gt;those as inputs into a neural network, and use that data as the&lt;br&gt;\n&gt;training&lt;br&gt;\n&gt;&gt;data. Then, when I add a bunch of new pictures to the database, I can&lt;br&gt;\n&gt;let&lt;br&gt;\n&gt;&gt;the network pre-classify their relationship to the others. If the&lt;br&gt;\n&gt;network&lt;br&gt;\n&gt;&gt;doesn&#39;t have a CLEAR preference, it passes on the comparison. When it&lt;br&gt;\n&gt;is&lt;br&gt;\n&gt;&gt;done, the best pictures automatically end up near the top, the dogs&lt;br&gt;\n&gt;&gt;automatically fall to the bottom.&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;I&#39;ve thinking about how to do exactly that ( with the intention of&lt;br&gt;\n&gt;processing motion picture data for a vision system ) and combining it&lt;br&gt;\n&gt;with ideas from the emergent behaviour theory. If you develop a set of&lt;br&gt;\n&gt;networks, one for each &#39;charachteristic&#39; your looking for, and all work&lt;br&gt;\n&gt;in parrellel from the same input. They become the &#39;input layer of&lt;br&gt;\n&gt;networks&#39; and then you can evolve a network who&#39;s input is from that&lt;br&gt;\n&gt;input layer to actually judge the quality/fitness of the image, from&lt;br&gt;\n&gt;those charachteristics.&lt;br&gt;\n&gt;I havn&#39;t actually tried this approach yet, myself, but I&#39;m working&lt;br&gt;\n&gt;toward it. The &quot;real job&quot; has been too much fun. If you go for this&lt;br&gt;\n&gt;approach, there will be some decisions you have to make about how to&lt;br&gt;\n&gt;decide if charachteristics exists or not, and I would really like to see&lt;br&gt;\n&gt;how you choose to filter for them. It could be as simple as having a&lt;br&gt;\n&gt;list of pictures, with corrosponding values for magnitude of&lt;br&gt;\n&gt;charachteristic. A sticky point is things like curves vs lines. Do you&lt;br&gt;\n&gt;have two different networks, one to detect curves, the other lines? Or&lt;br&gt;\n&gt;can one network decide that there are more lines than curves, and make a&lt;br&gt;\n&gt;decision....&lt;br&gt;\n&gt;Quick question: what do you think your input resolution will be?&lt;br&gt;\n&lt;br&gt;\nI don&#39;t know.  I don&#39;t know what characteristics to input.  I might just &lt;br&gt;\nfeed scaled-down pixel data for two images with a single 0/1 output.  In &lt;br&gt;\nwhich case, probably 256x256 pixels per image, times 2 for two images, times &lt;br&gt;\n3 for RGB.  That&#39;s a lot of inputs, though.  It would take a long time to &lt;br&gt;\nlearn to distinguish.  But eventually, it would learn, I&#39;m sure of that.  &lt;br&gt;\nJust not necessarily in my lifetime. :)&lt;br&gt;\n&lt;br&gt;\nI&#39;ll do some research first, see what kinds of things I can do to an image &lt;br&gt;\nto help me determine useful and relevant characteristics.  I know that some &lt;br&gt;\nof the important features are color, saturation, balance (both of colors and &lt;br&gt;\nof content), focus, and stuff like that.  But what I don&#39;t know (yet) is how &lt;br&gt;\nto extract those kinds of features from an image.  Thus, the need for &lt;br&gt;\nresearch.&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\n------------------------ Yahoo! Groups Sponsor --------------------~--&gt; &lt;br&gt;\nYahoo! Domains - Claim yours for only $14.70&lt;br&gt;\nhttp://us.click.yahoo.com/Z1wmxD/DREIAA/yQLSAA/7brrlB/TM&lt;br&gt;\n--------------------------------------------------------------------~-&gt; &lt;br&gt;\n&lt;br&gt;\n &lt;br&gt;\nYahoo! Groups Links&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; To visit your group on the web, go to:&lt;br&gt;\n     http://groups.yahoo.com/group/neat/&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; To unsubscribe from this group, send an email to:&lt;br&gt;\n     neat-unsubscribe@yahoogroups.com&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; Your use of Yahoo! Groups is subject to:&lt;br&gt;\n     http://docs.yahoo.com/info/terms/&lt;br&gt;\n &lt;br&gt;\n&lt;br&gt;\n.&lt;br&gt;\n\n&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_122F7_01C44F0E.28B14860--\r\n\n"}}