{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"_xVCGoT0IHw_d-3spqU4Y1cX9NkyUe4ymqffnqz9oDrQnPMq3uQim4H3f3Rpsw2tFt05Y4fYescstQs-b_rL2cMvFTzuzrx8-0OSBBGoejJL8UGp4jU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Intelligently and nonarbitrarily penalising complexity","postDate":"1316172204","msgId":5639,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGo0dmJqYytvdmk0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGo0dXNhOStxcHVnQGVHcm91cHMuY29tPg=="},"prevInTopic":5638,"nextInTopic":5640,"prevInTime":5638,"nextInTime":5640,"topicId":5638,"numMessagesInTopic":6,"msgSnippet":"Hi Arman, Actually you don t need to penalize complexity explicitly because the NEAT s speciation mechanism takes care of that, in particular you penalize","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 49413 invoked from network); 16 Sep 2011 11:23:25 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m8.grp.sp2.yahoo.com with QMQP; 16 Sep 2011 11:23:25 -0000\r\nX-Received: from unknown (HELO ng4-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.135)\n  by mta2.grp.sp2.yahoo.com with SMTP; 16 Sep 2011 11:23:25 -0000\r\nX-Received: from [98.138.217.180] by ng4.bullet.mail.ne1.yahoo.com with NNFMP; 16 Sep 2011 11:23:25 -0000\r\nX-Received: from [69.147.65.148] by tg5.bullet.mail.ne1.yahoo.com with NNFMP; 16 Sep 2011 11:23:25 -0000\r\nX-Received: from [98.137.34.155] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 16 Sep 2011 11:23:25 -0000\r\nDate: Fri, 16 Sep 2011 11:23:24 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;j4vbjc+ovi4@...&gt;\r\nIn-Reply-To: &lt;j4usa9+qpug@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Intelligently and nonarbitrarily penalising complexity\r\nX-Yahoo-Group-Post: member; u=283334584; y=oykHUKKfUFYmWNF1-dzb9wiwFKF3-QhrmzgwqVXT1Pq68khVR1l3vPIfyw\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi Arman, \n\nActually you don&#39;t need to penalize complexity explicitly becau=\r\nse the NEAT&#39;s speciation mechanism takes care of that, in particular you pe=\r\nnalize species that don&#39;t make progress, which focuses the search on the mo=\r\nst promising species. Complexity is irrelevant in this, because species tha=\r\nt make progress can be either simple or complex. Species with simple genome=\r\ns tend to stick around as long as they show progress. You obviously want si=\r\nmple individuals with big fitness, and NEAT makes sure this is what happens=\r\n.  \n\nOne thing regarding your CPU time idea is that in some domains you may=\r\n have variable time for evaluation, like for example a robot maze navigatio=\r\nn task (or something kinda like the asteroids game), where the fitness is e=\r\nquated to the time it takes before a collision occurs, or basically any dom=\r\nain where something related to time is to be maximized. It&#39;s not wrong to p=\r\nenalize individuals for excessive CPU usage, but that is usually associated=\r\n with complexity and what you need is to evolve complexity. \n\nAnother solut=\r\nion to avoid excessive complexity is to add subtractive mutations, that is,=\r\n to make NEAT delete genes at random. This would lead to a &quot;blended search&quot;=\r\n which some people report is slightly more efficient. The best thing I know=\r\n of so far is the &quot;phased searching&quot; technique of Colin Green, which is com=\r\nplexifying and then pruning in sequential stages. \n\nPeter\n\n--- In neat@yaho=\r\nogroups.com, &quot;arman.schwarz&quot; &lt;arman.schwarz@...&gt; wrote:\n&gt;\n&gt; Hi everyone,\n&gt; =\r\n\n&gt; I noticed that there seem to be 2 schools of thought regarding penalisin=\r\ng complexity; either you do it or you don&#39;t. NEAT steps away from this blac=\r\nk or white approach a little by simply adding complexity only where it is n=\r\needed, but it still does not discourage it implicitly.\n&gt; \n&gt; This is fine in=\r\n nature, where a large brain or a complex array of organs can be a benefit =\r\nwithout necessarily creating problems, but it is less so in the world of co=\r\nmputing.\n&gt; \n&gt; The flipside is of course that simply creating some arbitrary=\r\n function that penalises complexity also restricts the model.\n&gt; \n&gt; How abou=\r\nt a system whereby complexity is penalised organically, and not by means of=\r\n manipulating the fitness?\n&gt; \n&gt; Suppose we have a population of 100 organis=\r\nms spread across 10 species. Let&#39;s allocate each organism a fraction of the=\r\n total CPU time (so 1% for each organism), then let&#39;s allocate each species=\r\n a fraction of CPU time based on its population. In this scenario, each spe=\r\ncies would be given 10% of total CPU time.\n&gt; \n&gt; Now lets evaluate each spec=\r\nies, allow it to evolve, and at each cycle speciate them as we would normal=\r\nly in NEAT. However, each evaluation of the epoch() function (or the evolut=\r\nion function) is timed, and each species develops a surplus or debt of CPU =\r\ntime based on the difference between its allocated and used amounts of CPU =\r\ntime. Species with a CPU time debt that exceeds the time it takes to run a =\r\ncycle are skipped, and species with a CPU time surplus that exceeds their (=\r\ntypical) cycle time are allowed to evolve a multiple of times (depending on=\r\n the number of cycles they can use without depleting their surplus).\n&gt; \n&gt; T=\r\nhis simple mechanism would encourage innovation and simplicity, while allow=\r\ning larger organisms with genuine advantage to still thrive. I&#39;d appreciate=\r\n some feedback on this, and would love to know whether something like this =\r\nhas been previously explored.\n&gt;\n\n\n\n"}}