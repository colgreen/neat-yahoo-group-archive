{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"37hxmPdLZWNaualg7SuPbreWa7TkUhyVjbjpUa1KFlShNyUc836etWOkzLJckfReG5JhVXjBPjTkHzvoG-XydfRRrKh4","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: New paper on why modules evolve, and how to evolve modular artificial neural networks","postDate":"1361552305","msgId":6005,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtnODgzaSticWlzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDc3NDVBMTQwLTQ1QzctNDFDQS04ODE3LTY2RjVDNUJDNkZFNkB1d3lvLmVkdT4="},"prevInTopic":6004,"nextInTopic":6006,"prevInTime":6004,"nextInTime":6006,"topicId":5976,"numMessagesInTopic":30,"msgSnippet":"Hi Jeff,  I don t mean to drag on the conversation too long but it s getting to some really interesting issues, some of which go beyond the one topic of","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 72400 invoked from network); 22 Feb 2013 16:58:28 -0000\r\nX-Received: from unknown (10.193.84.131)\n  by m6.grp.bf1.yahoo.com with QMQP; 22 Feb 2013 16:58:28 -0000\r\nX-Received: from unknown (HELO ng5-vm5.bullet.mail.gq1.yahoo.com) (98.136.219.57)\n  by mta4.grp.bf1.yahoo.com with SMTP; 22 Feb 2013 16:58:27 -0000\r\nX-Received: from [98.137.0.88] by ng5.bullet.mail.gq1.yahoo.com with NNFMP; 22 Feb 2013 16:58:27 -0000\r\nX-Received: from [10.193.94.105] by tg8.bullet.mail.gq1.yahoo.com with NNFMP; 22 Feb 2013 16:58:26 -0000\r\nDate: Fri, 22 Feb 2013 16:58:25 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kg883i+bqis@...&gt;\r\nIn-Reply-To: &lt;7745A140-45C7-41CA-8817-66F5C5BC6FE6@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;4-3208815244-4326035847=:9&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New paper on why modules evolve, and how to evolve modular artificial neural networks\r\nX-Yahoo-Group-Post: member; u=54567749; y=CueupEV19oLNsTEXw2nKFGivSht58vW8dKZvqLpfv_tikFU-mHSd\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\r\n--4-3208815244-4326035847=:9\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Jeff,  I don&#39;t mean to drag on the conversation too long but it&#39;s\ngettin=\r\ng to some really interesting issues, some of which go beyond the\none topic =\r\nof modularity, so I feel it&#39;s still productive to respond on\nsome of your p=\r\noints.  To keep the thread readable I didn&#39;t keep every\nsingle item from be=\r\nfore.  (My responses are the ones with the least\nindent.)\n\n\nNature doesn&#39;t =\r\nhave anything analogous either, which means there is at \nleast some evidenc=\r\ne that the &quot;fitness bias&quot; analogy with nature is not \nlining up perfectly. =\r\nYou might point to the continuing existence of \nsingle-celled organisms as =\r\nsomething similar to the perpetual \ndead-weight in this formulation, but th=\r\ney aren&#39;t really analogous \nbecause single-celled organisms are functional =\r\n- they retain the ability\nto make copies of themselves and continue to evol=\r\nve in their own right -\nwhile the low-connectivity deadweight maintains no =\r\ncapability \nwhatsoever. On the other hand, suspiciously, as in nature, noth=\r\ning \nsimilar to such a deadweight niche is perpetuated by a biased encoding=\r\n.\n\n\nThat&#39;s also true, but  that fault does not lie with the fitness cost\nco=\r\nncept, it lies with the  fact that multi-objective algorithms, which\nare th=\r\ne cause of the dead  weight, do not perfectly analogize to nature.\nThey&#39;re =\r\njust better than a  weighted sum for other reasons, but the\nfitness cost co=\r\nncept could  easily be implemented in a weighted sum\nfitness function and n=\r\not have  this dead weight issue.\n\nDoesn&#39;t it seem a little strange that the=\r\n price we have to pay to obtain\nmodular structure is to maintain a perpetua=\r\nl dead pool of genetic junk? \nNote that it doesn&#39;t suggest that such a syst=\r\nem won&#39;t work in some \ncases, but it&#39;s inelegant enough to raise questions =\r\nabout the best \nrealization of the concept..\n\n\nAll  I think that calls into=\r\n question is the optimality of\nmulti-objective  algorithms when you don&#39;t w=\r\nant the extreme of one\nobjective. But that  problem almost always occurs in=\r\n multi-objective\nalgorithms, so your  really indicting the whole field of M=\r\nOEA instead of\nour approach of  using a fitness penalty instead of a biased=\r\n encoding,\nno?\nNo I don&#39;t think I&#39;m indicting MOEAs in general.  The proble=\r\nm here is\nnot some inherent problem with MOEAs, but that MOEAs were not des=\r\nigned\nfor the purpose for which you have borrowed them.   MOEAs are designe=\r\nd\nto return a Pareto front given a number of objective trade-offs.  They\nar=\r\ne doing that perfectly well in your experiment.  It&#39;s just that your\nintere=\r\nst is not perfectly aligned with that design:  Your interest is in\nthe &quot;bes=\r\nt tradeoff&quot; (which is inherently slippery to formalize and not\nformalized b=\r\ny a traditional  MOEA), while some trade-offs that MOEAs are\nby design made=\r\n to preserve and elevate (such as total dominance on low\nconnectivity) are =\r\nof almost no interest in this domain, as you&#39;ve\nagreed.  So my general crit=\r\nique of manipulating the fitness function has\nnothing to do with MOEAs spec=\r\nifically.\n\nRather, what we are observing is simply the struggle to find som=\r\ne kind\nof expression of fitness that aligns with what you actually want to =\r\nsee\n(and thereby incentivizes following the right path through the search\ns=\r\npace).  And the fact that you settled on MOEAs as the best option, and\nthat=\r\n they do not align all that well, just illustrates how nasty this\nlittle pr=\r\noblem of tweaking fitness really is.\n\nYou noted that MOEAs are &quot;just better=\r\n than a  weighted sum for other\nreasons,&quot; but that&#39;s exactly the problem.  =\r\nThose &quot;other reasons&quot; are\nindeed unrelated to the problem you are trying to=\r\n solve here.  That is,\nMOEAs are a blunt kludge in this particular context.=\r\n  But although you\ndefend fitness in general with the response that &quot;the fi=\r\ntness cost\nconcept could  easily be implemented in a weighted sum fitness f=\r\nunction\nand not have  this dead weight issue,&quot; the problem there is that yo=\r\nu\nonce again end up with similarly unnatural and incongruous implications:\n=\r\n\nIf you make fitness a weighted sum and one component of that weighted\nsum =\r\nis &quot;low connectivity,&quot; then there will *still* be a special\neternally prote=\r\ncted pocket for non-functional low-connectivity\nstructure.  The reason is t=\r\nhat if there is any progress on actually\nsolving the problem (aside from co=\r\nnnectivity), then those networks that\nare moving towards solving it will be=\r\n more connected than the lowest\npossible connectivity.  Very often, because=\r\n of mutation, some of these\nmore connected networks will break, leading to =\r\nan inevitable (and\nunavoidable) subpopulation  of higher-connectivity netwo=\r\nrks that are\nbroken and nonfunctional.  Because of this inevitable subset o=\r\nf failures\nin every generation, a great strategy for some of the population=\r\n is to\nstay as minimally connected as possible while ignoring functionality=\r\n\n(just as in the MOEA) because they can be just barely  &quot;good enough&quot; to\nke=\r\nep perpetuating merely by their connectivity fitness bonus versus\nthose who=\r\n are more connected and also nonfunctional.\n\nNow you may then reason that t=\r\nhere is some more complicated way to\ncounteract this problem.  For example,=\r\n you may say, well, we just need\nto be more strict about selection, so amp =\r\nup selection pressure by\nblocking more of the population from reproducing. =\r\n But you have no way\nto know a priori what that threshold should be, so you=\r\n are risking\nbreaking evolution in other ways (such as becoming too converg=\r\nent) by\nwiping out diversity.  In fact, early in evolution, when most struc=\r\nture\nis nonfunctional or less functional, that could short circuit the  who=\r\nle\nprocess.\n\nBut I want to emphasize that my point here has nothing to do w=\r\nith trying\nto figure out the right &quot;trick&quot; to get fitness to actually align=\r\n\nproperly with what we want to see, or with natural evolution of\nmodularity=\r\n.  If you notice, when you begin to talk about using\nprobabilistic Pareto f=\r\nronts or something like that, you are just playing\nagain the same &quot;let&#39;s tw=\r\neak things around hoping to get it right&quot; game. \nAnd my point here is that =\r\nthat game is ultimately a game of futility. \nSure, in this very simply task=\r\n (relative to finding a natural brain),\nvirtually anything will work even i=\r\nf it is radically out of whack with\nnature, so you can convince yourself th=\r\nat this problem is possible to\nreconcile.  You can convince yourself that w=\r\nith enough tweaking you&#39;ll\njust write down the magic fitness/MOEA recipe th=\r\nat equals finding what\nyou want.  But the search space is so incredibly com=\r\nplex that such a\ndream is virtually impossible.  Because if you think about=\r\n it, as you\nmake one tweak after another, as you fix one unintended consequ=\r\nence with\nyet another trick, what you are ultimately doing is describing th=\r\ne path\nthrough the search space itself.  In other words, the logical extens=\r\nion\nof such a process is simply to identify all the stepping stones from al=\r\nl\npossible random starting points to the objective and give higher fitness\n=\r\nfor each step in the chain, a task akin to applied omnipotence.  You\nmight =\r\nas well just build the solution by hand in that case, because you\nwould kno=\r\nw all the stepping stones to the solution anyway.  So while\nthese fitness t=\r\nricks may work for now, while we play in modest\nplaygrounds, there are big =\r\nwarning signs looming in the future.\n\n\n\nI feel that you may not see what I&#39;=\r\nm saying about encoding here, because\nyou speak about encoding as if it has=\r\n similar effects to fitness \npressure, but I think it&#39;s not the same. You s=\r\nay:\n\n&quot;The reasons biases work is because they do bias search towards some \n=\r\nareas and away from others: so I think both encoding biases and fitness \npe=\r\nnalties have similar effects in this regard.&quot;\n\nBut I don&#39;t think that&#39;s tru=\r\ne for encoding. The difference with encoding\nis that it is not pushing the =\r\nsearch towards any particular area within \nthe space it induces. Absent any=\r\n kind of fitness function or selective \npressure, encoding says nothing abo=\r\nut which areas are accessible. Rather\nit simply says which types of phenoty=\r\npes are overrepresented or \nunderrepresented throughout the whole space of =\r\ngenotypes. In other \nwords, even if an encoding is &quot;biased&quot; towards low con=\r\nnectivity, if you \nhappen to get into an area of the space with high connec=\r\ntivity, the \nencoding does not have to push you out of that area (it could =\r\nbe a dense\nsubspace full of high-connectivity structures). But fitness bias=\r\n would \nhave to push you out because all it does it push you out. It can&#39;t =\r\nbend \nor change depending on where you go. Encoding can change with the tim=\r\nes \nand has the wonderful additional potential for canalization, a bonus \ne=\r\nntirely absent from fitness pressure.\n\n\nFirst of all, an  encoding can actu=\r\nally prevent you from accessing a\nspace. If I encode  the length of all tab=\r\nle legs in one number, than I\nhave eliminated the  possibility of a table h=\r\naving legs of different\nlengths. L-systems tend  to produce such overly rig=\r\nid biases (unless\nthey are parameterized  and/or made context-dependent). B=\r\nut more\nrelevant to our discussion are  biases that are strong likelihoods,=\r\n but\nnot strict edicts. Even these,  though, in practice do mean that entir=\r\ne\nareas of the search space go  unexplored. In our TEC paper, for example,\n=\r\nthe HyperNEAT generative  encoding far outperformed the direct encoding,\nev=\r\nen though the fitness  function was the exact same. Why? Because the\ndirect=\r\n encoding was biased  towards an entirely different area of the\nsearch spac=\r\ne. We know that  there was a selection pressure for certain\ntypes of ANNs (=\r\nnamely, the  ones HyperNEAT produced), and we know that\nthe direct encoding=\r\n can  express those phenotypes (they actually do in\nHybrID), but evolution =\r\n with the direct encoding did not do so because\nbiases have a huge effect  =\r\non the subset of the search space you visit.\nIn fact, it is precisely  beca=\r\nuse encodings have biases of large effect\nthat we all care about  generativ=\r\ne encodings, no? All of these arguments\nare also supported by  Hornby&#39;s com=\r\nparison of L-systems to a direct\nencoding, including his  maps of the types=\r\n of phenotypes produced (there\nare huge differences  between the two encodi=\r\nngs). I&#39;d argue that any\ncomparison of direct and  indirect encodings shows=\r\n that these biases are\nnot subtle, but grossly  change the types of phenoty=\r\npes explored, and\nfor all practical purposes  eliminate large swathes of th=\r\ne search space.\nFor these reasons I think  you&#39;ll get huge unintended conse=\r\nquences by\nplaying around with  encodings, and those consequences will not =\r\nbe\noverridden by the fitness  function, because we&#39;ve seen it happen time\na=\r\nnd time again. Note that I  agree that you also have unintended\nconsequence=\r\ns when playing with  fitness functions.\nNB: I agree with you about canaliza=\r\ntion, which is one of many reasons I\nlike generative encodings. :-)\nWe are =\r\nin agreement that encodings matter.  Of course, that is part of\nwhy I&#39;m say=\r\ning they&#39;re important.  But what I&#39;m really saying is that\nencodings are fa=\r\nr better suited than fitness for the long haul, i.e. for\ndoing something in=\r\nteresting over millions of generations, largely\n*because* a good encoding c=\r\nan canalize.  The trick behind radically\nsuccessful long-term evolution, in=\r\n my view, is to keep your options\nopen.  You don&#39;t want to say X is clearly=\r\n better than Y.  What you want\nto say is, if X and Y are fundamentally diff=\r\nerent, I want to check both\nX and Y and see where each of them lead and fol=\r\nlow both branches if both\nare interesting.  But furthermore, if some proper=\r\nty of X proves helpful\nin leading it to all kinds of cool stuff (or the sam=\r\ne for Y), then let&#39;s\nstart preserving (i.e. canalizing) that property THEN,=\r\n when we observe\nits potential, rather than a priori from day one when we w=\r\nould have to\nbe an omnipotent being to anticipate everything that might be =\r\nuseful. \nAnd only encoding offers that possibility.  Fitness is all about m=\r\naking\nchoices about priorities long before you have any idea what the optio=\r\nns\nare.  Encoding with canalization is about giving evolution the choice to=\r\n\nfind the level that&#39;s right for it.  There is nothing analogous to\ncanaliz=\r\nation in fitness.\n\nCanalization is an intriguing issue that is not fully un=\r\nderstood, but it\ndoes happen, clearly in nature, and even in CPPNs.  For ex=\r\nample, one\ncool experiment I tried informally on Picbreeder was to keep\nreg=\r\nenerating new populations from the same starting image over and over\nagain =\r\nfrom both (1) a highly-evolved image and (2) a low-generation\nimage.  Not s=\r\nurprisingly, the offspring of the highly-evolved image were\nsignificantly m=\r\nore consistent (based on my subjective perception) than\nof the less-evolved=\r\n one.  That&#39;s canalization in action, even in\nPicbreeder.  By the way, appl=\r\nying an objective fitness function will\nundermine the potential for canaliz=\r\nation (with CPPNs or anything else)\nbecause of the tendency of objectives t=\r\no wreck the representation.  So\nfitness here has a huge disadvantage as a t=\r\nool for manipulation:  Not\nonly does it offer no mechanism remotely compara=\r\nble to canalization, but\nit actually thwarts canalization in the encoding e=\r\nven if the encoding\ncan do it.  It&#39;s like you keep whipping evolution for l=\r\nosing modularity\nand it keeps paying the price without every really getting=\r\n the idea\nfundamentally (i.e. through the encoding).\n\nSo this is why we wan=\r\nt something like LEO where modularity *can* evolve\naway to different degree=\r\ns:  We want to make no a priori assumptions\nabout what must be correct in a=\r\nll generations, and instead allow\nevolution to try out everything.  And tho=\r\nse things that lead to more\npotential over time will become canalized, you =\r\ncan be confident, and\ntherein evolution works its magic.\n\nSo while you are =\r\nsaying regarding the human head size that DNA perhaps\n*can* encode brains w=\r\nith high connectivity but that fitness is\npreventing it, I would say that D=\r\nNA *in general* perhaps can do that,\nbut by now, long into the human lineag=\r\ne, these pseudo-modular structures\nare so deeply canalized that breaking ou=\r\nt of that canal for the encoding\nwould require herculean effort.  But that&#39;=\r\ns beauty of encoding.\n\n\nThe right level of modularity is likely on a delica=\r\nte continuum - not \nentirely one way or another, and probably varies by spe=\r\ncies. You believe\nevolution can pay a kind of tax for going against the pre=\r\nssure towards \nlow connectivity: &quot;if a certain phenotype pays for its wirin=\r\ng by \nincreasing fitness, it can add high-connectivity areas anywhere that =\r\n\nthey are useful.&quot; But in a delicate balancing act where the best option \ni=\r\ns likely some middle ground, that sounds too much like gambling and \nit&#39;s v=\r\nulnerable to deception in cases where there is no immediate \nfitness benefi=\r\nt (whereas encoding is orthogonal to fitness). With \nencoding you don&#39;t hav=\r\ne the play that game. Encoding can create its own \ntendency towards some mi=\r\nddle ground and canalize that tendency over \ntime.\nIf there is no  fitness =\r\ngradient toward such a bias toward intermediate\nconnectivity,  why would it=\r\n evolve? Evolution can only think short term.\nI&#39;ll give you  that an encodi=\r\nng bias might override the fitness gradient\nby making it  impossible to fol=\r\nlow, but I don&#39;t buy that evolution can\nmagically  figure out biases that a=\r\nre helpful in the long-term if the\nshort-term  fitness gradients all point =\r\nin another direction. Or, at\nleast, that&#39;s  something we hope that evolutio=\r\nn might do, but it&#39;s a\ncontroversial,  unproven, and theoretically tricky i=\r\nssue that I certain\ndon&#39;t think we  can bank on happening until we understa=\r\nnd it a lot more.\nI think the problem is that you are thinking of evolution=\r\n as &quot;thinking&quot;\nshort term or long term, and that you are hoping that some &quot;=\r\ngradient&quot;\nwill somehow describe for us the right path over all these dispar=\r\nate\ntimescales.   Evolution indeed cannot think ahead.  Its job when it\nthr=\r\nives is to try many things and see where they go.  Ad hoc a priori\ngradient=\r\ns will only get in the way of that.  Give the encoding the\nability to suppo=\r\nrt such diversified exploration and canalize the best of\nit, and evolution =\r\nneed not be thinking at all.\n\n\nWhile  you worry that modularity might &quot;evol=\r\nve away,&quot; the idea that it\ncannot  evolve away to varying degrees sounds wo=\r\nrse to me. Natural\nevolution is  generally good about not keeping all its e=\r\nggs in one\nbasket - a trait  may evolve away in some branches but not in ot=\r\nhers.\nBut for you to make  an all-out attempt to bar such a deviation from\n=\r\nsquare one is making a  lot of strong assumptions about what we want to\nsee=\r\n 1 billion years in  the future.\n\n\nI&#39;d argue that your  bias in the first r=\r\neplicator without any sustained\nfitness pressure  would have zero effect on=\r\n creatures a billion years\nlater, especially in  the case where there is an=\r\n active fitness gradient\nby default away from  modularity (which we know th=\r\nere is, since\nmodularity never evolves  without a bias or fitness pressure)=\r\n. Evolution\nwould not keep any eggs  in a basket with an active fitness pen=\r\nalty, at\nleast not for a billion  years. My 1-billion-years-later influence=\r\n may\nthus be imperfect, but it  at least exists!\nThat&#39;s why I don&#39;t like th=\r\ne word bias as much when it comes to encoding.\nI&#39;d think of it more as an o=\r\nption.  Evolution can try everything -\npreserve it in some lineages, to a l=\r\ness degree in others, and not at all\nin others still.  The ability to commi=\r\nt to subtlety is the magic here. \nThat&#39;s the smart strategy - keep your opt=\r\nions open but also have the\nchance to commit to an option when it&#39;s working=\r\n for you.  A single blunt\nbias imposed for a billion years (which is about =\r\nclosing off options)\ndoes not sound like a smart strategy in a search space=\r\n more astronomical\nthan imagination itself.\n\n\nSo I&#39;m still a fan of manipul=\r\nating encoding over manipulating fitness. \nBut I would not entirely despair=\r\n on fitness because there will still be \ncases where there is no clear opti=\r\non for manipulating the encoding. But \nsuch scenarios are not ones we shoul=\r\nd be hoping for.\n\n\nI do think you make  some great arguments for encodings,=\r\n but I cannot\nenvision a case in  which an initial bias only makes a huge d=\r\nifference\nin the long-term.  That&#39;s true even if the bias is neutral with r=\r\nespect\nto fitness (because  it would drift away), but seems a certainty to =\r\nme\nif it relates to a  bias that has an active fitness penalty. The whole\np=\r\noint of canalization  is that it figures out what produces fit\noffspring an=\r\nd generates that  type of organism: if modular creatures are\nless fit in th=\r\ne short term,  evolution will canalize away from\nmodularity, not toward it.=\r\n That said,  as I mentioned at the beginning\nof this conversation, I do thi=\r\nnk that a  sustained encoding bias of some\nsort is an interesting approach =\r\nthat  could work, although it may be\nthat all we have to do is provide a  f=\r\nitness cost and then the encoding\nwill canalize in a way that produces  suc=\r\nh a sustained bias. :-)I think\nyour view of evolution here is too linear (a=\r\ns opposed to branching),\nwhich is why you tend to worry about things like w=\r\nhat is good in the\nshort term or long term.  But the idea that you can impo=\r\nse these blunt\nconstraints on evolution for eternity fits with a linear per=\r\nspective, so\nit makes sense if that&#39;s how you view it, as a kind of step-by=\r\n-step\nsuccession along a single chain.  But I think evolution in nature is =\r\nnot\nwalking this single tightrope towards some kind of near-optimal ideal,\n=\r\nwhere all our effort needs to focus on not falling off the tightrope.  \nTha=\r\nt is a very objective view, and I think the evidence is pointing more\nand m=\r\nore towards why that kind of perspective has been an impediment for\nus.  Bu=\r\nt I agree the conversation has been great and hope I made my\npoints respect=\r\nfully.   I realize we&#39;re wading into controversy and that\nreasonable minds =\r\ncan disagree here.\n\nBest,\n\nken\n\n\n\n\n\r\n--4-3208815244-4326035847=:9\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n\n\nHi Jeff,&nbsp; I don&#39;t mean to drag on the conversation too long but it&#39;s=\r\n getting to some really interesting issues, some of which go beyond the one=\r\n topic of modularity, so I feel it&#39;s still productive to respond on some of=\r\n your points.&nbsp; To keep the thread readable I didn&#39;t keep every single =\r\nitem from before.&nbsp; (My responses are the ones with the least indent.)&lt;=\r\nbr&gt;&lt;br&gt;&lt;blockquote&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color=\r\n: rgb(255, 255, 255);&quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nNature doesn&#39;t have anything analogous either, which mea=\r\nns there is at \nleast some evidence that the &quot;fitness bias&quot; analogy with na=\r\nture is not \nlining up perfectly. You might point to the continuing existen=\r\nce of \nsingle-celled organisms as something similar to the perpetual \ndead-=\r\nweight in this formulation, but they aren&#39;t really analogous \nbecause singl=\r\ne-celled organisms are functional - they retain the ability\n to make copies=\r\n of themselves and continue to evolve in their own right -\n while the low-c=\r\nonnectivity deadweight maintains no capability \nwhatsoever. On the other ha=\r\nnd, suspiciously, as in nature, nothing \nsimilar to such a deadweight niche=\r\n is perpetuated by a biased encoding.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;=\r\n/blockquote&gt;&lt;div&gt;That&#39;s also true, but \nthat fault does not lie with the fi=\r\ntness cost concept, it lies with the \nfact that multi-objective algorithms,=\r\n which are the cause of the dead \nweight, do not perfectly analogize to nat=\r\nure. They&#39;re just better than a\n weighted sum for other reasons, but the fi=\r\ntness cost concept could \neasily be implemented in a weighted sum fitness f=\r\nunction and not have \nthis dead weight issue. &nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote t=\r\nype=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255);&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nDoesn&#39;t it s=\r\neem a little strange that the price we have to pay to obtain\n modular struc=\r\nture is to maintain a perpetual dead pool of genetic junk?\n Note that it do=\r\nesn&#39;t suggest that such a system won&#39;t work in some \ncases, but it&#39;s ineleg=\r\nant enough to raise questions about the best \nrealization of the concept..&lt;=\r\nbr&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All\n I thin=\r\nk that calls into question is the optimality of multi-objective \nalgorithms=\r\n when you don&#39;t want the extreme of one objective. But that \nproblem almost=\r\n always occurs in multi-objective algorithms, so your \nreally indicting the=\r\n whole field of MOEA instead of our approach of \nusing a fitness penalty in=\r\nstead of a biased encoding, no?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;No I don&#39;t=\r\n think I&#39;m indicting MOEAs in general.&nbsp; The problem here is not some i=\r\nnherent problem with MOEAs, but that MOEAs were not designed for the purpos=\r\ne for which you have borrowed them.&nbsp;&nbsp; MOEAs are designed to retur=\r\nn a Pareto front given a number of objective trade-offs.&nbsp; They are doi=\r\nng that perfectly well in your experiment.&nbsp; It&#39;s just that your intere=\r\nst is not perfectly aligned with that design:&nbsp; Your interest is in the=\r\n &quot;best tradeoff&quot; (which is inherently slippery to formalize and not formali=\r\nzed by a traditional&nbsp; MOEA), while some trade-offs that MOEAs are by d=\r\nesign made to preserve and elevate (such as total dominance on low connecti=\r\nvity) are of almost no interest in this domain, as you&#39;ve agreed.&nbsp; So =\r\nmy general critique of manipulating the fitness function has nothing to do =\r\nwith MOEAs specifically.&lt;br&gt;&lt;br&gt;Rather, what we are observing is simply the=\r\n struggle to find some kind of expression of fitness that aligns with what =\r\nyou actually want to see (and thereby incentivizes following the right path=\r\n through the search space).&nbsp; And the fact that you settled on MOEAs as=\r\n the best option, and that they do not align all that well, just illustrate=\r\ns how nasty this little problem of tweaking fitness really is.&nbsp; &lt;br&gt;&lt;b=\r\nr&gt;You noted that MOEAs are &quot;just better than a\n weighted sum for other reas=\r\nons,&quot; but that&#39;s exactly the problem.&nbsp; Those &quot;other reasons&quot; are indee=\r\nd unrelated to the problem you are trying to solve here.&nbsp; That is, MOE=\r\nAs are a blunt kludge in this particular context.&nbsp; But although you de=\r\nfend fitness in general with the response that &quot;the fitness cost concept co=\r\nuld \neasily be implemented in a weighted sum fitness function and not have =\r\n\nthis dead weight issue,&quot; the problem there is that you once again end up w=\r\nith similarly unnatural and incongruous implications:&lt;br&gt;&lt;br&gt;If you make fi=\r\ntness a weighted sum and one component of that weighted sum is &quot;low connect=\r\nivity,&quot; then there will *still* be a special eternally protected pocket for=\r\n non-functional low-connectivity structure.&nbsp; The reason is that if the=\r\nre is any progress on actually solving the problem (aside from connectivity=\r\n), then those networks that are moving towards solving it will be more conn=\r\nected than the lowest possible connectivity.&nbsp; Very often, because of m=\r\nutation, some of these more connected networks will break, leading to an in=\r\nevitable (and unavoidable) subpopulation&nbsp; of higher-connectivity netwo=\r\nrks that are broken and nonfunctional.&nbsp; Because of this inevitable sub=\r\nset of failures in every generation, a great strategy for some of the popul=\r\nation is to stay as minimally connected as possible while ignoring function=\r\nality (just as in the MOEA) because they can be just barely&nbsp; &quot;good eno=\r\nugh&quot; to keep perpetuating merely by their connectivity fitness bonus versus=\r\n those who are more connected and also nonfunctional.&lt;br&gt;&lt;br&gt;Now you may th=\r\nen reason that there is some more complicated way to counteract this proble=\r\nm.&nbsp; For example, you may say, well, we just need to be more strict abo=\r\nut selection, so amp up selection pressure by blocking more of the populati=\r\non from reproducing.&nbsp; But you have no way to know a priori what that t=\r\nhreshold should be, so you are risking breaking evolution in other ways (su=\r\nch as becoming too convergent) by wiping out diversity.&nbsp; In fact, earl=\r\ny in evolution, when most structure is nonfunctional or less functional, th=\r\nat could short circuit the&nbsp; whole process.&nbsp; &lt;br&gt;&lt;br&gt;But I want to=\r\n emphasize that my point here has nothing to do with trying to figure out t=\r\nhe right &quot;trick&quot; to get fitness to actually align properly with what we wan=\r\nt to see, or with natural evolution of modularity.&nbsp; If you notice, whe=\r\nn you begin to talk about using probabilistic Pareto fronts or something li=\r\nke that, you are just playing again the same &quot;let&#39;s tweak things around hop=\r\ning to get it right&quot; game.&nbsp; And my point here is that that game is ult=\r\nimately a game of futility.&nbsp; Sure, in this very simply task (relative =\r\nto finding a natural brain), virtually anything will work even if it is rad=\r\nically out of whack with nature, so you can convince yourself that this pro=\r\nblem is possible to reconcile.&nbsp; You can convince yourself that with en=\r\nough tweaking you&#39;ll just write down the magic fitness/MOEA recipe that equ=\r\nals finding what you want.&nbsp; But the search space is so incredibly comp=\r\nlex that such a dream is virtually impossible.&nbsp; Because if you think a=\r\nbout it, as you make one tweak after another, as you fix one unintended con=\r\nsequence with yet another trick, what you are ultimately doing is describin=\r\ng the path through the search space itself.&nbsp; In other words, the logic=\r\nal extension of such a process is simply to identify all the stepping stone=\r\ns from all possible random starting points to the objective and give higher=\r\n fitness for each step in the chain, a task akin to applied omnipotence.&nb=\r\nsp; You might as well just build the solution by hand in that case, because=\r\n you would know all the stepping stones to the solution anyway.&nbsp; So wh=\r\nile these fitness tricks may work for now, while we play in modest playgrou=\r\nnds, there are big warning signs looming in the future.&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;=\r\nblockquote&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(25=\r\n5, 255, 255);&quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-=\r\ntext&quot;&gt;&lt;p&gt;&lt;br&gt;\nI feel that you may not see what I&#39;m saying about encoding he=\r\nre, because\n you speak about encoding as if it has similar effects to fitne=\r\nss \npressure, but I think it&#39;s not the same. You say: &lt;br&gt;\n&lt;br&gt;\n&quot;The reason=\r\ns biases work is because they do bias search towards some \nareas and away f=\r\nrom others: so I think both encoding biases and fitness \npenalties have sim=\r\nilar effects in this regard.&quot;&lt;br&gt;\n&lt;br&gt;\nBut I don&#39;t think that&#39;s true for en=\r\ncoding. The difference with encoding\n is that it is not pushing the search =\r\ntowards any particular area within\n the space it induces. Absent any kind o=\r\nf fitness function or selective \npressure, encoding says nothing about whic=\r\nh areas are accessible. Rather\n it simply says which types of phenotypes ar=\r\ne overrepresented or \nunderrepresented throughout the whole space of genoty=\r\npes. In other \nwords, even if an encoding is &quot;biased&quot; towards low connectiv=\r\nity, if you \nhappen to get into an area of the space with high connectivity=\r\n, the \nencoding does not have to push you out of that area (it could be a d=\r\nense\n subspace full of high-connectivity structures). But fitness bias woul=\r\nd \nhave to push you out because all it does it push you out. It can&#39;t bend =\r\n\nor change depending on where you go. Encoding can change with the times \na=\r\nnd has the wonderful additional potential for canalization, a bonus \nentire=\r\nly absent from fitness pressure.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/bloc=\r\nkquote&gt;&lt;div&gt;First of all, an \nencoding can actually prevent you from access=\r\ning a space. If I encode \nthe length of all table legs in one number, than =\r\nI have eliminated the \npossibility of a table having legs of different leng=\r\nths. L-systems tend \nto produce such overly rigid biases (unless they are p=\r\narameterized \nand/or made context-dependent). But more relevant to our disc=\r\nussion are \nbiases that are strong likelihoods, but not strict edicts. Even=\r\n these, \nthough, in practice do mean that entire areas of the search space =\r\ngo \nunexplored. In our TEC paper, for example, the HyperNEAT generative \nen=\r\ncoding far outperformed the direct encoding, even though the fitness \nfunct=\r\nion was the exact same. Why? Because the direct encoding was biased\n toward=\r\ns an entirely different area of the search space. We know that \nthere was a=\r\n selection pressure for certain types of ANNs (namely, the \nones HyperNEAT =\r\nproduced), and we know that the direct encoding can \nexpress those phenotyp=\r\nes (they actually do in HybrID), but evolution \nwith the direct encoding di=\r\nd not do so because biases have a huge effect\n on the subset of the search =\r\nspace you visit. In fact, it is precisely \nbecause encodings have biases of=\r\n large effect that we all care about \ngenerative encodings, no? All of thes=\r\ne arguments are also supported by \nHornby&#39;s comparison of L-systems to a di=\r\nrect encoding, including his \nmaps of the types of phenotypes produced (the=\r\nre are huge differences \nbetween the two encodings). I&#39;d argue that any com=\r\nparison of direct and \nindirect encodings shows that these biases are not s=\r\nubtle, but grossly \nchange the types of phenotypes explored, and for all pr=\r\nactical purposes \neliminate large swathes of the search space. For these re=\r\nasons I think \nyou&#39;ll get huge unintended consequences by playing around wi=\r\nth \nencodings, and those consequences will not be overridden by the fitness=\r\n \nfunction, because we&#39;ve seen it happen time and time again. Note that I \n=\r\nagree that you also have unintended consequences when playing with \nfitness=\r\n functions.&nbsp;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;NB: I agree with you about canal=\r\nization, which is one of many reasons I like generative encodings. :-)&lt;/div=\r\n&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;We are in agreement that encodings matter.&nbs=\r\np; Of course, that is part of why I&#39;m saying they&#39;re important.&nbsp; But w=\r\nhat I&#39;m really saying is that encodings are far better suited than fitness =\r\nfor the long haul, i.e. for doing something interesting over millions of ge=\r\nnerations, largely *because* a good encoding can canalize.&nbsp; The trick =\r\nbehind radically successful long-term evolution, in my view, is to keep you=\r\nr options open.&nbsp; You don&#39;t want to say X is clearly better than Y.&nbs=\r\np; What you want to say is, if X and Y are fundamentally different, I want =\r\nto check both X and Y and see where each of them lead and follow both branc=\r\nhes if both are interesting.&nbsp; But furthermore, if some property of X p=\r\nroves helpful in leading it to all kinds of cool stuff (or the same for Y),=\r\n then let&#39;s start preserving (i.e. canalizing) that property THEN, when we =\r\nobserve its potential, rather than a priori from day one when we would have=\r\n to be an omnipotent being to anticipate everything that might be useful.&n=\r\nbsp; And only encoding offers that possibility.&nbsp; Fitness is all about =\r\nmaking choices about priorities long before you have any idea what the opti=\r\nons are.&nbsp; Encoding with canalization is about giving evolution the cho=\r\nice to find the level that&#39;s right for it.&nbsp; There is nothing analogous=\r\n to canalization in fitness.&lt;br&gt;&lt;br&gt;Canalization is an intriguing issue tha=\r\nt is not fully understood, but it does happen, clearly in nature, and even =\r\nin CPPNs.&nbsp; For example, one cool experiment I tried informally on Picb=\r\nreeder was to keep regenerating new populations from the same starting imag=\r\ne over and over again from both (1) a highly-evolved image and (2) a low-ge=\r\nneration image.&nbsp; Not surprisingly, the offspring of the highly-evolved=\r\n image were significantly more consistent (based on my subjective perceptio=\r\nn) than of the less-evolved one.&nbsp; That&#39;s canalization in action, even =\r\nin Picbreeder.&nbsp; By the way, applying an objective fitness function wil=\r\nl undermine the potential for canalization (with CPPNs or anything else) be=\r\ncause of the tendency of objectives to wreck the representation.&nbsp; So f=\r\nitness here has a huge disadvantage as a tool for manipulation:&nbsp; Not o=\r\nnly does it offer no mechanism remotely comparable to canalization, but it =\r\nactually thwarts canalization in the encoding even if the encoding can do i=\r\nt.&nbsp; It&#39;s like you keep whipping evolution for losing modularity and it=\r\n keeps paying the price without every really getting the idea fundamentally=\r\n (i.e. through the encoding).&lt;br&gt;&lt;br&gt;So this is why we want something like =\r\nLEO where modularity *can* evolve away to different degrees:&nbsp; We want =\r\nto make no a priori assumptions about what must be correct in all generatio=\r\nns, and instead allow evolution to try out everything.&nbsp; And those thin=\r\ngs that lead to more potential over time will become canalized, you can be =\r\nconfident, and therein evolution works its magic.&nbsp; &lt;br&gt;&lt;br&gt;So while yo=\r\nu are saying regarding the human head size that DNA perhaps *can* encode br=\r\nains with high connectivity but that fitness is preventing it, I would say =\r\nthat DNA *in general* perhaps can do that, but by now, long into the human =\r\nlineage, these pseudo-modular structures are so deeply canalized that break=\r\ning out of that canal for the encoding would require herculean effort.&nbsp=\r\n; But that&#39;s beauty of encoding.&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;blockquote =\r\ntype=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255);&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nThe right le=\r\nvel of modularity is likely on a delicate continuum - not \nentirely one way=\r\n or another, and probably varies by species. You believe\n evolution can pay=\r\n a kind of tax for going against the pressure towards \nlow connectivity: &quot;i=\r\nf a certain phenotype pays for its wiring by \nincreasing fitness, it can ad=\r\nd high-connectivity areas anywhere that \nthey are useful.&quot; But in a delicat=\r\ne balancing act where the best option \nis likely some middle ground, that s=\r\nounds too much like gambling and \nit&#39;s vulnerable to deception in cases whe=\r\nre there is no immediate \nfitness benefit (whereas encoding is orthogonal t=\r\no fitness). With \nencoding you don&#39;t have the play that game. Encoding can =\r\ncreate its own \ntendency towards some middle ground and canalize that tende=\r\nncy over \ntime. &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;If there is n=\r\no \nfitness gradient toward such a bias toward intermediate connectivity, \nw=\r\nhy would it evolve? Evolution can only think short term. I&#39;ll give you \ntha=\r\nt an encoding bias might override the fitness gradient by making it \nimposs=\r\nible to follow, but I don&#39;t buy that evolution can magically \nfigure out bi=\r\nases that are helpful in the long-term if the short-term \nfitness gradients=\r\n all point in another direction. Or, at least, that&#39;s \nsomething we hope th=\r\nat evolution might do, but it&#39;s a controversial, \nunproven, and theoretical=\r\nly tricky issue that I certain don&#39;t think we \ncan bank on happening until =\r\nwe understand it a lot more.&nbsp;&lt;/div&gt;&lt;br&gt;&lt;/blockquote&gt;I think the proble=\r\nm is that you are thinking of evolution as &quot;thinking&quot; short term or long te=\r\nrm, and that you are hoping that some &quot;gradient&quot; will somehow describe for =\r\nus the right path over all these disparate timescales.&nbsp;&nbsp; Evolutio=\r\nn indeed cannot think ahead.&nbsp; Its job when it thrives is to try many t=\r\nhings and see where they go.&nbsp; Ad hoc a priori gradients will only get =\r\nin the way of that.&nbsp; Give the encoding the ability to support such div=\r\nersified exploration and canalize the best of it, and evolution need not be=\r\n thinking at all.&nbsp; &lt;br&gt;&lt;br&gt;&lt;blockquote&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div =\r\nstyle=3D&quot;background-color: rgb(255, 255, 255);&quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div=\r\n id=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;While\n you worry that modularity =\r\nmight &quot;evolve away,&quot; the idea that it cannot \nevolve away to varying degree=\r\ns sounds worse to me. Natural evolution is \ngenerally good about not keepin=\r\ng all its eggs in one basket - a trait \nmay evolve away in some branches bu=\r\nt not in others. But for you to make \nan all-out attempt to bar such a devi=\r\nation from square one is making a \nlot of strong assumptions about what we =\r\nwant to see 1 billion years in \nthe future.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;=\r\n/div&gt;&lt;/blockquote&gt;&lt;div&gt;I&#39;d argue that your \nbias in the first replicator wi=\r\nthout any sustained fitness pressure \nwould have zero effect on creatures a=\r\n billion years later, especially in\n the case where there is an active fitn=\r\ness gradient by default away from\n modularity (which we know there is, sinc=\r\ne modularity never evolves \nwithout a bias or fitness pressure). Evolution =\r\nwould not keep any eggs \nin a basket with an active fitness penalty, at lea=\r\nst not for a billion \nyears. My 1-billion-years-later influence may thus be=\r\n imperfect, but it \nat least exists!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;=\r\nThat&#39;s why I don&#39;t like the word bias as much when it comes to encoding.&nb=\r\nsp; I&#39;d think of it more as an option.&nbsp; Evolution can try everything -=\r\n preserve it in some lineages, to a less degree in others, and not at all i=\r\nn others still.&nbsp; The ability to commit to subtlety is the magic here.&=\r\nnbsp; That&#39;s the smart strategy - keep your options open but also have the =\r\nchance to commit to an option when it&#39;s working for you.&nbsp; A single blu=\r\nnt bias imposed for a billion years (which is about closing off options) do=\r\nes not sound like a smart strategy in a search space more astronomical than=\r\n imagination itself.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;di=\r\nv style=3D&quot;background-color: rgb(255, 255, 255);&quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;&gt;&lt;d=\r\niv id=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nSo I&#39;m still a fan of manipula=\r\nting encoding over manipulating fitness. \nBut I would not entirely despair =\r\non fitness because there will still be \ncases where there is no clear optio=\r\nn for manipulating the encoding. But \nsuch scenarios are not ones we should=\r\n be hoping for.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;I do =\r\nthink you make \nsome great arguments for encodings, but I cannot envision a=\r\n case in \nwhich an initial bias only makes a huge difference in the long-te=\r\nrm. \nThat&#39;s true even if the bias is neutral with respect to fitness (becau=\r\nse\n it would drift away), but seems a certainty to me if it relates to a \nb=\r\nias that has an active fitness penalty. The whole point of canalization\n is=\r\n that it figures out what produces fit offspring and generates that \ntype o=\r\nf organism: if modular creatures are less fit in the short term, \nevolution=\r\n will canalize away from modularity, not toward it. That said, \nas I mentio=\r\nned at the beginning of this conversation, I do think that a \nsustained enc=\r\noding bias of some sort is an interesting approach that \ncould work, althou=\r\ngh it may be that all we have to do is provide a \nfitness cost and then the=\r\n encoding will canalize in a way that produces \nsuch a sustained bias. :-)&lt;=\r\n/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;div&gt;I think your view of evolution here is too line=\r\nar (as opposed to branching), which is why you tend to worry about things l=\r\nike what is good in the short term or long term.&nbsp; But the idea that yo=\r\nu can impose these blunt constraints on evolution for eternity fits with a =\r\nlinear perspective, so it makes sense if that&#39;s how you view it, as a kind =\r\nof step-by-step succession along a single chain.&nbsp; But I think evolutio=\r\nn in nature is not walking this single tightrope towards some kind of near-=\r\noptimal ideal, where all our effort needs to focus on not falling off the t=\r\nightrope. &nbsp; That is a very objective view, and I think the evidence is=\r\n pointing more and more towards why that kind of perspective has been an im=\r\npediment for us.&nbsp; But I agree the conversation has been great and hope=\r\n I made my points respectfully.&nbsp;&nbsp; I realize we&#39;re wading into con=\r\ntroversy and that reasonable minds can disagree here.&lt;br&gt;&lt;br&gt;Best,&lt;br&gt;&lt;br&gt;k=\r\nen&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;\n\n\r\n--4-3208815244-4326035847=:9--\r\n\n"}}