{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":434634266,"authorName":"Vassilis Vassiliades","from":"Vassilis Vassiliades &lt;vassilisvas@...&gt;","profile":"v.vassiliades","replyTo":"LIST","senderId":"stJTA9219cOtci12eQTmVkvZkPnUhwvF2bHOzmfQ5iUmWODKjRd1aoCTSXpZcUb4aUOVNbZ4btxWptOmOgbR8tvxiuGg9BngDnAtBSgTVvt9K0g","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: GECCO Paper on HyperNEAT","postDate":"1371482350","msgId":6153,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBTnRYaG11REFLZEp3OTN0cy05UGc3UmdhWTdSOHlCLVVTRHhMc2FtZXdUX1RlN0pYQUBtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PGtwbXRlYitlcWd2QGVHcm91cHMuY29tPg==","referencesHeader":"PGtvdGtoZytoZ3Z1QGVHcm91cHMuY29tPgk8a3BtdGViK2VxZ3ZAZUdyb3Vwcy5jb20+"},"prevInTopic":6151,"nextInTopic":6154,"prevInTime":6152,"nextInTime":6154,"topicId":6085,"numMessagesInTopic":14,"msgSnippet":"Hi Shimon, I have some questions regarding what you said about using bandit algorithms to design NN/CPPN topologies. Do you believe that in order to tackle","rawEmail":"Return-Path: &lt;vassilisvas@...&gt;\r\nX-Sender: vassilisvas@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 69214 invoked by uid 102); 17 Jun 2013 15:19:10 -0000\r\nX-Received: from unknown (HELO mtaq6.grp.bf1.yahoo.com) (10.193.84.37)\n  by m7.grp.bf1.yahoo.com with SMTP; 17 Jun 2013 15:19:10 -0000\r\nX-Received: (qmail 20985 invoked from network); 17 Jun 2013 15:19:10 -0000\r\nX-Received: from unknown (HELO mail-pa0-f46.google.com) (209.85.220.46)\n  by mtaq6.grp.bf1.yahoo.com with SMTP; 17 Jun 2013 15:19:10 -0000\r\nX-Received: by mail-pa0-f46.google.com with SMTP id fa11so2968112pad.19\n        for &lt;neat@yahoogroups.com&gt;; Mon, 17 Jun 2013 08:19:10 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.67.22.99 with SMTP id hr3mr13120324pad.12.1371482350408;\n Mon, 17 Jun 2013 08:19:10 -0700 (PDT)\r\nX-Received: by 10.70.83.73 with HTTP; Mon, 17 Jun 2013 08:19:10 -0700 (PDT)\r\nIn-Reply-To: &lt;kpmteb+eqgv@...&gt;\r\nReferences: &lt;kotkhg+hgvu@...&gt;\n\t&lt;kpmteb+eqgv@...&gt;\r\nDate: Mon, 17 Jun 2013 18:19:10 +0300\r\nMessage-ID: &lt;CANtXhmuDAKdJw93ts-9Pg7RgaY7R8yB-USDxLsamewT_Te7JXA@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=047d7b5da53b4fda3004df5b1e56\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Vassilis Vassiliades &lt;vassilisvas@...&gt;\r\nSubject: Re: [neat] Re: GECCO Paper on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=434634266; y=vbxcJMw2EGvTiWwhxBH9PyLC_v1e3NTXsZDjq_l-urxlKjpAxp1DCQ\r\nX-Yahoo-Profile: v.vassiliades\r\n\r\n\r\n--047d7b5da53b4fda3004df5b1e56\r\nContent-Type: text/plain; charset=UTF-8\r\n\r\nHi Shimon,\n\nI have some questions regarding what you said about using bandit algorithms\nto design NN/CPPN topologies.\n\nDo you believe that in order to tackle this problem, one would need\ncontextual bandit algorithms, where the state would be the current NN\ntopology?\n\nIf there are actions that correspond to the addition and deletion of nodes\nand connections, the dimensionality of the context/policy would change\nduring learning. So, I am wondering whether you know of any algorithms or\ntechniques that could deal with such problems, where the dimensionality of\nthe state is not fixed.\n\nBest,\nVassilis\n\n\n\nOn Mon, Jun 17, 2013 at 2:54 PM, shimonw &lt;shimon@...&gt; wrote:\n\n&gt; **\n&gt;\n&gt;\n&gt; Hi Ken,\n&gt;\n&gt; If I may, I&#39;d like to offer a couple reactions to your latest message.\n&gt; This is indeed an interesting discussion that touches on many potentially\n&gt; important issues. I hope I can offer a useful perspective on these topics.\n&gt;\n&gt; You are right that in a target-based scenario there can be many CPPNs that\n&gt; generate the same phenotype. But the CPPN is a genotype, not a phenotype.\n&gt; In what I&#39;m calling &quot;regular&quot; FFs, there are potentially many *phenotypes*\n&gt; that solve the problem, and for each of them potentially many genotypes. So\n&gt; in my mind, there is still a useful distinction between target based FFs\n&gt; and regular FFs, though they are perhaps best seen as different points on a\n&gt; spectrum.\n&gt;\n&gt; If I understand correctly, you are suggesting that the important\n&gt; distinction is how the FF interacts with the search process. But to me,\n&gt; this is a difficult criterion to use because the search process could be\n&gt; anything. The space of possible black-box optimization methods is huge, and\n&gt; what encourages piecewise incremental progress for one method may not for\n&gt; another.\n&gt;\n&gt; I don&#39;t pretend to know what kind of algorithm would generate\n&gt; Einstein-level intelligence (I don&#39;t even know if this is a useful goal).\n&gt; But as a researcher I highly respect once told me, &quot;your failure to imagine\n&gt; it does not constitute a proof that it cannot be done.&quot;\n&gt;\n&gt; That&#39;s why I think your hypothesis is quite a bold one, because it looks\n&gt; at the limitations of a specific class of black-box optimization methods\n&gt; and generalizes them to all possible black-box optimization methods.\n&gt;\n&gt; To give just one example of the possibilities here: algorithms for\n&gt; continuous-armed bandits, such as X-armed bandits and Bayesian optimization\n&gt; methods such as GP-UCB, can be applied to black-box optimization. These\n&gt; methods avoid the problem of local optima in a principled way, by\n&gt; maintaining a posterior distribution over the global FF, and using optimism\n&gt; in the face of uncertainty to ensure sufficient exploration of the solution\n&gt; space. As a result, these methods have very nice theoretical properties,\n&gt; like guaranteed convergence to the global optimum in the limit and\n&gt; logarithmic regret bounds along the way.\n&gt;\n&gt; As far as I know, no one has tried to develop versions of these methods\n&gt; that can discover NN topologies, and which would thus be suitable for\n&gt; optimizing CPPNs or other indirect encodings. But there&#39;s no a priori\n&gt; reason to think it can&#39;t be done. I&#39;m not saying this would necessarily\n&gt; work or even that it&#39;s the most promising approach to explore. I&#39;m just\n&gt; saying it&#39;s one example of a principled approach that could avoid all the\n&gt; difficulties you mention and which we currently have no strong reason to\n&gt; eliminate from contention.\n&gt;\n&gt; So I think it&#39;s quite likely that these hard FFs are not unsolvable, but\n&gt; just that current methods cannot solve them. Rather than giving up on them,\n&gt; in my opinion we should be focusing on developing better methods for them.\n&gt;\n&gt; Regarding whether 6 nodes is a lot to represent fracture, I think the same\n&gt; point applies: just because we can&#39;t think of a better way to do it,\n&gt; doesn&#39;t mean it doesn&#39;t exist. Our paper establishes 6 as an upper bound,\n&gt; which can be easily done by example. If I understand correctly, you are\n&gt; suggesting that 6 may be a lower bound, which is much more difficult to\n&gt; demonstrate.\n&gt;\n&gt; I could definitely imagine that a different type of network, or one with a\n&gt; different set of activation functions, might be able to make better use of\n&gt; 6 nodes. Even if it&#39;s true that there&#39;s a trade-off, and using fewer nodes\n&gt; means less flexibility, there may be many cases where that&#39;s a favorable\n&gt; trade-off. We should at least be open to the possibility that it some cases\n&gt; the sweet spot is not a representation that requires 6 nodes for fracture.\n&gt;\n&gt; I&#39;m looking forward to chatting more about this at GECCO.\n&gt;\n&gt; Cheers,\n&gt; Shimon\n&gt;\n\r\n--047d7b5da53b4fda3004df5b1e56\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;Hi Shimon,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div style&gt;I have some questions =\r\nregarding what you said about using bandit algorithms to design NN/CPPN top=\r\nologies.&lt;/div&gt;&lt;div style&gt;&lt;br&gt;&lt;/div&gt;&lt;div style&gt;Do you believe that in order =\r\nto tackle this problem, one would need contextual bandit algorithms, where =\r\nthe state would be the current NN topology?&lt;/div&gt;\n&lt;div style&gt;&lt;br&gt;&lt;/div&gt;&lt;div=\r\n style&gt;If there are actions that correspond to the addition and deletion of=\r\n nodes and connections, the dimensionality of the context/policy would chan=\r\nge during learning. So, I am wondering whether you know of any algorithms o=\r\nr techniques that could deal with such problems, where the dimensionality o=\r\nf the state is not fixed.&lt;/div&gt;\n&lt;div style&gt;&lt;br&gt;&lt;/div&gt;&lt;div style&gt;Best,&lt;/div&gt;=\r\n&lt;div style&gt;Vassilis&lt;/div&gt;&lt;div style&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div class=3D&quot;gmail_extr=\r\na&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On Mon, Jun 17, 2013 at 2:54 PM, shim=\r\nonw &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:shimon@...&quot; target=3D&quot;=\r\n_blank&quot;&gt;shimon@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;\n&lt;blockquote class=3D&quot;=\r\ngmail_quote&quot; style=3D&quot;margin:0px 0px 0px 0.8ex;border-left-width:1px;border=\r\n-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex&quot;&gt;\n\n\n&lt;=\r\nu&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n\n&lt;div style&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n    &lt;div=\r\n&gt;\n      \n      \n      &lt;p&gt;Hi Ken,&lt;br&gt;\n&lt;br&gt;\nIf I may, I&#39;d like to offer a=\r\n couple reactions to your latest message.  This is indeed an interesting di=\r\nscussion that touches on many potentially important issues.  I hope I can o=\r\nffer a useful perspective on these topics.&lt;br&gt;\n\n&lt;br&gt;\nYou are right that in =\r\na target-based scenario there can be many CPPNs that generate the same phen=\r\notype.  But the CPPN is a genotype, not a phenotype. In what I&#39;m callin=\r\ng &quot;regular&quot; FFs, there are potentially many *phenotypes* that sol=\r\nve the problem, and for each of them potentially many genotypes.  So in my =\r\nmind, there is still a useful distinction between target based FFs and regu=\r\nlar FFs, though they are perhaps best seen as different points on a spectru=\r\nm.&lt;br&gt;\n\n&lt;br&gt;\nIf I understand correctly, you are suggesting that the importa=\r\nnt distinction is how the FF interacts with the search process.  But to me,=\r\n this is a difficult criterion to use because the search process could be a=\r\nnything.  The space of possible black-box optimization methods is huge, and=\r\n what encourages piecewise incremental progress for one method may not for =\r\nanother.&lt;br&gt;\n\n&lt;br&gt;\nI don&#39;t pretend to know what kind of algorithm would=\r\n generate Einstein-level intelligence (I don&#39;t even know if this is a u=\r\nseful goal). But as a researcher I highly respect once told me, &quot;your =\r\nfailure to imagine it does not constitute a proof that it cannot be done.&q=\r\nuot;&lt;br&gt;\n\n&lt;br&gt;\nThat&#39;s why I think your hypothesis is quite a bold one, =\r\nbecause it looks at the limitations of a specific class of black-box optimi=\r\nzation methods and generalizes them to all possible black-box optimization =\r\nmethods.  &lt;br&gt;\n\n&lt;br&gt;\nTo give just one example of the possibilities here: al=\r\ngorithms for continuous-armed bandits, such as X-armed bandits and Bayesian=\r\n optimization methods such as GP-UCB, can be applied to black-box optimizat=\r\nion.  These methods avoid the problem of local optima in a principled way, =\r\nby maintaining a posterior distribution over the global FF, and using optim=\r\nism in the face of uncertainty to ensure sufficient exploration of the solu=\r\ntion space.  As a result, these methods have very nice theoretical properti=\r\nes, like guaranteed convergence to the global optimum in the limit and loga=\r\nrithmic regret bounds along the way. &lt;br&gt;\n\n&lt;br&gt;\nAs far as I know, no one ha=\r\ns tried to develop versions of these methods that can discover NN topologie=\r\ns, and which would thus be suitable for optimizing CPPNs or other indirect =\r\nencodings.  But there&#39;s no a priori reason to think it can&#39;t be don=\r\ne.  I&#39;m not saying this would necessarily work or even that it&#39;s th=\r\ne most promising approach to explore.  I&#39;m just saying it&#39;s one exa=\r\nmple of a principled approach that could avoid all the difficulties you men=\r\ntion and which we currently have no strong reason to eliminate from content=\r\nion.&lt;br&gt;\n\n&lt;br&gt;\nSo I think it&#39;s quite likely that these hard FFs are not=\r\n unsolvable, but just that current methods cannot solve them.  Rather than =\r\ngiving up on them, in my opinion we should be focusing on developing better=\r\n methods for them.&lt;br&gt;\n\n&lt;br&gt;\nRegarding whether 6 nodes is a lot to represen=\r\nt fracture, I think the same point applies: just because we can&#39;t think=\r\n of a better way to do it, doesn&#39;t mean it doesn&#39;t exist.  Our pape=\r\nr establishes 6 as an upper bound, which can be easily done by example.  If=\r\n I understand correctly, you are suggesting that 6 may be a lower bound, wh=\r\nich is much more difficult to demonstrate.&lt;br&gt;\n\n&lt;br&gt;\nI could definitely ima=\r\ngine that a different type of network, or one with a different set of activ=\r\nation functions, might be able to make better use of 6 nodes.  Even if it&#=\r\n39;s true that there&#39;s a trade-off, and using fewer nodes means less fl=\r\nexibility, there may be many cases where that&#39;s a favorable trade-off. =\r\n We should at least be open to the possibility that it some cases the sweet=\r\n spot is not a representation that requires 6 nodes for fracture.&lt;br&gt;\n\n&lt;br&gt;=\r\n\nI&#39;m looking forward to chatting more about this at GECCO.&lt;br&gt;\n&lt;br&gt;\nChe=\r\ners,&lt;br&gt;\nShimon=C2=A0&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;=\r\n/div&gt;&lt;/div&gt;\n\r\n--047d7b5da53b4fda3004df5b1e56--\r\n\n"}}