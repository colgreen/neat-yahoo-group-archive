{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":90508071,"authorName":"snapmedown","from":"&quot;snapmedown&quot; &lt;snapmedown@...&gt;","profile":"snapmedown","replyTo":"LIST","senderId":"RP5xjDYUk7VlmBlCVmc5DoFYyISn154J-ZcsTztDs31ONz7NvDNPs10F1gCH7PxrrgMAVQYWgaKlPG51Hu5IG_GGtaTjKet8O4I","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Discrete Neural Networks","postDate":"1260316375","msgId":4991,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhmbW9zbitpNjI3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDcyN2E0MDZjMDkxMjA4MTUxMGk1MTRlMTQ4NnM5YzYxYzczYjdhZjIwOWQzQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4990,"nextInTopic":4993,"prevInTime":4990,"nextInTime":4992,"topicId":4984,"numMessagesInTopic":16,"msgSnippet":"... Exactly.  I would use NEAT as a structure building algorithm vice both structure and weights.  Large scale changes would occur with connections with what","rawEmail":"Return-Path: &lt;snapmedown@...&gt;\r\nX-Sender: snapmedown@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 43183 invoked from network); 8 Dec 2009 23:52:57 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m14.grp.re1.yahoo.com with QMQP; 8 Dec 2009 23:52:57 -0000\r\nX-Received: from unknown (HELO n37b.bullet.mail.sp1.yahoo.com) (66.163.168.151)\n  by mta1.grp.re1.yahoo.com with SMTP; 8 Dec 2009 23:52:57 -0000\r\nX-Received: from [69.147.65.148] by n37.bullet.mail.sp1.yahoo.com with NNFMP; 08 Dec 2009 23:52:57 -0000\r\nX-Received: from [98.137.34.36] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 08 Dec 2009 23:52:57 -0000\r\nDate: Tue, 08 Dec 2009 23:52:55 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hfmosn+i627@...&gt;\r\nIn-Reply-To: &lt;727a406c0912081510i514e1486s9c61c73b7af209d3@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;snapmedown&quot; &lt;snapmedown@...&gt;\r\nSubject: Re: Discrete Neural Networks\r\nX-Yahoo-Group-Post: member; u=90508071; y=zLtlNSLsGXzd_i7VIkUHVPrPkFLC3n_QmtgFejV8SxgOlN8bMQ\r\nX-Yahoo-Profile: snapmedown\r\n\r\n&gt; If I&#39;m following you right I think you just end up having to evolve\n&gt; lar=\r\nger networks to represent equivalent functionality (to a normal\n&gt; ANN). So =\r\nyou end up searching a /different/ fitness landscape* of the\n&gt; same complex=\r\nity, not a landscape with less complexity.\n&gt; \n&gt; * More correctly a differen=\r\nt version/transformation of the same landscape.\n\nExactly.  I would use NEAT=\r\n as a structure building algorithm vice both structure and weights.  Large =\r\nscale changes would occur with connections with what we would call the most=\r\n significant bits, while optimization is done via connections involving the=\r\n least significant bits.  To get equivalent function, I WILL have to create=\r\n larger networks.\n\nIn the beginning of an evolution, those species with sig=\r\nnificant-bit connections will evolve into fitness faster.  Near the end of =\r\nan evolution the least-significant-bit connections will probably provide th=\r\ne best mutations, but novel behavior can still emerge with a significant-bi=\r\nt mutation.\n\nI understand what you mean by still searching the same complex=\r\nity.  Any technique we look at from the classical optimizations to back-pro=\r\npagation to NEAT all search the same complexity, what differs is the assump=\r\ntions each makes about the landscape.  The assumption my digital NN makes i=\r\ns that the peak is wide enough to accommodate one of those hill-steps.\n\n\n"}}