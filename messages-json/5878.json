{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"NXFygSGUWu77ODPrF3z7uxi7wKk5eOsE7E0QwsVaPXS-9pEfeNnKaY5SHY5srLlJqRzjG1e9UXTxDLY3N2G2LtL1MSzI","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: New Youtube Video of Talk on Novelty and Objectives","postDate":"1348108215","msgId":5878,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGszZHYzbitsbmNvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PENBRTBNK1lmQWVzcVRDaCtodlNKQkdmVU5LMj1zV0M5Z2pjT2VlT2h6MWVLQ1MyVkhnZ0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":5851,"nextInTopic":0,"prevInTime":5877,"nextInTime":5879,"topicId":5850,"numMessagesInTopic":3,"msgSnippet":"Hi Colin, I just wanted to note that I appreciated your analogy here with Deep Learning and backprop.  I agree that objective optimization could still have a","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 38220 invoked from network); 20 Sep 2012 02:30:15 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m15.grp.sp2.yahoo.com with QMQP; 20 Sep 2012 02:30:15 -0000\r\nX-Received: from unknown (HELO ng11-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.88)\n  by mta5.grp.sp2.yahoo.com with SMTP; 20 Sep 2012 02:30:15 -0000\r\nX-Received: from [98.139.164.123] by ng11.bullet.mail.bf1.yahoo.com with NNFMP; 20 Sep 2012 02:30:15 -0000\r\nX-Received: from [98.137.34.119] by tg4.bullet.mail.bf1.yahoo.com with NNFMP; 20 Sep 2012 02:30:15 -0000\r\nDate: Thu, 20 Sep 2012 02:30:15 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;k3dv3n+lnco@...&gt;\r\nIn-Reply-To: &lt;CAE0M+YfAesqTCh+hvSJBGfUNK2=sWC9gjcOeeOhz1eKCS2VHgg@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New Youtube Video of Talk on Novelty and Objectives\r\nX-Yahoo-Group-Post: member; u=54567749; y=UUbFa5ciXlZYMr3R2LE56rtavpgrDXV0IhDzI77bf4UjR3wqUSbv\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Colin, I just wanted to note that I appreciated your analogy here with=\r\n Deep Learning and backprop.  I agree that objective optimization could sti=\r\nll have a role to play, but (as you point out) it&#39;s more like the role of b=\r\nackprop with Deep Learning - something to do at the end once the hard work =\r\nhas been completed by something else.\n\nken\n\n--- In neat@yahoogroups.com, Co=\r\nlin Green &lt;colin.green1@...&gt; wrote:\n&gt;\n&gt; Superb. Thanks Ken.\n&gt; \n&gt; Regarding =\r\nthe question right at the end about applying objective\n&gt; search once near a=\r\n good solution. If we take the maze example, I would\n&gt; say that once we hav=\r\ne one (or a few) solutions that get through the\n&gt; maze, we can run objectiv=\r\ne search to find robots that are faster\n&gt; and/or take more direct/efficient=\r\n routes - because the paths followed\n&gt; by the robots produced by novelty mi=\r\nght tend to wander around a bit.\n&gt; \n&gt; This reminds me of Geoff Hinton&#39;s vie=\r\nw of back propagation in his\n&gt; talks on deep learning (which I may have men=\r\ntioned before). Back prop\n&gt; is essentially gradient descent towards optimal=\r\n connection weights,\n&gt; but the error signal is so weaked after being propag=\r\nated through only\n&gt; a few layers, that the gradient is pretty much dwarfed =\r\nby noise. Deep\n&gt; learning solves the problem of finding weights in networks=\r\n with many\n&gt; layers and thus solves the problem of abstract recognition and=\r\n\n&gt; modelling. Once you have those weights you can run backprop to\n&gt; optimis=\r\ne the solution - and it works well in that role even when\n&gt; applied to nets=\r\n with many layers.\n&gt; \n&gt; So the original method that was the focus of much a=\r\nttention (backprop)\n&gt; became a stepping stone to a much stronger method, bu=\r\nt remained as an\n&gt; optimisation to the new method. The basic goal and idea =\r\nwas there, but\n&gt; the method is/was too direct in how it goes about finding =\r\nthe goal\n&gt; states.\n&gt; \n&gt; Colin\n&gt;\n\n\n\n"}}