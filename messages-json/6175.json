{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"u11Q5l4W_xBy5sMr_vWpUz-y78SA3gJaid4ZO81_aN1UK6-cZBZ-5jE4Db4GExncznsPrZnbGCSjj2tF-l4QnJ3lka8m","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Impressively Smart, Non-Evolved Neural Network","postDate":"1374681135","msgId":6175,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtzb3Q3ZittNHJsQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDdGNzMxQzk3LTI5MTYtNDA2OS04MkY2LTk0QzAxNTA3MDlBNUBnbWFpbC5jb20+"},"prevInTopic":6172,"nextInTopic":6178,"prevInTime":6174,"nextInTime":6176,"topicId":6171,"numMessagesInTopic":4,"msgSnippet":"Hi Jeff, thanks for sharing this paper with the group.  It s a thought-provoking piece of work and a good impetus for discussion. By the way, here s one","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 99085 invoked by uid 102); 24 Jul 2013 15:52:17 -0000\r\nX-Received: from unknown (HELO mtaq3.grp.bf1.yahoo.com) (10.193.84.142)\n  by m4.grp.bf1.yahoo.com with SMTP; 24 Jul 2013 15:52:17 -0000\r\nX-Received: (qmail 23569 invoked from network); 24 Jul 2013 15:52:17 -0000\r\nX-Received: from unknown (HELO ng5-vm7.bullet.mail.gq1.yahoo.com) (98.136.219.59)\n  by mtaq3.grp.bf1.yahoo.com with SMTP; 24 Jul 2013 15:52:17 -0000\r\nX-Received: from [216.39.60.219] by ng5.bullet.mail.gq1.yahoo.com with NNFMP; 24 Jul 2013 15:52:16 -0000\r\nX-Received: from [10.193.94.42] by tg11.bullet.mail.gq1.yahoo.com with NNFMP; 24 Jul 2013 15:52:16 -0000\r\nDate: Wed, 24 Jul 2013 15:52:15 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ksot7f+m4rl@...&gt;\r\nIn-Reply-To: &lt;7F731C97-2916-4069-82F6-94C0150709A5@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Impressively Smart, Non-Evolved Neural Network\r\nX-Yahoo-Group-Post: member; u=54567749; y=1kcyYImu96z5P3DUw1q4rrWNCgEqHYdEDkKFp_5nfdsDDi9qSnVs\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Jeff, thanks for sharing this paper with the group.  It&#39;s a thought-pr=\r\novoking piece of work and a good impetus for discussion.  \n\nBy the way, her=\r\ne&#39;s one critical commentary from online (critiques can be hard to find with=\r\n a lot of gratuitous media coverage around):\n\nhttp://www.i-programmer.info/=\r\nnews/105-artificial-intelligence/5158-the-truth-about-spaun-the-brain-simul=\r\nation.html\n\nAnyway, my own opinion is that this work (called &quot;Spaun&quot;) is no=\r\n reason for pessimism about neuroevolution.  I don&#39;t think it&#39;s ultimately =\r\nmuch more impressive than anything we&#39;ve done in our field.  Many of the ta=\r\nsks it performs would be easy to program without neural networks, just like=\r\n the stuff we evolve.  Mainly it simply has more parts (strung together by =\r\nhand) than the stuff we usually evolve.  Also, while perhaps we could not e=\r\nvolve a neural network to do some of the tasks it  performs, it&#39;s important=\r\n to recognize that Spaun likely could not perform some of the tasks that we=\r\n evolve (e.g. breaking Keepaway records or learning to control Octopus arms=\r\n with arbitrary numbers of segments).  \n\nHowever, that doesn&#39;t mean it&#39;s un=\r\ninteresting.  It&#39;s a very different approach than neuroevolution and as suc=\r\nh provides us food for thought (as I imagine we would also provide them).  =\r\n\n\nBut the nuts and bolts of what is going on here ultimately is not that im=\r\npressive because it is a patchwork of modules that were specifically design=\r\ned to perform canned tasks (the authors note it cannot learn new tasks). Fo=\r\nr example, translating the intent to output a &quot;3&quot; to the arm movements that=\r\n draw a &quot;3&quot; is an independent problem that is entirely possible to engineer=\r\n by hand, even with neurons. Then tacking such a capability onto the output=\r\n of such a system just makes it look more impressive and &quot;real.&quot;  \n\nThese m=\r\nodular canned structures are in effect like subroutines.  Yet instead of be=\r\ning compiled from a programming language into machine language, they are co=\r\nmpiled from a high-level design into a fixed (i.e. mainly non-plastic) neur=\r\nal realization.  The &quot;NEF&quot; technique at the heart of the system is basicall=\r\ny a clever way of compiling a function f(x) into a set of spiking neurons. =\r\n But the overall architecture is carefully hand-designed at a high-level.  =\r\nThat is, in a sense it is less organic (and less plastic) than you would ho=\r\npe if you really wanted it to be like a brain.  As the critique linked abov=\r\ne says, it is a bit misleading the way it is packaged because the packaging=\r\n makes it look more brain-like than it is.\n\nYet I also think that character=\r\nizing this overall project as an example of hype is going too far.  Rather,=\r\n it is an example of people spending years building sophisticated canned mo=\r\ndels of specific phenomena and then stitching them together, which is kind =\r\nof the philosophically opposite approach to neuroevolution.   In neuroevolu=\r\ntion, we are trying to find general principles that generate complex brain-=\r\nlike architectures.  In the Spaun approach, humans search for the architect=\r\nures based on current spotty knowledge of neural mechanisms in the brain mi=\r\nxed with human intuition.  My instinct is that the problem of reconstitutin=\r\ng the complete architecture of a biological brain based on such a do-it-you=\r\nrself approach is ultimately too monumental for us mortal humans, though I&#39;=\r\nd be happy to be proven wrong.  But that is why philosophically I am more d=\r\nisposed towards the neuroevolution approach, which respects the monumental =\r\nnature of the problem by investing instead in the kinds of processes that p=\r\nroduce complexity on their own (as evolution did on Earth).  \n\nNevertheless=\r\n, both communities can probably fruitfully learn something from each other.=\r\n  All the brute force that goes into trying to engineer a brain probably le=\r\nads to underlying building blocks that could be raw material for evolution =\r\nto mold to its own purposes.    But we have to be very careful because what=\r\n is deeply insightful versus what is ad hoc in such models is unfortunately=\r\n highly opaque to outsiders (as Randy also notes), and the way they are pre=\r\nsented does not do much service towards those trying to tease apart the two=\r\n.  One of the unfortunate aspects of Spaun is that I would be skeptical tha=\r\nt anyone outside its creators can actually fully grasp what it actually doe=\r\ns because it is a patchwork of so many separate ideas from years of ad hoc =\r\ntinkering, many of which are left entirely to references.  Yet that is also=\r\n one of the reasons it is so tantalizing - by being almost intangibly compl=\r\nex, it feels a bit like somebody built a brain.\n\nBest,\n\nken\n\n\n--- In neat@y=\r\nahoogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello all,\n&gt; \n&gt; At GECCO=\r\n there were a few different conversations about whether neuroevolution rema=\r\nins a promising path to AI given the progress being made in other AI/neural=\r\n network areas relative to the progress in neuroevolution. One issue mentio=\r\nned a few times was this recent paper that shows surprisingly impressive AI=\r\n in a non-evolved neural network. \t\n&gt; \n&gt; http://clm.utexas.edu/compjclub/pa=\r\npers/Eliasmith2012.pdf\n&gt; \n&gt; Many people on this list expressed an interest =\r\nin reading this paper and discussing its techniques and implications on the=\r\n NEAT list. \n&gt; \n&gt; I don&#39;t understand their learning mechanisms (because I h=\r\nave not taken the time to read the papers they reference), but if someone d=\r\noes get a good grasp on how the magic happens, please share your take. More=\r\n generally, I&#39;d be interested in any of your reactions regarding whether yo=\r\nu agree that this  is a very impressive level of intelligence (and well bey=\r\nond what we can currently evolve) and whether that means we should question=\r\n our devotion to neuroevolution as one of the quickest paths to AGI. I want=\r\n to note that I&#39;m not (yet!) taking a position, but am just curious to hear=\r\n what you think. \n&gt; \n&gt; Let the discussion begin!\n&gt; \n&gt; \n&gt; Best regards,\n&gt; Je=\r\nff Clune\n&gt; \n&gt; Assistant Professor\n&gt; Computer Science\n&gt; University of Wyomin=\r\ng\n&gt; jeffclune@...\n&gt; jeffclune.com\n&gt;\n\n\n\n"}}