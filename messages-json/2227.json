{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":197999825,"authorName":"John Arrowwood","from":"John Arrowwood &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"ynoPVC16v-x05LKEke7t5mDNjh9EWdzN0d-juqhC0cAL8xoa5PM0zhpSULZSdiEm_0j9Fe-RItit09W1ktqCUUUW1aR5DmDn-jU","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Introduction---recurrency question","postDate":"1125534427","msgId":2227,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUxN2ZhNmYxMDUwODMxMTcyNzc1OWU1Y2RjQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PGRmNTBrcStlMTFyQGVHcm91cHMuY29tPg==","referencesHeader":"PGRmMzh1MCtkNGhvQGVHcm91cHMuY29tPiA8ZGY1MGtxK2UxMXJAZUdyb3Vwcy5jb20+"},"prevInTopic":2226,"nextInTopic":2229,"prevInTime":2226,"nextInTime":2228,"topicId":2209,"numMessagesInTopic":42,"msgSnippet":"Kevin, What you ve described here is far too complicated.  You re doing too much work.  Try this: For a given network topology, you only need to determine the","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 90154 invoked from network); 1 Sep 2005 00:27:11 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m29.grp.scd.yahoo.com with QMQP; 1 Sep 2005 00:27:11 -0000\r\nReceived: from unknown (HELO wproxy.gmail.com) (64.233.184.207)\n  by mta1.grp.scd.yahoo.com with SMTP; 1 Sep 2005 00:27:11 -0000\r\nReceived: by wproxy.gmail.com with SMTP id i7so238160wra\n        for &lt;neat@yahoogroups.com&gt;; Wed, 31 Aug 2005 17:27:07 -0700 (PDT)\r\nReceived: by 10.54.56.56 with SMTP id e56mr1168524wra;\n        Wed, 31 Aug 2005 17:27:07 -0700 (PDT)\r\nReceived: by 10.54.80.10 with HTTP; Wed, 31 Aug 2005 17:27:06 -0700 (PDT)\r\nMessage-ID: &lt;517fa6f10508311727759e5cdc@...&gt;\r\nDate: Wed, 31 Aug 2005 17:27:07 -0700\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;df50kq+e11r@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Disposition: inline\r\nReferences: &lt;df38u0+d4ho@...&gt; &lt;df50kq+e11r@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: John Arrowwood &lt;jarrowwx@...&gt;\r\nReply-To: John@...\r\nSubject: Re: [neat] Re: Introduction---recurrency question\r\nX-Yahoo-Group-Post: member; u=197999825; y=WbYgd_2I-HrYriBmPApJ-w8mVFRb54wPmTNIkr-XNcaVMNc\r\nX-Yahoo-Profile: jarrowwx\r\n\r\nKevin,\n\nWhat you&#39;ve described here is far too complicated.  You&#39;re doing to=\r\no\nmuch work.  Try this:\n\nFor a given network topology, you only need to det=\r\nermine the firing\norder ONCE.  Save that list somewhere.  It will be consul=\r\nted every\ntime the network is activated, which may be thousands of times fo=\r\nr a\nsingle fitness evaluation.  And of course a single network may be\nfitne=\r\nss evaluated multiple times with different scenarios presented to\nit during=\r\n the course of a generation.  And if that topology survives\ninto the next g=\r\neneration, you might as well take that list with it...\n\nWhen you are testin=\r\ng your network, you are testing it in a\n&#39;simulation&#39; where it checks the st=\r\nate of the world.  That determines\nthe values of the &#39;input&#39; nodes.\n\nYou ze=\r\nro out the state of all neurons only ONCE.  AT the beginning of\nthe simulat=\r\nion.\n\nThen, for a single time-step, you fire each neuron in the order that\n=\r\nit exists in the list.  The first time through, if a connection refers\nto a=\r\n neuron that hasn&#39;t fired yet, the output of that neuron is 0, so\nthe input=\r\n value that is sent to the firing neuron is zero.\n\nAt the end of that firin=\r\ng pass, you process the outputs, update the\n&#39;real world&#39; of the simulation,=\r\n and alter the inputs accordingly.  DO\nNOT RESET ANYTHING INSIDE THE NETWOR=\r\nK!  This continues in an infinite\nloop until an exit condition is met, name=\r\nly either failure of the\nnetwork to meet its objective in a timely fashion,=\r\n or success in\naccomplishing the desired goal.\n\nMake sense?  Again, you onl=\r\ny reset neurons once, at the beginning of\nfitness testing (for a given scen=\r\nario).  From that moment on, a\nneuron&#39;s value is retained for the next time=\r\n it is accessed.\n\nHere&#39;s the difference between this approach and the &#39;cano=\r\nnical&#39;\napproach.  In the canonical approach you have two values for every\nn=\r\neuron:  Last timestep&#39;s value, and this timestep&#39;s value.  Or\n&quot;beginning va=\r\nlue&quot; and &quot;ending value&quot;.  For input neurons, they are\nalways one and the sa=\r\nme.  Whenever a neuron references the value of\nanother neuron, it always in=\r\nspects the OLD or beginning value.  Then,\nit doesn&#39;t matter what order you =\r\nprocess the nodes in.  You process\nevery node, one by one, always referenci=\r\nng the old value of that\nneuron.  And you write the new value of the node y=\r\nou are working on to\nthe other or ending value.\n\nIn a standard feed-forward=\r\n network with 3 hidden layers, the first\ntimestep will only propagate the s=\r\nignal one layer down.  At which\npoint, in a &#39;simulation&#39;, the real world in=\r\nputs may change.  Now, the\nvalue of the first hidden layer has been changed=\r\n, so the second layer\nwill be calculated using those modified values.  But =\r\nthe inputs may\nhave changed, so the first layer will change.  But no matter=\r\n, the\nsecond layer is being calculated using the values that were present i=\r\nn\nthe first hidden layer at the end of the last time step.\n\nThe &#39;optimized&#39;=\r\n approach that I was advocating doesn&#39;t bother having a\n&#39;before&#39; and an &#39;af=\r\nter&#39; (or last and current) value.  It just has a\nvalue.  When another node =\r\nreferences the value of a node, it\nreferences the current value of that nod=\r\ne.  As soon as that node gets\ncalculated, the value of the node changes.  I=\r\nn a recurrent network,\nsome nodes my reference the value of a particular no=\r\nde BEFORE it was\nupdated, and others may reference it AFTER.  For the purit=\r\nan, that\n&#39;unpredictability&#39; would be undesirable.  But since you are evolvi=\r\nng a\nnetwork that WORKS, that argument becomes purely academic.\n\nUnless of =\r\ncourse tests show that for a particular experiment it\nrequires more topolog=\r\ny to solve the same problem using the one firing\nmechanism over the other. =\r\n In that case, the academic argument against\ndoing it does in fact hold wei=\r\nght.\n\nBut again, it only matters for a controller, not for a classifier\nnet=\r\nwork that is non-recurrent.  So if you are evolving a non-recurrent\nclassif=\r\nier, and CPU time matters (both during evolution and in the\nfinal product),=\r\n then this optimized routine is for you.  Otherwise,\nI&#39;d make both activati=\r\non schemes available, and test evolve networks\nusing both mechanisms, to fi=\r\nnd out whether or not it makes a\ndifference in the ability to evolve a solu=\r\ntion.\n\nHonestly, I can see that there might be pathological cases where thi=\r\ns\nfiring approach would hinder the evolution of a solution to a\ncontroller.=\r\n  But only for a particular class of problem, and it would\njust mean that t=\r\nhe successful topology will be different under the one\napproach than it wou=\r\nld have been under the other approach.  The\nchances of it being possible to=\r\n evolve a solution under one approach\nthat is impossible to evolve using th=\r\ne other approach are very slim. \nBut only experience can tell us if that is=\r\n true or not.  :p\n\nOn 8/31/05, maitrikaruna &lt;kevin@...&gt; wrote=\r\n:\n&gt; John,\n&gt; \n&gt; thanks for the reply...wish we were all at a whiteboard toge=\r\nther in\n&gt; which case we could come up with an elegant solution rather\n&gt; qui=\r\nckly...\n&gt; \n&gt; I understand all that you said, but it still creates problems.=\r\n  The\n&gt; idea of recurrency is that it stores a memory that allows the net t=\r\no\n&gt; anticipate and strategize based on a prior world state.\n&gt; \n&gt; Suppose I =\r\nfollow your idea of activating the net in several steps,\n&gt; moving my agent =\r\nin those time steps if the net says to do it, but\n&gt; not checking the new wo=\r\nrld state.\n&gt; \n&gt; After these several timesteps, I assume I should re-initial=\r\nize the\n&gt; inputs to all the neurons to zero.  Then I re-scan the &quot;world&quot;, g=\r\net\n&gt; my inputs, and do it all again.  But this resetting and rescanning\n&gt; i=\r\nmplies no memory of a prior world state since in our internal\n&gt; timesteps w=\r\ne did not consider the world inputs again until we were\n&gt; done with our net=\r\n activation.  Does this make sense?\n&gt; \n&gt; I have come up with my own way to =\r\nhandle this and I&#39;m coding it\n&gt; as we speak.  Following is what I propose:\n=\r\n&gt; \n&gt; 1) I do exactly what John suggested, I have a nice and tight\n&gt; recursi=\r\nve routine that quickly determines dependencies, which\n&gt; includes recursive=\r\n dependencies\n&gt; \n&gt; 2) I then activate each neuron that has all its depedenc=\r\nies\n&gt; fulfilled/processed iteratively, unitl ALL neurons have been\n&gt; proces=\r\nsed.  I also process recurrent links here, BUT if it is\n&gt; timestep 0, i sto=\r\nre the recurrent value in its own place separate\n&gt; from the neurons non-rec=\r\nurrent, total inputs.  Importantly, at\n&gt; timestep 0 these recurrent weights=\r\n are NOT considered in the\n&gt; firing/non-firing decision of the neuron.\n&gt; \n&gt;=\r\n 3) if the output neurons tell the agent to move, it does so.\n&gt; \n&gt; 4) reset=\r\n ALL the neurons...BUT, if its not timestep 0, then keep the\n&gt; recurrent to=\r\ntals in the neurons that had a recurrent link back to\n&gt; them..otherwise ers=\r\net all neurons totals including recurrent totals\n&gt; \n&gt; 5) get the new state =\r\nof the world..meaning read the input values..\n&gt; \n&gt; 6) process the net as ab=\r\nove...if it is not timestep 0, then when\n&gt; making a fire/not-fire decision,=\r\n we total the inputs for a neuron\n&gt; PLUS the recurrent values from the last=\r\n net execution....so this is\n&gt; the memory of the prior state being used.\n&gt; =\r\n\n&gt; 7) repeat all the above...\n&gt; \n&gt; This seems like a practical approach to =\r\nme that should work,\n&gt; although I haven&#39;t got it working yet.. The code to =\r\nfire the\n&gt; network, even knowing dependencies, is a little tricky.\n&gt; \n&gt; Hop=\r\ne this all makes some sense...hard to describe via written note...\n&gt; \n&gt; --K=\r\nevin\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n=\r\n&gt; \n&gt;\n\n"}}