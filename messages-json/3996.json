{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"WarxNaN70MOkO5a42gNpTiTzpc4i9_OJKqiZjWcPxO8ZDqzccEdBKipgXajVdbjLplFncHV8vc5R4BaUv3edyKEj","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Another New Paper:  Multiagent HyperNEAT","postDate":"1209243764","msgId":3996,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM0MzkxMEI0LjIyNzUxJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGZ1cW85ditxc205QGVHcm91cHMuY29tPg=="},"prevInTopic":3995,"nextInTopic":3997,"prevInTime":3995,"nextInTime":3997,"topicId":3955,"numMessagesInTopic":49,"msgSnippet":"Ken, one issue is what the goal of the research is. If one is trying to get the best controller for the fleet of ships in the near future, all shortcuts are","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 98236 invoked from network); 26 Apr 2008 21:02:54 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m54.grp.scd.yahoo.com with QMQP; 26 Apr 2008 21:02:54 -0000\r\nX-Received: from unknown (HELO py-out-1112.google.com) (64.233.166.181)\n  by mta18.grp.scd.yahoo.com with SMTP; 26 Apr 2008 21:02:54 -0000\r\nX-Received: by py-out-1112.google.com with SMTP id f47so4803578pye.8\n        for &lt;neat@yahoogroups.com&gt;; Sat, 26 Apr 2008 14:02:53 -0700 (PDT)\r\nX-Received: by 10.35.88.16 with SMTP id q16mr10110258pyl.66.1209243773345;\n        Sat, 26 Apr 2008 14:02:53 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?192.168.2.2? ( [67.167.130.112])\n        by mx.google.com with ESMTPS id y78sm10164407pyg.17.2008.04.26.14.02.45\n        (version=TLSv1/SSLv3 cipher=OTHER);\n        Sat, 26 Apr 2008 14:02:48 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.1.0.080305\r\nDate: Sat, 26 Apr 2008 17:02:44 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C43910B4.22751%jclune@...&gt;\r\nThread-Topic: [neat] Re: Another New Paper:  Multiagent HyperNEAT\r\nThread-Index: Acin4N8+KJD10K0a80utxIXuKudHaQ==\r\nIn-Reply-To: &lt;fuqo9v+qsm9@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-transfer-encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: Another New Paper:  Multiagent HyperNEAT\r\nX-Yahoo-Group-Post: member; u=211599040; y=n7ZevFKehq7ZLP8Qk1wCws9ZlhTLJUidMYghrbXq03wFnR7WkHQW\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nKen, one issue is what the goal of the research is. If one is trying to get\nthe best controller for the fleet of ships in the near future, all shortcuts\nare fine. But if one is trying to test whether a new algorithm is good at\ndiscovering and exploiting regularities in the environment, then it might be\ninteresting to present the algorithm with a problem that is easily divided\nand see whether it figures that out. If it can&#39;t, we can then move on to\ntrying to improve it. This sort of deep research will then yield payoffs\nwhen the algorithm comes across regularities we did not envision and tell it\nhow to exploit. In checkers, for example, there are all sorts of\nregularities in the game we *hope* HyperNEAT is exploiting. But the fact\nthat Dave&#39;s non-r(x) treatments did so poorly might suggest that it is not,\nin fact, doing a good job of exploiting many of those regularities.\n\nIf I had a decent go player, and I wanted it to be as good as possible for a\nmatch next week, I&#39;d probably hack in certain heuristics that it does not\nseem to be able to figure out on its own. But if I was taking the long view,\nI might be interested in seeing whether we could automate the process of it\ndiscovering such heuristics without them being manually input. I think most\nwill agree that every time we figure out these deep issues of how to get the\nsystem to do the learning on its own, we take a necessary step towards\ngeneral AI. I guess that is why I think these hard problems are part of the\ndeep work in AI research.\n\nI do agree that it is also important to be able to inject knowledge and have\nthe algorithm use it. So, I am in no way discounting the approach you\nchampion. However, I also think there is plenty of merit in trying to\nimprove the ability of these algorithms to exploit regularities in the\nenvironment on their own. To me it seems disconcerting that they cannot\ndiscover such regularities easily, and it would be worthwhile to see if we\ncan improve them in this regard.  I guess I also don&#39;t see the problem as so\ndaunting that we can&#39;t currently address it. For example, isn&#39;t your fitness\nsharing diversity technique, which you call &#39;speciation&#39;, one way of\nfacilitating modifications to underlying bauplans? Such approaches make it\neasier for a better upstream division of the problem to survive, because it\nallows some time for that improved bauplan to realize the fitness benefits\nassociated with that more intelligent subdivision of the problem.\n\n\n\nCheers,\nJeff Clune\n\nDigital Evolution Lab, Michigan State University\n\njclune@...\n\n\n\n\n&gt; From: Kenneth Stanley &lt;kstanley@...&gt;\n&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; Date: Thu, 24 Apr 2008 19:50:23 -0000\n&gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; Subject: [neat] Re: Another New Paper:  Multiagent HyperNEAT\n&gt; \n&gt; Jeff, perhaps the issue is partly a matter of degree: I agree that we\n&gt; want the algorithm to discover on its own the regularities in the\n&gt; geometry (and HyperNEAT is designed to be able to do so), but at some\n&gt; point, it becomes almost pedantic to withhold such information when it\n&gt; is at the most very basic core of the problem description.  For\n&gt; example, it does not seem rational to me to pose a multiagent problem\n&gt; to a learning algorithm and ask that the learner *figure out* that the\n&gt; problem is multiagent.  In effect, that is how I would interpret\n&gt; starting HyperNEAT without the r(x) repeating frame.\n&gt; \n&gt; It&#39;s like saying, first you have to discover what kind of problem this\n&gt; is, then you can go on and figure out how to solve it.  Or, it is like\n&gt; giving a person a keyboard to control of a fleet of ships, but not\n&gt; telling them that in fact different keys on the keyboard are assigned\n&gt; to different ships, or even that that there is more than one ship in\n&gt; the first place! (All the person finds out is who gets killed in the\n&gt; end and how badly.)  I&#39;m not sure even a great general intelligence\n&gt; should be expected to solve such an unreasonable problem in any nice\n&gt; amount of time?\n&gt; \n&gt; I do see that you can always argue that we should want our algorithm\n&gt; to be able to do everything, including that.  I think that&#39;s actually\n&gt; a more interesting subject, because it&#39;s about the grand goals of AI:\n&gt; Are we trying to create a general intelligence that precludes us from\n&gt; needing to provide any prior information?\n&gt; \n&gt; And I think the answer is yes.  So I agree with you.  So then, you\n&gt; ask, how can I believe that and then be advocating systems where we\n&gt; provide prior information?\n&gt; \n&gt; The answer to that is question is that I think you are seeing progress\n&gt; moving in a different order than I see it moving.  I believe that the\n&gt; most ambitious general intelligence is far far away, and is basically\n&gt; something like human intelligence: Not the kind of thing you just get\n&gt; by improving your encoding or diversity.  It&#39;s more like an\n&gt; astronomical paradigm shift from what we have now.\n&gt; \n&gt; Yet I am still genuinely trying to make steps down that road.  And I\n&gt; believe it will only be possible to create that general intelligence\n&gt; with an algorithm that *itself* can leverage every bit of prior\n&gt; information that could possibly be useful.  In other words, I am\n&gt; working with my students on the algorithm that will create the AI\n&gt; someday.  In contrast, you are seeing our algorithm as a candidate for\n&gt; that AI itself.  That is, HyperNEAT is not an embryonic form of\n&gt; general AI; rather, it is an embryonic form of an algorithm that will\n&gt; eventually generate a general AI.\n&gt; \n&gt; For example, if I could create a world champion Go player, it would\n&gt; not matter how much information I stuffed in at the start.  The point\n&gt; of the exercise would be to achieve my ultimate goal, not to satisfy a\n&gt; particular pedagogical criterion for purist learning.  In the same way\n&gt; , if I can create a human-level intelligence (which itself is a\n&gt; general learner), it does not matter either whether I stuff in some\n&gt; regularities from the start or not.  The more I give myself the\n&gt; capability to do that, the better.  Does anyone really believe that\n&gt; general AI can be most effectively evolved by *limiting* the amount of\n&gt; prior information?\n&gt; \n&gt; So the ability to provide a priori context is in my view directly on\n&gt; the track to the ultimate goal.  In fact, I believe the universe\n&gt; provides this type of information implicitly, which is one reason\n&gt; evolution did succeed as it did.  For example, the brain *does* exist\n&gt; in physical geometry that is the same geometry as that which is\n&gt; outside the brain, which thereby provided a strong bias to the kinds\n&gt; of structures it contains being correlated to the real world.  In this\n&gt; way, the universe is not without its biases, and we hardly fault it\n&gt; for cheating to reach its grandest achievements.\n&gt; \n&gt; In any case, on the road the general AI, any shortcut is fair game.\n&gt; The goal should be to find ways to provide all kinds of dramatic\n&gt; shortcuts, not to weed them out.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;&gt; \n&gt;&gt;&gt; Perhaps one way to explain why we thought about that first is to\n&gt;&gt;&gt; consider that one important philosophical motivation behind HyperNEAT\n&gt;&gt;&gt; is that machine learning needs a way for humans to convey to the\n&gt;&gt;&gt; learner a priori known domain geometry.  In effect, we are running\n&gt;&gt;&gt; away from the black box of No Free Lunch (which is a nasty trap) by\n&gt;&gt;&gt; finding new ways to convey critical a priori domain information.\n&gt;&gt;&gt; While arguments can be made that because certain techniques align with\n&gt;&gt;&gt; certain problem classes we should not pay too much heed to NFL, why\n&gt;&gt;&gt; would we purposefully move *towards* the black box when we don&#39;t have\n&gt;&gt;&gt; to?  The real excitement, I think, is to find very general techniques\n&gt;&gt;&gt; for conveying to the learner standard kinds of a priori practical\n&gt;&gt;&gt; information (or bias), e.g. geometry.\n&gt;&gt; \n&gt;&gt; Hi Ken. I think it is indeed cool that you demonstrate an easy way\n&gt; to inject\n&gt;&gt; user knowledge in a way that appropriately biases the algorithm toward\n&gt;&gt; better solutions. However, in my opinion, the reason we are\n&gt; interested in\n&gt;&gt; machine learning is because it can solve the problems we *don&#39;t*\n&gt; know how to\n&gt;&gt; solve. The reason we use simple toy problems is because we know what the\n&gt;&gt; expected solutions should look like, and we want to demonstrate that our\n&gt;&gt; algorithms can find them. That gives us some confidence that, when\n&gt; we start\n&gt;&gt; showing our algorithms problems where we don&#39;t know what the solutions\n&gt;&gt; should look like, they will discover good solutions to these problems.\n&gt;&gt; Specifically, with regards to generative encodings, one touted\n&gt; benefit is\n&gt;&gt; their ability to exploit regularities that exist in the problem\n&gt; domain. It\n&gt;&gt; is the hope that on complex domains there will be many such regularities\n&gt;&gt; that can be exploited. It is implied that humans will not always\n&gt; know what\n&gt;&gt; those regularities are. Even if we did, it would be nice if we did\n&gt; not have\n&gt;&gt; to tell the algorithm about each type of regularity. The hope is that\n&gt;&gt; generative encodings can discover them and exploit them without our\n&gt; aid. So,\n&gt;&gt; while it is nice to be able to inject knowledge, it is also important to\n&gt;&gt; devise algorithms that don&#39;t require such knowledge. Clearly the logical\n&gt;&gt; extremes of either position are untenable: it is uninteresting to\n&gt; tell the\n&gt;&gt; network how to do everything but one trivial thing and have it learn\n&gt; that,\n&gt;&gt; and NFL tells us we can&#39;t have it be a jack of all trades. But I\n&gt; think there\n&gt;&gt; are reasons to explore the intermediate ranges of both positions.\n&gt;&gt; \n&gt;&gt;&gt; That said, if you really did start without the repeating coordinate\n&gt;&gt;&gt; frames, I am guessing it would perform worse as you predict, though I\n&gt;&gt;&gt; don&#39;t know by how much.  It is probably worth doing just to see what\n&gt;&gt;&gt; happens.  Yet my personal view is that there would not be a very deep\n&gt;&gt;&gt; insight to gain from such a result.  After all, why would we expect it\n&gt;&gt;&gt; to consistently discover the right regularity simply by chance every\n&gt;&gt;&gt; time?  Remember that early in evolution, simply discovering this\n&gt;&gt;&gt; regularity may not even be rewarded; just because it somehow gets\n&gt;&gt;&gt; lucky and figures out exactly the right repeating frame of reference,\n&gt;&gt;&gt; that does not necessarily mean that within those coordinate frames it\n&gt;&gt;&gt; is doing anything useful (i.e. it could be a repetition of a bad\n&gt;&gt;&gt; policy), so the discovery is likely to go unnoticed and die out, just\n&gt;&gt;&gt; as easily as it might be leveraged and elaborated properly.\n&gt;&gt; \n&gt;&gt; I agree that this is a challenging problem, but I think that it is very\n&gt;&gt; important for us to figure out algorithms that can cope with it. Clearly\n&gt;&gt; nature figured out ways to deal with this issue. How can we set up\n&gt;&gt; algorithms such that if the population early on discovers a bauplan that\n&gt;&gt; keeps it trapped on a local peak, it can eventually discover a\n&gt; bauplan that\n&gt;&gt; gives it access to a higher peak?  To me this is a fundamental issue\n&gt; for our\n&gt;&gt; field. If we cannot improve upon it, we will be stuck evolving\n&gt; relatively\n&gt;&gt; trivial solutions and never evolve things as impressive as jaguars\n&gt; or poets.\n&gt;&gt; I am surprised you don&#39;t think research on this front is important\n&gt; or would\n&gt;&gt; provide deep insights. Or, is it that you think we can&#39;t make\n&gt; progress here,\n&gt;&gt; so documenting a further failure isn&#39;t deep?\n&gt;&gt;&gt; \n&gt;&gt;&gt; This problem is related to that discussion we had a while back about\n&gt;&gt;&gt; &quot;target-based evolution&quot; and the phenomena of Picbreeder.  Often the\n&gt;&gt;&gt; stepping stones (such as discovering the right basic regularity) are\n&gt;&gt;&gt; not recognized by the ultimate objective function, so it&#39;s pretty much\n&gt;&gt;&gt; up to luck to find them and keep them around long enough to take\n&gt;&gt;&gt; advantage of them.  My feeling is that it is not fruitful for any\n&gt;&gt;&gt; indirect encoding to try to solve that problem, because it is not a\n&gt;&gt;&gt; problem with the encoding per say but rather with the way fitness is\n&gt;&gt;&gt; assigned.\n&gt;&gt; \n&gt;&gt; Fitness is one part of the mix. But there are also issues of population\n&gt;&gt; diversity, representation flexibility and evolvability, etc. Any of\n&gt; these\n&gt;&gt; could assist in allowing deep switches in bauplan.\n&gt;&gt;  \n&gt;&gt; I&#39;d like to say one last thing. One of the great innovations of\n&gt; HyperNEAT\n&gt;&gt; was that you provided the geometry of the problem such that the\n&gt; algorithm\n&gt;&gt; could exploit it. That strikes me as a bit different than telling the\n&gt;&gt; algorithm *how* to go about exploiting that geometry. I think that\n&gt;&gt; distinction is important, and might be being conflated a bit here. I\n&gt; agree\n&gt;&gt; unequivocally that providing access to the geometry is important, but it\n&gt;&gt; seems to me that it is an interesting field of research to figure\n&gt; out how to\n&gt;&gt; create algorithms that learn how to exploit that geometry, and its\n&gt;&gt; regularities, on their own.\n&gt;&gt; \n&gt;&gt; \n&gt;&gt; Cheers,\n&gt;&gt; Jeff Clune\n&gt;&gt; \n&gt;&gt; Digital Evolution Lab, Michigan State University\n&gt;&gt; \n&gt;&gt; jclune@...\n&gt;&gt; \n&gt;&gt; \n&gt;&gt; \n&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Hello-\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; I enjoyed reading this. Thanks for posting it.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; A question: how did HyperNEAT perform when you did not provide it\n&gt;&gt;&gt; with the\n&gt;&gt;&gt;&gt; repeating coordinate frame for each agent? As you mention in the\n&gt;&gt;&gt; paper, this\n&gt;&gt;&gt;&gt; is something that HyperNEAT could learn on its own. I assume from\n&gt;&gt;&gt; the fact\n&gt;&gt;&gt;&gt; that you added it that HyperNEAT was not doing a good job of\n&gt;&gt;&gt; learning this.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; If that assumption is right, how bad was it at learning this problem\n&gt;&gt;&gt;&gt; decomposition? One of the touted benefits of HyperNEAT, and\n&gt; generative\n&gt;&gt;&gt;&gt; encodings in general, is the ability to evolve a module and reuse it\n&gt;&gt;&gt; many\n&gt;&gt;&gt;&gt; times (potentially with variation).  Here the modularity of the\n&gt;&gt;&gt; problem was\n&gt;&gt;&gt;&gt; cleanly divided, and should have been relatively easy for\n&gt; HyperNEAT to\n&gt;&gt;&gt;&gt; discover. Do you find it disconcerting that it couldn&#39;t do so?\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Digital Evolution Lab, Michigan State University\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; jclune@\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; From: Kenneth Stanley &lt;kstanley@&gt;\n&gt;&gt;&gt;&gt;&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt;&gt;&gt;&gt;&gt; Date: Wed, 16 Apr 2008 22:48:44 -0000\n&gt;&gt;&gt;&gt;&gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt;&gt;&gt;&gt;&gt; Subject: [neat] Another New Paper:  Multiagent HyperNEAT\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; David D&#39;Ambrosio and I discuss the potential for HyperNEAT\n&gt;&gt;&gt;&gt;&gt; controlling multiple heterogeneous agents in this new\n&gt;&gt;&gt;&gt;&gt; paper, &quot;Generative Encoding for Multiagent Learning,&quot; to appear at\n&gt;&gt;&gt;&gt;&gt; GECCO 2008:\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; http://eplex.cs.ucf.edu/index.php?\n&gt;&gt;&gt;&gt;&gt; option=com_content&task=view&id=14&Itemid=28#dambrosio.gecco08\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; Direct Link:\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; http://eplex.cs.ucf.edu/papers/dambrosio_gecco08.pdf\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; We also have a nice sample of videos that depict various evolved\n&gt;&gt;&gt;&gt;&gt; teams in action:\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; http://eplex.cs.ucf.edu/multiagenthyperneat\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; The interesting idea in this paper is that just as a single\n&gt;&gt;&gt;&gt;&gt; connective CPPN can encode how a single network varies over space,\n&gt;&gt;&gt;&gt;&gt; it can also encode how a *set* of networks (each representing the\n&gt;&gt;&gt;&gt;&gt; policy of one agent on the team) varies over space.  In this way,\n&gt;&gt;&gt;&gt;&gt; HyperNEAT can learn an expression that encodes how policies vary\n&gt;&gt;&gt;&gt;&gt; over the team geometry.  For example, in a soccer team agents vary\n&gt;&gt;&gt;&gt;&gt; from defensive to offensive as you move away from the goal.  Part of\n&gt;&gt;&gt;&gt;&gt; the power of this approach is that it means basic skills can be\n&gt;&gt;&gt;&gt;&gt; learned and shared among the whole team, since the CPPN encodes how\n&gt;&gt;&gt;&gt;&gt; those skills vary across the field.\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt; ken\n&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt; \n&gt; \n&gt; \n\n\n\n"}}