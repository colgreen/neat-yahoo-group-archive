{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":360532607,"authorName":"Sebastian Risi","from":"Sebastian Risi &lt;sebastian.risi@...&gt;","profile":"sebastian.risi","replyTo":"LIST","senderId":"ChxwbOFMgWu_uNofp4-mjFQYNm9gCECpSBIelORViUsO_2cdjgbz_HJb8ml4l4rUjbmXRvRN0Ex3tC0_KtnYZHfz1UkPYA1zVXUOnhAtI1g","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] New Publication Introduces Adaptive HyperNEAT (with \tSynaptic Plasticity)","postDate":"1276145584","msgId":5257,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEFBTkxrVGlrZTFlenVlTUVvX3lxOFRoT2xtN2dFMGpZSlZGNEF2TVVfNGJuMkBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":5240,"nextInTopic":5258,"prevInTime":5256,"nextInTime":5258,"topicId":5202,"numMessagesInTopic":4,"msgSnippet":"Hi Jeff, sorry for the late response. Let me try to adress your questions: 1) You mention a few times that in natural brains different regions have different","rawEmail":"Return-Path: &lt;sebastian.risi@...&gt;\r\nX-Sender: sebastian.risi@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 12383 invoked from network); 10 Jun 2010 04:53:26 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m2.grp.sp2.yahoo.com with QMQP; 10 Jun 2010 04:53:26 -0000\r\nX-Received: from unknown (HELO mail-vw0-f53.google.com) (209.85.212.53)\n  by mta3.grp.re1.yahoo.com with SMTP; 10 Jun 2010 04:53:26 -0000\r\nX-Received: by vws16 with SMTP id 16so2464054vws.40\n        for &lt;neat@yahoogroups.com&gt;; Wed, 09 Jun 2010 21:53:05 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.224.88.41 with SMTP id y41mr2642003qal.198.1276145584962; Wed, \n\t09 Jun 2010 21:53:04 -0700 (PDT)\r\nX-Received: by 10.220.97.70 with HTTP; Wed, 9 Jun 2010 21:53:04 -0700 (PDT)\r\nDate: Thu, 10 Jun 2010 00:53:04 -0400\r\nMessage-ID: &lt;AANLkTike1ezueMEo_yq8ThOlm7gE0jYJVF4AvMU_4bn2@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=00c09fa21d7145ff330488a5cc45\r\nFrom: Sebastian Risi &lt;sebastian.risi@...&gt;\r\nSubject: Re: [neat] New Publication Introduces Adaptive HyperNEAT (with \n\tSynaptic Plasticity)\r\nX-Yahoo-Group-Post: member; u=360532607; y=-6mE-niMQgxMuEsaD62kMRwGdAjE5xqEa00A_-mGT2ZMaUcWxH-UuHk\r\nX-Yahoo-Profile: sebastian.risi\r\n\r\n\r\n--00c09fa21d7145ff330488a5cc45\r\nContent-Type: text/plain; charset=UTF-8\r\n\r\nHi Jeff,\n\nsorry for the late response. Let me try to adress your questions:\n\n1) You mention a few times that in natural brains different regions have\ndifferent plasticity rules, but you do not provide a cite. I am guessing you\nare correct, but I was just wondering if you could tell us more about how\nyou know that (i.e., what the evidence is, or a cite where I can read about\nit, etc.). I do know that different neuromodulatory centers control\ndifferent regions of the brain, so that could potentially be an\nexample...but I was just wondering if you had other sources. If so, I would\nbe interested to hear about them.\n\nOne example of different plasticity rules is long-term potentiation (\nhttp://en.wikipedia.org/wiki/Long-term_potentiation) that is mostly observed\nin the hippocampus and not so much in other areas of the brain, I believe. I\nwould recommend to take a look at &quot;Principles of Neural Science&quot; by Kandel.\nIt&#39;s a very good book but kind of a hard read.\n\n2) You mention that &quot;for all hyperneat models synaptic strength is bound\nwithin the range [-1.0, 1.0].&quot; Why did you make this choice? Isn&#39;t the range\nnormally [-3, 3]?\n\nBecause the delta weight change of the iterated model is bound to be within\n[-1.0, 1.0] we decided that the weights should also be bounded between\n[-1.0, 1.0]. I haven&#39;t tried it with [-3, 3] but it should still work in\nthat case I believe.\n\n3) In the second paragraph of the results, you list that the iterated model\ntook 89 gens. Do you mean 189? Otherwise the plots tell a different story,\nunless I am misunderstanding something.\n\nThe iterated model took indeed on average 89 generations to find a solution.\nAt around 200 generations all of the runs found a solution which means\nthat the average reaches 395 fitness which can be seen in the figure when\nthe graph reaches the horizontal line. Does that make sense?\n\n4) Do you know why the plain Hebbian rule cannot solve the task?\n\nThe plain Hebbian rule strengthens the synaptic weights if pre and\npostsynaptic activity correlate. Because the reward in the maze\nis given with a delay from the action of choosing which way to turn\ncorrelation alone might not be sufficient to solve this domain. Andrea\nSoltoggio actually has an interesting paper about the type of learning rules\nthat are necessary to solve the T-Maze and bee domain, in case you&#39;re\ninterested. http://lis.epfl.ch/~soltoggio/Papers/SoltoggioHIS2008.pdf\n\n5) You mention that it might be the case that an ANN *with hidden nodes*\ncould have solved the task without the learning rule performing the\ncomplicated (xor-equivalent?) computation. Out of curiosity, did you try\nthat?\n\nWe actually never tried that.\n\n6) Can you explain (or speculate) how the CPPN network is solving this task?\nI assume (since there is no recurrence), that it is simply memorizing which\nnumbers represent a low reward (e.g. 0 or .8) instead of comparing the last\nreward to the current reward. Does that seem right? To compare to the\nprevious trial, would they need recurrence, or is it possible to embed\ninformation in the connections via learning that can function like\nrecurrence in terms of storing information? Do you know if something like\nthat is going on?\n\nThat is a tricky question :) The weight change actually seems to allow the\nagent to remember information from one trial to the next. All the evolved\nANNs are notrecurrent so they actually depend on this kind of plasticity. At\nthis point I&#39;m not 100% sure how the evolved CPPN rule separates the\nnonlinear separable reward signatures but that&#39;s definitely an interesting\nquestion for future research.\n\n7) You say that the evolved rules resemble postsynaptic-based learning rules\nthat have been shown essential in the T-Maze domain, and cite Andrea. Can\nyou elaborate on this a bit more? How were they similar? Wouldn&#39;t good\npostsynaptic learning rules depend on presynaptic and correlation rules\n(values) as well? Is it surprising to just see similar postynaptic values\nand not similar values for the other parameters?\n\nAndrea actually tested different ABC rules and found that the C, AC, BC and\nABC rule can solve the T-Maze task. So only C is in fact necessary, at least\nfor that particular domain. I think that the correlation term is not really\nimportant in the T-Maze because action and reward intake can&#39;t be directly\ncorrelated. But there are other domains, like the foraging bee domain, that\ncritically depend on the term A. So it will be interesting to try the\niterated model in one of those other domains to see what kind of learning\nrules it evolves.\n\nCheers,\nSebastian\n\r\n--00c09fa21d7145ff330488a5cc45\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Jeff,&lt;br&gt;&lt;br&gt;sorry for the late response. Let me try to adress your ques=\r\ntions:&lt;br&gt;&lt;br&gt;\n1) You mention a few times that in natural brains different =\r\nregions have&lt;br&gt;\ndifferent plasticity rules, but you do not provide a cite.=\r\n I am guessing\n you&lt;br&gt;\nare correct, but I was just wondering if you could =\r\ntell us more about \nhow&lt;br&gt;\nyou know that (i.e., what the evidence is, or a=\r\n cite where I can read \nabout&lt;br&gt;\nit, etc.). I do know that different neuro=\r\nmodulatory centers control&lt;br&gt;\ndifferent regions of the brain, so that coul=\r\nd potentially be an&lt;br&gt;\nexample...but I was just wondering if you had other=\r\n sources. If so, I \nwould&lt;br&gt;\nbe interested to hear about them.&lt;br&gt;&lt;br&gt;One =\r\nexample of different plasticity rules is long-term potentiation (&lt;a href=3D=\r\n&quot;http://en.wikipedia.org/wiki/Long-term_potentiation&quot;&gt;http://en.wikipedia.o=\r\nrg/wiki/Long-term_potentiation&lt;/a&gt;) that is mostly observed&lt;br&gt;\nin the hipp=\r\nocampus and not so much in other areas of the brain, I believe. I would rec=\r\nommend to take a look at &quot;Principles of Neural Science&quot; by Kandel=\r\n. It&#39;s a very good book but kind of a hard read.&lt;br&gt;&lt;br&gt;\n\n2) You mentio=\r\nn that &quot;for all hyperneat models synaptic strength is bound&lt;br&gt;\nwithin=\r\n the range [-1.0, 1.0].&quot; Why did you make this choice? Isn&#39;t the \n=\r\nrange&lt;br&gt;\nnormally [-3, 3]?&lt;br&gt;\n&lt;br&gt;Because the delta weight change of the =\r\niterated model is bound to be within&lt;br&gt;[-1.0, 1.0] we decided that the wei=\r\nghts should also be bounded between [-1.0, 1.0]. I haven&#39;t tried it wit=\r\nh [-3, 3] but it should still work in that case I believe.&lt;br&gt;\n&lt;br&gt;\n3) In t=\r\nhe second paragraph of the results, you list that the iterated \nmodel&lt;br&gt;\nt=\r\nook 89 gens. Do you mean 189? Otherwise the plots tell a different \nstory,&lt;=\r\nbr&gt;\nunless I am misunderstanding something.&lt;br&gt;\n&lt;br&gt;The iterated model took=\r\n indeed on average 89 generations to find a solution.&lt;br&gt;At around 200 gene=\r\nrations all of the runs found a solution which means&lt;br&gt;that the average re=\r\naches 395 fitness which can be seen in the figure when&lt;br&gt;\nthe graph reache=\r\ns the horizontal line. Does that make sense? &lt;br&gt;&lt;br&gt;\n4) Do you know why th=\r\ne plain Hebbian rule cannot solve the task?&lt;br&gt;\n&lt;br&gt;The plain Hebbian rule =\r\nstrengthens the synaptic weights if pre and postsynaptic activity correlate=\r\n. Because the reward in the maze &lt;br&gt;is given with a delay from the action =\r\nof choosing which way to turn&lt;br&gt;correlation alone might not be sufficient =\r\nto solve this domain. Andrea &lt;br&gt;\nSoltoggio actually has an interesting pap=\r\ner about the type of learning rules&lt;br&gt;that are necessary to solve the T-Ma=\r\nze and bee domain, in case you&#39;re interested. &lt;a href=3D&quot;http://lis.epf=\r\nl.ch/~soltoggio/Papers/SoltoggioHIS2008.pdf&quot;&gt;http://lis.epfl.ch/~soltoggio/=\r\nPapers/SoltoggioHIS2008.pdf&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n5) You mention that it might be th=\r\ne case that an ANN *with hidden nodes*&lt;br&gt;\ncould have solved the task witho=\r\nut the learning rule performing the&lt;br&gt;\ncomplicated (xor-equivalent?) compu=\r\ntation. Out of curiosity, did you try&lt;br&gt;\nthat? &lt;br&gt;&lt;br&gt;We actually never t=\r\nried that.&lt;br&gt;\n&lt;br&gt;\n6) Can you explain (or speculate) how the CPPN network =\r\nis solving this \ntask?&lt;br&gt;\nI assume (since there is no recurrence), that it=\r\n is simply memorizing \nwhich&lt;br&gt;\nnumbers represent a low reward (e.g. 0 or =\r\n.8) instead of comparing the \nlast&lt;br&gt;\nreward to the current reward. Does t=\r\nhat seem right? To compare to the&lt;br&gt;\nprevious trial, would they need recur=\r\nrence, or is it possible to embed&lt;br&gt;\ninformation in the connections via le=\r\narning that can function like&lt;br&gt;\nrecurrence in terms of storing informatio=\r\nn? Do you know if something \nlike&lt;br&gt;\nthat is going on?&lt;br&gt;\n&lt;br&gt;That is a t=\r\nricky question :) The weight change actually seems to allow the agent to re=\r\nmember information from one trial to the next. All the evolved ANNs are not=\r\nrecurrent so they actually depend on this kind of plasticity. At this point=\r\n I&#39;m not 100% sure how the evolved CPPN rule separates the nonlinear se=\r\nparable reward signatures but that&#39;s definitely an interesting question=\r\n for future research.&lt;br&gt;\n&lt;br&gt;\n7) You say that the evolved rules resemble p=\r\nostsynaptic-based learning \nrules&lt;br&gt;\nthat have been shown essential in the=\r\n T-Maze domain, and cite Andrea. \nCan&lt;br&gt;\nyou elaborate on this a bit more?=\r\n How were they similar? Wouldn&#39;t good&lt;br&gt;\npostsynaptic learning rules d=\r\nepend on presynaptic and correlation rules&lt;br&gt;\n(values) as well? Is it surp=\r\nrising to just see similar postynaptic \nvalues&lt;br&gt;\nand not similar values f=\r\nor the other parameters?&lt;br&gt;&lt;br&gt;Andrea actually tested different ABC rules =\r\nand found that the C, AC, BC and ABC rule can solve the T-Maze task. So onl=\r\ny C is in fact necessary, at least for that particular domain. I think that=\r\n the correlation term is not really important in the T-Maze because action =\r\nand reward intake can&#39;t be directly correlated. But there are other dom=\r\nains, like the foraging bee domain, that critically depend on the term A. S=\r\no it will be interesting to try the iterated model in one of those other do=\r\nmains to see what kind of learning rules it evolves.&lt;br&gt;\n&lt;br&gt;Cheers,&lt;br&gt;Seb=\r\nastian&lt;br&gt;&lt;br&gt;\n\r\n--00c09fa21d7145ff330488a5cc45--\r\n\n"}}