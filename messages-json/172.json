{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"coPj9PF3USn3vXWWIcc5FN7IE9_xhmtB8ydvRzUQve79sl4F2jHtHpkarEMStCFaW68jubk3SE0inbppa89DSIknpkFeHSroQFcTny6nHKWO","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Learning How to Learn","postDate":"1067468468","msgId":172,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGJucGdyaysyZm5lQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDMxMDI5MDUzNzEwLjc4ODIucW1haWxAd2ViMjE0MDIubWFpbC55YWhvby5jb20+"},"prevInTopic":170,"nextInTopic":174,"prevInTime":171,"nextInTime":173,"topicId":170,"numMessagesInTopic":15,"msgSnippet":"... Those are very nice results, showing that a recurrent neural network can indeed be evolved to be able to memorize the necessary information.  I still","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 17402 invoked from network); 29 Oct 2003 23:01:10 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m3.grp.scd.yahoo.com with QMQP; 29 Oct 2003 23:01:10 -0000\r\nReceived: from unknown (HELO n13.grp.scd.yahoo.com) (66.218.66.68)\n  by mta6.grp.scd.yahoo.com with SMTP; 29 Oct 2003 23:01:10 -0000\r\nReceived: from [66.218.67.149] by n13.grp.scd.yahoo.com with NNFMP; 29 Oct 2003 23:01:09 -0000\r\nDate: Wed, 29 Oct 2003 23:01:08 -0000\r\nTo: neat@yahoogroups.com\r\nSubject: Re: Learning How to Learn\r\nMessage-ID: &lt;bnpgrk+2fne@...&gt;\r\nIn-Reply-To: &lt;20031029053710.7882.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2766\r\nX-Mailer: Yahoo Groups Message Poster\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n--- In neat@yahoogroups.com, Mitchell Timin &lt;zenguyuno@y...&gt; wrote:\n&gt; A 44-neuron ANN has evolved which is a perfect player\n&gt; of the 4-card puzzle.\n&gt; \n\n...\n\n&gt; A friend of mine, Prof. Roderick Edwards here at U.\n&gt; Vic., pointed out that the evolution software &quot;learned\n&gt; how to learn&quot;.  This seems apt to me.  The program had\n&gt; to kill off a few millions ANNs that wouldn&#39;t quite\n&gt; play perfectly until finally producing some that\n&gt; could.  That was the machine learning phase, and the\n&gt; results are fixed in the weights of the ANN.  Now the\n&gt; ANN can learn what it need to when it plays this game.\n&gt; \n&gt; I&#39;m interested in finding out if this has been done\n&gt; before; i.e., has someone trained a recurrent ANN so\n&gt; that it makes use of its memory while doing its job. \n&gt; I suspect some of your robots with NEAT ANN\n&gt; controllers qualify under this definition.\n&gt; \n\n\nThose are very nice results, showing that a recurrent neural network\ncan indeed be evolved to be able to memorize the necessary\ninformation.  I still wonder why it needed 44 nodes, but perhaps that\ndoes make sense given all the possibilities.\n\nAnyway, yes I&#39;ve been interested in &quot;learning how to learn&quot; for a long\ntime.  (Or, in other words, evolving networks that can learn.) \nInterestingly, a lot of people think (and it makes sense) that\nlearning requires synaptic plasticity, i.e. the ability to change\nweights dynamically during the network&#39;s lifetime.  Usually such\nplasticity would be Hebbian learning or something like it.  Your\nexperiment, and others, show that this is not necessarily true;  in\nfact, recurrent activation alone can store state information.\n\nWe actually do have a paper in which the two kinds of adaptation were\ntested in a very simple &quot;learning&quot; domain.  The domain involved\nforaging food.  A forager must collect items on a board that are\neither food or poison, but it has to learn which is the case.  If they\nare food, it can keep eating, but if they are poisonous, it should\nstop.  So it has to make an adjustment in policy according to what it\ndiscovers.  We found that both recurrent networks and networks with\nsynaptic plasticity could handle this task, although they tend to do\nit differently.  Here is the paper (yahoo may mangle the link, so try\ncopying it):\n\nhttp://nn.cs.utexas.edu/pub-view.php?RECORD_KEY(Pu\nbs)=PubID&PubID(Pubs)=131\n\n(On a side note, for anyone wondering, yes this does mean there is\na version of NEAT that can evolve Hebbian networks with plastic\nsynapses, but I haven&#39;t released it yet.) \n\nAnyway, these are very interesting issues.  When do you need Hebbian\nconnections to learn as opposed to only fixed-weight recurrent\nconnections?  It isn&#39;t clear.  And what is the capacity of a\nfixed-weight recurrent network to remember information?\n\nken\n\n\n"}}