{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"tCstjA0E_yZ-bKVkOe_CXdilm3gIfEu6p9k06Z6sGdWWixIR6q7Ikj44TzPhEziYfE6zq_1tSCybfDlJ8Xu0T30","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205438472","msgId":3865,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZyYzE2OCtodGE3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZyNGk0YitsbHVyQGVHcm91cHMuY29tPg=="},"prevInTopic":3863,"nextInTopic":3867,"prevInTime":3864,"nextInTime":3866,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"In fact, it may be that a substancial portion of the value-added of speciation and niche protection of infant organisms, is associated with providing","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 13687 invoked from network); 13 Mar 2008 20:01:15 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m55.grp.scd.yahoo.com with QMQP; 13 Mar 2008 20:01:15 -0000\r\nX-Received: from unknown (HELO n49a.bullet.mail.sp1.yahoo.com) (66.163.168.143)\n  by mta18.grp.scd.yahoo.com with SMTP; 13 Mar 2008 20:01:15 -0000\r\nX-Received: from [216.252.122.216] by n49.bullet.mail.sp1.yahoo.com with NNFMP; 13 Mar 2008 20:01:15 -0000\r\nX-Received: from [66.218.69.4] by t1.bullet.sp1.yahoo.com with NNFMP; 13 Mar 2008 20:01:14 -0000\r\nX-Received: from [66.218.66.92] by t4.bullet.scd.yahoo.com with NNFMP; 13 Mar 2008 20:01:14 -0000\r\nDate: Thu, 13 Mar 2008 20:01:12 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frc168+hta7@...&gt;\r\nIn-Reply-To: &lt;fr4i4b+llur@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=qGPalIhRr8plSBTNUowL_bh9Ihly1IOh9jmxtoBWam2GlA\r\nX-Yahoo-Profile: afcarl2\r\n\r\nIn fact, it may be that a substancial portion of the value-added of \nspecia=\r\ntion and niche protection of infant organisms, is associated \nwith providin=\r\ng opportunity to accumulate sufficient neighborhood \nevaluations to &quot;discov=\r\ner&quot; the same local minimia over multiple \ngenerations, that a local search =\r\nmay discover in one generation. And \nmaintaining multiple species in hope t=\r\nhat one of the local minimia \nwill in fact also be the global minimia.\n\n---=\r\n In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@...&gt; wrote:\n&gt;\n&gt; If &quot;most indivi=\r\nduals in a species represented by a given topology&quot; \n&gt; ended up in &quot;the sam=\r\ne local minimia&quot;, one could argue that the \n&gt; subject specie&#39;s logical end =\r\npoint was the same local minimia, and \n&gt; that the cost of maintaining more =\r\nthan one organism was \n&gt; computationally wasteful. Better to know sooner an=\r\nd breed \nadditional \n&gt; organisms of differing topology so as to maintain th=\r\ne population \nsize \n&gt; and maximize the population&#39;s &quot;effective&quot; diversity.\n=\r\n&gt; \n&gt; Paying more for the same answer does not make it a better answer.\n&gt; \n&gt;=\r\n --- In neat@yahoogroups.com, &quot;petar_chervenski&quot; \n&gt; &lt;petar_chervenski@&gt; wro=\r\nte:\n&gt; &gt;\n&gt; &gt; Well I think that encoding the resulting weights back to the \ng=\r\nenome \n&gt; &gt; would somehow hurt the population weight diversity, since most \n=\r\n&gt; &gt; individuals in a species represented by a given topology can end \nup \n&gt;=\r\n &gt; in the same local minima, thus leaving out a species with the \n&gt; nearly =\r\n\n&gt; &gt; same individuals, i.e. clones. \n&gt; &gt; This is why I think that backprop =\r\nshould be applied occasionaly \n&gt; after \n&gt; &gt; long periods of stagnation, for=\r\n example the cases where delta-\n&gt; coding \n&gt; &gt; kicks in, when it focuses the=\r\n search in the most promising areas \nof \n&gt; &gt; the search space. \n&gt; &gt; I am st=\r\nill trying to re-implement RTRL myself, though.. Then I&#39;ll \n&gt; see \n&gt; &gt; if i=\r\nt is going to actually enhance performance. \n&gt; &gt; \n&gt; &gt; Peter\n&gt; &gt; \n&gt; &gt; --- In=\r\n neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Raf=\r\nael, thank you for pointing out the connection to memetic \n&gt; &gt; &gt; algorithms=\r\n.  That is good to point out that such a combination \n&gt; &gt; falls \n&gt; &gt; &gt; unde=\r\nr that category.\n&gt; &gt; &gt; \n&gt; &gt; &gt; However, there are still those who would argu=\r\ne that the local \n&gt; &gt; search \n&gt; &gt; &gt; method should not be encoded back into =\r\nthe genome, that is, \nthat \n&gt; &gt; &gt; evolution should simply search for the be=\r\nst starting point from \n&gt; &gt; which \n&gt; &gt; &gt; a local search would depart.  Beca=\r\nuse of the Baldwin Effect, \nthat \n&gt; &gt; may \n&gt; &gt; &gt; even work better.\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; Personally, I do not know which approach would work better but \n&gt; both=\r\n \n&gt; &gt; &gt; are viable and it is probably domain dependent.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Rafael C.P.&quot; &lt;kurama.youko.br@&gt; \n&gt;=\r\n &gt; &gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Ken, it doesn&#39;t fit pure evolution but it fits =\r\nmemetic \n&gt; &gt; algorithms, \n&gt; &gt; &gt; that\n&gt; &gt; &gt; &gt; consists exactly of evolution =\r\nalternated with local search \n&gt; &gt; methods \n&gt; &gt; &gt; for fine\n&gt; &gt; &gt; &gt; tunning (=\r\njust few steps). NEAT+BP may become a good memetic \n&gt; &gt; &gt; algorithm for\n&gt; &gt;=\r\n &gt; &gt; neural networks.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; On Mon, Mar 10, 2008 at 2:19 PM, Ken=\r\nneth Stanley &lt;kstanley@&gt;\n&gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;   Peter, I belie=\r\nve that backprop can potentially improve the\n&gt; &gt; &gt; &gt; &gt; accuracy. It has bee=\r\nn shown to work effectively with \n&gt; &gt; neurevolution\n&gt; &gt; &gt; &gt; &gt; in classifica=\r\ntion tasks in the past. So in principle it \ncould\n&gt; &gt; &gt; &gt; &gt; help. Of course=\r\n, there is always the chance that it will not\n&gt; &gt; &gt; &gt; &gt; enhance performance=\r\n as well.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; One issue I would also consider is that some =\r\npeople \ndisagree \n&gt; on\n&gt; &gt; &gt; &gt; &gt; whether the changes to weights from backpr=\r\nop should be \n&gt; encoded \n&gt; &gt; &gt; back\n&gt; &gt; &gt; &gt; &gt; into the genome or not. If it=\r\n is actually encoded back into \n&gt; the\n&gt; &gt; &gt; &gt; &gt; genome, that is &quot;Lamarckian=\r\n&quot; evolution because in effect \nwhat \n&gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; organism learned ove=\r\nr its lifetime is encoded into its own\n&gt; &gt; &gt; &gt; &gt; offspring. That is obvious=\r\nly not how real evolution works.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; However, of course, it=\r\n doesn&#39;t have to work like real \n&gt; evolution \n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; &gt; some peop=\r\nle believe that Lamarckian evolution will work \n&gt; better.\n&gt; &gt; &gt; &gt; &gt; However=\r\n, there are arguments that in fact it works worse \n&gt; &gt; because \n&gt; &gt; &gt; it\n&gt; =\r\n&gt; &gt; &gt; &gt; hurts the diversity of the population. Because of the \nBaldwin\n&gt; &gt; =\r\n&gt; &gt; &gt; effect, some would argue that evolution+backprop is most \n&gt; &gt; powerfu=\r\nl \n&gt; &gt; &gt; if\n&gt; &gt; &gt; &gt; &gt; the learned weights are not encoded back into the gen=\r\nome. \n&gt; This \n&gt; &gt; &gt; topic\n&gt; &gt; &gt; &gt; &gt; is fairly extensive. A lot is written a=\r\nbout the &quot;Baldwin \n&gt; &gt; effect.&quot;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt;=\r\n\n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%\n&gt; &gt; &gt; 40yahoogroups.com&gt;, &quot;pe=\r\ntar_chervenski&quot;\n&gt; &gt; &gt; &gt; &gt; &lt;petar_chervenski@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; Hi Ken,\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; I am evolving time series predictors, in =\r\nfact even a \n&gt; &gt; simplified\n&gt; &gt; &gt; &gt; &gt; &gt; version of time series predictors, =\r\nwhere the network has \nto \n&gt; &gt; &gt; answer\n&gt; &gt; &gt; &gt; &gt; is\n&gt; &gt; &gt; &gt; &gt; &gt; the future=\r\n value going up or down. The actual output \nneuron \n&gt; &gt; is a\n&gt; &gt; &gt; &gt; &gt; &gt; si=\r\nmple step function, but back-prop can be applied if it \nis \n&gt; &gt; &gt; turned\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; out to a sigmoid with a very steep slope.\n&gt; &gt; &gt; &gt; &gt; &gt; The network=\r\ns are allowed to have any topology and they are\n&gt; &gt; &gt; &gt; &gt; evaluated\n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; on the run, meaning that on each timestep, an error is \nbeing\n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; calculated (being 0 or 1, depending on the prediction \nmade).\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; First of all, do you think that applying back-prop to \nthese\n&gt; &gt; &gt; &gt; &gt; n=\r\networks\n&gt; &gt; &gt; &gt; &gt; &gt; may bring any accuracy improvement? I know that it is \n=\r\ngoing \n&gt; &gt; to \n&gt; &gt; &gt; eat\n&gt; &gt; &gt; &gt; &gt; &gt; the CPU resourses, so it can be applie=\r\nd at regular \n&gt; intervals, \n&gt; &gt; &gt; say\n&gt; &gt; &gt; &gt; &gt; &gt; each 50 generations, to p=\r\nush the networks&#39;s weights in \nthe \n&gt; &gt; right\n&gt; &gt; &gt; &gt; &gt; &gt; direction, a kind=\r\n of a hint to the search. I am still \n&gt; thinking\n&gt; &gt; &gt; &gt; &gt; of &quot;is\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; it worth it?&quot;..\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Peter\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%\n&gt; &gt; 40yahoogroups.=\r\ncom&gt;, &quot;Kenneth \n&gt; &gt; &gt; Stanley&quot;\n&gt; &gt; &gt; &gt; &gt; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; A number of people have programmed backprop into NEAT. \n&gt; Chri=\r\ns\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Christenson did a Masters thesis on combining NEAT and \n&gt; &gt;=\r\n &gt; backprop;\n&gt; &gt; &gt; &gt; &gt; a\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; paper based on this work is actually=\r\n in the files \nsection \n&gt; of\n&gt; &gt; &gt; &gt; &gt; this\n&gt; &gt; &gt; &gt; &gt; &gt; group:\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; \n&gt; \nhttp://f1.grp.yahoofs=\r\n.com/v1/UP7SR8rDovimxlLlvcmGOziLUBIVncb2Tfr7sruo\n&gt; &gt; &gt; &gt; &gt; B\n&gt; &gt; &gt; &gt; &gt; &gt; 8b=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; taAfELU62JLyQ9XCxXF_Akhcmi-\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; \n&gt; \nTH4gpVHIikwnzB59ArOMQfPOAzyw25/Evolving_Trainable_Neura=\r\nl_Networks_6_p\n&gt; &gt; &gt; &gt; &gt; a\n&gt; &gt; &gt; &gt; &gt; &gt; ge\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; s.doc\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Shimon Whiteson implemented it as part of his NEAT+Q\n&gt; &gt; &gt; &gt;=\r\n &gt; reinforcement\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; learning method:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; \n&gt; &gt; \n&gt; \nhttp://staff.science.uva.nl/~whiteson/pubs/whitesonaaai06.=\r\npdf&lt;http://s\n&gt; &gt; &gt; taff.science.uva.nl/%7Ewhiteson/pubs/whitesonaaai06.pdf&gt;=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; There has been a lot written on backprop in NE=\r\nAT in the \n&gt; &gt; &gt; archives\n&gt; &gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; this group: just searc=\r\nh for &quot;backprop&quot; from the yahoo \n&gt; page \n&gt; &gt; for\n&gt; &gt; &gt; &gt; &gt; this\n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; group and many messages will pop up.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; In gene=\r\nral, if you do not allow recurrence then I \nbelieve \n&gt; &gt; &gt; there\n&gt; &gt; &gt; &gt; &gt; =\r\nis\n&gt; &gt; &gt; &gt; &gt; &gt; no\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; special change needed in the traditional ba=\r\nckprop \n&gt; algorithm.\n&gt; &gt; &gt; &gt; &gt; With\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; recurrence you would need=\r\n something like recurrent \n&gt; backprop \n&gt; &gt; &gt; like\n&gt; &gt; &gt; &gt; &gt; &gt; Derek\n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; suggested. But let&#39;s just say you are evolving \n&gt; nonrecurrent\n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; networks-\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; is there a particular problem you have in mi=\r\nnd that \ncomes \n&gt; up\n&gt; &gt; &gt; &gt; &gt; with\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; applying backprop to such=\r\n networks?\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; --- =\r\nIn neat@yahoogroups.com &lt;neat%40yahoogroups.com&gt;,\n&gt; &gt; &gt; &gt; &gt; &quot;petar_chervens=\r\nki&quot;\n&gt; &gt; &gt; &gt; &gt; &lt;petar_chervenski@&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; &gt; Hello there.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I am looking for a=\r\nny back-propagation algorithm that \n&gt; can \n&gt; &gt; &gt; work\n&gt; &gt; &gt; &gt; &gt; on\n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; networks with arbitrary topology such as these that \nNEAT\n&gt; &gt; &gt; &gt; &gt;=\r\n evolves.\n&gt; &gt; &gt; &gt; &gt; &gt; All\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; libraries I found so far either a=\r\nssume layered \nnetworks \n&gt; or\n&gt; &gt; &gt; &gt; &gt; only\n&gt; &gt; &gt; &gt; &gt; &gt; feed-\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; forward ones.. I am confused. Is there any source \ncode \n&gt; &gt; that\n&gt; &gt; &gt;=\r\n &gt; &gt; might\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; help\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; me? Any back-prop implementat=\r\nion that can work on NEAT\n&gt; &gt; &gt; &gt; &gt; networks\n&gt; &gt; &gt; &gt; &gt; &gt; such\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; that it can easily be integrated. Or maybe some \npapers \n&gt; on \n&gt; &gt; &gt; the=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; topic?\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I appreciate any help from the communit=\r\ny.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Peter\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;  \n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\n-- \n&gt; &gt; &gt; &gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; &gt; &gt; &gt; Rafael C.P.\n&gt; &gt; &gt; &gt; =3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}