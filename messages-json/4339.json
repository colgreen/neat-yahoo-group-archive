{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"sM4vzkGHpWMbCrBF8zhQiztOdEd6q9-n9gZNeWaF5gcrRg5tMr3MaObkjK906syQCTnocVQ5PEYyYZ75kN26imgoaUhlU6HFIIJCuD2Axahi","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Article Documenting How Natural Selection is Not Good at Choosing At Least One of Its Own Parameters (Mutation Rate)","postDate":"1223149380","msgId":4339,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdjOGgwNCt0bnRxQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM1MDg0NkE1LjI1MkE2JWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4332,"nextInTopic":4344,"prevInTime":4338,"nextInTime":4340,"topicId":4326,"numMessagesInTopic":12,"msgSnippet":"... *evolve* the ... Rechenberg s 1/5th ... heuristic. It ... fixed ... paper (cited ... global peak ... is on the ... helpful, ... CB shows ... rates, to ... ","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 71153 invoked from network); 4 Oct 2008 19:43:01 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m43.grp.scd.yahoo.com with QMQP; 4 Oct 2008 19:43:01 -0000\r\nX-Received: from unknown (HELO n38d.bullet.mail.sp1.yahoo.com) (66.163.169.144)\n  by mta16.grp.scd.yahoo.com with SMTP; 4 Oct 2008 19:43:01 -0000\r\nX-Received: from [69.147.65.148] by n38.bullet.mail.sp1.yahoo.com with NNFMP; 04 Oct 2008 19:43:01 -0000\r\nX-Received: from [66.218.66.84] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 04 Oct 2008 19:43:01 -0000\r\nDate: Sat, 04 Oct 2008 19:43:00 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gc8h04+tntq@...&gt;\r\nIn-Reply-To: &lt;C50846A5.252A6%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Article Documenting How Natural Selection is Not Good at Choosing At Least One of Its Own Parameters (Mutation Rate)\r\nX-Yahoo-Group-Post: member; u=54567749; y=WmsxapfwtA96LBLk4nxilBuhn8wNFTcDe8cFXlOeEf8KnoMzUdwh\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n--- In neat@yahoogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n\n&gt; As Alexandre=\r\n points out in the following email, there is an important\n&gt; distinction to =\r\nbe made between &#39;adaptive&#39; and &#39;self-adaptive&#39; parameter\n&gt; changes. I consi=\r\nder self-adaptive parameter regimes those that\n*evolve* the\n&gt; parameters. A=\r\ndaptive regimes use an external heuristic to change the\n&gt; parameter setting=\r\ns. For example, simulated annealing and\nRechenberg&#39;s 1/5th\n&gt; rule (for Evol=\r\nutionary Strategies) use an adaptive external\nheuristic. It\n&gt; has been show=\r\nn that such adaptive mutation rates can be better than\nfixed\n&gt; mutation rat=\r\nes on certain problems. Thomas Back did this in his\npaper (cited\n&gt; in mine)=\r\n with counting ones. When a population is far from the\nglobal peak\n&gt; it is =\r\ngood to have a higher mutation rate, but once the population\nis on the\n&gt; gl=\r\nobal peak it is better to lower the mutation rate.\n&gt; \n&gt; For this reason, I =\r\nthink that adapting parameters during a run is\nhelpful,\n&gt; if you know how t=\r\no do it properly. What my current paper from PLoS\nCB shows\n&gt; is that it is =\r\nnot a good idea, at least with respect to mutation\nrates, to\n&gt; *evolve* the=\r\n parameter settings.\n&gt; \n&gt; I think this discussion is helpful, though, becau=\r\nse it is very\ncommon for\n&gt; people in our field to assume that because adapt=\r\nive regimes are good,\n&gt; self-adaptive regimes are good. It is partly my hop=\r\ne that this paper\nwill\n&gt; highlight that the one does not imply the other.\n&gt;=\r\n \n&gt; So, I am going to throw down this provocative statement, because I am\n&gt;=\r\n curious to see if there is evidence to the contrary. Claim: whenever\npeopl=\r\ne\n&gt; say that self-adaptation works, they are working on a toy problem with =\r\na\n&gt; smooth fitness landscape.\n&gt; \n&gt; I have seen a couple papers that claimed=\r\n that self-adaptation\nworked. But\n&gt; whenever I looked under the hood and or=\r\n talked with the authors, I\nended up\n&gt; finding either that they used a smoo=\r\nth fitness landscape, or that\nthey did\n&gt; not check whether a fixed mutation=\r\n rate would have performed better than\n&gt; their self-adapted mutation rate.\n=\r\n&gt; \n&gt; Alexandre, you mention that CMAES are faster than SAES. Does that\nimpl=\r\ny that\n&gt; SAES has also been shown to work? If so, was it on a smooth fitnes=\r\ns\n&gt; landscape?\n&gt; \n&gt; Thanks all for the interesting conversation.\n&gt; Jeff\n&gt; \n=\r\n\nJeff, why do you feel there is an important distinction between\nself-adapt=\r\nive and adaptive schemes (as you define them) aside from\npeople&#39;s reported =\r\nsuccesses with them?  I would have expected after\nyour results that you wou=\r\nld be skeptical even of the adaptive schemes\n(e.g. ones that change paramet=\r\ners deterministically, i.e. without\nevolution, like CMA-ES).  After all, bo=\r\nth self-adaptive\nand adaptive schemes are heuristic.  I don&#39;t know why one =\r\ntype of\nheuristic should be vastly superior to another simply because it is=\r\n\ndeterministic?  They both face the same ultimate problem that they are\ntry=\r\ning to optimize meta-parameters in the midst of searching for the\nsolution =\r\nwithin the domain itself.  My understanding of your results\nwas that the re=\r\nason the self-adaptive heuristic fails is not so much\nbecause of the &quot;self&quot;=\r\n part, but rather because of the interaction\nbetween meta-optimization and =\r\noptimization at the same time, as well\nas the vastness of the meta-search. =\r\n That pitfall would seem to apply\nequally in deterministic adaptation.\n\nAs =\r\nJulian pointed out, if evolution is getting sucked into a local\noptimum, th=\r\ne CMA-ES can actually exacerbate this problem even more by\ncomputing the ri=\r\nght distribution of mutations to be even more likely\nto head into the trap.=\r\n  That would seem to be an instance of the same\nproblem that you are observ=\r\ning with self-adaptation.\n\nSo I am curious why you feel the self-adaptive s=\r\nchemes are more\nvulnerable than the adaptive ones?  \n\nken\n\n\n"}}