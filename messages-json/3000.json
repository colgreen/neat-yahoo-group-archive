{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"KLofsC6eEkLmB57XputRjc_fRtlqs1pWFGqScAS-Cv44kBLo0pXYzsXPXO7c2oMwM13HiwTD9hw9OvvVEIPgesiWjiVSgttTj8CDxLRX1dTy","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: lost message?","postDate":"1173940399","msgId":3000,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV0YXBiZitlb2JuQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGV0OHJhMCtuaTlvQGVHcm91cHMuY29tPg=="},"prevInTopic":2996,"nextInTopic":0,"prevInTime":2999,"nextInTime":3001,"topicId":2995,"numMessagesInTopic":3,"msgSnippet":"Hi Petar, within the next couple weeks we will finally be releasing new work involving CPPNs that will answer some of these questions, in particular the big","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 24470 invoked from network); 15 Mar 2007 06:33:28 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m51.grp.scd.yahoo.com with QMQP; 15 Mar 2007 06:33:28 -0000\r\nReceived: from unknown (HELO n15c.bullet.sp1.yahoo.com) (69.147.64.120)\n  by mta6.grp.scd.yahoo.com with SMTP; 15 Mar 2007 06:33:28 -0000\r\nReceived: from [216.252.122.216] by n15.bullet.sp1.yahoo.com with NNFMP; 15 Mar 2007 06:33:21 -0000\r\nReceived: from [66.218.69.4] by t1.bullet.sp1.yahoo.com with NNFMP; 15 Mar 2007 06:33:21 -0000\r\nReceived: from [66.218.66.81] by t4.bullet.scd.yahoo.com with NNFMP; 15 Mar 2007 06:33:21 -0000\r\nDate: Thu, 15 Mar 2007 06:33:19 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;etapbf+eobn@...&gt;\r\nIn-Reply-To: &lt;et8ra0+ni9o@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: lost message?\r\nX-Yahoo-Group-Post: member; u=54567749; y=UvuNHhY4RWHqiSfV57Gq2yp4RMryh5BH-zf46aKWomGFm5mcY9wO\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nHi Petar, within the next couple weeks we will finally be releasing \nnew wo=\r\nrk involving CPPNs that will answer some of these questions, \nin particular=\r\n the big question of how they can be used as a \npractical device for produc=\r\ning phenotypes.  I think it&#39;s fair to say \nthat it&#39;s a deep topic with a lo=\r\nt of possibilities.\n\nIn the meantime before those papers are out, let me co=\r\nmment a bit on \nactivation functions.  I agree that multiplication is a pot=\r\nentially \nuseful function, and that it does have a corresponding logical \ni=\r\nnterpretation similar to AND.  \n\nOther activation functions that you sugges=\r\nt look interesting too, \nbut there is one thing to keep in mind:  Activatio=\r\nn functions should \nbe chosen with care.  It is not necessarily an advantag=\r\ne to have a \nlot of them.  Rather, the goal should be to choose ones that a=\r\nre \nfundamental to important motifs such as symmetry.  Yet if you \nalready =\r\nhave one symmetric function (e.g. Gaussian) it is \nquestionable whether you=\r\n should have additional symmetric ones (e.g. \nabsolute value) since they ju=\r\nst become redundant.  Sine and cosine \nraise similar issues: They both give=\r\n evolution an easy way to \ndiscover periodicity (such as segmental structur=\r\ne), yet it is not \nclear why having two such functions is better than one. =\r\n At some \npoint, having too many of these functions simply explodes the sea=\r\nrch \nspace unnecessarily.  \n\nAnother consideration is that if periodic stru=\r\ncture has no \nconceivable role to play in your phenotype, then including pe=\r\nriodic \nfunctions can only be bad for the search.  \n\nSo there are a lot of =\r\nconsiderations when choosing your activation \nfunction set.  They should be=\r\n chosen in a principled manner, each \nwith at least an intuitive justificat=\r\nion of why it might help.\n\nOf course, it&#39;s fun to experiment and just see w=\r\nhat pictures come \nup, and when you&#39;re just doing that, there&#39;s no harm in =\r\ntrying a lot \nof different things.\n\nken\n\n--- In neat@yahoogroups.com, &quot;peta=\r\nr_chervenski&quot; \n&lt;petar_chervenski@...&gt; wrote:\n&gt;\n&gt; Ken, I deleted it, because=\r\n I couldn&#39;t edit it further and expand \nit \n&gt; with some other thoughts I ha=\r\nd in mind. It was mentioned that I&#39;ll \nadd \n&gt; to it, but it turned out that=\r\n I cannot, so, I have to write that \n&gt; again.. :)\n&gt; \n&gt; I realized the conce=\r\npt of CPPNs, it is really an interesting \n&gt; indirection of creating the phe=\r\nnotype. Instead of evolving the \n&gt; phenotypes directly, &quot;phenotype builders=\r\n&quot; are evolved, and their \n&gt; product is evaluated. I don&#39;t know if this is t=\r\nhe same as the \n&gt; composition of functions, it is simply phenotypes constru=\r\ncting \n&gt; phenotypes. I even think there may be infinite levels of such an \n=\r\n&gt; indirecton, like phenotypes create phenotypes that further create \n&gt; phen=\r\notypes.. \n&gt; It is really interesting that ANY phenotype can be described by=\r\n a \nCPPN, \n&gt; since the CPPN can approximate any possible function with infi=\r\nnite \n&gt; precision. \n&gt; But WHAT is the phenotype space? It is very hard to i=\r\nnterpret the \n&gt; results from a CPPN into something practical. Consider the =\r\ncase \nwhen I \n&gt; evolve Alife creatures, composed of &quot;cells&quot; that live in a =\r\ncomplex \n&gt; simulated environment.\n&gt; Given the phenotype&#39;s space as a vector=\r\n (the object space origin \n&gt; (0,0,0)), and 3 unit vectors for the XYZ axise=\r\ns, we can build the \n&gt; creature using the CPPN around the origin, and so on=\r\n... The CPPN \nwill \n&gt; tell me &quot;here place a muscle cell&quot;, &quot;there is no cell=\r\n here&quot;, \nright? \n&gt; But when to stop? How big is the phenotype??? What if th=\r\ne \nindividual \n&gt; CPPN produce a negative image, saying &quot;there is an empty s=\r\npace \naround \n&gt; the origin, and everything that goes further into infinity =\r\nare \ncells, \n&gt; cells... \n&gt; This is what is confusing me.\n&gt; \n&gt; Anothier thin=\r\ng to mention, I have the idea of using lots of \nactivation \n&gt; functions plu=\r\ns splitting the node activation into 2 stages. \n&gt; First is the summing func=\r\ntion. \n&gt; I realized that summing the weighted inputs in the node is equial =\r\n\nto a \n&gt; OR logic operation on them. Would it be more powerful to add more =\r\n\nto \n&gt; that, like AND? \n&gt; It turns out that multiplication is AND in fact..=\r\n Check this out:\n&gt; ----------------------------\n&gt; &quot;the apple is red&quot;     =\r\n=3D a\n&gt; &quot;my CPU is pentium-4&quot;  =3D b\n&gt; &quot;the cofee is black&quot;   =3D c\n&gt; \n&gt; a =\r\n+ b =3D &quot;the apple is red OR my CPU is pentium-4&quot;\n&gt; a * b =3D &quot;the apple is=\r\n red AND my CPU is pentium-4&quot; \n&gt; \n&gt; further you can see that when we apply =\r\nmath with the a,b,c \nstatements, \n&gt; it&#39;s all true:\n&gt; \n&gt; a * b =3D b * a\n&gt; a=\r\n + b =3D b + a\n&gt; \n&gt; a * (b + c) =3D (a * b) + (a * c) \n&gt; ------------------=\r\n-------------\n&gt; \n&gt; So I changed the Network::activate() method like this: \n=\r\n&gt; \n&gt; // initial active sum depends on the sum function type\n&gt; // if actives=\r\num=3D=3D0 and a MUL sum func type, it will always be 0 .. \n&gt; if ((*curnode)=\r\n-&gt;sftype =3D=3D NEAT::ADD )\n&gt; {\n&gt; (*curnode)-&gt;activesum=3D0.0;\n&gt; }\n&gt; else\n&gt;=\r\n {\n&gt; (*curnode)-&gt;activesum=3D1.0;\n&gt; }\n&gt; \n&gt; ***\n&gt; \n&gt; ///////////////////////=\r\n////////\n&gt; // SUM function here\n&gt; // MIN/MAX not implemented yet\n&gt; switch((=\r\n*curnode)-&gt;sftype)\n&gt; {\n&gt; case NEAT::ADD:\n&gt;   (*curnode)-&gt;activesum +=3D add=\r\n_amount;\n&gt; break;\n&gt; case NEAT::MUL:\n&gt;   (*curnode)-&gt;activesum *=3D add_amou=\r\nnt;\n&gt; break;\n&gt; default:\n&gt; // default is addition\n&gt;   (*curnode)-&gt;activesum =\r\n+=3D add_amount;\n&gt; break;\n&gt; }\n&gt; \n&gt; ***\n&gt; \n&gt; When real values are applied, i=\r\nt becomes something like fuzzy \nlogic... \n&gt; I think this can raise the poss=\r\nible complexity A LOT, in addition \nto \n&gt; the many activation functions add=\r\ned:\n&gt; \n&gt; //----------------------------------------------------------------=\r\n-\n-----\n&gt; -\n&gt; // ACTIVATION FUNCTIONS SUPPORTED: name / output range / form=\r\nula\n&gt; // -------------------------------\n&gt; // NEURAL FUNCTIONS\n&gt; // -------=\r\n---------\n&gt; // plain sigmoid       : (0  .. 1)      : f(x) =3D 1/(1+exp(-x)=\r\n);\n&gt; // hyperbolic tangent  : {-1 .. 1)      : f(x) =3D tanh(x);\n&gt; // gauss=\r\nian            : (0  .. 1)      : f(x) =3D ?\n&gt; // ----------------------\n&gt; =\r\n// MATHEMATICAL FUNCTIONS (experimental)\n&gt; // ----------------------\n&gt; // s=\r\nine                : (-1 .. 1)      : f(x) =3D sin(x);\n&gt; // cosine         =\r\n     : (-1 .. 1)      : f(x) =3D cos(x);\n&gt; // square              : (0, +in=\r\nf)      : f(x) =3D x*x;\n&gt; // square root         : (0, +inf)      : f(x) =\r\n=3D sqrt(x);\n&gt; // exponential         : (?)            : f(x) =3D exp(x);\n&gt;=\r\n // log                 : (?)            : f(x) =3D log(x);\n&gt; // inv       =\r\n          : (-inf, +inf)   : f(x) =3D (x!=3D0)?\n1/x:BIG_NUMBER; \n&gt; // absol=\r\nute value      : (0 .. +inf)    : f(x) =3D abs(x);\n&gt; // linear             =\r\n : (-inf .. +inf) : f(x) =3D x;\n&gt; //---------------------------------------=\r\n--------------------------\n-----\n&gt; -\n&gt; \n&gt; /////////////////////////////////=\r\n///////////////////\n&gt; // NEURON INPUT SUM FUNCTIONS (experimental)\n&gt; // ---=\r\n--------------------------------------\n&gt; // addition       : (i1*w1) + (i2*=\r\nw2) + (in*wn)       : \ndefault      : \n&gt; OR\n&gt; // multiplication : (i1*w1) *=\r\n (i2*w2) * (in*wn)       : \nexperimental : \n&gt; AND\n&gt; // maximal of     : MAX=\r\n ((i1*w1), (i2*w2), (i3*w3))   : \nexperimental\n&gt; // minimal of     : MIN ((=\r\ni1*w1), (i2*w2), (i3*w3))   : \nexperimental\n&gt; /////////////////////////////=\r\n////////////////////////\n&gt; \n&gt; \n&gt; Please tell me if you have any thoughts on=\r\n this, I will be happy \nto \n&gt; know. \n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;=\r\nKenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Did the message, &quot;Some thoughts=\r\n about CPPNs,&quot; by \npetar_chervenski get \n&gt; &gt; deleted?  I was going to respo=\r\nnd to it but it seems to be gone.  \n&gt; &gt; Petar, if you meant to delete it th=\r\nat&#39;s fine but if not somehow \nyour \n&gt; &gt; message, which was interesting, mys=\r\nteriously disappeared.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt;\n&gt;\n\n\n\n"}}