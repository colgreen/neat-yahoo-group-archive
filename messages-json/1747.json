{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"mQL5cy-wb_wCNJsIqqXlBV3CIbnKkszbfK_hGTl2_M66a6wBn8RnRoC_RvnL6sJQrixAZ6SK6DtjClpM6-Kpa-vYGT40tsw6Jeti2Ie6y83J","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: High rez input (i.e. Video) generalization","postDate":"1101955913","msgId":1747,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNvbTAwOSs0Z3VvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDE5YjEwZDUxMDQxMjAxMDg1MzJlYjRjMGJhQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":1746,"nextInTopic":1748,"prevInTime":1746,"nextInTime":1748,"topicId":1743,"numMessagesInTopic":9,"msgSnippet":"The first thing I should clarify is that when my dissertation (and the chapter on RARS) was written, we had *not* used raw visual input, as you quoted.","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 30575 invoked from network); 2 Dec 2004 02:52:52 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m21.grp.scd.yahoo.com with QMQP; 2 Dec 2004 02:52:52 -0000\r\nReceived: from unknown (HELO n12a.bulk.scd.yahoo.com) (66.94.237.20)\n  by mta1.grp.scd.yahoo.com with SMTP; 2 Dec 2004 02:52:52 -0000\r\nReceived: from [66.218.69.6] by n12.bulk.scd.yahoo.com with NNFMP; 02 Dec 2004 02:51:53 -0000\r\nReceived: from [66.218.66.121] by mailer6.bulk.scd.yahoo.com with NNFMP; 02 Dec 2004 02:51:53 -0000\r\nDate: Thu, 02 Dec 2004 02:51:53 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;com009+4guo@...&gt;\r\nIn-Reply-To: &lt;19b10d5104120108532eb4c0ba@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 4462\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.94.237.20\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: High rez input (i.e. Video) generalization\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\nThe first thing I should clarify is that when my dissertation (and \nthe chapter on RARS) was written, we had *not* used raw visual \ninput, as you quoted.  However, just within the last couple weeks we \nhave been experimenting with such input and that&#39;s what Reuben is \nreferring to with his quotes.\n\nThe first set of sensors we used previously were like laser \nrangefinder sensors, and yes we did evolution one track for the most \npart.  (We may have evolved on a few different tracks, but each \nindividual evolution was on one track)\n\nIn answers to your questions about noise, there are several types of \nnoise that can poitentially be added, but my disucssions with Reuben \nwere specifically about adding noise to prevent NEAT from learning \nthat specific pixels in a raw visual field are indicators of \nspecific states or necessary actions.  That kind of correlation is \nbad because it&#39;s probably just a fluke if some pixel came up intense \nduring a certain type of crash or situation in a particular training \nrun, and we don&#39;t want NEAT learning such correlations.  So one way \nto prevent that might be to add noise to the pixels.  It&#39;s only a \nsuggestion as we have not tried it yet.\n\nIn general, it has been shown that for real world transfer &quot;model \nnoise&quot; is quite effective, meaning that the actions requested by the \noutputs result in slightly unpredictable results.  Faustino Gomez \nshowed this here at UT.\n\nHowever, in the particular case of raw visual input, we are talking \nabout a specific kind of problem- learning pixel correlations to \nstates - and that might be best served by some noise in the \ndisplay.  \n\nken\n\n\n\n\n--- In neat@yahoogroups.com, Derek James &lt;djames@g...&gt; wrote:\n&gt; &gt; --- In neat@yahoogroups.com, &quot;Reuben&quot; &lt;reuben.grinberg@y...&gt; \nwrote:\n&gt; &gt;\n&gt; &gt; &gt; Ken - when you were running NEAT in the car domain, did you \ntry to\n&gt; &gt; perturb the way the\n&gt; &gt; &gt; video was presented? While it would certainly increase the \nnumber\n&gt; &gt; of generations needed\n&gt; &gt; &gt; to get something acceptable, it might also make a solution \nthat is\n&gt; &gt; able to generalize. That\n&gt; &gt; &gt; is, it might make a solution where there isn&#39;t a pixel-feature\n&gt; &gt; correspondance.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Any thoughts?\n&gt; &gt; &gt;\n&gt; &gt; \n&gt; &gt; I think that&#39;s a totally valid approach and should be looked \ninto.\n&gt; &gt; It may help a lot.  We just had results today suggesting that\n&gt; &gt; longer, more diverse training experiences lead to better\n&gt; &gt; generalization, which suggests that the more varied the examples,\n&gt; &gt; the better it generalizes.  That in turn suggests that adding \nsome\n&gt; &gt; noise might help.\n&gt; &gt; \n&gt; &gt; ken\n&gt; \n&gt; I hadn&#39;t actually read the &quot;Automobile Warning System&quot; portion of \nyour\n&gt; dissertation, but I did so after Reuben&#39;s mention of it.  It&#39;s\n&gt; interesting stuff.  But I did want to clarify.\n&gt; \n&gt; This is the domain Reuben&#39;s referring to when he talks about \nthe &quot;car\n&gt; domain&quot;, correct?\n&gt; \n&gt; And according to the paper, you&#39;re not using video data, right?\n&gt; \n&gt; The dissertation says:\n&gt; \n&gt; &quot;Using raw data provided by RARS, two kinds of sensor systems were\n&gt; developed for this\n&gt; project and provided as input to NEAT neural networks. First,\n&gt; rangefinder sensors project rays at several angles relative to the\n&gt; car&#39;s heading to the edge of the road (figure 8.2). The \nrangefinders\n&gt; give the car an indication of its position and heading relative to \nthe\n&gt; sides of the road, and also of the curvature of the road.\n&gt; \n&gt; Second, several simulated radar sensors detect other cars or \nobstacles\n&gt; (figure 8.3). The radar sensors are convenient for detecting \ndiscrete\n&gt; objects by locating them inside of one of several slices that\n&gt; represent relative angles and positions. The radars return a value\n&gt; equivalent to the distance of the nearest car in each slice, or a\n&gt; maximum value if there is no car.&quot;\n&gt; \n&gt; So are the first type of sensors analogous to feedback from laser \nsensors?\n&gt; \n&gt; And it sounded from the first experiment, just learning to drive \non an\n&gt; empty track, that only one track was used...is that correct?\n&gt; \n&gt; Does RARS support randomization of track designs?  This is a type \nof\n&gt; noise that could have been added to the environment.  You also \ntalked\n&gt; here about possibly adding noise to the controls, in this case the\n&gt; gas, brake, and steering.  I guess one could also artificially add\n&gt; noise to the sensor data that the cars are receiving.  But none of\n&gt; these were actually done, right?  Would you think any or all of \nthem\n&gt; would be effective?\n&gt; \n&gt; Derek\n\n\n\n\n"}}