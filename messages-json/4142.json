{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":345796568,"authorName":"peterberrington","from":"&quot;peterberrington&quot; &lt;peterberrington@...&gt;","profile":"peterberrington","replyTo":"LIST","senderId":"R-7e2Q7dmZ-Dakj5iMwV_BYZiTMdMeQPA2Fe5jjd-9sOZnmm1n5JBPrmCUx_EkwQmUjfOJb-2aHxtzXKEyTjCswO-v3IWRxTr7MGfbBzOQPT4WE","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Parallelizing novelty search","postDate":"1213097332","msgId":4142,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcybG9oaytrMm5pQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGcybGhuZytqdTJ2QGVHcm91cHMuY29tPg=="},"prevInTopic":4141,"nextInTopic":4144,"prevInTime":4141,"nextInTime":4143,"topicId":4137,"numMessagesInTopic":4,"msgSnippet":"Petar, I understand what you are saying, and indeed you can do it exactly as you described using rtneat. I should have clarified, my implementation is not a","rawEmail":"Return-Path: &lt;peterberrington@...&gt;\r\nX-Sender: peterberrington@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 91263 invoked from network); 10 Jun 2008 11:28:54 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m53.grp.scd.yahoo.com with QMQP; 10 Jun 2008 11:28:54 -0000\r\nX-Received: from unknown (HELO n27c.bullet.scd.yahoo.com) (66.218.67.220)\n  by mta15.grp.scd.yahoo.com with SMTP; 10 Jun 2008 11:28:54 -0000\r\nX-Received: from [66.218.69.4] by n27.bullet.scd.yahoo.com with NNFMP; 10 Jun 2008 11:28:54 -0000\r\nX-Received: from [66.218.66.92] by t4.bullet.scd.yahoo.com with NNFMP; 10 Jun 2008 11:28:54 -0000\r\nDate: Tue, 10 Jun 2008 11:28:52 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g2lohk+k2ni@...&gt;\r\nIn-Reply-To: &lt;g2lhng+ju2v@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;peterberrington&quot; &lt;peterberrington@...&gt;\r\nSubject: Re: Parallelizing novelty search\r\nX-Yahoo-Group-Post: member; u=345796568; y=N8wurvZlbtrItM98M4LKWEnxB45pXoUpj0VWc1loTqml4DYnF_X5EJ0-\r\nX-Yahoo-Profile: peterberrington\r\n\r\nPetar, I understand what you are saying, and indeed you can do it\nexactly a=\r\ns you described using rtneat. I should have clarified, my\nimplementation is=\r\n not a direct copy of the rtneat algorithm; I do not\ncontinuously evaluate =\r\nindividuals in my implementation and remove\naccording to eligibility requir=\r\nements; while that may work for a\nvideogame, its not necessary and the sear=\r\nch dynamics are preserved so\nlong as you follow the dynamic of removing and=\r\n adding one individual\nat time. That is all besides the point, I realize I =\r\ncan probably do\nthings your way, I was trying to hint at adapting the searc=\r\nh itself.\n\nThe point I was making (and why I used the word is anastomosis) =\r\nis\nthat evolutionary search is in many respects like a kind of branching\nex=\r\nploration through some parameter-dimensional space. We always like\nto imagi=\r\nne a tree branching out into all the possible points in search\nspace, but i=\r\nt is instructive to look at actual phylogenetic networks\nfrom biology; beca=\r\nuse of features like lateral gene transfer,\nrecombination, hybridization an=\r\nd gene duplication, biological search\nnot only branches but reconverges. Th=\r\nis is why taxonomic\nclassification of some species is complicated, and henc=\r\ne we use\nnetworks (with closed cycles) rather than bifurcating trees for so=\r\nme\ntaxonomic data. \n\nI&#39;m getting a little philosophical but my point is, no=\r\nvelty search\ncould probably benefit from a separate level of forced\ndiversi=\r\nfication; the fact that it can be done concurrently if you have\nmultiple co=\r\nres on your computer or a big cluster of cpus is icing on\nthe cake.  If you=\r\n look at a picture of a leaf skeleton or a\ncirculatory/venous system you wi=\r\nll notice that a vast area is able to\nbe spanned by recursively branching o=\r\nut and joining in again; I think\nthis metaphor/pattern is applicable to sea=\r\nrch as well because of some\ninherent properties: for one, a large area is s=\r\npanned because the root\nbranches are equidistant from each other in space a=\r\nnd each spans\noutward. Secondly, effort is not duplicated because when the =\r\nbranches\nare full enough to converge on each others space, they rejoin. \n\nT=\r\no combine those two properties and exploit parallel processing, I\nthink nov=\r\nelty search (all of it, not just evaluation) should be done\nin parallel wit=\r\nh regular forced merging of the disparate populations.\nIf this can be done =\r\nnondestructively, all of the information obtained\nfrom each separate search=\r\n will be unified and used as starting points\nfor the next phase. \n\nIn effec=\r\nt I feel this will reify the anastomosis pattern in search and\nallow it to =\r\ncover a VAST amount more space (limited by the number of\ncpus you have and =\r\nthe amount of overlap in search). \n\n--- In neat@yahoogroups.com, &quot;petar_che=\r\nrvenski&quot; &lt;petar_chervenski@...&gt;\nwrote:\n&gt;\n&gt; You welcome :) I will upload mor=\r\ne stuff when I have the time. I have \n&gt; some other interesting projects in =\r\nmind. Now let me tell you about \n&gt; the parallel/distributed NS. The most CP=\r\nU resources are taken by the \n&gt; evaluation process. In real-time NEAT (whic=\r\nh is the steady state \n&gt; evolution) you can evaluate all individuals in the=\r\n population *in the \n&gt; same time*, not one after another. So this should be=\r\n the way to \n&gt; parallelize it. And then you replace the worst individual ev=\r\nery few \n&gt; ticks in a separate thread or something. This part of the algori=\r\nthm \n&gt; doesn&#39;t take much time. The time spent in NEAT genetic routines is \n=\r\n&gt; very small compared to the time spent evaluating the phenotypes. Or \n&gt; at=\r\n least this is true in most domains. So you should focus on how to \n&gt; evalu=\r\nate the individuals in parallel, because you only need the \n&gt; fitness score=\r\ns of the whole population for the NEAT part. Getting \n&gt; these scores takes =\r\nmost of the time :) \n&gt; \n&gt; Peter\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;peterber=\r\nrington&quot; &lt;peterberrington@&gt; \n&gt; wrote:\n&gt; &gt;\n&gt; &gt; Thanks a lot to Petar C for h=\r\nis novelty-based nevh, its really \n&gt; coming\n&gt; &gt; along nicely.\n&gt; &gt; \n&gt; &gt; In t=\r\nhe past while I have been thinking of how to best exploit \n&gt; parallel\n&gt; &gt; a=\r\nrchitecture with novelty search. \n&gt; &gt; I have a pretty good idea of how to d=\r\no this in general, but the\n&gt; &gt; details need a lot of work and I could use a=\r\ns much help and input \n&gt; as I\n&gt; &gt; can get.\n&gt; &gt; \n&gt; &gt; With generational dynam=\r\nics its quite easy to simply divide the\n&gt; &gt; population into the number of w=\r\norking processors you have and \n&gt; perform\n&gt; &gt; evaluation in parallel, explo=\r\niting the extra cpu power to do the \n&gt; most\n&gt; &gt; cpu intensive part of the N=\r\nEAT algorithm. \n&gt; &gt; \n&gt; &gt; However, since steady state novelty search only mo=\r\ndifies a single\n&gt; &gt; population member each tick, a different approach is ne=\r\ncessary. \n&gt; &gt; (When I say tick from henceforth I am just referring to the 3=\r\n steps \n&gt; of\n&gt; &gt; remove worst, sort by fitness/species_size, add new \n&gt; pro=\r\nbabilistically).\n&gt; &gt; \n&gt; &gt; At first I thought an easy modification to implem=\r\nent is this: view \n&gt; the\n&gt; &gt; tick() method as a function which takes a popu=\r\nlation and returns a\n&gt; &gt; population of the same size, with the worst indivi=\r\ndual replaced with\n&gt; &gt; an new individual. Simply performing n concurrent ti=\r\ncks and \n&gt; selecting\n&gt; &gt; the resulting population which is the best could t=\r\nhen be done, which\n&gt; &gt; bears some resemblance to the idea of tournament sel=\r\nection.\n&gt; &gt; \n&gt; &gt; Thinking on this further though, it occurred to me that th=\r\nis is \n&gt; greedy\n&gt; &gt; and in a way wasteful/inefficient. In some sense you ca=\r\nn view \n&gt; novelty\n&gt; &gt; search&#39;s tick() method as not only adding a new indiv=\r\nidual; it also\n&gt; &gt; alters the search &quot;frontier&quot;. Since each species has a d=\r\nifferent \n&gt; spawn\n&gt; &gt; probability you are getting information about which d=\r\nirections in\n&gt; &gt; search space are less or more fruitful; by simply selectin=\r\ng the best\n&gt; &gt; of N populations each tick we are discarding this useful inf=\r\no. \n&gt; &gt; \n&gt; &gt; So after looking at a picture of the skeleton of a leaf, I tho=\r\nught\n&gt; &gt; that the best approach is to take an idea from nature; faced with =\r\n\n&gt; the\n&gt; &gt; problem of covering the most area and the tools of forking and\n&gt;=\r\n &gt; merging, nature has evolved circulatory systems which branch and\n&gt; &gt; con=\r\nverge regularly in specific ways (in particular, one noticed\n&gt; &gt; recursion)=\r\n. The process is called anastomosis I think. NEAT already\n&gt; &gt; does this in =\r\na way with species, which has the effect of packaging \n&gt; the\n&gt; &gt; population=\r\n into discrete chunks which explore particular regions of\n&gt; &gt; search space.=\r\n I propose simply doing this at a higher level in order\n&gt; &gt; to benefit from=\r\n multi-core machines and distributed processing.\n&gt; &gt; \n&gt; &gt; There is normally=\r\n a certain amount of ticks that are performed \n&gt; between\n&gt; &gt; speciation. Th=\r\ne easiest way to split up the algorithm I think is to\n&gt; &gt; perform these tic=\r\nks in parallel, then have a &quot;merge&quot; function which\n&gt; &gt; selectively decides =\r\nhow to combine the n disparate populations into \n&gt; a\n&gt; &gt; unified one, for s=\r\npeciation. This is made easier if a &quot;control&quot;\n&gt; &gt; population is saved befor=\r\ne forking, for comparison later. To be a\n&gt; &gt; little more clear, a &#39;populati=\r\non&#39; object actually consists of 3 \n&gt; objects:\n&gt; &gt; A set of member chromosom=\r\nes, each with their own attributes\n&gt; &gt; A set of member species, each with t=\r\nheir own attributes and member\n&gt; &gt; chromosomes\n&gt; &gt; A set of behaviours (i.e=\r\n. the archive), which I call a &quot;novelty \n&gt; pool&quot;\n&gt; &gt; in my implementations.=\r\n \n&gt; &gt; Each parallel tick() should take a copy of these 3 objects and \n&gt; ret=\r\nurn\n&gt; &gt; 3 new ones. \n&gt; &gt; \n&gt; &gt; So in python the main loop would look superfi=\r\ncially like this:\n&gt; &gt; \n&gt; &gt; while ( not time_to_stop )\n&gt; &gt;     speciate\n&gt; &gt; =\r\n    for i in range ( j )\n&gt; &gt;         do tick in parallel()\n&gt; &gt;     if reach=\r\ned_goal: time_to_stop =3D True\n&gt; &gt; \n&gt; &gt; j is the integer that controls how =\r\nmany ticks are performed between\n&gt; &gt; speciation, which in nero is 5 but I&#39;m=\r\n sure is robust to some \n&gt; variation.\n&gt; &gt; \n&gt; &gt; Novelty search should be per=\r\nformed with a single consolidated\n&gt; &gt; behaviour archive to avoid duplicatio=\r\nn of work, but should branch \n&gt; out\n&gt; &gt; when exploring new individuals and =\r\nharvest information about the\n&gt; &gt; search frontier whenever possible. Becaus=\r\ne of this, the\n&gt; &gt; merge/selection operation should be carefully designed t=\r\no \n&gt; incorporate\n&gt; &gt; this information non-destructively.\n&gt; &gt; \n&gt; &gt; Novelty s=\r\nearch often results in the most recently added individual\n&gt; &gt; being removed=\r\n on the next available tick (this is because a species\n&gt; &gt; with many member=\r\ns often has a high spawn probability, and \n&gt; the &#39;remove\n&gt; &gt; worst chromoso=\r\nme&#39; operation tends to remove the worst of larger\n&gt; &gt; species before smalle=\r\nr species). This has the effect that between \n&gt; many\n&gt; &gt; ticks, no new indi=\r\nviduals are added, but nonetheless the search\n&gt; &gt; frontier is altered by wa=\r\ny of aging, stagnation, and changes to\n&gt; &gt; average fitness. When comparing =\r\nthe reference/control population to\n&gt; &gt; the result of a few ticks, we can t=\r\nabulate a list of member\n&gt; &gt; chromosomes which are disjoint between the two=\r\n sets; the chromosomes\n&gt; &gt; which are in reference but not the new populatio=\r\nn can be considered\n&gt; &gt; dead-ends, and conversely the chromosomes in the ne=\r\nw population not\n&gt; &gt; present in the reference can be considered improvement=\r\ns.\n&gt; &gt; \n&gt; &gt; The total set of improvements between all n concurrent set of t=\r\nicks\n&gt; &gt; should be preserved in the new unified population, and conversely =\r\n\n&gt; the\n&gt; &gt; dead ends should be removed, but doing this is more difficult th=\r\nan \n&gt; it\n&gt; &gt; seems. This is partly because the list of member chromosomes i=\r\ns also\n&gt; &gt; intimately coupled with the list of member species.\n&gt; &gt; \n&gt; &gt; Of =\r\nthe species which are common to both a new population and the\n&gt; &gt; reference=\r\n population, there may be differences in the species &quot;no\n&gt; &gt; improvement ag=\r\ne&quot;, age, average fitness, and member chromosomes. \n&gt; &gt; Unifying these dispa=\r\nrate sets presents a problem for me.\n&gt; &gt; \n&gt; &gt; For example, what if an impro=\r\nvement from one of the new populations \n&gt; is\n&gt; &gt; a member of a species whic=\r\nh was removed in all the other new\n&gt; &gt; populations? What if a species has a=\r\nged and stagnated in most of the\n&gt; &gt; populations but has produced an improv=\r\nement in another population? \n&gt; How\n&gt; &gt; can we produced a unified populatio=\r\nn which reflects the \n&gt; contributions\n&gt; &gt; to search that each concurrent sa=\r\nlvo of ticks has made?\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Any thoughts people have are welcome.\n=\r\n&gt; &gt;\n&gt;\n\n\n\n"}}