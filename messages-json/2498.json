{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"BUuq5_YGdj3jmF9su1P0Ep10_FQJG8vcZpYPZ99ivOvlfRFztT1i87FXAzqAnDZZ-PpniJxXgvQVevto_6bs45lRutxngWNka3jWJgoFW_ht","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: real-time roving eye fitness evaluation","postDate":"1137784961","msgId":2498,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRxcmRhMStjMDVvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDYwMTE4MTQ0OTMyLjUzMTU2LnFtYWlsQHdlYjYwODIzLm1haWwueWFob28uY29tPg=="},"prevInTopic":2497,"nextInTopic":2499,"prevInTime":2497,"nextInTime":2499,"topicId":2494,"numMessagesInTopic":17,"msgSnippet":"Interestingly, since Thomas s goal is to test the roving eye idea on a real robot, the size of the robot doesn t really matter.  The issue in this case is the","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 96342 invoked from network); 20 Jan 2006 19:24:50 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m32.grp.scd.yahoo.com with QMQP; 20 Jan 2006 19:24:50 -0000\r\nReceived: from unknown (HELO n9a.bullet.scd.yahoo.com) (66.94.237.43)\n  by mta6.grp.scd.yahoo.com with SMTP; 20 Jan 2006 19:24:50 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.69.4] by n9.bullet.scd.yahoo.com with NNFMP; 20 Jan 2006 19:22:44 -0000\r\nReceived: from [66.218.66.91] by t4.bullet.scd.yahoo.com with NNFMP; 20 Jan 2006 19:22:43 -0000\r\nDate: Fri, 20 Jan 2006 19:22:41 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;dqrda1+c05o@...&gt;\r\nIn-Reply-To: &lt;20060118144932.53156.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: real-time roving eye fitness evaluation\r\nX-Yahoo-Group-Post: member; u=54567749; y=06YCvBrYwry-iHdw9sPwOnbyyiYTy5se5Luc2YzW41AEZvjDIenW\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nInterestingly, since Thomas&#39;s goal is to test the roving eye idea on \na rea=\r\nl robot, the size of the robot doesn&#39;t really matter.  The \nissue in this c=\r\nase is the visual system.  We know we can mount \ncameras on small robots su=\r\nch as Kheperas, so in principle this \nexperiment is possible to run complet=\r\nely on live hardware.  It&#39;s \nimportant to note that the camera itself doesn=\r\n&#39;t need to be \nphysically panning and zooming.  The roving eye can theoreti=\r\ncally \nmove around within the field of the camera.  In fact, that is a \nfai=\r\nrly realistic setup since a real eye is not requal resolution at \nall point=\r\ns (like a camera is).  \n\nThe hard part, like Thomas pointed out, is getting=\r\n the robot into a \nconsistent &quot;start state.&quot;  It may be possible to sort th=\r\nings out \nsuch that it doesn&#39;t matter where the robot is when it starts.  \n=\r\nOtherwise, there needs to be a reliable method to automate going \nback to t=\r\nhe start.  People have done this, in fact.  There is work \non evolving Aibo=\r\n walking gates where the robots walked back on their \nown to the starting l=\r\nine after each trial.\n\nken\n\n--- In neat@yahoogroups.com, Mitchell Timin &lt;ze=\r\nnguyuno@y...&gt; wrote:\n&gt;\n&gt; I had not considered that there might be situation=\r\ns\n&gt; where hardware fitness testing is practical.  For the\n&gt; usual robots th=\r\nat we are familiar with it is usually\n&gt; too slow to go through the 100&#39;s or=\r\n 1000&#39;s of\n&gt; generations required.  However, this might be perfect\n&gt; for na=\r\nnobots.  If there is some kind of tiny robot\n&gt; needing software, it may ver=\r\ny well be practical to\n&gt; make several hundred of them and have a real\n&gt; pop=\r\nulation.  There would have to be a way of rapidly &\n&gt; repeatedly loading da=\r\nta into them, so that fitness\n&gt; testing and survival of the fittest could b=\r\ne\n&gt; implemented.\n&gt; \n&gt; I expect this will become practical, perhaps not\n&gt; to=\r\nday, but at some time in the future. \n&gt; \n&gt; Does anyone have a tiny robot ne=\r\neding software?\n&gt; \n&gt; Mitchell Timin\n&gt; \n&gt; --- Derek James &lt;djames@g...&gt; wrot=\r\ne:\n&gt; \n&gt; &gt; Well, it doesn&#39;t require simulation, but simulation\n&gt; &gt; lets you =\r\ndo a whole lot\n&gt; &gt; more runs in a whole lot less time.\n&gt; &gt; \n&gt; &gt; At a confer=\r\nence presentation at GECCO, Dario\n&gt; &gt; Floreano talked about some\n&gt; &gt; roboti=\r\ncs experiments in which the candidate ANNs\n&gt; &gt; were uploaded into the same\n=\r\n&gt; &gt; robot one at a time for a given task (navigating a\n&gt; &gt; small environmen=\r\nt, I\n&gt; &gt; think).  So if you have a population size of 100,\n&gt; &gt; you&#39;re uploa=\r\nding them one\n&gt; &gt; at a time and testing each.  Plus, you have to have\n&gt; &gt; s=\r\nome way of measuring\n&gt; &gt; progress...if the robot has a particular sensor fo=\r\nr\n&gt; &gt; how far it is from a\n&gt; &gt; given goal state, then that could feed back =\r\ninto the\n&gt; &gt; software that&#39;s\n&gt; &gt; handling the evolutionary algorithm.\n&gt; &gt; \n=\r\n&gt; &gt; Floreano also had some experiments with extremely\n&gt; &gt; small robots (sug=\r\nar cube\n&gt; &gt; size).  If you could upload the candidate ANNs into\n&gt; &gt; 100 rob=\r\nots at a time,\n&gt; &gt; that would speed things up too...of course, most\n&gt; &gt; pla=\r\nces don&#39;t have 100 cheap\n&gt; &gt; robots and the means to upload ANN controllers=\r\n on\n&gt; &gt; the fly.\n&gt; &gt; \n&gt; &gt; There are advantages to both simulation and\n&gt; &gt; u=\r\nploading directly into\n&gt; &gt; hardware.  Simulations are a pain to implement f=\r\nrom\n&gt; &gt; scratch, and there&#39;s\n&gt; &gt; always, always performance issues when tra=\r\nnsfering a\n&gt; &gt; controller from a\n&gt; &gt; simulated environment to a real one...=\r\nso\n&gt; &gt; hardware-only mitigates that.  But\n&gt; &gt; of course it&#39;s excruciatingly=\r\n slow, and the task is\n&gt; &gt; going to have to be\n&gt; &gt; relatively simple and qu=\r\nick or you&#39;ll be doing runs\n&gt; &gt; that last years.\n&gt; &gt; \n&gt; &gt; Derek\n&gt; &gt; \n&gt; &gt; On=\r\n 1/17/06, Mitchell Timin &lt;zenguyuno@y...&gt;\n&gt; &gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; --- tomolj=\r\nack &lt;thomasjack@g...&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hello,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I&#39;m curre=\r\nntly writing an implementation of NEAT\n&gt; &gt; in\n&gt; &gt; &gt; &gt; Ruby. When I&#39;m\n&gt; &gt; &gt; =\r\n&gt; finished, I plan to evolve neural nets to\n&gt; &gt; control a\n&gt; &gt; &gt; &gt; CYE robot=\r\n, taking\n&gt; &gt; &gt; &gt; input from a roving eye on the (dynamic) video\n&gt; &gt; input\n&gt;=\r\n &gt; &gt; &gt; from the robot&#39;s\n&gt; &gt; &gt; &gt; video camera, and outputting data about how=\r\n to\n&gt; &gt; &gt; &gt; move/zoom the roving\n&gt; &gt; &gt; &gt; eye and how to change the robots s=\r\npeed and\n&gt; &gt; heading.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; However, I can&#39;t decide how I will go=\r\n about\n&gt; &gt; &gt; &gt; evaluating the networks&#39;\n&gt; &gt; &gt; &gt; fitnesses. I would think it=\r\n would be impractical\n&gt; &gt; to\n&gt; &gt; &gt; &gt; actually have the\n&gt; &gt; &gt; &gt; robot run us=\r\ning each neural net from every\n&gt; &gt; &gt; &gt; population (and it would\n&gt; &gt; &gt; &gt; inv=\r\nolve lots of extra code to manage\n&gt; &gt; automatically\n&gt; &gt; &gt; &gt; guiding the rob=\r\not\n&gt; &gt; &gt; &gt; back to its charging station when its batteries\n&gt; &gt; run\n&gt; &gt; &gt; &gt; =\r\nlow).\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; However, the robot will eventually use the\n&gt; &gt; champi=\r\non\n&gt; &gt; &gt; &gt; network to\n&gt; &gt; &gt; &gt; actually perform a task, so the networks will=\r\n\n&gt; &gt; need\n&gt; &gt; &gt; &gt; to learn how to\n&gt; &gt; &gt; &gt; process dynamic video data and re=\r\nspond\n&gt; &gt; accordingly.\n&gt; &gt; &gt; &gt; I can&#39;t think of a\n&gt; &gt; &gt; &gt; way to simulate t=\r\nhis.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I thought maybe I would run the robot manually\n&gt; &gt; &gt; &gt;=\r\n through a number of\n&gt; &gt; &gt; &gt; ideal courses, recording the video, and compar=\r\ne\n&gt; &gt; &gt; &gt; networks&#39; responses to\n&gt; &gt; &gt; &gt; the necessary responses for those =\r\ncourses, but\n&gt; &gt; I&#39;m\n&gt; &gt; &gt; &gt; not sure that will\n&gt; &gt; &gt; &gt; work, as the respon=\r\nses during simulation would\n&gt; &gt; not\n&gt; &gt; &gt; &gt; affect the video\n&gt; &gt; &gt; &gt; data. =\r\nThe final net&#39;s responses will actually\n&gt; &gt; move\n&gt; &gt; &gt; &gt; the robot and\n&gt; &gt; =\r\n&gt; &gt; therefore affect the video data.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Has anyone else tried =\r\nanything like this, or\n&gt; &gt; does\n&gt; &gt; &gt; &gt; anyone have any\n&gt; &gt; &gt; &gt; ideas about=\r\n how to evaluate these networks&#39;\n&gt; &gt; &gt; &gt; fitnesses?\n&gt; &gt; &gt;\n&gt; &gt; &gt; I&#39;m afraid =\r\nthat neuroevolution requires a computer\n&gt; &gt; &gt; simulation of the system to b=\r\ne controlled by the\n&gt; &gt; ANN.\n&gt; &gt; &gt; If there is any other way of doing it I =\r\nwould be\n&gt; &gt; very\n&gt; &gt; &gt; interested in knowing about it.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Using a=\r\n simulation instead of the real system\n&gt; &gt; allows\n&gt; &gt; &gt; you to evaluate the=\r\n fitness of thousands of\n&gt; &gt; candidate\n&gt; &gt; &gt; ANNs.  This is required to acc=\r\nomplish evolution. \n&gt; &gt; Of\n&gt; &gt; &gt; course if the simulation is not an accurat=\r\ne\n&gt; &gt; &gt; representation of the real system, the the ANN\n&gt; &gt; that\n&gt; &gt; &gt; does =\r\na good job controlling the simulation may not\n&gt; &gt; do\n&gt; &gt; &gt; as well controll=\r\ning the real system.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Mitchell Timin\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; Mitchell =\r\nTimin\n&gt; &gt; &gt; http://annevolve.sourceforge.net\n&gt; &gt; &gt;\n&gt; &gt; &gt; __________________=\r\n________________________________\n&gt; &gt; &gt; Do You Yahoo!?\n&gt; &gt; &gt; Tired of spam? =\r\n Yahoo! Mail has the best spam\n&gt; &gt; protection around\n&gt; &gt; &gt; http://mail.yaho=\r\no.com\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; Yahoo! Groups Links\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt;=\r\n &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; \n&gt; \n&gt; \n&gt; Mitchell Timin\n&gt; http://annevolve.sourc=\r\neforge.net\n&gt; \n&gt; __________________________________________________\n&gt; Do You=\r\n Yahoo!?\n&gt; Tired of spam?  Yahoo! Mail has the best spam protection around =\r\n\n&gt; http://mail.yahoo.com\n&gt;\n\n\n\n\n\n"}}