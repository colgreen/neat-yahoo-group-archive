{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":256087559,"authorName":"Andrei","from":"&quot;Andrei&quot; &lt;andrei.rusu@...&gt;","profile":"andrei.rusu","replyTo":"LIST","senderId":"kIOtjMCYQH36QdHZ1GxvQkdNbGvK5Rfv1P8-cJ3_6x6LtANDz0vPIKGQmsLc1Y1VKvvFzRBsSmn-D1uKuVRcR_unuyAsPCo","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: solution for NEAT on CUDA","postDate":"1260456870","msgId":5000,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhmcjIzNitkdXFpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhmb2xzcytjMmJ1QGVHcm91cHMuY29tPg=="},"prevInTopic":4995,"nextInTopic":5001,"prevInTime":4999,"nextInTime":5001,"topicId":4995,"numMessagesInTopic":8,"msgSnippet":"CUDA is extremely appropriate for a numerous, but very specific set of problems, namely highly parallel, vector computation driven problems. Whenever the","rawEmail":"Return-Path: &lt;andrei.rusu@...&gt;\r\nX-Sender: andrei.rusu@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 51255 invoked from network); 10 Dec 2009 14:59:18 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m13.grp.re1.yahoo.com with QMQP; 10 Dec 2009 14:59:18 -0000\r\nX-Received: from unknown (HELO n43d.bullet.mail.sp1.yahoo.com) (66.163.169.157)\n  by mta1.grp.re1.yahoo.com with SMTP; 10 Dec 2009 14:59:18 -0000\r\nX-Received: from [69.147.65.149] by n43.bullet.mail.sp1.yahoo.com with NNFMP; 10 Dec 2009 14:54:30 -0000\r\nX-Received: from [98.137.34.34] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 10 Dec 2009 14:54:30 -0000\r\nDate: Thu, 10 Dec 2009 14:54:30 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hfr236+duqi@...&gt;\r\nIn-Reply-To: &lt;hfolss+c2bu@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Andrei&quot; &lt;andrei.rusu@...&gt;\r\nSubject: Re: solution for NEAT on CUDA\r\nX-Yahoo-Group-Post: member; u=256087559; y=etChwNVwxzlU8WoLi2x9uLT_z2v7OT97UX3BjLt8-0y1l9iBodQ\r\nX-Yahoo-Profile: andrei.rusu\r\n\r\nCUDA is extremely appropriate for a numerous, but very specific set of prob=\r\nlems, namely highly parallel, vector computation driven problems. Whenever =\r\nthe treads have to do very different work, CUDA programs don&#39;t provide much=\r\n speed-up, because the hardware scheduler has to serialise operations. Many=\r\n times though, you can implement serial programs in CUDA and still get impr=\r\nessive speed-ups. \n\nI implemented an adapted version of the Conjugate Gradi=\r\nent sparse system solver you can find on Wikipedia in CUDA, and it was stil=\r\nl 10x faster than the GMM++ version. This is an iterative algorithm, but so=\r\nme subroutines can be done very efficiently on a GPU, hence the speed-up. I=\r\n am talking FLOAT operations, not double, the latter are much slower than t=\r\nhe former on current GPUs.  \n\nThe key is to implement very large portions o=\r\nf your program in CUDA, things that would take the CPU minutes, to give a r=\r\neference. Just calling a GPU matrix multiplication will make you program sl=\r\nower many times, unless we are talking huge matrices. \n\nI have to warn you,=\r\n getting performance out of CUDA does take considerably longer, and it&#39;s pa=\r\ninfully more difficult to program and debug WELL, compared to CPU programmi=\r\nng. I would also recommend a GTX200 to have enough memory and speed. \n\nThat=\r\n being said, I am looking forward to CUDA projects for the summer break!\n\nC=\r\nheers!\nAndrei\n\n--- In neat@yahoogroups.com, &quot;openmind767&quot; &lt;openmind767@...&gt;=\r\n wrote:\n&gt;\n&gt; Hi, I use NEAT these days. Although I have add parallel for \n&gt; =\r\nEvaluateNetwork and SSE for sigmoid, the performance\n&gt; is still not well. M=\r\naybe performance will never be satisfied.\n&gt; The performance profile show 90=\r\n% cpu time is used in \n&gt; Matrix-Vector Multiplication and sigmoid.\n&gt; \n&gt; CUD=\r\nA maybe is the best solution for the performance now. But\n&gt; CUDA program is=\r\n not like normal program. I don&#39;t have any \n&gt; experience with CUDA. As I th=\r\nink, in most case single network \n&gt; structure is not too big. When Calling =\r\nCUDA do Matrix-Vector \n&gt; Multiplication and sigmoid for one network, CUDA m=\r\nemory latency \n&gt; will not be hidden. so it wont gain too much performance f=\r\nor \n&gt; single network. Join all networks of population into one big \n&gt; netwo=\r\nrk, and call CUDA to do this big network, CUDA memory latency\n&gt; will be hid=\r\nden well. Maybe this is good solution for NEAT on CUDA.\n&gt; Any suggestion an=\r\nd experience is welcome.\n&gt; \n&gt; Thanks,\n&gt; Baihi\n&gt;\n\n\n\n"}}