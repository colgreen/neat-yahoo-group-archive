{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"-dhCEcbzmMVh-6UIlDUAWldtMvH5Kv81RY2k8UMwosnUdWABw-Md_cLIQMwTSBSl1t6-FfbUERHDblGLRxED2kvwRrsT808RsmT6eKO2RWqX","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: New Paper on Novelty Search and Adaptive Neural Networks","postDate":"1242277123","msgId":4663,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGd1ZzhlMytpdmExQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGd1OXY3NCszdWF0QGVHcm91cHMuY29tPg=="},"prevInTopic":4660,"nextInTopic":4692,"prevInTime":4662,"nextInTime":4664,"topicId":4619,"numMessagesInTopic":8,"msgSnippet":"Jeff, my hypothesis is that static heuristics are easier to find than adaptive ones because it is a lot easier to encode knowledge than to encode how to gain","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 8609 invoked from network); 14 May 2009 04:59:10 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m3.grp.re1.yahoo.com with QMQP; 14 May 2009 04:59:10 -0000\r\nX-Received: from unknown (HELO n45b.bullet.mail.sp1.yahoo.com) (66.163.168.159)\n  by mta1.grp.sp2.yahoo.com with SMTP; 14 May 2009 04:59:09 -0000\r\nX-Received: from [69.147.65.147] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 14 May 2009 04:58:45 -0000\r\nX-Received: from [98.137.35.12] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 14 May 2009 04:58:45 -0000\r\nDate: Thu, 14 May 2009 04:58:43 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gug8e3+iva1@...&gt;\r\nIn-Reply-To: &lt;gu9v74+3uat@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New Paper on Novelty Search and Adaptive Neural Networks\r\nX-Yahoo-Group-Post: member; u=54567749; y=maOtjzSuQXYTy2YokgZC4EHkKJQgwDgtJaFRsVpmaN3pAt1w9ia_\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, my hypothesis is that static heuristics are easier to find than adapt=\r\nive ones because it is a lot easier to encode knowledge than to encode how =\r\nto gain knowledge.  Therefore, no matter where you start in the search spac=\r\ne, you are probably closer to a static heuristic than an adaptive one.  Fur=\r\nthermore, once you begin to climb the gradient of a static heuristic, you a=\r\nre making no progress towards an adaptive one because adaptive heuristics a=\r\nre not based on a static foundation.  Rather, adaptive heuristics are based=\r\n on entirely different mechanisms, which means that static gradients are a =\r\ndeceptive trap.\n\nIn any case, we are actually presently looking quite close=\r\nly at this issue by analyzing the search space in an adaptive domain.  So l=\r\nike you, we are also interested in a more detailed answer.\n\nken\n\n--- In nea=\r\nt@yahoogroups.com, &quot;jeffreyclune&quot; &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello Ken-\n&gt; \n&gt; I=\r\n agree with you that, from what I have read and personally experienced, evo=\r\nlution likes to evolve static, rather than adaptive, heuristics. It seems l=\r\nike your argument is one of induction: evolution tends to evolve static heu=\r\nristics, so there must be a valley, cause otherwise it would evolve adaptiv=\r\ne heuristics. That sounds right to me, but it would be very cool for us as =\r\na community to figure out exactly why there is a valley between static heur=\r\nistics and adaptive ones...and why evolution tends to gravitate toward the =\r\nstatic instead of the adaptive peaks. That&#39;s not an easy challenge, but it =\r\nis probably a worthwhile one. It&#39;s almost like the science is currently at =\r\nthe point of having an observation of a phenomenon without an understanding=\r\n as to why the phenomena occurs. It&#39;ll be hard to solve the problem unless =\r\nwe understand it. \n&gt; \n&gt; If any of you out there have any ideas, it would be=\r\n cool to hear hypotheses. \n&gt; \n&gt; PS. Apologies for the delayed response (to =\r\nthis, and to your other email about the novelty search paper). I am traveli=\r\nng at the moment and can only get on for brief spurts. I look forward to pr=\r\noperly responding at or after the CEC. \n&gt; \n&gt; -jeff \n&gt; --- In neat@yahoogrou=\r\nps.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Jeff, I see where you&#39;=\r\nre coming from.  First, I am not necessarily saying there is only one valle=\r\ny between these strategies.  There could be many valleys, or there could be=\r\n a long neutral plateau.\n&gt; &gt; \n&gt; &gt; But still the question is the same- why s=\r\nhould there be one or more valleys or a plateau?\n&gt; &gt; \n&gt; &gt; A general way to =\r\nlook at this question is just the see that the word &quot;harder&quot; generally mean=\r\ns there is at least one valley or plateau when you are talking about a sear=\r\nch problem.  After all, what else would make the problem &quot;hard?&quot;  If here i=\r\ns just a straight shot up a hill then the problem is easy.  \n&gt; &gt; \n&gt; &gt; The o=\r\nther aspect of hardness is dimensionality.  But both novelty-based and obje=\r\nctive-based NEAT approach high-dimensionality the same way, i.e. through co=\r\nmplexification, so that is controlled in the experiment.\n&gt; &gt; \n&gt; &gt; So if ada=\r\nptive problems get stuck, it is likely because of a valley or plateau.  The=\r\n plateau idea makes sense especially in the context of this type of problem=\r\n because the fitness function does not recognize differences in behavior th=\r\nat actually matter although they appear equally useless.  Such fitness equi=\r\nvalence between very different behaviors is shown in the paper in one examp=\r\nle in figure 5.\n&gt; &gt; \n&gt; &gt; More specifically to adaptation, and this is proba=\r\nbly more what you are looking for, you really have to get into the experien=\r\nce of evolving adaptive neural networks to realize how terribly deceiving t=\r\nhey are.  I think most people who have worked in this area (and there aren&#39;=\r\nt that many) would agree from experience that it is an incredibly frustrati=\r\nng area of research because of evolution&#39;s tendency to find non-adaptive so=\r\nlutions (I realize your ECAL paper is related to this experience as well). =\r\n In fact, my guess is that this reason explains why so few people are in th=\r\nis area (i.e. evolving adaptive ANNs).  Otherwise, the area is fascinating.=\r\n  But when you start trying to evolve adaptive networks, you face the endle=\r\nss frustration of trying to force it to actually use the adaptive capabilit=\r\nies.  It becomes intuitively apparent that whatever path there is towards a=\r\ndaptive behavior must cross some behaviors that appear entirely useless to =\r\nthe ultimate goal.  However, this kind of argument will probably not appear=\r\n in a paper because it is anecdotal.  But I still believe it, and others wh=\r\no research adaptive ANNs have said similar things.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; \n&gt;=\r\n &gt; \n&gt; &gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; Hello Ken-\n&gt; &gt; &gt; \n&gt; &gt; &gt; Thanks for the thought-provoking response. I&#39;d li=\r\nke to think about your\n&gt; &gt; &gt; answers a bit before responding.\n&gt; &gt; &gt; \n&gt; &gt; &gt; =\r\nHowever, if you have a second, I would be interested to hear your thoughts\n=\r\n&gt; &gt; &gt; on what I originally intended to be my main question, which is this:\n=\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt;&gt; The paper seems to further suggest that the reason many of =\r\nthese problems\n&gt; &gt; &gt; &gt;&gt; are deceptive is because (a) it is easier to learn =\r\na fixed-heuristic, and\n&gt; &gt; &gt; &gt;&gt; then (b) there is a fitness valley between =\r\nthat fixed-heuristic and the\n&gt; &gt; &gt; &gt;&gt; adaptive strategy.\n&gt; &gt; &gt; &gt;&gt; \n&gt; &gt; &gt; &gt;&gt;=\r\n I agree with (a) (in most cases), but why assume (b)?\n&gt; &gt; &gt; \n&gt; &gt; &gt; Much of=\r\n analysis in the paper hinges on the fact that there is actually a\n&gt; &gt; &gt; fi=\r\ntness valley between a fixed-heuristic and learning. But do we know that\n&gt; =\r\n&gt; &gt; is the case for your experiment? Is it usually the case? Why?\n&gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; For me, questions on this front are really intriguing and, before your\n=\r\n&gt; &gt; &gt; paper, I had not spent much time thinking about them. An understandin=\r\ng of\n&gt; &gt; &gt; them might really help our field better evolve adaptive agents.\n=\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; Jeff\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}