{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"qvieKdLOc--6Hctg1jFWqnqH3aavvENDNsvTvazY_4oVbanhk52FaYDni8Gt3TZeBtoFmghob0nS5sGtWws_VOT475o60_ezSi8","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Faster evolution for IEX","postDate":"1095343980","msgId":1535,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMS4yLjAuMC4yMDA0MDkxNjExNDEzMC4wMjRlZmRhMEBwb3AubWFpbC55YWhvby5jby51az4=","inReplyToHeader":"PDUxN2ZhNmYxMDQwOTE1MTMzODM3NGVlNjliQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDUxN2ZhNmYxMDQwOTE1MDc1ODZlMzgzOTRkQG1haWwuZ21haWwuY29tPiA8Ni4xLjIuMC4wLjIwMDQwOTE1MTY0NDUxLjAyNTMzMmIwQHBvcC5tYWlsLnlhaG9vLmNvLnVrPiA8NTE3ZmE2ZjEwNDA5MTUxMzM4Mzc0ZWU2OWJAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":1534,"nextInTopic":0,"prevInTime":1534,"nextInTime":1536,"topicId":1532,"numMessagesInTopic":4,"msgSnippet":"... I knew it was greyscale, but the way you phrased it, it sounded like B&W (e.g. exactly two pixel values, 0 and 1). I guess what I really meant was: what","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 32155 invoked from network); 16 Sep 2004 14:12:05 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m21.grp.scd.yahoo.com with QMQP; 16 Sep 2004 14:12:05 -0000\r\nReceived: from unknown (HELO smtp001.mail.ukl.yahoo.com) (217.12.11.32)\n  by mta5.grp.scd.yahoo.com with SMTP; 16 Sep 2004 14:12:04 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp001.mail.ukl.yahoo.com with SMTP; 16 Sep 2004 14:11:03 -0000\r\nMessage-Id: &lt;6.1.2.0.0.20040916114130.024efda0@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.1.2.0\r\nDate: Thu, 16 Sep 2004 15:13:00 +0100\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;517fa6f10409151338374ee69b@...&gt;\r\nReferences: &lt;517fa6f104091507586e38394d@...&gt;\n &lt;6.1.2.0.0.20040915164451.025332b0@...&gt;\n &lt;517fa6f10409151338374ee69b@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Remote-IP: 217.12.11.32\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] Faster evolution for IEX\r\nX-Yahoo-Group-Post: member; u=7192225\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nAt 21:38 15/09/2004, you wrote:\n&gt;On Wed, 15 Sep 2004 16:48:27 +0100, Ian Badcoe &lt;ian_badcoe@...&gt; wrote:\n&gt; &gt;\n&gt; &gt; At 15:58 15/09/2004, you wrote:\n&gt; &gt;\n&gt; &gt; &gt;All right, here&#39;s some thoughts.  Anybody have any feedback?\n&gt; &gt; &gt;\n&gt; &gt; &gt;First, I can settle for a fixed-enlargement scale.  I didn&#39;t want to,\n&gt; &gt; &gt;but I really want a better enlargement method, even if it isn&#39;t able\n&gt; &gt; &gt;to do arbitrary scale.  Now, having fixed-position outputs, the\n&gt; &gt; &gt;problem is reduced to a classification problem.  &quot;Should this pixel be\n&gt; &gt; &gt;above or below the center?&quot;  Easily solved, except for the BILLIONS of\n&gt; &gt; &gt;training samples...\n&gt; &gt;\n&gt; &gt; I can&#39;t work out what you meant by &quot;above or below the center&quot;?  Surely\n&gt; &gt; it&#39;s not classification, it&#39;s function fitting?  Unless it&#39;s in black and\n&gt; &gt; white?\n&gt;\n&gt;Sorry...yes, it&#39;s black and white.  Repeat the enlargement process\n&gt;once for each color channel then merge to enlarge color photos.\n\nI knew it was greyscale, but the way you phrased it, it sounded like B&W \n(e.g. exactly two pixel values, 0 and 1).\n\nI guess what I really meant was: what does &quot;above or below the center&quot; mean?\n\n&gt; &gt; &gt;Second, to get an idea of how many hidden nodes I will need, I can\n&gt; &gt; &gt;evolve for the normal input nodes, but with only one output node.\n&gt; &gt; &gt;However many hidden nodes it takes for one, that&#39;s how many I start\n&gt; &gt; &gt;with for trying to evolve the final solution.\n&gt; &gt;\n&gt; &gt; I think you need to give a brief summary of what experiment you&#39;re\n&gt; &gt; imagining now, because I cannot follow you.  Surely there&#39;s only ever one\n&gt; &gt; output node (because you run the network once for each pixel you are asking\n&gt; &gt; about...)\n&gt;\n&gt;Not if I go with a fixed enlargement scale.\n&gt;\n&gt;Suppose I&#39;m doing a 4x enlargement.  For every pixel in the input\n&gt;image, I need to know the 4x4 or 16 pixels that make up that position\n&gt;in the output image.  If I activate the network once per input pixel,\n&gt;I have 16 output nodes in the network.  Of course, I will have to look\n&gt;at more than the pixel I&#39;m trying to enlarge, I&#39;ll have to look at the\n&gt;surrounding pixels to get an idea of how to generate those 16 pixels.\n\nTrue, but there are further considerations.  e.g. if this is your grid of \noutput pixels:\n\n0123\n4567\n89AB\nCDEF\n\nThen is there any argument that (for example) 3 is a different case than 0?\n\nIf you expect the network to work on mirrored images, then it cannot \nbe.  Similarly 0 and C, 4 and 8 etc etc.\n\nIn fact, you only have three cases here:\n\n0, 3, C and F                   Corner\n1, 2, 7, B, E, D, 8 and 4       Edge\n5, 6, 9 and A                   Centre\n\nThus it would be a waste of evolution to try and evolve a single network \nwith 4 copies of the corner sub-net, 8 copies of the edge sub-net and 4 \ncopies of the centre sub-net.\n\nIt makes more sense to evolve three different networks (corner, edge and \ncentre) and apply them several times (mirrored and rotated) to cover the \nwhole output region.  It also makes the problems smaller and so faster \nevolving.\n\nThe downside is that if corner needs a same &quot;subroutine&quot; as edge, then they \nhave to evolve it separately.  But that&#39;s modularity and I think the \nconsensus is that we don&#39;t really know how to do that anyway.  For example, \nif just corner needed two copies of the &quot;subroutine&quot;, then we don&#39;t have a \nway to even do that, let alone share it with a different network.\n\n[[Of course, there&#39;s also symmetry in the input data, e.g. if this is the \ninput region:\n\nPQR\nSTU\nVWX\n\n(where the whole output region lies under T).\n\nThe relationships between input S and output 1 and between input Q and \noutput 1 are exactly the same.  So is there any justification for the \nnetwork _ever_ treating S and Q in an asymmetric manner?  I would say not.\n\nHowever, symmetry is a difficult thing to enforce, or even define.  It does \nnot mean anything as crude as anything connected to S must also connect \nQ.  For example, a whole sub-net can take Q as an input without reference \nto S, as long as there is another sub-net doing the same with S and their \nresults are merged sometime before the output.  Similarly a sub-net could \ntake S with positive weight and Q with negative weight as long as another \ndid the reverse...\n\nOne way to enforce this is via some sort of indirect encoding (which nobody \ninvented yet...)\n\nI also tried, while writing this, to come up with another lazy-man&#39;s \napproach based on &quot;symmetrifying&quot; the network before running it, but it&#39;s \nmore complex than I imagined and I may start a new thread to discuss it.\n\nI do feel quite strongly that constraints like this are critical because \nthey hugely reduce the size of the search space.\n\nIn this case I&#39;m suggesting building them into the (human created) \ndefinition of the problem, but one of the points of a modular system would \nbe that without artificially enforcing symmetry, a symmetric arrangement of \n(instances of) modules is far higher probability than evolving a whole \nnetwork to be symmetric, one weight at a time.\n\n&gt;Threre are variations I can do.  I can expand the output are to be 8x8\n\n&lt;snip&gt;\n\nNEAT already tends to keep the number of nodes down, and your arguments \nabout sample size seem valid, so I wouldn&#39;t worry about the number of nodes \ngetting out of hand until it does.\n\nSOMs arrange themselves to detect &quot;features&quot; but:\n(i) in this case what are the features\n(ii) the position in the SOM where a given &quot;feature&quot; appears is random \n(needing a human to label it)\n(iii) they detect &quot;features&quot; as a sum over the whole training set but in \nthis case would the set actually contain &quot;features&quot; or do the samples form \na continuum\n(iv) an SOM would not necessarily classify a feature and it&#39;s rotations as \nthe same thing\n\n         Ian\n\n\n\n\nLiving@Home - Open Source Evolving Organisms - \nhttp://livingathome.sourceforge.net/\n\n\n\n\n"}}