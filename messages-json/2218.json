{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":204774783,"authorName":"Matt Simmerson","from":"&quot;Matt Simmerson&quot; &lt;m.simmerson@...&gt;","profile":"easablade","replyTo":"LIST","senderId":"PxLEFLcyF1sFDuhr28jlj0PpVcuNKhrO-LhORVncEDmzd-4r3nOBBsSvKgKbWCvW1L9aIgf1abgGHMh-sFwXumwHEtMuLI1bb3OPnBdcWKe4p1E1iQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Introduction---recurrency question","postDate":"1124958505","msgId":2218,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRlanZmOSszNDNiQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDUxN2ZhNmYxMDUwODI0MTMxNjRlMzI3OTlmQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":2215,"nextInTopic":2221,"prevInTime":2217,"nextInTime":2219,"topicId":2209,"numMessagesInTopic":42,"msgSnippet":"This is exactly the way I have implemented it in my version.  Each neuron stores its last output (X) such that any recurrent connections to it will receive","rawEmail":"Return-Path: &lt;m.simmerson@...&gt;\r\nX-Sender: m.simmerson@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 47352 invoked from network); 25 Aug 2005 08:29:23 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m13.grp.scd.yahoo.com with QMQP; 25 Aug 2005 08:29:23 -0000\r\nReceived: from unknown (HELO n2a.bulk.scd.yahoo.com) (66.94.237.36)\n  by mta2.grp.scd.yahoo.com with SMTP; 25 Aug 2005 08:29:23 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.69.2] by n2.bulk.scd.yahoo.com with NNFMP; 25 Aug 2005 08:28:27 -0000\r\nReceived: from [66.218.66.91] by mailer2.bulk.scd.yahoo.com with NNFMP; 25 Aug 2005 08:28:27 -0000\r\nDate: Thu, 25 Aug 2005 08:28:25 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;dejvf9+343b@...&gt;\r\nIn-Reply-To: &lt;517fa6f105082413164e32799f@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Length: 9925\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Matt Simmerson&quot; &lt;m.simmerson@...&gt;\r\nSubject: Re: Introduction---recurrency question\r\nX-Yahoo-Group-Post: member; u=204774783; y=IJ4gadtQhDC163lQi67fcDSsSA3X-t1cG-4KCfed0qje01vnRpU9339KiH7XLQvnRLQRpPrQ\r\nX-Yahoo-Profile: easablade\r\n\r\nThis is exactly the way I have implemented it in my version.  Each\nneuron s=\r\ntores its last output (X) such that any recurrent connections\nto it will re=\r\nceive that rather than fire the neuron again.  Initially,\nX will always be =\r\n0.\n\nI have been thinking about implementing time delay signals (as in ANJI\n=\r\n2) so that I can evolve various delays for recurrency.\n\n--- In neat@yahoogr=\r\noups.com, John Arrowwood &lt;jarrowwx@g...&gt; wrote:\n&gt; I wanted to throw out the=\r\n other alternative that I myself implemented.  \n&gt; \n&gt; Based on what Ken desc=\r\nribed, a 5 layer network will require being\n&gt; activated in 5 discreet time =\r\nsteps.  But if there is no recurrency,\n&gt; then it should be possible to acti=\r\nvate it in ONE time step by just\n&gt; activating each of the nodes in the prop=\r\ner order.  That&#39;s what I did. \n&gt; For a given topology, I do a dependency an=\r\nalysis.  From that, I figure\n&gt; out what the proper order should be in order=\r\n to activate individual\n&gt; nodes.  If I activate the nodes in that order, th=\r\nen the inputs will\n&gt; reach the outputs in a single activation of the networ=\r\nk.  This, in\n&gt; turn, reduces the number of calculations required for an act=\r\nivation.\n&gt; \n&gt; For recurrent networks, you can do it in much the same way.  =\r\nHowever,\n&gt; if node A has an input coming from node B, but node B hasn&#39;t bee=\r\nn\n&gt; calculated, you use an assumed output of 0 for node B.  On the next\n&gt; a=\r\nctivation of the network, node B *has* been calculated.  Let&#39;s say\n&gt; it&#39;s o=\r\nutput was X.  So A will use X as the value of the input from B.\n&gt; \n&gt; Mind y=\r\nou, if you use this technique, you will save a great deal on CPU\n&gt; resource=\r\ns, since you don&#39;t have to do nearly as many calculations. \n&gt; However, you =\r\ncan&#39;t (necessarily) mix the paradigms.  You can&#39;t develop\n&gt; a topology usin=\r\ng Ken&#39;s activation technique and expect it to perform\n&gt; identically using m=\r\nine, and vice versa.  It might, but it might not! \n&gt; So whatever you decide=\r\n on, stick with it.\n&gt; \n&gt; Realistically, how you do it isn&#39;t that important.=\r\n  The network will\n&gt; learn (or evolve) to solve the problem using whatever =\r\nmethod you\n&gt; decide upon.  The only advantage of one method over another is=\r\n in how\n&gt; much computational resources are required either during testing o=\r\nr in\n&gt; final implementation.  My NEAT was written in Perl, which is an\n&gt; in=\r\nterpreted language, and so could benefit from as much accelleration\n&gt; as I =\r\ncould find.  That&#39;s why I opted for the less computationally\n&gt; intensive ac=\r\ntivation method.  If you don&#39;t care about CPU resources\n&gt; during the firing=\r\n of the network, then go with whatever is easiest for\n&gt; you to code.  :)\n&gt; =\r\n\n&gt; -- John\n&gt; \n&gt; On 8/24/05, Kenneth Stanley &lt;kstanley@c...&gt; wrote:\n&gt; &gt; Kevi=\r\nn,\n&gt; &gt; \n&gt; &gt; Let me add to Charles comments a bit...although Charles does a =\r\ngood\n&gt; &gt; job giving some background, I believe there are some things Charle=\r\ns\n&gt; &gt; didn&#39;t mention you should be aware of.\n&gt; &gt; \n&gt; &gt; First, see the questi=\r\non, &quot;How are networks with arbitrary topologies\n&gt; &gt; activated?&quot; in the NEAT=\r\n FAQ located at:\n&gt; &gt; \n&gt; &gt; http://www.cs.utexas.edu/users/kstanley/neat.html=\r\n\n&gt; &gt; \n&gt; &gt; That question gives some background on your own question.\n&gt; &gt; \n&gt; =\r\n&gt; The short answer is that every node is activated on every timestep\n&gt; &gt; fr=\r\nom ALL incoming connections.  Any node that has not yet received\n&gt; &gt; input =\r\nit assumed to be outputting a zero.  In other words, time\n&gt; &gt; delay does no=\r\nt enter into it at all (I have never actually used the\n&gt; &gt; time-delay code)=\r\n.  Also, activation does not travel all the way from\n&gt; &gt; inputs to outputs =\r\nin a single timestep unless there is a direct\n&gt; &gt; connection from inputs to=\r\n outputs.  But activation traveling over\n&gt; &gt; intervening nodes will take ex=\r\ntra time to get there.\n&gt; &gt; \n&gt; &gt; So what happens is that a node that connect=\r\ns to itself receives the\n&gt; &gt; activation that itself output on the *previous=\r\n* timestep.  Networks\n&gt; &gt; are activated over a series of timesteps.\n&gt; &gt; \n&gt; =\r\n&gt; It is important to note that you should *not* be relaxing a network\n&gt; &gt; d=\r\nuring a control task like food gathering.  Charles mentions\n&gt; &gt; relaxation =\r\nbut that is only appropriate for classification tasks\n&gt; &gt; where the network=\r\n is trying to decide on a final answer.  See the\n&gt; &gt; question, &quot;How do I en=\r\nsure that a network stabilizes before taking\n&gt; &gt; its output(s) for a classi=\r\nfication problem?&quot; in the NEAT FAQ for\n&gt; &gt; more info on this.\n&gt; &gt; \n&gt; &gt; In a=\r\n continual control task like food gathering (or most tasks NEAT\n&gt; &gt; is used=\r\n for) there is always new input coming in and new output\n&gt; &gt; coming out, so=\r\n the network will never relax, since there is\n&gt; &gt; no &quot;final&quot; answer.  The o=\r\nnly question that comes up is how many\n&gt; &gt; times (steps) to activate the ne=\r\ntwork per world tick.  Almost any\n&gt; &gt; experiment I&#39;ve heard of activates on=\r\nce per tick, but it is possible\n&gt; &gt; to imagine activating &gt;1 time per tick,=\r\n which is equivalent to\n&gt; &gt; speeding up the rate of thought.   However, not=\r\ne that more\n&gt; &gt; activations also means more CPU time per world tick.\n&gt; &gt; \n&gt;=\r\n &gt; I hope this help; feel free to ask any other questions.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt;=\r\n \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, Charles Tarun &lt;ctarun@g..=\r\n.&gt; wrote:\n&gt; &gt; &gt; Hello Maitrikaruna,\n&gt; &gt; &gt; I would like to offer any help I =\r\ncan, and I&#39;m sure others will\n&gt; &gt; also help,\n&gt; &gt; &gt;\n&gt; &gt; &gt; I also don&#39;t have =\r\nany training on NN either, but I&#39;ve been read a\n&gt; &gt; lot about\n&gt; &gt; &gt; them. E=\r\nach implementation of NEAT handles the firing of the node\n&gt; &gt; in their\n&gt; &gt; =\r\n&gt; own way, as NEAT doesn&#39;t define it exactly. My method of choice is\n&gt; &gt; on=\r\ne of\n&gt; &gt; &gt; the SharpNEAT ones, &quot;FastConcurrentNetwork&quot;. This network\n&gt; &gt; si=\r\nmulates each\n&gt; &gt; &gt; neuron activating concurrently.\n&gt; &gt; &gt;\n&gt; &gt; &gt; 1) Assign th=\r\ne values to all input nodes\n&gt; &gt; &gt; 2) Activate the network\n&gt; &gt; &gt; 3) Relax th=\r\ne network\n&gt; &gt; &gt; 4) Read the outputs\n&gt; &gt; &gt;\n&gt; &gt; &gt; Activate network is pass a =\r\nparameter of how many times to run for,\n&gt; &gt; this is\n&gt; &gt; &gt; basically how man=\r\ny steps to run for. Each step uses the signal\n&gt; &gt; strength from\n&gt; &gt; &gt; the p=\r\nrevious.\n&gt; &gt; &gt;\n&gt; &gt; &gt; The Relax network function is very much like the Activ=\r\nate\n&gt; &gt; function, but also\n&gt; &gt; &gt; take in a maxAllowedSignalDelta. It runs u=\r\nntil the signal change\n&gt; &gt; for each\n&gt; &gt; &gt; node is &lt;maxAllowedSignalDelta or=\r\n the maxSteps count is reached.\n&gt; &gt; &gt;\n&gt; &gt; &gt; |-------\n&gt; &gt; &gt; v |\n&gt; &gt; &gt; NODE1-=\r\n-&gt;NODE2--&gt;NODE3\n&gt; &gt; &gt;\n&gt; &gt; &gt; They way I see this working with your diagram i=\r\ns(assuming the\n&gt; &gt; links had\n&gt; &gt; &gt; enough weight to cause the next to fire)=\r\n:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Step 1:\n&gt; &gt; &gt; Node1(input) is firing.\n&gt; &gt; &gt; node2 get enough =\r\nsignal to fire at this time stamp\n&gt; &gt; &gt; node3 only getting signal from the =\r\nprevious step when node2 wasn&#39;t\n&gt; &gt; firing\n&gt; &gt; &gt; does not have enough signa=\r\nl to fire.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Step2:\n&gt; &gt; &gt; Node1(input) is firing.\n&gt; &gt; &gt; node2 get=\r\ns enough signal to fire from node1&#39;s last step, but is\n&gt; &gt; not getting\n&gt; &gt; =\r\n&gt; signal from node3.\n&gt; &gt; &gt; node3 gets enough signal to fire from node2&#39;s la=\r\nst step and fires\n&gt; &gt; &gt;\n&gt; &gt; &gt; step3:\n&gt; &gt; &gt; Node1(input) is firing(As always=\r\n, input nodes don&#39;t change)\n&gt; &gt; &gt; node2 is getting signal from node1 and no=\r\nde3 now\n&gt; &gt; &gt; node3 is getting signal from node2 last time step, the recurr=\r\nent\n&gt; &gt; connection\n&gt; &gt; &gt; hasn&#39;t effected the signal from 2 to 3 yet.\n&gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; Under such a system it is possible to get oscillation in the\n&gt; &gt; sign=\r\nals, that&#39;s\n&gt; &gt; &gt; why there is a maxSteps on the relax function. The creato=\r\nr of\n&gt; &gt; SharpNEAT is\n&gt; &gt; &gt; part of this list as well(Colin D. Green). I ho=\r\npe this will be\n&gt; &gt; helpful.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Chuck Tarun\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; On 8/24/05, maitrikaruna &lt;kevin@t...&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hello =\r\nall,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I stumbled on NEAT just a short week ago and have foun=\r\nd it very\n&gt; &gt; &gt; &gt; interesting. I spent the last few days implementing NEAT =\r\nin\n&gt; &gt; &gt; &gt; PowerBASIC and I&#39;m nearly done. I am doing a rather simple\n&gt; &gt; &gt;=\r\n &gt; simulation.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I basically set up a &quot;room&quot; and drop an agen=\r\nt in the middle.\n&gt; &gt; &gt; &gt; The\n&gt; &gt; &gt; &gt; agent needs to eat=85so I place a larg=\r\ne circle representing\n&gt; &gt; food in\n&gt; &gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; room. The agent has s=\r\no many steps to find the food or it\n&gt; &gt; &gt; &gt; disappears. The food is then mo=\r\nved to a new location and the\n&gt; &gt; agent\n&gt; &gt; &gt; &gt; can try again. The agent is=\r\n tested against four different food\n&gt; &gt; &gt; &gt; locations. The agent has 8 sens=\r\nors that allow it to &quot;see&quot; in\n&gt; &gt; &gt; &gt; those 8\n&gt; &gt; &gt; &gt; directions.\n&gt; &gt; &gt; &gt;\n&gt;=\r\n &gt; &gt; &gt; Right now with only 50 parents and 10 generations it is able to\n&gt; &gt; =\r\nfind\n&gt; &gt; &gt; &gt; all the 4 different food bins after about9 or 10 gens...which =\r\nis\n&gt; &gt; &gt; &gt; pretty good.. Especially since I discovered that I have a neuron=\r\n\n&gt; &gt; &gt; &gt; firing issue in my code..\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Anyway..I am completely =\r\nnew to NN&#39;s...i have no training on them\n&gt; &gt; at\n&gt; &gt; &gt; &gt; all, although I do =\r\nknow GA&#39;s fairly well (I am CEO of\n&gt; &gt; bioinformatics\n&gt; &gt; &gt; &gt; firm that use=\r\ns GA&#39;s to analyze genetics data).\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I have a question I hope =\r\nyou can help with. the way I setup the\n&gt; &gt; &gt; &gt; networks allows for recurren=\r\nt connections to occur. So suppose\n&gt; &gt; you\n&gt; &gt; &gt; &gt; have a simple netowrk wh=\r\nere input node 1 connects to hidden node\n&gt; &gt; 2,\n&gt; &gt; &gt; &gt; which connects to h=\r\nidden node 3, which connects to back to node\n&gt; &gt; 2.\n&gt; &gt; &gt; &gt; How is firing t=\r\no proceed in such a scenario? Node 2 can&#39;t fire\n&gt; &gt; &gt; &gt; until it has all it=\r\ns inputs, yet one of its outputs(the one to\n&gt; &gt; node\n&gt; &gt; &gt; &gt; 3) affects wha=\r\nt its input will be. Thanks for your help...\n&gt; &gt; &gt; &gt; |-------\n&gt; &gt; &gt; &gt; v |\n&gt;=\r\n &gt; &gt; &gt; NODE1--&gt;NODE2--&gt;NODE3\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; And what if a node links back =\r\nto itself? Then how is the firing\n&gt; &gt; &gt; &gt; sequence to work? I saw a time de=\r\nlay in teh C code and I am\n&gt; &gt; &gt; &gt; guessing this is involved, but I&#39;m not q=\r\nuite sure how...\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; When I get this working, I would like to t=\r\nackle the tic-tac-toe\n&gt; &gt; &gt; &gt; problem you guys are working on.\n&gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; i really appreciate all your posts...very enlightening...\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n &gt; Best,\n&gt; &gt; &gt; &gt; Kevin Cramer\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n &gt;\n&gt; &gt; &gt; &gt; Yahoo! Groups Links\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Yahoo! Groups Links\n&gt; &gt; \n&gt; &gt; =\r\n\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt;\n\n\n\n"}}