{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"xIkYjh_zEpR3a4ij48HIijnxLSBqUjd8WZQCo-LAct_R4gMWnlg7sDI0ylgAZbCrJAT9ANtwqKG1nZH0_0U5bEgfmLLXg4lvHfqOOfdUmPv8","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: New Paper on Novelty Search and Adaptive Neural Networks","postDate":"1241074237","msgId":4649,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGd0YmhudCthMmpjQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM2MUI1NjdELjJBNzU3JWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4645,"nextInTopic":4652,"prevInTime":4648,"nextInTime":4650,"topicId":4619,"numMessagesInTopic":8,"msgSnippet":"Jeff, those are some good (and hard) questions, let me try to give my best answers... ... Sure, it s usually wrong to believe that anything is always true 100%","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 65624 invoked from network); 30 Apr 2009 06:50:54 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m8.grp.re1.yahoo.com with QMQP; 30 Apr 2009 06:50:54 -0000\r\nX-Received: from unknown (HELO n35b.bullet.mail.sp1.yahoo.com) (66.163.168.149)\n  by mta2.grp.sp2.yahoo.com with SMTP; 30 Apr 2009 06:50:54 -0000\r\nX-Received: from [69.147.65.171] by n35.bullet.mail.sp1.yahoo.com with NNFMP; 30 Apr 2009 06:50:37 -0000\r\nX-Received: from [98.137.34.32] by t13.bullet.mail.sp1.yahoo.com with NNFMP; 30 Apr 2009 06:50:37 -0000\r\nDate: Thu, 30 Apr 2009 06:50:37 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gtbhnt+a2jc@...&gt;\r\nIn-Reply-To: &lt;C61B567D.2A757%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New Paper on Novelty Search and Adaptive Neural Networks\r\nX-Yahoo-Group-Post: member; u=54567749; y=nTKZEwxaiT-kmR9nvNu1w87V_bWYrRvXz8fwLr2DHTcVXqvTnIOy\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, those are some good (and hard) questions, let me try to give my best =\r\nanswers...\n\n--- In neat@yahoogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt;=\r\n Hello all-\n&gt; \n&gt; Congrats on the best paper nomination, and thanks for post=\r\ning this very\n&gt; interesting work. My favorite thing about it was said in th=\r\ne conclusion,\n&gt; which is that novelty search offers a new tool in the toolb=\r\nox that one can\n&gt; try when encountering a difficult problem. As I have said=\r\n previously, I\n&gt; think there are situations in which novelty search will no=\r\nt work very well\n&gt; (have you guys run into any yet?), but this paper demons=\r\ntrates that there\n&gt; are problems in which it works quite well, and even bet=\r\nter than fitness\n&gt; based search.\n&gt; \n&gt; A few questions/comments;\n&gt; \n&gt; I get =\r\nthe impression that the paper suggests that problems that require\n&gt; adaptiv=\r\ne-heuristics are *always* deceptive. Is that right? This line in\n&gt; particul=\r\nar triggers this comment: &quot;This paper argues that domains that\n&gt; require ad=\r\naptation are inherently deceptive.&quot;\n&gt; \n&gt; I certainly agree that some such p=\r\nroblems are deceptive, and could be\n&gt; persuaded that many are, but doesn&#39;t =\r\nit seem too strong to say that all are?\n&gt; \n\nSure, it&#39;s usually wrong to bel=\r\nieve that anything is always true 100% of the time.  But I think qualifying=\r\n every general statement one can make with that caveat unnecessarily waters=\r\n down otherwise provocative ideas.  It&#39;s just a general statement, which me=\r\nans it&#39;s a general characterization of that class of problems.  Exceptions,=\r\n while possible,  are unusual or unlikely.\n\n&gt; The paper seems to further su=\r\nggest that the reason many of these problems\n&gt; are deceptive is because (a)=\r\n it is easier to learn a fixed-heuristic, and\n&gt; then (b) there is a fitness=\r\n valley between that fixed-heuristic and the\n&gt; adaptive strategy. \n&gt; \n&gt; I a=\r\ngree with (a) (in most cases), but why assume (b)?\n&gt; \n&gt; In practice, I have=\r\n seen that evolution does seem to really want to find a\n&gt; fixed-heuristic i=\r\nnstead of developing phenotypic plasticity. I actually have\n&gt; an ECAL paper=\r\n about this wherein I describe how digital organisms in a\n&gt; cycling two-sea=\r\nson environment that required them to behave differently in\n&gt; each season f=\r\nigured out a way to run the exact same code, but have that code\n&gt; still wor=\r\nk perfectly in the two different seasons. Once I tweaked the\n&gt; environment =\r\na bit, though, they switched over to learning the adaptive\n&gt; strategy.  \n&gt; =\r\n\n&gt; So, I do agree that in many situations evolution learns a fixed strategy=\r\n and\n&gt; then cannot find the adaptive one. Part of the reason I ask my quest=\r\nion is\n&gt; because I am interested in *why* it is typically the case that it =\r\nis hard to\n&gt; go from a fixed heuristic that gets 50% of the reward to an ad=\r\naptive\n&gt; heuristic that gets 100% of the reward?  One reason you suggest in=\r\n the paper\n&gt; is that the adaptive strategy simply does not pay off that muc=\r\nh as a percent\n&gt; of overall fitness. But if that is the only problem, then =\r\nswitching to an\n&gt; exponential fitness function would solve it (which I am s=\r\nure many\n&gt; researchers have tried). My instincts tell me there is an additi=\r\nonal\n&gt; explanation. \n&gt; \n\nI&#39;m not sure why making the fitness function expon=\r\nential would help?  If you must cross a huge chasm to get to the other side=\r\n, how does it help if the other side is exponentially higher in the air?  T=\r\nhe chasm is still monstrous and will still prohibit you from crossing.  \n\nI=\r\n would also point out that while some kind of tinkering with the fitness fu=\r\nnction might increase performance, performance would *still* decrease with =\r\nincreasing deception.  It&#39;s just that the degradation curve would be pushed=\r\n up by a constant, or perhaps made less steep.  But it would still degrade,=\r\n like the 0,5, and 10 scenarios in the paper.  \n\nIn other words, each decep=\r\ntive scenario might perform better individually, but performance in the mor=\r\ne deceptive scenarios would still be worse than in those that are less dece=\r\nptive.\n\nThus the issue is not just to make it perform better overall but to=\r\n remove the effect of deception entirely.  That is what novelty search did =\r\nin this domain (it flattened the degradation curve), which I think is reall=\r\ny intriguing (more intriguing than just higher performance).  I suspect it =\r\nwill be quite difficult to do the same with a simple heuristic like making =\r\nthe fitness function exponential.  \n\n&gt; A final question. You write:&quot; novelt=\r\ny search removes the need to carefully\n&gt; design a domain that fosters the e=\r\nmergence of learning...the only\n&gt; prerequisite is that the novelty metric i=\r\ns constructed such that learning\n&gt; and non-learning agents are separable, w=\r\nhich is not easy, but is worth the\n&gt; effort if objective-based search would=\r\n otherwise fail.&quot;\n&gt; \n&gt; As you mention, you had to spend the time to design =\r\na domain (and novelty\n&gt; metric) that fosters the emergence of learning by d=\r\nelineating those that\n&gt; learn from those that don&#39;t. Couldn&#39;t it be argued =\r\nthat you might have\n&gt; success if you did the same thing for objective-based=\r\n search? For example,\n&gt; did you try any runs that gave a huge fitness boost=\r\n to organisms that\n&gt; successfully went the other way after they discovered =\r\nthat the high reward\n&gt; had moved? It seems like an equal amount of energy (=\r\nto that which you spent\n&gt; designing the novelty metric) should arguably be =\r\napplied to the\n&gt; fitness-based search to see if you can coax it into evolvi=\r\nng learners, no?\n&gt; \n\nThis question is interesting.  But I think it misses a=\r\n deeper issue.  There probably is a fitness function that performs better t=\r\nhan novelty search in any given domain.  But in deceptive domains, it&#39;s one=\r\n that defies all logic.  After all, think about what &quot;deceptive&quot; means.  It=\r\n means that a function that we believe maximizes the right right variables =\r\nactually does the opposite.  Therefore, by definition, a &quot;good&quot; fitness fun=\r\nction in such a domain is one that does not make sense to us.  It&#39;s somethi=\r\nng that rewards a behavior that seems to deserve to be penalized.  I do not=\r\n think it is a question of &quot;effort&quot; because we are talking about circuitous=\r\n paths through behavior space that are completely unintuitive.  Rather than=\r\n effort, what you need to devise such a fitness function is more akin to pr=\r\nofound insight (or profound luck).  Of course, in some cases you might actu=\r\nally have such a flash of insight and realize, for example, &quot;yeah you know =\r\nwhat, we need to reward the rat for falling into the hole and getting eaten=\r\n by the monster,&quot; even though it&#39;s exactly what we don&#39;t want to happen.  \n=\r\n\nBut most people won&#39;t have that insight, and besides, what kind of learnin=\r\ng algorithm requires something akin to genius on the part of the practition=\r\ner?  That seems to undermine the whole purpose of machine learning.  The th=\r\ning about novelty search is, you have to do work to characterize behavior, =\r\nbut you don&#39;t need to be especially insightful or smart.  You just need to =\r\nbe meticulous.  That is, you never need to really understand the structure =\r\nof the search space.  \n\nSo when we talk about effort, it&#39;s important to thi=\r\nnk about what kind of effort it is:  Does it mean somehow intuiting the con=\r\nnective structure of the search lattice itself from the weight vector of th=\r\ne genome, or does it mean simply breaking behavior down into characteristic=\r\n variables?   The latter is significantly more practical and reasonable to =\r\nexpect of a human being.\n\nken\n\n\n\n\n"}}