{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":8147458,"authorName":"Christian","from":"&quot;Christian&quot; &lt;Christian.Hofmann@...&gt;","profile":"chhofchhof","replyTo":"LIST","senderId":"y2XSXfleHIvLSFq2y5AAEQohKfeJBFaDlyDdhhI6f38duA_nZDPbV5WZRqN6sQPWTmLg7yWgM_dP_0CPrx0DPbKwd_Dd4u3AAEwFsp4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Questions regarding HyperSharpNeat and basic NEAT questions","postDate":"1217522527","msgId":4240,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGc2c3EwditiMHRpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGc2cW90bStkN3NmQGVHcm91cHMuY29tPg=="},"prevInTopic":4239,"nextInTopic":4241,"prevInTime":4239,"nextInTime":4241,"topicId":4238,"numMessagesInTopic":6,"msgSnippet":"Hello David, thank you for your very detailed and helpful answers! Using NN I have every time problems like choosing the right activation function(s) or the","rawEmail":"Return-Path: &lt;Christian.Hofmann@...&gt;\r\nX-Sender: Christian.Hofmann@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 22428 invoked from network); 31 Jul 2008 16:42:11 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m51.grp.scd.yahoo.com with QMQP; 31 Jul 2008 16:42:11 -0000\r\nX-Received: from unknown (HELO n29b.bullet.sp1.yahoo.com) (209.131.38.250)\n  by mta15.grp.scd.yahoo.com with SMTP; 31 Jul 2008 16:42:11 -0000\r\nX-Received: from [216.252.122.217] by n29.bullet.sp1.yahoo.com with NNFMP; 31 Jul 2008 16:42:11 -0000\r\nX-Received: from [66.218.69.5] by t2.bullet.sp1.yahoo.com with NNFMP; 31 Jul 2008 16:42:09 -0000\r\nX-Received: from [66.218.66.78] by t5.bullet.scd.yahoo.com with NNFMP; 31 Jul 2008 16:42:09 -0000\r\nDate: Thu, 31 Jul 2008 16:42:07 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g6sq0v+b0ti@...&gt;\r\nIn-Reply-To: &lt;g6qotm+d7sf@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Christian&quot; &lt;Christian.Hofmann@...&gt;\r\nSubject: Re: Questions regarding HyperSharpNeat and basic NEAT questions\r\nX-Yahoo-Group-Post: member; u=8147458; y=jqaqUCdICJmcL_aibZ-P42au8JT3QxpEOkgNnNQbpBpUKsVdfA\r\nX-Yahoo-Profile: chhofchhof\r\n\r\nHello David,\n\nthank you for your very detailed and helpful answers!\n\nUsing =\r\nNN I have every time problems like choosing the right activation\nfunction(s=\r\n) or the correct hidden layer design. That&#39;s something I\nwanted to avoid us=\r\ning Neat/HyperNeat. It is not possible for me to\ndefine a substrate for my =\r\ndomain, but I want to profit from the\nmulti-threading approach and the CPPN=\r\n feature. \n\nSo using HyperSharpNeat with the standard substrate method, it =\r\nwould\nbe possible to get networks with different activation functions in on=\r\ne\nNN and with the ability of using multiple CPUs?\n\nMy thoughts are that if =\r\nI am choosing the wrong activation functions\nor wrong input/output values, =\r\nNeat will compensate this by using\ndifferent activation functions or an add=\r\nitional hidden layer to\ntransform the input/output value to the correct / b=\r\netter values. \n\nEven every geometric layout should get be designed by a nor=\r\nmal CPPN\nnetwork. It will use be more neurons, but at the end of the day ev=\r\nery\nsubstrate / geometric layout should be expressed by additional neurons.=\r\n\n\nKind regards,\n\nChristian\n\n\n--- In neat@yahoogroups.com, &quot;David D&#39;Ambrosio=\r\n&quot; &lt;ddambro84@...&gt; wrote:\n&gt;\n&gt; Hi Christian,\n&gt; \n&gt; I&#39;m the one who converted S=\r\nharpNEAT to HyperSharpNEAT so hopefully\n&gt; I&#39;ll be able to shed some light o=\r\nn the issues you&#39;re facing.  I would\n&gt; like to point out that your first qu=\r\nestion makes it seem like you may\n&gt; not be interested in HyperNEAT, but ins=\r\ntead CPPNs.  CPPNs are\n&gt; essentially neural networks with different activat=\r\nion functions in the\n&gt; nodes.  HyperNEAT uses CPPNs to create patterns of c=\r\nonnections in\n&gt; traditional neural networks (i.e. only one activation funct=\r\nion) that\n&gt; are laid out on a substrate to create geometric relationships b=\r\netween\n&gt; the nodes.  The answers I give are still relevant either way, but\n=\r\n&gt; that&#39;s something to think about.\n&gt; \n&gt; 1.  The experiment stuff is mostly =\r\nderived from Colin&#39;s SharpNEAT\n&gt; (http://sharpneat.sourceforge.net/), and i=\r\nf you&#39;d like information\n&gt; about that, it might be better to look at his do=\r\ncumentation as it is\n&gt; MUCH better than mine, of course I&#39;ll try and answer=\r\n any questions you\n&gt; have.  With that said, you do have the basic idea: eac=\r\nh experiment\n&gt; needs an experiment, a network evaluator and a population ev=\r\naluator. \n&gt; The basic substrate should work, but only for the simplest of\n&gt;=\r\n situations, you should inherit it and override the generateGenome\n&gt; functi=\r\non to represent your substrate.  Of course, if you are only\n&gt; interested in=\r\n evolving CPPNs, you can completely ignore the substrate\n&gt; class as well as=\r\n the the related parameters in the params.txt file,\n&gt; and the algorithm wil=\r\nl produce just CPPNs.\n&gt; \n&gt; 2.  The reason that MultipleSteps takes a variab=\r\nle number is because\n&gt; NEAT evolves networks of varying topologies which ca=\r\nn include\n&gt; recurrent connections, making it impossible to determine the &quot;c=\r\norrect&quot;\n&gt; number of times to activate the network.  Colin did include\n&gt; Rel=\r\naxNetwork function which will run a network for some number of\n&gt; steps or u=\r\nntil the outputs stop changing.\n&gt; \n&gt; 3.  I don&#39;t use Hyperbolic Tanget for =\r\nthe simple reason that there\n&gt; were several sigmoids included with SharpNEA=\r\nT and they have about the\n&gt; same functionality for what I use them for.  Co=\r\nlin did some cool stuff\n&gt; to make it really easy to add your own activation=\r\n functions though. \n&gt; Simply make a class that implements IActivationFuctio=\r\nn and put it in\n&gt; the ActivationFunctions folder and in the NeuralNetwork n=\r\namespace.  It\n&gt; can then be accessed through the factory.  To use it with m=\r\ny code,\n&gt; just add the name and probability of that function occurring to t=\r\nhe\n&gt; params.txt file.\n&gt; \n&gt; 4. I don&#39;t have much experience with this issue,=\r\n but my advice is that\n&gt; it depends on which functions you have in your net=\r\nwork.  If the\n&gt; functions in the network are bipolar (-1,1) then your binar=\r\ny\n&gt; representation should be as well.  Ken&#39;s original XOR experiment used\n&gt;=\r\n &gt;.5 as 1 and &lt;.5 as 0, but that&#39;s because he used sigmoids that ranged\n&gt; f=\r\nrom 0 to 1.\n&gt; \n&gt; Hopefully that&#39;s answered everything, if you have any furt=\r\nher\n&gt; questions you can email me at ddambro@... and I&#39;m sure the\n&gt; group wo=\r\nuld be happy to address any general NEAT and HyperNEAT ideas\n&gt; or questions=\r\n you might have.\n&gt; \n&gt; David D&#39;Ambrosio\n\n\n\n"}}