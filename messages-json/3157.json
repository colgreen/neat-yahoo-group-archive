{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"ZhjgR1i2SRga8M6Kpf25v5ugJ_zC_MVjWxd94OoxlgHFAIhvRQXUVwL9VgBAXuXSEyHRzllZEvqBhVyzx-OucGsj60OcQUD3VrdP8tKBzMdXp-LZOgQ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Another note on activation","postDate":"1176602184","msgId":3157,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV2czBvOCtvY2hlQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEE1RkNGOTMyLUZBNDItNDgyQy1BM0Y2LTFDNzFDNDIzNTJFQUB3YWl0cy5uZXQ+"},"prevInTopic":3156,"nextInTopic":3158,"prevInTime":3156,"nextInTime":3158,"topicId":3139,"numMessagesInTopic":15,"msgSnippet":"Methods for activating neural networks are a very interesting topic. I don t have much to say about it. I prefer the a-node-activated-once- per-tick method","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 49021 invoked from network); 15 Apr 2007 01:57:17 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m44.grp.scd.yahoo.com with QMQP; 15 Apr 2007 01:57:17 -0000\r\nReceived: from unknown (HELO n11e.bullet.scd.yahoo.com) (66.218.67.71)\n  by mta9.grp.scd.yahoo.com with SMTP; 15 Apr 2007 01:57:17 -0000\r\nReceived: from [66.218.69.6] by n21.bullet.scd.yahoo.com with NNFMP; 15 Apr 2007 01:56:26 -0000\r\nReceived: from [66.218.66.76] by t6.bullet.scd.yahoo.com with NNFMP; 15 Apr 2007 01:56:26 -0000\r\nDate: Sun, 15 Apr 2007 01:56:24 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;evs0o8+oche@...&gt;\r\nIn-Reply-To: &lt;A5FCF932-FA42-482C-A3F6-1C71C42352EA@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Another note on activation\r\nX-Yahoo-Group-Post: member; u=283334584; y=MiY09UTnUIZd2LmjnrmhCRhWrjTZ2vGWPtRnX5BhfUATg5ttaRXjAI4ZRA\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nMethods for activating neural networks are a very interesting topic. \nI don=\r\n&#39;t have much to say about it. I prefer the a-node-activated-once-\nper-tick =\r\nmethod too, as Ken does. It looks good for me. The way to \nactivate the net=\r\nworks is in fact what is the view of the space that \nis searched. Since neu=\r\nral networks are flexible enough to compute any \nfunction, they can compute=\r\n the same thing in any way, it&#39;s just the \nright topology and weights that =\r\nmatter. \nDo you think about leaky integrator neurons, where the activation =\r\nis \nactually always changing? Every neuron depends on all others and \ntime?=\r\n \nIn biology, it&#39;s true that networks are never comletely activated, \nbut t=\r\nhis is the case when they continuously react to the environment. \n(which th=\r\ney do in fact). \nBut in the case of CPPNs, where a state of the network has=\r\n to be \ncomputed for the given coordinates, it may be different. \nI guess t=\r\nhe particular application of the NN is important at all. \n\n\n--- In neat@yah=\r\noogroups.com, Stephen Waits &lt;steve@...&gt; wrote:\n&gt;\n&gt; \n&gt; On Apr 13, 2007, at 4=\r\n:57 PM, Kenneth Stanley wrote:\n&gt; \n&gt; &gt; Biological neural networks are never =\r\n&quot;completely activated.&quot;\n&gt; \n&gt; Makes sense Ken, thanks!\n&gt; \n&gt; --Steve\n&gt;\n\n\n\n"}}