{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":274910130,"authorName":"ddambroeplex","from":"&quot;ddambroeplex&quot; &lt;ddambro84@...&gt;","profile":"ddambroeplex","replyTo":"LIST","senderId":"Iv-65VPtLxHPuzCSg8NKwTXF3DSpl5bJZD0kb_01sE9AGOsVhF_7s_jyFDAaHi7KXf2eqp3VmOcQiQRSGvGX_fQ4EblOYRzqlUcgSZI","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Applying NEAT to mountain car","postDate":"1355937499","msgId":5936,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGthc3NzcitlZWN1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGthc2Ztbis2MmplQGVHcm91cHMuY29tPg=="},"prevInTopic":5935,"nextInTopic":5937,"prevInTime":5935,"nextInTime":5937,"topicId":5933,"numMessagesInTopic":5,"msgSnippet":"Hello, This paper http://www.cs.lafayette.edu/~taylorm/Publications/JAAMAS09-Whiteson.pdf has NEAT in the mountain car domain, so that may give you some hints","rawEmail":"Return-Path: &lt;ddambro84@...&gt;\r\nX-Sender: ddambro84@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 73008 invoked from network); 19 Dec 2012 17:18:20 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m5.grp.sp2.yahoo.com with QMQP; 19 Dec 2012 17:18:20 -0000\r\nX-Received: from unknown (HELO ng20-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.178)\n  by mta5.grp.sp2.yahoo.com with SMTP; 19 Dec 2012 17:18:20 -0000\r\nX-Received: from [98.139.164.124] by ng20.bullet.mail.bf1.yahoo.com with NNFMP; 19 Dec 2012 17:18:19 -0000\r\nX-Received: from [98.137.34.36] by tg5.bullet.mail.bf1.yahoo.com with NNFMP; 19 Dec 2012 17:18:19 -0000\r\nDate: Wed, 19 Dec 2012 17:18:19 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kasssr+eecu@...&gt;\r\nIn-Reply-To: &lt;kasfmn+62je@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;ddambroeplex&quot; &lt;ddambro84@...&gt;\r\nSubject: Re: Applying NEAT to mountain car\r\nX-Yahoo-Group-Post: member; u=274910130; y=fyW3vps-chpBs0og7ZQKK-cHBlB1OXpIL9rbRr5GV6HtAdX9\r\nX-Yahoo-Profile: ddambroeplex\r\n\r\n\n\n\nHello,\n\nThis paper http://www.cs.lafayette.edu/~taylorm/Publications/JAA=\r\nMAS09-Whiteson.pdf has NEAT in the mountain car domain, so that may give yo=\r\nu some hints about parameters and such.  I am a bit unsure about what you m=\r\nean by setting the &quot;learning rate&quot; and &quot;initial weights&quot; though.  In vanill=\r\na NEAT the weights of the initial population are randomized and there isn&#39;t=\r\n any concept of a learning rate.  Are you evolving adaptive neural networks=\r\n?\n\nDavid\n\n--- In neat@yahoogroups.com, &quot;ivalcky&quot; &lt;ivalcky@...&gt; wrote:\n&gt;\n&gt; H=\r\ni, everyone, I have a problem about neat.\n&gt; I applied NEAT to the mountain =\r\ncar problem, and I found the result is bad. I want to find out why.\n&gt; Here =\r\nare some possilbility I am thinking of. Can anyone give me any hints and co=\r\nmments.\n&gt; The first possibility I thought is the weak ability of the initia=\r\nl population, since there are no hidden nodes, the neural network can not a=\r\npproximate the value function well. In my experiment, it can not achieve th=\r\ne top after 10000 steps. \n&gt; Another reason I considered is the initial weig=\r\nhts of the neural network, learning rate and so on, these parameters should=\r\n be set carefully, but it takes me a long time, and I haven&#39;t found a bette=\r\nr setting.\n&gt; I also think the mutation rate is an important factor.If I set=\r\n a small mutation rate, it may take a longer time to envolve. If I set a bi=\r\ngger value, does this lead to divergence?\n&gt; \n&gt; Any feedback is appreciated.=\r\n\n&gt;\n\n\n"}}