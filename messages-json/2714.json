{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":279942280,"authorName":"mneylon01","from":"&quot;mneylon01&quot; &lt;mneylon01@...&gt;","profile":"mneylon01","replyTo":"LIST","senderId":"uG5jXarFLPcLg_AIrCpIVmCKoDObrtT54HzDMuXK1x-Xn1nAUA4iizxe0SkR4yQnupLorbVlqGc2UkV8vcynvrccKfwR7VEi","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: NEAT and highly recurrent networks","postDate":"1156778507","msgId":2714,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVjdjFtYis3cDVtQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGVjdDBtOSs1NWtyQGVHcm91cHMuY29tPg=="},"prevInTopic":2712,"nextInTopic":2717,"prevInTime":2713,"nextInTime":2715,"topicId":2711,"numMessagesInTopic":7,"msgSnippet":"I haven t had a chance to go back and try the weight adjustment test to start, but I did try the C# NEAT package that already exists to try out the delayed XOR","rawEmail":"Return-Path: &lt;mneylon01@...&gt;\r\nX-Sender: mneylon01@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 57074 invoked from network); 28 Aug 2006 15:24:20 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m21.grp.scd.yahoo.com with QMQP; 28 Aug 2006 15:24:20 -0000\r\nReceived: from unknown (HELO n31.bullet.scd.yahoo.com) (66.94.237.25)\n  by mta6.grp.scd.yahoo.com with SMTP; 28 Aug 2006 15:24:19 -0000\r\nReceived: from [66.218.69.3] by n31.bullet.scd.yahoo.com with NNFMP; 28 Aug 2006 15:21:47 -0000\r\nReceived: from [66.218.66.86] by t3.bullet.scd.yahoo.com with NNFMP; 28 Aug 2006 15:21:47 -0000\r\nDate: Mon, 28 Aug 2006 15:21:47 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ecv1mb+7p5m@...&gt;\r\nIn-Reply-To: &lt;ect0m9+55kr@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;mneylon01&quot; &lt;mneylon01@...&gt;\r\nSubject: Re: NEAT and highly recurrent networks\r\nX-Yahoo-Group-Post: member; u=279942280; y=QuB4BM2lcBNdwDJHf_xoR98VHJUlOvpn7MZ_-I9sjA1-nFl3\r\nX-Yahoo-Profile: mneylon01\r\n\r\nI haven&#39;t had a chance to go back and try the weight adjustment test\nto sta=\r\nrt, but I did try the C# NEAT package that already exists to try\nout the de=\r\nlayed XOR test (since that appears to work fine and is a\ngood way to compar=\r\ne to what I&#39;m trying to do, plus it was easy to add\nthe delayed XOR experim=\r\nent).\n\nI found that (without adjusting the parameters from the default XOR\n=\r\ncase) the network would not grow well - it tended towards a very large\nnumb=\r\ner of hidden nodes without much recurrance and really had a hard\ntime impro=\r\nving after even 10,000 generations.  I tried changing a few\nparameters (wei=\r\nghting more on new connections vs new nodes) and really\ndidn&#39;t get anywhere=\r\n.  For reference, one should be able to do a\ndelayed XOR network, with abou=\r\nt n+1 hidden nodes in a fully recurrent\nElman network, where n is the numbe=\r\nr of time steps for the delay.\n\nI saw the paper that is in this group about=\r\n noisy time data, and\nnoticed that one thing the authors did was to actuall=\r\ny train the\nresulting networks, and then used test results to obtain fitnes=\r\ns (As\nopposed to what I&#39;ve seen others do, which is to simply test the\nnetw=\r\nork, possibly relaxing the network over several cycles to handle\nrecurrency=\r\n, but no change in weight values).  I think this may be the\ndirection one h=\r\nas to go, with the assumption that once trained, the\nnew weights then becom=\r\ne the weights of the connection genes in the\ngenome, and by extension, the =\r\nchance of perturbuation of weights vs\nmutation of weights during evolution =\r\nshould be much higher as to\navoiding to disrupt the training too much.\n\nAny=\r\nway, I will look at my weight mutation processes and compatibility\nterms to=\r\n see if I can fix mine, as I can then easily add the above\ntraining/testing=\r\n process.\n\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; w=\r\nrote:\n&gt;\n&gt; It sounds like the main issue before you can really start looking=\r\n at \n&gt; delayed-XOR is to get XOR working more closely to my own NEAT\n&gt; (and=\r\n others developed since).  Certainly the 500-1000 generations \n&gt; it&#39;s takin=\r\ng you indicates somethign is likely wrong in your \n&gt; implementation.\n&gt; \n&gt; I=\r\n would suggest the following experiment:  Start evolution with  a \n&gt; popula=\r\ntion of networks that already have the correct topology for a \n&gt; solution t=\r\no XOR and turn off structural mutations.  Then run your \n&gt; version of NEAT =\r\nas usual, except in this case, it will only be \n&gt; searching over weight spa=\r\nce.  If it takes forever, it tells you that \n&gt; the problem is in the way yo=\r\nur weights are being mutated, or the way \n&gt; they are being combined in cros=\r\nsover.  It may also indicate a \n&gt; problem in speciation (related to weight =\r\ncomparison).  In any case, \n&gt; it will greatly narrow down the problem.\n&gt; \n&gt;=\r\n Once you get it working on pure weight-evolution, then you can move \n&gt; to =\r\nthe normal topology evolution, and you will either see it work \n&gt; right awa=\r\ny, or find that there is a problem in adding structure as \n&gt; well.\n&gt; \n&gt; Abo=\r\nut compatibility testing for speciation, when you menion &quot;N,&quot; do \n&gt; you mea=\r\nn the normalization term in my papers?  Regrettably, many \n&gt; people miss th=\r\nat I did not use N (for normalization) in practice, \n&gt; that is, I set N to =\r\n1 in all cases.  That may explain why you using \n&gt; the same coefficients as=\r\n me does not work.  If you look at my papers \n&gt; closely, they say that N ca=\r\nn be set to 1 if genomes are not too \n&gt; large.  I have found in practice th=\r\nat it always works fine with it \n&gt; set to 1, so that&#39;s what I&#39;ve done.  Thi=\r\ns confusion is my fault and \n&gt; I apologize for it- the papers should be mor=\r\ne clear- but I wanted \n&gt; people to be aware of N and the option for normali=\r\nzation in case it \n&gt; indeed does come into play with very large genomes.\n&gt; =\r\n\n&gt; As for deviations from typical values, you can see all the values \n&gt; I&#39;v=\r\ne used in the appendix to my dissertation.  There is some \n&gt; explanation th=\r\nere too for why different values were chosen.  One \n&gt; consideration might b=\r\ne whether very fine grained weight changed are \n&gt; key or not in a particula=\r\nr problem.  If they are, you might want the \n&gt; coefficient of weight differ=\r\nences to be higher.\n&gt; \n&gt; Once you get XOR working, please let the group kno=\r\nw how things go \n&gt; with the delayed XOR!  By the way, what language/platfor=\r\nm did you \n&gt; use for your version of NEAT?\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoog=\r\nroups.com, &quot;mneylon01&quot; &lt;mneylon01@&gt; wrote:\n&gt; &gt;\n&gt; &gt; I&#39;ve been working on my =\r\nown implimentation of NEAT (having to fit \n&gt; to a\n&gt; &gt; predescribed framewor=\r\nk) and while it&#39;s mostly working, I&#39;m looking \n&gt; at\n&gt; &gt; a couple of questio=\r\nns.\n&gt; &gt; \n&gt; &gt; First, I know that the networks that NEAT generates can have\n&gt;=\r\n &gt; recurrency (feedback), and this is likely why some of the robot \n&gt; game\n=\r\n&gt; &gt; examples work well.  However, I&#39;m looking at trying to use NEAT to\n&gt; &gt; =\r\nfind patterns in time series data, as one would use fully recurrent\n&gt; &gt; net=\r\nworks for (In these, also known as Elmen networks, all of the\n&gt; &gt; hidden la=\r\nyer and output layer values are &#39;propagated&#39; into the next\n&gt; &gt; time step to=\r\n give the network memory, with full connectivity \n&gt; between\n&gt; &gt; all the inp=\r\nut and previous nodes to the hidden/output nodes).\n&gt; &gt; \n&gt; &gt; Such a network =\r\nshould be possible to be generated by NEAT, though I\n&gt; &gt; figure that not ev=\r\nery recurrent type problem needs a fully \n&gt; recurrent\n&gt; &gt; network.  So I&#39;m =\r\ntrying to use NEAT to generate such, using the\n&gt; &gt; classic delayed-XOR prob=\r\nlem (such that the result of xor of the two\n&gt; &gt; current inputs will be the =\r\nactual output some time steps away).  \n&gt; Fully\n&gt; &gt; recurrent networks can b=\r\ne trained to do this, but I want to \n&gt; generate a\n&gt; &gt; NEAT network that, af=\r\nter running through the fixed data series a\n&gt; &gt; number of relaxation times,=\r\n that the weights have already been \n&gt; trained\n&gt; &gt; through NEAT evolution s=\r\nuch that I don&#39;t have to perform additional\n&gt; &gt; training on the network.  \n=\r\n&gt; &gt; \n&gt; &gt; Has anyone had any success directly in generating such recurrent\n&gt;=\r\n &gt; networks?  I know my fitnesses improve with time, but it takes a \n&gt; lot\n=\r\n&gt; &gt; of generations (1000+ with a 150 member population) to even see\n&gt; &gt; som=\r\nething, and even then, it&#39;s not anywhere close to what simple\n&gt; &gt; recurrent=\r\n training can provide.  (This may be also related to my\n&gt; &gt; second question=\r\n).\n&gt; &gt; \n&gt; &gt; The other question I had was about convergence times.  I&#39;m tryi=\r\nng \n&gt; to\n&gt; &gt; test my network on the normal XOR problem (non-recurrent mode)=\r\n and\n&gt; &gt; find that it takes many more evolution generations for the fitness=\r\n \n&gt; to\n&gt; &gt; get to acceptable levels (based solely on the distance of expect=\r\ned \n&gt; vs\n&gt; &gt; observed output), exceptionaly more than listed in the NEAT pa=\r\npers\n&gt; &gt; (500-1000 evolution steps as opposed to 10-30 steps) even when \n&gt; =\r\nusing\n&gt; &gt; what I believe are the same values described by Kenneth in his \n&gt;=\r\n papers.\n&gt; &gt;  I&#39;ve tried nearly every parameter, and the only one that I kn=\r\now I\n&gt; &gt; want to keep low is the new node probability to avoid excessive \n&gt;=\r\n growth\n&gt; &gt; of the network.  Anyone have any pointers on what parameters ar=\r\ne\n&gt; &gt; critical to help with rapid convergence on the best network?  Mind\n&gt; =\r\n&gt; you, it could still be something in my code which I&#39;ve been \n&gt; pounding\n&gt;=\r\n &gt; through to try to find differences.\n&gt; &gt; \n&gt; &gt; Another related question is=\r\n on the species comparison expression \n&gt; and\n&gt; &gt; tolerance.  I tend to use =\r\nN=3Dnumber of genes in largest species\n&gt; &gt; regardless of the case, and for =\r\nthat I have to play with the \n&gt; tolerance\n&gt; &gt; as to get 5 or more species i=\r\nn a population of 150.  Is there an \n&gt; ideal\n&gt; &gt; average number of species =\r\nthat you want to carry through in the\n&gt; &gt; population in order to take advan=\r\ntage of NEAT&#39;s use of species?  \n&gt; And\n&gt; &gt; when do people move away from th=\r\ne &#39;typical&#39; values of the \n&gt; coefficients\n&gt; &gt; (1 and 1 for disjoint and exc=\r\ness elements, 0.4 for weight \n&gt; difference\n&gt; &gt; average)\n&gt; &gt;\n&gt;\n\n\n\n\n\n"}}