{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"U-8roa9FxK_APvyNoWw29NqgwvcwatLyxWk6J5wLs1DJ3a5Ci-bWg70ksd9pD5nSmqxO4UnvgaLbkR9LVavSjyr-VioZ0xMd4w","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Image Enlargement domain","postDate":"1153006914","msgId":2671,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0Qjk3RDQyLjMwODAzMDJAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PDUxN2ZhNmYxMDYwNzEyMTIxMnQ1OGFjMGNjeDliN2JiY2FiNjU2MDljYzdAbWFpbC5nbWFpbC5jb20+","referencesHeader":"PDUxN2ZhNmYxMDYwNzEyMTIxMnQ1OGFjMGNjeDliN2JiY2FiNjU2MDljYzdAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":2660,"nextInTopic":2675,"prevInTime":2670,"nextInTime":2672,"topicId":2660,"numMessagesInTopic":7,"msgSnippet":"... Ah yes, that old chestnut :) ... Seems like a completely reasonable and sensible approach to me. [...] ... I started out in EANNs by looking at incremental","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 70357 invoked from network); 15 Jul 2006 23:41:55 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m27.grp.scd.yahoo.com with QMQP; 15 Jul 2006 23:41:55 -0000\r\nReceived: from unknown (HELO ranger.systems.pipex.net) (62.241.162.32)\n  by mta9.grp.scd.yahoo.com with SMTP; 15 Jul 2006 23:41:54 -0000\r\nReceived: from [10.0.0.11] (81-86-161-87.dsl.pipex.com [81.86.161.87])\n\tby ranger.systems.pipex.net (Postfix) with ESMTP id 43137E000129\n\tfor &lt;neat@yahoogroups.com&gt;; Sun, 16 Jul 2006 00:41:51 +0100 (BST)\r\nMessage-ID: &lt;44B97D42.3080302@...&gt;\r\nDate: Sun, 16 Jul 2006 00:41:54 +0100\r\nUser-Agent: Mozilla Thunderbird 1.0.7 (Windows/20050923)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;517fa6f10607121212t58ac0ccx9b7bbcab65609cc7@...&gt;\r\nIn-Reply-To: &lt;517fa6f10607121212t58ac0ccx9b7bbcab65609cc7@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Image Enlargement domain\r\nX-Yahoo-Group-Post: member; u=127853030; y=gRwmFloOQEoVzU2__Waa2GCzkFhKSZ077u5QW0-x_5goeeEv_tSd\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nJohn Arrowwood wrote:\n\n&gt; All,\n&gt;\n&gt; For those that remember, I originally got interested in NEAT in order \n&gt; to do\n&gt; image enlargement.\n\n\nAh yes, that old chestnut :)\n\n\n&gt;\n&gt; An idea came to mind, and I wanted to solicit feedback on the idea, as \n&gt; well\n&gt; as suggestions on how to implement it.  The idea is to use artificially\n&gt; generated training samples for the initial training set.  \n\n\n\nSeems like a completely reasonable and sensible approach to me.\n\n[...]\n\n&gt;\n&gt; Question 1:  What do people think of the idea of having a progressively\n&gt; harder and harder task for networks to complete as they evolve?  I \n&gt; believe\n&gt; this has been tested before, and I am wondering what lessons have been\n&gt; learned in the past.\n\n\nI started out in EANNs by looking at incremental evolution applied to \nthe prey capture problem, the exact paper I&#39;ve refered to a few times on \nthe list in the past:\n\nhttp://citeseer.ist.psu.edu/gomez96incremental.html\n\nIn that domain the harder problems are too difficult for evolution to \nfind direct solutions, so we try and move through the fitness space in \nincrements. Your image enlargement domain is a little different because \nyou could actually provide the most difficult and all encompassing test \nset, and progress could concievably be made right from teh inital \npopulation right up to a [near] perfect solution. The reason being that \nyou could have a fitness function that reflects how close the enlarged \nimage is to the target on a continous scale, whereas the prey capture is \nan all or nothing (the prey got caught) situation that requires a large \njump in functionality in order to register any fitness at all on the \nmost difficult test case.\n\nOn the other hand your all-encompassing test set would be massive so it \nseems sensible to speed up the early stages of evolution by testing the \ncandidate genomes as much as possible with as little test data and CPU \nusage possible.\n\n\n&gt;\n&gt; Question 2: Does anybody have an opinion on using testing samples that \n&gt; are\n&gt; quantitatively similar but not identical between generations?  Naturally,\n&gt; the champion of one generation may not be the champion of the next\n&gt; generation, just because of differences in the testing samples used.  Are\n&gt; there any serious rammifications to this?  Anything else I should know\n&gt; about?\n\n\nI suppos eit depends on how large the training set is. If you start out \nwith a small trainign set then overfitting becomes a possibility and \n&#39;jiggling&#39; the images around between generations may help revent this. \nAs the training set size increases I would say the possibility of \noverfitting reduces, so the need to jiggle the images may be lesser. I \nthink it&#39;s worth doing so long as you do only jiggle the images a bit \nand not generate a completely new set of images for each generation.\n\n\n\n\n\n\n&gt;\n&gt; Question 3: Does anybody have a suggestion of a way to create the \n&gt; training\n&gt; samples?  My first idea was to generate SVG and convert the SVG to \n&gt; bitmaps\n&gt; via an external tool.  ImageMagick can do this, but it does a really \n&gt; crappy\n&gt; job with curves.  Is there a suggestion of another way to convert SVG to\n&gt; bitmap?  Or is there another way other than SVG?  How would you go about\n&gt; creating bitmap images that are programmatically defined based on\n&gt; parameterized vectors?  A library?  A tool?  What existing \n&gt; technologies can\n&gt; anybody recommend?\n\n\nIf I were doing this in .Net I would just write my own graphics (GDI+) \nparameterised routine to draw a line on to a Bitmap (which is a .Net \nclass). Having said that when I did my simple OCR experiment I started \nout using the Bitmap class but it was very slow to query a bitmap for \nthe value of each pixel, so I wrote my own class for representing a 2D \narray of bits bu twhich didn;t have the overhead of actually being \nsomething that could be displayed (with all of the data layout of bits \nand bytes that that entails). But you could still use somethign liek the \nBitmap class to generate the images, which is a once per generation \noperation and then copy the resultign images to an optimised bitmap for \nuse during ANN evaluation - which occurs many times per generation.\n\nColin.\n\n\n\n"}}