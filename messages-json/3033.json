{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"kH1uJzfvJqzNVUUxKrjI_mqq80DSqy5chI7hIqruYSbu-H7VCgyeEOURuuZdp3-4KCF3kQffUImgEG3a1ngzcPtOqavLXmt50zeBEYDljt1P","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HyperNEAT: Creating Neural Networks with CPPNs","postDate":"1174953049","msgId":3033,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV1OW04cCtkamg0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwNDYzMzI3NzI2MzIyQG1haWwuaWRuZXQubmV0LnVrPg=="},"prevInTopic":3031,"nextInTopic":3034,"prevInTime":3032,"nextInTime":3034,"topicId":3028,"numMessagesInTopic":34,"msgSnippet":"Ian, thanks for the great post.  These are indeed critical and deep issues at the core of indirect encoding. I want to carefully address them because I have","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 61144 invoked from network); 26 Mar 2007 23:51:03 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m42.grp.scd.yahoo.com with QMQP; 26 Mar 2007 23:51:03 -0000\r\nReceived: from unknown (HELO n17a.bullet.scd.yahoo.com) (66.94.237.46)\n  by mta10.grp.scd.yahoo.com with SMTP; 26 Mar 2007 23:51:03 -0000\r\nReceived: from [66.218.69.6] by n17.bullet.scd.yahoo.com with NNFMP; 26 Mar 2007 23:50:50 -0000\r\nReceived: from [66.218.66.87] by t6.bullet.scd.yahoo.com with NNFMP; 26 Mar 2007 23:50:50 -0000\r\nDate: Mon, 26 Mar 2007 23:50:49 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;eu9m8p+djh4@...&gt;\r\nIn-Reply-To: &lt;20463327726322@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: HyperNEAT: Creating Neural Networks with CPPNs\r\nX-Yahoo-Group-Post: member; u=54567749; y=Ql1STTY3oLmZGzd9a8HLxSdNhGoIHZzdy3fEX-lZhvXfphkCE6q7\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nIan, thanks for the great post.  These are indeed critical and deep \nissues=\r\n at the core of indirect encoding.\n\nI want to carefully address them becaus=\r\ne I have been thinking about \nthese issues for a long time and they are tie=\r\nd into the theory \nbehind CPPNs.  \n\nFirst, note that our new journal paper =\r\nthat I just \nannounced, &quot;Compositional Pattern Producing Networks: A Novel =\r\n\nAbstraction of Development,&quot; gives an extensive treatment of the \nissues y=\r\nou raise in a better way than the old &quot;Patterns Without \nDevelopment.&quot;  (Th=\r\ne journal paper has replaced &quot;Patterns Without \nDevelopment,&quot; which is no l=\r\nonger available)  So you may find a \nbetter motivation in that paper.\n\nIn a=\r\nny case, I will give my thoughts here in short.  I have come to \nthe conclu=\r\nsion after thinking about this issue for a couple years \nthat there may be =\r\nno representational or even computational \nadvantage to iterated developmen=\r\ntal systems over CPPN-like \nfunctional representation.  I say &quot;may&quot; because=\r\n I am not yet 100% \ncertain, but I am nearing it.  If I am right, this is a=\r\n very deep \nand significant fact that should change the way we are looking =\r\nat \nrepresentation through development.  \n\nThere are a few reasons for this=\r\n view.  One is the simple \ntheoretical fact that a single hidden layer neur=\r\nal network can \nrepresent any function with arbitrary accuracy (a theorem b=\r\ny \nCybenko).  From the perspective of patterns, this theorem means that \n*t=\r\nheoretically*, there is no pattern that iterative development can \nproduce =\r\nthat a functional description cannot describe with \narbitrarily close preci=\r\nsion.\n\nOf course, that is only theory, and theory and practice are often \no=\r\npposed:  It still leaves open the possibility that somehow \nrepresentations=\r\n of certain patterns are for some reason more \n*compact* if they are descri=\r\nbed and mapped through an iterative \nprocess.  Thus one can still argue the=\r\ny are more powerful.\n\nYet I also have come to believe that that is not the =\r\ncase either.  \nThe reason hinges on an interesting insight that you put lik=\r\ne this:\n\n&quot;genes essentially &#39;pattern recognize&#39; certain areas in the  \norga=\r\nnism&quot;\n\nThat is absolutely correct for biological organisms, and for \niterat=\r\ned developmental systems in general.  However, the deep \nquestion is *why* =\r\nshould they need to &quot;pattern recognize&quot; certain \nareas?\n\nAnd the answer is =\r\nbecause they need to know where they are.  In \neffect, in the physical univ=\r\nerse, there is no intrinsic coordinate \nsystem that cells can query to ask =\r\ntheir location.  Thus, they must \ndevelop elaborate and ad hoc ways of comm=\r\nunicating to each other, as \na group, where everyone is.  I send my neighbo=\r\nr signals, my neighbor \nsends me signals back, and we negotiate our roles. =\r\n\n\nMy undoubtedly controversial contention is that the question &quot;where \nam I=\r\n?&quot; is the ONLY reason that such negotation is necessary.  If you \ndidn&#39;t ha=\r\nve to ask that question, then you would not need to talk to \nyour neighbors=\r\n in order to determine your role.  Rather, you could \njust compute your rol=\r\ne as a function of your known \ncoordinate/position in the world.  \n\nThat is=\r\n exactly what CPPNs do.  Because inside a computer the \ncoordinates of ever=\r\ny &quot;cell&quot; in (2D or 4D or 6D or whatever) space is \nknown, they do not need =\r\nto communicate with each other.  Rather, \nthey simply compute a function of=\r\n their position.\n\nThat function in effect encompasses all the unfolding eve=\r\nnts that \nwould happen in a normal iterative process, as the CPPN theory \ns=\r\nays.  So if there was a symmetric gradient laid from one side to \nanother i=\r\nn a growing organism through some complex process of \ncommunication, a CPPN=\r\n simply instantiates a symmetric function \ninstead as an analogue of the sa=\r\nme process.  \n\nThus, I would argue that the CPPN likely completely subsumes=\r\n \niterative development, and that all the fancy stuff that is so mind-\nblow=\r\ning that looks so important in devleopmental biology is simply a \nbig compl=\r\nicated quest to answer the question &quot;where am I?&quot; (and \nhence &quot;who am I?&quot;).=\r\n  In a computer, since we know the &quot;where&quot; answer \na priori by definition, =\r\nwe can wipe out all of this unnecessary \ncomplexity, in effect massively si=\r\nmplifying the problem of \nrepresnetation.\n\nMy hunch is that this principle =\r\nis why CPPNs are producing such \nintricate and complex structures compared =\r\nto every artificial \ndevelopmental encoding that has come before.  Have you=\r\n ever seen a \npattern as nuanced and intricate as the spaceship produced by=\r\n CPPNs \nproduced by another developmental encoding?  In fact, evolving a \nb=\r\nlob or a flag-like pattern is currently considered cutting edge \nwith such =\r\nsystems today.\n\nSo I&#39;d actually argue that CPPNs are a more powerful repres=\r\nentation \nthan an iterative system because they wipe out all kinds of \nunne=\r\ncessary complexity that results at the core from simply needing \nto know wh=\r\nere one is in the body plan.  And they also wipe out the \niterations themse=\r\nlves.  So it&#39;s a radical contrast.  In effect, this \nradical shift away fro=\r\nm iteration and local interaction is possible \nbecause CPPNs are cheating: =\r\nThey can know the coordinate frame \nwithin which they operate a priori- som=\r\nething that is not available \nin biology.  So it is not a surprise that whe=\r\nn we cheat we can do \nbetter.  \n\nThus, I am arguing an admittedly radical p=\r\nosition that classic \niterated devbelopment is best abandoned as a form of =\r\nindirect \nencoding for evolutionary algorithms.\n\nPlease note however, havin=\r\ng said that, that iteration IS necessary \nfor developmental systems that in=\r\nteract with the environment over \ntheir lifetime (such as brains).  However=\r\n, CPPNs can iterate in such \na way just as any other system.  It only means=\r\n re-querying the CPPN \nat each iteration.  Thus, CPPNs do not miss this cap=\r\nability even \nwhen it is necessary (and it will be in the long run).\n\nThere=\r\nfore, my hunch is that CPPNs (or something quite similar) are \nthe best typ=\r\ne of abstraction we will get.  The enchantment with a \nprocess of unfolding=\r\n over time and local interaction may turn out to \nbe an intuitive mistake.\n=\r\n\nken\n\n\n\n--- In neat@yahoogroups.com, Ian Badcoe &lt;ian_badcoe@...&gt; wrote:\n&gt;\n&gt;=\r\n Hi,\n&gt; \tCan I add my opinion to the other&#39;s saying that from what I \nread s=\r\no \n&gt; far, the idea of HyperNEAT is brilliant.\n&gt; \n&gt; \tHaving said that (alway=\r\ns got to balance the praise and \ncriticism) I \n&gt; do feel that there is a li=\r\nttle something that has been missed in \nthis \n&gt; particular approach.  I rea=\r\nlly meant to say something before, way \n&gt; back when you posted the &quot;Pattern=\r\ns without development&quot; work that \n&gt; preceded this.\n&gt; \n&gt; \tWhat I am getting =\r\nat, is the difference between a function \nmapping, \n&gt; however complex, and =\r\nan iterative system.  This difference seems \nto \n&gt; me to be a fairly crucia=\r\nl factor in the nature of developmental \nbiology.\n&gt; \n&gt; \tThe reason this dif=\r\nference matters is something I touched on \nbefore:\n&gt; \n&gt; http://tech.groups.=\r\nyahoo.com/group/neat/message/1818\n&gt; \n&gt; \talbeit only &quot;touched&quot; on it.\n&gt; \n&gt; \t=\r\nI am having some difficulty justifying this position, partly \nbecause \n&gt; I =\r\nhaven&#39;t been near the literature on any of this for over a year, \n&gt; partly =\r\nbecause it is quite a deep point about evolvability, and \n&gt; partly because =\r\nit is by no means proven, intuitive and a \nquantitative \n&gt; difference rathe=\r\nr than a qualitative one, however:\n&gt; \n&gt; \tFIRST let me illustrate the sort o=\r\nf iterative system that I \n&gt; mean.  What I am referring to is (say) somethi=\r\nng like your 4D \n&gt; connection density function (substrate configuration, I =\r\nthink you \n&gt; called it).  Some sort of field, probably discretised into cel=\r\nls \nfor \n&gt; convenience of computation, with some value(s) stored on each ce=\r\nll.\n&gt; \n&gt; \tNOW, the difference in the two approaches is that using \nCPPNs, a=\r\nll \n&gt; we will do is evaluate one function (possibly very complex) once, \nfo=\r\nr \n&gt; each cell in the field.\n&gt; \n&gt; \tBUT for an iterative approach, we will p=\r\nrobably fill the \nfield in \n&gt; that manner as a start state, but after that =\r\nwe will then iterate \n&gt; over it N times applying some sort of rule to updat=\r\ne the field on \n&gt; each pass.  It is the fact that the rules act on the outp=\r\nut of \n&gt; previous stages that gives the system its power.  Rules could be \n=\r\n&gt; targeted in various ways and have various effects, but we can \nimagine \n&gt;=\r\n the general case of recognizing some pattern (either of values in \na \n&gt; si=\r\nngle cell, or else relative values in a locality of cells) and \n&gt; changing =\r\nsome values in a cell as a result.\n&gt; \n&gt; \tIn BIOLOGY, this equates to real c=\r\nells.  Every cell contains \nthe \n&gt; same genes but not all genes are activat=\r\ned.  The embryo starts \nwith a \n&gt; simple polarity (up-down) defined by a ch=\r\nemical gradient.  Genes \nare \n&gt; activated at certain places based on the am=\r\nount of chemical and \nthe \n&gt; gene-products produce other chemicals.  Some c=\r\nhemicals also leak \nfrom \n&gt; cell to cell.  Thus simple patterns of chemical=\r\ns become more \ncomplex \n&gt; because genes essentially &quot;pattern recognize&quot; cer=\r\ntain areas in the \n&gt; organism, and start producing other chemicals in respo=\r\nnse.\n&gt; \n&gt; \tThe power of a system like this is, if (say) the number of \nlegs=\r\n \n&gt; changes (by changing the number of repeats of a pattern at an \nearly \n&gt;=\r\n stage in the process), then the later stages still have a \nreasonable \n&gt; c=\r\nhance of doing something sane even though the basic plan has \n&gt; changed.  T=\r\nhe process that would wire nerves and blood to N legs, \n&gt; works (almost) as=\r\n happily with N+2 legs.  This is why two headed \n&gt; snakes are alive (if unf=\r\nit) but two nosed Boeing 747&#39;s are scrap.\n&gt; \n&gt; \t[[I have spoken about this =\r\nbefore, and in fact I wrote (most \nof) a \n&gt; complex philosophical web-page =\r\n(called &quot;the Manifesto for Evolving \n&gt; Agents&quot;) which went into this in som=\r\ne depth.  Maybe I&#39;ll see if I \ncan \n&gt; get that up on the web somewhere, eve=\r\nn unfinished, and the \ncommunity \n&gt; might give me some useful feedback on i=\r\nt and get me working again.\n&gt; \n&gt; \tAnyway, as you can imagine, an iterative =\r\ndevelopment system \nis an \n&gt; order of magnitude more complex than HyperNEAT=\r\n, and strays into \nall \n&gt; out usual areas of interest/difficulty such as mo=\r\ndularity etc.  \nWhich \n&gt; is why HyperNEAT is so clever as an intermediate s=\r\ntep.  Nice one \nKen!\n&gt; \n&gt; \tIan\n&gt;\n\n\n\n"}}