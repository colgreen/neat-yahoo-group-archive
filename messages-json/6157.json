{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":55268137,"authorName":"shimonw","from":"&quot;shimonw&quot; &lt;shimon@...&gt;","profile":"shimonw","replyTo":"LIST","senderId":"8FswbxjqJmfu0cdM4Y56fwqTdRlZm2rJn26ogB4AHRySyTdyVWyFTT-H0zzBp63jTdn32LDlYTmGK0kRwajZNhc7BcHziQ","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: GECCO Paper on HyperNEAT","postDate":"1372142842","msgId":6157,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtxYmVkcitpZHFjQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtwb2locytsdjd1QGVHcm91cHMuY29tPg=="},"prevInTopic":6156,"nextInTopic":6158,"prevInTime":6156,"nextInTime":6158,"topicId":6085,"numMessagesInTopic":14,"msgSnippet":"Hi Ken, Yes, I agree that this conversation is exposing some of our fundamental assumptions, and it is always good to examine and question such assumptions. ","rawEmail":"Return-Path: &lt;shimon@...&gt;\r\nX-Sender: shimon@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 42952 invoked from network); 25 Jun 2013 06:47:25 -0000\r\nX-Received: from unknown (98.137.63.203)\n  by m16.grp.sp2.yahoo.com with QMQP; 25 Jun 2013 06:47:25 -0000\r\nX-Received: from unknown (HELO ng8-ip5.bullet.mail.ne1.yahoo.com) (98.138.215.175)\n  by mtaq4.grp.sp2.yahoo.com with SMTP; 25 Jun 2013 06:47:25 -0000\r\nX-Received: from [98.138.217.182] by ng8.bullet.mail.ne1.yahoo.com with NNFMP; 25 Jun 2013 06:47:24 -0000\r\nX-Received: from [98.137.34.32] by tg7.bullet.mail.ne1.yahoo.com with NNFMP; 25 Jun 2013 06:47:24 -0000\r\nDate: Tue, 25 Jun 2013 06:47:22 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kqbedr+idqc@...&gt;\r\nIn-Reply-To: &lt;kpoihs+lv7u@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;shimonw&quot; &lt;shimon@...&gt;\r\nSubject: Re: GECCO Paper on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=55268137; y=stqT16vAiGib3nr9yjbYidFpt_2JeSCnmPbJLNjKx8Lbeg\r\nX-Yahoo-Profile: shimonw\r\n\r\nHi Ken,\n\nYes, I agree that this conversation is exposing some of our fundam=\r\nental assumptions, and it is always good to examine and question such assum=\r\nptions.\n\nHowever, if you think that our hypotheses are equally bold, then I=\r\n fear my main point has been misunderstood.  I am not actually hypothesizin=\r\ng that an algorithm with any particular qualities exists.  I am only saying=\r\n that I am not aware of any result which gives good reason to abandon hope =\r\nin developing methods that work with indirect encodings and excel on &quot;regul=\r\nar&quot; FFs.  This is actually not a hypothesis at all; it is an incontrovertib=\r\nle fact. Of course, it doesn&#39;t prove that such a result doesn&#39;t exist and I=\r\n certainly don&#39;t claim a comprehensive mastery of the literature.  But if s=\r\nuch a result does exist (though it&#39;s hard to imagine it would), anyone is f=\r\nree to simply point it out to me.\n\nBy contrast, your hypothesis was that &quot;a=\r\nn unhappy and unhealthy indirect encoding is one with only a strict target =\r\nto which to aspire.&quot;  I continue to maintain that this quite a bold claim. =\r\n You suggested that the &quot;success&quot; of natural evolution provides a proof of =\r\nconcept to support your hypothesis, but I find this highly problematic.  Fi=\r\nrstly, it&#39;s unclear that evolution was &quot;successful&quot; in any meaningful way b=\r\necause there&#39;s an anthropic principle at work here: we are human and so we =\r\nfind humans impressive.  The success of evolution is thus a self-fulfilling=\r\n prophecy.  Secondly, and more importantly, even if we accept that evolutio=\r\nn is successful, this actually does not validate your hypothesis at all.  S=\r\nhowing that there&#39;s a nice algorithm that works without a target is not the=\r\n same as showing that there are *no* algorithms that work with a target, wh=\r\nich is what your hypothesis claims.\n\nThat&#39;s why I think it&#39;s not correct to=\r\n describe our &quot;hypotheses&quot; as equally bold.  In my case, there is nothing t=\r\no prove: there&#39;s just a simple fact.  In your case, validating the hypothes=\r\nis requires proving a negative (and quite a sweeping one at that), which is=\r\n notoriously difficult to do.\n\nFinally, I sense from your defense of PicBre=\r\neder that I may have been misunderstood in another way.  I&#39;m in no way tryi=\r\nng to criticize PicBreeder or suggest that research into it is misguided.  =\r\nI think it&#39;s a very cool and intriguing result, possibly a highly significa=\r\nnt one.  You and I may disagree about *why* it&#39;s significant, but we defini=\r\ntely agree that it&#39;s useful to study further and has the potential to yield=\r\n important insights.  \n\nI&#39;m just saying that, in the complementary search f=\r\nor optimization methods that use indirect encodings and can excel on hard F=\r\nFs, there&#39;s really no reason for despair.\n\nCheers,\nShimon\n\n--- In neat@yaho=\r\nogroups.com, &quot;Ken&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Hi Shimon,\n&gt; \n&gt; The nice thing=\r\n about this type of conversation is that it pushes us\n&gt; towards realizing o=\r\nur fundamental assumptions.  In that spirit, a few\n&gt; other thoughts in resp=\r\nonse:\n&gt; \n&gt; Many top biologists and EC researchers would call the behavior o=\r\nf the\n&gt; organism in the world (i.e. its interactions with the world) the\n&gt; =\r\n&quot;phenotype.&quot;  David Fogel once sent me a long and forceful defense of\n&gt; suc=\r\nh a position, quoting a number of famous biologists.  In that\n&gt; context, wh=\r\nether you map CPPN-&gt;pattern or CPPN-&gt;behavior, a target is\n&gt; still a target=\r\n and the neural network is not the phenotype.\n&gt; \n&gt; In any case, I guess we =\r\nboth hold bold hypotheses in some sense.  Your\n&gt; hypothesis that there exis=\r\nt methods that can solve hard FFs almost\n&gt; deterministically as targets (up=\r\n to and even beyond delivering us an\n&gt; Einstein-level brain) seems boldly o=\r\nptimistic to me.  But the big\n&gt; difference between our hypotheses is that y=\r\nou have no proof of concept\n&gt; for your approach while I do.  In your approa=\r\nch, you will set a target\n&gt; of Einstein and almost magically the algorithm =\r\nwill then deliver us\n&gt; Einstein, which no method has yet shown even the fai=\r\nntest sign of\n&gt; achieving.  In my approach, Einstein is not the target of t=\r\nhe search\n&gt; process but instead  appears as a byproduct of a search without=\r\n any\n&gt; explicit target, which is (amazingly) actually what happened in the =\r\nreal\n&gt; world!  It may be tempting to dismiss that distinction, but think ab=\r\nout\n&gt; it, the fact that any process actually *did* produce Einstein is beyo=\r\nnd\n&gt; incredible.  We should learn from that as much as we can before\n&gt; insi=\r\nsting &quot;there&#39;s got to be a better way.&quot;\n&gt; \n&gt; Of course, it&#39;s great that you=\r\n&#39;re searching for a better way (it sure\n&gt; would be nice if we could just se=\r\nt Einstein&#39;s IQ as a fitness target),\n&gt; but the things is, there will alway=\r\ns be a ton of people trying to follow\n&gt; that path because it&#39;s such a clean=\r\n and intuitively appealing notion. \n&gt; So it hardly needs a vigorous argumen=\r\nt to convince someone that it&#39;s\n&gt; important to try.  The danger is instead =\r\n that in such a rush of\n&gt; enthusiasm for intuitively appealing approaches, =\r\nwe sweep aside the much\n&gt; more delicate yet equally critical attempt to har=\r\nness evolution on its\n&gt; own terms, which leads to things like novelty searc=\r\nh, indirect encoding,\n&gt; and behavioral diversity.  The power of this proces=\r\ns may not be as clean\n&gt; and simple  as the optimization crowd is hoping; my=\r\n argument here guards\n&gt; against that danger.\n&gt; \n&gt; I think something similar=\r\n is going on in our fracture argument: In\n&gt; Picbreeder (and to some extent =\r\nEndlessforms too, which also uses CPPNs)\n&gt; we have perhaps the only massive=\r\n proof-of-concept that exists of\n&gt; fracture evolving through an artificial =\r\nencoding.  Picbreeder is a\n&gt; treasure trove of almost 10,000 examples, each=\r\n one with its own lesson\n&gt; to teach us on fracture.  And my argument is, si=\r\nnce we are fortunate\n&gt; enough to have this example right in front of us (li=\r\nke the example of\n&gt; natural evolution evolving Einstein), let&#39;s learn every=\r\nthing we can from\n&gt; it before looking away and saying hastily, &quot;there must =\r\nbe something\n&gt; better.&quot;  Picbreeder is a fortuitous goldmine of data that i=\r\ns very hard\n&gt; to  reproduce; it took several years and the contributions of=\r\n hundreds\n&gt; of  people to accumulate its results.  Let&#39;s scrub every last b=\r\nit of\n&gt; wisdom  from that windfall that we can.  It&#39;s not a question of bet=\r\nter\n&gt; for me, it&#39;s a question of learning from the only evidence we have.  =\r\nHow\n&gt; do you expect to really develop a better encoding of fracture if you\n=\r\n&gt; ignore the thousands of examples of fracture that already exist?  You\n&gt; w=\r\nill just end up reinventing the wheel.\n&gt; \n&gt; The danger of that is evident i=\r\nn some of the assumptions you hold\n&gt; already about how CPPNs encode fractur=\r\ne.  For example, you are worried\n&gt; that it may not do so efficiently, but y=\r\nou have only constructed a\n&gt; single thought experiment (your figure 13) ins=\r\ntead of taking a measured\n&gt; look at the thousands of examples in front of u=\r\ns.  In fact, while indeed\n&gt; I don&#39;t think 6 nodes is particularly much, it&#39;=\r\ns easy enough to find\n&gt; fracture in Picbreeder represented in under 6 nodes=\r\n.  For example, the\n&gt; pattern below has at least 3 distinct fractured regio=\r\nns (which I\n&gt; numbered for clarity): a pinkish region, an ovular inner regi=\r\non, and a\n&gt; conic lower region.  However, the CPPN that encodes it (shown t=\r\no its\n&gt; left) only uses 4 nodes to encode these 3 fractured regions (notice=\r\n that\n&gt; two of the displayed hidden nodes have outgoing weights of zero, so=\r\n they\n&gt; are not contributing to the output pattern, leaving only the 4 node=\r\ns). \n&gt; That&#39;s a respectable 1.3 nodes per fractured region:\n&gt; \n&gt; (this imag=\r\ne is also available at\n&gt; http://eplex.cs.ucf.edu/hyperNEATpage/content/four=\r\n-node-fracture.jpg\n&gt; &lt;http://eplex.cs.ucf.edu/hyperNEATpage/content/four-no=\r\nde-fracture.jpg&gt; \n&gt; )\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; We could argue about the definition of =\r\nfracture, and perhaps you&#39;d want\n&gt; to refine the definition to argue that t=\r\nhe above example doesn&#39;t really\n&gt; have three fractured regions.  Or you cou=\r\nld argue that the &quot;d&quot; input\n&gt; should be counted as a 5th node (to encode th=\r\ne 3 regions, which is still\n&gt; a respectable 1.7 nodes per region).  But eve=\r\nn those would be healthy\n&gt; discussions that we could not begin to have with=\r\nout first referring to\n&gt; the examples that we already have.  Of course (int=\r\nuitively) more complex\n&gt; fracture will require more nodes (maybe at some po=\r\nint 6!), as it should.\n&gt; All I&#39;m saying is I think this kind of speculation=\r\n about whether it&#39;s\n&gt; efficient or not is jumping the gun:  Let&#39;s understan=\r\nd it first before\n&gt; we worry about fixing it.\n&gt; \n&gt; So I think there&#39;s a dif=\r\nference of philosophies ultimately at work here.\n&gt; Because the road ahead t=\r\no AI is so vast, I&#39;m more motivated by\n&gt; maximizing our information than do=\r\ning &quot;better.&quot;  For example, that&#39;s the\n&gt; motivation behind Picbreeder - obv=\r\niously it is not quantifiably better\n&gt; than anything in particular, but it =\r\nincreased our understanding of a\n&gt; number of important phenomena, including=\r\n fracture, representation, and\n&gt; non-objective search, by providing useful =\r\ninformation.  So I say, let&#39;s\n&gt; see where this takes us - there&#39;s still a t=\r\non left to learn.  But you\n&gt; are already itching to start anew and fix thin=\r\ngs that are not clearly\n&gt; broken just when we have hit a goldmine of untapp=\r\ned information.\n&gt; \n&gt; Without question, neither of our perspectives is defin=\r\nitively superior;\n&gt; we are both merely speculating about where time is best=\r\n invested, and\n&gt; obviously neither of us can predict the future.  This argu=\r\nment is only\n&gt; my own case for my perspective.\n&gt; \n&gt; Best,\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; =\r\n--- In neat@yahoogroups.com, &quot;shimonw&quot;  wrote:\n&gt; &gt;\n&gt; &gt; Hi Ken,\n&gt; &gt;\n&gt; &gt; If I=\r\n may, I&#39;d like to offer a couple reactions to your latest message.\n&gt; This i=\r\ns indeed an interesting discussion that touches on many\n&gt; potentially impor=\r\ntant issues.  I hope I can offer a useful perspective\n&gt; on these topics.\n&gt; =\r\n&gt;\n&gt; &gt; You are right that in a target-based scenario there can be many CPPNs=\r\n\n&gt; that generate the same phenotype.  But the CPPN is a genotype, not a\n&gt; p=\r\nhenotype. In what I&#39;m calling &quot;regular&quot; FFs, there are potentially many\n&gt; *=\r\nphenotypes* that solve the problem, and for each of them potentially\n&gt; many=\r\n genotypes.  So in my mind, there is still a useful distinction\n&gt; between t=\r\narget based FFs and regular FFs, though they are perhaps best\n&gt; seen as dif=\r\nferent points on a spectrum.\n&gt; &gt;\n&gt; &gt; If I understand correctly, you are sug=\r\ngesting that the important\n&gt; distinction is how the FF interacts with the s=\r\nearch process.  But to me,\n&gt; this is a difficult criterion to use because t=\r\nhe search process could be\n&gt; anything.  The space of possible black-box opt=\r\nimization methods is huge,\n&gt; and what encourages piecewise incremental prog=\r\nress for one method may\n&gt; not for another.\n&gt; &gt;\n&gt; &gt; I don&#39;t pretend to know =\r\nwhat kind of algorithm would generate\n&gt; Einstein-level intelligence (I don&#39;=\r\nt even know if this is a useful\n&gt; goal). But as a researcher I highly respe=\r\nct once told me, &quot;your failure\n&gt; to imagine it does not constitute a proof =\r\nthat it cannot be done.&quot;\n&gt; &gt;\n&gt; &gt; That&#39;s why I think your hypothesis is quit=\r\ne a bold one, because it\n&gt; looks at the limitations of a specific class of =\r\nblack-box optimization\n&gt; methods and generalizes them to all possible black=\r\n-box optimization\n&gt; methods.\n&gt; &gt;\n&gt; &gt; To give just one example of the possib=\r\nilities here: algorithms for\n&gt; continuous-armed bandits, such as X-armed ba=\r\nndits and Bayesian\n&gt; optimization methods such as GP-UCB, can be applied to=\r\n black-box\n&gt; optimization.  These methods avoid the problem of local optima=\r\n in a\n&gt; principled way, by maintaining a posterior distribution over the gl=\r\nobal\n&gt; FF, and using optimism in the face of uncertainty to ensure sufficie=\r\nnt\n&gt; exploration of the solution space.  As a result, these methods have ve=\r\nry\n&gt; nice theoretical properties, like guaranteed convergence to the global=\r\n\n&gt; optimum in the limit and logarithmic regret bounds along the way.\n&gt; &gt;\n&gt; =\r\n&gt; As far as I know, no one has tried to develop versions of these\n&gt; methods=\r\n that can discover NN topologies, and which would thus be\n&gt; suitable for op=\r\ntimizing CPPNs or other indirect encodings.  But there&#39;s\n&gt; no a priori reas=\r\non to think it can&#39;t be done.  I&#39;m not saying this would\n&gt; necessarily work=\r\n or even that it&#39;s the most promising approach to\n&gt; explore.  I&#39;m just sayi=\r\nng it&#39;s one example of a principled approach that\n&gt; could avoid all the dif=\r\nficulties you mention and which we currently have\n&gt; no strong reason to eli=\r\nminate from contention.\n&gt; &gt;\n&gt; &gt; So I think it&#39;s quite likely that these har=\r\nd FFs are not unsolvable,\n&gt; but just that current methods cannot solve them=\r\n.  Rather than giving up\n&gt; on them, in my opinion we should be focusing on =\r\ndeveloping better\n&gt; methods for them.\n&gt; &gt;\n&gt; &gt; Regarding whether 6 nodes is =\r\na lot to represent fracture, I think the\n&gt; same point applies: just because=\r\n we can&#39;t think of a better way to do\n&gt; it, doesn&#39;t mean it doesn&#39;t exist. =\r\n Our paper establishes 6 as an upper\n&gt; bound, which can be easily done by e=\r\nxample.  If I understand correctly,\n&gt; you are suggesting that 6 may be a lo=\r\nwer bound, which is much more\n&gt; difficult to demonstrate.\n&gt; &gt;\n&gt; &gt; I could d=\r\nefinitely imagine that a different type of network, or one\n&gt; with a differe=\r\nnt set of activation functions, might be able to make\n&gt; better use of 6 nod=\r\nes.  Even if it&#39;s true that there&#39;s a trade-off, and\n&gt; using fewer nodes me=\r\nans less flexibility, there may be many cases where\n&gt; that&#39;s a favorable tr=\r\nade-off.  We should at least be open to the\n&gt; possibility that it some case=\r\ns the sweet spot is not a representation\n&gt; that requires 6 nodes for fractu=\r\nre.\n&gt; &gt;\n&gt; &gt; I&#39;m looking forward to chatting more about this at GECCO.\n&gt; &gt;\n&gt;=\r\n &gt; Cheers,\n&gt; &gt; Shimon\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com, &quot;Ken&quot; kstanley@ =\r\nwrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi Shimon,\n&gt; &gt; &gt;\n&gt; &gt; &gt; These are some really interesting=\r\n and deep issues we&#39;re getting\n&gt; into.  I\n&gt; &gt; &gt; am sure they will be the fo=\r\nundation of great discussions at GECCO. \n&gt; I&#39;ll\n&gt; &gt; &gt; try to keep my respon=\r\nse more brief than before.\n&gt; &gt; &gt;\n&gt; &gt; &gt; 1) Indeed recent quadruped results a=\r\nre not in the same setup as in\n&gt; your\n&gt; &gt; &gt; work; that is a legitimate qual=\r\nification and they do not constitute\n&gt; a\n&gt; &gt; &gt; proof that in your particula=\r\nr setup HyperNEAT would succeed. \n&gt; However,\n&gt; &gt; &gt; they are arguably at lea=\r\nst comparably complex.  For example, the\n&gt; CTRNN\n&gt; &gt; &gt; in\n&gt; &gt; &gt; http://eple=\r\nx.cs.ucf.edu/papers/risi_gecco13b.pdf\n&gt; &gt; &gt;    is a complicated\n&gt; &gt; &gt; struc=\r\nture and the CPPN that encodes it is required not only to\n&gt; generate\n&gt; &gt; &gt; =\r\na controller for a single quadruped morphology, but to generate\n&gt; multiple\n=\r\n&gt; &gt; &gt; controllers for multiple morphologies, all from the same CPPN.  A\n&gt; v=\r\nideo\n&gt; &gt; &gt; of three controllers all from the same CPPN is here:\n&gt; &gt; &gt; http:=\r\n//youtu.be/oLSSt5GyHNk\n&gt; &gt; &gt;\n&gt; &gt; &gt; 2) I think the question of what is &quot;targ=\r\net-based&quot; can actually be\n&gt; &gt; &gt; interesting, but I completely agree that th=\r\ne semantic side of the\n&gt; &gt; &gt; argument isn&#39;t really important.  But what I d=\r\no find interesting is\n&gt; the\n&gt; &gt; &gt; idea that these two scenarios differ subs=\r\ntantively in your mind (as\n&gt; you\n&gt; &gt; &gt; put it):\n&gt; &gt; &gt;\n&gt; &gt; &gt; &quot;there is an im=\r\nportant difference between FFs that require a single\n&gt; &gt; &gt; specific phenoty=\r\npe and FFs that require only that some goal be\n&gt; achieved&quot;\n&gt; &gt; &gt;\n&gt; &gt; &gt; I th=\r\nink by &quot;single specific phenotype&quot; you mean pattern-matching\n&gt; (i.e.\n&gt; &gt; &gt; =\r\nimage-matching).  But I think this distinction doesn&#39;t really exist:\n&gt; &gt; &gt; =\r\nThere are an unlimited number of networks (i.e. CPPNs) that can\n&gt; encode a\n=\r\n&gt; &gt; &gt; particular two-dimensional image, just as there are an unlimited\n&gt; nu=\r\nmber\n&gt; &gt; &gt; of CPPNs that can encode a particular behavior or goal (such as\n=\r\n&gt; &gt; &gt; following a line).\n&gt; &gt; &gt;\n&gt; &gt; &gt; What makes both target-based and funda=\r\nmentally the same is not the\n&gt; &gt; &gt; number of ways they can be solved, but r=\r\nather the way the fitness\n&gt; &gt; &gt; function interacts with the search process.=\r\n  The problem is that\n&gt; &gt; &gt; target-based fitness encourages piece-wise incr=\r\nemental progress,\n&gt; which\n&gt; &gt; &gt; tends to be highly deceptive.  For example,=\r\n with an image, matching\n&gt; a\n&gt; &gt; &gt; single pixel can raise fitness even if t=\r\nhe function that causes that\n&gt; &gt; &gt; pixel to be matched has no relationship =\r\nwhatsoever to the overall\n&gt; &gt; &gt; regularities in the target pattern.  The sa=\r\nme is true in control\n&gt; tasks:\n&gt; &gt; &gt; A mutation that causes a quadruped to =\r\nlunge forward clumsily is\n&gt; rewarded\n&gt; &gt; &gt; for the slight improvement in fi=\r\ntness, whereas an important\n&gt; underlying\n&gt; &gt; &gt; regularity (e.g. oscillation=\r\n) necessary to get really good at the\n&gt; task\n&gt; &gt; &gt; is never established.  N=\r\non-target-based fitness (or what I call\n&gt; &gt; &gt; &quot;non-objective&quot;) avoids these=\r\n problems because it *does* reward\n&gt; &gt; &gt; establishing regularities: it appr=\r\neciates new regularities even if\n&gt; they\n&gt; &gt; &gt; don&#39;t immediately raise fitne=\r\nss.\n&gt; &gt; &gt;\n&gt; &gt; &gt; But what&#39;s most interesting to me is your intuition that th=\r\nere is\n&gt; some\n&gt; &gt; &gt; way to sidestep the tradeoff in combining indirect enco=\r\ndings with\n&gt; &gt; &gt; target-based fitness functions.  That is, you suspect ther=\r\ne may\n&gt; exist an\n&gt; &gt; &gt; indirect encoding that can both elaborate regulariti=\r\nes\n&gt; compositionally\n&gt; &gt; &gt; over very many generations and also almost deter=\r\nministically satisfy\n&gt; an\n&gt; &gt; &gt; arbitrary target-based objective.  I am con=\r\nvinced that is not the\n&gt; case\n&gt; &gt; &gt; (it would be too good to be true), but =\r\nyou rightly point out that my\n&gt; &gt; &gt; position is a hypothesis.   However, ju=\r\nst as a thought experiment,\n&gt; can\n&gt; &gt; &gt; you really imagine any neural netwo=\r\nrk encoding (including DNA) that\n&gt; &gt; &gt; would give you Einstein-level intell=\r\nigence if the target was simply\n&gt; to\n&gt; &gt; &gt; score maximally on an IQ test?  =\r\nIt is plain to me that the stepping\n&gt; &gt; &gt; stones to human level cannot be c=\r\nrossed in the presence of a\n&gt; &gt; &gt; target-based objective (or any one concei=\r\nvable).  However,\n&gt; &gt; &gt; interestingly, that does not mean that such a neura=\r\nl network does\n&gt; not\n&gt; &gt; &gt; exist in the search space.  It just means a targ=\r\net won&#39;t get you\n&gt; there.\n&gt; &gt; &gt;\n&gt; &gt; &gt; 3) We apparently disagree on whether =\r\n6 is a big number (for nodes\n&gt; needed\n&gt; &gt; &gt; to represent fracture).  If you=\r\n try to devise an encoding that\n&gt; &gt; &gt; represents fracture with fewer than t=\r\nhat, my intuition is that you\n&gt; would\n&gt; &gt; &gt; be sacrificing an enormous brea=\r\ndth of flexibility in the kinds of\n&gt; &gt; &gt; fracture (and patterns in general)=\r\n that you can represent.  Think\n&gt; about\n&gt; &gt; &gt; the number of &quot;degrees of fre=\r\nedom&quot; in fracture: it&#39;s not really\n&gt; &gt; &gt; well-defined, but a single line of=\r\n fracture has a lot of dimensions:\n&gt; &gt; &gt;\n&gt; &gt; &gt; -position\n&gt; &gt; &gt; -orientation=\r\n\n&gt; &gt; &gt; -curvature (which can be arbitrarily complex)\n&gt; &gt; &gt; -fracture gradie=\r\nnt (that is, one region can smoothly transition into\n&gt; &gt; &gt; another in a kin=\r\nd of interpolated transitional zone)\n&gt; &gt; &gt; -embedding (fracture can potenti=\r\nally be hierarchical or regular,\n&gt; i.e.\n&gt; &gt; &gt; dependent on higher-level con=\r\ntaining regions)\n&gt; &gt; &gt;\n&gt; &gt; &gt; The idea that all of that can be encoded in an=\r\nything less than about\n&gt; 6\n&gt; &gt; &gt; simple functions seems optimistic.  Of cou=\r\nrse, if you are willing to\n&gt; &gt; &gt; sacrifice some of those degrees of freedom=\r\n, then you can get fewer\n&gt; &gt; &gt; nodes, but the exquisite minutia of such pat=\r\nterns would be lost (and\n&gt; &gt; &gt; you&#39;d move more towards direct encoding, lik=\r\ne the wavelets do).\n&gt; &gt; &gt;\n&gt; &gt; &gt; By the way, here are some cool examples of =\r\ncomplicated kinds of\n&gt; fracture\n&gt; &gt; &gt; from Picbreeder (such as fractured pe=\r\nriodic zones, but even more\n&gt; complex\n&gt; &gt; &gt; than even that):\n&gt; &gt; &gt;\n&gt; &gt; &gt; No=\r\nntrivial color patterns in each zone:\n&gt; &gt; &gt; http://picbreeder.org/search/sh=\r\nowgenome.php?sid=3D11328\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; Very complex brush-stroke patter=\r\nn inside the apple vs. outside (the\n&gt; DNA\n&gt; &gt; &gt; for this one is fascinating=\r\n):\n&gt; &gt; &gt; http://picbreeder.org/search/showgenome.php?sid=3D7109\n&gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n\n&gt; &gt; &gt;\n&gt; &gt; &gt; Fractured regions covering a distorted surface, giving a remar=\r\nkable\n&gt; &gt; &gt; underlying curvature:\n&gt; &gt; &gt; http://picbreeder.org/search/showge=\r\nnome.php?sid=3D2684\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; A color variant:\n&gt; http://picbreeder.=\r\norg/search/showgenome.php?sid=3D6652\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; When I see so many r=\r\nemarkable examples like these on Picbreeder, the\n&gt; &gt; &gt; message to me is tha=\r\nt we have only scratched the surface of what\n&gt; CPPN\n&gt; &gt; &gt; encoding can teac=\r\nh us about representation.  That&#39;s why I think it&#39;s\n&gt; &gt; &gt; premature (in the=\r\n face of such a treasure trove of evidence) to be\n&gt; &gt; &gt; worrying about whet=\r\nher we can represent some subcomponent of such\n&gt; &gt; &gt; patterns with less tha=\r\nn 6 nodes.  At present I&#39;m amazed they can be\n&gt; &gt; &gt; represented at all, let=\r\n alone with under 6 nodes.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Thanks very much for raising these i=\r\nssues in any case - it&#39;s a great\n&gt; &gt; &gt; debate to have about representation =\r\nand search and goes to the heart\n&gt; of\n&gt; &gt; &gt; the field of GDS/indirect encod=\r\ning.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Best,\n&gt; &gt; &gt;\n&gt; &gt; &gt; ken\n&gt; &gt; &gt;\n&gt; &gt; &gt; --- In neat@yahoogroups.=\r\ncom, &quot;shimonw&quot;  wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Thanks for y=\r\nour interesting and thought-provoking comments.  I&#39;ll\n&gt; give\n&gt; &gt; &gt; some bri=\r\nef reactions here, and I hope we can have a productive\n&gt; &gt; &gt; discussion abo=\r\nut it at GECCO.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 1) I won&#39;t comment for now on the new exper=\r\niments you&#39;ve been\n&gt; running\n&gt; &gt; &gt; because the details are not available ye=\r\nt.  Instead, I will just\n&gt; comment\n&gt; &gt; &gt; on the various walking gait domain=\r\ns, because the details of the\n&gt; &gt; &gt; additional results you mentioned are in=\r\n that case already available,\n&gt; in\n&gt; &gt; &gt; newly published GECCO papers.\n&gt; &gt; =\r\n&gt; &gt;\n&gt; &gt; &gt; &gt; FIrst of all, these are very cool results, and nice success\n&gt; s=\r\ntories\n&gt; &gt; &gt; for HyperNEAT.  It&#39;s great to see that the GDS community is\n&gt; =\r\ncontinuing\n&gt; &gt; &gt; the push the envelope in terms of robot locomotion, which =\r\nseems to\n&gt; be\n&gt; &gt; &gt; emerging as a nice application for indirect encodings.\n=\r\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; However, I would simply caution against placing all these\n&gt;=\r\n variations\n&gt; &gt; &gt; on the walking gait task on a one-dimensional spectrum of=\r\n\n&gt; difficulty.\n&gt; &gt; &gt; In our paper, we took the orignal walking gait task an=\r\nd made only\n&gt; one\n&gt; &gt; &gt; change (increasing the mass of the torso) which cle=\r\narly makes the\n&gt; task\n&gt; &gt; &gt; harder.  In the papers Ken mentioned, there are=\r\n other differences,\n&gt; e.g.,\n&gt; &gt; &gt; the use of an SUPG encoding, the use of C=\r\nTRNNs, the use of a\n&gt; different\n&gt; &gt; &gt; substrate topology, and varying the l=\r\nength of the legs.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; It&#39;s completely legitimate to make these=\r\n changes and they don&#39;t\n&gt; &gt; &gt; detract from the results at all.   But they a=\r\nre confounding factors\n&gt; when\n&gt; &gt; &gt; it comes to comparing HyperNEAT&#39;s perfo=\r\nrmance on walking gait tasks\n&gt; of\n&gt; &gt; &gt; different difficulties.  Some of th=\r\nese changes may make the task\n&gt; harder\n&gt; &gt; &gt; in some ways but other changes=\r\n may make it easier in others ways,\n&gt; and so\n&gt; &gt; &gt; far we don&#39;t have experi=\r\nmental results that control for these\n&gt; factors.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 2) I hope =\r\nto avoid a semantic debate about what is a\n&gt; &quot;target-based&quot;\n&gt; &gt; &gt; FF.  If y=\r\nou want to include what I was calling a &quot;regular&quot; FF in the\n&gt; &gt; &gt; scope of =\r\ntarget-based FFs, I won&#39;t object.  But my point is that,\n&gt; &gt; &gt; regardless o=\r\nf what you call them, there is an important difference\n&gt; &gt; &gt; between FFs th=\r\nat require a single specific phenotype and FFs that\n&gt; &gt; &gt; require only that=\r\n some goal be achieved.  For the latter, there may\n&gt; be\n&gt; &gt; &gt; many ways to =\r\nskin the cat, though in any interesting problem, good\n&gt; &gt; &gt; solutions are s=\r\ntill quite rare.  The distinction is important\n&gt; because,\n&gt; &gt; &gt; while the f=\r\normer category is arguably only of theoretical interest,\n&gt; the\n&gt; &gt; &gt; second=\r\n category corresponds to what I consider the most interesting\n&gt; and\n&gt; &gt; &gt; i=\r\nmportant class of FFs, because these are the FFs that naturally\n&gt; arise\n&gt; &gt;=\r\n &gt; in a very large number of real-world optimization problems.\n&gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; So, using your terminology, I agree it is reasonable to say\n&gt; &gt; &gt; Hyper=\r\nNEAT&#39;s difficulties with fracture are probably limited to\n&gt; &gt; &gt; &quot;target-bas=\r\ned&quot; FFs.  But for me, this is a potentially serious\n&gt; &gt; &gt; restriction, sinc=\r\ne target-based FFs include not just pathological\n&gt; FFs\n&gt; &gt; &gt; but a large cl=\r\nass of real-world FFs.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Regarding the wavelet method, I woul=\r\nd still definitely call this\n&gt; an\n&gt; &gt; &gt; indirect encoding, but it is in som=\r\ne sense &quot;less indirect&quot; because\n&gt; it\n&gt; &gt; &gt; lacks the compositional function=\r\ns of HyperNEAT. It&#39;s a perfectly\n&gt; &gt; &gt; reasonable hypothesis that such comp=\r\nositionality is advantageous in\n&gt; some\n&gt; &gt; &gt; ways.  However, if that&#39;s true=\r\n, then we should be able to\n&gt; demonstrate\n&gt; &gt; &gt; that by finding tasks where=\r\n HyperNEAT outperforms the wavelet method\n&gt; &gt; &gt; (FYI, in the extended analy=\r\nsis Thomas is conducting for his master&#39;s\n&gt; &gt; &gt; thesis, we have found one v=\r\nariation of the line-following task where\n&gt; &gt; &gt; this is the case).  So in t=\r\nhat sense, the wavelet method is a useful\n&gt; &gt; &gt; baseline, which is the whol=\r\ne reason we introduced it.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 3) If it&#39;s true that it takes ~6=\r\n nodes to represent fracture, then\n&gt; I\n&gt; &gt; &gt; think this a potentially impor=\r\ntant point.  On regular FFs, it could\n&gt; &gt; &gt; contribute to the difficulty of=\r\n discovering fracture, since\n&gt; &gt; &gt; representations that have only some of t=\r\nhe necessary components may\n&gt; not\n&gt; &gt; &gt; be rewarded (I think you would call=\r\n this &quot;deception&quot;).  In\n&gt; &gt; &gt; Picbreeder-like tasks, we already see that fr=\r\nacture can evolve\n&gt; anyway,\n&gt; &gt; &gt; but this doesn&#39;t mean it wouldn&#39;t do it e=\r\nven better if fracture\n&gt; required\n&gt; &gt; &gt; fewer nodes to represent.  If we th=\r\nink that the solutions to many\n&gt; &gt; &gt; interesting problems require fracture,=\r\n then I think it&#39;s at least\n&gt; &gt; &gt; possible that one could devise a better r=\r\nepresentation for such\n&gt; problems\n&gt; &gt; &gt; than the CPPNs used in HyperNEAT.\n&gt;=\r\n &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; As I understand it, your approach to dealing with &quot;regular&quot; =\r\nFFs is\n&gt; to\n&gt; &gt; &gt; reformulate them &quot;in a way that respects the need for phe=\r\nnotypic\n&gt; &gt; &gt; diversity and open-endedness.&quot;  That&#39;s a very interesting app=\r\nroach\n&gt; and I\n&gt; &gt; &gt; think it has a lot of merit, but I don&#39;t think it will =\r\nsolve all our\n&gt; &gt; &gt; problems because it presupposes that such a reformulati=\r\non is\n&gt; possible\n&gt; &gt; &gt; (or that the prior knowledge it requires is availabl=\r\ne).  In some\n&gt; cases,\n&gt; &gt; &gt; I think we are just stuck with hard FFs and we =\r\nneed to develop\n&gt; better\n&gt; &gt; &gt; methods to deal with them.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; R=\r\negarding the idea that &quot;an unhappy and unhealthy indirect\n&gt; encoding is\n&gt; &gt;=\r\n &gt; one with only a strict target to which to aspire&quot;: this is a very\n&gt; &gt; &gt; =\r\nintriguing hypothesis, but to me it is only a hypothesis.  I think\n&gt; it&#39;s\n&gt;=\r\n &gt; &gt; true of existing indirect encodings, but that for me does not in any\n&gt;=\r\n way\n&gt; &gt; &gt; rule out the possibility of developing a different indirect enco=\r\nding\n&gt; for\n&gt; &gt; &gt; which that is not true, and I think that&#39;s one thing we sh=\r\nould be\n&gt; &gt; &gt; working on.   One of the reasons that I&#39;m interested in indir=\r\nect\n&gt; &gt; &gt; encodings is that I strongly believe this can be done.\n&gt; &gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; &gt; Shimon\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n"}}