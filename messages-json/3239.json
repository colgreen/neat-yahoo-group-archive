{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":37465196,"authorName":"Ken Lloyd","from":"&quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;","profile":"kalloyd2","replyTo":"LIST","senderId":"S-NUfYkG_tqX-9Slrvyi4rUCSpYEEcHfazkTMiFUVcXrFJnpu0YKNawVNTgGb1G0sPIIrzy4LaQDogz5uIt0iLfLXb6WZnCN","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [neat] Re: HyperNEAT experiment ..","postDate":"1178044049","msgId":3239,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAxNmMwMWM3OGMxZSQ2M2IxMjYxMCQ2NDAxYThjMEB3YXR0cDQ+","inReplyToHeader":"PGYxN3VlbStscTk4QGVHcm91cHMuY29tPg==","referencesHeader":"PEYzODY2M0MwLTc1MzUtNDYxOS1BRjc0LTNEQTM3QTA0MDNDQ0B3YWl0cy5uZXQ+IDxmMTd1ZW0rbHE5OEBlR3JvdXBzLmNvbT4="},"prevInTopic":3237,"nextInTopic":3240,"prevInTime":3238,"nextInTime":3240,"topicId":3232,"numMessagesInTopic":8,"msgSnippet":"Petar, I have used a n-dimensional context space to hold the input and output nodes, and embed the hidden nodes (graph)  - genome dual in that space. If you","rawEmail":"Return-Path: &lt;kalloyd@...&gt;\r\nX-Sender: kalloyd@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 69665 invoked from network); 1 May 2007 18:35:11 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m44.grp.scd.yahoo.com with QMQP; 1 May 2007 18:35:11 -0000\r\nReceived: from unknown (HELO wattsys.com) (209.43.123.15)\n  by mta10.grp.scd.yahoo.com with SMTP; 1 May 2007 18:35:11 -0000\r\nReceived: from wattp4 (c-68-35-191-92.hsd1.nm.comcast.net [68.35.191.92])\n\tby wattsys.com (8.11.6/8.11.6) with ESMTP id l41IR7i26543\n\tfor &lt;neat@yahoogroups.com&gt;; Tue, 1 May 2007 14:27:07 -0400\r\nTo: &lt;neat@yahoogroups.com&gt;\r\nReferences: &lt;F38663C0-7535-4619-AF74-3DA37A0403CC@...&gt; &lt;f17uem+lq98@...&gt;\r\nDate: Tue, 1 May 2007 12:27:29 -0600\r\nMessage-ID: &lt;016c01c78c1e$63b12610$6401a8c0@wattp4&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_016D_01C78BEC.1916B610&quot;\r\nX-Mailer: Microsoft Office Outlook 11\r\nIn-Reply-To: &lt;f17uem+lq98@...&gt;\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.3028\r\nThread-Index: AceMGSEOFlT+ApE3SamTcDGKVvvXoQAA83Zg\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: &quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;\r\nSubject: RE: [neat] Re: HyperNEAT experiment ..\r\nX-Yahoo-Group-Post: member; u=37465196; y=bP-bfO9QLSr193bEhlJS5k9TqszCIFLTsllzRKoK1BkRqsc\r\nX-Yahoo-Profile: kalloyd2\r\n\r\n\r\n------=_NextPart_000_016D_01C78BEC.1916B610\r\nContent-Type: text/plain;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: 7bit\r\n\r\nPetar,\n \nI have used a n-dimensional context space to hold the input and output\nnodes, and embed the hidden nodes (graph)  - genome dual in that space.\n \nIf you use a 3D representation, you can always project in down to 2D by\nreciprocal homogeneous w values if necessary.  \n \nWhile this may be computationally expensive there are ways of using the\nprocessing power of your GPU to do the number crunching without involving\nmuch CPU processing.  c.f. NVIDIA&#39;s CUDA.\n \nKen\n \n \n\n\n\n  _____  \n\nFrom: neat@yahoogroups.com [mailto:neat@yahoogroups.com] On Behalf Of\npetar_chervenski\nSent: Tuesday, May 01, 2007 11:47 AM\nTo: neat@yahoogroups.com\nSubject: [neat] Re: HyperNEAT experiment ..\n\n\n\nYes, a 2D space was the first realization. But things got complicated \nmainly because there is no way to make a matrix-like input layer, and \nto place the hidden and output nodes in positions that are meaningful. \nAn intuitive idea is to put the output at the center and the inputs and \nhidden neurons around it, but then it becomes not a visual field, you \nknow, a grid of inputs. The solution was to add an extra dimention and \nto put the hidden and output nodes behind the input layer, not on it. \nI think this is good, even in reality there are only 3D neural \nnetworks, 2D is just a simplification. \nSomeone had mentioned that a roving eye is a controller and a \nclassifier at the same time. I guess it is hard for HyperNEAT to figure \nout how to control the eye at first. This is very important. \nCurrently I am trying out Jason&#39;s suggestion about it (normalizing the \ninputs to avoid the multiplication problem.), but it still doesn&#39;t \nlearn to find the shape on the field. \nPerhaps I should not use a roving eye at all? \n\n--- In neat@yahoogroups. &lt;mailto:neat%40yahoogroups.com&gt; com, Stephen Waits\n&lt;steve@...&gt; wrote:\n&gt;\n&gt; \n&gt; On May 1, 2007, at 4:51 AM, petar_chervenski wrote:\n&gt; \n&gt; &gt; The\n&gt; &gt; substrate space is 3D cartesian.\n&gt; \n&gt; Have you tried it on a 2D space? Perhaps the extra dimension is \n&gt; stretching the NEAT part of HyperNEAT a bit too far for this problem?\n&gt; \n&gt; --Steve\n&gt;\n\n\n\n \n\n\r\n------=_NextPart_000_016D_01C78BEC.1916B610\r\nContent-Type: text/html;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.=\r\nw3c.org/TR/1999/REC-html401-19991224/loose.dtd&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;\n&lt;META http-eq=\r\nuiv=3DContent-Type content=3D&quot;text/html; charset=3Dus-ascii&quot;&gt;&lt;!-- Network c=\r\nontent --&gt;\n&lt;META content=3D&quot;MSHTML 6.00.6000.16414&quot; name=3DGENERATOR&gt;&lt;/HEAD=\r\n&gt;\n&lt;BODY style=3D&quot;BACKGROUND-COLOR: #ffffff&quot;&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;F=\r\nONT face=3DArial color=3D#0000ff size=3D2&gt;&lt;SPAN \nclass=3D843091718-01052007=\r\n&gt;Petar,&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial =\r\ncolor=3D#0000ff size=3D2&gt;&lt;SPAN \nclass=3D843091718-01052007&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&n=\r\nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial color=3D#0000ff s=\r\nize=3D2&gt;&lt;SPAN \nclass=3D843091718-01052007&gt;I have used a n-dimensional conte=\r\nxt space to hold the \ninput and output nodes, and embed the hidden nodes (g=\r\nraph)&nbsp; -&nbsp;genome \ndual&nbsp;in that space.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DI=\r\nV dir=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;&lt;SPAN =\r\n\nclass=3D843091718-01052007&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=\r\n=3Dleft&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;&lt;SPAN \nclass=3D84309171=\r\n8-01052007&gt;If you use a 3D representation, you can always project \nin down =\r\nto 2D by reciprocal homogeneous w values if necessary.&nbsp; \n&lt;/SPAN&gt;&lt;/FONT=\r\n&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial color=3D#0000ff size=\r\n=3D2&gt;&lt;SPAN \nclass=3D843091718-01052007&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV dir=\r\n=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;&lt;SPAN \nclas=\r\ns=3D843091718-01052007&gt;While this may be computationally expensive there ar=\r\ne \nways of using the processing power of your GPU to do the number crunchin=\r\ng \nwithout&nbsp;involving much CPU processing.&nbsp; c.f. NVIDIA&#39;s \nCUDA.&lt;/=\r\nSPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial color=3D#=\r\n0000ff size=3D2&gt;&lt;SPAN \nclass=3D843091718-01052007&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV=\r\n&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;&lt;=\r\nSPAN \nclass=3D843091718-01052007&gt;Ken&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT face=3D=\r\nArial color=3D#0000ff size=3D2&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV align=3Dleft&gt;&lt;FONT =\r\nface=3DArial size=3D2&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;&lt;FONT face=3DArial \nsize=3D2&gt;&lt;/FON=\r\nT&gt;&lt;BR&gt;\n&lt;BLOCKQUOTE \nstyle=3D&quot;PADDING-LEFT: 5px; MARGIN-LEFT: 5px; BORDER-LE=\r\nFT: #0000ff 2px solid; MARGIN-RIGHT: 0px&quot;&gt;\n  &lt;DIV class=3DOutlookMessageHea=\r\nder lang=3Den-us dir=3Dltr align=3Dleft&gt;\n  &lt;HR tabIndex=3D-1&gt;\n  &lt;FONT face=\r\n=3DTahoma size=3D2&gt;&lt;B&gt;From:&lt;/B&gt; neat@yahoogroups.com \n  [mailto:neat@yahoog=\r\nroups.com] &lt;B&gt;On Behalf Of \n  &lt;/B&gt;petar_chervenski&lt;BR&gt;&lt;B&gt;Sent:&lt;/B&gt; Tuesday,=\r\n May 01, 2007 11:47 \n  AM&lt;BR&gt;&lt;B&gt;To:&lt;/B&gt; neat@yahoogroups.com&lt;BR&gt;&lt;B&gt;Subject:=\r\n&lt;/B&gt; [neat] Re: HyperNEAT \n  experiment ..&lt;BR&gt;&lt;/FONT&gt;&lt;BR&gt;&lt;/DIV&gt;\n  &lt;DIV&gt;&lt;/DI=\r\nV&gt;\n  &lt;DIV id=3Dygrp-text&gt;\n  &lt;P&gt;Yes, a 2D space was the first realization. B=\r\nut things got complicated \n  &lt;BR&gt;mainly because there is no way to make a m=\r\natrix-like input layer, and \n  &lt;BR&gt;to place the hidden and output nodes in =\r\npositions that are meaningful. \n  &lt;BR&gt;An intuitive idea is to put the outpu=\r\nt at the center and the inputs and \n  &lt;BR&gt;hidden neurons around it, but the=\r\nn it becomes not a visual field, you \n  &lt;BR&gt;know, a grid of inputs. The sol=\r\nution was to add an extra dimention and \n  &lt;BR&gt;to put the hidden and output=\r\n nodes behind the input layer, not on it. \n  &lt;BR&gt;I think this is good, even=\r\n in reality there are only 3D neural \n  &lt;BR&gt;networks, 2D is just a simplifi=\r\ncation. &lt;BR&gt;Someone had mentioned that a \n  roving eye is a controller and =\r\na &lt;BR&gt;classifier at the same time. I guess it \n  is hard for HyperNEAT to f=\r\nigure &lt;BR&gt;out how to control the eye at first. This \n  is very important. &lt;=\r\nBR&gt;Currently I am trying out Jason&#39;s suggestion about it \n  (normalizing th=\r\ne &lt;BR&gt;inputs to avoid the multiplication problem.), but it \n  still doesn&#39;t=\r\n &lt;BR&gt;learn to find the shape on the field. &lt;BR&gt;Perhaps I should \n  not use =\r\na roving eye at all? &lt;BR&gt;&lt;BR&gt;--- In &lt;A \n  href=3D&quot;mailto:neat%40yahoogroups=\r\n.com&quot;&gt;neat@yahoogroups.&lt;WBR&gt;com&lt;/A&gt;, Stephen \n  Waits &lt;steve@...&gt; wro=\r\nte:&lt;BR&gt;&gt;&lt;BR&gt;&gt; &lt;BR&gt;&gt; On May 1, 2007, at \n  4:51 AM, petar_chervensk=\r\ni wrote:&lt;BR&gt;&gt; &lt;BR&gt;&gt; &gt; The&lt;BR&gt;&gt; &gt; \n  substrate space is 3D ca=\r\nrtesian.&lt;BR&gt;&gt; &lt;BR&gt;&gt; Have you tried it on a 2D \n  space? Perhaps the e=\r\nxtra dimension is &lt;BR&gt;&gt; stretching the NEAT part of \n  HyperNEAT a bit t=\r\noo far for this problem?&lt;BR&gt;&gt; &lt;BR&gt;&gt; \n  --Steve&lt;BR&gt;&gt;&lt;BR&gt;&lt;BR&gt;&lt;/P&gt;&lt;/D=\r\nIV&gt;&lt;!--End group email --&gt;&lt;/BLOCKQUOTE&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_016D_01C78BEC.1916B610--\r\n\n"}}