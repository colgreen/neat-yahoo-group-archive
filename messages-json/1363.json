{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"gcFkOKqztNSd4INtUe8h8zNx5Whh3JTAkRVrkcAbPnaaxWdQGqvLK8ga7zXEtJ1at-EKl6CYe-wGu8_J-dBLsxV-2NX8V5XO8Dw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] IEX update","postDate":"1092237154","msgId":1363,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMS4yLjAuMC4yMDA0MDgxMTE2MDUwMC4wMjUzYjNjOEBwb3AubWFpbC55YWhvby5jby51az4=","inReplyToHeader":"PDQxMTI4QjNGLjcwNjA5MDRAZHNsLnBpcGV4LmNvbT4=","referencesHeader":"PEJBWTItRjM2MWk2YmRWSldyR1cwMDA3MGMzOUBob3RtYWlsLmNvbT4gPDQxMTI4QjNGLjcwNjA5MDRAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":1361,"nextInTopic":1368,"prevInTime":1362,"nextInTime":1364,"topicId":1176,"numMessagesInTopic":38,"msgSnippet":"... Hi, No, I think John s case is different.  He avoids over fitting by using a range of pictures but his graded increase of magnification values is a","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 22806 invoked from network); 11 Aug 2004 15:13:36 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m2.grp.scd.yahoo.com with QMQP; 11 Aug 2004 15:13:36 -0000\r\nReceived: from unknown (HELO smtp002.mail.ukl.yahoo.com) (217.12.11.33)\n  by mta6.grp.scd.yahoo.com with SMTP; 11 Aug 2004 15:13:36 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp002.mail.ukl.yahoo.com with SMTP; 11 Aug 2004 15:13:35 -0000\r\nMessage-Id: &lt;6.1.2.0.0.20040811160500.0253b3c8@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.1.2.0\r\nDate: Wed, 11 Aug 2004 16:12:34 +0100\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;41128B3F.7060904@...&gt;\r\nReferences: &lt;BAY2-F361i6bdVJWrGW00070c39@...&gt;\n &lt;41128B3F.7060904@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Remote-IP: 217.12.11.33\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] IEX update\r\nX-Yahoo-Group-Post: member; u=7192225\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nAt 20:32 05/08/2004, you wrote:\n&gt;John Arrowwood wrote:\n&gt;\n&gt; &gt;I&#39;ve restarted the experiment with it being required to be successful at\n&gt; &gt;enlargement before it does reduction.  It&#39;s proceeding much faster now!\n&gt; &gt;\n&gt; &gt;I also took a long hard look at how MUCH enlargement I was asking of it.\n&gt; &gt;16x is too much to ask it to try to learn on.  So I made a minor\n&gt; &gt;modification that lets me first train it to do  2x.  Once it appears to be\n&gt; &gt;able to do 2x, I can up the expected amount of enlargement to 3x, 4x, 5x,\n&gt; &gt;and so on, until I max out forward progress.  That should make things\n&gt; &gt;progress much faster.  But we&#39;ll have to wait and see if theory meets\n&gt; &gt;reality. :)\n&gt; &gt;\n&gt; &gt;\n&gt;Hi John,\n&gt;\n&gt;I suppose if you take the logic that we applied to Chad&#39;s cross product\n&gt;problem then it would make more sense to test against a spread of\n&gt;enlargement/reduction factors on each evaluation. Otherwise you might\n&gt;see overfitting at the enlargement end of the scale similar to the\n&gt;signal averaging you observed with reduction.  I guess that would slow\n&gt;your experiment down quite a lot though huh :(\n&gt;\n&gt;Colin\n\nHi,\n         No, I think John&#39;s case is different.  He avoids over fitting by \nusing a range of pictures but his graded increase of magnification values \nis a legitimate attempt to start simple and work up.  Of course, if the \nsteps in complexity are too steep then the system will not be able to carry \nanything useful over from one to the next, but that&#39;s something to wait for \nin the results.\n\n         To come back to a question I touched on before.  Are all these \nimages from the same domain?  e.g. are you training the network to fill in \ndetail which can reasonably be expected to be in same way &quot;consistent&quot; from \nimage to image.  If you are not, and the images are drawn from anywhere, \nthen the task is impossible because one can readily construct a set of \nimages which all average to the same reduced data and the net won&#39;t succeed \nat them all.  Note that a &quot;domain&quot; could be as wide as &quot;photos&quot;, however...\n\n         Ian Badcoe\n\n\n\nLiving@Home - Open Source Evolving Organisms - \nhttp://livingathome.sourceforge.net/\n\n\n\n\n"}}