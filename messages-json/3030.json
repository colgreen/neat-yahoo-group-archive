{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"2tf8r_Cs6prcbCB7ICAf9rE1DVX4Meba0707kGTN6_FbrtIn7trqsZ3mB8t2nBPi44JB1gYSofTCurhNk97UF16jlvRt1FfSAVmxtY7wa5Hz27phMss","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HyperNEAT: Creating Neural Networks with CPPNs","postDate":"1174896780","msgId":3030,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV1N3ZhYythcWF2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGV1NDh1cSt0Y2pvQGVHcm91cHMuY29tPg=="},"prevInTopic":3029,"nextInTopic":3031,"prevInTime":3029,"nextInTime":3031,"topicId":3028,"numMessagesInTopic":34,"msgSnippet":"Hi Ken. I was waiting for these publications to come out, I was checking the Publications page every single day :) Now I m so excited. This is a great idea, I","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 79314 invoked from network); 26 Mar 2007 08:13:37 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m42.grp.scd.yahoo.com with QMQP; 26 Mar 2007 08:13:37 -0000\r\nReceived: from unknown (HELO n26c.bullet.sp1.yahoo.com) (209.131.38.242)\n  by mta5.grp.scd.yahoo.com with SMTP; 26 Mar 2007 08:13:37 -0000\r\nReceived: from [216.252.122.218] by n26.bullet.sp1.yahoo.com with NNFMP; 26 Mar 2007 08:13:02 -0000\r\nReceived: from [209.73.164.86] by t3.bullet.sp1.yahoo.com with NNFMP; 26 Mar 2007 08:13:02 -0000\r\nReceived: from [66.218.66.74] by t8.bullet.scd.yahoo.com with NNFMP; 26 Mar 2007 08:13:02 -0000\r\nDate: Mon, 26 Mar 2007 08:13:00 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;eu7vac+aqav@...&gt;\r\nIn-Reply-To: &lt;eu48uq+tcjo@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: HyperNEAT: Creating Neural Networks with CPPNs\r\nX-Yahoo-Group-Post: member; u=283334584; y=V2baSGhE_h3fz8BWXo1r2SF3SIL3Xehmiy0kxhz5-s49UDbhVXojHaJYCA\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi Ken. I was waiting for these publications to come out, I was \nchecking t=\r\nhe Publications page every single day :) Now I&#39;m so \nexcited. This is a gre=\r\nat idea, I will even try to do some \nexperiments. :) I&#39;ll try to extend the=\r\n rtNEAT release further to be \nable to evolve those CPPNs, as I did with th=\r\ne CTRNN networks. \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;=\r\nkstanley@...&gt; wrote:\n&gt;\n&gt; Hi everyone, as some of you know, we have been wor=\r\nking for a while \n&gt; now on turning the patterns output by CPPNs into neural=\r\n networks.  \n&gt; \n&gt; I am excited to report that we have found a \n&gt; straightfo=\r\nrward and principled approach to interpreting CPPN output \n&gt; as a connectiv=\r\nity pattern rather than a spatial pattern.    We are \n&gt; calling this method=\r\n HyperNEAT, which stands for Hypercube-based \n&gt; NEAT.  With HyperNEAT, we h=\r\nave been able to produce working neural \n&gt; networks with millions of connec=\r\ntions.\n&gt; \n&gt; Because we have just recently had two publications on this meth=\r\nod \n&gt; accepted at GECCO-2007, we can finally disclose our work and share \n&gt;=\r\n it with others.  The publications are available on \n&gt; the &quot;Publications&quot; p=\r\nage at http://eplex.cs.ucf.edu \n&gt; \n&gt; They are also available through my hom=\r\nepage \n&gt; http://www.cs.ucf.edu/~kstanley/#publications (under Publications,=\r\n \n&gt; Conference and Symposium Papers), or directly at the following \n&gt; addre=\r\nss, which I am sure yahoo is going to mangle:\n&gt; \n&gt; http://eplex.cs.ucf.edu/=\r\nindex.php?\n&gt; option=3Dcom_content&task=3Dview&id=3D14&Itemid=3D28\n&gt; \n&gt; The =\r\ntwo papers, which present separate experiments are:\n&gt; \n&gt; &quot;Generating Large-=\r\nScale Neural Networks Through Discovering \n&gt; Geometric Regularities&quot; by Jas=\r\non J. Gauci and Kenneth O. Stanley\n&gt; \n&gt; and \n&gt; \n&gt; &quot;A Novel Generative Encod=\r\ning for Exploiting Neural Network Sensor \n&gt; and Output Geometry&quot; by David B=\r\n. D&#39;Ambrosio and Kenneth O. Stanley\n&gt; \n&gt; David D&#39;Ambriosio and Jason Gauci =\r\nare both Ph.D. students in the \n&gt; EPlex lab who did an enormous amount of w=\r\nork to make this possible.\n&gt; \n&gt; HyperNEAT is based on a surprisingly simple=\r\n principle: Connectivity \n&gt; patterns are actually no different from spatial=\r\n patterns in a \nhigher-\n&gt; dimensional space.  In other words, a 2-dimension=\r\nal connectivity \n&gt; pattern is the same thing as a 4-dimensional spatial pat=\r\ntern.  (The \n&gt; technical term is that they are &quot;isomorphic.&quot;)  Therefore, i=\r\nf we \n&gt; simply produce spatial patterns within a 4D hypercube instead of a =\r\n\n&gt; 2D plane, they can be mapped directly to connectivity patterns with \n&gt; a=\r\nll the nice properties that we have seen from CPPNs.  Thus, they \n&gt; require=\r\n no special &quot;image recognition&quot; type tricks.  The mapping is \n&gt; perfectly i=\r\nsomorphic.  We are calling these 4D CPPNs &quot;connective \n&gt; CPPNs&quot; since they =\r\nare interpreted as connectivity patterns.\n&gt; \n&gt; This insight yields a handfu=\r\nl of unprecedented capabilities.  For \n&gt; example, with connective CPPNs, yo=\r\nu can recreate the same solution \n&gt; network at a different resolution witho=\r\nut further evolution!  You \n&gt; can also place inputs and outputs in meaningf=\r\nul geometric \n&gt; configurations that HyperNEAT can exploit for symmetries an=\r\nd \n&gt; regularities.  \n&gt; \n&gt; In any case, I am excited about this new advance =\r\nand these papers \n&gt; are a first step in exploring the new approach.\n&gt; \n&gt; ke=\r\nn\n&gt;\n\n\n\n"}}