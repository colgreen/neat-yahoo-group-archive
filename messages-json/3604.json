{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"cQJLoV1wkkmXWTM-MDsi874_2XEv_mO9BMjzNeybr0Hs6Ek4PG52cKXNmN0lnt29MeFwdFGsk-zeWESq7pVrmzKIjEnM3uj8t-8TDJDkmx3-","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: NEAT x Cascade Correlation","postDate":"1192685038","msgId":3604,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZmNnFsZSs4aTkwQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGQyNzhlM2FkMDcxMDE3MTI1MW02MTUyZjBkOGg5ZTExNDkzZjIwOTNmYTFmQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":3603,"nextInTopic":0,"prevInTime":3603,"nextInTime":3605,"topicId":3600,"numMessagesInTopic":5,"msgSnippet":"Rafael, actually, that s a good point- NEAT should be more paralleizable than CC because NEAT is population based.  In CC there is only one individual, which","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 73364 invoked from network); 18 Oct 2007 05:24:01 -0000\r\nReceived: from unknown (66.218.67.97)\n  by m53.grp.scd.yahoo.com with QMQP; 18 Oct 2007 05:24:01 -0000\r\nReceived: from unknown (HELO n28a.bullet.sp1.yahoo.com) (209.131.38.246)\n  by mta18.grp.scd.yahoo.com with SMTP; 18 Oct 2007 05:24:01 -0000\r\nReceived: from [216.252.122.219] by n28.bullet.sp1.yahoo.com with NNFMP; 18 Oct 2007 05:24:01 -0000\r\nReceived: from [66.218.69.2] by t4.bullet.sp1.yahoo.com with NNFMP; 18 Oct 2007 05:24:01 -0000\r\nReceived: from [66.218.66.91] by t2.bullet.scd.yahoo.com with NNFMP; 18 Oct 2007 05:24:00 -0000\r\nDate: Thu, 18 Oct 2007 05:23:58 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ff6qle+8i90@...&gt;\r\nIn-Reply-To: &lt;d278e3ad0710171251m6152f0d8h9e11493f2093fa1f@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: NEAT x Cascade Correlation\r\nX-Yahoo-Group-Post: member; u=54567749; y=lmqTzzZT4YgvCvqHzjr831otDngis-CkIww7ygz8sd0mpjrzac0H\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nRafael, actually, that&#39;s a good point- NEAT should be more \nparalleizable t=\r\nhan CC because NEAT is population based.  In CC there \nis only one individu=\r\nal, which must be trained serially.\n\nCC and NEAT have never been directly c=\r\nompared as far as I know.  They \nboth do share the idea of complexification=\r\n from a minimal starting \npoint.  However, the way they perform that proces=\r\ns is quite \ndifferent.  CC has a deterministic rule for when to add a node,=\r\n and \nit always adds one in the same way.  NEAT on the other hand is \nstoch=\r\nastic in its topology additions.\n\nYet the fundamental difference is that CC=\r\n is fundamentally a \nsupervised training method, which means that it requir=\r\nes output \ntargets so that it can compare its outputs to the targets and co=\r\nmpute \nan error.  NEAT, like other neuroevolution methods, does not require=\r\n \ntargets so it can work on sparse reinforcement tasks where the \ntargets a=\r\nre unknown.  For example, you can evolve an ANN to drive a \ncar with NEAT w=\r\nithout needing to know anything about how to drive a \ncar.  With CC, you&#39;d =\r\nneed to know what the network should have done \non each timestep.  It is in=\r\n this sense that CC is trained similarly \nto backprop- both are supervised.=\r\n\n\nThere are ways around this supervised limitation, just as there are \nwith=\r\n backprop.  The field of Reinforcemtn Learning (specifically \nvalue-functio=\r\nn-based learning) turns the value of actions in states \ninto targets as a w=\r\nay of making what is normally implicit in \nunsupervised tasks more explicit=\r\n, so that such methods can deal with \nthem.  However, NEAT needs no such cl=\r\neverness and can compute fitness \nbased on things like crashes or speed of =\r\ncompletion, bypassing the \nneed to capture the value function.\n\nNone of the=\r\nse considerations tells you which method is &quot;better&quot; on \nany particular tas=\r\nk in an empirical comparison.  However, it makes \nsense to use NEAT on RL t=\r\nasks instead of CC simply because NEAT is \nmore straightforwardly applied. =\r\n On supervised tasks, it is possible \nthat CC may outperform NEAT or vice v=\r\nersa.  However, supervised tasks \nare not the focus of NEAT and even backpr=\r\nop can do quite well on such \ntasks sometimes.\n\nThe inherent parallelism of=\r\n population-based approaches like NEAT is \nalso an important consideration,=\r\n as you point out.\n\nken\n\n--- In neat@yahoogroups.com, &quot;Rafael C.P.&quot; &lt;kurama=\r\n.youko.br@...&gt; \nwrote:\n&gt;\n&gt; Ah, just thought NEAT may be more parallelizable=\r\n than CC.\n&gt; \n&gt; On 10/17/07, Rafael C.P. &lt;kurama.youko.br@...&gt; wrote:\n&gt; &gt;\n&gt; =\r\n&gt; The first difference I can see is that the topology created by \nNEAT can =\r\nbe\n&gt; &gt; much simpler than that of CC (yet I think you need to include the \nn=\r\network\n&gt; &gt; size in the fitness calculation), because CC will add hidden \nno=\r\ndes always\n&gt; &gt; adding a new layer (the new hidden node is connected to all =\r\n\ninputs and all\n&gt; &gt; previous hidden nodes). To solve this problem there are=\r\n pruning \nmethods like\n&gt; &gt; optimal brain damage or a CC variant, the Flat C=\r\nC, in which \nthere&#39;s only 1\n&gt; &gt; hidden layer (but FCC generalizes worse). A=\r\nbout recurrence, I \nthink there&#39;s\n&gt; &gt; an extension for recurrent CC. The al=\r\ngorithm used by CC isn&#39;t BP, \nbut I\n&gt; &gt; don&#39;t know it very well.\n&gt; &gt;\n&gt; &gt; On=\r\n 10/17/07, Derek James &lt;djames@...&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt;   Cascade Correlatio=\r\nn is when hidden units are incrementally \nadded to a\n&gt; &gt; &gt; network until th=\r\ne optimal number is found, correct?\n&gt; &gt; &gt;\n&gt; &gt; &gt; I don&#39;t know much about it.=\r\n Is CC used with recurrent networks? \nI\n&gt; &gt; &gt; remember thinking it was anal=\r\nogous to NEAT in some ways when I \nread about it\n&gt; &gt; &gt; a couple of years ag=\r\no, such as the idea of starting small, while\n&gt; &gt; &gt; incrementally adding top=\r\nology and testing it. But it seemed a \nlot more\n&gt; &gt; &gt; limited in the types =\r\nof topologies it could create. And are \nnetworks created\n&gt; &gt; &gt; with CC stil=\r\nl trained via backprop?\n&gt; &gt; &gt;\n&gt; &gt; &gt; Would anybody familiar with CCs provide=\r\n some links to relevant \npapers or\n&gt; &gt; &gt; websites explaining it a bit more?=\r\n\n&gt; &gt; &gt;\n&gt; &gt; &gt; --Derek\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; On 10/17/07, Rafael C.P. &lt;kurama.you=\r\nko.br@... &gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;   Is there any study showing a compariso=\r\nn between NEAT and \nthe Cascade\n&gt; &gt; &gt; &gt; Correlation algorithm? Or could Sta=\r\nnley himself points out \nimportant\n&gt; &gt; &gt; &gt; differences and similarities, as=\r\n well as performance \nmeasurements\n&gt; &gt; &gt; &gt; (like training speed, runtime sp=\r\need, size, etc...)?\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; (I&#39;ve made a *similar* question 1 or 2 =\r\nyear ago but haven&#39;t \ngot many\n&gt; &gt; &gt; &gt; answers, sorry if it appears repetit=\r\nive)\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; --\n&gt; &gt; &gt; &gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; &gt; &gt; &gt; Rafael =\r\nC.P.\n&gt; &gt; &gt; &gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;  \n&gt; &gt; &gt;\n&gt; &gt;\n&gt; =\r\n&gt;\n&gt; &gt;\n&gt; &gt; --\n&gt; &gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; &gt; Rafael C.P.\n&gt; &gt; =3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; -- \n&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; Rafael=\r\n C.P.\n&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt;\n\n\n\n"}}