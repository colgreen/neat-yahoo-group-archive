{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"FuZSVQdtI_ym9rFuyorOERxoyj9df4pG5BKnSnHX7dHrqmnqRLnZgopwWs0FZWVLUuTvSawPZDnbD33qPptEgepn7jnNnwJoSTA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Image Sampling for Scaling","postDate":"1095678248","msgId":1559,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMS4yLjAuMC4yMDA0MDkyMDExNTUyNS4wMjUwNWFlMEBwb3AubWFpbC55YWhvby5jby51az4=","inReplyToHeader":"PDE5YjEwZDUxMDQwOTE4MTAzOTM1OTM0YUBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PDE5YjEwZDUxMDQwOTE4MTAzOTM1OTM0YUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":1558,"nextInTopic":1561,"prevInTime":1558,"nextInTime":1560,"topicId":1552,"numMessagesInTopic":7,"msgSnippet":"... I think you are mixing up zooming-in approaches with zooming-out approaches here.  These interpolations you have listed here are generally for ","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 88643 invoked from network); 20 Sep 2004 11:01:55 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m25.grp.scd.yahoo.com with QMQP; 20 Sep 2004 11:01:55 -0000\r\nReceived: from unknown (HELO smtp002.mail.ukl.yahoo.com) (217.12.11.33)\n  by mta3.grp.scd.yahoo.com with SMTP; 20 Sep 2004 11:01:55 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp002.mail.ukl.yahoo.com with SMTP; 20 Sep 2004 11:01:39 -0000\r\nMessage-Id: &lt;6.1.2.0.0.20040920115525.02505ae0@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.1.2.0\r\nDate: Mon, 20 Sep 2004 12:04:08 +0100\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;19b10d51040918103935934a@...&gt;\r\nReferences: &lt;19b10d51040918103935934a@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Remote-IP: 217.12.11.33\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] Image Sampling for Scaling\r\nX-Yahoo-Group-Post: member; u=7192225\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nAt 18:39 18/09/2004, you wrote:\n&gt;Hi all,\n&gt;\n&gt;We continue to work on our active vision implementation for object\n&gt;recognition.  We&#39;ve formalized some experiments and are aiming to\n&gt;write a paper for a special edition of Pattern Recogition Letters (the\n&gt;deadline is October 31st).\n&gt;\n&gt;But we have an issue we thought we&#39;d open to the group.  Our\n&gt;implementation has a zoom feature, and if for example the eye is fully\n&gt;zoomed out and centered on the canvas, there are a number of ways of\n&gt;sampling or filtering the image for input into the neural network.\n&gt;\n&gt;If the canvas is 100x100, for example, and the eye resolution is 5x5,\n&gt;then if the eye is fully zoomed out and centered, there are 25 20x20\n&gt;regions.  So how do you get the value for each region to input into\n&gt;each visual input in your eye?\n&gt;\n&gt;Standard interpolation methods include nearest neighber, bilinear, and\n&gt;bicubic, which sample either a single pixel in the field, an average\n&gt;of two, or an average of four, respectively.\n\nI think you are mixing up zooming-in approaches with zooming-out approaches \nhere.  These interpolations you have listed here are generally for \ninterpolation between pixels when zooming in*.  Zooming-out most commonly \nworks by averaging pixels in an area.  I would not normally think of it as \nexpensive, but I guess it depends whether you have to recalculate it over \nand over...\n\n(* OK, they do come up in, for example, Mip Mapping, which is for \nzooming-out, but that operates on pre-made averaged data)\n\nWhy is averaging too expensive?\n\nHow about providing the net with Min(area) and Max(area)?  When you get \ndown to a single pixel, they are the same.  Is the area always \nsquare?  (and it so, why? :)  Is it axis aligned?\n\n&gt;   The problem with these\n&gt;approximations is, there is often loss of information.  We thought a\n&gt;method that averaged every pixel in a given region would be best, but\n&gt;it is very computationally expensive.\n&gt;\n&gt;In the Kato/Floreano paper which evolved networks to discriminate\n&gt;between triangles and squares, the network can has an output which can\n&gt;choose the sampling method for each timestep.  The two sampling\n&gt;methods are: 1) take the value of the upper-leftmost pixel, 2) full\n&gt;area averaging.  Their paper reports that given the choice, the\n&gt;networks use the first, simpler form of sampling 61% of the time.\n&gt;They speculate that harsher, blockier edges are easier to discern than\n&gt;fuzzy, grey ones.\n\nWell, since you are training a network under the conditions of whatever \nsampling method you choose, then to some extent if it can adapt to a given \ntechnique it will do.  How much is your data B+W and how much \ngrey-scale?  ISRT it&#39;s B+W but with some anti-aliasing on the edges?  If \nthis is the case, then to expand on my MIN/MAX idea, maybe a histogram of \npixel values in the region, maybe just taking four ranges (0-0.25, \n0.25-0.5, 0.5 to 0.75, 0.75-1.0).  That tells the network directly whether \nthe sample is inside, outside or on an edge...\n\n&gt;This seems to correlate with some of the ad hoc experiments we&#39;re\n&gt;doing.  Simpler sampling methods seem to provide better results for\n&gt;the task than area averaging.  This seems a little counterintuitive,\n&gt;since the simpler method results in loss of information and worse\n&gt;distortion of the image at higher zoom factors.\n\nCounterintuitive at first, yes, but since the network is learning the \nsampling system...\n\n         Ian\n\n\n\nLiving@Home - Open Source Evolving Organisms - \nhttp://livingathome.sourceforge.net/\n\n\n\n\n"}}