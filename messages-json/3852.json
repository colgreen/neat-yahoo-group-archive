{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"oTzSeYhceYB_S42L9sum_cN1fXh-V6_J4JyIG-IW8NPtMGMObsyRBq8yZqVtnDW7A0UplfiCHdSxT24GNC0lgQ5b9_7QZxiwiCA73x3Rt-pI","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205013428","msgId":3852,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZxdjIzayszNnNpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZxcjFiZytocm9kQGVHcm91cHMuY29tPg=="},"prevInTopic":3848,"nextInTopic":3853,"prevInTime":3851,"nextInTime":3853,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"A number of people have programmed backprop into NEAT.  Chris Christenson did a Masters thesis on combining NEAT and backprop; a paper based on this work is","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 44938 invoked from network); 8 Mar 2008 21:57:08 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m46.grp.scd.yahoo.com with QMQP; 8 Mar 2008 21:57:08 -0000\r\nX-Received: from unknown (HELO n30a.bullet.scd.yahoo.com) (66.94.237.33)\n  by mta17.grp.scd.yahoo.com with SMTP; 8 Mar 2008 21:57:08 -0000\r\nX-Received: from [66.218.69.1] by n30.bullet.scd.yahoo.com with NNFMP; 08 Mar 2008 21:57:08 -0000\r\nX-Received: from [66.218.66.78] by t1.bullet.scd.yahoo.com with NNFMP; 08 Mar 2008 21:57:08 -0000\r\nDate: Sat, 08 Mar 2008 21:57:08 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fqv23k+36si@...&gt;\r\nIn-Reply-To: &lt;fqr1bg+hrod@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=Ci8aix2hv-hjGTZ_7gefvO9eJABLkNcfTA5kNpl5u8VQnS21YqVO\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nA number of people have programmed backprop into NEAT.  Chris \nChristenson =\r\ndid a Masters thesis on combining NEAT and backprop; a \npaper based on this=\r\n work is actually in the files section of this group:\n\nhttp://f1.grp.yahoof=\r\ns.com/v1/UP7SR8rDovimxlLlvcmGOziLUBIVncb2Tfr7sruoB8b\ntaAfELU62JLyQ9XCxXF_Ak=\r\nhcmi-\nTH4gpVHIikwnzB59ArOMQfPOAzyw25/Evolving_Trainable_Neural_Networks_6_p=\r\nage\ns.doc\n\nShimon Whiteson implemented it as part of his NEAT+Q reinforceme=\r\nnt \nlearning method:\n\nhttp://staff.science.uva.nl/~whiteson/pubs/whitesonaa=\r\nai06.pdf\n\nThere has been a lot written on backprop in NEAT in the archives =\r\nof \nthis group: just search for &quot;backprop&quot; from the yahoo page for this \ngr=\r\noup and many messages will pop up.\n\nIn general, if you do not allow recurre=\r\nnce then I believe there is no \nspecial change needed in the traditional ba=\r\nckprop algorithm.  With \nrecurrence you would need something like recurrent=\r\n backprop like Derek \nsuggested.  But let&#39;s just say you are evolving nonre=\r\ncurrent networks- \nis there a particular problem you have in mind that come=\r\ns up with \napplying backprop to such networks?\n\nken\n\n--- In neat@yahoogroup=\r\ns.com, &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt; \nwrote:\n&gt;\n&gt; Hello there. \n=\r\n&gt; \n&gt; I am looking for any back-propagation algorithm that can work on \n&gt; ne=\r\ntworks with arbitrary topology such as these that NEAT evolves. All \n&gt; libr=\r\naries I found so far either assume layered networks or only feed-\n&gt; forward=\r\n ones.. I am confused. Is there any source code that might \nhelp \n&gt; me? Any=\r\n back-prop implementation that can work on NEAT networks such \n&gt; that it ca=\r\nn easily be integrated. Or maybe some papers on the topic? \n&gt; I appreciate =\r\nany help from the community. \n&gt; \n&gt; Peter\n&gt;\n\n\n\n"}}