{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":345796568,"authorName":"peterberrington","from":"&quot;peterberrington&quot; &lt;peterberrington@...&gt;","profile":"peterberrington","replyTo":"LIST","senderId":"zXnl0IlSMqZz9O1zA30SCOQyvYcaWo_vUJo5d7dTmvOTXwfqlxPaM-liWoxemNu-DbQPd37kmjUYKmdaF4Fd_MfnVQhmKCgWardM5Thx7r3ZGwc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Parallelizing novelty search","postDate":"1213075149","msgId":4137,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcybDJzZCszMTlyQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4141,"prevInTime":4136,"nextInTime":4138,"topicId":4137,"numMessagesInTopic":4,"msgSnippet":"Thanks a lot to Petar C for his novelty-based nevh, its really coming along nicely. In the past while I have been thinking of how to best exploit parallel ","rawEmail":"Return-Path: &lt;peterberrington@...&gt;\r\nX-Sender: peterberrington@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 64525 invoked from network); 10 Jun 2008 05:19:10 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m43.grp.scd.yahoo.com with QMQP; 10 Jun 2008 05:19:10 -0000\r\nX-Received: from unknown (HELO n17a.bullet.sp1.yahoo.com) (69.147.64.124)\n  by mta18.grp.scd.yahoo.com with SMTP; 10 Jun 2008 05:19:10 -0000\r\nX-Received: from [216.252.122.218] by n17.bullet.sp1.yahoo.com with NNFMP; 10 Jun 2008 05:19:10 -0000\r\nX-Received: from [66.218.69.6] by t3.bullet.sp1.yahoo.com with NNFMP; 10 Jun 2008 05:19:10 -0000\r\nX-Received: from [66.218.66.75] by t6.bullet.scd.yahoo.com with NNFMP; 10 Jun 2008 05:19:10 -0000\r\nDate: Tue, 10 Jun 2008 05:19:09 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g2l2sd+319r@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;peterberrington&quot; &lt;peterberrington@...&gt;\r\nSubject: Parallelizing novelty search\r\nX-Yahoo-Group-Post: member; u=345796568; y=r_ZOzftlAi42De4ouplirNxwzGbQ_BpD29fRjcoW-2FF9YTBfOQ-nGqj\r\nX-Yahoo-Profile: peterberrington\r\n\r\nThanks a lot to Petar C for his novelty-based nevh, its really coming\nalong=\r\n nicely.\n\nIn the past while I have been thinking of how to best exploit par=\r\nallel\narchitecture with novelty search. \nI have a pretty good idea of how t=\r\no do this in general, but the\ndetails need a lot of work and I could use as=\r\n much help and input as I\ncan get.\n\nWith generational dynamics its quite ea=\r\nsy to simply divide the\npopulation into the number of working processors yo=\r\nu have and perform\nevaluation in parallel, exploiting the extra cpu power t=\r\no do the most\ncpu intensive part of the NEAT algorithm. \n\nHowever, since st=\r\neady state novelty search only modifies a single\npopulation member each tic=\r\nk, a different approach is necessary. \n(When I say tick from henceforth I a=\r\nm just referring to the 3 steps of\nremove worst, sort by fitness/species_si=\r\nze, add new probabilistically).\n\nAt first I thought an easy modification to=\r\n implement is this: view the\ntick() method as a function which takes a popu=\r\nlation and returns a\npopulation of the same size, with the worst individual=\r\n replaced with\nan new individual. Simply performing n concurrent ticks and =\r\nselecting\nthe resulting population which is the best could then be done, wh=\r\nich\nbears some resemblance to the idea of tournament selection.\n\nThinking o=\r\nn this further though, it occurred to me that this is greedy\nand in a way w=\r\nasteful/inefficient. In some sense you can view novelty\nsearch&#39;s tick() met=\r\nhod as not only adding a new individual; it also\nalters the search &quot;frontie=\r\nr&quot;. Since each species has a different spawn\nprobability you are getting in=\r\nformation about which directions in\nsearch space are less or more fruitful;=\r\n by simply selecting the best\nof N populations each tick we are discarding =\r\nthis useful info. \n\nSo after looking at a picture of the skeleton of a leaf=\r\n, I thought\nthat the best approach is to take an idea from nature; faced wi=\r\nth the\nproblem of covering the most area and the tools of forking and\nmergi=\r\nng, nature has evolved circulatory systems which branch and\nconverge regula=\r\nrly in specific ways (in particular, one noticed\nrecursion). The process is=\r\n called anastomosis I think. NEAT already\ndoes this in a way with species, =\r\nwhich has the effect of packaging the\npopulation into discrete chunks which=\r\n explore particular regions of\nsearch space. I propose simply doing this at=\r\n a higher level in order\nto benefit from multi-core machines and distribute=\r\nd processing.\n\nThere is normally a certain amount of ticks that are perform=\r\ned between\nspeciation. The easiest way to split up the algorithm I think is=\r\n to\nperform these ticks in parallel, then have a &quot;merge&quot; function which\nsel=\r\nectively decides how to combine the n disparate populations into a\nunified =\r\none, for speciation. This is made easier if a &quot;control&quot;\npopulation is saved=\r\n before forking, for comparison later. To be a\nlittle more clear, a &#39;popula=\r\ntion&#39; object actually consists of 3 objects:\nA set of member chromosomes, e=\r\nach with their own attributes\nA set of member species, each with their own =\r\nattributes and member\nchromosomes\nA set of behaviours (i.e. the archive), w=\r\nhich I call a &quot;novelty pool&quot;\nin my implementations. \nEach parallel tick() s=\r\nhould take a copy of these 3 objects and return\n3 new ones. \n\nSo in python =\r\nthe main loop would look superficially like this:\n\nwhile ( not time_to_stop=\r\n )\n    speciate\n    for i in range ( j )\n        do tick in parallel()\n    =\r\nif reached_goal: time_to_stop =3D True\n\nj is the integer that controls how =\r\nmany ticks are performed between\nspeciation, which in nero is 5 but I&#39;m sur=\r\ne is robust to some variation.\n\nNovelty search should be performed with a s=\r\ningle consolidated\nbehaviour archive to avoid duplication of work, but shou=\r\nld branch out\nwhen exploring new individuals and harvest information about =\r\nthe\nsearch frontier whenever possible. Because of this, the\nmerge/selection=\r\n operation should be carefully designed to incorporate\nthis information non=\r\n-destructively.\n\nNovelty search often results in the most recently added in=\r\ndividual\nbeing removed on the next available tick (this is because a specie=\r\ns\nwith many members often has a high spawn probability, and the &#39;remove\nwor=\r\nst chromosome&#39; operation tends to remove the worst of larger\nspecies before=\r\n smaller species). This has the effect that between many\nticks, no new indi=\r\nviduals are added, but nonetheless the search\nfrontier is altered by way of=\r\n aging, stagnation, and changes to\naverage fitness. When comparing the refe=\r\nrence/control population to\nthe result of a few ticks, we can tabulate a li=\r\nst of member\nchromosomes which are disjoint between the two sets; the chrom=\r\nosomes\nwhich are in reference but not the new population can be considered\n=\r\ndead-ends, and conversely the chromosomes in the new population not\npresent=\r\n in the reference can be considered improvements.\n\nThe total set of improve=\r\nments between all n concurrent set of ticks\nshould be preserved in the new =\r\nunified population, and conversely the\ndead ends should be removed, but doi=\r\nng this is more difficult than it\nseems. This is partly because the list of=\r\n member chromosomes is also\nintimately coupled with the list of member spec=\r\nies.\n\nOf the species which are common to both a new population and the\nrefe=\r\nrence population, there may be differences in the species &quot;no\nimprovement a=\r\nge&quot;, age, average fitness, and member chromosomes. \nUnifying these disparat=\r\ne sets presents a problem for me.\n\nFor example, what if an improvement from=\r\n one of the new populations is\na member of a species which was removed in a=\r\nll the other new\npopulations? What if a species has aged and stagnated in m=\r\nost of the\npopulations but has produced an improvement in another populatio=\r\nn? How\ncan we produced a unified population which reflects the contribution=\r\ns\nto search that each concurrent salvo of ticks has made?\n\n\nAny thoughts pe=\r\nople have are welcome. \n\n\n"}}