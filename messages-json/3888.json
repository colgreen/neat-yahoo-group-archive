{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"vbGDQDVVVsInhuFH-d5jZnFKXni6l51DkF-W_pp-QGgBShrZc0SZ1cEps6JW9w8WbKkTlhdUIrJtGqGY-px_KNRhxYnjrmAV6gOkafRI3XxYrKR3THk","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205779946","msgId":3888,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZybWVsYSs2bmJuQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZybWRwNytxNmF2QGVHcm91cHMuY29tPg=="},"prevInTopic":3887,"nextInTopic":3892,"prevInTime":3887,"nextInTime":3889,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"Hey this is moving towards philoshophy. Almost all things known to man have a pattern. Biology is one perfect example for this. And a pattern means underlying","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 44773 invoked from network); 17 Mar 2008 18:52:30 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m43.grp.scd.yahoo.com with QMQP; 17 Mar 2008 18:52:30 -0000\r\nX-Received: from unknown (HELO n25c.bullet.scd.yahoo.com) (66.218.67.216)\n  by mta16.grp.scd.yahoo.com with SMTP; 17 Mar 2008 18:52:30 -0000\r\nX-Received: from [66.218.69.1] by n25.bullet.scd.yahoo.com with NNFMP; 17 Mar 2008 18:52:27 -0000\r\nX-Received: from [66.218.66.91] by t1.bullet.scd.yahoo.com with NNFMP; 17 Mar 2008 18:52:27 -0000\r\nDate: Mon, 17 Mar 2008 18:52:26 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frmela+6nbn@...&gt;\r\nIn-Reply-To: &lt;frmdp7+q6av@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=283334584; y=Xs03cG364iukrk3vrvQK8n7lduyoLwCj5DhjgWpuXn99Qt-Z-Pe8xaj8XA\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHey this is moving towards philoshophy. Almost all things known to \nman hav=\r\ne a pattern. Biology is one perfect example for this. And a \npattern means =\r\nunderlying information. \n\n--- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@..=\r\n.&gt; wrote:\n&gt;\n&gt; Ken,\n&gt; \n&gt; I can appreciate the need to choose applications &quot;w=\r\nith careful \n&gt; scrutiny with a sincere belief in their practical ramificati=\r\nons&quot;, \nbut \n&gt; the simple truth is that your bias for exploring &quot;patterns an=\r\nd \n&gt; regularities&quot;, are utterly destroyed by the application of non-\nlinear=\r\n \n&gt; inequality feasibility constraints. Which routinely happens in the \n&gt; d=\r\nomain of engineering optimization/search. \n&gt; \n&gt; Your operation without the =\r\napplication of the pressures associated \n&gt; with these pattern destroying in=\r\nfluences results in a unrealistic \n&gt; perspective on the utility of global p=\r\nattern exploitation, and a \n&gt; failure to address the repercussions of the s=\r\nometimes seemingly \n&gt; totally arbitrary nature of enforced feasibility cons=\r\ntraints \ndictated \n&gt; by real-world problems.\n&gt; \n&gt; Until you can simultaneou=\r\nsly address the exploitation of multiple \n&gt; hyperspace &quot;regional/sub-volume=\r\n&quot; patterns/regularities overlaid \nwith \n&gt; multiple arbitrary non-linear ine=\r\nquality feasibility constraints, \nin \n&gt; a computationally practical manner,=\r\n methodologies such as Hyperneat \n&gt; will be dispatched as &quot;curiosities&quot; onl=\r\ny.\n&gt; \n&gt; These kinds of pressures are routinely addressed in the domain of \n=\r\n&gt; engineering optimization/search. Your choice of side-stepping these \n&gt; in=\r\nfluences shapes what infrastructure is and is-not developed, as \nhas \n&gt; bee=\r\nn adequately addressed in prior posts.\n&gt; \n&gt; An applicable quote: &quot;I have li=\r\nttle patience with scientists who \ntake \n&gt; a board of wood, look for its th=\r\ninnest part, and drill a great \nnumber \n&gt; of holes where drilling is easy.&quot;=\r\n--Albert Einstein\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;ksta=\r\nnley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Andy, I have no problem with the idea of NEAT as a fo=\r\nundation upon\n&gt; &gt; which to build.  That&#39;s perfectly aligned with my view th=\r\nat there \nis\n&gt; &gt; more yet to accomplish.  \n&gt; &gt; \n&gt; &gt; Let me respond to some =\r\nof your specific points below.\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;afcar=\r\nl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; The issues you raise, though valid, =\r\nappear disingenuous for two \n&gt; &gt; &gt; reasons. First, if you had reviewed the =\r\ncontents and \ncapabilities \n&gt; of \n&gt; &gt; &gt; the Dakota toolkit, you would have =\r\ndiscovered the issues as \nbeing \n&gt; &gt; &gt; essentially addressed. Second, not i=\r\nntending any disrespect, \nfrom \n&gt; &gt; &gt; external appearances, your efforts ap=\r\npear directed in other \n&gt; &gt; &gt; directions than that of addressing your self =\r\nadmitted areas of \n&gt; &gt; &gt; concern.\n&gt; &gt; &gt; \n&gt; &gt; &gt; From a review of literature =\r\non the subject, there is a common \n&gt; &gt; &gt; understanding that EA is computati=\r\nonally expensive and slow to \n&gt; &gt; &gt; converge, but robust for global search =\r\nin problem domains with \n&gt; &gt; &gt; multiple local minima.\n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; It re=\r\nally just depends who you are talking about whether there is \na\n&gt; &gt; &quot;common=\r\n understanding&quot; about anything in AI.  It also depends \n&gt; whether\n&gt; &gt; we ar=\r\ne talking about the past or the future.  \n&gt; &gt; \n&gt; &gt; For example, it&#39;s often =\r\nsaid that &quot;neural networks get caught on \n&gt; local\n&gt; &gt; optima&quot; (and there is=\r\n indeed a &quot;common understanding&quot; that they \ndo)\n&gt; &gt; but when people say tha=\r\nt they are almost always only talking about\n&gt; &gt; backprop, which is just one=\r\n single neural network learning \n&gt; algorithm.\n&gt; &gt;  Backprop is not the only=\r\n way a neural network can learn.\n&gt; &gt; \n&gt; &gt; The problem is that when we talk =\r\nabout methods in machine \nlearning \n&gt; we\n&gt; &gt; often confuse whether we are t=\r\nalking about a *field* or a \nparticular\n&gt; &gt; method.  In the case of EAs, yo=\r\nu seem to be talking about some\n&gt; &gt; existing methods that have been analyze=\r\nd (often by people who are \n&gt; not\n&gt; &gt; even aware of the most modern approac=\r\nhes) in the past.   For \n&gt; example,\n&gt; &gt; the old-fashioned bit-string based =\r\nsimple EA has been analyzed\n&gt; &gt; extensively.\n&gt; &gt; \n&gt; &gt; Yet as a field, EAs t=\r\nhemselves are evolving.  Problems identified \nin\n&gt; &gt; the past are actively =\r\nbeing addressed in the present and future. \n&gt; Some\n&gt; &gt; modern approaches co=\r\nmpletely overturn the assumptions and \nproblems \n&gt; of\n&gt; &gt; the past (and of =\r\ncourse introduce their own new problems).  Check \n&gt; out\n&gt; &gt; Estimation of D=\r\nistribution Algorithms and the CMA-ES:\n&gt; &gt; \n&gt; &gt; http://en.wikipedia.org/wik=\r\ni/Estimation_of_distribution_algorithm\n&gt; &gt; http://en.wikipedia.org/wiki/CMA=\r\n-ES\n&gt; &gt; \n&gt; &gt; When I look at EAs, or any research area for that matter, I al=\r\nways\n&gt; &gt; think about what they *could* be, rather than what they are.  And =\r\n\n&gt; as a\n&gt; &gt; researcher, I try to make them what they could be.  To me, that=\r\n \nis \n&gt; the\n&gt; &gt; exciting thing about research: At its best, it overturns do=\r\ngma.  I\n&gt; &gt; like to view a limitation as a challenge rather than as a brick=\r\n \n&gt; wall.\n&gt; &gt; \n&gt; &gt; &gt; And that is from people who are working &quot;hard&quot; problem=\r\ns (i.e. \n&gt; multi-\n&gt; &gt; &gt; discipline, multiobjective, non-linear inequality c=\r\nonstraints, \n&gt; etc.), \n&gt; &gt; &gt; at government laboratories and Fortune 100 def=\r\nense firms. Not \n&gt; dancing \n&gt; &gt; &gt; rag-dolls and computer-aided art.\n&gt; &gt; &gt; \n=\r\n&gt; &gt; \n&gt; &gt; First, while you often cite multiobjective optimization as a &quot;hard=\r\n\n&gt; &gt; problem&quot; for EAs, in fact some of the most effective algorithms in\n&gt; &gt;=\r\n multiobjective optimization are EAs.  EAs are naturally suited to\n&gt; &gt; main=\r\ntaining a pareto front because a pareto front requires a\n&gt; &gt; population to =\r\nhold it.  There is vast literature on pareto\n&gt; &gt; optimization in EAs, both =\r\nin multiobjective optimization and in\n&gt; &gt; coevolution.  Here are some semin=\r\nal examples:\n&gt; &gt; \n&gt; &gt; K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A Fa=\r\nst and \nElitist\n&gt; &gt; Multiobjective Genetic Algorithm: NSGA-II. IEEE Transac=\r\ntions on\n&gt; &gt; Evolutionary Computation, 6(2):182=96197, 2002.\n&gt; &gt; http://cit=\r\neseer.ist.psu.edu/530140.html\n&gt; &gt; \n&gt; &gt; De Jong, E.D. (2004). The Incrementa=\r\nl Pareto-Coevolution Archive.\n&gt; &gt; Proceedings of the Genetic and Evolutiona=\r\nry Computation Conference\n&gt; &gt; GECCO-04, pp. 525-536. \n&gt; &gt; http://people.cs.=\r\nuu.nl/dejong/publications/gecco04coev.pdf\n&gt; &gt; \n&gt; &gt; in fact, some of the mos=\r\nt brilliant theorists in pareto \noptimization\n&gt; &gt; are in evolutionary compu=\r\ntation.\n&gt; &gt; \n&gt; &gt; As for NEAT in government research labs on &quot;serious&quot; probl=\r\nems, \nhere \n&gt; is\n&gt; &gt; an example:\n&gt; &gt; \n&gt; &gt; Shimon Whiteson and Daniel Whites=\r\non (2007). &quot;Stochastic \nOptimization\n&gt; &gt; for Collision Selection in High En=\r\nergy Physics&quot;. IAAI 2007:\n&gt; &gt; Proceedings of the Nineteenth Annual Innovati=\r\nve Applications of\n&gt; &gt; Artificial Intelligence Conference.&#8202;\n&gt; &gt; http:=\r\n//arxiv.org/PS_cache/hep-ex/pdf/0607/0607012v1.pdf\n&gt; &gt; \n&gt; &gt; The article its=\r\nelf states, &quot;These NEAT selectors are currently in \n&gt; use\n&gt; &gt; at FermiLab f=\r\nor selecting collisions from real data collected\n&gt; &gt; with the Tevatron coll=\r\nider.&quot;  So, there you go, NEAT is being \nused \n&gt; at\n&gt; &gt; FermiLab itself to =\r\nselect which particle collisions are most \n&gt; promising.\n&gt; &gt; \n&gt; &gt; When you m=\r\nention rag dolls and art, you&#39;re giving me an \nopportunity \n&gt; to\n&gt; &gt; commen=\r\nt on some of our own current research.  Our group has indeed\n&gt; &gt; recently p=\r\nroduced a number of works in interactive evolution,\n&gt; &gt; including dance, ar=\r\nt, music, and particle effects.  Perhaps it may\n&gt; &gt; seem a somewhat lighthe=\r\narted departure from more serious subjects.\n&gt; &gt; \n&gt; &gt; Yet the implications o=\r\nf this work are as serious as any in my \nview. \n&gt; &gt; All of that work is a p=\r\nrobe of the ubiquity of patterns and\n&gt; &gt; regularities, in particular throug=\r\nh the theory of CPPNs.  The \ndeeper\n&gt; &gt; lesson in that body of work is that=\r\n the very same encoding is \nable \n&gt; to\n&gt; &gt; produce patterns appropriate to =\r\nwhat would otherwise appear to be\n&gt; &gt; disparate domains.  The idea is to de=\r\nvelop a theory of generic \n&gt; pattern\n&gt; &gt; generation and to show that patter=\r\nns are interchangeable across \nmany\n&gt; &gt; domains.  That insight leads to the=\r\n idea of HyperNEAT, which takes\n&gt; &gt; again the very same encoding that is pr=\r\noducing art and music and \n&gt; uses\n&gt; &gt; it to produce a large-scale neural pa=\r\nttern.  Therein it becomes\n&gt; &gt; serious, because the hard problems you like =\r\nto focus on almost \n&gt; always\n&gt; &gt; involve patterns and regularities.  \n&gt; &gt; \n=\r\n&gt; &gt; It is no accident that in building a theory of pattern \ngeneration, a\n&gt;=\r\n &gt; number of interactive evolutionary computation experiments would \n&gt; need=\r\n\n&gt; &gt; to be performed because understanding the capabilities of a \npattern\n&gt;=\r\n &gt; generator require *exploring* the space of possibilities rather \nthan\n&gt; =\r\n&gt; simply optimizing, and humans are much better explorers than\n&gt; &gt; computer=\r\ns.  The theory would never have gotten off the ground if \nwe\n&gt; &gt; had stuck =\r\nto more traditional optimization problems.   Indeed, as\n&gt; &gt; funny as it sou=\r\nnds, the whole idea began to materialize only \nafter I\n&gt; &gt; evolved a spaces=\r\nhip in Mattias Fagerlund&#39;s DelphiNEAT.  \n&gt; &gt; \n&gt; &gt; To put it starkly, withou=\r\nt that exploration in genetic art, there\n&gt; &gt; would have been no HyperNEAT. =\r\n And in fact even more new theories \n&gt; with\n&gt; &gt; practical implications are =\r\ncoming (not yet published) because of\n&gt; &gt; phenomena that became apparent th=\r\nrough Picbreeder.  So you see, in\n&gt; &gt; building a new algorithm or a new the=\r\nory with practical \n&gt; implications,\n&gt; &gt; often traditional problems are exac=\r\ntly the wrong vehicle to \n&gt; discovery\n&gt; &gt; because they perpetuate the same =\r\ndogmatic perspectives that \nalready\n&gt; &gt; permeate the field to begin with an=\r\nd cause it to be staying in one\n&gt; &gt; place.   Thus all of these applications=\r\n are chosen with careful\n&gt; &gt; scrutiny with a sincere belief in their practi=\r\ncal ramifications.\n&gt; &gt; \n&gt; &gt; Not to mention the fact that interactive evolut=\r\nion itself has the\n&gt; &gt; practical potential to change the way we do engineer=\r\ning in some \n&gt; cases.\n&gt; &gt;  Can you imagine Picbreeder for furinute instead =\r\nof pictures?  Or \n&gt; for\n&gt; &gt; cars?  Someday that may be how we create highly=\r\n customized \n&gt; artifacts.\n&gt; &gt;    In fact, some of the problems to which you=\r\n are referring \n(highly\n&gt; &gt; nonlinear and multi-objective) may only be poss=\r\nible to solve \nthrough\n&gt; &gt; interactive evolution.\n&gt; &gt; \n&gt; &gt; &gt; How many times=\r\n has NEAT, as a monolithic approach, been cited \nand \n&gt; &gt; &gt; successfully ap=\r\nplied by government laboratories and Fortune 100 \n&gt; &gt; &gt; defense firms for t=\r\nhese type of &quot;hard&quot; problems?\n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; You can refer to the paper on=\r\n high-energy physics at FermiLab if\n&gt; &gt; you&#39;re interested, but I still thin=\r\nk there is a bigger picture.  \n&gt; &gt; \n&gt; &gt; In some ways, as researchers in AI,=\r\n what practitioners are using \nto\n&gt; &gt; solve hard problems is exactly what w=\r\ne *don&#39;t* want to use.  After\n&gt; &gt; all, how is anything ever going to become=\r\n more powerful if we just\n&gt; &gt; look to practitioners to show us what methods=\r\n we should be \nusing?  \n&gt; As\n&gt; &gt; researchers, it is our job to give the pra=\r\nctitioners *new* \noptions,\n&gt; &gt; not the other way around.\n&gt; &gt; \n&gt; &gt; Practitio=\r\nners are often several steps behind algorithm \ndevelopers, \n&gt; and\n&gt; &gt; with =\r\ngood reason.  They often can&#39;t afford to take big risks and \n&gt; need\n&gt; &gt; som=\r\nething practical in the here and now.   You will therefore find\n&gt; &gt; that mo=\r\nst cutting-edge algorithms are not in use in industry or as\n&gt; &gt; tools in ot=\r\nher scientific disciplines at the very moment that \nthey \n&gt; are\n&gt; &gt; cutting=\r\n-edge.  Yet someone has to be developing the algorithms of \n&gt; the\n&gt; &gt; futur=\r\ne.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt;\n&gt;\n\n\n\n"}}