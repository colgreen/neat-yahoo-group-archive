{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"V6zYNzbbhTPuMhys-0qPtnMcX_W08n-IqcA4JOXNSlpRmUBtF_BjY4m4bzuPnsS7GXzmgd0jJwy2n9u-eMpLZcqqUMemtyGVzpdYRnaHKYZN8KK9ZtU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Substrate Evolution","postDate":"1253320167","msgId":4854,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGg5MThsNytiYWthQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGg4OGdpaysyc2M4QGVHcm91cHMuY29tPg=="},"prevInTopic":4853,"nextInTopic":4863,"prevInTime":4853,"nextInTime":4855,"topicId":4848,"numMessagesInTopic":5,"msgSnippet":"Hi Paul, This is a second message, because the first one was actually lost. My Yahoo e-mail was bouncing and stuff. So the group automatically kicked me.","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 88053 invoked from network); 19 Sep 2009 00:29:36 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m2.grp.re1.yahoo.com with QMQP; 19 Sep 2009 00:29:36 -0000\r\nX-Received: from unknown (HELO n43d.bullet.mail.sp1.yahoo.com) (66.163.169.157)\n  by mta3.grp.re1.yahoo.com with SMTP; 19 Sep 2009 00:29:35 -0000\r\nX-Received: from [69.147.65.147] by n43.bullet.mail.sp1.yahoo.com with NNFMP; 19 Sep 2009 00:29:27 -0000\r\nX-Received: from [98.137.34.33] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 19 Sep 2009 00:29:27 -0000\r\nDate: Sat, 19 Sep 2009 00:29:27 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;h918l7+baka@...&gt;\r\nIn-Reply-To: &lt;h88gik+2sc8@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Substrate Evolution\r\nX-Yahoo-Group-Post: member; u=283334584; y=l0LUOQKNwMBrDYUeOUP3w3NALh7tV4XuwbBBVCpmS7-Cx4jXfzAIyIyDgQ\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi Paul, \n\nThis is a second message, because the first one was actually los=\r\nt. My Yahoo e-mail was &quot;bouncing&quot; and stuff. So the group automatically &quot;ki=\r\ncked&quot; me. Nevermind, \n\nI am researching the evolution of CPPNs, and in part=\r\nicular HyperNEAT substrate configurations, a lot of time. I still haven&#39;t f=\r\nound the solution to it. The problem is really kind of simple one: &quot;how man=\r\ny nodes, and where?&quot; \n\nIt is usually a good idea to see how biology does it=\r\n, but the theory you point out is such that deals with phenotypes during th=\r\neir lifetime. I mean, yes, the brain is born with lots of neurons and then =\r\nsome process gradually filters them out, making more connections meanwhile.=\r\n But I think this process is because of &quot;biological performance&quot; issues. Ne=\r\nural tissue requires lots of oxygen. More neurons - more oxygen & food requ=\r\nired. It is better to have few neurons computing lots of stuff, requiring l=\r\ness oxygen, as the whole body grows in size. So this can kind of explain wh=\r\ny neurons prefer to make many many connections, no matter how much they are=\r\n. \n\nBut I can&#39;t see any connection to HyperNEAT at all. To evolve a substra=\r\nte means to have all the nodes (count of nodes and their placement) depend =\r\non evolutionary dynamics. Like for example, if the fittest individual can e=\r\nvolve faster using a circular substrate configuration than such that displa=\r\nys a square config, the algorithm should make sure it has been selected for=\r\n the next generation. And if the same circular-substrate individual perform=\r\ns good with 16 nodes and another one performs equally well with 64, the sma=\r\nller one should be chosen as better. \n\nThe count of nodes is a big problem.=\r\n Even the human brain, the chimp&#39;s brain, the rat&#39;s brain, all started from=\r\n one single cell. So I think it is more fundamental to understand biologica=\r\nl development than the post-development of the human brain after it is born=\r\n. We can actually think of the entire life cycle as one pattern in 4D space=\r\n. CPPNs can create any pattern in any space. \n\nPeter\n\n--- In neat@yahoogrou=\r\nps.com, &quot;spoonsx21&quot; &lt;spoonsx21@...&gt; wrote:\n&gt;\n&gt; Hello everyone,\n&gt; \n&gt; I&#39;m new=\r\n to the Neat group. My name is Paul, I&#39;m an undergraduate interested in evo=\r\nlutionary computation, and obviously HyperNEAT/ NEAT. I have been thinking =\r\na lot about substrate evolution, and its parallel in biology. One of the fu=\r\nndamental questions I&#39;ve been trying to answer is, how did brain topology e=\r\nvolve? And it is clearly fundamental to the problem of substrate evolution.=\r\n Our sensory information is pretty well segregated in the brain. For instan=\r\nce, visual areas are broken down into separate processing locations (V1-V5)=\r\n, each area dealing with different aspects of visualization like object mov=\r\nement, or pattern recognition. There are plenty of studies and papers on cu=\r\nrrent brain topology, but it&#39;s difficult to find ideas on how brain topolog=\r\ny evolved. \n&gt; \n&gt; However, I did stumble upon one theory I enjoyed. It was G=\r\nerald Edelman&#39;s theory on what he calls neural Darwinism, or the theory of =\r\nneuronal group selection (TNGS). And while I attempt to truly get my head a=\r\nround the theory, what I have drawn from his theory seems applicable to Hyp=\r\nerNEAT&#39;s extensions. The theory states that within the brain there is first=\r\n a process of selection in creating the brain&#39;s anatomy, with small epigene=\r\ntic changes occurring in development (Here you can imagine that the anatomy=\r\n in HyperNEAT is our substrate). Then in the postnatal stage, there is a ti=\r\nme of neuron selection, where some synaptic connections are strengthened, a=\r\nnd others simply disappear altogether through neuron death (something with =\r\nlittle or no parallel in HyperNEAT). He gives as an example a chicken, whic=\r\nh is born with 20,000 neurons. At the adult stage, the chicken has 12,000 n=\r\neurons, keeping only 60% of the original neurons. There is in fact much mor=\r\ne to this theory, but I am in no way able to communicate it effectively. I =\r\nencourage you to read any of his papers of books (or a quick Wikipedia scan=\r\n). My interest was in HyperNEAT&#39;s possible abstraction of the idea. \n&gt; \n&gt; S=\r\nomething HyperNEAT has yet to incorporate is the idea of intra-life learnin=\r\ng. I read a few of the other posts, and I think this might be in some ways =\r\nrelated to the HybrID conversation about irregularities. HybrID attempts to=\r\n make up for this lack of intra-life learning through the use of NEAT. At s=\r\nome point in the algorithm, HyperNEAT is stopped in favor of using NEAT to =\r\nmore accurately pinpoint irregularities. But this is not really the &quot;job&quot; o=\r\nf evolution, rather this is an intralife task. Evolution can provide the fr=\r\namework (i.e. a species), but the more fit individual is able to adapt to t=\r\nhe irregularities of life (i.e. through intralife learning). \n&gt; \n&gt; The poin=\r\nt I&#39;m laboriously trying to bring you to is that I believe substrate evolut=\r\nion and intralife learning are related. And perhaps you could take out two =\r\nbirds with one stone using some ideas from neural Darwinism. My idea is a b=\r\nit crude, and the details aren&#39;t ironed out, but these were some thoughts. =\r\nSpeaking strictly about HyperNEAT, what I thought would be helpful would be=\r\n to generate more points then necessary within the substrate. This would ha=\r\nppen during mutation/crossover. Perhaps duplicating inputs in more than one=\r\n place on the substrate (within a certain distance from each other), and ad=\r\nding additional layers in the hidden nodes (if they exist). Through the eva=\r\nluation of the new population, essentially neuron&#39;s that fire together wire=\r\n together (as Edelman loves to say in his books) and weights can be modifie=\r\nd slowly during the evaluation, additionally allowing for the removal of le=\r\nss fit neurons. What&#39;s left is an individual whose substrate isn&#39;t strictly=\r\n identical to the original, and weight connections that might slightly diff=\r\ner from the original CPPN. \n&gt; \n&gt; Now problems. There are a host of them, an=\r\nd this is what currently makes this idea a bit clunky and inelegant. At a v=\r\nery basic level, I&#39;m still uncertain how one could reconcile the difference=\r\n between the resulting substrate and the original. Also the resulting CPPN =\r\nand the original. Also scaling issues, when trying to modify neuron connect=\r\nions, making changes to 1 connection weight at a time makes this impossible=\r\n when examining a neural net of 9 million connections. This makes it diffic=\r\nult to convince anyone that this is the direction that HyperNEAT should hea=\r\nd in. Rather, it was my idea to ping some ideas off of you guys. And I do b=\r\nelieve that the solutions to substrate evolution and intralife learning are=\r\n linked, whether or not this is the best way to do it (most likely not). \n&gt;=\r\n \n&gt; Let me know what you guys think,\n&gt; -Paul\n&gt;\n\n\n\n"}}