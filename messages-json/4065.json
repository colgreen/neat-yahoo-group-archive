{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"UT2VBqYz2cB9iakM24vI4VKI8V8WvpsHd5wgPeibIbK41xexte8HBrD_PfdrpQwsLd6X80-98XZSMO5PVJ4GMbDv_7TP0ogshyDn48Z0Hdto","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1210832000","msgId":4065,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwZ2thMCsxMHFxbkBlR3JvdXBzLmNvbT4=","inReplyToHeader":"PEM0NTExQkNBLjIyRDVGJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4064,"nextInTopic":4066,"prevInTime":4064,"nextInTime":4066,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"Jeff, Thanks for asking these questions.  These are likely the kinds of questions we are going to face over time so it s a good chance to work on our response.","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 47703 invoked from network); 15 May 2008 06:13:21 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m36.grp.scd.yahoo.com with QMQP; 15 May 2008 06:13:21 -0000\r\nX-Received: from unknown (HELO n38b.bullet.mail.sp1.yahoo.com) (66.163.168.152)\n  by mta15.grp.scd.yahoo.com with SMTP; 15 May 2008 06:13:21 -0000\r\nX-Received: from [216.252.122.219] by n38.bullet.mail.sp1.yahoo.com with NNFMP; 15 May 2008 06:13:21 -0000\r\nX-Received: from [66.218.69.5] by t4.bullet.sp1.yahoo.com with NNFMP; 15 May 2008 06:13:21 -0000\r\nX-Received: from [66.218.66.74] by t5.bullet.scd.yahoo.com with NNFMP; 15 May 2008 06:13:20 -0000\r\nDate: Thu, 15 May 2008 06:13:20 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g0gka0+10qqn@...&gt;\r\nIn-Reply-To: &lt;C4511BCA.22D5F%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=54567749; y=5vVeeS3VgFZT8Byw7iIz-TqFFK6bP0JsLty--QTen-uuPjpM-via\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff,\n\nThanks for asking these questions.  These are likely the kinds of\nqu=\r\nestions we are going to face over time so it&#39;s a good chance to work\non our=\r\n response.  I&#39;m going to start with a technical response but\nmove to philos=\r\nophical.  It&#39;s a bit of an essay but hopefully worth the\nread.\n\nYour first =\r\nset of questions regards the relationship between novelty\nsearch (NS) and e=\r\nxhaustive search of behavioral space.  Do we think\nthese are effectively th=\r\ne same thing?\n\nI think it&#39;s a tricky subject but in the end I would not equ=\r\nate NS to\nexhaustive search.  While NS indeed does attempt to essentially v=\r\nisit\nevery behavior in behavioral space, the way it does it is not the same=\r\n\nas what is usually meant by exhaustive search.  We usually think of an\nexh=\r\naustive search as a purposeful enumeration, where if I just try\nevery combi=\r\nnation of something, one will be the answer.  A key feature\nof this type of=\r\n search is that it does not require or utilize\ninformation or feedback of a=\r\nny kind as a guide.  Rather, it simply\nmakes sure it does not visit the sam=\r\ne point twice.  (It is similar to\nrandom search except that random search m=\r\night indeed visit the same\npoint twice.)\n\nOne clear difference between such=\r\n a search and NS is that we cannot\npurposefully enumerate all possible beha=\r\nviors because our search space\nis the genotype space, which maps indirectly=\r\n to the behavior space. \nTherefore, there is actually no way to simply say =\r\n&quot;list all possible\nbehaviors&quot; and try each one in succession.  We must seek=\r\n them out.\n\nFurthermore, in novelty search there is *information* guiding t=\r\nhe\norder of points we visit (the information is the novelty measure). \nThe =\r\npoints also have an inherent order (perhaps quite useful) induced\nby the ge=\r\nnetic encoding (hence the promise of combining it with\nHyperNEAT). In other=\r\n words, we are not simply enumerating in an\narbitrary non-overlapping order=\r\n.  Rather, we follow the most promising\ntrails that seem to be leading to s=\r\nomething new.\n\nOne significant consequence of this fact is that the actual =\r\nsearch\nspace (which is the genotype space) will almost certainly never need=\r\n\nto be exhaustively searched.  So we effectively avoided wasting our\ntime e=\r\nxamining all kinds of genetic combinations that would have\nproduced redunda=\r\nnt behaviors.  In its usual meaning, exhaustive search\nwould be just such a=\r\n search through genotype space.  So certainly it\nis not normal exhaustive s=\r\nearch.\n\nYet if you still want to talk about exhaustively searching behavior=\r\n\nspace, it is still not a typical exhaustive search because of the fact\nit =\r\nproceeds in an order guided by information- not typical of\nexhaustive searc=\r\nh.  Another corollary is that it is impossible to\nperform a typical exhaust=\r\nive search of behavior space because we have\nno method to enumerate it:  It=\r\n must be explored.\n\nYet you might still say, fine, semantically perhaps it =\r\nis something\ndifferent, but still, in spirit are you not essentially doing\n=\r\nsomething equally inefficient, i.e. looking for absolutely everything?  \n\nA=\r\nnd it is true that in effect we are searching for every behavior, or\nat lea=\r\nst every behavior that looks distinguishable from each other\nwith respect t=\r\no the novelty metric and in an order from simplicity to\nhigh complexity.  Y=\r\net therein lies the fundamental insight: While such\na search might sound ba=\r\nd, it is a lot better to look at everything (in\nsome meaningful order) and =\r\neventually run across what you want\n(perhaps after a very long time) than t=\r\no look for one specific thing\nand *never* find it.\n\nWe are indeed suggestin=\r\ng that this rather tortured choice (between\nlooking for something without h=\r\nope and looking for everything) is\nsometimes the real choice that we face w=\r\nith the most ambitious\nproblems.  In other words, objective-based fitness i=\r\ns literally doomed\nwhen it comes to evolving many incredibly complex system=\r\ns from\nscratch.  It will simply never happen because at high levels of\ncomp=\r\nlexity, there is going to be massive deception at many levels, and\nfitness =\r\nbecomes as bad as random search in such a problem.  In fact,\nas our results=\r\n show, you don&#39;t even have to make the problem all that\nhard to cause fitne=\r\nss to crumble into something as bad as random\nsearch.  What do you think wi=\r\nll happen if you are trying to evolve a\nneural network into the mind of a q=\r\nuantum physicist based on how\nbrilliant it is at quantum physics?  The answ=\r\ner: Nothing.\n\nA more down-to-earth example is the car that I evolved on Pic=\r\nbreeder.\n It could never have evolved if evolving a car had been the\n*objec=\r\ntive* because it was preceded by an alien face (evolved by\nsomeone else).  =\r\nIt just so happens that the alien face is a stepping\nstone to a car, but if=\r\n we had judged the alien face on it &quot;car-ness,&quot;\nit would have failed misera=\r\nbly and been deleted.  Hence if we were\nlooking for a car we would never ha=\r\nve found one.\n\nIn nature, if we had bred flatworms (the earliest chordates)=\r\n based on\ntheir humanity, they too would have never evolved into amphibians=\r\n,\nthen reptiles, then mammals, as they did.  The objective in long-run\nprob=\r\nlems is totally blind to the necessary stepping stones.  Unless we\nknow the=\r\nm a priori, we are lost.\n\nWhy do you suppose we have never seen a flowering=\r\n of diversity and\ncomplexity such as seen in nature in evolutionary computa=\r\ntion?  In 30\nor 40 years of this field, which is inspired by nature, we hav=\r\ne never\nseen something that comes even close to even nature&#39;s modest\nachiev=\r\nements.  The problem is that we have been blinded by objectives.\n   As soon=\r\n as we set an objective, the stepping stones to it often\nvanish into thin a=\r\nir.  There is no escape from this very sobering\nfact.  It will have to be a=\r\nccepted, though it will be hard to accept.\n\nNovelty search cures this probl=\r\nem, although admittedly in a painful\nway, because it forces us to let go of=\r\n our natural desire to *control*\nwhat is happening.  We feel compelled to d=\r\nemand to the search\nalgorithm that it go in a certain direction.  It is dif=\r\nficult to\nrelinquish this feeling of control, yet if we recognize that in t=\r\nhe\nend the setting of such goals is its own worst enemy, then we can\nbegin =\r\nto be liberated from this longstanding compulsion.\n\n(Note that I am not say=\r\ning fitness is always useless; obviously that\nis not the case.  I am talkin=\r\ng about very ambitious problems, beyond\nthe kind we have been able to solve=\r\n yet- though even the &quot;hard maze&quot;\nis bordering on such a problem.)\n\nYou poi=\r\nnt out that novelty search may get &quot;lost&quot; in a kind of endless\noffshoot in =\r\nbehavior space.  And yes, in some situations, it very well\nmay.  Yet I beli=\r\neve it will not do so in many interesting domains. \nFor example, if there w=\r\nas indeed a long offshoot of the maze, first,\nsince there is a time limit f=\r\nor each robot, it would make little\ndifference and would quickly be filled =\r\nup by novelty search.  If there\nare no obstacles in the offshoot, it would =\r\nbe filled especially fast.\n But at the same time, novelty search is not lik=\r\nely to go off in only\none direction anyway.  Because it is a population, it=\r\n will go off in\nmany directions at once.  While some parts may shoot down t=\r\nhe\ndiversionary offshoot, at the same time others will begin to flow down\nt=\r\nhe paths we want.  If it happens to take the wrong paths, it will\nfill that=\r\n areas first and eventually be pushed back into the areas we\ncare about (on=\r\nly if each individual was given infinite time could it\nbe stuck in one area=\r\n forever)\n\nIn the end, of course there is a chance it will fail to go the r=\r\night\nway in reasonable time; after all, it has no objective!  In fact, in\nt=\r\nhe hard maze experiment, it did once fail to find a solution in 40\nruns.  Y=\r\net look at how much more consistent it is than fitness-based\nsearch.  So th=\r\ne point is not that this is a guarantee (there will\nnever be one).  Rather,=\r\n it is a profoundly different kind of search,\nwhich is likely to reach plac=\r\nes that fitness-based search can never\nhope to touch.  So it opens up a who=\r\nle new world of possibilities to\nevolutionary computation.  That does not m=\r\nean it solves everything; of\ncourse it may still not always give us what we=\r\n want.  There is no\nmethod that will ever always give you what you want.  Y=\r\net objective\nfitness is often even worse.  That is the sobering moral of th=\r\ne story.\n\nSo in my view, NS is actually suited for exactly those &quot;large spa=\r\nces&quot;\nthat you suggest it will have trouble in.  And by large I mean LARGE.\n=\r\n Those are the ones where objective-based fitness has no hope.  These\nare s=\r\npaces like life on earth, where it would be futile (and silly) to\nstart wit=\r\nh a single cell and select offspring based on relative\nhumanity.  The only =\r\nreason we got to humans in nature is because\nnobody said we had to get ther=\r\ne.  It&#39;s almost paradoxical, but if you\naccept it, it is an exciting libera=\r\ntion.  If we let go of the\ncompulsion to be in control, we may find somethi=\r\nng we did not expect\nthat is quite significant.\n\nSo actually the idea of ru=\r\nnning fitness-based search and then novelty\nsearch is less exciting to us a=\r\nlthough we raise it as a practical\nmatter.  In some domains, objective fitn=\r\ness is simply impotent, and\nthe compulsion to have some shred of guidance t=\r\no hang onto is a false\ncomfort.  We will have to let go, and then, strangel=\r\ny, we will end up\nwhere we want to be.  It&#39;s like when your grandparents to=\r\nld you that\nif you stop worrying so much about making things work out, they=\r\n will\nwork out on their own.  Did you believe them?  Maybe there is more\nwi=\r\nsdom in it than there appeared to be.\n\nken\n\n\n--- In neat@yahoogroups.com, J=\r\neff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello. \n&gt; \n&gt; Thanks for the thought provo=\r\nking paper. Here is my main question\nregarding\n&gt; the work: How would you di=\r\nfferentiate the NSA (novelty search algorithm)\n&gt; from exhaustive search in =\r\nthe behavior space?\n&gt; \n&gt; If you think there is a relevant difference betwee=\r\nn the NSA and\nexhaustive\n&gt; behavioral search, have you tried using the form=\r\ner as a control and\nseeing\n&gt; how they compare?\n&gt; \n&gt; If the NSA is effective=\r\nly exhaustive search in behavior space, it\nseems to\n&gt; me that, while it wil=\r\nl work well (and better than a GA) in small,\ndeceptive\n&gt; landscapes, it wil=\r\nl not perform very well in large search spaces.\nImagine,\n&gt; for example, the=\r\n paper&#39;s &quot;medium map&quot; but with a huge (near\ninfinite) open\n&gt; area to the le=\r\nft of the starting condition. It could easily get lost\nover\n&gt; there indefin=\r\nitely.\n&gt; \n&gt; You mention that it helps to have the domain constrain the sear=\r\nch space.\n&gt; Does this just mean that the (behavioral) search space has to b=\r\ne small\n&gt; enough that it can an exhaustive search can deal with it? How wil=\r\nl\nit fare\n&gt; in the much larger search spaces of real-world problems, like c=\r\nheckers?\n&gt; \n&gt; Using the NSA as something to bail out objective-search when =\r\nit\nstagnates is\n&gt; an interesting suggestion. But at that point it should be=\r\n compared to\n&gt; fitness sharing. Would it do better than fitness sharing? I =\r\ncan think of\n&gt; reasons it might (because it truly is not tempted by decepti=\r\nve\ntraps), but\n&gt; it would useful to see it compared to fitness sharing cont=\r\nrols.\n&gt; \n&gt; Just my 2 cents. Thanks for putting this out there.\n&gt; \n&gt; \n&gt; Chee=\r\nrs,\n&gt; Jeff Clune\n&gt; \n&gt; Digital Evolution Lab, Michigan State University\n&gt; \n&gt;=\r\n jclune@...\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; &gt; From: Kenneth Stanley &lt;kstanley@...&gt;\n&gt; &gt; Reply-=\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; Date: Fri, 09 May 200=\r\n8 02:00:33 -0000\n&gt; &gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; =\r\nSubject: [neat] Introducing a New Approach to Search: Novelty\nSearch (New\n&gt;=\r\n &gt; Paper)\n&gt; &gt; \n&gt; &gt; Joel Lehman and I are excited to announce our new public=\r\nation to\n&gt; &gt; appear in the Eleventh International Conference on Articifial =\r\nLife\n&gt; &gt; (ALIFE XI), called &quot;Exploiting Open-Endedness to Solve Problems\n&gt; =\r\n&gt; Through the Search for Novelty.&quot;\n&gt; &gt; \n&gt; &gt; The paper is here:\n&gt; &gt; \n&gt; &gt; htt=\r\np://eplex.cs.ucf.edu/publications.html#lehman.alife08\n&gt; &gt; \n&gt; &gt; Direct link:=\r\n http://eplex.cs.ucf.edu/papers/lehman_alife08.pdf\n&gt; &gt; \n&gt; &gt; This paper is a=\r\nbout a new kind of search (which works with NEAT) that\n&gt; &gt; abandons the lon=\r\ngstanding notion in all of machine learning that the\n&gt; &gt; gradient of search=\r\n should be measured with respect to the ultimate\n&gt; &gt; objective.  In other w=\r\nords, it entirely abandons objectives and\n&gt; &gt; thereby also abandons fitness=\r\n functions as the impetus for search.\n&gt; &gt; Yet remarkably, we still show tha=\r\nt such an algorithm can perform\n&gt; &gt; *better* than one that actually tries t=\r\no achieve the objective!  I\n&gt; &gt; believe this strange result has fascinating=\r\n implications for machine\n&gt; &gt; learning, artificial life, and even biology.\n=\r\n&gt; &gt; \n&gt; &gt; Lately on this forum we have often discussed the nagging problem t=\r\nhat\n&gt; &gt; the fitness function often does not properly recognize or reward th=\r\ne\n&gt; &gt; stepping stones on the way to the solution.  I went as far as\n&gt; &gt; sug=\r\ngesting that the fitness function can become an *obstacle* to\n&gt; &gt; success (=\r\ne.g. when we discussed creativity in Picbreeder).\n&gt; &gt; \n&gt; &gt; While this discu=\r\nssion was largely philosophical, Joel Lehman and I\n&gt; &gt; decided to make it c=\r\noncrete and actually introduce an algorithm that\n&gt; &gt; makes an automated evo=\r\nlutionary process in *any* domain behave like\n&gt; &gt; humans in Picbreeder, tha=\r\nt is, like open-ended evolution.  This\n&gt; &gt; approach is called &quot;novelty sear=\r\nch.&quot;  The algorithm simply searches\n&gt; &gt; for behavior that is novel with res=\r\npect to what has come before.\n&gt; &gt; \n&gt; &gt; The benefit of this approach is that=\r\n it is immune to deception because\n&gt; &gt; it does not even try to achieve the =\r\nobjective.  I know it seems\n&gt; &gt; strange but, counterintuitively, we show th=\r\nat in fact it is far more\n&gt; &gt; effective at solving a difficult problem in a=\r\n deceptive landscape than\n&gt; &gt; fitness-based search.\n&gt; &gt; \n&gt; &gt; In other words=\r\n, what we are saying is that to achieve some of the most\n&gt; &gt; ambitious obje=\r\nctives we might have for evolution, we must abandon\n&gt; &gt; trying to explicitl=\r\ny achieve them.  To quote from the end of our\n&gt; &gt; Discussion section:\n&gt; &gt; \n=\r\n&gt; &gt; &quot;In summary, almost like a riddle, novelty search suggests\n&gt; &gt; a surpri=\r\nsing new perspective on achievement: To achieve\n&gt; &gt; your highest goals, you=\r\n must be willing to abandon them.&quot;\n&gt; &gt; \n&gt; &gt; I believe this lesson is true i=\r\nn practice and is therefore beyond a\n&gt; &gt; philosophical curiosity.  In fact,=\r\n we are instinctively familiar with\n&gt; &gt; it in life in general when people s=\r\nay things like &quot;You are trying too\n&gt; &gt; hard&quot; or when we focus so much on so=\r\nmething so far ahead of us in life\n&gt; &gt; that we forget completely to solve t=\r\nhe short term problems that stand\n&gt; &gt; in our way.  It is no less true in ev=\r\nolution or search in general.\n&gt; &gt; \n&gt; &gt; For NEAT, novelty search should open=\r\n up new opportunities for\n&gt; &gt; discovery that were previously closed off to =\r\nus.\n&gt; &gt; \n&gt; &gt; I look forward to hearing your thoughts on this work.\n&gt; &gt; \n&gt; &gt;=\r\n ken\n&gt; &gt;\n&gt;\n\n\n\n"}}