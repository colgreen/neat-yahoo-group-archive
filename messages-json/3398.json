{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"BTdy9Z2Gud-i1a85ZJJcUuwULISi6EAe9ZEIvt1j2eKHRz_QzSWSprDNmQ9761SgXYjjeN6c50YPReoOO4Y12U5fqzzcjMPjGhQgHE5uFrkF","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: ANJI : NEAT implementation (fingerprint implementation issues)","postDate":"1181764293","msgId":3398,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY0cGhzNStsZGM3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGY0ajkwZitxaGN1QGVHcm91cHMuY29tPg=="},"prevInTopic":3397,"nextInTopic":3399,"prevInTime":3397,"nextInTime":3399,"topicId":3384,"numMessagesInTopic":37,"msgSnippet":"Hi Peter, I agree with your statement of the problem.  In a way, translation and scaling are both natural, but rotation is particularly difficult to evolve.","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 7080 invoked from network); 13 Jun 2007 19:51:48 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m44.grp.scd.yahoo.com with QMQP; 13 Jun 2007 19:51:48 -0000\r\nReceived: from unknown (HELO n31d.bullet.scd.yahoo.com) (66.94.237.9)\n  by mta6.grp.scd.yahoo.com with SMTP; 13 Jun 2007 19:51:48 -0000\r\nReceived: from [209.73.164.83] by n31.bullet.scd.yahoo.com with NNFMP; 13 Jun 2007 19:51:34 -0000\r\nReceived: from [66.218.66.87] by t7.bullet.scd.yahoo.com with NNFMP; 13 Jun 2007 19:51:34 -0000\r\nDate: Wed, 13 Jun 2007 19:51:33 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f4phs5+ldc7@...&gt;\r\nIn-Reply-To: &lt;f4j90f+qhcu@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: ANJI : NEAT implementation (fingerprint implementation issues)\r\nX-Yahoo-Group-Post: member; u=54567749; y=PulXTTdYg7LiVA0osju5lPpH_tV1kkS2J2a0BG8qECRU1_frunW0\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nHi Peter,\n\nI agree with your statement of the problem.  In a way, translati=\r\non \nand scaling are both natural, but rotation is particularly difficult \nt=\r\no evolve.  If it did evolve, it would take significant effort for \nHyperNEA=\r\nT to discover the concept of rotation.\n\nThat suggests that perhaps there is=\r\n a way to make rotation a \ncanonical activation function instead of somethi=\r\nng that needs to be \ncomposed from several parts. However, like you say, it=\r\n&#39;s hard to \nimagine how a single (traditional) neuron could implement a rot=\r\nation \nfunction that requires multiple variables.\n\nOne idea is to create a =\r\nnew kind of neuron that actually has \ndistinct input entrances.  That way, =\r\nit is possible to have an &quot;x&quot; \nand a &quot;y&quot; entrance to the rotation node.  Ea=\r\nch entrance could itself \nbe a summation of activation coming from elsewher=\r\ne, just like a \nregaular node input.\n\nAnother issue is the alpha argument. =\r\n I need to think about that a \nlittle more because we do not want to explic=\r\nitly enter an alpha.  \nYet then what is the rotation operating on?  \n\nken  =\r\n\n\n--- In neat@yahoogroups.com, &quot;petar_chervenski&quot; \n&lt;petar_chervenski@...&gt; w=\r\nrote:\n&gt;\n&gt; Hi Ken, \n&gt; \n&gt; I made the eye static as you suggested in one previ=\r\nous disscussion \n&gt; about this experiment, using HyperNEAT for visual recogn=\r\nition. \n&gt; (Roving eye & HyperNEAT is an overkill). It is &quot;alive&quot; for about =\r\n5 \n&gt; timesteps, in order to use some reccurence. \n&gt; \n&gt; I think about the ro=\r\ntation.. So, let&#39;s clear things out. \n&gt; A point (X,Y) is rotated with angle=\r\n (Aplha) to (X1, Y1).  \n&gt; This is a function, taking 3 arguments and return=\r\ning 2. \n&gt; \n&gt; x1=3D y*sin(alpha) + x*cos(alpha)\n&gt; y1=3D y*cos(alpha) - x*sin=\r\n(alpha)\n&gt; \n&gt; I think this cannot be covered by a single neuron, but a clust=\r\ner \nof \n&gt; neurons with sin() and cos() activation functions.. Am I right? \n=\r\n&gt; Let&#39;s say that we have 2 inputs (x, y) and a bias node in the \nCPPN. \n&gt; F=\r\nurther, we have 2 hidden nodes, one is &quot;sine&quot; other is &quot;cosine&quot;. \n&gt; These h=\r\nidden nodes are both connected to the bias. The bias here \nis \n&gt; our &quot;alpha=\r\n&quot; value. \n&gt; Then, we can imagine how these nodes should be connected to \nco=\r\nnstruct \n&gt; this formula above. We need linear outputs, and maybe some \naddi=\r\ntional \n&gt; linear nodes with multiplying summing functions (to represent the=\r\n \n&gt; multiplications by x and y)... \n&gt; \n&gt; Similar, translation can be handle=\r\nd even easier. The main \ncoordinate \n&gt; frames has to be connected to 2 line=\r\nar nodes, where an addition to \na \n&gt; bias occurs in each. \n&gt; \n&gt; Scaling is =\r\nin fact everywhere, since the weights of the \nconnections \n&gt; can be thought=\r\n of as scalars of the coordinate frames. \n&gt; \n&gt; So, that were the 3 main tra=\r\nnsformations.. :) \n&gt; But the rotation seems hard to evolve.. And using line=\r\nar nodes and \n&gt; multiplying summing functions (before the activation) is im=\r\nportant.\n&gt; \n&gt; Peter\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;ks=\r\ntanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com, &quot;petar_chervenski&quot; \n&lt;p=\r\netar_chervenski@&gt; \n&gt; &gt; wrote:\n&gt; &gt; &gt; - My current experiments with ActiveVis=\r\nion show that it is \nhard \n&gt; to \n&gt; &gt; &gt; evolve substrates that recognize sim=\r\nple shapes that are \nrandomly \n&gt; &gt; &gt; rotated. Perhaps I should tweak the NE=\r\nAT parameters or the set \nof \n&gt; &gt; &gt; activation functions? \n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; =\r\nPeter, in the experiment you are describing, are you using a \nroving \n&gt; eye=\r\n \n&gt; &gt; or just inputting a whole image into the substrate?  With \n&gt; HyperNEA=\r\nT, it \n&gt; &gt; should be possible to do recognition tasks without needing a \nro=\r\nving \n&gt; eye.\n&gt; &gt; \n&gt; &gt; In any case, I believe rotational invariance is indee=\r\nd an \n&gt; activation \n&gt; &gt; function issue.  The problem is that you need to ge=\r\nt the same \n&gt; pattern \n&gt; &gt; of connects repeated in a rotating fashion, so t=\r\nhat they can \n&gt; recognize \n&gt; &gt; rotated images.  This kind of rotation is no=\r\nt a very natural \n&gt; byproduct \n&gt; &gt; of the usual set of activation functions=\r\n.  I believe there is \n&gt; probably \n&gt; &gt; a rotational activation function tha=\r\nt would be quite helpful, \nbut I \n&gt; &gt; have not resolved what function that =\r\nshould be.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt;\n&gt;\n\n\n\n"}}