{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":8147458,"authorName":"Christian","from":"&quot;Christian&quot; &lt;Christian.Hofmann@...&gt;","profile":"chhofchhof","replyTo":"LIST","senderId":"5_E0959GWS6Fx0kG93eMSFPUw8MHMnGncbNrka1vi_xg01CgieHyo8DXyePCNy7GJgewGWAQogPYFqfpLOLKVF19heaOg7xCwMhrK4k","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Evaluating population with large training data set","postDate":"1218059139","msgId":4253,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGc3ZDYyMytiaXA0QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4254,"prevInTime":4252,"nextInTime":4254,"topicId":4253,"numMessagesInTopic":11,"msgSnippet":"Hello, I want to discuss with you about this topic. The main bottleneck of NEAT is the evaluation of every created network to get the fitness. But what if you","rawEmail":"Return-Path: &lt;Christian.Hofmann@...&gt;\r\nX-Sender: Christian.Hofmann@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 50741 invoked from network); 6 Aug 2008 21:45:40 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m50.grp.scd.yahoo.com with QMQP; 6 Aug 2008 21:45:40 -0000\r\nX-Received: from unknown (HELO n34b.bullet.mail.sp1.yahoo.com) (66.163.168.148)\n  by mta17.grp.scd.yahoo.com with SMTP; 6 Aug 2008 21:45:40 -0000\r\nX-Received: from [216.252.122.217] by n34.bullet.mail.sp1.yahoo.com with NNFMP; 06 Aug 2008 21:45:40 -0000\r\nX-Received: from [66.218.69.4] by t2.bullet.sp1.yahoo.com with NNFMP; 06 Aug 2008 21:45:40 -0000\r\nX-Received: from [66.218.66.89] by t4.bullet.scd.yahoo.com with NNFMP; 06 Aug 2008 21:45:40 -0000\r\nDate: Wed, 06 Aug 2008 21:45:39 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g7d623+bip4@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Christian&quot; &lt;Christian.Hofmann@...&gt;\r\nSubject: Evaluating population with large training data set\r\nX-Yahoo-Group-Post: member; u=8147458; y=msrQq26eWaXUvQamqIUm132LVYcVQALf3MeJcw9FCN1MGGeK-g\r\nX-Yahoo-Profile: chhofchhof\r\n\r\nHello,\n\nI want to discuss with you about this topic. The main bottleneck of=\r\n\nNEAT is the evaluation of every created network to get the fitness.\nBut wh=\r\nat if you have big networks and very much training data? I have\nover one mi=\r\nllion training datasets that I need to evaluate for every\nnetwork. I need a=\r\nbout one minute per network. \n\nI have thought about some solutions regardin=\r\ng this problem. Maybe you\nhave already tried one of these or you think that=\r\n I cannot do some of\nthem or should favorite one of them.\nFirst I need to s=\r\nay that I calculate the fitness based on fitness\nvalues divided by the numb=\r\ner of used sample data. So it is the same\nfitness level regarding of using =\r\n10% or 100% of the training data.\n\n1) You could evaluate only (for example)=\r\n 10% of the training data. And\ncalculate the overall fitness based on this =\r\ndata.  Then if the fitness\nis higher than the previous highest  10% fitness=\r\n data, calculate the\nremaining 90% and return the value for all 100% traini=\r\nngdata. If the\nfitness is lower than the previous highest 10% fitness data =\r\nyou can\nreturn the fitness data for these 10%.\n\nI don&#39;t know if it is bette=\r\nr to choose just the first 10% of training\ndata (so every network is gettin=\r\ng the same data) or just picking the\n10% training data by random from the c=\r\nomplete training data set. I\ndon&#39;t know if 10% is the right number or if yo=\r\nu should use some\nadditional steps (10%, 25%,50%, 75%, 100%). I really don&#39;=\r\nt know.\n\n2) Instead of choosing just 10% if the data we could choose the\ntr=\r\naining data that correlate like 0 or -1 with the other training\ndata.  This=\r\n way we train with data that is the most different. But\nhow get this correl=\r\nation? I don&#39;t know if there is an algorithm.\nSpecialty if you have 100 inp=\r\nut and 300 output neurons =85\n\n3) Just pick 10% training data randomly from=\r\n the complete training\ndata set without calculating the other 90% ever. Thi=\r\ns way every\ntraining dataset will get chosen one time. \n\nDo you have some e=\r\nxperience in this area? Maybe there are some other\nways. I would really app=\r\nreciate to hear them :-)\n\nKind regards,\n\nChristian\n\n\n\n"}}