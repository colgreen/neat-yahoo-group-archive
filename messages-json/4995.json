{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":413981748,"authorName":"openmind767","from":"&quot;openmind767&quot; &lt;openmind767@...&gt;","profile":"openmind767","replyTo":"LIST","senderId":"C9-JTFNFVKp334ZTuc0_OBjkXS1xxn2PgqjGKAa8dZRkUqfnA_JkOwIRmX8ceqcp4QbUSEOL8IFfEk5qntvxW-2JcQZewmx3X2yNfA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"solution for NEAT on CUDA","postDate":"1260378844","msgId":4995,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhmb2xzcytjMmJ1QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":5000,"prevInTime":4994,"nextInTime":4996,"topicId":4995,"numMessagesInTopic":8,"msgSnippet":"Hi, I use NEAT these days. Although I have add parallel for EvaluateNetwork and SSE for sigmoid, the performance is still not well. Maybe performance will","rawEmail":"Return-Path: &lt;openmind767@...&gt;\r\nX-Sender: openmind767@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 74683 invoked from network); 9 Dec 2009 17:16:58 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m5.grp.sp2.yahoo.com with QMQP; 9 Dec 2009 17:16:58 -0000\r\nX-Received: from unknown (HELO n37b.bullet.mail.sp1.yahoo.com) (66.163.168.151)\n  by mta2.grp.re1.yahoo.com with SMTP; 9 Dec 2009 17:16:58 -0000\r\nX-Received: from [69.147.65.174] by n37.bullet.mail.sp1.yahoo.com with NNFMP; 09 Dec 2009 17:14:04 -0000\r\nX-Received: from [98.137.34.34] by t12.bullet.mail.sp1.yahoo.com with NNFMP; 09 Dec 2009 17:14:04 -0000\r\nDate: Wed, 09 Dec 2009 17:14:04 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hfolss+c2bu@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;openmind767&quot; &lt;openmind767@...&gt;\r\nSubject: solution for NEAT on CUDA\r\nX-Yahoo-Group-Post: member; u=413981748; y=lte9Aa3Gr2aHLrH7IXb9R9z8sgbgGqHnjxLIrTSeEjPMEcgNZ2U\r\nX-Yahoo-Profile: openmind767\r\n\r\nHi, I use NEAT these days. Although I have add parallel for \nEvaluateNetwor=\r\nk and SSE for sigmoid, the performance\nis still not well. Maybe performance=\r\n will never be satisfied.\nThe performance profile show 90% cpu time is used=\r\n in \nMatrix-Vector Multiplication and sigmoid.\n\nCUDA maybe is the best solu=\r\ntion for the performance now. But\nCUDA program is not like normal program. =\r\nI don&#39;t have any \nexperience with CUDA. As I think, in most case single net=\r\nwork \nstructure is not too big. When Calling CUDA do Matrix-Vector \nMultipl=\r\nication and sigmoid for one network, CUDA memory latency \nwill not be hidde=\r\nn. so it wont gain too much performance for \nsingle network. Join all netwo=\r\nrks of population into one big \nnetwork, and call CUDA to do this big netwo=\r\nrk, CUDA memory latency\nwill be hidden well. Maybe this is good solution fo=\r\nr NEAT on CUDA.\nAny suggestion and experience is welcome.\n\nThanks,\nBaihi\n\n\n"}}