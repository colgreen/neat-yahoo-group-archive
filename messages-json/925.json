{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"-aP8efhqT_FU4tckWt7_gc2Ht7axm1jSdZAIsOLMrKTBLjmiH00yIKWHq6QxMZ_u16SqSLN4XdwOvpMtCwBa7UPHH9foNqK11U3cfu2njyLl","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Network Stabilization Question","postDate":"1086034068","msgId":925,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGM5ZzNhays4YXU5QGVHcm91cHMuY29tPg==","inReplyToHeader":"PEJBWTE4LURBVjY0ZGRxTjE5YkIwMDAyMmY4M0Bob3RtYWlsLmNvbT4="},"prevInTopic":924,"nextInTopic":926,"prevInTime":924,"nextInTime":926,"topicId":871,"numMessagesInTopic":15,"msgSnippet":"Robert, I understand why you want to let the networks learn to remember on their own.  I agree with the idea of activating the network some constant n times","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 88767 invoked from network); 31 May 2004 20:08:20 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m22.grp.scd.yahoo.com with QMQP; 31 May 2004 20:08:20 -0000\r\nReceived: from unknown (HELO n22.grp.scd.yahoo.com) (66.218.66.78)\n  by mta4.grp.scd.yahoo.com with SMTP; 31 May 2004 20:08:20 -0000\r\nReceived: from [66.218.67.152] by n22.grp.scd.yahoo.com with NNFMP; 31 May 2004 20:07:51 -0000\r\nDate: Mon, 31 May 2004 20:07:48 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;c9g3ak+8au9@...&gt;\r\nIn-Reply-To: &lt;BAY18-DAV64ddqN19bB00022f83@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 3849\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.78\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Network Stabilization Question\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nRobert,\n\nI understand why you want to let the networks learn to remember on \ntheir own.  I agree with the idea of activating the network some \nconstant n times for each move.  In general you are treating TTT (or \nwhatever discrete domain) as a continuous domain in the sense that \nthere is now continuity between game states.  In such a situation \nthe amount of times you activate the network per step should be \nrelated to how much the situation can change from one state to the \nnext.  For example, in a driving simulation with very small times \nsteps (0.01 seconds, say), you don&#39;t need much more than 1 \nactivation per state.  But in TTT, the world can totally change from \none state to the next (in terms of what the right thing to do is) so \nI would recommend a fairly high number of activations.  Actually, \nthe 10 you have now sounds reasonable to me.\n\nThere may be other issues in memory aside from # activations and \nrecurrency.  For example, the neural activation model may need to be \nrevised to get really good performance.  Or you may want to use \nadaptive networks with Hebbian connections.  It&#39;s a very interesting \nissue you&#39;re exploring and I have a feeling it&#39;s fairly nontrivial \nand deep.\n\nken\n\n--- In neat@yahoogroups.com, &quot;Robert Winkel&quot; &lt;robert_winkel@h...&gt; \nwrote:\n&gt; Ken,\n&gt; \n&gt; I thought about using standard perfect memory and allowing\n&gt; the neural network access to this memory, but this will defeat\n&gt; my true goal.  I don&#39;t want to have to tell the networks that\n&gt; memory is important, or even how much to remember.\n&gt; I want evolution to find out that memory is a good thing for\n&gt; the networks to have and also how they should use this\n&gt; memory for their advantage.\n&gt; \n&gt; Chad,\n&gt; \n&gt; If I don&#39;t stabilize, should I at least activate the network a set\n&gt; number of times?  If I only activate the network once, then\n&gt; the mapping of current input to current output can only be\n&gt; very simple.  What I am thinking is that I pick a number of\n&gt; activations that corresponds to the approximate memory\n&gt; size that I am after, so that if I would like the network to\n&gt; remember the last 5 states, then I will relax the network by\n&gt; activating it 5 times for each input.  What&#39;s your opinion on\n&gt; this?\n&gt; \n&gt; One thing that I am not concerned about is &quot;perfect&quot; memory.\n&gt; Humans don&#39;t have perfect memory, and it tends to degrade\n&gt; over time.  I would be happy if my experimental game player\n&gt; shows use of memory, even if it is imperfect.  One of the\n&gt; experiments that I have coded up and had a preliminary run\n&gt; was with Tic Tac Toe, but with one twist - I only present to\n&gt; the network the opponent&#39;s *current* move - it is up to the\n&gt; network to remember the opponent&#39;s (and its own) previous\n&gt; moves.  During my preliminary run, the fitness of the networks\n&gt; continued to increase, slowly, over time.  I will soon run this\n&gt; experiment properly, and intend to turn it into a competitive\n&gt; coevolutionary one.  In this experiment, I set the depth for\n&gt; relaxation to 10, simply because it was a few more than the\n&gt; required memory size and I assumed that this would be enough\n&gt; to evolve the necessary recurrent links for memory. I am not\n&gt; sure whether or not this is a good idea, although my preliminary\n&gt; results showed increasing fitness.\n&gt; \n&gt; &gt; Yeah like Chad said, stabilization is not something I&#39;d use for \n&gt; &gt; memory tasks.  One hack to consider is that if you know exactly \nwhat \n&gt; &gt; prior activations you need in memory you can just have them be \n&gt; &gt; inputs, as in a sliding window of past activations.\n&gt; &gt; \n&gt; &gt; ken\n&gt; \n&gt; &gt; &gt; My first impulse to your question is to say: don&#39;t stabalize!\n&gt; &gt; &gt; Stabalizing is a method to destroy memory information by \nrepeatedly\n&gt; &gt; &gt; inputing the current state, and waiting until that input \npropigates the\n&gt; &gt; &gt; network. So, yes, the network &quot;forgets&quot; previous states.\n&gt; &gt; &gt;\n&gt; &gt; &gt; chad\n\n\n"}}