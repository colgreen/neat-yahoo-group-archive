{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":191742632,"authorName":"maitrikaruna","from":"&quot;maitrikaruna&quot; &lt;kevin@...&gt;","profile":"maitrikaruna","replyTo":"LIST","senderId":"mjPY_8ZgRvXQpZOtBkBwQ5cg4o2tOky7Dwss8EhW0IyJ03YeaAhFpQeaF1nR7Y8Gc4LzFYCJT3lxKcPr2U-_h3tB1fDG_R8ZnEwdHZFqdg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Introduction---recurrency question","postDate":"1125609923","msgId":2232,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRmN3JrMys3MTV0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDUxN2ZhNmYxMDUwODMxMTcyNzc1OWU1Y2RjQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":2231,"nextInTopic":2233,"prevInTime":2231,"nextInTime":2233,"topicId":2209,"numMessagesInTopic":42,"msgSnippet":"John, I want to add that the only difference between what I was doing and what you propose was the resetting of the net.  Of course I only calc d dependencies","rawEmail":"Return-Path: &lt;kevin@...&gt;\r\nX-Sender: kevin@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 53142 invoked from network); 1 Sep 2005 21:25:23 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m35.grp.scd.yahoo.com with QMQP; 1 Sep 2005 21:25:23 -0000\r\nReceived: from unknown (HELO n14a.bulk.scd.yahoo.com) (66.94.237.28)\n  by mta3.grp.scd.yahoo.com with SMTP; 1 Sep 2005 21:25:23 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.69.3] by n14.bulk.scd.yahoo.com with NNFMP; 01 Sep 2005 21:25:23 -0000\r\nReceived: from [66.218.66.78] by mailer3.bulk.scd.yahoo.com with NNFMP; 01 Sep 2005 21:25:23 -0000\r\nDate: Thu, 01 Sep 2005 21:25:23 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;df7rk3+715t@...&gt;\r\nIn-Reply-To: &lt;517fa6f10508311727759e5cdc@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 9398\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;maitrikaruna&quot; &lt;kevin@...&gt;\r\nSubject: Re: Introduction---recurrency question\r\nX-Yahoo-Group-Post: member; u=191742632; y=bh2_EjxGT7gJKt46uFCvB_2ZdxuTDxYs__-FIVAi_bivhehVhSJ8\r\nX-Yahoo-Profile: maitrikaruna\r\n\r\nJohn,\n\nI want to add that the only difference between what I was doing and \nwhat you propose was the resetting of the net.  Of course I only \ncalc&#39;d dependencies once...i understand how to fire and add the \nweights..\n\nEven for a neophyte like me, that is pretty straightforward :)\n\nI am moving towards something much more complex.  I would like to \ntry and implement NEAT+Hawkins(On Intelligence) ideas on how the \nbrain works.  This requires more complex structures that allow, for \ninstance, for recurrent connections back to *input* nodes.  In the \nhuman brain the feedback mechanisms actually far outnumber the the \nfeed forward ones.  Hawkins proposes that we use this &quot;memory&quot; to \ninterpert what we see, hear, feel, etc.  So while the inputs are \ntelling the output what they &quot;see&quot;, the output is simoultaneously \ntelling the input what it *expects* to see.\n\nthere is also a strong temporal aspect to this according to \nhawkins.  incorporating both the feedback and temporal aspects into \na net raises the level of complexity quite a bit.  Hawkins team has \nimplemented a fixed structure hierarchy that is not really a NN.  It \nuses bayesian probabilities throughout the feedback mechanism.  \nTheir early tests show some real promise in invariant visual \nrecognition...but I feel their structure is too constrained and \nwould like to see if NEAT can be applied with his concepts \nincorporated.  It may not work or may be too complex...I dunno...\n\nI am running a software company, so I have limited time to theorize \non this, which I would rather be doing!  But I have to pay the bills \nsomehow ;)\n\n--Kevin\n\n--- In neat@yahoogroups.com, John Arrowwood &lt;jarrowwx@g...&gt; wrote:\n&gt; Kevin,\n&gt; \n&gt; What you&#39;ve described here is far too complicated.  You&#39;re doing \ntoo\n&gt; much work.  Try this:\n&gt; \n&gt; For a given network topology, you only need to determine the firing\n&gt; order ONCE.  Save that list somewhere.  It will be consulted every\n&gt; time the network is activated, which may be thousands of times for \na\n&gt; single fitness evaluation.  And of course a single network may be\n&gt; fitness evaluated multiple times with different scenarios \npresented to\n&gt; it during the course of a generation.  And if that topology \nsurvives\n&gt; into the next generation, you might as well take that list with \nit...\n&gt; \n&gt; When you are testing your network, you are testing it in a\n&gt; &#39;simulation&#39; where it checks the state of the world.  That \ndetermines\n&gt; the values of the &#39;input&#39; nodes.\n&gt; \n&gt; You zero out the state of all neurons only ONCE.  AT the beginning \nof\n&gt; the simulation.\n&gt; \n&gt; Then, for a single time-step, you fire each neuron in the order \nthat\n&gt; it exists in the list.  The first time through, if a connection \nrefers\n&gt; to a neuron that hasn&#39;t fired yet, the output of that neuron is 0, \nso\n&gt; the input value that is sent to the firing neuron is zero.\n&gt; \n&gt; At the end of that firing pass, you process the outputs, update the\n&gt; &#39;real world&#39; of the simulation, and alter the inputs accordingly.  \nDO\n&gt; NOT RESET ANYTHING INSIDE THE NETWORK!  This continues in an \ninfinite\n&gt; loop until an exit condition is met, namely either failure of the\n&gt; network to meet its objective in a timely fashion, or success in\n&gt; accomplishing the desired goal.\n&gt; \n&gt; Make sense?  Again, you only reset neurons once, at the beginning \nof\n&gt; fitness testing (for a given scenario).  From that moment on, a\n&gt; neuron&#39;s value is retained for the next time it is accessed.\n&gt; \n&gt; Here&#39;s the difference between this approach and the &#39;canonical&#39;\n&gt; approach.  In the canonical approach you have two values for every\n&gt; neuron:  Last timestep&#39;s value, and this timestep&#39;s value.  Or\n&gt; &quot;beginning value&quot; and &quot;ending value&quot;.  For input neurons, they are\n&gt; always one and the same.  Whenever a neuron references the value of\n&gt; another neuron, it always inspects the OLD or beginning value.  \nThen,\n&gt; it doesn&#39;t matter what order you process the nodes in.  You process\n&gt; every node, one by one, always referencing the old value of that\n&gt; neuron.  And you write the new value of the node you are working \non to\n&gt; the other or ending value.\n&gt; \n&gt; In a standard feed-forward network with 3 hidden layers, the first\n&gt; timestep will only propagate the signal one layer down.  At which\n&gt; point, in a &#39;simulation&#39;, the real world inputs may change.  Now, \nthe\n&gt; value of the first hidden layer has been changed, so the second \nlayer\n&gt; will be calculated using those modified values.  But the inputs may\n&gt; have changed, so the first layer will change.  But no matter, the\n&gt; second layer is being calculated using the values that were \npresent in\n&gt; the first hidden layer at the end of the last time step.\n&gt; \n&gt; The &#39;optimized&#39; approach that I was advocating doesn&#39;t bother \nhaving a\n&gt; &#39;before&#39; and an &#39;after&#39; (or last and current) value.  It just has a\n&gt; value.  When another node references the value of a node, it\n&gt; references the current value of that node.  As soon as that node \ngets\n&gt; calculated, the value of the node changes.  In a recurrent network,\n&gt; some nodes my reference the value of a particular node BEFORE it \nwas\n&gt; updated, and others may reference it AFTER.  For the puritan, that\n&gt; &#39;unpredictability&#39; would be undesirable.  But since you are \nevolving a\n&gt; network that WORKS, that argument becomes purely academic.\n&gt; \n&gt; Unless of course tests show that for a particular experiment it\n&gt; requires more topology to solve the same problem using the one \nfiring\n&gt; mechanism over the other.  In that case, the academic argument \nagainst\n&gt; doing it does in fact hold weight.\n&gt; \n&gt; But again, it only matters for a controller, not for a classifier\n&gt; network that is non-recurrent.  So if you are evolving a non-\nrecurrent\n&gt; classifier, and CPU time matters (both during evolution and in the\n&gt; final product), then this optimized routine is for you.  Otherwise,\n&gt; I&#39;d make both activation schemes available, and test evolve \nnetworks\n&gt; using both mechanisms, to find out whether or not it makes a\n&gt; difference in the ability to evolve a solution.\n&gt; \n&gt; Honestly, I can see that there might be pathological cases where \nthis\n&gt; firing approach would hinder the evolution of a solution to a\n&gt; controller.  But only for a particular class of problem, and it \nwould\n&gt; just mean that the successful topology will be different under the \none\n&gt; approach than it would have been under the other approach.  The\n&gt; chances of it being possible to evolve a solution under one \napproach\n&gt; that is impossible to evolve using the other approach are very \nslim. \n&gt; But only experience can tell us if that is true or not.  :p\n&gt; \n&gt; On 8/31/05, maitrikaruna &lt;kevin@t...&gt; wrote:\n&gt; &gt; John,\n&gt; &gt; \n&gt; &gt; thanks for the reply...wish we were all at a whiteboard together \nin\n&gt; &gt; which case we could come up with an elegant solution rather\n&gt; &gt; quickly...\n&gt; &gt; \n&gt; &gt; I understand all that you said, but it still creates problems.  \nThe\n&gt; &gt; idea of recurrency is that it stores a memory that allows the \nnet to\n&gt; &gt; anticipate and strategize based on a prior world state.\n&gt; &gt; \n&gt; &gt; Suppose I follow your idea of activating the net in several \nsteps,\n&gt; &gt; moving my agent in those time steps if the net says to do it, but\n&gt; &gt; not checking the new world state.\n&gt; &gt; \n&gt; &gt; After these several timesteps, I assume I should re-initialize \nthe\n&gt; &gt; inputs to all the neurons to zero.  Then I re-scan the &quot;world&quot;, \nget\n&gt; &gt; my inputs, and do it all again.  But this resetting and \nrescanning\n&gt; &gt; implies no memory of a prior world state since in our internal\n&gt; &gt; timesteps we did not consider the world inputs again until we \nwere\n&gt; &gt; done with our net activation.  Does this make sense?\n&gt; &gt; \n&gt; &gt; I have come up with my own way to handle this and I&#39;m coding it\n&gt; &gt; as we speak.  Following is what I propose:\n&gt; &gt; \n&gt; &gt; 1) I do exactly what John suggested, I have a nice and tight\n&gt; &gt; recursive routine that quickly determines dependencies, which\n&gt; &gt; includes recursive dependencies\n&gt; &gt; \n&gt; &gt; 2) I then activate each neuron that has all its depedencies\n&gt; &gt; fulfilled/processed iteratively, unitl ALL neurons have been\n&gt; &gt; processed.  I also process recurrent links here, BUT if it is\n&gt; &gt; timestep 0, i store the recurrent value in its own place separate\n&gt; &gt; from the neurons non-recurrent, total inputs.  Importantly, at\n&gt; &gt; timestep 0 these recurrent weights are NOT considered in the\n&gt; &gt; firing/non-firing decision of the neuron.\n&gt; &gt; \n&gt; &gt; 3) if the output neurons tell the agent to move, it does so.\n&gt; &gt; \n&gt; &gt; 4) reset ALL the neurons...BUT, if its not timestep 0, then keep \nthe\n&gt; &gt; recurrent totals in the neurons that had a recurrent link back to\n&gt; &gt; them..otherwise erset all neurons totals including recurrent \ntotals\n&gt; &gt; \n&gt; &gt; 5) get the new state of the world..meaning read the input \nvalues..\n&gt; &gt; \n&gt; &gt; 6) process the net as above...if it is not timestep 0, then when\n&gt; &gt; making a fire/not-fire decision, we total the inputs for a neuron\n&gt; &gt; PLUS the recurrent values from the last net execution....so this \nis\n&gt; &gt; the memory of the prior state being used.\n&gt; &gt; \n&gt; &gt; 7) repeat all the above...\n&gt; &gt; \n&gt; &gt; This seems like a practical approach to me that should work,\n&gt; &gt; although I haven&#39;t got it working yet.. The code to fire the\n&gt; &gt; network, even knowing dependencies, is a little tricky.\n&gt; &gt; \n&gt; &gt; Hope this all makes some sense...hard to describe via written \nnote...\n&gt; &gt; \n&gt; &gt; --Kevin\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Yahoo! Groups Links\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt;\n\n\n\n"}}