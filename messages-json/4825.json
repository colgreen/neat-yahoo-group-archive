{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":37465196,"authorName":"Ken Lloyd","from":"&quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;","profile":"kalloyd2","replyTo":"LIST","senderId":"WnpKlYAdYraRJKZqbIQe0B8vapwvSY76nIyhErU-kJqUF2NKL5SiTw35yipZy6wtE5ObUfAMKL2L3YAQYzIYVD8CG7g5Opgf","spamInfo":{"isSpam":false,"reason":"12"},"subject":"RE: [neat] Re: hyperneat questions","postDate":"1250111748","msgId":4825,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDExNzBFOTAxMjM4QjRDNzM5RjMwMTJDM0M2ODc1OThGQHdhdHRwND4=","inReplyToHeader":"PGg1djZsOStlOWoxQGVHcm91cHMuY29tPg==","referencesHeader":"PGg1dWxlOStrZ3U3QGVHcm91cHMuY29tPiA8aDV2Nmw5K2U5ajFAZUdyb3Vwcy5jb20+"},"prevInTopic":4824,"nextInTopic":4826,"prevInTime":4824,"nextInTime":4826,"topicId":4808,"numMessagesInTopic":10,"msgSnippet":"Nikolai, After doing NEAT w/ CUDA for a while, I still consider myself very much a newbie. There is a practical limit to how many GPUs you can run on a","rawEmail":"Return-Path: &lt;kalloyd@...&gt;\r\nX-Sender: kalloyd@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 62660 invoked from network); 12 Aug 2009 21:16:03 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m8.grp.re1.yahoo.com with QMQP; 12 Aug 2009 21:16:03 -0000\r\nX-Received: from unknown (HELO QMTA09.emeryville.ca.mail.comcast.net) (76.96.30.96)\n  by mta2.grp.re1.yahoo.com with SMTP; 12 Aug 2009 21:16:02 -0000\r\nX-Received: from OMTA09.emeryville.ca.mail.comcast.net ([76.96.30.20])\n\tby QMTA09.emeryville.ca.mail.comcast.net with comcast\n\tid TZ9s1c00C0S2fkCA9ZFrBC; Wed, 12 Aug 2009 21:15:51 +0000\r\nX-Received: from wattp4 ([174.56.66.94])\n\tby OMTA09.emeryville.ca.mail.comcast.net with comcast\n\tid TZFq1c00A221HGW8VZFqzr; Wed, 12 Aug 2009 21:15:51 +0000\r\nTo: &lt;neat@yahoogroups.com&gt;\r\nReferences: &lt;h5ule9+kgu7@...&gt; &lt;h5v6l9+e9j1@...&gt;\r\nDate: Wed, 12 Aug 2009 15:15:48 -0600\r\nMessage-ID: &lt;1170E901238B4C739F3012C3C687598F@wattp4&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_007B_01CA1B5F.C664FA70&quot;\r\nX-Mailer: Microsoft Office Outlook 11\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.5579\r\nThread-Index: AcobhsPqSEQtOuazRNGE1rRxx/GFgwABpdAQ\r\nIn-Reply-To: &lt;h5v6l9+e9j1@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;\r\nSubject: RE: [neat] Re: hyperneat questions\r\nX-Yahoo-Group-Post: member; u=37465196; y=fXJBxwPecbz4BfAYZxOs8hksdjJfA-XiA6N0W8xZv3Jk6nE\r\nX-Yahoo-Profile: kalloyd2\r\n\r\n\r\n------=_NextPart_000_007B_01CA1B5F.C664FA70\r\nContent-Type: text/plain;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: 7bit\r\n\r\nNikolai,\n \nAfter doing NEAT w/ CUDA for a while, I still consider myself very much a\nnewbie.\n \nThere is a practical limit to how many GPUs you can run on a motherboard.\nThis is constrained by the number of lanes on the PCIe 2.0 bus and the # of\nmemcpys between host and devices. The most I have been able to run are 3\nGTX-285 (or similar) devices, or 2 GTX-295&#39;s.  I haven&#39;t generated figures\non dual Nehalem boards with dual 5520 chips but the only such mobo I know of\nhas only 3 PCIe x16 slots.  It is interesting how closely QDR InfiniBand\nHCAs matches the new PCIe 2.0 in throughput, and what this holds for my\nRocks/CUDA implementation is still underdetermined.\n \nThere are several (understatement) ways to slice and dice the computations,\nand where in the various kinds of GPU memory (shared, texture) to put what\ndata matrices.  What seems to work best for me (so far) for MPP on the GPU\nkernel is alternating between cycles of evolution, _syncthread, evaluation,\n_syncthread, then repeating that cycle - in parallel across the block(s).  I\nhave other stuff beside the kernel launch and memcpy ops from host to device\ngoing on in the other CPUs during this time. Generally I try to stay with 1\nCPU core for 1 GPU device. Using Intel&#39;s TBB and some early VS-2010 C++ OX\nusing the Parallel Pattern Library were encouraging.\n \nI haven&#39;t made up my mind yet on whether texture memory is really the proper\nplace for just storing NEAT parameters or forward evolution operators\n(without parameters).  The overhead for changing your mind here is steep,\nbut storing NEAT parameters in texture has the current lead.  Stay tuned.\nAs always, any suggestions from others are always welcome.\n \nIsn&#39;t this stuff wickedly complicated?  Too many variables.\n \nKen Lloyd\n\n\n  _____  \n\nFrom: neat@yahoogroups.com [mailto:neat@yahoogroups.com] On Behalf Of\nNikolai\nSent: Wednesday, August 12, 2009 1:54 PM\nTo: neat@yahoogroups.com\nSubject: [neat] Re: hyperneat questions\n\n\n  \n\n--- In neat@yahoogroups. &lt;mailto:neat%40yahoogroups.com&gt; com, &quot;Jason Gauci&quot;\n&lt;jgmath2000@...&gt; wrote:\n&gt;\n&gt; Hey Nikolai,\n&gt; \n&gt; I think the key to implementing HyperNEAT on the GPU would be to take\nadvantage of the fact that substrates are so regular. A sheet of connections\nbetween two layers on a substrate of size (a,b) and (x,y) can be represented\nas a 4d texture of size (a,b,x,y) where the pixel values on the texture hold\nthe link weights. The activation levels of the substrate can be represented\nby textures of size (a,b) and (x,y). Then maybe the GPU can optimize\nmultiplying the activation level texture by the weight texture and summing\nthat and executing the sigmoid, then stuffing that into the next layer.\n&gt; \n&gt; Do you know if something like this is possible on the GPU? I don&#39;t have\nany GPU programming experience.\n&gt; \n\nneither i am an expert in GPU programming. I use CUDA and it maps it pretty\nwell, you even don&#39;t have to know what a texture is. Just knowing the basic\narchitecture of the card is enough. I have ran some activation tests, and a\nsimple kernel to activate 13,107,200 nodes with 7 incoming links each takes\n20 milliseconds (with sigmoid exp-based function, step function would do\nmuch faster). This is on one GPU , but you can have 4 , and even 7 in a\nmotherboard. All connected with a PCI bus transfering at 2.5Gbytes per sec,\nagainst traditional single core cluster on obsolete GigaBit ethernet which\nis only 100MB per sec. With 4 NVIDIA GTX295 cards you can have a\nsupercomputer with 1920 cores for about 4,000-5,000USD. But the key for fast\nimplementation is, of course, knowing your hardware, so , for example to\ncount bits in an integer you don&#39;t use ANDs and ORs, but special assembly\nlanguage instructions like POPCNT, MMX instructions with non-polluting cache\nloads like _mm_stream_si128() which can speed up your software hundreds of\ntimes. I think the only reason we don&#39;t have an artificial brain yet is\nbecause we don&#39;t have enough cores to do the math, but for the methods\ninvented, we already surpassed all the possible algorithms we would need.\nSo, it is all about computing power now.\n\n\n\n\n\n\r\n------=_NextPart_000_007B_01CA1B5F.C664FA70\r\nContent-Type: text/html;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;=\r\n\n&lt;META content=3D&quot;text/html; charset=3Dus-ascii&quot; http-equiv=3DContent-Type&gt;=\r\n\n&lt;META name=3DGENERATOR content=3D&quot;MSHTML 8.00.6001.18812&quot;&gt;&lt;/HEAD&gt;\n&lt;BODY st=\r\nyle=3D&quot;BACKGROUND-COLOR: #ffffff&quot;&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=\r\n=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;Nikolai,=\r\n&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000ff size=\r\n=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/D=\r\nIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000ff size=3D2 face=3DArial=\r\n&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;After doing NEAT w/ CUDA for a while, I =\r\nstill consider \nmyself very much a newbie.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dl=\r\ntr align=3Dleft&gt;&lt;FONT color=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D=\r\n752064220-12082009&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;=\r\nFONT color=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-1208200=\r\n9&gt;There is a practical limit to how many GPUs you can run \non a motherboard=\r\n.&nbsp; This is constrained by the number of lanes on the PCIe \n2.0 bus and=\r\n the # of memcpys between host and devices. The most I have been able \nto r=\r\nun are 3 GTX-285 (or similar) devices, or 2 GTX-295&#39;s.&nbsp; I haven&#39;t \ngen=\r\nerated figures on dual Nehalem boards with dual 5520 chips but the only \nsu=\r\nch&nbsp;mobo I know of has only 3 PCIe x16 slots.&nbsp; It is interesting h=\r\now \nclosely QDR InfiniBand HCAs&nbsp;matches the new PCIe 2.0 in throughput=\r\n, and \nwhat this holds for my Rocks/CUDA implementation is still \nunderdete=\r\nrmined.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000=\r\nff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&n=\r\nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000ff size=3D2 face=\r\n=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;There are several (understatemen=\r\nt) ways to slice and \ndice the computations, and where in the various kinds=\r\n of GPU memory (shared, \ntexture) to put what data matrices.&nbsp; What see=\r\nms to work best for me (so \nfar) for&nbsp;MPP on the GPU kernel&nbsp;is alt=\r\nernating between cycles of \nevolution, _syncthread, evaluation, _syncthread=\r\n, then repeating that cycle - in \nparallel across the block(s).&nbsp; I hav=\r\ne other stuff beside the kernel launch \nand&nbsp;memcpy ops&nbsp;from&nbsp;=\r\nhost to device&nbsp;going on in the other \nCPUs during this time. Generally=\r\n I&nbsp;try to&nbsp;stay with&nbsp;1 CPU core \nfor 1 GPU device.&nbsp;Using=\r\n&nbsp;Intel&#39;s TBB and some early VS-2010 C++ OX \nusing the Parallel Pattern=\r\n Library were encouraging.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;=\r\n&lt;FONT color=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-120820=\r\n09&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#00=\r\n00ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;I haven&#39;t made=\r\n up my mind yet&nbsp;on whether texture \nmemory is really&nbsp;the proper p=\r\nlace for just storing NEAT parameters or \nforward evolution operators (with=\r\nout parameters).&nbsp; The overhead for \nchanging your mind here is steep, =\r\nbut storing NEAT parameters in texture has the \ncurrent lead.&nbsp; Stay tu=\r\nned.&nbsp; As always, any suggestions from others are \nalways welcome.&lt;/SPA=\r\nN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000ff size=3D2 =\r\nface=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;=\r\nDIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPA=\r\nN \nclass=3D752064220-12082009&gt;Isn&#39;t this stuff wickedly complicated?&nbsp; =\r\nToo many \nvariables.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT =\r\ncolor=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;&lt;/S=\r\nPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;FONT color=3D#0000ff s=\r\nize=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D752064220-12082009&gt;Ken Lloyd&lt;/SPAN&gt;&lt;/FO=\r\nNT&gt;&lt;/DIV&gt;&lt;BR&gt;\n&lt;BLOCKQUOTE \nstyle=3D&quot;BORDER-LEFT: #0000ff 2px solid; PADDING=\r\n-LEFT: 5px; MARGIN-LEFT: 5px; MARGIN-RIGHT: 0px&quot; \ndir=3Dltr&gt;\n  &lt;DIV dir=3Dl=\r\ntr lang=3Den-us class=3DOutlookMessageHeader align=3Dleft&gt;\n  &lt;HR tabIndex=\r\n=3D-1&gt;\n  &lt;FONT size=3D2 face=3DTahoma&gt;&lt;B&gt;From:&lt;/B&gt; neat@yahoogroups.com \n  =\r\n[mailto:neat@yahoogroups.com] &lt;B&gt;On Behalf Of &lt;/B&gt;Nikolai&lt;BR&gt;&lt;B&gt;Sent:&lt;/B&gt; \n=\r\n  Wednesday, August 12, 2009 1:54 PM&lt;BR&gt;&lt;B&gt;To:&lt;/B&gt; \n  neat@yahoogroups.com&lt;=\r\nBR&gt;&lt;B&gt;Subject:&lt;/B&gt; [neat] Re: hyperneat \n  questions&lt;BR&gt;&lt;/FONT&gt;&lt;BR&gt;&lt;/DIV&gt;\n =\r\n &lt;DIV&gt;&lt;/DIV&gt;&lt;SPAN style=3D&quot;DISPLAY: none&quot;&gt;&nbsp;&lt;/SPAN&gt; \n  &lt;DIV id=3Dygrp-t=\r\next&gt;\n  &lt;P&gt;--- In &lt;A \n  href=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogro=\r\nups.&lt;WBR&gt;com&lt;/A&gt;, &quot;Jason \n  Gauci&quot; &lt;jgmath2000@&lt;WBR&gt;...&gt; wrote:&lt;BR&gt;&g=\r\nt;&lt;BR&gt;&gt; Hey Nikolai,&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt; I think the key to implementing=\r\n HyperNEAT on the GPU would be to take \n  advantage of the fact that substr=\r\nates are so regular. A sheet of connections \n  between two layers on a subs=\r\ntrate of size (a,b) and (x,y) can be represented \n  as a 4d texture of size=\r\n (a,b,x,y) where the pixel values on the texture hold \n  the link weights. =\r\nThe activation levels of the substrate can be represented by \n  textures of=\r\n size (a,b) and (x,y). Then maybe the GPU can optimize multiplying \n  the a=\r\nctivation level texture by the weight texture and summing that and \n  execu=\r\nting the sigmoid, then stuffing that into the next layer.&lt;BR&gt;&gt; \n  &lt;BR&gt;&g=\r\nt; Do you know if something like this is possible on the GPU? I don&#39;t \n  ha=\r\nve any GPU programming experience.&lt;BR&gt;&gt; &lt;BR&gt;&lt;BR&gt;neither i am an expert i=\r\nn \n  GPU programming. I use CUDA and it maps it pretty well, you even don&#39;t=\r\n have to \n  know what a texture is. Just knowing the basic architecture of =\r\nthe card is \n  enough. I have ran some activation tests, and a simple kerne=\r\nl to activate \n  13,107,200 nodes with 7 incoming links each takes 20 milli=\r\nseconds (with \n  sigmoid exp-based function, step function would do much fa=\r\nster). This is on \n  one GPU , but you can have 4 , and even 7 in a motherb=\r\noard. All connected with \n  a PCI bus transfering at 2.5Gbytes per sec, aga=\r\ninst traditional single core \n  cluster on obsolete GigaBit ethernet which =\r\nis only 100MB per sec. With 4 \n  NVIDIA GTX295 cards you can have a superco=\r\nmputer with 1920 cores for about \n  4,000-5,000USD. But the key for fast im=\r\nplementation is, of course, knowing \n  your hardware, so , for example to c=\r\nount bits in an integer you don&#39;t use ANDs \n  and ORs, but special assembly=\r\n language instructions like POPCNT, MMX \n  instructions with non-polluting =\r\ncache loads like _mm_stream_si128(&lt;WBR&gt;) which \n  can speed up your softwar=\r\ne hundreds of times. I think the only reason we don&#39;t \n  have an artificial=\r\n brain yet is because we don&#39;t have enough cores to do the \n  math, but for=\r\n the methods invented, we already surpassed all the possible \n  algorithms =\r\nwe would need. So, it is all about computing power \n  now.&lt;BR&gt;&lt;BR&gt;&lt;/P&gt;&lt;/DIV=\r\n&gt;&lt;!--End group email --&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_007B_01CA1B5F.C664FA70--\r\n\n"}}