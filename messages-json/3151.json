{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"ogYnHh-N79JDbh9ZXH92L6Kc3NKWP33-uw7d7fKiZNqBc-BISRquaJe_R9uQ1mQEpiRHRWI0YZ0vR8uvUMONR1g-FsG-VhW8P-H8TLQ3UL_e","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Adaptive Representations for NEAT","postDate":"1176526836","msgId":3151,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV2cG41ays3c3NsQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEZEMEMxMTExLUY2NEYtNDQ2MC1CQ0JFLTY5QUUzNkU5NzQyRUBjcy51dGV4YXMuZWR1Pg=="},"prevInTopic":3110,"nextInTopic":3155,"prevInTime":3150,"nextInTime":3152,"topicId":3028,"numMessagesInTopic":34,"msgSnippet":"Joe, how did you program MaxSolve coevolution?  Does that have any bad interactions with fitness sharing in NEAT (some methods for coevolution do) or is it","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 58759 invoked from network); 14 Apr 2007 05:02:25 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m49.grp.scd.yahoo.com with QMQP; 14 Apr 2007 05:02:25 -0000\r\nReceived: from unknown (HELO n30a.bullet.scd.yahoo.com) (66.94.237.33)\n  by mta7.grp.scd.yahoo.com with SMTP; 14 Apr 2007 05:02:24 -0000\r\nReceived: from [66.218.69.3] by n30.bullet.scd.yahoo.com with NNFMP; 14 Apr 2007 05:00:38 -0000\r\nReceived: from [66.218.66.73] by t3.bullet.scd.yahoo.com with NNFMP; 14 Apr 2007 05:00:38 -0000\r\nDate: Sat, 14 Apr 2007 05:00:36 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;evpn5k+7ssl@...&gt;\r\nIn-Reply-To: &lt;FD0C1111-F64F-4460-BCBE-69AE36E9742E@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Adaptive Representations for NEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=RsSpglHqI4cM6sdvHXA3qFSW9UBdFKoM6bpKZFLHOVYrzYcvQBpD\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJoe, how did you program MaxSolve coevolution?  Does that have any \nbad int=\r\neractions with fitness sharing in NEAT (some methods for \ncoevolution do) o=\r\nr is it pretty well compatible?\n\nken\n\n--- In neat@yahoogroups.com, Joseph R=\r\neisinger &lt;joeraii@...&gt; wrote:\n&gt;\n&gt; So a few days back I mentioned some adapt=\r\nive representations work  \n&gt; I&#39;ve been doing using NEAT to study the effect=\r\ns of &quot;development&quot; \non  \n&gt; evolvability. This research has some of the same=\r\n goals as Ken&#39;s \nCPPN  \n&gt; work, but the approach is quite different. Using =\r\na very simple  \n&gt; &quot;indirect&quot; encoding of neural network weights that has so=\r\nme of the  \n&gt; features found in GRNs in biology, we show (empirically) that=\r\n both  \n&gt; the final performance and sample complexity of NeuroEvolution can=\r\n \nbe  \n&gt; improved in a coevolutionary setting.\n&gt; \n&gt; But the story gets even=\r\n better: Making random mutations to the  \n&gt; champions that result from the =\r\nGRN-like encoding, we find that  \n&gt; performance degrades much more slowly t=\r\nhan when the same number of  \n&gt; mutations are made to NEAT-encoded networks=\r\n. Furthermore, if we \nplot  \n&gt; this fitness degradation against network dis=\r\ntance instead of \nmutation  \n&gt; distance, we find that each mutation is havi=\r\nng a vastly larger  \n&gt; phenotypic effect on the GRN-encoded neural nets. In=\r\n other words  \n&gt; performance is decreasing /less/ even when we make /larger=\r\n/ \nchanges  \n&gt; to the network topology and weights. This kind of artifact i=\r\ns \nexactly  \n&gt; what we&#39;d like to see in so-called &quot;evolvable&quot; encodings: Th=\r\ne  \n&gt; representation has learned to bias the effects of mutation towards  \n=\r\n&gt; better networks\n&gt; \n&gt; Anyway, this work is definitely still only a first s=\r\ntep, but I \nfind  \n&gt; it very exciting. My paper is even going up against Ke=\r\nn&#39;s CPPN \npaper  \n&gt; for the best paper award in the GDS track at GECCO. Wis=\r\nh me luck :)\n&gt; \n&gt; If you are at all interested, you should definitely take =\r\na look:\n&gt; \n&gt; http://nn.cs.utexas.edu/keyword?reisinger:gecco07\n&gt; \n&gt; -- Joe\n=\r\n&gt;\n\n\n\n"}}