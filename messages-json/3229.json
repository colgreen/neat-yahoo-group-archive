{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"3s5IG9DeBeANPZ0GzqRuk0cmVMVa2jCpJRFpgNzIR8FZIBajPi3Dw7OO8iebmCEWWPQYnJPvTUdSZAuclRCLuve3pRuuowb76ZQbpupKu-AV","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HyperNEAT and No Free Lunch","postDate":"1177978642","msgId":3229,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYxNjB1aStxN2I1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDcyODQxNzRGLTczRjctNEIyRS04NTAzLTQ1NkQ1NzRDOUU2Q0Bjcy51dGV4YXMuZWR1Pg=="},"prevInTopic":3228,"nextInTopic":3231,"prevInTime":3228,"nextInTime":3231,"topicId":3214,"numMessagesInTopic":27,"msgSnippet":"... could ... what ... don t ... something ... provide ... as ... concept. ... trying ... is ... wrong ... having ... validation ... Really ... and ... falls ","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 83707 invoked from network); 1 May 2007 00:18:41 -0000\r\nReceived: from unknown (66.218.66.70)\n  by m43.grp.scd.yahoo.com with QMQP; 1 May 2007 00:18:41 -0000\r\nReceived: from unknown (HELO n20a.bullet.scd.yahoo.com) (66.94.237.49)\n  by mta12.grp.scd.yahoo.com with SMTP; 1 May 2007 00:18:41 -0000\r\nReceived: from [66.218.69.5] by n20.bullet.scd.yahoo.com with NNFMP; 01 May 2007 00:17:23 -0000\r\nReceived: from [66.218.66.81] by t5.bullet.scd.yahoo.com with NNFMP; 01 May 2007 00:17:23 -0000\r\nDate: Tue, 01 May 2007 00:17:22 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f160ui+q7b5@...&gt;\r\nIn-Reply-To: &lt;7284174F-73F7-4B2E-8503-456D574C9E6C@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: HyperNEAT and No Free Lunch\r\nX-Yahoo-Group-Post: member; u=54567749; y=Rl8iZ0EoDS1Z7Ce6YdfqJpFJbkntCOxKFS_N-VXVtCya--9G_YTC\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n--- In neat@yahoogroups.com, Joseph Reisinger &lt;joeraii@...&gt; wrote:\n&gt;\n&gt; &gt; Hm=\r\nm, yes, that could be interesting.  I see where you&#39;re going.\n&gt; &gt; Maybe the=\r\nre is a theoretically clean way to make the point.  It \ncould\n&gt; &gt; be nice. =\r\n I would definitely not rule it out.\n&gt; &gt;\n&gt; &gt; But I need more guidance towar=\r\nd a statement more concrete than \nwhat\n&gt; &gt; I&#39;ve already said.  You suggest =\r\nthat I misapplied NFL, but I \ndon&#39;t\n&gt; &gt; think I was really applying NFL at =\r\nall.  I was just saying \nsomething\n&gt; &gt; that is already well-accepted about =\r\nNFL, which is that if you \nprovide\n&gt; &gt; a priori bias you are no longer in a=\r\nn NFL situation vs. something\n&gt; &gt; that lacks such bias.  I was not so much =\r\nmaking a new assertion \nas\n&gt; &gt; just bringing it up as a reminder of a gener=\r\nally accepted \nconcept.\n&gt; \n&gt; Yeah I&#39;m trying to bring to light a more subtl=\r\ne point. You are \ntrying  \n&gt; to claim that the way prior knowledge can be i=\r\nncluded in HyperNEAT \nis  \n&gt; somehow better than other algorithms. I just w=\r\nanted to amend that  \n&gt; statement somewhat with the idea that the experimen=\r\nter could be \nwrong  \n&gt; in guessing the geometry, and thus inadvertently ma=\r\nke search more  \n&gt; difficult for HyperNEAT. So there is both good and bad w=\r\nith \nhaving  \n&gt; more knobs to control. So appealing simply to NFL here as \n=\r\nvalidation  \n&gt; of HyperNEAT being better than NEAT is a little misleading. =\r\n\nReally  \n&gt; all you can say is that NFL tells us nothing about how HyperNEA=\r\nT \nand  \n&gt; NEAT are related.\n&gt; \n&gt; You were applying NFL in the sense that y=\r\nou said that HyperNEAT \nfalls  \n&gt; outside of the purview of NFL because it =\r\ncan employ prior \nknowledge.  \n&gt; This is true, but you can also use prior k=\r\nnowledge in NEAT, albeit \nto  \n&gt; in some sense a lesser extent. So would yo=\r\nu say that NEAT also \nfalls  \n&gt; outside of NFL? No, I don&#39;t think anyone wo=\r\nuld try to make this  \n&gt; argument, rather, the use of prior knowledge is ju=\r\nst sort of \nswept  \n&gt; under the rug when doing any NFL-related comparisons.=\r\n\n&gt; \n&gt; Derek actually summarizes this point really well with his \ncomment: &quot;=\r\nI  \n&gt; don&#39;t understand how it&#39;s possible *not* to include a priori  \n&gt; know=\r\nledge into any optimization algorithm in practice.&quot; In \ngeneral  \n&gt; you can=\r\n&#39;t really exclude all prior knowledge. Thats one of the \nmain  \n&gt; practical=\r\n reasons that we never see evidence of NFL in the real \nworld.\n&gt; \n\nLike I s=\r\naid to Derek, if two algorithms both include the same kind \nof prior knowle=\r\ndge then they are back under NFL with respect to each \nother.  There is no =\r\ndispute that neuroevolution includes a kind of \nprior knowledge through use=\r\nrs&#39; input and output encoding decisions.  \nHowever, virtually all neuroevol=\r\nution algorithms include the exact \nsame kind of prior knowledge, i.e. what=\r\n the inputs and outputs are, \nmeaning that no such algorithm has a theorect=\r\nical advantage over any \nother with respect to NFL.\n\nSo let&#39;s try to put my=\r\n point in more acceptable terms:\n\nHyperNEAT creates a new class of neuroevo=\r\nlution algorithm because a \nnew kind of prior knowledge can now be included=\r\n.  Therefore, it now \nhas a novel means to outperform other neuroevolution =\r\nalgorithms on \nthe class of problems in which we are interested, assuming t=\r\nhe right \nprior knowledge is supplied.  That should have enough caveats to =\r\n\ncover its theoretical bases :)\n\nBeyond that, of course it depends whether =\r\nthe user supplies the \nright knowledge- I don&#39;t think there&#39;s any dispute t=\r\nhere.  Yet that \npoint is highly general and disconnected from what we are =\r\ntalking \nabout in practice, which is evolving brain-like structures, which,=\r\n \nas Derek pointed out, depend upon geometry all over the place.  So \nmy fe=\r\neling is that the specfic practical point is more important \nthan the gener=\r\nal theoretical one.  In fact, no one would be doing \nresearch in machine le=\r\narning if they didn&#39;t feel the same.\n\nSo you see, we agree.  But I just don=\r\n&#39;t like to dwell on or conclude \nwith nebulous generalities (which is where=\r\n my newly phrased \nstatement is heading).  For if we ended on the note that=\r\n &quot;All in \nall, theoretically, no advantage can be shown to exist over all \n=\r\npossible problems even when the user provides prior knwoledge \nbecause the =\r\nuser is no more reliable than any given algorithm,&quot; we \nwould have achieved=\r\n theoretical accuracy yet said essentially \nnothing.  This is one reason I =\r\nsometimes dislike discussions on \ntheory since they veer the conversation a=\r\nway from interesting points \n(i.e. the importance of geometrical relations =\r\nto neural organization \nand computation) onto pleasantly precise yet incons=\r\nequential \ngeneralities.  \n\nken\n\n\n\n\n"}}