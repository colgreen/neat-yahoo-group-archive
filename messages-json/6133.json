{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234577593,"authorName":"Oliver Coleman","from":"Oliver Coleman &lt;oliver.coleman@...&gt;","profile":"olivercoleman04","replyTo":"LIST","senderId":"S7ANqma201-FbtlcVwjfP9Z_YJp0A8APfsQGE11qygrCEyQ1NSoUsN87GqnOgDp8z2wLwn0tBeD28TwhA5s-VfbdajC6O-o8erQzHXno4Hg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Novelty search in a generational GA","postDate":"1370906695","msgId":6133,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBK2R1aW1PcFFadjQzNVZXVG53YTZqblpQSzh0K2VpTD0wcEF6SnFpYnFnLVFwWUVzd0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PENBK2R1aW1QVS12cVRvYTZlZUQwNTYyd1hzMVlwYVZ6ZFFrS1UrUl9IeHB2c2EraWFKd0BtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PGtvdm10YStkbjVrQGVHcm91cHMuY29tPgk8a3AyNG91KzNjdmlAZUdyb3Vwcy5jb20+CTxDQStkdWltUFUtdnFUb2E2ZWVEMDU2MndYczFZcGFWemRRa0tVK1JfSHhwdnNhK2lhSndAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":6132,"nextInTopic":6135,"prevInTime":6132,"nextInTime":6134,"topicId":6129,"numMessagesInTopic":9,"msgSnippet":"​Hi Joel, Clicked the send button before I was finished... in addition to previous email: ​ * ​ That said, the simpler algorithm you suggest is","rawEmail":"Return-Path: &lt;oliver.coleman@...&gt;\r\nX-Sender: oliver.coleman@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 67263 invoked by uid 102); 10 Jun 2013 23:24:56 -0000\r\nX-Received: from unknown (HELO mtaq6.grp.bf1.yahoo.com) (10.193.84.37)\n  by m12.grp.bf1.yahoo.com with SMTP; 10 Jun 2013 23:24:56 -0000\r\nX-Received: (qmail 9681 invoked from network); 10 Jun 2013 23:24:56 -0000\r\nX-Received: from unknown (HELO mail-wi0-f177.google.com) (209.85.212.177)\n  by mtaq6.grp.bf1.yahoo.com with SMTP; 10 Jun 2013 23:24:56 -0000\r\nX-Received: by mail-wi0-f177.google.com with SMTP id ey16so3603781wid.4\n        for &lt;neat@yahoogroups.com&gt;; Mon, 10 Jun 2013 16:24:55 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.194.7.137 with SMTP id j9mr6920069wja.11.1370906695362; Mon,\n 10 Jun 2013 16:24:55 -0700 (PDT)\r\nX-Received: by 10.194.92.34 with HTTP; Mon, 10 Jun 2013 16:24:55 -0700 (PDT)\r\nIn-Reply-To: &lt;CA+duimPU-vqToa6eeD0562wXs1YpaVzdQkKU+R_Hxpvsa+iaJw@...&gt;\r\nReferences: &lt;kovmta+dn5k@...&gt;\n\t&lt;kp24ou+3cvi@...&gt;\n\t&lt;CA+duimPU-vqToa6eeD0562wXs1YpaVzdQkKU+R_Hxpvsa+iaJw@...&gt;\r\nDate: Tue, 11 Jun 2013 09:24:55 +1000\r\nMessage-ID: &lt;CA+duimOpQZv435VWTnwa6jnZPK8t+eiL=0pAzJqibqg-QpYEsw@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=047d7b5d57c898f10e04ded51614\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Oliver Coleman &lt;oliver.coleman@...&gt;\r\nSubject: Re: [neat] Re: Novelty search in a generational GA\r\nX-Yahoo-Group-Post: member; u=234577593; y=oUNlcDine-dz8ZO_G3BVR8w9599YODgrV8T9g3YmgK8vs3n3AlkKGARpps7mu0MoevXnj63gjA\r\nX-Yahoo-Profile: olivercoleman04\r\n\r\n\r\n--047d7b5d57c898f10e04ded51614\r\nContent-Type: text/plain; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n=E2=80=8BHi Joel,\n\nClicked the send button before I was finished... in addi=\r\ntion to previous\nemail:\n=E2=80=8B\n*\n&quot;=E2=80=8B\nThat said, the simpler algor=\r\nithm you suggest is interesting. It seems a bit\nmore greedy in nature and m=\r\nay work well sometimes in practice. One slightly\nstrange thing about it is =\r\nthat the evaluation order of individuals within a\ngeneration may matter; th=\r\nat is, the novelty of an individual evaluated\nlater in the population may b=\r\ne affected by archive additions earlier. I am\nnot sure if that is bad or go=\r\nod. &quot;*\n\nIt should definitely be the case that a later evaluation of an indi=\r\nvidual\nmay be affected by archive additions from earlier in the current\ngen=\r\neration: that is how it takes into account the current population. But I\nag=\r\nree that it is in some sense more greedy and will give a less accurate\nsign=\r\nal about where the search currently is, and so will presumably not\nmaintain=\r\n population diversity quite as well. As well as having the possibly\nundesir=\r\nable fact that the order of evaluation will have some impact (though\nI don&#39;=\r\nt see this as a major issue).\n\n=E2=80=8BThanks for the tips on creating a s=\r\nmoother gradient in a generational\nsetting, makes perfect sense. :)\n\nI&#39;m am=\r\nbivalent about the deterministic and probabilistic methods of\ndetermining w=\r\nhether to add an individual to the archive. Is there any\nexperimental evide=\r\nnce to show one is better than the other (at least for\nsome tasks)? =E2=80=\r\n=8BIn the paper you linked (&quot;Ef=EF=AC=81ciently Evolving Programs\nthrough t=\r\nhe Search for Novelty&quot;) it says:\n*&quot;adding a highly novel individual to the =\r\narchive has the disadvantage that\nit penalizes an area of the behavior spac=\r\ne that may merit further ex\nploration.&quot;*\nBut I wonder if the average distan=\r\nce to the k-nearest-neighbours metric\nisn&#39;t enough to avoid this issue for =\r\nmost practical purposes? I suppose KNN\ncan mitigate it (more so as K is inc=\r\nreased), but won&#39;t do away with it\ncompletely like the probabilistic approa=\r\nch will tend to (apart from the\nhopefully rare occasions when a new highly =\r\nnovel individual is added to the\narchive).\n\nOn the other hand, perhaps the =\r\nprobabilistic approach might tend to result\nin the search revisiting the sa=\r\nme behaviours many times because they\nweren&#39;t added to the archive the firs=\r\nt time they were discovered? Again,\nthis is just an intuition, I have no id=\r\nea if this is likely in practice.\nPerhaps a combination of both methods is =\r\nthe safest bet. :)\n\n=E2=80=8BCheers,\nOliver=E2=80=8B\n\n\nT: 0421 972 953 | E:=\r\n oliver.coleman@... | W: http://ojcoleman.com\n\n\n\nOn 11 June 2013 08:5=\r\n5, Oliver Coleman &lt;oliver.coleman@...&gt; wrote:\n\n&gt; Hi Joel,\n&gt;\n&gt; Thanks =\r\nfor your advice!\n&gt;\n&gt; Creating pressure for diversity within the population =\r\nby comparing novelty\n&gt; among all current members certainly seems like a goo=\r\nd idea and makes\n&gt; intuitive sense. In &quot;Novelty-based Multiobjectivization&quot;=\r\n (J. Mouret,\n&gt; 2009) it was found that ignoring the current population resu=\r\nlted in much\n&gt; slower convergence on the solution to a deceptive T-maze tas=\r\nk, though I&#39;m\n&gt; not entirely sure if this is due to higher diversity in the=\r\n population.\n&gt;\n&gt; &quot;\n&gt; That said, the simpler algorithm you suggest is intere=\r\nsting. It seems a\n&gt; bit more greedy in nature and may work well sometimes i=\r\nn practice. One\n&gt; slightly strange thing about it is that the evaluation or=\r\nder of individuals\n&gt; within a generation may matter; that is, the novelty o=\r\nf an individual\n&gt; evaluated later in the population may be affected by arch=\r\nive additions\n&gt; earlier. I am not sure if that is bad or good. &quot;\n&gt;\n&gt; Yes,\n&gt;=\r\n\n&gt;\n&gt; T: 0421 972 953 | E: oliver.coleman@... | W: http://ojcoleman.co=\r\nm\n&gt;\n&gt;\n&gt;\n&gt; On 10 June 2013 00:51, joel278 &lt;lehman.154@...&gt; wrote:\n&gt;\n&gt;&gt; *=\r\n*\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Oliver,\n&gt;&gt;\n&gt;&gt; Also related to the simplifying the novelty search=\r\n algorithm is the idea\n&gt;&gt; of adding to the archive probabilistically instea=\r\nd of using a threshold.\n&gt;&gt; That is, in the original C++ implementation indi=\r\nviduals are added to the\n&gt;&gt; archive when their novelty is greater than an e=\r\nxperimenter-specified\n&gt;&gt; threshold (which an also vary dynamically). Howeve=\r\nr, in new implementations\n&gt;&gt; I&#39;ve tended to remove the threshold and instea=\r\nd add any new individual to\n&gt;&gt; the archive (at the end of a generation) wit=\r\nh fixed probability (e.g.\n&gt;&gt; 0.05%).\n&gt;&gt;\n&gt;&gt; Note that this approach is also =\r\ndescribed in a paper applying novelty\n&gt;&gt; search to genetic programming (\n&gt;&gt;=\r\n http://eplex.cs.ucf.edu/publications/2010/lehman-gecco10b).\n&gt;&gt;\n&gt;&gt; One nice=\r\n thing about this approach is that it is easier to understand how\n&gt;&gt; changi=\r\nng the probability will influence archive growth than the novelty\n&gt;&gt; thresh=\r\nold. That is, the expectation of growth per generation is just the\n&gt;&gt; proba=\r\nbility of addition (which is a parameter to be chosen by the\n&gt;&gt; experimente=\r\nr) times the population size. In contrast, the novelty threshold\n&gt;&gt; is spec=\r\nified in terms of a more abstract quantity (i.e. novelty scores),\n&gt;&gt; and wh=\r\nile this threshold can also be adjusted dynamically to add one or two\n&gt;&gt; in=\r\ndividuals per generation on average, it can add some complication to the\n&gt;&gt;=\r\n implementation.\n&gt;&gt;\n&gt;&gt; Adding to the archive probabilistically (i.e. each n=\r\new individual has\n&gt;&gt; some fixed chance of being added to the archive regard=\r\nless of how novel\n&gt;&gt; they are) may also be more principled than the thresho=\r\nld method. In effect,\n&gt;&gt; adding probabilistically samples uniformly where s=\r\nearch has been and\n&gt;&gt; creates an accumulating force away from behaviors sea=\r\nrch has been spending\n&gt;&gt; most effort exploring. In contrast, adding new ind=\r\nividuals to the archive\n&gt;&gt; when they are greater than the threshold tends t=\r\no create a small repulsive\n&gt;&gt; force exactly where things are most novel. Of=\r\n course, over time it also\n&gt;&gt; approximates where search has been, but the p=\r\nrobabilistic approach does so\n&gt;&gt; more directly.\n&gt;&gt;\n&gt;&gt; In any case, I though=\r\nt I&#39;d mention this slightly nuanced implementation\n&gt;&gt; detail because it als=\r\no relates to interactions between the archive and\n&gt;&gt; population, and is per=\r\nhaps a simpler and more principled way to accumulate\n&gt;&gt; an archive of past =\r\nbehaviors to encourage search to diverge from behaviors\n&gt;&gt; explored in the =\r\npast.\n&gt;&gt;\n&gt;&gt; Best,\n&gt;&gt; Joel\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; --- In neat@yahoogroups.com, &quot;joel278&quot; &lt;=\r\nlehman.154@...&gt; wrote:\n&gt;&gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt; &gt; Hi Oliver,\n&gt;&gt; &gt;\n&gt;&gt; &gt; Thanks for =\r\nraising this interesting question relating to pairing\n&gt;&gt; novelty search wit=\r\nh generational evolutionary algorithms. Whether novelty\n&gt;&gt; search is perfor=\r\nmed generationally or in a steady-state algorithm, I think\n&gt;&gt; that taking t=\r\nhe population into account in some way or another when\n&gt;&gt; calculating the n=\r\novelty of new individuals can often be very helpful.\n&gt;&gt; &gt;\n&gt;&gt; &gt; In particula=\r\nr, the motivation for measuring novelty against the current\n&gt;&gt; population a=\r\ns well as the archive is to take all available information into\n&gt;&gt; account.=\r\n While it is true that the archive alone provides some information\n&gt;&gt; about=\r\n where in the space of behaviors has *previously* been searched, the\n&gt;&gt; pop=\r\nulation gives additional information about where is *currently* being\n&gt;&gt; se=\r\narched.\n&gt;&gt; &gt;\n&gt;&gt; &gt; In other words, it is likely desirable to have the popula=\r\ntion itself\n&gt;&gt; spread over the space of previously unexplored behaviors. If=\r\n only the\n&gt;&gt; archive is taken into account, it is possible that the populat=\r\nion itself\n&gt;&gt; may converge to searching one novel area of the behavior spac=\r\ne (where there\n&gt;&gt; are few archive points), which could potentially lead dow=\r\nn blind alleys.\n&gt;&gt; When the population is taken into account there is some =\r\nrepulsive force\n&gt;&gt; within the population to maintain diversity and explore =\r\ndifferent novel\n&gt;&gt; areas of the behavior space -- which may in general bene=\r\nfit exploring the\n&gt;&gt; overall search for novelty.\n&gt;&gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt; =E2=80=8B=E2=\r\n=80=8B\n&gt;&gt; That said, the simpler algorithm you suggest is interesting. It s=\r\neems a\n&gt;&gt; bit more greedy in nature and may work well sometimes in practice=\r\n. One\n&gt;&gt; slightly strange thing about it is that the evaluation order of in=\r\ndividuals\n&gt;&gt; within a generation may matter; that is, the novelty of an ind=\r\nividual\n&gt;&gt; evaluated later in the population may be affected by archive add=\r\nitions\n&gt;&gt; earlier. I am not sure if that is bad or good.\n&gt;&gt; &gt;\n&gt;&gt; &gt; In a gen=\r\nerational novelty search in particular, it may be wise to\n&gt;&gt; reduce selecti=\r\non pressure or increase the number of nearest neighbors\n&gt;&gt; considered in ca=\r\nlculated novelty. The reason is that unlike in the steady\n&gt;&gt; state variatio=\r\nn, where the novelty of an individual will smoothly vary over\n&gt;&gt; time (as i=\r\nndividuals are replaced individually), in a generational model,\n&gt;&gt; the nove=\r\nlty of an individual can change abruptly over generations (what is\n&gt;&gt; novel=\r\n one generation may not be novel even the next generation). To provide\n&gt;&gt; a=\r\n smoother gradient, it may thus be important to reduce novelty pressure\n&gt;&gt; =\r\n(e.g. by decreasing the greediness of the search through the survival\n&gt;&gt; th=\r\nreshold or however you are applying pressure, or by increasing the size\n&gt;&gt; =\r\nof the neighborhood considered for calculating novelty, which may also\n&gt;&gt; s=\r\nmooth novelty calculations).\n&gt;&gt; &gt;\n&gt;&gt; &gt; I hope you find this response inform=\r\native, while novelty search is\n&gt;&gt; viable whether it is generational or stea=\r\ndy-state, there are some factors\n&gt;&gt; that may increase its performance when =\r\nspecializing the algorithm to\n&gt;&gt; generational or steady-state evolutionary =\r\nalgorithms in particular.\n&gt;&gt; &gt;\n&gt;&gt; &gt; Best,\n&gt;&gt; &gt; Joel\n&gt;&gt; &gt;\n&gt;&gt; &gt; --- In neat@y=\r\nahoogroups.com, Oliver Coleman &lt;oliver.coleman@&gt; wrote:\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Hi al=\r\nl,\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; I have a question about implementing novelty search in a g=\r\nenerational\n&gt;&gt; GA.\n&gt;&gt; &gt; &gt; In &quot;Abandoning Objectives: Evolution through the\n=\r\n&gt;&gt; &gt; &gt; Search for Novelty Alone&quot; (Lehman and Stanley, 2011, pg 13), it\n&gt;&gt; s=\r\nuggests\n&gt;&gt; &gt; &gt; that it&#39;s necessary (or at least a good idea) to determine t=\r\nhe\n&gt;&gt; novelty of\n&gt;&gt; &gt; &gt; an individual against the archive and the (entire) =\r\ncurrent population.\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; I&#39;m wondering why this is better than the=\r\n following approach:\n&gt;&gt; &gt; &gt; for (individual I in population)\n&gt;&gt; &gt; &gt; N =3D n=\r\novelty of I measured against archive\n&gt;&gt; &gt; &gt; if (N &gt; threshold)\n&gt;&gt; &gt; &gt; add I=\r\n to archive\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; That is, if you iterate through the population, a=\r\ndding individuals to\n&gt;&gt; the\n&gt;&gt; &gt; &gt; archive as you go, then is this equivale=\r\nnt (or a reasonable\n&gt;&gt; approximation)\n&gt;&gt; &gt; &gt; to checking each individual ag=\r\nainst the entire population and the\n&gt;&gt; archive?\n&gt;&gt; &gt; &gt; If not, why not?\n&gt;&gt; =\r\n&gt; &gt;\n&gt;&gt; &gt; &gt; Thanks in advance for any assistance! :)\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Cheers,\n&gt;=\r\n&gt; &gt; &gt; Oliver\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; T: 0421 972 953 | E: oliver.coleman@ | W: http:/=\r\n/ojcoleman.com\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt;\n&gt;&gt;  \n&gt;&gt;\n&gt;\n&gt;\n\r\n--047d7b5d57c898f10e04ded51614\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;&lt;div style=3D&quot;font-family:georgia,serif&quot; class=3D&quot;gma=\r\nil_default&quot;&gt;=E2=80=8BHi Joel,&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,serif&quot;=\r\n class=3D&quot;gmail_default&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,serif&quot;=\r\n class=3D&quot;gmail_default&quot;&gt;\n\nClicked the send button before I was finished...=\r\n in addition to previous email:&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,seri=\r\nf&quot; class=3D&quot;gmail_default&quot;&gt;=E2=80=8B&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia=\r\n,serif&quot; class=3D&quot;gmail_default&quot;&gt;&lt;i&gt;&lt;div class=3D&quot;gmail_default&quot; style=3D&quot;co=\r\nlor:rgb(80,0,80);display:inline&quot;&gt;\n\n&quot;=E2=80=8B&lt;/div&gt;&lt;span style=3D&quot;colo=\r\nr:rgb(80,0,80);font-family:arial&quot;&gt;That said, the simpler algorithm you sugg=\r\nest is interesting. It seems a bit more greedy in nature and may work well =\r\nsometimes in practice. One slightly strange thing about it is that the eval=\r\nuation order of individuals within a generation may matter; that is, the no=\r\nvelty of an individual evaluated later in the population may be affected by=\r\n archive additions earlier. I am not sure if that is bad or good.=C2=A0&quo=\r\nt;&lt;/span&gt;&lt;/i&gt;&lt;br&gt;\n\n&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,serif&quot; class=3D&quot;=\r\ngmail_default&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,serif&quot; class=3D&quot;=\r\ngmail_default&quot;&gt;It should definitely be the case that a later evaluation of =\r\nan individual may be affected by archive additions from earlier in the curr=\r\nent generation: that is how it takes into account the current population. B=\r\nut I agree that it is in some sense more greedy and will give a less accura=\r\nte signal about where the search currently is, and so will presumably not m=\r\naintain population diversity quite as well. As well as having the possibly =\r\nundesirable fact that the order of evaluation will have some impact (though=\r\n I don&#39;t see this as a major issue).&lt;/div&gt;\n\n&lt;div style=3D&quot;font-family:g=\r\neorgia,serif&quot; class=3D&quot;gmail_default&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;font-family:g=\r\neorgia,serif&quot; class=3D&quot;gmail_default&quot;&gt;=E2=80=8BThanks for the tips on creat=\r\ning a smoother gradient in a generational setting, makes perfect sense. :)&lt;=\r\n/div&gt;\n\n&lt;div style=3D&quot;font-family:georgia,serif&quot; class=3D&quot;gmail_default&quot;&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_default&quot;&gt;&lt;font face=3D&quot;georgia, serif&quot;&gt;I&#39;m a=\r\nmbivalent about the deterministic and probabilistic methods of determining =\r\nwhether to add an individual to the archive. Is there any experimental evid=\r\nence to show one is better than the other (at least for some tasks)? =E2=80=\r\n=8BIn the paper you linked (&quot;Ef=EF=AC=81ciently Evolving Programs thro=\r\nugh the Search for=C2=A0&lt;/font&gt;&lt;span style=3D&quot;font-family:georgia,serif&quot;&gt;No=\r\nvelty&quot;)&lt;/span&gt;&lt;span style=3D&quot;font-family:georgia,serif&quot;&gt;=C2=A0it says:=\r\n=C2=A0&lt;/span&gt;&lt;/div&gt;\n&lt;div class=3D&quot;gmail_default&quot;&gt;&lt;i&gt;&lt;font face=3D&quot;georgia, =\r\nserif&quot;&gt;&quot;adding a highly novel indi&lt;/font&gt;&lt;span style=3D&quot;font-family:ge=\r\norgia,serif&quot;&gt;vidual to the archive has the disadvantage that it penalizes=\r\n=C2=A0&lt;/span&gt;&lt;span style=3D&quot;font-family:georgia,serif&quot;&gt;an area of the behav=\r\nior space that may merit further ex&lt;/span&gt;&lt;span style=3D&quot;font-family:georgi=\r\na,serif&quot;&gt;ploration.&quot;&lt;/span&gt;&lt;/i&gt;&lt;/div&gt;\n&lt;div class=3D&quot;gmail_default&quot; sty=\r\nle&gt;&lt;span style=3D&quot;font-family:georgia,serif&quot;&gt;But I wonder if the average di=\r\nstance to the k-nearest-neighbours metric isn&#39;t enough to avoid this is=\r\nsue for most practical purposes? I suppose KNN can mitigate it (more so as =\r\nK is increased), but won&#39;t do away with it completely like the probabil=\r\nistic approach will tend to (apart from the hopefully rare occasions when a=\r\n new highly novel individual is added to the archive).=C2=A0&lt;/span&gt;&lt;/div&gt;\n&lt;=\r\ndiv class=3D&quot;gmail_default&quot; style&gt;&lt;span style=3D&quot;font-family:georgia,serif&quot;=\r\n&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_default&quot; style&gt;&lt;span style=3D&quot;font-fa=\r\nmily:georgia,serif&quot;&gt;On the other hand, perhaps the probabilistic approach m=\r\night tend to result in the search revisiting the same behaviours many times=\r\n because they weren&#39;t added to the archive the first time they were dis=\r\ncovered? Again, this is just an intuition, I have no idea if this is likely=\r\n in practice. Perhaps a combination of both methods is the safest bet. :)&lt;/=\r\nspan&gt;&lt;/div&gt;\n&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;div style=3D&quot;font-family:=\r\ngeorgia,serif&quot; class=3D&quot;gmail_default&quot;&gt;=E2=80=8BCheers,&lt;/div&gt;&lt;div style=3D&quot;=\r\nfont-family:georgia,serif&quot; class=3D&quot;gmail_default&quot;&gt;Oliver=E2=80=8B&lt;/div&gt;&lt;br=\r\n clear=3D&quot;all&quot;&gt;&lt;div&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;\n&lt;br&gt;&lt;/div&gt;\nT: 0421 972 953 |=C2=\r\n=A0E: &lt;a href=3D&quot;mailto:oliver.coleman@...&quot; target=3D&quot;_blank&quot;&gt;oliver.=\r\ncoleman@...&lt;/a&gt;=C2=A0|=C2=A0W:=C2=A0&lt;a href=3D&quot;http://ojcoleman.com&quot; =\r\ntarget=3D&quot;_blank&quot;&gt;http://ojcoleman.com&lt;/a&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/=\r\ndiv&gt;\n\n&lt;/div&gt;&lt;/div&gt;\n&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On 11 June 2013 08:55=\r\n, Oliver Coleman &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:oliver.coleman@gma=\r\nil.com&quot; target=3D&quot;_blank&quot;&gt;oliver.coleman@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br=\r\n&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0px 0.8ex;border=\r\n-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;=\r\npadding-left:1ex&quot;&gt;\n\n&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div style=3D&quot;font-family:georgia,seri=\r\nf&quot;&gt;Hi Joel,&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,serif&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div st=\r\nyle=3D&quot;font-family:georgia,serif&quot;&gt;\nThanks for your advice!&lt;/div&gt;&lt;div style=\r\n=3D&quot;font-family:georgia,serif&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;font face=3D&quot;georgia, serif&quot;=\r\n&gt;Creating pressure for diversity within the population by comparing novelty=\r\n among all current members certainly seems like a good idea and makes intui=\r\ntive sense. In &quot;Novelty-based Multiobjectivization&quot; (&lt;/font&gt;&lt;span=\r\n style=3D&quot;font-family:georgia,serif&quot;&gt;J. Mouret, 2009) it was found that ign=\r\noring the current population resulted in much slower convergence on the sol=\r\nution to a deceptive T-maze task, though I&#39;m not entirely sure if this =\r\nis due to higher diversity in the population.&lt;/span&gt;&lt;/div&gt;\n\n&lt;div&gt;\n&lt;div&gt;&lt;spa=\r\nn style=3D&quot;font-family:georgia,serif&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=3D&quot;=\r\nfont-family:georgia,serif&quot;&gt;&quot;&lt;/span&gt;&lt;div style=3D&quot;color:rgb(80,0,80);fo=\r\nnt-family:georgia,serif;display:inline&quot;&gt;\n&lt;/div&gt;&lt;span style=3D&quot;color:rgb(80,=\r\n0,80)&quot;&gt;That said, the simpler algorithm you suggest is interesting. It seem=\r\ns a bit more greedy in nature and may work well sometimes in practice. One =\r\nslightly strange thing about it is that the evaluation order of individuals=\r\n within a generation may matter; that is, the novelty of an individual eval=\r\nuated later in the population may be affected by archive additions earlier.=\r\n I am not sure if that is bad or good. &quot;&lt;/span&gt;&lt;/div&gt;\n\n\n&lt;div&gt;&lt;span sty=\r\nle=3D&quot;color:rgb(80,0,80)&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=3D&quot;color:=\r\nrgb(80,0,80)&quot;&gt;Yes,=C2=A0&lt;/span&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br clear=\r\n=3D&quot;all&quot;&gt;&lt;div&gt;&lt;div dir=3D&quot;ltr&quot;&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;T: 0421 972 953 |=C2=A0E: &lt;a=\r\n href=3D&quot;mailto:oliver.coleman@...&quot; target=3D&quot;_blank&quot;&gt;oliver.coleman@=\r\ngmail.com&lt;/a&gt;=C2=A0|=C2=A0W:=C2=A0&lt;a href=3D&quot;http://ojcoleman.com&quot; target=\r\n=3D&quot;_blank&quot;&gt;http://ojcoleman.com&lt;/a&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;&lt;/div=\r\n&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;\n&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On 10 June 2013 =\r\n00:51, joel278 &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:lehman.154@...&quot; =\r\ntarget=3D&quot;_blank&quot;&gt;lehman.154@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote c=\r\nlass=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0px 0.8ex;border-left-width:1p=\r\nx;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1=\r\nex&quot;&gt;\n\n\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n\n&lt;div&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n   =\r\n &lt;div&gt;\n      \n      \n      &lt;p&gt;Oliver,&lt;br&gt;\n&lt;br&gt;\nAlso related to the simplify=\r\ning the novelty search algorithm is the idea of adding to the archive proba=\r\nbilistically instead of using a threshold. That is, in the original C++ imp=\r\nlementation individuals are added to the archive when their novelty is grea=\r\nter than an experimenter-specified threshold (which an also vary dynamicall=\r\ny). However, in new implementations I&#39;ve tended to remove the threshold=\r\n  and instead add any new individual to the archive (at the end of a genera=\r\ntion) with fixed probability (e.g. 0.05%). &lt;br&gt;\n\n\n\n&lt;br&gt;\nNote that this appr=\r\noach is also described in a paper applying novelty search to genetic progra=\r\nmming (&lt;a href=3D&quot;http://eplex.cs.ucf.edu/publications/2010/lehman-gecco10b=\r\n&quot; target=3D&quot;_blank&quot;&gt;http://eplex.cs.ucf.edu/publications/2010/lehman-gecco1=\r\n0b&lt;/a&gt;).&lt;br&gt;\n\n\n\n&lt;br&gt;\nOne nice thing about this approach is that it is easie=\r\nr to understand how changing the probability will influence archive growth =\r\nthan the novelty threshold. That is, the expectation of growth per generati=\r\non is just the probability of addition (which is a parameter to be chosen b=\r\ny the experimenter) times the population size. In contrast, the novelty thr=\r\neshold is specified in terms of a more abstract quantity (i.e. novelty scor=\r\nes), and while this threshold can also be adjusted dynamically to add one o=\r\nr two individuals per generation on average, it can add some complication t=\r\no the implementation.&lt;br&gt;\n\n\n\n&lt;br&gt;\nAdding to the archive probabilistically (=\r\ni.e. each new individual has some fixed chance of being added to the archiv=\r\ne regardless of how novel they are) may also be more principled than the th=\r\nreshold method. In effect, adding probabilistically samples uniformly where=\r\n search has been and creates an accumulating force away from behaviors sear=\r\nch has been spending most effort exploring. In contrast, adding new individ=\r\nuals to the archive when they are greater than the threshold tends to creat=\r\ne a small repulsive force exactly where things are most novel. Of course, o=\r\nver time it also approximates where search has been, but the probabilistic =\r\napproach does so more directly.&lt;br&gt;\n\n\n\n&lt;br&gt;\nIn any case, I thought I&#39;d =\r\nmention this slightly nuanced implementation detail because it also relates=\r\n to interactions between the archive and population, and is perhaps a simpl=\r\ner and more principled way to accumulate an archive of past behaviors to en=\r\ncourage search to diverge from behaviors explored in the past.&lt;br&gt;\n\n\n\n&lt;br&gt;\n=\r\nBest,&lt;br&gt;\nJoel&lt;/p&gt;&lt;div&gt;&lt;br&gt;\n&lt;br&gt;\n--- In &lt;a href=3D&quot;mailto:neat%40yahoogroup=\r\ns.com&quot; target=3D&quot;_blank&quot;&gt;neat@yahoogroups.com&lt;/a&gt;, &quot;joel278&quot; &lt;=\r\nlehman.154@...&gt; wrote:&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Hi Oliver,&lt;=\r\nbr&gt;\n&gt; &lt;br&gt;\n&gt; Thanks for raising this interesting question relating to=\r\n pairing novelty search with generational evolutionary algorithms. Whether =\r\nnovelty search is performed generationally or in a steady-state algorithm, =\r\nI think that taking the population into account in some way or another when=\r\n calculating the novelty of new individuals can often be very helpful.&lt;br&gt;\n=\r\n\n\n\n&gt; &lt;br&gt;\n&gt; In particular, the motivation for measuring novelty again=\r\nst the current population as well as the archive is to take all available i=\r\nnformation into account. While it is true that the archive alone provides s=\r\nome information about where in the space of behaviors has *previously* been=\r\n searched, the population gives additional information about where is *curr=\r\nently* being searched.&lt;br&gt;\n\n\n\n&gt; &lt;br&gt;\n&gt; In other words, it is likely d=\r\nesirable to have the population itself spread over the space of previously =\r\nunexplored behaviors. If only the archive is taken into account, it is poss=\r\nible that the population itself may converge to searching one novel area of=\r\n the behavior space (where there are few archive points), which could poten=\r\ntially lead down blind alleys. When the population is taken into account th=\r\nere is some repulsive force within the population to maintain diversity and=\r\n explore different novel areas of the behavior space -- which may in genera=\r\nl benefit exploring the overall search for novelty.&lt;br&gt;\n\n\n\n&gt; &lt;br&gt;\n&gt; &lt;=\r\ndiv&gt;&lt;/div&gt;&lt;div style=3D&quot;font-family:georgia,serif;display:inline&quot; class=3D&quot;=\r\ngmail_default&quot;&gt;=E2=80=8B=E2=80=8B&lt;/div&gt;That said, the simpler algorithm you=\r\n suggest is interesting. It seems a bit more greedy in nature and may work =\r\nwell sometimes in practice. One slightly strange thing about it is that the=\r\n evaluation order of individuals within a generation may matter; that is, t=\r\nhe novelty of an individual evaluated later in the population may be affect=\r\ned by archive additions earlier. I am not sure if that is bad or good. &lt;br&gt;=\r\n\n\n\n\n&gt; &lt;br&gt;\n&gt; In a generational novelty search in particular, it may b=\r\ne wise to reduce selection pressure or increase the number of nearest neigh=\r\nbors considered in calculated novelty. The reason is that unlike in the ste=\r\nady state variation, where the novelty of an individual will smoothly vary =\r\nover time (as individuals are replaced individually), in a generational mod=\r\nel, the novelty of an individual can change abruptly over generations (what=\r\n is novel one generation may not be novel even the next generation). To pro=\r\nvide a smoother gradient, it may thus be important to reduce novelty pressu=\r\nre (e.g. by decreasing the greediness of the search through the survival th=\r\nreshold or however you are applying pressure, or by increasing the size of =\r\nthe neighborhood considered for calculating novelty, which may also smooth =\r\nnovelty calculations).&lt;br&gt;\n\n\n\n&gt; &lt;br&gt;\n&gt; I hope you find this response =\r\ninformative, while novelty search is viable whether it is generational or s=\r\nteady-state, there are some factors that may increase its performance when =\r\nspecializing the algorithm to generational or steady-state evolutionary alg=\r\norithms in particular.&lt;br&gt;\n\n\n\n&gt; &lt;br&gt;\n&gt; Best,&lt;br&gt;\n&gt; Joel&lt;br&gt;\n&gt; &lt;=\r\nbr&gt;&lt;/div&gt;&lt;div&gt;\n&gt; --- In &lt;a href=3D&quot;mailto:neat%40yahoogroups.com&quot; target=\r\n=3D&quot;_blank&quot;&gt;neat@yahoogroups.com&lt;/a&gt;, Oliver Coleman &lt;oliver.coleman@&gt=\r\n; wrote:&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; Hi all,&lt;br&gt;\n&gt; &gt; &lt;br&gt;\n&gt; &gt; I=\r\n have a question about implementing novelty search in a generational GA.&lt;br=\r\n&gt;\n&gt; &gt; In &quot;Abandoning Objectives: Evolution through the&lt;br&gt;\n&gt; =\r\n&gt; Search for Novelty Alone&quot; (Lehman and Stanley, 2011, pg 13), it s=\r\nuggests&lt;br&gt;\n&gt; &gt; that it&#39;s necessary (or at least a good idea) to =\r\ndetermine the novelty of&lt;br&gt;\n&gt; &gt; an individual against the archive an=\r\nd the (entire) current population.&lt;br&gt;\n&gt; &gt; &lt;br&gt;\n&gt; &gt; I&#39;m won=\r\ndering why this is better than the following approach:&lt;br&gt;\n&gt; &gt; for (i=\r\nndividual I in population)&lt;br&gt;\n&gt; &gt;   N =3D novelty of I measured agai=\r\nnst archive&lt;br&gt;\n&gt; &gt;   if (N &gt; threshold)&lt;br&gt;\n&gt; &gt;     add I t=\r\no archive&lt;br&gt;\n&gt; &gt; &lt;br&gt;\n&gt; &gt; That is, if you iterate through the =\r\npopulation, adding individuals to the&lt;br&gt;\n&gt; &gt; archive as you go, then=\r\n is this equivalent (or a reasonable approximation)&lt;br&gt;\n&gt; &gt; to checki=\r\nng each individual against the entire population and the archive?&lt;br&gt;\n&gt; =\r\n&gt; If not, why not?&lt;br&gt;\n&gt; &gt; &lt;br&gt;\n&gt; &gt; Thanks in advance for an=\r\ny assistance! :)&lt;br&gt;\n&gt; &gt; &lt;br&gt;\n&gt; &gt; Cheers,&lt;br&gt;\n&gt; &gt; Oliver&lt;=\r\nbr&gt;\n&gt; &gt; &lt;br&gt;&lt;/div&gt;\n&gt; &gt; T: 0421 972 953 | E: oliver.coleman@ | W=\r\n: &lt;a href=3D&quot;http://ojcoleman.com&quot; target=3D&quot;_blank&quot;&gt;http://ojcoleman.com&lt;/=\r\na&gt;&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;div=\r\n style=3D&quot;color:rgb(255,255,255);min-height:0px&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n=\r\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/=\r\ndiv&gt;&lt;/div&gt;\n\r\n--047d7b5d57c898f10e04ded51614--\r\n\n"}}