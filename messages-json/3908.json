{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"4oixnMpOy1p85iCIcBS_e8V9ERLvuOSZ04z_RmXubKVHYvfIapsHGDDz2WggjD6W1PK-rNpWKghzdoQKM74Z9W8","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205947056","msgId":3908,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZycmhyZythamU1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZycWUydCtsdnJ0QGVHcm91cHMuY29tPg=="},"prevInTopic":3905,"nextInTopic":3911,"prevInTime":3907,"nextInTime":3909,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"Ken, I believe it would be beneficial to others contemplating usage of NEAT, to prominently label what your individually favored version of NEAT/HyperNEAT","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 61056 invoked from network); 19 Mar 2008 17:17:36 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m57.grp.scd.yahoo.com with QMQP; 19 Mar 2008 17:17:36 -0000\r\nX-Received: from unknown (HELO n47a.bullet.mail.sp1.yahoo.com) (66.163.168.141)\n  by mta16.grp.scd.yahoo.com with SMTP; 19 Mar 2008 17:17:36 -0000\r\nX-Received: from [216.252.122.216] by n47.bullet.mail.sp1.yahoo.com with NNFMP; 19 Mar 2008 17:17:36 -0000\r\nX-Received: from [209.73.164.86] by t1.bullet.sp1.yahoo.com with NNFMP; 19 Mar 2008 17:17:36 -0000\r\nX-Received: from [66.218.66.88] by t8.bullet.scd.yahoo.com with NNFMP; 19 Mar 2008 17:17:36 -0000\r\nDate: Wed, 19 Mar 2008 17:17:36 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frrhrg+aje5@...&gt;\r\nIn-Reply-To: &lt;frqe2t+lvrt@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=6oEkFwKaUh61ycdIeOCwT61DUHSU7YZP4Li4F4SN4t8KiQ\r\nX-Yahoo-Profile: afcarl2\r\n\r\nKen,\n\nI believe it would be beneficial to others contemplating usage of \nNE=\r\nAT, to prominently label what your &quot;individually favored&quot; version \nof NEAT/=\r\nHyperNEAT is. Namely, unconstrained mono-objective search. \nThis way it wil=\r\nl enable them to more quickly identify if it is \nconsistent with there requ=\r\nirements, embrace it or continue looking.\n\nFYI, &quot;physics-based surrogate mo=\r\ndels&quot; is to surrogate models, what \nNEAT is to AI. One part of a much large=\r\nr whole. Its evident that you \ndid not &quot;see the deeper connection&quot; intended=\r\n. That&#39;s unfortunate, \nsince I believe the applicability of NEAT and HyperN=\r\nEAT would be \nprofoundly broadened.\n\n\n--- In neat@yahoogroups.com, &quot;Kenneth=\r\n Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Andy, I fully appreciate your enthusias=\r\nm for engineering \noptimization \n&gt; and operations research.  In fact, I am =\r\nnot unaware of this area \nand \n&gt; have looked into &quot;physics-based surrogate =\r\nmodels.&quot;  Here is a nice \n&gt; paper on the subject:\n&gt; \n&gt; http://www.cs.sandia=\r\n.gov/DAKOTA/papers/OUU_MAO2004.pdf\n&gt; \n&gt; Nevertheless, I still see no concre=\r\nte connection to HyperNEAT other \n&gt; than the fact that HyperNEAT (like any =\r\nmachine learning algorithm) \n&gt; will undoubtedly sometimes need to be applie=\r\nd to a domain that is \n&gt; best modeled by a surrogate.  It appears I am unli=\r\nkely to see the \n&gt; deeper connection so perhaps it is not important to bela=\r\nbor it \n&gt; further.  It is very possible others have internalized your point=\r\n \n&gt; better and that your efforts at promoting your view will therefore \n&gt; l=\r\nead to productive explorations.\n&gt; \n&gt; In any case, at least we are agreed th=\r\nat challenges remain in all \nof \n&gt; machine learning, including for HyperNEA=\r\nT.  The exciting \nopportunity \n&gt; is to meet these challenges with new ideas=\r\n.  Perhaps novel \n&gt; hybridizations will answer some challenges; perhaps in =\r\nother cases \nit \n&gt; will be something else.  What is great for all of us is =\r\nthat by \n&gt; pursuing the paths we individually favor, even if they differ, w=\r\ne \nare \n&gt; expanding the diversity of options for everyone in the future.  S=\r\no \n&gt; let us encourage each other to follow our instincts to their most \n&gt; p=\r\nromising ends.  \n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.ca=\r\nrl@&gt; wrote:\n&gt; &gt;\n&gt; &gt; To the motivated and intellectually honest, I contend t=\r\nhat prior \n&gt; &gt; references and explanations are sufficient for discovery and=\r\n \n&gt; &gt; understanding.\n&gt; &gt; \n&gt; &gt; That said, no reference has been made to disf=\r\navor discovery of \n&gt; &gt; patterns. In the context of engineering optimization=\r\n/search, your \n&gt; &gt; predisposition and creation of hyperneat could be viewed=\r\n as the \n&gt; &gt; analogous equivalent of seeking a physics-based surrogate mode=\r\nl, \n&gt; &gt; though for differing reasons.\n&gt; &gt; \n&gt; &gt; Perhaps within the confines =\r\nof your area of expertise, this \nconcept \n&gt; &gt; is novel, as it appears from =\r\nyour statements. But in the larger \n&gt; &gt; landscape of engineering optimizati=\r\non/search, there is an entire \n&gt; &gt; branch of research associated with surro=\r\ngate-based models and \n&gt; &gt; optimization/search. Which, btw, if you take the=\r\n opportunity to \n&gt; &gt; review what the other guys are doing outside of your a=\r\nrea of \n&gt; &gt; expertise (i.e. previously provided reference), I believe it ma=\r\ny \n&gt; even \n&gt; &gt; facilitate your endeavors. And at the very least, it would h=\r\nelp \nto \n&gt; &gt; convey an impression of genuine motivation to discover, rather=\r\n \nthan \n&gt; &gt; a &quot;not invented here&quot; mentality.\n&gt; &gt; \n&gt; &gt; It is difficult to se=\r\ne the utility of expending the energy of \n&gt; &gt; explanation, when it appears =\r\nthat you are entangled in the \n&gt; conflicts \n&gt; &gt; and differences of opinions=\r\n within the differing niches of AI, \n&gt; seemly \n&gt; &gt; unable to take a step ba=\r\nck to get a perspective which includes \nmore \n&gt; &gt; than these differing nich=\r\nes.\n&gt; &gt; \n&gt; &gt; In a nutshell:\n&gt; &gt; a) Multi-discipline: seemly self-evident, s=\r\nimultaneous or staged, \n&gt; &gt; analogous to multiple differing vocabularies an=\r\nd syntax.\n&gt; &gt; b) Multi-Objective: simultaneous, multiple arbitrary hyperspa=\r\nces \nof \n&gt; &gt; arbitrary sub-sets of input parameter dimensionalities.\n&gt; &gt; c)=\r\n Linear equality/inequality feasibility constraints: seemly \nself-\n&gt; &gt; evid=\r\nent, multiple arbitrary discrete values and/or ranges of \n&gt; &gt; acceptable va=\r\nlues of arbitrary input parameters.\n&gt; &gt; d) Non-linear equality/inequality f=\r\neasibility constraints: \nmultiple \n&gt; &gt; arbitrary discrete values and/or ran=\r\nges of acceptable values of \n&gt; &gt; multiple arbitrary hyperspaces of arbitrar=\r\ny sub-sets of input \n&gt; &gt; parameter dimensionalities.\n&gt; &gt; \n&gt; &gt; That said, yo=\r\nur predisposition of endeavor appears to be the \n&gt; &gt; discovery of a global =\r\npattern (with or w/o \nvariation/elaboration), \n&gt; &gt; associated with a given =\r\nobjective hyperspace.\n&gt; &gt; \n&gt; &gt; The fundamental problem is that, subsequent =\r\nto whatever means are \n&gt; &gt; utilized to apply the arbitrary feasibility cons=\r\ntraints (i.e. &quot;c&quot; \n&gt; &gt; and &quot;d&quot; above), what&#39;s left of the given objective f=\r\nunction \n&gt; &gt; landscape &quot;as-delivered&quot; to the EA process, will be difficult =\r\nor \n&gt; &gt; perhaps impossible to identify a global pattern of the specific \n&gt; =\r\n&gt; objective (i.e. &quot;ARBITRARY&quot; feasibility constraints).\n&gt; &gt; \n&gt; &gt; The issue =\r\nthen becomes one of economy. How much computational \n&gt; &gt; resources should b=\r\ne expended for the sole purpose of discovery of \n&gt; &gt; a &quot;GLOBAL&quot; pattern (w/=\r\n or w/o variation/elaboration) of a given \n&gt; &gt; objective of a multi-objecti=\r\nve problem?\n&gt; &gt; \n&gt; &gt; It soon becomes evident that it is more computationall=\r\ny feasible \nto \n&gt; &gt; accept &quot;REGIONAL&quot; patterns/correlations/curve-fits.\n&gt; &gt;=\r\n \n&gt; &gt; This is one of the reasons there is an entire research area \n&gt; &gt; asso=\r\nciated w/ surrogate-based models and optimization/search. In \n&gt; your \n&gt; &gt; f=\r\nield you appear to refer to it as &quot;representation&quot;.\n&gt; &gt; \n&gt; &gt; No reference h=\r\nas been made to disfavor use or applicability of EA \n&gt; for \n&gt; &gt; determinati=\r\non of pareto front solution sets. On the contrary, \nthey \n&gt; &gt; are favored a=\r\nnd well suited for this application. The issue was \n&gt; that \n&gt; &gt; the computa=\r\ntional resources required for pareto front \ndetermination \n&gt; &gt; only magnifi=\r\nes/multiplies the computational costs issues \nassociated \n&gt; &gt; with EA metho=\r\ndologies. \n&gt; &gt; \n&gt; &gt; Furthermore, it is self-evident that the application of=\r\n a given \nset \n&gt; &gt; of weights to a multiobjective problem to transform it t=\r\no a mono-\n&gt; &gt; objective problem (i.e. NEAT), the solution of which constitu=\r\ntes \n&gt; only \n&gt; &gt; a single point of a pareto front solution set.\n&gt; &gt; \n&gt; &gt; Si=\r\nmply put, the utility of stove-pipe focus on discovery of \nglobal \n&gt; &gt; patt=\r\nerns on mono-objective problems w/o application of arbitrary \n&gt; &gt; feasibili=\r\nty constraints is marginal at best. And inapplicable to \n&gt; real \n&gt; &gt; world =\r\nproblems at worst.\n&gt; &gt; \n&gt; &gt; IMHO, I believe your endevor associated with &quot;r=\r\nepresentation&quot;, \n&gt; would \n&gt; &gt; be well served by a review of surrogate-based=\r\n \n&gt; &gt; models/optimization/search. But then, that may not be considered \n&gt; &gt;=\r\n a &quot;breakthrough&quot;.\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stan=\r\nley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Andy, maybe you can provide an example =\r\nof &quot;non-linear \ninequality \n&gt; &gt; &gt; feasibility constraints&quot; that &quot;utterly de=\r\nstroy&quot; patterns and \n&gt; &gt; &gt; regularities? \n&gt; &gt; &gt; \n&gt; &gt; &gt; I think most people =\r\nwould agree that many practical problems \n&gt; &gt; involve \n&gt; &gt; &gt; some kind of p=\r\nattern.  The human brain itself is filled with \n&gt; &gt; &gt; spectacular examples =\r\nof neural patterns, both spatially and \n&gt; &gt; &gt; temporally.   Is the human br=\r\nain &quot;utterly destroyed&quot; by &quot;non-\n&gt; linear \n&gt; &gt; &gt; inequality feasibility con=\r\nstraints?&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; I get your broader point, though.  You&#39;re saying th=\r\nat I&#39;m \ngetting \n&gt; a \n&gt; &gt; &gt; distorted perspective because I&#39;m conentrating =\r\non patterns when \n&gt; &gt; &gt; there are other factors in the world than just patt=\r\nerns.  Yet \nwe \n&gt; &gt; &gt; cannot expect every new algorithm to simultaneously a=\r\nddress \nevery \n&gt; &gt; &gt; challenge faced by man.  Any researcher who would try =\r\nto do \nthat \n&gt; &gt; &gt; would never get anywhere.  With HyperNEAT we have taken =\r\na step \nin \n&gt; a \n&gt; &gt; &gt; promising direction; no more, no less.  If you feel =\r\nit should \nbe \n&gt; &gt; &gt; expanded to take into account additional particular co=\r\nncerns \nthat \n&gt; &gt; &gt; you have (which for me are still fuzzy), I encourage yo=\r\nu to \n&gt; extend \n&gt; &gt; &gt; it in that direction.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; I think your quo=\r\nte from Einstein is delivered in entirely the \n&gt; wrong \n&gt; &gt; &gt; context.  The=\r\n problem of representation is largely ignored by \nthe \n&gt; &gt; &gt; machine learni=\r\nng community because it *is* the difficult part.  \n&gt; &gt; &gt; The &quot;thin part of =\r\nthe wood&quot; is the minutia of gradient \n&gt; &gt; optimization, \n&gt; &gt; &gt; which have b=\r\neen beaten to death; yet scientists to this day \nstill \n&gt; &gt; &gt; focus on it i=\r\nntently.  The reason they do that is because it&#39;s \n&gt; the \n&gt; &gt; &gt; easy part, =\r\nnot the hard part.  It is easy to climb a hill once \n&gt; you \n&gt; &gt; &gt; see it; i=\r\nt is hard to move the hill itself.  Representation \nmeans \n&gt; &gt; &gt; moving the=\r\n hills.  I believe Einstein would have no objection \nto \n&gt; &gt; &gt; rearranging =\r\nthe intellectual landscape.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In nea=\r\nt@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Ken,\n&gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; I can appreciate the need to choose applications &quot;with \ncareful \n&gt;=\r\n &gt; &gt; &gt; scrutiny with a sincere belief in their practical \n&gt; ramifications&quot;,=\r\n \n&gt; &gt; &gt; but \n&gt; &gt; &gt; &gt; the simple truth is that your bias for exploring &quot;patt=\r\nerns \nand \n&gt; &gt; &gt; &gt; regularities&quot;, are utterly destroyed by the application =\r\nof \nnon-\n&gt; &gt; &gt; linear \n&gt; &gt; &gt; &gt; inequality feasibility constraints. Which ro=\r\nutinely happens \nin \n&gt; &gt; the \n&gt; &gt; &gt; &gt; domain of engineering optimization/se=\r\narch. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Your operation without the application of the press=\r\nures \n&gt; &gt; associated \n&gt; &gt; &gt; &gt; with these pattern destroying influences resu=\r\nlts in a \n&gt; unrealistic \n&gt; &gt; &gt; &gt; perspective on the utility of global patte=\r\nrn exploitation, \nand \n&gt; a \n&gt; &gt; &gt; &gt; failure to address the repercussions of=\r\n the sometimes \nseemingly \n&gt; &gt; &gt; &gt; totally arbitrary nature of enforced fea=\r\nsibility constraints \n&gt; &gt; &gt; dictated \n&gt; &gt; &gt; &gt; by real-world problems.\n&gt; &gt; &gt;=\r\n &gt; \n&gt; &gt; &gt; &gt; Until you can simultaneously address the exploitation of \n&gt; mul=\r\ntiple \n&gt; &gt; &gt; &gt; hyperspace &quot;regional/sub-volume&quot; patterns/regularities \nover=\r\nlaid \n&gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; multiple arbitrary non-linear inequality feasibil=\r\nity \n&gt; constraints, \n&gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; a computationally practical manner, =\r\nmethodologies such as \n&gt; &gt; &gt; Hyperneat \n&gt; &gt; &gt; &gt; will be dispatched as &quot;curi=\r\nosities&quot; only.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; These kinds of pressures are routinely addr=\r\nessed in the \ndomain \n&gt; of \n&gt; &gt; &gt; &gt; engineering optimization/search. Your c=\r\nhoice of side-stepping \n&gt; &gt; &gt; these \n&gt; &gt; &gt; &gt; influences shapes what infrast=\r\nructure is and is-not \ndeveloped, \n&gt; as \n&gt; &gt; &gt; has \n&gt; &gt; &gt; &gt; been adequately=\r\n addressed in prior posts.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; An applicable quote: &quot;I have li=\r\nttle patience with scientists \n&gt; who \n&gt; &gt; &gt; take \n&gt; &gt; &gt; &gt; a board of wood, =\r\nlook for its thinnest part, and drill a \ngreat \n&gt; &gt; &gt; number \n&gt; &gt; &gt; &gt; of ho=\r\nles where drilling is easy.&quot;--Albert Einstein\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@=\r\nyahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; \n&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; =\r\n&gt; Andy, I have no problem with the idea of NEAT as a \nfoundation \n&gt; &gt; &gt; upo=\r\nn\n&gt; &gt; &gt; &gt; &gt; which to build.  That&#39;s perfectly aligned with my view that \n&gt; =\r\n&gt; &gt; there is\n&gt; &gt; &gt; &gt; &gt; more yet to accomplish.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Let m=\r\ne respond to some of your specific points below.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; --- I=\r\nn neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; The issues you raise, though valid, appear disingenuous \nfor \n&gt;=\r\n &gt; &gt; two \n&gt; &gt; &gt; &gt; &gt; &gt; reasons. First, if you had reviewed the contents and =\r\n\n&gt; &gt; &gt; capabilities \n&gt; &gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; &gt; the Dakota toolkit, you would =\r\nhave discovered the issues \nas \n&gt; &gt; &gt; being \n&gt; &gt; &gt; &gt; &gt; &gt; essentially addres=\r\nsed. Second, not intending any \n&gt; disrespect, \n&gt; &gt; &gt; from \n&gt; &gt; &gt; &gt; &gt; &gt; exte=\r\nrnal appearances, your efforts appear directed in \nother \n&gt; &gt; &gt; &gt; &gt; &gt; direc=\r\ntions than that of addressing your self admitted \nareas \n&gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; concern.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; From a review of literature on the subj=\r\nect, there is a \n&gt; common \n&gt; &gt; &gt; &gt; &gt; &gt; understanding that EA is computation=\r\nally expensive and \nslow \n&gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; converge, but robust for glob=\r\nal search in problem domains \n&gt; &gt; with \n&gt; &gt; &gt; &gt; &gt; &gt; multiple local minima.\n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; It really just depends who you are talkin=\r\ng about whether \n&gt; there \n&gt; &gt; &gt; is a\n&gt; &gt; &gt; &gt; &gt; &quot;common understanding&quot; about=\r\n anything in AI.  It also \ndepends \n&gt; &gt; &gt; &gt; whether\n&gt; &gt; &gt; &gt; &gt; we are talkin=\r\ng about the past or the future.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; For example, it&#39;s of=\r\nten said that &quot;neural networks get \ncaught \n&gt; &gt; on \n&gt; &gt; &gt; &gt; local\n&gt; &gt; &gt; &gt; &gt;=\r\n optima&quot; (and there is indeed a &quot;common understanding&quot; that \n&gt; they \n&gt; &gt; &gt; =\r\ndo)\n&gt; &gt; &gt; &gt; &gt; but when people say that they are almost always only \ntalking=\r\n \n&gt; &gt; &gt; about\n&gt; &gt; &gt; &gt; &gt; backprop, which is just one single neural network l=\r\nearning \n&gt; &gt; &gt; &gt; algorithm.\n&gt; &gt; &gt; &gt; &gt;  Backprop is not the only way a neura=\r\nl network can learn.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; The problem is that when we talk =\r\nabout methods in machine \n&gt; &gt; &gt; learning \n&gt; &gt; &gt; &gt; we\n&gt; &gt; &gt; &gt; &gt; often confus=\r\ne whether we are talking about a *field* or a \n&gt; &gt; &gt; particular\n&gt; &gt; &gt; &gt; &gt; m=\r\nethod.  In the case of EAs, you seem to be talking about \nsome\n&gt; &gt; &gt; &gt; &gt; ex=\r\nisting methods that have been analyzed (often by people \nwho \n&gt; &gt; &gt; are \n&gt; =\r\n&gt; &gt; &gt; not\n&gt; &gt; &gt; &gt; &gt; even aware of the most modern approaches) in the past. =\r\n  \nFor \n&gt; &gt; &gt; &gt; example,\n&gt; &gt; &gt; &gt; &gt; the old-fashioned bit-string based simpl=\r\ne EA has been \nanalyzed\n&gt; &gt; &gt; &gt; &gt; extensively.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Yet as =\r\na field, EAs themselves are evolving.  Problems \n&gt; &gt; &gt; identified in\n&gt; &gt; &gt; =\r\n&gt; &gt; the past are actively being addressed in the present and \n&gt; &gt; future. \n=\r\n&gt; &gt; &gt; &gt; Some\n&gt; &gt; &gt; &gt; &gt; modern approaches completely overturn the assumption=\r\ns and \n&gt; &gt; &gt; problems \n&gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; the past (and of course introdu=\r\nce their own new problems).  \n&gt; &gt; &gt; Check \n&gt; &gt; &gt; &gt; out\n&gt; &gt; &gt; &gt; &gt; Estimation=\r\n of Distribution Algorithms and the CMA-ES:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; http:=\r\n//en.wikipedia.org/wiki/Estimation_of_distribution_algorithm\n&gt; &gt; &gt; &gt; &gt; http=\r\n://en.wikipedia.org/wiki/CMA-ES\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; When I look at EAs, or=\r\n any research area for that matter, I \n&gt; &gt; &gt; always\n&gt; &gt; &gt; &gt; &gt; think about w=\r\nhat they *could* be, rather than what they \nare.  \n&gt; &gt; &gt; And \n&gt; &gt; &gt; &gt; as a\n=\r\n&gt; &gt; &gt; &gt; &gt; researcher, I try to make them what they could be.  To me, \n&gt; tha=\r\nt \n&gt; &gt; &gt; is \n&gt; &gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; exciting thing about research: At its be=\r\nst, it overturns \n&gt; &gt; dogma.  \n&gt; &gt; &gt; I\n&gt; &gt; &gt; &gt; &gt; like to view a limitation =\r\nas a challenge rather than as a \n&gt; brick \n&gt; &gt; &gt; &gt; wall.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; And that is from people who are working &quot;hard&quot; problems \n&gt; (i.e. \n&gt; &gt; &gt;=\r\n &gt; multi-\n&gt; &gt; &gt; &gt; &gt; &gt; discipline, multiobjective, non-linear inequality \n&gt; =\r\n&gt; constraints, \n&gt; &gt; &gt; &gt; etc.), \n&gt; &gt; &gt; &gt; &gt; &gt; at government laboratories and =\r\nFortune 100 defense firms. \n&gt; Not \n&gt; &gt; &gt; &gt; dancing \n&gt; &gt; &gt; &gt; &gt; &gt; rag-dolls a=\r\nnd computer-aided art.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; First, while you o=\r\nften cite multiobjective optimization as \n&gt; &gt; &gt; a &quot;hard\n&gt; &gt; &gt; &gt; &gt; problem&quot; =\r\nfor EAs, in fact some of the most effective \n&gt; algorithms \n&gt; &gt; &gt; in\n&gt; &gt; &gt; &gt;=\r\n &gt; multiobjective optimization are EAs.  EAs are naturally \n&gt; suited \n&gt; &gt; t=\r\no\n&gt; &gt; &gt; &gt; &gt; maintaining a pareto front because a pareto front requires a\n&gt; =\r\n&gt; &gt; &gt; &gt; population to hold it.  There is vast literature on pareto\n&gt; &gt; &gt; &gt; =\r\n&gt; optimization in EAs, both in multiobjective optimization \nand \n&gt; in\n&gt; &gt; &gt;=\r\n &gt; &gt; coevolution.  Here are some seminal examples:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; K. =\r\nDeb, A. Pratap, S. Agarwal, and T. Meyarivan. A Fast and \n&gt; &gt; &gt; Elitist\n&gt; &gt;=\r\n &gt; &gt; &gt; Multiobjective Genetic Algorithm: NSGA-II. IEEE \nTransactions \n&gt; on\n=\r\n&gt; &gt; &gt; &gt; &gt; Evolutionary Computation, 6(2):182=96197, 2002.\n&gt; &gt; &gt; &gt; &gt; http://=\r\nciteseer.ist.psu.edu/530140.html\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; De Jong, E.D. (2004).=\r\n The Incremental Pareto-Coevolution \n&gt; &gt; Archive.\n&gt; &gt; &gt; &gt; &gt; Proceedings of =\r\nthe Genetic and Evolutionary Computation \n&gt; &gt; &gt; Conference\n&gt; &gt; &gt; &gt; &gt; GECCO-=\r\n04, pp. 525-536. \n&gt; &gt; &gt; &gt; &gt; http://people.cs.uu.nl/dejong/publications/gecc=\r\no04coev.pdf\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; in fact, some of the most brilliant theori=\r\nsts in pareto \n&gt; &gt; &gt; optimization\n&gt; &gt; &gt; &gt; &gt; are in evolutionary computation=\r\n.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; As for NEAT in government research labs on &quot;serious&quot;=\r\n \n&gt; problems, \n&gt; &gt; &gt; here \n&gt; &gt; &gt; &gt; is\n&gt; &gt; &gt; &gt; &gt; an example:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; &gt; &gt; Shimon Whiteson and Daniel Whiteson (2007). &quot;Stochastic \n&gt; &gt; &gt; Optimi=\r\nzation\n&gt; &gt; &gt; &gt; &gt; for Collision Selection in High Energy Physics&quot;. IAAI 2007=\r\n:\n&gt; &gt; &gt; &gt; &gt; Proceedings of the Nineteenth Annual Innovative \nApplications \n=\r\n&gt; of\n&gt; &gt; &gt; &gt; &gt; Artificial Intelligence Conference.&#8202;\n&gt; &gt; &gt; &gt; &gt; http://=\r\narxiv.org/PS_cache/hep-ex/pdf/0607/0607012v1.pdf\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; The a=\r\nrticle itself states, &quot;These NEAT selectors are \n&gt; currently \n&gt; &gt; &gt; in \n&gt; &gt;=\r\n &gt; &gt; use\n&gt; &gt; &gt; &gt; &gt; at FermiLab for selecting collisions from real data \ncol=\r\nlected\n&gt; &gt; &gt; &gt; &gt; with the Tevatron collider.&quot;  So, there you go, NEAT is \nb=\r\neing \n&gt; &gt; &gt; used \n&gt; &gt; &gt; &gt; at\n&gt; &gt; &gt; &gt; &gt; FermiLab itself to select which part=\r\nicle collisions are \nmost \n&gt; &gt; &gt; &gt; promising.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; When you=\r\n mention rag dolls and art, you&#39;re giving me an \n&gt; &gt; &gt; opportunity \n&gt; &gt; &gt; &gt;=\r\n to\n&gt; &gt; &gt; &gt; &gt; comment on some of our own current research.  Our group has \n=\r\n&gt; &gt; &gt; indeed\n&gt; &gt; &gt; &gt; &gt; recently produced a number of works in interactive \n=\r\nevolution,\n&gt; &gt; &gt; &gt; &gt; including dance, art, music, and particle effects.  Pe=\r\nrhaps \n&gt; it \n&gt; &gt; &gt; may\n&gt; &gt; &gt; &gt; &gt; seem a somewhat lighthearted departure fro=\r\nm more serious \n&gt; &gt; &gt; subjects.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Yet the implications o=\r\nf this work are as serious as any in \nmy \n&gt; &gt; &gt; view. \n&gt; &gt; &gt; &gt; &gt; All of tha=\r\nt work is a probe of the ubiquity of patterns and\n&gt; &gt; &gt; &gt; &gt; regularities, i=\r\nn particular through the theory of CPPNs.  \nThe \n&gt; &gt; &gt; deeper\n&gt; &gt; &gt; &gt; &gt; les=\r\nson in that body of work is that the very same encoding \nis \n&gt; &gt; &gt; able \n&gt; =\r\n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; produce patterns appropriate to what would otherwise app=\r\near \n&gt; to \n&gt; &gt; be\n&gt; &gt; &gt; &gt; &gt; disparate domains.  The idea is to develop a th=\r\neory of \n&gt; generic \n&gt; &gt; &gt; &gt; pattern\n&gt; &gt; &gt; &gt; &gt; generation and to show that p=\r\natterns are interchangeable \n&gt; across \n&gt; &gt; &gt; many\n&gt; &gt; &gt; &gt; &gt; domains.  That =\r\ninsight leads to the idea of HyperNEAT, \nwhich \n&gt; &gt; &gt; takes\n&gt; &gt; &gt; &gt; &gt; again=\r\n the very same encoding that is producing art and \nmusic \n&gt; &gt; and \n&gt; &gt; &gt; &gt; =\r\nuses\n&gt; &gt; &gt; &gt; &gt; it to produce a large-scale neural pattern.  Therein it \n&gt; b=\r\necomes\n&gt; &gt; &gt; &gt; &gt; serious, because the hard problems you like to focus on \n&gt;=\r\n almost \n&gt; &gt; &gt; &gt; always\n&gt; &gt; &gt; &gt; &gt; involve patterns and regularities.  \n&gt; &gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; It is no accident that in building a theory of pattern \n&gt; =\r\n&gt; &gt; generation, a\n&gt; &gt; &gt; &gt; &gt; number of interactive evolutionary computation =\r\nexperiments \n&gt; &gt; would \n&gt; &gt; &gt; &gt; need\n&gt; &gt; &gt; &gt; &gt; to be performed because unde=\r\nrstanding the capabilities of a \n&gt; &gt; &gt; pattern\n&gt; &gt; &gt; &gt; &gt; generator require =\r\n*exploring* the space of possibilities \n&gt; rather \n&gt; &gt; &gt; than\n&gt; &gt; &gt; &gt; &gt; simp=\r\nly optimizing, and humans are much better explorers than\n&gt; &gt; &gt; &gt; &gt; computer=\r\ns.  The theory would never have gotten off the \nground \n&gt; &gt; if \n&gt; &gt; &gt; we\n&gt; =\r\n&gt; &gt; &gt; &gt; had stuck to more traditional optimization problems.   \n&gt; Indeed, \n=\r\n&gt; &gt; as\n&gt; &gt; &gt; &gt; &gt; funny as it sounds, the whole idea began to materialize \no=\r\nnly \n&gt; &gt; &gt; after I\n&gt; &gt; &gt; &gt; &gt; evolved a spaceship in Mattias Fagerlund&#39;s Del=\r\nphiNEAT.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; To put it starkly, without that exploration=\r\n in genetic art, \n&gt; &gt; there\n&gt; &gt; &gt; &gt; &gt; would have been no HyperNEAT.  And in=\r\n fact even more new \n&gt; &gt; &gt; theories \n&gt; &gt; &gt; &gt; with\n&gt; &gt; &gt; &gt; &gt; practical impli=\r\ncations are coming (not yet published) \nbecause \n&gt; of\n&gt; &gt; &gt; &gt; &gt; phenomena t=\r\nhat became apparent through Picbreeder.  So you \n&gt; see, \n&gt; &gt; &gt; in\n&gt; &gt; &gt; &gt; &gt;=\r\n building a new algorithm or a new theory with practical \n&gt; &gt; &gt; &gt; implicati=\r\nons,\n&gt; &gt; &gt; &gt; &gt; often traditional problems are exactly the wrong vehicle to =\r\n\n&gt; &gt; &gt; &gt; discovery\n&gt; &gt; &gt; &gt; &gt; because they perpetuate the same dogmatic pers=\r\npectives that \n&gt; &gt; &gt; already\n&gt; &gt; &gt; &gt; &gt; permeate the field to begin with and=\r\n cause it to be staying \n&gt; in \n&gt; &gt; &gt; one\n&gt; &gt; &gt; &gt; &gt; place.   Thus all of the=\r\nse applications are chosen with \n&gt; careful\n&gt; &gt; &gt; &gt; &gt; scrutiny with a sincer=\r\ne belief in their practical \n&gt; ramifications.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Not to m=\r\nention the fact that interactive evolution itself \nhas \n&gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; p=\r\nractical potential to change the way we do engineering in \n&gt; some \n&gt; &gt; &gt; &gt; =\r\ncases.\n&gt; &gt; &gt; &gt; &gt;  Can you imagine Picbreeder for furinute instead of \n&gt; pic=\r\ntures?  \n&gt; &gt; &gt; Or \n&gt; &gt; &gt; &gt; for\n&gt; &gt; &gt; &gt; &gt; cars?  Someday that may be how we =\r\ncreate highly customized \n&gt; &gt; &gt; &gt; artifacts.\n&gt; &gt; &gt; &gt; &gt;    In fact, some of =\r\nthe problems to which you are referring \n&gt; &gt; &gt; (highly\n&gt; &gt; &gt; &gt; &gt; nonlinear =\r\nand multi-objective) may only be possible to \nsolve \n&gt; &gt; &gt; through\n&gt; &gt; &gt; &gt; =\r\n&gt; interactive evolution.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; How many times has NEAT, as=\r\n a monolithic approach, been \n&gt; cited \n&gt; &gt; &gt; and \n&gt; &gt; &gt; &gt; &gt; &gt; successfully =\r\napplied by government laboratories and \nFortune \n&gt; &gt; &gt; 100 \n&gt; &gt; &gt; &gt; &gt; &gt; def=\r\nense firms for these type of &quot;hard&quot; problems?\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; &gt; You can refer to the paper on high-energy physics at \nFermiLab \n&gt; if\n&gt;=\r\n &gt; &gt; &gt; &gt; you&#39;re interested, but I still think there is a bigger \n&gt; &gt; pictur=\r\ne.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; In some ways, as researchers in AI, what practiti=\r\noners are \n&gt; &gt; using \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; solve hard problems is exactly wha=\r\nt we *don&#39;t* want to \nuse.  \n&gt; &gt; &gt; After\n&gt; &gt; &gt; &gt; &gt; all, how is anything eve=\r\nr going to become more powerful if \nwe \n&gt; &gt; &gt; just\n&gt; &gt; &gt; &gt; &gt; look to practi=\r\ntioners to show us what methods we should be \n&gt; &gt; &gt; using?  \n&gt; &gt; &gt; &gt; As\n&gt; &gt;=\r\n &gt; &gt; &gt; researchers, it is our job to give the practitioners *new* \n&gt; &gt; &gt; op=\r\ntions,\n&gt; &gt; &gt; &gt; &gt; not the other way around.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Practitione=\r\nrs are often several steps behind algorithm \n&gt; &gt; &gt; developers, \n&gt; &gt; &gt; &gt; and=\r\n\n&gt; &gt; &gt; &gt; &gt; with good reason.  They often can&#39;t afford to take big \nrisks \n&gt;=\r\n &gt; and \n&gt; &gt; &gt; &gt; need\n&gt; &gt; &gt; &gt; &gt; something practical in the here and now.   Y=\r\nou will \ntherefore \n&gt; &gt; &gt; find\n&gt; &gt; &gt; &gt; &gt; that most cutting-edge algorithms =\r\nare not in use in \nindustry \n&gt; or \n&gt; &gt; &gt; as\n&gt; &gt; &gt; &gt; &gt; tools in other scient=\r\nific disciplines at the very moment \nthat \n&gt; &gt; &gt; they \n&gt; &gt; &gt; &gt; are\n&gt; &gt; &gt; &gt; =\r\n&gt; cutting-edge.  Yet someone has to be developing the \n&gt; algorithms \n&gt; &gt; &gt; =\r\nof \n&gt; &gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; future.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; =\r\n&gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}