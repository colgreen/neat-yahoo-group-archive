{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":183620858,"authorName":"Derek James","from":"&quot;Derek James&quot; &lt;djames@...&gt;","profile":"blue5432","replyTo":"LIST","senderId":"sRw_bcfMWnI-Bzm55pB8lv95pVMvQTMNGK6GRLCeSBtqsKu282anqXHCqRMAVS__PB9Sn_cHIA6bFdn55S1GBj8uxxVfxZU","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Benchmarks for Artificial Embryogeny Systems","postDate":"1218909263","msgId":4281,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDE5YjEwZDUxMDgwODE2MTA1NGpmNTkwYWM4cDZjNWQ2MTUyNzU5NDMwNDRAbWFpbC5nbWFpbC5jb20+","inReplyToHeader":"PGc3dmE2ditkbGI0QGVHcm91cHMuY29tPg==","referencesHeader":"PDE5YjEwZDUxMDgwODA1MDgyNnRlNjFlY2VhdjNjZTMwMzEwNTFiNjY0ZTZAbWFpbC5nbWFpbC5jb20+CSA8Zzd2YTZ2K2RsYjRAZUdyb3Vwcy5jb20+"},"prevInTopic":4280,"nextInTopic":4282,"prevInTime":4280,"nextInTime":4282,"topicId":4244,"numMessagesInTopic":20,"msgSnippet":"On Wed, Aug 13, 2008 at 11:46 AM, Kenneth Stanley ... Thanks for responding, Ken. I do think it s an interesting discussion. ... Right, which is why you d want","rawEmail":"Return-Path: &lt;djames@...&gt;\r\nX-Sender: djames@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 24988 invoked from network); 16 Aug 2008 17:54:24 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m36.grp.scd.yahoo.com with QMQP; 16 Aug 2008 17:54:24 -0000\r\nX-Received: from unknown (HELO wf-out-1314.google.com) (209.85.200.174)\n  by mta15.grp.scd.yahoo.com with SMTP; 16 Aug 2008 17:54:24 -0000\r\nX-Received: by wf-out-1314.google.com with SMTP id 28so2029603wfa.8\n        for &lt;neat@yahoogroups.com&gt;; Sat, 16 Aug 2008 10:54:23 -0700 (PDT)\r\nX-Received: by 10.142.172.12 with SMTP id u12mr1437181wfe.180.1218909263870;\n        Sat, 16 Aug 2008 10:54:23 -0700 (PDT)\r\nX-Received: by 10.142.77.4 with HTTP; Sat, 16 Aug 2008 10:54:23 -0700 (PDT)\r\nMessage-ID: &lt;19b10d510808161054jf590ac8p6c5d615275943044@...&gt;\r\nDate: Sat, 16 Aug 2008 10:54:23 -0700\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;g7va6v+dlb4@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nContent-Disposition: inline\r\nReferences: &lt;19b10d510808050826te61eceav3ce3031051b664e6@...&gt;\n\t &lt;g7va6v+dlb4@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Derek James&quot; &lt;djames@...&gt;\r\nSubject: Re: [neat] Re: Benchmarks for Artificial Embryogeny Systems\r\nX-Yahoo-Group-Post: member; u=183620858; y=CRsBvnJk9QTxIFJbydk8uDbJ9ubreyAkCAmMG5uJjRqmx5g\r\nX-Yahoo-Profile: blue5432\r\n\r\nOn Wed, Aug 13, 2008 at 11:46 AM, Kenneth Stanley\n&lt;kstanley@...&gt; wrote:\n&gt; Derek, it took me a little time to respond but I did want to address\n&gt; some of your points..\n\nThanks for responding, Ken. I do think it&#39;s an interesting discussion.\n\n&gt; Yes I agree, it&#39;s the general case of getting stuck. Which is why I\n&gt; think benchmarks are a tricky business in any field, not just in AE.\n&gt; However, I do not think it is particularly important if a particular\n&gt; candidate (which I guess means a run of evolution) fails to represent\n&gt; a simple target. Just because it doesn&#39;t do it does not mean that it\n&gt; cannot do it, and if the fitness function does not reward the proper\n&gt; stepping stones, then it doesn&#39;t seem very significant for the\n&gt; encoding that it did or did not end up hitting a target in one run.\n\nRight, which is why you&#39;d want to do many runs, and even then you&#39;d\nwant to be careful about categorically claiming what the AE system\ncannot represent.\n\nI think it would be particularly interesting to carry out some of the\nbenchmarks you suggested in your paper in the context of artificial\nselection. For example, evolving an n-pointed star by having a user or\nmultiple users start with a simple configuration and then iteratively\nchoose patterns that more closely resembled the target pattern. Do you\nhave any sense of how difficult/easy it is to evolve particular simple\nshapes with picbreeder?\n\n&gt; Yes I think we are not disagreeing that much. If you want to be able\n&gt; to evolve bilateral symmetry then of course you want an encoding that\n&gt; has a high probability of doing so. However, the problem is that\n&gt; &quot;bilateral symmetry&quot; is not a single target pattern, but rather a\n&gt; large set of patterns. Therefore, if you choose say five arbitrary\n&gt; bilaterally symmetric patterns and the encoding doesn&#39;t hit them, it\n&gt; doesn&#39;t necessarily mean that it has any intrinsic problem with\n&gt; bilateral symmetry. Even if you chose a kind of general target, like\n&gt; &quot;anything bilaterally symmetric,&quot; you still have to ask whether the\n&gt; fitness function actually rewards the stepping stones towards that\n&gt; goal, or whether perhaps the probability of hitting it is totally\n&gt; orthogonal to the fitness function (and hence the target).\n&gt;\n&gt; In some cases (such as CPPNs), it will be a priori obvious how often\n&gt; you will tend to get bilateral symmetry without even needing to run a\n&gt; benchmark because you know how the encoding works. With CPPNs, if you\n&gt; know the mutation rate then you know that probability of adding\n&gt; Gaussian in front of x or y, and then you have right away an idea\n&gt; about the probabilities. Thus benchmarks don&#39;t really add much in\n&gt; such a case.\n\nThat makes sense. And if your system included primitives like rings,\nthen you&#39;d know what the probability of one or more rings emerging\nwould be. So we&#39;d agree that benchmarks are only meaningful for the\ntypes of patterns that aren&#39;t explicit in the encoding, but have to\nemerge as a result of evolutionary processes.\n\n&gt; I think some experiments like that would be interesting, so I agree.\n&gt; I&#39;m just saying you have to be cautious about drawing conclusions. If\n&gt; system A evolves a star and system B doesn&#39;t, what does it actually\n&gt; tell us about which system to use in any situation aside from one in\n&gt; which that exact star is needed with that exact fitness function? It\n&gt; may tell us something, but we need to think about what that would be.\n&gt;\n&gt; By the way, my concern with benchmark comparisons is broader than just\n&gt; AE. The whole field of machine learning abuses benchmarks to no end,\n&gt; and benchmarks get a lot more credit than they deserve. While they\n&gt; are by no means worthless, at this moment in time, what benchmark\n&gt; comparisons could use is a healthy dose of criticism. What I&#39;m saying\n&gt; is that while they can certainly be defended rationally, right now\n&gt; they don&#39;t really need much defending because everyone automatically\n&gt; assumes that they are the be all and end all of machine learning\n&gt; research anyway. In other words, the pendulum can spare to swing a\n&gt; little back the other way.\n&gt;\n&gt; What I think we need to consider in AI and machine learning that\n&gt; benchmark comparisons have made us forget is that a lot of them time,\n&gt; our own personal ability to analyze and intuit the value of an\n&gt; approach through our intellect often should trump benchmark comparisons.\n&gt;\n&gt; As I said to Jeff at GECCO, it would be interesting to see an AI\n&gt; journal that explicitly prohibits reviewers from basing their accept\n&gt; or reject decisions on experimental results in submitted papers.\n&gt; Instead, they would be forced to evaluate the merits of an approach\n&gt; intellectually. Papers would not even be required to present any\n&gt; results at all. While it is a radical idea, if we had world-class\n&gt; reviewers and took the policy seriously, we would get a rapid\n&gt; exploration of the space of interesting ideas- something AI is\n&gt; handicapped from doing right now because of its obsession with\n&gt; benchmarks. Benchmarks have become an excuse not to think deeply. We\n&gt; should not get rid of them, but they can spare a little pruning in the\n&gt; current environment.\n\nIt kind of sounds like you&#39;re advocating a greater role for\nsubjectivity in evaluating research, by not focusing on experimental\nresults or benchmarks. Is this what you&#39;re advocating?\n\nI admit that the images produced by Picbreeder are complex and\ninteresting, but if I&#39;m trying to solve a particular problem, and I\nneed to choose between System A and System B, wouldn&#39;t it be better if\nI had more solid quantitative data to support my decision, rather than\nrelying on some sort of subjective evaluation?\n\n--Derek\n\n"}}