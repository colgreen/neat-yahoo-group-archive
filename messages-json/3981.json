{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"EG3pLyRcUVjsXlxfTeKJKOm7ltsUbaNbKvzt0gLE-_lt3pSgXLM_Sso295LoQtZhzasXohblsFnD300huSIRkCc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Another New Paper:  Multiagent HyperNEAT","postDate":"1209058691","msgId":3981,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ1cWdpMys1aWg2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZ1cWcyMytxdWFiQGVHcm91cHMuY29tPg=="},"prevInTopic":3980,"nextInTopic":3982,"prevInTime":3980,"nextInTime":3982,"topicId":3955,"numMessagesInTopic":49,"msgSnippet":"I would be interested in your post-mortem musings, regarding possible NEAT/HyperNEAT infrastructure modifications to facilitate seeding and scalability (i.e.","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 31666 invoked from network); 24 Apr 2008 17:38:11 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m54.grp.scd.yahoo.com with QMQP; 24 Apr 2008 17:38:11 -0000\r\nX-Received: from unknown (HELO n47b.bullet.mail.sp1.yahoo.com) (66.163.168.161)\n  by mta15.grp.scd.yahoo.com with SMTP; 24 Apr 2008 17:38:11 -0000\r\nX-Received: from [216.252.122.219] by n47.bullet.mail.sp1.yahoo.com with NNFMP; 24 Apr 2008 17:38:11 -0000\r\nX-Received: from [66.218.69.2] by t4.bullet.sp1.yahoo.com with NNFMP; 24 Apr 2008 17:38:11 -0000\r\nX-Received: from [66.218.66.87] by t2.bullet.scd.yahoo.com with NNFMP; 24 Apr 2008 17:38:11 -0000\r\nDate: Thu, 24 Apr 2008 17:38:11 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fuqgi3+5ih6@...&gt;\r\nIn-Reply-To: &lt;fuqg23+quab@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Another New Paper:  Multiagent HyperNEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=LUYm51zwBM5_T9bCLK45eID7UtvPN2l6r_FTT2618F9C4w\r\nX-Yahoo-Profile: afcarl2\r\n\r\nI would be interested in your post-mortem musings, regarding possible \nNEAT=\r\n/HyperNEAT infrastructure modifications to facilitate seeding and \nscalabil=\r\nity (i.e. seemless addition/reduction of agents).\n\n\n--- In neat@yahoogroups=\r\n.com, &quot;David D&#39;Ambrosio&quot; &lt;ddambro84@...&gt; wrote:\n&gt;\n&gt; I actually did run some=\r\n heterogeneous experiments without the\n&gt; repeating frame, although it was p=\r\nurely by accident so I did not do\n&gt; any real analysis to the results, but w=\r\nhat I saw was that without r\n(X)\n&gt; unseeded heterogeneous teams performed w=\r\norse than the other four \ntypes\n&gt; in this paper.\n&gt; \n&gt; The reasoning behind =\r\nthis disparity in performance is, I think, what\n&gt; Ken suggested: that there=\r\n is a kind of &quot;chicken and egg&quot; problem \nhere.\n&gt;  Finding the pattern of ag=\r\nents doesn&#39;t directly benefit the agents \nin\n&gt; terms of fitness, and simila=\r\nrly finding an optimal control policy \nfor\n&gt; five agents doesn&#39;t help unles=\r\ns you can distribute it properly among\n&gt; them.  However, by giving HyperNEA=\r\nT one of these two things that we\n&gt; know to be correct (the agent locations=\r\n), it can work on finding the\n&gt; other.\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;K=\r\nenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Jeff, those are good questions. =\r\n Actually, David can correct me \nif I\n&gt; &gt; am wrong, but I believe we never =\r\ndid try to run these experiments\n&gt; &gt; without providing the repeating coordi=\r\nnate frame.  It is \ninteresting\n&gt; &gt; that you see that as a natural first st=\r\nep, since our thinking \nunfolded\n&gt; &gt; in a different order:\n&gt; &gt; \n&gt; &gt; The ide=\r\na originated from the thought that it is an advantage of\n&gt; &gt; HyperNEAT that=\r\n we can describe to it a priori the locations of\n&gt; &gt; different agents on th=\r\ne substrate and that way convey to it that \nthere\n&gt; &gt; are variations on a t=\r\nheme from the start.  Also, we thought it was\n&gt; &gt; tidy that we can perfectl=\r\ny express to the learner from the start\n&gt; &gt; exactly where those agents&#39; net=\r\nworks begin and end, leaving no \nroom\n&gt; &gt; for ambiguity or misalignment.\n&gt; =\r\n&gt; \n&gt; &gt; Perhaps one way to explain why we thought about that first is to\n&gt; &gt;=\r\n consider that one important philosophical motivation behind \nHyperNEAT\n&gt; &gt;=\r\n is that machine learning needs a way for humans to convey to the\n&gt; &gt; learn=\r\ner a priori known domain geometry.  In effect, we are running\n&gt; &gt; away from=\r\n the black box of No Free Lunch (which is a nasty trap) \nby\n&gt; &gt; finding new=\r\n ways to convey critical a priori domain information. \n&gt; &gt; While arguments =\r\ncan be made that because certain techniques align \nwith\n&gt; &gt; certain problem=\r\n classes we should not pay too much heed to NFL, \nwhy\n&gt; &gt; would we purposef=\r\nully move *towards* the black box when we don&#39;t \nhave\n&gt; &gt; to?  The real exc=\r\nitement, I think, is to find very general \ntechniques\n&gt; &gt; for conveying to =\r\nthe learner standard kinds of a priori practical\n&gt; &gt; information (or bias),=\r\n e.g. geometry.\n&gt; &gt; \n&gt; &gt; That said, if you really did start without the rep=\r\neating \ncoordinate\n&gt; &gt; frames, I am guessing it would perform worse as you =\r\npredict, \nthough I\n&gt; &gt; don&#39;t know by how much.  It is probably worth doing =\r\njust to see \nwhat\n&gt; &gt; happens.  Yet my personal view is that there would no=\r\nt be a very \ndeep\n&gt; &gt; insight to gain from such a result.  After all, why w=\r\nould we \nexpect it\n&gt; &gt; to consistently discover the right regularity simply=\r\n by chance \nevery\n&gt; &gt; time?  Remember that early in evolution, simply disco=\r\nvering this\n&gt; &gt; regularity may not even be rewarded; just because it someho=\r\nw gets\n&gt; &gt; lucky and figures out exactly the right repeating frame of \nrefe=\r\nrence,\n&gt; &gt; that does not necessarily mean that within those coordinate \nfra=\r\nmes it\n&gt; &gt; is doing anything useful (i.e. it could be a repetition of a bad=\r\n\n&gt; &gt; policy), so the discovery is likely to go unnoticed and die out, \njust=\r\n\n&gt; &gt; as easily as it might be leveraged and elaborated properly.\n&gt; &gt; \n&gt; &gt; T=\r\nhis problem is related to that discussion we had a while back \nabout\n&gt; &gt; &quot;t=\r\narget-based evolution&quot; and the phenomena of Picbreeder.  Often \nthe\n&gt; &gt; ste=\r\npping stones (such as discovering the right basic regularity) \nare\n&gt; &gt; not =\r\nrecognized by the ultimate objective function, so it&#39;s pretty \nmuch\n&gt; &gt; up =\r\nto luck to find them and keep them around long enough to take\n&gt; &gt; advantage=\r\n of them.  My feeling is that it is not fruitful for any\n&gt; &gt; indirect encod=\r\ning to try to solve that problem, because it is not \na\n&gt; &gt; problem with the=\r\n encoding per say but rather with the way fitness \nis\n&gt; &gt; assigned.\n&gt; &gt; \n&gt; =\r\n&gt; With this dilemma in mind, I think it is perhaps most useful to \npoint\n&gt; =\r\n&gt; out that we can simply tell it the regularity that is important \nand\n&gt; &gt; =\r\nsee if it can exploit that effectively, which shows that we can\n&gt; &gt; provide=\r\n powerful domain bias.  \n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com,=\r\n Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hello-\n&gt; &gt; &gt; \n&gt; &gt; &gt; I enjoyed read=\r\ning this. Thanks for posting it.\n&gt; &gt; &gt; \n&gt; &gt; &gt; A question: how did HyperNEAT=\r\n perform when you did not provide \nit\n&gt; &gt; with the\n&gt; &gt; &gt; repeating coordina=\r\nte frame for each agent? As you mention in the\n&gt; &gt; paper, this\n&gt; &gt; &gt; is som=\r\nething that HyperNEAT could learn on its own. I assume \nfrom\n&gt; &gt; the fact\n&gt;=\r\n &gt; &gt; that you added it that HyperNEAT was not doing a good job of\n&gt; &gt; learn=\r\ning this.\n&gt; &gt; &gt; \n&gt; &gt; &gt; If that assumption is right, how bad was it at learn=\r\ning this \nproblem\n&gt; &gt; &gt; decomposition? One of the touted benefits of HyperN=\r\nEAT, and \ngenerative\n&gt; &gt; &gt; encodings in general, is the ability to evolve a=\r\n module and \nreuse it\n&gt; &gt; many\n&gt; &gt; &gt; times (potentially with variation).  H=\r\nere the modularity of the\n&gt; &gt; problem was\n&gt; &gt; &gt; cleanly divided, and should=\r\n have been relatively easy for \nHyperNEAT to\n&gt; &gt; &gt; discover. Do you find it=\r\n disconcerting that it couldn&#39;t do so?\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Cheers,\n&gt;=\r\n &gt; &gt; Jeff Clune\n&gt; &gt; &gt; \n&gt; &gt; &gt; Digital Evolution Lab, Michigan State Universi=\r\nty\n&gt; &gt; &gt; \n&gt; &gt; &gt; jclune@\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; From: Kenneth S=\r\ntanley &lt;kstanley@&gt;\n&gt; &gt; &gt; &gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogrou=\r\nps.com&gt;\n&gt; &gt; &gt; &gt; Date: Wed, 16 Apr 2008 22:48:44 -0000\n&gt; &gt; &gt; &gt; To: &quot;neat@yah=\r\noogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; &gt; Subject: [neat] Another New Pa=\r\nper:  Multiagent HyperNEAT\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; David D&#39;Ambrosio and I discuss =\r\nthe potential for HyperNEAT\n&gt; &gt; &gt; &gt; controlling multiple heterogeneous agen=\r\nts in this new\n&gt; &gt; &gt; &gt; paper, &quot;Generative Encoding for Multiagent Learning,=\r\n&quot; to \nappear at\n&gt; &gt; &gt; &gt; GECCO 2008:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; http://eplex.cs.ucf.ed=\r\nu/index.php?\n&gt; &gt; &gt; &gt; option=3Dcom_content&task=3Dview&id=3D14&Itemid=3D28#d=\r\nambrosio.gecco08\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Direct Link:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; http://eple=\r\nx.cs.ucf.edu/papers/dambrosio_gecco08.pdf\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; We also have a n=\r\nice sample of videos that depict various \nevolved\n&gt; &gt; &gt; &gt; teams in action:\n=\r\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; http://eplex.cs.ucf.edu/multiagenthyperneat\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; The interesting idea in this paper is that just as a single\n&gt; &gt; &gt; &gt; conn=\r\nective CPPN can encode how a single network varies over \nspace,\n&gt; &gt; &gt; &gt; it =\r\ncan also encode how a *set* of networks (each representing \nthe\n&gt; &gt; &gt; &gt; pol=\r\nicy of one agent on the team) varies over space.  In this \nway,\n&gt; &gt; &gt; &gt; Hyp=\r\nerNEAT can learn an expression that encodes how policies \nvary\n&gt; &gt; &gt; &gt; over=\r\n the team geometry.  For example, in a soccer team agents \nvary\n&gt; &gt; &gt; &gt; fro=\r\nm defensive to offensive as you move away from the goal.  \nPart of\n&gt; &gt; &gt; &gt; =\r\nthe power of this approach is that it means basic skills can \nbe\n&gt; &gt; &gt; &gt; le=\r\narned and shared among the whole team, since the CPPN \nencodes how\n&gt; &gt; &gt; &gt; =\r\nthose skills vary across the field.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n=\r\n&gt;\n\n\n\n"}}