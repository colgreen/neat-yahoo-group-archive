{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":344770313,"authorName":"Colin Green","from":"Colin Green &lt;colin.green1@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"GdJOnS8dP1Q19toujKXbe4-IOWNYaPWIN-bP2aydy9I64GhHblEr31w25g66R7u6_kY2MwWO9QNsej3SXqSxc7VlIN8c8bIvjhQCk32yedA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Doble/Single digit precision NEAT [1 Attachment]","postDate":"1242779097","msgId":4675,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDcyN2E0MDZjMDkwNTE5MTcyNG41NDQzMmMxMnIyYTQ5ZmQ0NGMyZWQzODI3QG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PEMwRDVBMjI3OEVDODQ4MkNCMTMwRERCQUY2OEJBNUYxQHdhdHRwND4=","referencesHeader":"PGd1c2xlZSt1dDU4QGVHcm91cHMuY29tPiA8Qzg2RkU4RjQ4QzE3NDlCMjhFRkZDMTNFNzYxNzQwMzVAd2F0dHA0PgkgPDcyN2E0MDZjMDkwNTE5MTAzM3Q3NjExMWRlY3hlMTQ1Yzc3MGQwMTgxYzZAbWFpbC5nbWFpbC5jb20+CSA8QzBENUEyMjc4RUM4NDgyQ0IxMzBEREJBRjY4QkE1RjFAd2F0dHA0Pg=="},"prevInTopic":4674,"nextInTopic":4676,"prevInTime":4674,"nextInTime":4676,"topicId":4671,"numMessagesInTopic":7,"msgSnippet":"Ken (L), ... I ve not thougth of SA as a means to overcome low perturbation potential (as you put it), but yes I can see how it would help. I do get the sense","rawEmail":"Return-Path: &lt;colin.green1@...&gt;\r\nX-Sender: colin.green1@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 97591 invoked from network); 20 May 2009 00:25:03 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m3.grp.re1.yahoo.com with QMQP; 20 May 2009 00:25:03 -0000\r\nX-Received: from unknown (HELO yx-out-1718.google.com) (74.125.44.153)\n  by mta1.grp.sp2.yahoo.com with SMTP; 20 May 2009 00:25:02 -0000\r\nX-Received: by yx-out-1718.google.com with SMTP id 34so78082yxf.12\n        for &lt;neat@yahoogroups.com&gt;; Tue, 19 May 2009 17:24:58 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.90.90.4 with SMTP id n4mr520957agb.46.1242779097468; Tue, 19 \n\tMay 2009 17:24:57 -0700 (PDT)\r\nIn-Reply-To: &lt;C0D5A2278EC8482CB130DDBAF68BA5F1@wattp4&gt;\r\nReferences: &lt;guslee+ut58@...&gt; &lt;C86FE8F48C1749B28EFFC13E76174035@wattp4&gt;\n\t &lt;727a406c0905191033t76111decxe145c770d0181c6@...&gt;\n\t &lt;C0D5A2278EC8482CB130DDBAF68BA5F1@wattp4&gt;\r\nDate: Wed, 20 May 2009 01:24:57 +0100\r\nMessage-ID: &lt;727a406c0905191724n54432c12r2a49fd44c2ed3827@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Colin Green &lt;colin.green1@...&gt;\r\nSubject: Re: [neat] Doble/Single digit precision NEAT [1 Attachment]\r\nX-Yahoo-Group-Post: member; u=344770313; y=Wf2MheVvoIthB7rPuC6HHMNj4uvFIFMMWKl1r9-Yyty7KvQDUzk0\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nKen (L),\n\n&gt; Thank you for this background information. In many gradient descent (or\n&gt; hill climbing), there are two very real problems. The first is becoming\n&gt; stuck in local minima and the second related problem is (as you describe) is\n&gt; low perturbation potential at some point in time. The common solution I use\n&gt; to handle both conditions is a scheduled form of simulated annealing. This\n&gt; keeps the plasticity of the topology &quot;pliable&quot;\n\nI&#39;ve not thougth of SA as a means to overcome low perturbation\npotential (as you put it), but yes I can see how it would help. I do\nget the sense that it&#39;s a solution to a problem that is significantly\nreduced with greater precision variables - but of course the problem\nnever completely goes away.\n\n&gt; (in NEAT, and in radial basis\n&gt; function ANN&#39;s, we are dealing with both lengths (such as distance, L-p\n&gt; norms, etc) and weights. But even here, single precision floats properly\n&gt; normalized will help.\n\nHow would you propose normalizing these values? Do you mean as a way\nof reducing the amount/significance of floating point math &#39;errors&#39;\nduring simulation of a network?\n\n\n&gt; A very important aspect I really didn&#39;t want to get into on this project was\n&gt; the balancing of parallelization paths between tasks run on CPU cores with\n&gt; kernels run on the GPU process cores, which close-couple with the\n&gt; partitioning of the data structures between device and host memory sectors.\n\nHow is that relevant to the choice of floating point precision?\nProbably it matters because double the precision means twice the data\ntraffic between main memory and device memory and this complicates the\nchoice of how best to partition work. I&#39;m just trying to determine the\nlink in your reasoning here.\n\n&gt; This discussion may have changed my mind. Realize, that there will always\n&gt; exist some resolution limit in the data - even in double-doubles.\n\nSure (unless you have some analog sub-system, which also has it&#39;s\nlimits due to noise and imperfect electrical components).\n\n&gt; I think\n&gt; that issue becomes a red herring in neuroevolution, for reasons more related\n&gt; to the probabilistic (non-deterministic) nature of recurrent network graph\n&gt; structures. What is evolving is actually a probability density envelope -\n&gt; representing an ensemble of solutions - not one deterministic answer. Even\n&gt; as the solution approaches certainty (rho = 0), there may still be an\n&gt; infinity of solutions in that deterministic solution set. This is where\n&gt; cycles of forward and inverse Bayesian refinements are helpful (running on\n&gt; the CPUs while evolution of genome commences on the GPU). Again - far off\n&gt; the track for what I see as the fascinating study of NEAT.\n\nDo you mean something analogous to Geoff Hinton&#39;s RBM video we\ndiscussed recently? What do you refine towards? e.g. when evolving a\ncontroller with no defined &#39;correct&#39; output?\n\n\n&gt; So I ask your input, as I also ask of the group: What do want to accomplish\n&gt; by running n-dimensional substrates NEAT on a hybrid CPU/GPGPU compute node\n&gt; (or clusters thereof)? Solutions, or learning opportunities?\n\nI&#39;m not sure I&#39;m understanding the context of the question correctly,\nhowever I&#39;d say the goal is to simply run hyperneat faster. From there\nyou can perform more experiments and more detailed experiments,\nidentify strengths and weaknesses and gather more and better\nsupporting evidence towards hypotheses on how NEAT/HyperNEAT could be\nimproved - such as &#39;optimising&#39; networks in some way with e.g. a\nhybrid of evolutionary search, gradient descent, SA or whatever.\n\nColin\n\n"}}