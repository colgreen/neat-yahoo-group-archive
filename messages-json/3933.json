{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"Zw7hyX9Jed8_R1xGTEycgTaSqVwpqv9spEhYYw3OmmnrmDIlNxtD8iWn7XFt-uWDF_es2il-sxo_zf0CGXbIkZPTMTVAz9sgGEb8MAYREdrH","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Combining evolution with evolution (request for references)","postDate":"1207354045","msgId":3933,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ0NmZydCttZmYxQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIzMGU0NjNlMDgwNDAzMDM0NHA1MTkzMTJkZHFhMDNhMDY0NDY2N2U5NDU5QG1haWwuZ21haWwuY29tPg=="},"prevInTopic":3932,"nextInTopic":3934,"prevInTime":3932,"nextInTime":3934,"topicId":3922,"numMessagesInTopic":14,"msgSnippet":"... form of ... combining topology ... weights. ... obvious next ... I think that some people did see themselves as taking the next step when  neuroevoltuion","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 53154 invoked from network); 5 Apr 2008 00:07:25 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m54.grp.scd.yahoo.com with QMQP; 5 Apr 2008 00:07:25 -0000\r\nX-Received: from unknown (HELO n45c.bullet.mail.sp1.yahoo.com) (66.163.168.179)\n  by mta17.grp.scd.yahoo.com with SMTP; 5 Apr 2008 00:07:25 -0000\r\nX-Received: from [216.252.122.216] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 05 Apr 2008 00:07:25 -0000\r\nX-Received: from [66.218.69.1] by t1.bullet.sp1.yahoo.com with NNFMP; 05 Apr 2008 00:07:25 -0000\r\nX-Received: from [66.218.67.197] by t1.bullet.scd.yahoo.com with NNFMP; 05 Apr 2008 00:07:25 -0000\r\nDate: Sat, 05 Apr 2008 00:07:25 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ft6frt+mff1@...&gt;\r\nIn-Reply-To: &lt;230e463e0804030344p519312ddqa03a0644667e9459@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Combining evolution with evolution (request for references)\r\nX-Yahoo-Group-Post: member; u=54567749; y=4DMNO9--6LIIeO5cX-g_PTy1MfM7kU7iRMPrv17p6uKD14Rjdrcn\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n&gt; \n&gt; But yes, it&#39;s a combination of topology modification with another \nfor=\r\nm of\n&gt; search/learning. Much like many of those experiments with \ncombining=\r\n topology\n&gt; evolution with gradient-based learning, such as backprop, for t=\r\nhe \nweights.\n&gt; What puzzles me is why the people seem not to have taken the=\r\n \nobvious next\n&gt; step, and replaced backprop with evolution for the weights=\r\n as well.\n&gt; \n\nI think that some people did see themselves as taking the nex=\r\nt step \nwhen  neuroevoltuion algorithms started proliferating in the 90s.  =\r\n\nI think a lot of those early algorithms were motivated by people who \nsaw =\r\nthemselves as cutting backprop completely out of the loop.  You \nknow, if y=\r\nou look back at some of the papers on neuroevolution at \nthat time, some wo=\r\nuld evolve topology and combine it with backprop, \nand some would simply ev=\r\nolve everything (weights and topology, which \nare sometimes called TWEANNs =\r\nfor topology and weight evolving \nartificial neural networks).  Probably so=\r\nme of those people evolving \nTWEANNs saw themselves as taking the next step=\r\n you describe.  (Xin \nYao&#39;s 1999 review covers a lot of those methods from =\r\nthat time)\n\nThe difference is that no one did it with a population of one, =\r\nbut \nthat probably just did not occur to them because as soon as you go \nto=\r\n a non-gradient type of problem (like evolving topologies) \npopulations see=\r\nm natural at first thought.  Of course what you&#39;ve \nshown is that you can m=\r\nake it work at least in some cases without a \npopulation.  \n\nken\n\n\n"}}