{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"pP74ARomyrJMKZFGUg_ap0vDFp3Geee48RBgTUIIK2YaLczkAyf-M39VHKkD7M-igdE_VbJqYbFPEr01uVQAM7Bii9gbq3rDM2v_cQZaXsPv","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205797133","msgId":3892,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZybXZlZCtlbmRpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZybWRwNytxNmF2QGVHcm91cHMuY29tPg=="},"prevInTopic":3888,"nextInTopic":3893,"prevInTime":3891,"nextInTime":3893,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"Andy, maybe you can provide an example of non-linear inequality feasibility constraints that utterly destroy patterns and regularities? I think most people","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 52240 invoked from network); 17 Mar 2008 23:38:55 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m44.grp.scd.yahoo.com with QMQP; 17 Mar 2008 23:38:55 -0000\r\nX-Received: from unknown (HELO n50a.bullet.mail.sp1.yahoo.com) (66.163.168.144)\n  by mta17.grp.scd.yahoo.com with SMTP; 17 Mar 2008 23:38:55 -0000\r\nX-Received: from [216.252.122.218] by n50.bullet.mail.sp1.yahoo.com with NNFMP; 17 Mar 2008 23:38:55 -0000\r\nX-Received: from [66.218.69.6] by t3.bullet.sp1.yahoo.com with NNFMP; 17 Mar 2008 23:38:54 -0000\r\nX-Received: from [66.218.66.81] by t6.bullet.scd.yahoo.com with NNFMP; 17 Mar 2008 23:38:54 -0000\r\nDate: Mon, 17 Mar 2008 23:38:53 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frmved+endi@...&gt;\r\nIn-Reply-To: &lt;frmdp7+q6av@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=XIKYiTnK6Ge5zVlV16jhvibVH_3rECRpohcdYxN-hJk4xfN2Gvki\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nAndy, maybe you can provide an example of &quot;non-linear inequality \nfeasibili=\r\nty constraints&quot; that &quot;utterly destroy&quot; patterns and \nregularities? \n\nI thin=\r\nk most people would agree that many practical problems involve \nsome kind o=\r\nf pattern.  The human brain itself is filled with \nspectacular examples of =\r\nneural patterns, both spatially and \ntemporally.   Is the human brain &quot;utte=\r\nrly destroyed&quot; by &quot;non-linear \ninequality feasibility constraints?&quot;\n\nI get =\r\nyour broader point, though.  You&#39;re saying that I&#39;m getting a \ndistorted pe=\r\nrspective because I&#39;m conentrating on patterns when \nthere are other factor=\r\ns in the world than just patterns.  Yet we \ncannot expect every new algorit=\r\nhm to simultaneously address every \nchallenge faced by man.  Any researcher=\r\n who would try to do that \nwould never get anywhere.  With HyperNEAT we hav=\r\ne taken a step in a \npromising direction; no more, no less.  If you feel it=\r\n should be \nexpanded to take into account additional particular concerns th=\r\nat \nyou have (which for me are still fuzzy), I encourage you to extend \nit =\r\nin that direction.  \n\nI think your quote from Einstein is delivered in enti=\r\nrely the wrong \ncontext.  The problem of representation is largely ignored =\r\nby the \nmachine learning community because it *is* the difficult part.  \nTh=\r\ne &quot;thin part of the wood&quot; is the minutia of gradient optimization, \nwhich h=\r\nave been beaten to death; yet scientists to this day still \nfocus on it int=\r\nently.  The reason they do that is because it&#39;s the \neasy part, not the har=\r\nd part.  It is easy to climb a hill once you \nsee it; it is hard to move th=\r\ne hill itself.  Representation means \nmoving the hills.  I believe Einstein=\r\n would have no objection to \nrearranging the intellectual landscape.\n\nken\n\n=\r\n\n--- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@...&gt; wrote:\n&gt;\n&gt; Ken,\n&gt; \n&gt; I=\r\n can appreciate the need to choose applications &quot;with careful \n&gt; scrutiny w=\r\nith a sincere belief in their practical ramifications&quot;, \nbut \n&gt; the simple =\r\ntruth is that your bias for exploring &quot;patterns and \n&gt; regularities&quot;, are u=\r\ntterly destroyed by the application of non-\nlinear \n&gt; inequality feasibilit=\r\ny constraints. Which routinely happens in the \n&gt; domain of engineering opti=\r\nmization/search. \n&gt; \n&gt; Your operation without the application of the pressu=\r\nres associated \n&gt; with these pattern destroying influences results in a unr=\r\nealistic \n&gt; perspective on the utility of global pattern exploitation, and =\r\na \n&gt; failure to address the repercussions of the sometimes seemingly \n&gt; tot=\r\nally arbitrary nature of enforced feasibility constraints \ndictated \n&gt; by r=\r\neal-world problems.\n&gt; \n&gt; Until you can simultaneously address the exploitat=\r\nion of multiple \n&gt; hyperspace &quot;regional/sub-volume&quot; patterns/regularities o=\r\nverlaid \nwith \n&gt; multiple arbitrary non-linear inequality feasibility const=\r\nraints, \nin \n&gt; a computationally practical manner, methodologies such as \nH=\r\nyperneat \n&gt; will be dispatched as &quot;curiosities&quot; only.\n&gt; \n&gt; These kinds of p=\r\nressures are routinely addressed in the domain of \n&gt; engineering optimizati=\r\non/search. Your choice of side-stepping \nthese \n&gt; influences shapes what in=\r\nfrastructure is and is-not developed, as \nhas \n&gt; been adequately addressed =\r\nin prior posts.\n&gt; \n&gt; An applicable quote: &quot;I have little patience with scie=\r\nntists who \ntake \n&gt; a board of wood, look for its thinnest part, and drill =\r\na great \nnumber \n&gt; of holes where drilling is easy.&quot;--Albert Einstein\n&gt; \n&gt; =\r\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; A=\r\nndy, I have no problem with the idea of NEAT as a foundation \nupon\n&gt; &gt; whic=\r\nh to build.  That&#39;s perfectly aligned with my view that \nthere is\n&gt; &gt; more =\r\nyet to accomplish.  \n&gt; &gt; \n&gt; &gt; Let me respond to some of your specific point=\r\ns below.\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt;=\r\n &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; The issues you raise, though valid, appear disingenuous fo=\r\nr \ntwo \n&gt; &gt; &gt; reasons. First, if you had reviewed the contents and \ncapabil=\r\nities \n&gt; of \n&gt; &gt; &gt; the Dakota toolkit, you would have discovered the issues=\r\n as \nbeing \n&gt; &gt; &gt; essentially addressed. Second, not intending any disrespe=\r\nct, \nfrom \n&gt; &gt; &gt; external appearances, your efforts appear directed in othe=\r\nr \n&gt; &gt; &gt; directions than that of addressing your self admitted areas of \n&gt; =\r\n&gt; &gt; concern.\n&gt; &gt; &gt; \n&gt; &gt; &gt; From a review of literature on the subject, there=\r\n is a common \n&gt; &gt; &gt; understanding that EA is computationally expensive and =\r\nslow to \n&gt; &gt; &gt; converge, but robust for global search in problem domains wi=\r\nth \n&gt; &gt; &gt; multiple local minima.\n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; It really just depends who=\r\n you are talking about whether there \nis a\n&gt; &gt; &quot;common understanding&quot; about=\r\n anything in AI.  It also depends \n&gt; whether\n&gt; &gt; we are talking about the p=\r\nast or the future.  \n&gt; &gt; \n&gt; &gt; For example, it&#39;s often said that &quot;neural net=\r\nworks get caught on \n&gt; local\n&gt; &gt; optima&quot; (and there is indeed a &quot;common und=\r\nerstanding&quot; that they \ndo)\n&gt; &gt; but when people say that they are almost alw=\r\nays only talking \nabout\n&gt; &gt; backprop, which is just one single neural netwo=\r\nrk learning \n&gt; algorithm.\n&gt; &gt;  Backprop is not the only way a neural networ=\r\nk can learn.\n&gt; &gt; \n&gt; &gt; The problem is that when we talk about methods in mac=\r\nhine \nlearning \n&gt; we\n&gt; &gt; often confuse whether we are talking about a *fiel=\r\nd* or a \nparticular\n&gt; &gt; method.  In the case of EAs, you seem to be talking=\r\n about some\n&gt; &gt; existing methods that have been analyzed (often by people w=\r\nho \nare \n&gt; not\n&gt; &gt; even aware of the most modern approaches) in the past.  =\r\n For \n&gt; example,\n&gt; &gt; the old-fashioned bit-string based simple EA has been =\r\nanalyzed\n&gt; &gt; extensively.\n&gt; &gt; \n&gt; &gt; Yet as a field, EAs themselves are evolv=\r\ning.  Problems \nidentified in\n&gt; &gt; the past are actively being addressed in =\r\nthe present and future. \n&gt; Some\n&gt; &gt; modern approaches completely overturn t=\r\nhe assumptions and \nproblems \n&gt; of\n&gt; &gt; the past (and of course introduce th=\r\neir own new problems).  \nCheck \n&gt; out\n&gt; &gt; Estimation of Distribution Algori=\r\nthms and the CMA-ES:\n&gt; &gt; \n&gt; &gt; http://en.wikipedia.org/wiki/Estimation_of_di=\r\nstribution_algorithm\n&gt; &gt; http://en.wikipedia.org/wiki/CMA-ES\n&gt; &gt; \n&gt; &gt; When =\r\nI look at EAs, or any research area for that matter, I \nalways\n&gt; &gt; think ab=\r\nout what they *could* be, rather than what they are.  \nAnd \n&gt; as a\n&gt; &gt; rese=\r\narcher, I try to make them what they could be.  To me, that \nis \n&gt; the\n&gt; &gt; =\r\nexciting thing about research: At its best, it overturns dogma.  \nI\n&gt; &gt; lik=\r\ne to view a limitation as a challenge rather than as a brick \n&gt; wall.\n&gt; &gt; \n=\r\n&gt; &gt; &gt; And that is from people who are working &quot;hard&quot; problems (i.e. \n&gt; mult=\r\ni-\n&gt; &gt; &gt; discipline, multiobjective, non-linear inequality constraints, \n&gt; =\r\netc.), \n&gt; &gt; &gt; at government laboratories and Fortune 100 defense firms. Not=\r\n \n&gt; dancing \n&gt; &gt; &gt; rag-dolls and computer-aided art.\n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; First,=\r\n while you often cite multiobjective optimization as \na &quot;hard\n&gt; &gt; problem&quot; =\r\nfor EAs, in fact some of the most effective algorithms \nin\n&gt; &gt; multiobjecti=\r\nve optimization are EAs.  EAs are naturally suited to\n&gt; &gt; maintaining a par=\r\neto front because a pareto front requires a\n&gt; &gt; population to hold it.  The=\r\nre is vast literature on pareto\n&gt; &gt; optimization in EAs, both in multiobjec=\r\ntive optimization and in\n&gt; &gt; coevolution.  Here are some seminal examples:\n=\r\n&gt; &gt; \n&gt; &gt; K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A Fast and \nEliti=\r\nst\n&gt; &gt; Multiobjective Genetic Algorithm: NSGA-II. IEEE Transactions on\n&gt; &gt; =\r\nEvolutionary Computation, 6(2):182=96197, 2002.\n&gt; &gt; http://citeseer.ist.psu=\r\n.edu/530140.html\n&gt; &gt; \n&gt; &gt; De Jong, E.D. (2004). The Incremental Pareto-Coev=\r\nolution Archive.\n&gt; &gt; Proceedings of the Genetic and Evolutionary Computatio=\r\nn \nConference\n&gt; &gt; GECCO-04, pp. 525-536. \n&gt; &gt; http://people.cs.uu.nl/dejong=\r\n/publications/gecco04coev.pdf\n&gt; &gt; \n&gt; &gt; in fact, some of the most brilliant =\r\ntheorists in pareto \noptimization\n&gt; &gt; are in evolutionary computation.\n&gt; &gt; =\r\n\n&gt; &gt; As for NEAT in government research labs on &quot;serious&quot; problems, \nhere \n=\r\n&gt; is\n&gt; &gt; an example:\n&gt; &gt; \n&gt; &gt; Shimon Whiteson and Daniel Whiteson (2007). &quot;=\r\nStochastic \nOptimization\n&gt; &gt; for Collision Selection in High Energy Physics=\r\n&quot;. IAAI 2007:\n&gt; &gt; Proceedings of the Nineteenth Annual Innovative Applicati=\r\nons of\n&gt; &gt; Artificial Intelligence Conference.&#8202;\n&gt; &gt; http://arxiv.org/=\r\nPS_cache/hep-ex/pdf/0607/0607012v1.pdf\n&gt; &gt; \n&gt; &gt; The article itself states, =\r\n&quot;These NEAT selectors are currently \nin \n&gt; use\n&gt; &gt; at FermiLab for selectin=\r\ng collisions from real data collected\n&gt; &gt; with the Tevatron collider.&quot;  So,=\r\n there you go, NEAT is being \nused \n&gt; at\n&gt; &gt; FermiLab itself to select whic=\r\nh particle collisions are most \n&gt; promising.\n&gt; &gt; \n&gt; &gt; When you mention rag =\r\ndolls and art, you&#39;re giving me an \nopportunity \n&gt; to\n&gt; &gt; comment on some o=\r\nf our own current research.  Our group has \nindeed\n&gt; &gt; recently produced a =\r\nnumber of works in interactive evolution,\n&gt; &gt; including dance, art, music, =\r\nand particle effects.  Perhaps it \nmay\n&gt; &gt; seem a somewhat lighthearted dep=\r\narture from more serious \nsubjects.\n&gt; &gt; \n&gt; &gt; Yet the implications of this w=\r\nork are as serious as any in my \nview. \n&gt; &gt; All of that work is a probe of =\r\nthe ubiquity of patterns and\n&gt; &gt; regularities, in particular through the th=\r\neory of CPPNs.  The \ndeeper\n&gt; &gt; lesson in that body of work is that the ver=\r\ny same encoding is \nable \n&gt; to\n&gt; &gt; produce patterns appropriate to what wou=\r\nld otherwise appear to be\n&gt; &gt; disparate domains.  The idea is to develop a =\r\ntheory of generic \n&gt; pattern\n&gt; &gt; generation and to show that patterns are i=\r\nnterchangeable across \nmany\n&gt; &gt; domains.  That insight leads to the idea of=\r\n HyperNEAT, which \ntakes\n&gt; &gt; again the very same encoding that is producing=\r\n art and music and \n&gt; uses\n&gt; &gt; it to produce a large-scale neural pattern. =\r\n Therein it becomes\n&gt; &gt; serious, because the hard problems you like to focu=\r\ns on almost \n&gt; always\n&gt; &gt; involve patterns and regularities.  \n&gt; &gt; \n&gt; &gt; It =\r\nis no accident that in building a theory of pattern \ngeneration, a\n&gt; &gt; numb=\r\ner of interactive evolutionary computation experiments would \n&gt; need\n&gt; &gt; to=\r\n be performed because understanding the capabilities of a \npattern\n&gt; &gt; gene=\r\nrator require *exploring* the space of possibilities rather \nthan\n&gt; &gt; simpl=\r\ny optimizing, and humans are much better explorers than\n&gt; &gt; computers.  The=\r\n theory would never have gotten off the ground if \nwe\n&gt; &gt; had stuck to more=\r\n traditional optimization problems.   Indeed, as\n&gt; &gt; funny as it sounds, th=\r\ne whole idea began to materialize only \nafter I\n&gt; &gt; evolved a spaceship in =\r\nMattias Fagerlund&#39;s DelphiNEAT.  \n&gt; &gt; \n&gt; &gt; To put it starkly, without that =\r\nexploration in genetic art, there\n&gt; &gt; would have been no HyperNEAT.  And in=\r\n fact even more new \ntheories \n&gt; with\n&gt; &gt; practical implications are coming=\r\n (not yet published) because of\n&gt; &gt; phenomena that became apparent through =\r\nPicbreeder.  So you see, \nin\n&gt; &gt; building a new algorithm or a new theory w=\r\nith practical \n&gt; implications,\n&gt; &gt; often traditional problems are exactly t=\r\nhe wrong vehicle to \n&gt; discovery\n&gt; &gt; because they perpetuate the same dogma=\r\ntic perspectives that \nalready\n&gt; &gt; permeate the field to begin with and cau=\r\nse it to be staying in \none\n&gt; &gt; place.   Thus all of these applications are=\r\n chosen with careful\n&gt; &gt; scrutiny with a sincere belief in their practical =\r\nramifications.\n&gt; &gt; \n&gt; &gt; Not to mention the fact that interactive evolution =\r\nitself has the\n&gt; &gt; practical potential to change the way we do engineering =\r\nin some \n&gt; cases.\n&gt; &gt;  Can you imagine Picbreeder for furinute instead of p=\r\nictures?  \nOr \n&gt; for\n&gt; &gt; cars?  Someday that may be how we create highly cu=\r\nstomized \n&gt; artifacts.\n&gt; &gt;    In fact, some of the problems to which you ar=\r\ne referring \n(highly\n&gt; &gt; nonlinear and multi-objective) may only be possibl=\r\ne to solve \nthrough\n&gt; &gt; interactive evolution.\n&gt; &gt; \n&gt; &gt; &gt; How many times ha=\r\ns NEAT, as a monolithic approach, been cited \nand \n&gt; &gt; &gt; successfully appli=\r\ned by government laboratories and Fortune \n100 \n&gt; &gt; &gt; defense firms for the=\r\nse type of &quot;hard&quot; problems?\n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; You can refer to the paper on h=\r\nigh-energy physics at FermiLab if\n&gt; &gt; you&#39;re interested, but I still think =\r\nthere is a bigger picture.  \n&gt; &gt; \n&gt; &gt; In some ways, as researchers in AI, w=\r\nhat practitioners are using \nto\n&gt; &gt; solve hard problems is exactly what we =\r\n*don&#39;t* want to use.  \nAfter\n&gt; &gt; all, how is anything ever going to become =\r\nmore powerful if we \njust\n&gt; &gt; look to practitioners to show us what methods=\r\n we should be \nusing?  \n&gt; As\n&gt; &gt; researchers, it is our job to give the pra=\r\nctitioners *new* \noptions,\n&gt; &gt; not the other way around.\n&gt; &gt; \n&gt; &gt; Practitio=\r\nners are often several steps behind algorithm \ndevelopers, \n&gt; and\n&gt; &gt; with =\r\ngood reason.  They often can&#39;t afford to take big risks and \n&gt; need\n&gt; &gt; som=\r\nething practical in the here and now.   You will therefore \nfind\n&gt; &gt; that m=\r\nost cutting-edge algorithms are not in use in industry or \nas\n&gt; &gt; tools in =\r\nother scientific disciplines at the very moment that \nthey \n&gt; are\n&gt; &gt; cutti=\r\nng-edge.  Yet someone has to be developing the algorithms \nof \n&gt; the\n&gt; &gt; fu=\r\nture.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt;\n&gt;\n\n\n\n"}}