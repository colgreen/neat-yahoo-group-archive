{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"WsTkRRfeD_pUATPttssIqur-PV3tVfooIuwg2TwuEygc9AJ4y88-8yRf9rSiOM-dg1Bx6a8CMvrYXw5svcc70M0","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: ANJI : NEAT implementation (fingerprint implementation issues)","postDate":"1181852472","msgId":3405,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY0czd2bytrMWE5QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGY0czdpOCtoYmsyQGVHcm91cHMuY29tPg=="},"prevInTopic":3404,"nextInTopic":3406,"prevInTime":3404,"nextInTime":3406,"topicId":3384,"numMessagesInTopic":37,"msgSnippet":" wrote:  The way to realize rotation is probably distinct inputs/outputs ... I think this is a major issue about HyperNEAT and","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 68854 invoked from network); 14 Jun 2007 20:23:29 -0000\r\nReceived: from unknown (66.218.66.71)\n  by m46.grp.scd.yahoo.com with QMQP; 14 Jun 2007 20:23:29 -0000\r\nReceived: from unknown (HELO n31.bullet.scd.yahoo.com) (66.94.237.25)\n  by mta13.grp.scd.yahoo.com with SMTP; 14 Jun 2007 20:23:29 -0000\r\nReceived: from [209.73.164.86] by n31.bullet.scd.yahoo.com with NNFMP; 14 Jun 2007 20:21:13 -0000\r\nReceived: from [66.218.66.79] by t8.bullet.scd.yahoo.com with NNFMP; 14 Jun 2007 20:21:13 -0000\r\nDate: Thu, 14 Jun 2007 20:21:12 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f4s7vo+k1a9@...&gt;\r\nIn-Reply-To: &lt;f4s7i8+hbk2@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: ANJI : NEAT implementation (fingerprint implementation issues)\r\nX-Yahoo-Group-Post: member; u=281645563; y=J7RLBEEkL5zXQtDZF4ynxf5aYjlJQHqwq7uQXZfRaRzhAA\r\nX-Yahoo-Profile: afcarl2\r\n\r\n&lt;petar_chervenski@...&gt; wrote:\n&quot;&gt; The way to realize rotation is probably di=\r\nstinct \ninputs/outputs&quot;...&quot;&gt; I think this is a major issue about HyperNEAT =\r\n\nand CPPNs.&quot;\n\nYes, ditto.\n\nAndy Carl\n\n\n--- In neat@yahoogroups.com, &quot;petar_=\r\nchervenski&quot; \n&lt;petar_chervenski@...&gt; wrote:\n&gt;\n&gt; This is not rotation, but a =\r\nmirror image. This would not preserve, \n&gt; say a triangle in the input space=\r\n will be very deformed as a \nresult. \n&gt; The way to realize rotation is prob=\r\nably distinct inputs/outputs, as \n&gt; Ken said. \n&gt; \n&gt; A possible implementati=\r\non for this is to divide the incoming \n&gt; connections by 2 in two separate p=\r\narts every time, and the outgoing \n&gt; also. \n&gt; \n&gt; Let&#39;s think only for space=\r\ns now, please. The 2D space is rotated \ninto \n&gt; another 2D space. One linea=\r\nr space into another linear space. We \nneed \n&gt; a neuron that takes 2 and re=\r\nturns 2. Anyone has an idea about it? \n&gt; \n&gt; In fact it is incorrect to say =\r\n&quot;activation functions&quot;, it is \ncorrect \n&gt; to say &quot;space warping functions&quot;.=\r\n.. \n&gt; \n&gt; There is a way to combine the equation so the neuron would output =\r\n\n&gt; (x+y) instead of (x) and (y), but this has no sense. \n&gt; \n&gt; I think this =\r\nis a major issue about HyperNEAT and CPPNs. \n&gt; \n&gt; Peter\n&gt; \n&gt; \n&gt; \n&gt; --- In n=\r\neat@yahoogroups.com, &quot;Jason G&quot; &lt;jgmath2000@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Maybe if we tho=\r\nught of a rotation as two reflections it would \nmake \n&gt; it easier\n&gt; &gt; to cr=\r\neate such a thing with HyperNEAT?\n&gt; &gt; \n&gt; &gt; A reflection can be constructed =\r\nif we used a negation activation \n&gt; function.\n&gt; &gt; Then again, this is the s=\r\name as having no activation function and \na \n&gt; negative\n&gt; &gt; weight.   Of co=\r\nurse, it&#39;s easier to have a sum-negation \nactivation \n&gt; function\n&gt; &gt; than t=\r\no enforce that every outgoing weight is negative, and \nthat&#39;s \n&gt; assuming\n&gt;=\r\n &gt; you have a direct summation activation function\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; On 6/14/07=\r\n, petar_chervenski &lt;petar_chervenski@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt;   Hello, Jan-Jaap=\r\n,\n&gt; &gt; &gt;\n&gt; &gt; &gt; It is good to see that you are experimenting with NEAT, but \n=\r\nthis \n&gt; is\n&gt; &gt; &gt; an CPPN/HyperNEAT issue we are discussing right now.\n&gt; &gt; &gt;=\r\n Your suggestion is interesting, but a roving eye cannot be used \n&gt; in a\n&gt; =\r\n&gt; &gt; CPPN.\n&gt; &gt; &gt; The problem about it is that the basic coordinate frames th=\r\nat \nare\n&gt; &gt; &gt; passed in the CPPN must be static all the time. If they are \n=\r\nnot, \n&gt; then\n&gt; &gt; &gt; evolution would break down. I mean, the space itself tha=\r\nt we \nbuild\n&gt; &gt; &gt; our phenotypes in should not bend, twist or move in any w=\r\nay.\n&gt; &gt; &gt; A roving eye can be used with the HyperNEAT neural substrate, \nbu=\r\nt \n&gt; my\n&gt; &gt; &gt; first experiments showed that this is hard for the evolution =\r\nto\n&gt; &gt; &gt; master.\n&gt; &gt; &gt;\n&gt; &gt; &gt; HyperNEAT allows very large input/output space=\r\ns and recognition \nof\n&gt; &gt; &gt; whole images, without roving eyes and so on.\n&gt; =\r\n&gt; &gt; Are you familiar with the concept of CPPNs and HyperNEAT?\n&gt; &gt; &gt; Check o=\r\nut this excellent paper on the concept of CPPNs:\n&gt; &gt; &gt; http://eplex.cs.ucf.=\r\nedu/papers/stanley_gpem07.pdf\n&gt; &gt; &gt; And also this one, on HyperNEAT:\n&gt; &gt; &gt; =\r\nhttp://eplex.cs.ucf.edu/papers/gauci_gecco07.pdf\n&gt; &gt; &gt;\n&gt; &gt; &gt; P.S. Derek Jam=\r\nes has a paper about his experiments with a \nroving \n&gt; eye\n&gt; &gt; &gt; visual dis=\r\ncrimination system in ANJI that includes rotatitng \n&gt; roving\n&gt; &gt; &gt; eye, too=\r\n. It is interesting that the system has better \nperformance\n&gt; &gt; &gt; without r=\r\notation.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Peter\n&gt; &gt; &gt;\n&gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40=\r\nyahoogroups.com&gt;, &quot;Jan-Jaap \n&gt; van de\n&gt; &gt; &gt; Velde&quot;\n&gt; &gt; &gt; &lt;janjaap.vandeveld=\r\ne@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hello,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I&#39;ve been reading this em=\r\nailgroup for a couple of weeks now \nwith\n&gt; &gt; &gt; great\n&gt; &gt; &gt; &gt; interest and s=\r\ntarted experimenting with Neat also.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; As I see your problem =\r\nit shouldn&#39;t be needed to evolve \nrotation \n&gt; in\n&gt; &gt; &gt; your\n&gt; &gt; &gt; &gt; network=\r\n.\n&gt; &gt; &gt; &gt; Concider a woman rotating a map to be able to read it. You \n&gt; cou=\r\nld do\n&gt; &gt; &gt; the same\n&gt; &gt; &gt; &gt; with a &#39;roving eye&#39; and present the data in ev=\r\nery angle or \nmaybe\n&gt; &gt; &gt; just a\n&gt; &gt; &gt; &gt; couple of orientations.\n&gt; &gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; &gt; Maybe this could give some better results.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I&#39;m lookin=\r\ng forward to reading you&#39;re results. I&#39;m still \n&gt; learning\n&gt; &gt; &gt; to program=\r\n\n&gt; &gt; &gt; &gt; in Java and C++ in the process, so my own experiments are \nstill\n&gt;=\r\n &gt; &gt; waiting to\n&gt; &gt; &gt; &gt; get started.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; greetz,\n&gt; &gt; &gt; &gt; Jan-Ja=\r\nap\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; from the Netherlands\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; On 6/13/07, Kenneth=\r\n Stanley &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Hi Peter,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt; I agree with your statement of the problem. In a way, \n&gt; translation\n&gt; &gt;=\r\n &gt; &gt; &gt; and scaling are both natural, but rotation is particularly\n&gt; &gt; &gt; dif=\r\nficult\n&gt; &gt; &gt; &gt; &gt; to evolve. If it did evolve, it would take significant \nef=\r\nfort \n&gt; for\n&gt; &gt; &gt; &gt; &gt; HyperNEAT to discover the concept of rotation.\n&gt; &gt; &gt; =\r\n&gt; &gt;\n&gt; &gt; &gt; &gt; &gt; That suggests that perhaps there is a way to make rotation a\n=\r\n&gt; &gt; &gt; &gt; &gt; canonical activation function instead of something that \nneeds \n&gt;=\r\n to\n&gt; &gt; &gt; be\n&gt; &gt; &gt; &gt; &gt; composed from several parts. However, like you say, =\r\nit&#39;s \nhard \n&gt; to\n&gt; &gt; &gt; &gt; &gt; imagine how a single (traditional) neuron could =\r\nimplement a\n&gt; &gt; &gt; rotation\n&gt; &gt; &gt; &gt; &gt; function that requires multiple variab=\r\nles.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; One idea is to create a new kind of neuron that ac=\r\ntually has\n&gt; &gt; &gt; &gt; &gt; distinct input entrances. That way, it is possible to =\r\nhave \n&gt; an &quot;x&quot;\n&gt; &gt; &gt; &gt; &gt; and a &quot;y&quot; entrance to the rotation node. Each entr=\r\nance could\n&gt; &gt; &gt; itself\n&gt; &gt; &gt; &gt; &gt; be a summation of activation coming from =\r\nelsewhere, just \nlike \n&gt; a\n&gt; &gt; &gt; &gt; &gt; regaular node input.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt; Another issue is the alpha argument. I need to think about \n&gt; that a\n&gt; &gt;=\r\n &gt; &gt; &gt; little more because we do not want to explicitly enter an \n&gt; alpha.\n=\r\n&gt; &gt; &gt; &gt; &gt; Yet then what is the rotation operating on?\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; k=\r\nen\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yahoogroups.com&gt;=\r\n &lt;neat%\n&gt; &gt; &gt; 40yahoogroups.com&gt;, &quot;petar_chervenski&quot;\n&gt; &gt; &gt; &gt; &gt; &lt;petar_cherv=\r\nenski@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; I ma=\r\nde the eye static as you suggested in one previous\n&gt; &gt; &gt; disscussion\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; about this experiment, using HyperNEAT for visual \n&gt; recognition.\n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; (Roving eye & HyperNEAT is an overkill). It is &quot;alive&quot; for\n&gt; &gt; &gt; a=\r\nbout 5\n&gt; &gt; &gt; &gt; &gt; &gt; timesteps, in order to use some reccurence.\n&gt; &gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; I think about the rotation.. So, let&#39;s clear things out.\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; A point (X,Y) is rotated with angle (Aplha) to (X1, Y1).\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\nThis is a function, taking 3 arguments and returning 2.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; x1=3D y*sin(alpha) + x*cos(alpha)\n&gt; &gt; &gt; &gt; &gt; &gt; y1=3D y*cos(alpha) - x*s=\r\nin(alpha)\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; I think this cannot be covered by a singl=\r\ne neuron, but a \n&gt; cluster\n&gt; &gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; neurons with sin() and =\r\ncos() activation functions.. Am I \n&gt; right?\n&gt; &gt; &gt; &gt; &gt; &gt; Let&#39;s say that we h=\r\nave 2 inputs (x, y) and a bias node in \n&gt; the\n&gt; &gt; &gt; &gt; &gt; CPPN.\n&gt; &gt; &gt; &gt; &gt; &gt; F=\r\nurther, we have 2 hidden nodes, one is &quot;sine&quot; other\n&gt; &gt; &gt; is &quot;cosine&quot;.\n&gt; &gt; =\r\n&gt; &gt; &gt; &gt; These hidden nodes are both connected to the bias. The \nbias \n&gt; her=\r\ne\n&gt; &gt; &gt; &gt; &gt; is\n&gt; &gt; &gt; &gt; &gt; &gt; our &quot;alpha&quot; value.\n&gt; &gt; &gt; &gt; &gt; &gt; Then, we can imag=\r\nine how these nodes should be connected \nto\n&gt; &gt; &gt; &gt; &gt; construct\n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n this formula above. We need linear outputs, and maybe some\n&gt; &gt; &gt; &gt; &gt; addit=\r\nional\n&gt; &gt; &gt; &gt; &gt; &gt; linear nodes with multiplying summing functions (to \n&gt; re=\r\npresent\n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; &gt; multiplications by x and y)...\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; Similar, translation can be handled even easier. The main\n&gt; &gt; &gt; &gt;=\r\n &gt; coordinate\n&gt; &gt; &gt; &gt; &gt; &gt; frames has to be connected to 2 linear nodes, whe=\r\nre an \n&gt; addition\n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; a\n&gt; &gt; &gt; &gt; &gt; &gt; bias occurs in each.\n&gt; &gt;=\r\n &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Scaling is in fact everywhere, since the weights of th=\r\ne\n&gt; &gt; &gt; &gt; &gt; connections\n&gt; &gt; &gt; &gt; &gt; &gt; can be thought of as scalars of the coo=\r\nrdinate frames.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; So, that were the 3 main transforma=\r\ntions.. :)\n&gt; &gt; &gt; &gt; &gt; &gt; But the rotation seems hard to evolve.. And using li=\r\nnear \n&gt; nodes\n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; &gt; &gt; multiplying summing functions (before t=\r\nhe activation) is\n&gt; &gt; &gt; important.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Peter\n&gt; &gt; &gt; &gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yahoogroups.com&gt;&lt;neat%\n&gt; =\r\n40yahoogroups.com&gt;, &quot;Kenneth\n&gt; &gt; &gt; Stanley&quot;\n&gt; &gt; &gt; &gt; &gt; &lt;kstanley@&gt; wrote:\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%\n40yahoogroups.=\r\ncom&gt;&lt;neat%\n&gt; 40yahoogroups.com&gt;,\n&gt; &gt; &gt; &gt; &gt; &quot;petar_chervenski&quot;\n&gt; &gt; &gt; &gt; &gt; &lt;pe=\r\ntar_chervenski@&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; - My current experime=\r\nnts with ActiveVision show that \nit \n&gt; is\n&gt; &gt; &gt; &gt; &gt; hard\n&gt; &gt; &gt; &gt; &gt; &gt; to\n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; evolve substrates that recognize simple shapes that \nare\n&gt; &gt; &gt;=\r\n &gt; &gt; randomly\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; rotated. Perhaps I should tweak the NEAT para=\r\nmeters \nor \n&gt; the\n&gt; &gt; &gt; set\n&gt; &gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; activation functio=\r\nns?\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Peter, in the experiment yo=\r\nu are describing, are you \n&gt; using a\n&gt; &gt; &gt; &gt; &gt; roving\n&gt; &gt; &gt; &gt; &gt; &gt; eye\n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; or just inputting a whole image into the substrate? With\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; HyperNEAT, it\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; should be possible to do recognition tasks w=\r\nithout \n&gt; needing a\n&gt; &gt; &gt; &gt; &gt; roving\n&gt; &gt; &gt; &gt; &gt; &gt; eye.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; In any case, I believe rotational invariance is indeed \nan\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; activation\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; function issue. The problem is that you need to=\r\n get the \n&gt; same\n&gt; &gt; &gt; &gt; &gt; &gt; pattern\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; of connects repeated in =\r\na rotating fashion, so that \nthey \n&gt; can\n&gt; &gt; &gt; &gt; &gt; &gt; recognize\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; rotated images. This kind of rotation is not a very \n&gt; natural\n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; byproduct\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; of the usual set of activation functions. I belie=\r\nve \nthere \n&gt; is\n&gt; &gt; &gt; &gt; &gt; &gt; probably\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; a rotational activation =\r\nfunction that would be quite \n&gt; helpful,\n&gt; &gt; &gt; &gt; &gt; but I\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; have=\r\n not resolved what function that should be.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; ken=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; =\r\n&gt;  \n&gt; &gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; -- \n&gt; &gt; Jason G\n&gt; &gt;\n&gt;\n\n\n\n"}}