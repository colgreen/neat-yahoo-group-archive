{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":82117382,"authorName":"Jim O&#39;Flaherty","from":"Jim O&#39;Flaherty &lt;jim_oflaherty_jr@...&gt;","profile":"jim_oflaherty_jr","replyTo":"LIST","senderId":"yYSFrCgnwSThtDeScdMH85jUGFF1vToLjiPNpE6kOqqqnUrG6Ud43kVwV0HdaeGqPUg2hPwTU5gxAlawaG91gdM2oEzhaMRhzgAsZlWLcCs2pA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: rtNEAT: max_depth() in an endless loop","postDate":"1225740628","msgId":4410,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5MEY1MTU0LjQwODA4MDhAeWFob28uY29tPg==","inReplyToHeader":"PDEyODBjZjZhMDgxMTAzMTExNnUxOGEwYzdmYnZmZDVkZGM5ZDZmMzY4NDFAbWFpbC5nbWFpbC5jb20+","referencesHeader":"PGdlbmI1ZitxZ3BzQGVHcm91cHMuY29tPiA8NDkwRjRCODIuNjAzMDgwNkB5YWhvby5jb20+IDwxMjgwY2Y2YTA4MTEwMzExMTZ1MThhMGM3ZmJ2ZmQ1ZGRjOWQ2ZjM2ODQxQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4409,"nextInTopic":4411,"prevInTime":4409,"nextInTime":4411,"topicId":4396,"numMessagesInTopic":16,"msgSnippet":"Thomas, Were you addressing my response? Or are you referring to the original poster s endless loop implementation? My implementation has no notion of depth.","rawEmail":"Return-Path: &lt;jim_oflaherty_jr@...&gt;\r\nX-Sender: jim_oflaherty_jr@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 89558 invoked from network); 3 Nov 2008 19:30:32 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m44.grp.scd.yahoo.com with QMQP; 3 Nov 2008 19:30:32 -0000\r\nX-Received: from unknown (HELO smtp107.prem.mail.sp1.yahoo.com) (98.136.44.62)\n  by mta17.grp.scd.yahoo.com with SMTP; 3 Nov 2008 19:30:32 -0000\r\nX-Received: (qmail 98109 invoked from network); 3 Nov 2008 19:30:32 -0000\r\nX-Received: from unknown (HELO ?192.168.1.2?) (jim_oflaherty_jr@24.175.76.77 with plain)\n  by smtp107.prem.mail.sp1.yahoo.com with SMTP; 3 Nov 2008 19:30:31 -0000\r\nX-YMail-OSG: kPaSl2kVM1nCpuD0hEZ6.wg7phLL3RrAoISihm4H2YPZ4uEHgOD67RKkWb7lwM.KsyJFq7f0SMpBMMZK2z1GwXc2nVn9ldNC1t_LY2lzBOQ6bd4l2c7JUrMFes3momuhrmQj8Sf8tPyNZrEEdgYtEbFMZrtKmnuEfp8h85vzicyMSWZXVxgL_fADuaFA5L2o4MtkXNh__Iet1KQFaheNmUirm25cgaYpaW_WQiJJi7ozySFSTxcQE_I3Xf7oBssUPplgOZzliB36qzK7lVMEBrIjRaJcKHjQ_cRrTQ--\r\nX-Yahoo-Newman-Property: ymail-3\r\nMessage-ID: &lt;490F5154.4080808@...&gt;\r\nDate: Mon, 03 Nov 2008 13:30:28 -0600\r\nUser-Agent: Thunderbird 2.0.0.17 (Windows/20080914)\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;genb5f+qgps@...&gt; &lt;490F4B82.6030806@...&gt; &lt;1280cf6a0811031116u18a0c7fbvfd5ddc9d6f36841@...&gt;\r\nIn-Reply-To: &lt;1280cf6a0811031116u18a0c7fbvfd5ddc9d6f36841@...&gt;\r\nContent-Type: multipart/alternative;\n boundary=&quot;------------050501060709010502040006&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jim O&#39;Flaherty &lt;jim_oflaherty_jr@...&gt;\r\nSubject: Re: [neat] Re: rtNEAT: max_depth() in an endless loop\r\nX-Yahoo-Group-Post: member; u=82117382; y=3i2Fo-G7ClRgfnZRh4v2LTnSdXXbnYBA--YVJ5NTjvEqj3qGjFp1z0LphA\r\nX-Yahoo-Profile: jim_oflaherty_jr\r\n\r\n\r\n--------------050501060709010502040006\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\n\r\nThomas,\n\nWere you addressing my response? Or are you referring to the original \nposter&#39;s endless loop implementation?\n\nMy implementation has no notion of depth. It flattens the ANN into a \nsingle array of nodes each activated once and only once from left to \nright (where left to right is defined by node dependency and then by \nage). So, if there are 12 nodes, regardless of recurrent connections, \nthere is exactly 12 node activation recalculations. When a node is \nrecalculated, it grabs the list of nodes upon which it depends (which \ncan include itself and nodes yet to be recalculated during this pass), \nrecalculates its value and stores it. There is exactly 12 store \noperations in a single activation pass. A node activation is never \nre-calculated during the same activation pass. The only way I can see a \nloop forming is if a node activation is recalculated during the same \nactivation pass. And if that is happening, I would like to understand \nhow it is being done, and why. What benefits are being derived from that \nactivation strategy?\n\n\nJim\n\n\nThomas Johnson wrote:\n&gt;\n&gt; It&#39;s not clear to me that it&#39;s desirable to calculate the number of\n&gt; times to activate by using the depth, regardless of how you handle\n&gt; loops. This method works fine on non-recurrent networks, but once you\n&gt; have a network that has loops, consider how hard it is for a network\n&gt; to evolve to, for instance, have a cycle activate twice. The network\n&gt; would have to significantly in increase its longest path length\n&gt; (assuming that&#39;s how we calculate how many times to activate) so that\n&gt; the cycle would be activated twice. When you add in the wall-clock\n&gt; time it takes to calculate the longest path length for each network,\n&gt; maybe it&#39;s better to just activate a pre-specified (albeit reasonably\n&gt; large) number of times.\n&gt;\n&gt; Tom\n&gt;\n&gt; On Mon, Nov 3, 2008 at 2:05 PM, Jim O&#39;Flaherty\n&gt; &lt;jim_oflaherty_jr@... &lt;mailto:jim_oflaherty_jr%40yahoo.com&gt;&gt; wrote:\n&gt; &gt; Peter,\n&gt; &gt;\n&gt; &gt; That doesn&#39;t make sense to me. Cesar&#39;s comments indicate he has a \n&gt; similar\n&gt; &gt; implementation to mine. Basically, every node&#39;s value in a single \n&gt; instance\n&gt; &gt; of an ANN is calculated just once on an activation pass. When the \n&gt; node is\n&gt; &gt; calculated, each of the nodes attached to it as &quot;input&quot; are used \n&gt; (whether\n&gt; &gt; they have been activated in this pass, or hold a residual value from the\n&gt; &gt; previous pass) to calculate it&#39;s current value. And assuming the \n&gt; ordering of\n&gt; &gt; the activations is lined up by dependency and they by node age, the \n&gt; network\n&gt; &gt; ought to activate deterministically meaning that starting with an empty\n&gt; &gt; network (all node activation values are set to 0.0), providing the same\n&gt; &gt; input and making several activation passes ought to be able to return\n&gt; &gt; reliably repeatable results given the node activation values are \n&gt; reset to\n&gt; &gt; 0.0 and precisely the same input is submitted for the same number of\n&gt; &gt; activation passes.\n&gt; &gt;\n&gt; &gt; I get that the network graph can have cycles, as in recurrent \n&gt; connections.\n&gt; &gt; However, those have no relevance to activation order or cause any \n&gt; sort of\n&gt; &gt; &quot;loop&quot; in a straightforward ANN implementation. So, I am getting \n&gt; confused\n&gt; &gt; about where and how an &quot;endless loop&quot; could form. Perhaps they are \n&gt; talking\n&gt; &gt; about the network output never stabilizing to within some stable value\n&gt; &gt; ranges when activating it repeatedly with the same input. That&#39;s to be\n&gt; &gt; expected in a network with enough recurrent connections - \n&gt; non-uniformity in\n&gt; &gt; the output following activations with the same input. Each additional\n&gt; &gt; recurrent connection increases the &quot;echos from the past&quot; causing a \n&gt; stable\n&gt; &gt; output cycle to become less and less probable.\n&gt; &gt;\n&gt; &gt; Said another way, a single activation of an ANN, with or without \n&gt; recurrent\n&gt; &gt; connections, will results in exactly the same number of node activation\n&gt; &gt; calculations each time it is told to process input. There should not \n&gt; be any\n&gt; &gt; variability to the number of node activations AT ALL. If so, then \n&gt; some sort\n&gt; &gt; of different activation strategy is being employed. And if so, what \n&gt; is it?\n&gt; &gt; And why?\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Jim\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; petar_chervenski wrote:\n&gt; &gt;\n&gt; &gt; It is about the loop in which you calculate the longest path from an\n&gt; &gt; input node to an output node. Not the activation loop in which you\n&gt; &gt; activate the network.\n&gt; &gt;\n&gt; &gt; Peter\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.com&gt;, Jim \n&gt; O&#39;Flaherty &lt;jim_oflaherty_jr@...&gt;\n&gt; &gt; wrote:\n&gt; &gt;&gt;\n&gt; &gt;&gt; Ken,\n&gt; &gt;&gt;\n&gt; &gt;&gt; I am confused how you could end up in an endless activation loop. If\n&gt; &gt; you\n&gt; &gt;&gt; are moving from the input nodes forward through the hidden nodes to\n&gt; &gt; the\n&gt; &gt;&gt; output nodes as a state calculation progression, there would be no\n&gt; &gt; need\n&gt; &gt;&gt; to worry about activation loops - you would only calculate the value\n&gt; &gt; of\n&gt; &gt;&gt; each node once in a single pass. The point of a recurrent connection\n&gt; &gt; is\n&gt; &gt;&gt; to carry state between full network activations. So, the value\n&gt; &gt; provided\n&gt; &gt;&gt; by a recurrent connection would not be used until the next\n&gt; &gt; activation\n&gt; &gt;&gt; pass (assuming all the nodes from the previous pass have not be\n&gt; &gt; &quot;zeroed\n&gt; &gt;&gt; out&quot;).\n&gt; &gt;&gt;\n&gt; &gt;&gt; How is it there is an endless loop?\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt; Jim\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt; Kenneth Stanley wrote:\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; Yes I have heard about this problem coming up in the XOR\n&gt; &gt; experiment.\n&gt; &gt;&gt; &gt; Most neuroevolution experiments are not classification experiments\n&gt; &gt;&gt; &gt; (i.e. they don&#39;t have a &quot;final&quot; output), or they allow recurrent\n&gt; &gt;&gt; &gt; connections, and therefore do not require depth to be computed.\n&gt; &gt;&gt; &gt; Therefore, this problem will not come up in most expeirments.\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; However, XOR is a benchmark classification problem that is only\n&gt; &gt; meant\n&gt; &gt;&gt; &gt; to be attempted by feedforward networks so it needs to have depth\n&gt; &gt;&gt; &gt; computed. It appears that my attempts to keep the network\n&gt; &gt; feedforward\n&gt; &gt;&gt; &gt; in all cases is not perfect, so sometimes when a loop arises, it\n&gt; &gt; sends\n&gt; &gt;&gt; &gt; the depth computation into an infinite loop. I have not had time\n&gt; &gt; to\n&gt; &gt;&gt; &gt; think about the most elegant solution to this problem: Maybe it\n&gt; &gt; should\n&gt; &gt;&gt; &gt; be a stronger check on recurrence, perhaps entirely different from\n&gt; &gt; how\n&gt; &gt;&gt; &gt; it works now. Or perhaps it should be a fixed abort-iteration for\n&gt; &gt; the\n&gt; &gt;&gt; &gt; depth routine.\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; If someone does feel they have an elegant bit of code to address\n&gt; &gt; the\n&gt; &gt;&gt; &gt; issue, I will be happy to take a look.\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; In any case, it should not cause serious problems in general. I\n&gt; &gt;&gt; &gt; apologize for any inconvenience.\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; ken\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; --- In neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.com&gt; \n&gt; &lt;mailto:neat%40yahoogroups.com&gt;,\n&gt; &gt;&gt; &gt; &quot;petar_chervenski&quot; &lt;petar_chervenski@&gt;\n&gt; &gt;&gt; &gt; wrote:\n&gt; &gt;&gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; Hi Cesar,\n&gt; &gt;&gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; I know of this problem. It is obvious that depth cannot be\n&gt; &gt; determined\n&gt; &gt;&gt; &gt; &gt; in a recurrent network, but in general it depends, what is your\n&gt; &gt; way to\n&gt; &gt;&gt; &gt; &gt; handle the situation. Try improving the add_link() code so that\n&gt; &gt; the\n&gt; &gt;&gt; &gt; &gt; right nodes are picked up when trying to add a forward or a\n&gt; &gt; recurrent\n&gt; &gt;&gt; &gt; &gt; connection. This is a good solution but in general the problem\n&gt; &gt; with\n&gt; &gt;&gt; &gt; &gt; looped networks cannot be avoided. Suppose you have 3 hidden\n&gt; &gt; nodes, A,\n&gt; &gt;&gt; &gt; &gt; B, and C. If you link these like A-&gt;B, B-&gt;C, C-&gt;A, it is a loop\n&gt; &gt; in the\n&gt; &gt;&gt; &gt; &gt; network, even though all connections are meant to be forward.\n&gt; &gt;&gt; &gt; &gt; The best solution in my opinion is to put a limit on the\n&gt; &gt; possible\n&gt; &gt;&gt; &gt; &gt; depth, say 32, if the depth exceeds 32, quit the recursion and\n&gt; &gt;&gt; &gt; &gt; activate the network 32 times. It slows things down but at least\n&gt; &gt; it\n&gt; &gt;&gt; &gt; &gt; will not hurt evolution as if you penalize looped networks.\n&gt; &gt;&gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; Peter\n&gt; &gt;&gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; --- In neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.com&gt; \n&gt; &lt;mailto:neat%40yahoogroups.com&gt;,\n&gt; &gt; &quot;Cesar\n&gt; &gt;&gt; &gt; G. Miguel&quot; &lt;cesar.gomes@&gt;\n&gt; &gt;&gt; &gt; &gt; wrote:\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; &gt; Hi all,\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; &gt; I&#39;m not sure if someone else has notice this &quot;bug&quot; in rtNEAT,\n&gt; &gt; but\n&gt; &gt;&gt; &gt; &gt; the\n&gt; &gt;&gt; &gt; &gt; &gt; max_depth() method in network.cpp has the potential to be\n&gt; &gt; forever in\n&gt; &gt;&gt; &gt; &gt; &gt; loop if a recurrent link is added in a feedforward topology,\n&gt; &gt; e.g.,\n&gt; &gt;&gt; &gt; &gt; the\n&gt; &gt;&gt; &gt; &gt; &gt; XOR experiment (and that can happen even when the\n&gt; &gt; recur_only_prob\n&gt; &gt;&gt; &gt; &gt; &gt; parameter is set to zero). A real example is attached.\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; &gt; It seems to happen in 1 out of 10 runs. The max_depth() method\n&gt; &gt; calls\n&gt; &gt;&gt; &gt; &gt; &gt; depth() in nnode.cpp, which should return the max depth of\n&gt; &gt; that\n&gt; &gt;&gt; &gt; &gt; node.\n&gt; &gt;&gt; &gt; &gt; &gt; But it can get trapped in a loop if any recurrent link is\n&gt; &gt; present\n&gt; &gt;&gt; &gt; &gt; (as\n&gt; &gt;&gt; &gt; &gt; &gt; it is commented out in the source: DEPTH NOT DETERMINED FOR\n&gt; &gt; NETWORK\n&gt; &gt;&gt; &gt; &gt; &gt; WITH LOOP).\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; &gt; For those cases I have to force a return if an endless loop is\n&gt; &gt;&gt; &gt; &gt; &gt; detected and then set the chromosome&#39;s fitness to zero in\n&gt; &gt; order to\n&gt; &gt;&gt; &gt; &gt; &gt; continue.\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; &gt; Has anyone dealed with that before?\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt; &gt; []&#39;s\n&gt; &gt;&gt; &gt; &gt; &gt; Cesar\n&gt; &gt;&gt; &gt; &gt; &gt;\n&gt; &gt;&gt; &gt; &gt;\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n&gt;  \n\r\n--------------050501060709010502040006\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\n\r\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;meta content=&quot;text/html;charset=ISO-8859-1&quot; http-equiv=&quot;Content-Type&quot;&gt;\n&lt;/head&gt;\n&lt;body bgcolor=&quot;#ffffff&quot; text=&quot;#000000&quot;&gt;\nThomas,&lt;br&gt;\n&lt;br&gt;\nWere you addressing my response? Or are you referring to the original\nposter&#39;s endless loop implementation?&lt;br&gt;\n&lt;br&gt;\nMy implementation has no notion of depth. It flattens the ANN into a\nsingle array of nodes each activated once and only once from left to\nright (where left to right is defined by node dependency and then by\nage). So, if there are 12 nodes, regardless of recurrent connections,\nthere is exactly 12 node activation recalculations. When a node is\nrecalculated, it grabs the list of nodes upon which it depends (which\ncan include itself and nodes yet to be recalculated during this pass),\nrecalculates its value and stores it. There is exactly 12 store\noperations in a single activation pass. A node activation is never\nre-calculated during the same activation pass. The only way I can see a\nloop forming is if a node activation is recalculated during the same\nactivation pass. And if that is happening, I would like to understand\nhow it is being done, and why. What benefits are being derived from\nthat activation strategy?&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\nJim&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\nThomas Johnson wrote:\n&lt;blockquote\n cite=&quot;mid:1280cf6a0811031116u18a0c7fbvfd5ddc9d6f36841@...&quot;\n type=&quot;cite&quot;&gt;\n  &lt;div id=&quot;ygrp-text&quot;&gt;\n  &lt;p&gt;It&#39;s not clear to me that it&#39;s desirable to calculate the number of&lt;br&gt;\ntimes to activate by using the depth, regardless of how you handle&lt;br&gt;\nloops. This method works fine on non-recurrent networks, but once you&lt;br&gt;\nhave a network that has loops, consider how hard it is for a network&lt;br&gt;\nto evolve to, for instance, have a cycle activate twice. The network&lt;br&gt;\nwould have to significantly in increase its longest path length&lt;br&gt;\n(assuming that&#39;s how we calculate how many times to activate) so that&lt;br&gt;\nthe cycle would be activated twice. When you add in the wall-clock&lt;br&gt;\ntime it takes to calculate the longest path length for each network,&lt;br&gt;\nmaybe it&#39;s better to just activate a pre-specified (albeit reasonably&lt;br&gt;\nlarge) number of times.&lt;br&gt;\n  &lt;br&gt;\nTom&lt;br&gt;\n  &lt;br&gt;\nOn Mon, Nov 3, 2008 at 2:05 PM, Jim O&#39;Flaherty&lt;br&gt;\n&lt;&lt;a moz-do-not-send=&quot;true&quot; href=&quot;mailto:jim_oflaherty_jr%40yahoo.com&quot;&gt;jim_oflaherty_&lt;wbr&gt;jr@yahoo.&lt;wbr&gt;com&lt;/a&gt;&gt;\nwrote:&lt;br&gt;\n&gt; Peter,&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; That doesn&#39;t make sense to me. Cesar&#39;s comments indicate he has a\nsimilar&lt;br&gt;\n&gt; implementation to mine. Basically, every node&#39;s value in a single\ninstance&lt;br&gt;\n&gt; of an ANN is calculated just once on an activation pass. When the\nnode is&lt;br&gt;\n&gt; calculated, each of the nodes attached to it as &quot;input&quot; are used\n(whether&lt;br&gt;\n&gt; they have been activated in this pass, or hold a residual value\nfrom the&lt;br&gt;\n&gt; previous pass) to calculate it&#39;s current value. And assuming the\nordering of&lt;br&gt;\n&gt; the activations is lined up by dependency and they by node age,\nthe network&lt;br&gt;\n&gt; ought to activate deterministically meaning that starting with an\nempty&lt;br&gt;\n&gt; network (all node activation values are set to 0.0), providing the\nsame&lt;br&gt;\n&gt; input and making several activation passes ought to be able to\nreturn&lt;br&gt;\n&gt; reliably repeatable results given the node activation values are\nreset to&lt;br&gt;\n&gt; 0.0 and precisely the same input is submitted for the same number\nof&lt;br&gt;\n&gt; activation passes.&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; I get that the network graph can have cycles, as in recurrent\nconnections.&lt;br&gt;\n&gt; However, those have no relevance to activation order or cause any\nsort of&lt;br&gt;\n&gt; &quot;loop&quot; in a straightforward ANN implementation. So, I am getting\nconfused&lt;br&gt;\n&gt; about where and how an &quot;endless loop&quot; could form. Perhaps they are\ntalking&lt;br&gt;\n&gt; about the network output never stabilizing to within some stable\nvalue&lt;br&gt;\n&gt; ranges when activating it repeatedly with the same input. That&#39;s\nto be&lt;br&gt;\n&gt; expected in a network with enough recurrent connections -\nnon-uniformity in&lt;br&gt;\n&gt; the output following activations with the same input. Each\nadditional&lt;br&gt;\n&gt; recurrent connection increases the &quot;echos from the past&quot; causing a\nstable&lt;br&gt;\n&gt; output cycle to become less and less probable.&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Said another way, a single activation of an ANN, with or without\nrecurrent&lt;br&gt;\n&gt; connections, will results in exactly the same number of node\nactivation&lt;br&gt;\n&gt; calculations each time it is told to process input. There should\nnot be any&lt;br&gt;\n&gt; variability to the number of node activations AT ALL. If so, then\nsome sort&lt;br&gt;\n&gt; of different activation strategy is being employed. And if so,\nwhat is it?&lt;br&gt;\n&gt; And why?&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Jim&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; petar_chervenski wrote:&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; It is about the loop in which you calculate the longest path from\nan&lt;br&gt;\n&gt; input node to an output node. Not the activation loop in which you&lt;br&gt;\n&gt; activate the network.&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Peter&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; --- In &lt;a moz-do-not-send=&quot;true&quot;\n href=&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.&lt;wbr&gt;com&lt;/a&gt;,\nJim O&#39;Flaherty &lt;jim_oflaherty_&lt;wbr&gt;jr@...&gt;&lt;br&gt;\n&gt; wrote:&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; Ken,&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; I am confused how you could end up in an endless activation\nloop. If&lt;br&gt;\n&gt; you&lt;br&gt;\n&gt;&gt; are moving from the input nodes forward through the hidden\nnodes to&lt;br&gt;\n&gt; the&lt;br&gt;\n&gt;&gt; output nodes as a state calculation progression, there would\nbe no&lt;br&gt;\n&gt; need&lt;br&gt;\n&gt;&gt; to worry about activation loops - you would only calculate the\nvalue&lt;br&gt;\n&gt; of&lt;br&gt;\n&gt;&gt; each node once in a single pass. The point of a recurrent\nconnection&lt;br&gt;\n&gt; is&lt;br&gt;\n&gt;&gt; to carry state between full network activations. So, the value&lt;br&gt;\n&gt; provided&lt;br&gt;\n&gt;&gt; by a recurrent connection would not be used until the next&lt;br&gt;\n&gt; activation&lt;br&gt;\n&gt;&gt; pass (assuming all the nodes from the previous pass have not be&lt;br&gt;\n&gt; &quot;zeroed&lt;br&gt;\n&gt;&gt; out&quot;).&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; How is it there is an endless loop?&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; Jim&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; Kenneth Stanley wrote:&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; Yes I have heard about this problem coming up in the XOR&lt;br&gt;\n&gt; experiment.&lt;br&gt;\n&gt;&gt; &gt; Most neuroevolution experiments are not classification\nexperiments&lt;br&gt;\n&gt;&gt; &gt; (i.e. they don&#39;t have a &quot;final&quot; output), or they allow\nrecurrent&lt;br&gt;\n&gt;&gt; &gt; connections, and therefore do not require depth to be\ncomputed.&lt;br&gt;\n&gt;&gt; &gt; Therefore, this problem will not come up in most\nexpeirments.&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; However, XOR is a benchmark classification problem that\nis only&lt;br&gt;\n&gt; meant&lt;br&gt;\n&gt;&gt; &gt; to be attempted by feedforward networks so it needs to\nhave depth&lt;br&gt;\n&gt;&gt; &gt; computed. It appears that my attempts to keep the network&lt;br&gt;\n&gt; feedforward&lt;br&gt;\n&gt;&gt; &gt; in all cases is not perfect, so sometimes when a loop\narises, it&lt;br&gt;\n&gt; sends&lt;br&gt;\n&gt;&gt; &gt; the depth computation into an infinite loop. I have not\nhad time&lt;br&gt;\n&gt; to&lt;br&gt;\n&gt;&gt; &gt; think about the most elegant solution to this problem:\nMaybe it&lt;br&gt;\n&gt; should&lt;br&gt;\n&gt;&gt; &gt; be a stronger check on recurrence, perhaps entirely\ndifferent from&lt;br&gt;\n&gt; how&lt;br&gt;\n&gt;&gt; &gt; it works now. Or perhaps it should be a fixed\nabort-iteration for&lt;br&gt;\n&gt; the&lt;br&gt;\n&gt;&gt; &gt; depth routine.&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; If someone does feel they have an elegant bit of code to\naddress&lt;br&gt;\n&gt; the&lt;br&gt;\n&gt;&gt; &gt; issue, I will be happy to take a look.&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; In any case, it should not cause serious problems in\ngeneral. I&lt;br&gt;\n&gt;&gt; &gt; apologize for any inconvenience.&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; ken&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; --- In &lt;a moz-do-not-send=&quot;true&quot;\n href=&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.&lt;wbr&gt;com&lt;/a&gt;\n&lt;&lt;a class=&quot;moz-txt-link-freetext&quot; href=&quot;mailto:neat%&quot;&gt;mailto:neat%&lt;/a&gt;&lt;wbr&gt;40yahoogroups.&lt;wbr&gt;com&gt;,&lt;br&gt;\n&gt;&gt; &gt; &quot;petar_chervenski&quot; &lt;petar_chervenski@&lt;wbr&gt;&gt;&lt;br&gt;\n&gt;&gt; &gt; wrote:&lt;br&gt;\n&gt;&gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; Hi Cesar,&lt;br&gt;\n&gt;&gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; I know of this problem. It is obvious that depth\ncannot be&lt;br&gt;\n&gt; determined&lt;br&gt;\n&gt;&gt; &gt; &gt; in a recurrent network, but in general it depends,\nwhat is your&lt;br&gt;\n&gt; way to&lt;br&gt;\n&gt;&gt; &gt; &gt; handle the situation. Try improving the add_link()\ncode so that&lt;br&gt;\n&gt; the&lt;br&gt;\n&gt;&gt; &gt; &gt; right nodes are picked up when trying to add a\nforward or a&lt;br&gt;\n&gt; recurrent&lt;br&gt;\n&gt;&gt; &gt; &gt; connection. This is a good solution but in general\nthe problem&lt;br&gt;\n&gt; with&lt;br&gt;\n&gt;&gt; &gt; &gt; looped networks cannot be avoided. Suppose you have\n3 hidden&lt;br&gt;\n&gt; nodes, A,&lt;br&gt;\n&gt;&gt; &gt; &gt; B, and C. If you link these like A-&gt;B, B-&gt;C,\nC-&gt;A, it is a loop&lt;br&gt;\n&gt; in the&lt;br&gt;\n&gt;&gt; &gt; &gt; network, even though all connections are meant to be\nforward.&lt;br&gt;\n&gt;&gt; &gt; &gt; The best solution in my opinion is to put a limit on\nthe&lt;br&gt;\n&gt; possible&lt;br&gt;\n&gt;&gt; &gt; &gt; depth, say 32, if the depth exceeds 32, quit the\nrecursion and&lt;br&gt;\n&gt;&gt; &gt; &gt; activate the network 32 times. It slows things down\nbut at least&lt;br&gt;\n&gt; it&lt;br&gt;\n&gt;&gt; &gt; &gt; will not hurt evolution as if you penalize looped\nnetworks.&lt;br&gt;\n&gt;&gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; Peter&lt;br&gt;\n&gt;&gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; --- In &lt;a moz-do-not-send=&quot;true&quot;\n href=&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.&lt;wbr&gt;com&lt;/a&gt;\n&lt;&lt;a class=&quot;moz-txt-link-freetext&quot; href=&quot;mailto:neat%&quot;&gt;mailto:neat%&lt;/a&gt;&lt;wbr&gt;40yahoogroups.&lt;wbr&gt;com&gt;,&lt;br&gt;\n&gt; &quot;Cesar&lt;br&gt;\n&gt;&gt; &gt; G. Miguel&quot; &lt;cesar.gomes@&lt;wbr&gt;&gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; wrote:&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; Hi all,&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; I&#39;m not sure if someone else has notice this\n&quot;bug&quot; in rtNEAT,&lt;br&gt;\n&gt; but&lt;br&gt;\n&gt;&gt; &gt; &gt; the&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; max_depth() method in network.cpp has the\npotential to be&lt;br&gt;\n&gt; forever in&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; loop if a recurrent link is added in a\nfeedforward topology,&lt;br&gt;\n&gt; e.g.,&lt;br&gt;\n&gt;&gt; &gt; &gt; the&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; XOR experiment (and that can happen even when\nthe&lt;br&gt;\n&gt; recur_only_prob&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; parameter is set to zero). A real example is\nattached.&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; It seems to happen in 1 out of 10 runs. The\nmax_depth() method&lt;br&gt;\n&gt; calls&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; depth() in nnode.cpp, which should return the\nmax depth of&lt;br&gt;\n&gt; that&lt;br&gt;\n&gt;&gt; &gt; &gt; node.&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; But it can get trapped in a loop if any\nrecurrent link is&lt;br&gt;\n&gt; present&lt;br&gt;\n&gt;&gt; &gt; &gt; (as&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; it is commented out in the source: DEPTH NOT\nDETERMINED FOR&lt;br&gt;\n&gt; NETWORK&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; WITH LOOP).&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; For those cases I have to force a return if an\nendless loop is&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; detected and then set the chromosome&#39;s fitness\nto zero in&lt;br&gt;\n&gt; order to&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; continue.&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; Has anyone dealed with that before?&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; []&#39;s&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt; Cesar&lt;br&gt;\n&gt;&gt; &gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; &gt;&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; &lt;br&gt;\n  &lt;/p&gt;\n  &lt;/div&gt;\n&lt;!--End group email --&gt; &lt;/blockquote&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\r\n--------------050501060709010502040006--\r\n\n"}}