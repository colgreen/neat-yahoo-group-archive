{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234577593,"authorName":"Oliver Coleman","from":"Oliver Coleman &lt;oliver.coleman@...&gt;","profile":"olivercoleman04","replyTo":"LIST","senderId":"qDLZI6xbka_V97QuqxwBQK5btdjaL2C2IQOwcR2TbWk83pfcNXfJthkQwTxTnNjPWsNXXPh-kOLGxJv3YR2mxWOrkkXS7Zzsy2pMr92ceXw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Models of brains, what should we borrow from biology?","postDate":"1343254551","msgId":5835,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBK2R1aW1QR3Y9dUVZbVJWVGhNSm53UDNKbmVmclV0dVYtcy12TGoyMmZjai1ZS0U9Z0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PGp1bzdocis3NWtjQGVHcm91cHMuY29tPg==","referencesHeader":"PDc0NEJBN0EyLUE2MzAtNEREMC1CRDdDLTcxRDkyMzI0QjhFQkBjb3JuZWxsLmVkdT4JPGp1bzdocis3NWtjQGVHcm91cHMuY29tPg=="},"prevInTopic":5834,"nextInTopic":5836,"prevInTime":5834,"nextInTime":5836,"topicId":5801,"numMessagesInTopic":16,"msgSnippet":"Hi Ken, I agree overall that qualitative results are much more interesting and necessary than quantitative results at least at this stage of advancement in AI","rawEmail":"Return-Path: &lt;oliver.coleman@...&gt;\r\nX-Sender: oliver.coleman@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 78266 invoked from network); 25 Jul 2012 22:15:52 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m14.grp.sp2.yahoo.com with QMQP; 25 Jul 2012 22:15:52 -0000\r\nX-Received: from unknown (HELO mail-yx0-f174.google.com) (209.85.213.174)\n  by mta4.grp.sp2.yahoo.com with SMTP; 25 Jul 2012 22:15:52 -0000\r\nX-Received: by yenl2 with SMTP id l2so1459768yen.5\n        for &lt;neat@yahoogroups.com&gt;; Wed, 25 Jul 2012 15:15:51 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.50.159.196 with SMTP id xe4mr135350igb.43.1343254551412; Wed,\n 25 Jul 2012 15:15:51 -0700 (PDT)\r\nX-Received: by 10.231.46.209 with HTTP; Wed, 25 Jul 2012 15:15:51 -0700 (PDT)\r\nIn-Reply-To: &lt;juo7hr+75kc@...&gt;\r\nReferences: &lt;744BA7A2-A630-4DD0-BD7C-71D92324B8EB@...&gt;\n\t&lt;juo7hr+75kc@...&gt;\r\nDate: Thu, 26 Jul 2012 08:15:51 +1000\r\nMessage-ID: &lt;CA+duimPGv=uEYmRVThMJnwP3JnefrUtuV-s-vLj22fcj-YKE=g@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=14dae934059b613e2704c5aed2ba\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Oliver Coleman &lt;oliver.coleman@...&gt;\r\nSubject: Re: [neat] Re: Models of brains, what should we borrow from biology?\r\nX-Yahoo-Group-Post: member; u=234577593; y=Md-yml8XeFWkktV9f29KLlSTB2WuWI-Qhh42J_vqrUxGoSk7yOnz_VlfoKYDti4shP6eQfc-Xg\r\nX-Yahoo-Profile: olivercoleman04\r\n\r\n\r\n--14dae934059b613e2704c5aed2ba\r\nContent-Type: text/plain; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Ken,\n\nI agree overall that qualitative results are much more interesting=\r\n and\nnecessary than quantitative results at least at this stage of advancem=\r\nent\nin AI (I&#39;m strongly swayed by your arguments; what have you got to say\n=\r\nJeff?).\nHowever, perhaps comparative performance results can help to provid=\r\ne\ninsight into the characteristics of one approach versus another and provi=\r\nde\nuseful information to help improve them, for example if two approaches f=\r\nail\non different kinds of tasks perhaps we can look at how they each succee=\r\nd in\ndifferent ways in order to improve one or both approaches. In the sear=\r\nch\nspace of AI algorithms, comparative results can provide information abou=\r\nt\nwhich algorithms should have a crossover operator applied to them to\nprod=\r\nuce potentially better ones (the apple and orange may combine to\nproduce a =\r\nnew inspirational fruit ;)). Perhaps this is too vague to be\nuseful...\n\nOli=\r\nver\n\nP.S. I&#39;ve quoted your comment in a reply on my blog, I&#39;m assuming that=\r\n your\npermission to post your comments on my blog earlier in this discussio=\r\nn\napplies to ongoing replies, let me know if this is not okay...\n\nOn 25 Jul=\r\ny 2012 17:34, Ken &lt;kstanley@...&gt; wrote:\n\n&gt; **\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; Hi Jeff a=\r\nnd Oliver, nice discussion and definitely relevant to the group.\n&gt; Jeff men=\r\ntioned my &quot;strong opinions&quot; about algorithm comparisons, so I\n&gt; thought it =\r\ncan&#39;t hurt to follow up on what Jeff said:\n&gt;\n&gt; &quot;Ken Stanley has strong opin=\r\nions on why comparing different\n&gt; algorithms on one or a few tasks tells us=\r\n very little, which he may\n&gt; want to chime in with. I generally agree with =\r\nhim that it is not\n&gt; terribly informative, although I tend to think it is s=\r\ntill somewhat\n&gt; tvaluable, while he thinks it is mostly worthless! (Sorry i=\r\nf I am\n&gt; tincorrectly paraphrasing you Ken). Ken is right that different\n&gt; =\r\nalgorithms perform very differently on different problems, so a few tests\n&gt;=\r\n provides too small a sample size to learn much. Moreover, every researcher=\r\n\n&gt; inadvertently knows their own algorithm much better than what they are\n&gt;=\r\n comparing against, so they keep tuning their algorithm to the benchmarks\n&gt;=\r\n being used until they win, reducing the value of the comparison. There&#39;s n=\r\no\n&gt; great alternative, in my opinion, so I still do it...but I increasingly=\r\n\n&gt; agree with Ken that our time as scientists can better be spent on other\n=\r\n&gt; chores (such as showing the new, interesting, properties of our new\n&gt; alg=\r\norithms...an example being HyperNEAT genomes scaling up to very large\n&gt; net=\r\nworks without substantial performance drops).&quot;\n&gt;\n&gt; I agree with these conce=\r\nrns but as Jeff hints I&#39;d go farther with it. The\n&gt; problem here is more fu=\r\nndamental than simply that it&#39;s hard to tell which\n&gt; algorithm is &quot;better&quot; =\r\nfrom a few comparisons. The problem is that it&#39;s not\n&gt; even clear what &quot;bet=\r\nter&quot; means no matter how many comparisons there are.\n&gt; Quantitative compari=\r\nsons imply that &quot;better&quot; means that an algorithms\n&gt; scores better on averag=\r\ne on some performance metric. But for those who are\n&gt; pursuing revolutionar=\r\ny advances in AI, I&#39;m skeptical that it really matters\n&gt; which algorithm sc=\r\nores better even across many benchmarks.\n&gt;\n&gt; The reason is that to me &quot;bett=\r\ner&quot; should mean &quot;leads to the most new\n&gt; algorithms in the future.&quot; In othe=\r\nr words, it has little or nothing to do\n&gt; with performance. &quot;Better&quot; means =\r\ncreating a foundation for new ideas and a\n&gt; new research direction. We know=\r\n it when we see it. We&#39;re talking about\n&gt; primitive AI algorithms here that=\r\n are about 3 inches into a\n&gt; 10-million-kilometer marathon to the pinnacle =\r\nof AI. If you&#39;re looking at\n&gt; two different algorithms then in effect you&#39;r=\r\ne comparing two different\n&gt; points in the vast space of all possible algori=\r\nthms. Given that there are\n&gt; probably light years of advances to go in the =\r\ndirection of either one of\n&gt; them, why would you cut the path of either one=\r\n of them off regardless of\n&gt; the &quot;results&quot; if both of them are interesting =\r\nideas?\n&gt;\n&gt; If you were running an evolutionary algorithm with diversity mai=\r\nntenance\n&gt; of some kind, then how one arbitrary point in the search space c=\r\nompares to\n&gt; another would hardly matter. So why do we care about apple-and=\r\n-oranges\n&gt; comparisons in AI?\n&gt;\n&gt; I think it has become a convenient way to=\r\n avoid the sobering reality that\n&gt; most algorithms don&#39;t have any exciting =\r\nideas behind them. So the only\n&gt; thing you can do is look at a pointless co=\r\nmparison. For those algorithms\n&gt; that do have interesting ideas behind them=\r\n, I don&#39;t even need a comparison\n&gt; to know they&#39;re interesting, and even if=\r\n they perform worse than something\n&gt; else, the last thing I want to do is t=\r\nhrow out an interesting idea. Who\n&gt; knows where it might lead?\n&gt;\n&gt; So yes c=\r\nomparisons are very overrated. One type of comparison I do think\n&gt; can be u=\r\nseful once in a while is to compare an algorithm with a variant of\n&gt; itself=\r\n (which includes ablations). That can give a sense of what a new\n&gt; ingredie=\r\nnt adds. But even then, if the idea isn&#39;t inspirational, the\n&gt; performance =\r\ngain won&#39;t matter much in the long run. Because in the long run\n&gt; we aren&#39;t=\r\n interested in performance gains but rather in stepping stones to\n&gt; new fro=\r\nntiers. These things (i.e. performance and where an idea leads) are\n&gt; not c=\r\norrelated in any complex search space and therefore we should should\n&gt; not =\r\nbe running the whole field of AI research like a naive giant\n&gt; hill-climbin=\r\ng algorithm. The irony here is that the world&#39;s greatest\n&gt; experts in searc=\r\nh are doing exactly that at the meta-level (i.e. at the\n&gt; level of how the =\r\ncommunity searches for new algorithms) by focusing so\n&gt; intently on compara=\r\ntive performance results.\n&gt;\n&gt; The one other kind of performance result I th=\r\nink is useful is when an\n&gt; algorithm does something completely unprecedente=\r\nd. Of course, in that case,\n&gt; you don&#39;t need a comparison because there&#39;s n=\r\nothing to compare with. Though\n&gt; that won&#39;t stop traditionalists from clamo=\r\nring for a comparison anyway.\n&gt;\n&gt; ken\n&gt;\n&gt;  \n&gt;\n\r\n--14dae934059b613e2704c5aed2ba\r\nContent-Type: text/html; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;p&gt;Hi Ken,&lt;/p&gt;&lt;p&gt;I agree overall that qualitative results are much more int=\r\neresting and necessary than quantitative results at least at this stage of =\r\nadvancement in AI (I&#39;m strongly swayed by your arguments; what have you=\r\n got to say Jeff?).&lt;/p&gt;\nHowever, perhaps comparative performance \nresults c=\r\nan help to provide insight into the characteristics of one \napproach versus=\r\n another and provide useful information to help improve \nthem, for example =\r\nif two approaches fail on different kinds of tasks \nperhaps we can look at =\r\nhow they each succeed in different ways in order \nto improve one or both ap=\r\nproaches. In the search space of AI algorithms,\n comparative results can pr=\r\novide information about which algorithms \nshould have a crossover operator =\r\napplied to them to produce potentially \nbetter ones (the apple and orange m=\r\nay combine to produce a new inspirational fruit ;)). Perhaps this is too va=\r\ngue to be useful...=A0&lt;p&gt;Oliver&lt;/p&gt;\n&lt;br&gt;\nP.S. I&#39;ve quoted your comment =\r\nin a reply on my blog, I&#39;m assuming that \nyour permission to post your =\r\ncomments on my blog earlier in this \ndiscussion applies to ongoing replies,=\r\n let me know if this is not \nokay...&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On 2=\r\n5 July 2012 17:34, Ken &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:kstanley@cs.=\r\nutexas.edu&quot; target=3D&quot;_blank&quot;&gt;kstanley@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;=\r\nbr&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0 0 0 .8ex;border-left=\r\n:1px #ccc solid;padding-left:1ex&quot;&gt;\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n\n&lt;div style&gt;\n&lt;span&gt;=\r\n=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n    &lt;div&gt;\n      \n      \n      &lt;p&gt;&lt;/p&gt;&lt;div clas=\r\ns=3D&quot;im&quot;&gt;&lt;br&gt;\n&lt;br&gt;\nHi Jeff and Oliver, nice discussion and definitely relev=\r\nant to the group.  Jeff mentioned my &quot;strong opinions&quot; about algo=\r\nrithm comparisons, so I thought it can&#39;t hurt to follow up on what Jeff=\r\n said:&lt;br&gt;\n&lt;br&gt;\n&quot;Ken Stanley has strong opinions on why comparing diff=\r\nerent&lt;br&gt;\nalgorithms on one or a few tasks tells us very little, which he m=\r\nay &lt;br&gt;\nwant to chime in with. I generally agree with him that it is not &lt;b=\r\nr&gt;\nterribly informative, although I tend to think it is still somewhat &lt;br&gt;=\r\n&lt;/div&gt;\ntvaluable, while he thinks it is mostly worthless! (Sorry if I am &lt;b=\r\nr&gt;\ntincorrectly paraphrasing you Ken). Ken is right that different &lt;br&gt;&lt;div=\r\n class=3D&quot;im&quot;&gt;\nalgorithms perform very differently on different problems, s=\r\no a few tests provides too small a sample size to learn much. Moreover, eve=\r\nry researcher inadvertently knows their own algorithm much better than what=\r\n they are comparing against, so they keep tuning their algorithm to the ben=\r\nchmarks being used until they win, reducing the value of the comparison. Th=\r\nere&#39;s no great alternative, in my opinion, so I still do it...but  I in=\r\ncreasingly agree with Ken that our time as scientists can better be spent o=\r\nn other chores (such as showing the new, interesting, properties of our new=\r\n algorithms...an example being HyperNEAT genomes scaling up to very large n=\r\networks without substantial performance drops).&quot;&lt;br&gt;\n\n&lt;br&gt;&lt;/div&gt;\nI agr=\r\nee with these concerns but as Jeff hints I&#39;d go farther with it.  The p=\r\nroblem here is more fundamental than simply that it&#39;s hard to tell whic=\r\nh algorithm is &quot;better&quot; from a few comparisons.  The problem is t=\r\nhat it&#39;s not even clear what &quot;better&quot; means no matter how man=\r\ny comparisons there are.  Quantitative comparisons imply that &quot;better&=\r\nquot; means that an algorithms scores better on average on some performance=\r\n metric.  But for those who are pursuing revolutionary advances in AI, I&#3=\r\n9;m skeptical that it really matters which algorithm scores better even acr=\r\noss many benchmarks.&lt;br&gt;\n\n&lt;br&gt;\nThe reason is that to me &quot;better&quot; =\r\nshould mean &quot;leads to the most new algorithms in the future.&quot;  In=\r\n other words, it has little or nothing to do with performance.  &quot;Bette=\r\nr&quot; means creating a foundation for new ideas and a new research direct=\r\nion.  We know it when we see it.  We&#39;re talking about primitive AI algo=\r\nrithms here that are about 3 inches into a 10-million-kilometer marathon to=\r\n the pinnacle of AI.  If you&#39;re looking at two different algorithms the=\r\nn in effect you&#39;re comparing two different points in the vast space of =\r\nall possible algorithms.  Given that there are probably light years of adva=\r\nnces to go in the direction of either one of them, why would you cut the pa=\r\nth of either one of them off regardless of the &quot;results&quot; if both =\r\nof them are interesting ideas?&lt;br&gt;\n\n&lt;br&gt;\nIf you were running an evolutionar=\r\ny algorithm with diversity maintenance of some kind, then how one arbitrary=\r\n point in the search space compares to another would hardly matter.  So why=\r\n do we care about apple-and-oranges comparisons in AI?  &lt;br&gt;\n\n&lt;br&gt;\nI think =\r\nit has become a convenient way to avoid the sobering reality that most algo=\r\nrithms don&#39;t have any exciting ideas behind them.  So the only thing yo=\r\nu can do is look at a pointless comparison.  For those algorithms that do h=\r\nave interesting ideas behind them, I don&#39;t even need a comparison to kn=\r\now they&#39;re interesting, and even if they perform worse than something e=\r\nlse, the last thing I want to do is throw out an interesting idea.   Who kn=\r\nows where it might lead?&lt;br&gt;\n\n&lt;br&gt;\nSo yes comparisons are very overrated.  =\r\nOne type of comparison I do think can be useful once in a while is to compa=\r\nre an algorithm with a variant of itself (which includes ablations).  That =\r\ncan give a sense of what a new ingredient adds.  But even then, if the idea=\r\n isn&#39;t inspirational, the performance gain won&#39;t matter much in the=\r\n long run.  Because in the long run we aren&#39;t interested in performance=\r\n gains but rather in stepping stones to new frontiers. These things (i.e. p=\r\nerformance and where an idea leads) are not correlated in any complex searc=\r\nh space and therefore we should should not be running the whole field of AI=\r\n research like a naive giant hill-climbing algorithm.  The irony here is th=\r\nat the world&#39;s greatest experts in search are doing exactly that at the=\r\n meta-level (i.e. at the level of how the community searches for new algori=\r\nthms) by focusing so intently on comparative performance results.&lt;br&gt;\n\n&lt;br&gt;=\r\n\nThe one other kind of performance result I think is useful is when an algo=\r\nrithm does something completely unprecedented.  Of course, in that case, yo=\r\nu don&#39;t need a comparison because there&#39;s nothing to compare with. =\r\n Though that won&#39;t stop traditionalists from clamoring for a comparison=\r\n anyway.&lt;br&gt;\n\n&lt;br&gt;\nken&lt;br&gt;\n&lt;br&gt;\n&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;div st=\r\nyle=3D&quot;color:#fff;min-height:0&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/blockquote&gt;&lt;/=\r\ndiv&gt;&lt;br&gt;\n\r\n--14dae934059b613e2704c5aed2ba--\r\n\n"}}