{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"a4nqoGC1n7sq3iWGDEly3sUCww190--oW1Ga0I_xQUyIZtLBz-8CZ1NUC1DjWFcZO459qs1MY-ji5rvvpZocbI5IoVrF0bqhkvlWYehHDxO2","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Idea concerning image enlargement...","postDate":"1078608135","msgId":473,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGMyZGZlNyt0Y2JpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQwNDlENjFBLjQwOTAyMDNAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":472,"nextInTopic":477,"prevInTime":472,"nextInTime":474,"topicId":469,"numMessagesInTopic":32,"msgSnippet":"John, Colin makes a good point that this method greatly complicates the function to be computed.  But on the other hand, as you pointed out, it does make the","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 56834 invoked from network); 6 Mar 2004 21:22:19 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m7.grp.scd.yahoo.com with QMQP; 6 Mar 2004 21:22:19 -0000\r\nReceived: from unknown (HELO n14.grp.scd.yahoo.com) (66.218.66.69)\n  by mta6.grp.scd.yahoo.com with SMTP; 6 Mar 2004 21:22:19 -0000\r\nReceived: from [66.218.66.112] by n14.grp.scd.yahoo.com with NNFMP; 06 Mar 2004 21:22:16 -0000\r\nDate: Sat, 06 Mar 2004 21:22:15 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;c2dfe7+tcbi@...&gt;\r\nIn-Reply-To: &lt;4049D61A.4090203@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 5198\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.69\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Idea concerning image enlargement...\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJohn,\n\nColin makes a good point that this method greatly complicates the\nfunction to be computed.  But on the other hand, as you pointed out,\nit does make the network more minimal.  So it breaks one golden rule\nbut adheres to another.  There&#39;s clearly a tradeoff there.  My opinion\nis that this is a very open question, and we really won&#39;t know how\nfeasible this idea is until we try.  \n\nIf you look in the NEAT FAQ, I actually made a similar suggestion in\nthe games domain, i.e. instead of having outputs for every position on\nthe board, you add the output nodes to the *inputs* and then query the\nnetwork over the set of all board coordinates, and place a piece where\nthe network responds most strongly:\n\nSee &quot;How can NEAT &quot;start minimally&quot; in a high-input/high-output\ndomain?&quot;\n\nNotice in my idea I suggested actually having an input node for every\ncoordinate on the board (as opposed to a 2-node coordinate system). \nThis may seem like it isn&#39;t a gain but it is; note that a 10x10 net\nstarts with 100 inputs, but if you move the 10 outputs to the input,\nyou then have a 20x1 net, which only has 20 connections to begin\nwith.  \nMy point is that this idea is a third option, though similar to your\n(John&#39;s) idea.\n  \nAs I said the utility of any of these ideas is unknown, but I wouldn&#39;t\nassume anything before we try them.  One thing that might make things\ntough with functions with query coordinates in the inputs is if they\nhave a lot of XOR-like properties, because that would mean a lot of\ntricky plateaus in the fitness space, and a lot of waiting for the\nright node to appear.  \n\nken \n\n\n--- In neat@yahoogroups.com, Colin Green &lt;cgreen@d...&gt; wrote:\n&gt; Hi John,\n&gt; \n&gt; As far as evolving a parameterized/continous enlargment NN goes I\nthink \n&gt; you&#39;re on the right lines but I&#39;m a bit concerned that you are\ntrying to \n&gt; &#39;jump the gun&#39; on this one. Remember that the golden rule with NN&#39;s\nis \n&gt; to keep the function you are trying to instill into the network as \n&gt; simple as possible. The new technique has added complexity to the \n&gt; required function by introducing the need to interpret coordinates\nand \n&gt; then to modify the enlargment function part of the network based\nupon \n&gt; those coordinates. Initially I would stick with the fixed\nmultiplicative \n&gt; factor - when you have that cracked *then* move on to trying a \n&gt; parameterized enlargment.\n&gt; \n&gt; When/if you do try this I also would initially start with just a\nsingle \n&gt; pixel input (and thus a single coordinate) and move onto the an\ninput \n&gt; range later - again this is additional complexity which NEAT may\nnot be \n&gt; able to evolve. You also need to specify an enlargment factor\nsomewhere \n&gt; don&#39;t you? so that the network knows the bounds of the output pixel \n&gt; coordinate system?\n&gt; \n&gt; Colin.\n&gt; \n&gt; John Arrowwood wrote:\n&gt; \n&gt; &gt;&gt;From the beginning, I was concerned about one thing:  The output\nis a fixed \n&gt; &gt;multiplicative factor.  I didn&#39;t like that.  I suspect that deep in\nthe \n&gt; &gt;bowels of the network is a continuous function, but how we access\nit renders \n&gt; &gt;it discreet.  I really wanted continuous, but figured I had to\nsettle for \n&gt; &gt;discreet.\n&gt; &gt;\n&gt; &gt;But this morning, I had an idea.  Tell me if you think this might\nwork...\n&gt; &gt;\n&gt; &gt;Instead of having an output matrix, have only a single output\nnode, \n&gt; &gt;representing a single output pixel.  Then add four additional\ninputs:  The \n&gt; &gt;x,y position of the upper left corner of the region of interest,\nand the \n&gt; &gt;lower right corner.  The output is to represent the average of the\nfunction \n&gt; &gt;described by the rest of the network at the specified location\nrelative to \n&gt; &gt;the input space.  0,0 represents the upper left corner of the input\nsample, \n&gt; &gt;and 1,1 represents the opposite corner.\n&gt; &gt;\n&gt; &gt;I realize that it would make more sense if described visually. \nI&#39;ll try...\n&gt; &gt;\n&gt; &gt;Input:\n&gt; &gt;[  ] bias\n&gt; &gt;[  ][  ][  ][  ]  pixels\n&gt; &gt;[  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ]\n&gt; &gt;[  ] x1\n&gt; &gt;[  ] y1\n&gt; &gt;[  ] x2\n&gt; &gt;[  ] y2\n&gt; &gt;\n&gt; &gt;Output:\n&gt; &gt;[  ] output pixel value that is the average for the region\nx1,y1-x2,y2\n&gt; &gt;\n&gt; &gt;Thus, the output region would be (for a 2x enlargement)\n&gt; &gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt; &gt;[  ][  ][a][  ][  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ][b][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt; &gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt; &gt;\n&gt; &gt;So if x1 = 0.25 and x2 = 0.375, y1=0.25 and y2=0.375, the output of\nthe \n&gt; &gt;network should be the pixel labeled &#39;a&#39;.  Whereas, if all other\ninput is \n&gt; &gt;kept the same but x1=0.5, x2=0.625, y1=0.625, y2=0.75, then the\noutput \n&gt; &gt;corresponds to &#39;b&#39;.  If I were to input 0,0-0.25,0.25, I should get\nas an \n&gt; &gt;output the value of the input pixel at 0,0.  And once trained, I\ncould get \n&gt; &gt;ANY level of enlargement by just sampling the network at\nprogressively \n&gt; &gt;smaller intervals.\n&gt; &gt;\n&gt; &gt;The best part is, it is more conducive to complexification.  With a\nnumber \n&gt; &gt;of input nodes, and only a single output node, it can complexify\nthe way it \n&gt; &gt;should.\n&gt; &gt;\n&gt; &gt;So, what do you think?  Sound plausable?  Any known reason why\nsuch an \n&gt; &gt;approach might be doomed to failure?\n&gt; &gt;\n&gt; &gt;-- John\n&gt; &gt;\n&gt; &gt;__\n&gt; &gt;\n\n\n"}}