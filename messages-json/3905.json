{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"N6ejhf_eke3I3qcXcVH9P-yAUpO7TCz1MPsKzmEO8G7MQpX35aKwuvcaNl1gUICP9yvZj2Hk7jII0Z5jKN3bqLRpKhgZbUAj-0DVwe2036dG","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205910429","msgId":3905,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZycWUydCtsdnJ0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZycDFpbStla2pjQGVHcm91cHMuY29tPg=="},"prevInTopic":3901,"nextInTopic":3908,"prevInTime":3904,"nextInTime":3906,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"Andy, I fully appreciate your enthusiasm for engineering optimization and operations research.  In fact, I am not unaware of this area and have looked into","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 168 invoked from network); 19 Mar 2008 07:07:10 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m47.grp.scd.yahoo.com with QMQP; 19 Mar 2008 07:07:10 -0000\r\nX-Received: from unknown (HELO n45d.bullet.mail.sp1.yahoo.com) (66.163.169.159)\n  by mta15.grp.scd.yahoo.com with SMTP; 19 Mar 2008 07:07:10 -0000\r\nX-Received: from [216.252.122.216] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 19 Mar 2008 07:07:10 -0000\r\nX-Received: from [66.218.69.4] by t1.bullet.sp1.yahoo.com with NNFMP; 19 Mar 2008 07:07:10 -0000\r\nX-Received: from [66.218.66.90] by t4.bullet.scd.yahoo.com with NNFMP; 19 Mar 2008 07:07:10 -0000\r\nDate: Wed, 19 Mar 2008 07:07:09 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frqe2t+lvrt@...&gt;\r\nIn-Reply-To: &lt;frp1im+ekjc@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=QGvFFUlckSMuPmzn9RF3_e2FCOABVnrMIzi1IPCHtRDUOFyzVw2b\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nAndy, I fully appreciate your enthusiasm for engineering optimization \nand =\r\noperations research.  In fact, I am not unaware of this area and \nhave look=\r\ned into &quot;physics-based surrogate models.&quot;  Here is a nice \npaper on the sub=\r\nject:\n\nhttp://www.cs.sandia.gov/DAKOTA/papers/OUU_MAO2004.pdf\n\nNevertheless=\r\n, I still see no concrete connection to HyperNEAT other \nthan the fact that=\r\n HyperNEAT (like any machine learning algorithm) \nwill undoubtedly sometime=\r\ns need to be applied to a domain that is \nbest modeled by a surrogate.  It =\r\nappears I am unlikely to see the \ndeeper connection so perhaps it is not im=\r\nportant to belabor it \nfurther.  It is very possible others have internaliz=\r\ned your point \nbetter and that your efforts at promoting your view will the=\r\nrefore \nlead to productive explorations.\n\nIn any case, at least we are agre=\r\ned that challenges remain in all of \nmachine learning, including for HyperN=\r\nEAT.  The exciting opportunity \nis to meet these challenges with new ideas.=\r\n  Perhaps novel \nhybridizations will answer some challenges; perhaps in oth=\r\ner cases it \nwill be something else.  What is great for all of us is that b=\r\ny \npursuing the paths we individually favor, even if they differ, we are \ne=\r\nxpanding the diversity of options for everyone in the future.  So \nlet us e=\r\nncourage each other to follow our instincts to their most \npromising ends. =\r\n \n\nken\n\n--- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@...&gt; wrote:\n&gt;\n&gt; To t=\r\nhe motivated and intellectually honest, I contend that prior \n&gt; references =\r\nand explanations are sufficient for discovery and \n&gt; understanding.\n&gt; \n&gt; Th=\r\nat said, no reference has been made to disfavor discovery of \n&gt; patterns. I=\r\nn the context of engineering optimization/search, your \n&gt; predisposition an=\r\nd creation of hyperneat could be viewed as the \n&gt; analogous equivalent of s=\r\neeking a physics-based surrogate model, \n&gt; though for differing reasons.\n&gt; =\r\n\n&gt; Perhaps within the confines of your area of expertise, this concept \n&gt; i=\r\ns novel, as it appears from your statements. But in the larger \n&gt; landscape=\r\n of engineering optimization/search, there is an entire \n&gt; branch of resear=\r\nch associated with surrogate-based models and \n&gt; optimization/search. Which=\r\n, btw, if you take the opportunity to \n&gt; review what the other guys are doi=\r\nng outside of your area of \n&gt; expertise (i.e. previously provided reference=\r\n), I believe it may \neven \n&gt; facilitate your endeavors. And at the very lea=\r\nst, it would help to \n&gt; convey an impression of genuine motivation to disco=\r\nver, rather than \n&gt; a &quot;not invented here&quot; mentality.\n&gt; \n&gt; It is difficult t=\r\no see the utility of expending the energy of \n&gt; explanation, when it appear=\r\ns that you are entangled in the \nconflicts \n&gt; and differences of opinions w=\r\nithin the differing niches of AI, \nseemly \n&gt; unable to take a step back to =\r\nget a perspective which includes more \n&gt; than these differing niches.\n&gt; \n&gt; =\r\nIn a nutshell:\n&gt; a) Multi-discipline: seemly self-evident, simultaneous or =\r\nstaged, \n&gt; analogous to multiple differing vocabularies and syntax.\n&gt; b) Mu=\r\nlti-Objective: simultaneous, multiple arbitrary hyperspaces of \n&gt; arbitrary=\r\n sub-sets of input parameter dimensionalities.\n&gt; c) Linear equality/inequal=\r\nity feasibility constraints: seemly self-\n&gt; evident, multiple arbitrary dis=\r\ncrete values and/or ranges of \n&gt; acceptable values of arbitrary input param=\r\neters.\n&gt; d) Non-linear equality/inequality feasibility constraints: multipl=\r\ne \n&gt; arbitrary discrete values and/or ranges of acceptable values of \n&gt; mul=\r\ntiple arbitrary hyperspaces of arbitrary sub-sets of input \n&gt; parameter dim=\r\nensionalities.\n&gt; \n&gt; That said, your predisposition of endeavor appears to b=\r\ne the \n&gt; discovery of a global pattern (with or w/o variation/elaboration),=\r\n \n&gt; associated with a given objective hyperspace.\n&gt; \n&gt; The fundamental prob=\r\nlem is that, subsequent to whatever means are \n&gt; utilized to apply the arbi=\r\ntrary feasibility constraints (i.e. &quot;c&quot; \n&gt; and &quot;d&quot; above), what&#39;s left of t=\r\nhe given objective function \n&gt; landscape &quot;as-delivered&quot; to the EA process, =\r\nwill be difficult or \n&gt; perhaps impossible to identify a global pattern of =\r\nthe specific \n&gt; objective (i.e. &quot;ARBITRARY&quot; feasibility constraints).\n&gt; \n&gt; =\r\nThe issue then becomes one of economy. How much computational \n&gt; resources =\r\nshould be expended for the sole purpose of discovery of \n&gt; a &quot;GLOBAL&quot; patte=\r\nrn (w/ or w/o variation/elaboration) of a given \n&gt; objective of a multi-obj=\r\nective problem?\n&gt; \n&gt; It soon becomes evident that it is more computationall=\r\ny feasible to \n&gt; accept &quot;REGIONAL&quot; patterns/correlations/curve-fits.\n&gt; \n&gt; T=\r\nhis is one of the reasons there is an entire research area \n&gt; associated w/=\r\n surrogate-based models and optimization/search. In \nyour \n&gt; field you appe=\r\nar to refer to it as &quot;representation&quot;.\n&gt; \n&gt; No reference has been made to d=\r\nisfavor use or applicability of EA \nfor \n&gt; determination of pareto front so=\r\nlution sets. On the contrary, they \n&gt; are favored and well suited for this =\r\napplication. The issue was \nthat \n&gt; the computational resources required fo=\r\nr pareto front determination \n&gt; only magnifies/multiplies the computational=\r\n costs issues associated \n&gt; with EA methodologies. \n&gt; \n&gt; Furthermore, it is=\r\n self-evident that the application of a given set \n&gt; of weights to a multio=\r\nbjective problem to transform it to a mono-\n&gt; objective problem (i.e. NEAT)=\r\n, the solution of which constitutes \nonly \n&gt; a single point of a pareto fro=\r\nnt solution set.\n&gt; \n&gt; Simply put, the utility of stove-pipe focus on discov=\r\nery of global \n&gt; patterns on mono-objective problems w/o application of arb=\r\nitrary \n&gt; feasibility constraints is marginal at best. And inapplicable to =\r\n\nreal \n&gt; world problems at worst.\n&gt; \n&gt; IMHO, I believe your endevor associa=\r\nted with &quot;representation&quot;, \nwould \n&gt; be well served by a review of surrogat=\r\ne-based \n&gt; models/optimization/search. But then, that may not be considered=\r\n \n&gt; a &quot;breakthrough&quot;.\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley=\r\n&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Andy, maybe you can provide an example of &quot;non=\r\n-linear inequality \n&gt; &gt; feasibility constraints&quot; that &quot;utterly destroy&quot; pat=\r\nterns and \n&gt; &gt; regularities? \n&gt; &gt; \n&gt; &gt; I think most people would agree that=\r\n many practical problems \n&gt; involve \n&gt; &gt; some kind of pattern.  The human b=\r\nrain itself is filled with \n&gt; &gt; spectacular examples of neural patterns, bo=\r\nth spatially and \n&gt; &gt; temporally.   Is the human brain &quot;utterly destroyed&quot; =\r\nby &quot;non-\nlinear \n&gt; &gt; inequality feasibility constraints?&quot;\n&gt; &gt; \n&gt; &gt; I get yo=\r\nur broader point, though.  You&#39;re saying that I&#39;m getting \na \n&gt; &gt; distorted=\r\n perspective because I&#39;m conentrating on patterns when \n&gt; &gt; there are other=\r\n factors in the world than just patterns.  Yet we \n&gt; &gt; cannot expect every =\r\nnew algorithm to simultaneously address every \n&gt; &gt; challenge faced by man. =\r\n Any researcher who would try to do that \n&gt; &gt; would never get anywhere.  Wi=\r\nth HyperNEAT we have taken a step in \na \n&gt; &gt; promising direction; no more, =\r\nno less.  If you feel it should be \n&gt; &gt; expanded to take into account addit=\r\nional particular concerns that \n&gt; &gt; you have (which for me are still fuzzy)=\r\n, I encourage you to \nextend \n&gt; &gt; it in that direction.  \n&gt; &gt; \n&gt; &gt; I think =\r\nyour quote from Einstein is delivered in entirely the \nwrong \n&gt; &gt; context. =\r\n The problem of representation is largely ignored by the \n&gt; &gt; machine learn=\r\ning community because it *is* the difficult part.  \n&gt; &gt; The &quot;thin part of t=\r\nhe wood&quot; is the minutia of gradient \n&gt; optimization, \n&gt; &gt; which have been b=\r\neaten to death; yet scientists to this day still \n&gt; &gt; focus on it intently.=\r\n  The reason they do that is because it&#39;s \nthe \n&gt; &gt; easy part, not the hard=\r\n part.  It is easy to climb a hill once \nyou \n&gt; &gt; see it; it is hard to mov=\r\ne the hill itself.  Representation means \n&gt; &gt; moving the hills.  I believe =\r\nEinstein would have no objection to \n&gt; &gt; rearranging the intellectual lands=\r\ncape.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.=\r\ncarl@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Ken,\n&gt; &gt; &gt; \n&gt; &gt; &gt; I can appreciate the need to ch=\r\noose applications &quot;with careful \n&gt; &gt; &gt; scrutiny with a sincere belief in th=\r\neir practical \nramifications&quot;, \n&gt; &gt; but \n&gt; &gt; &gt; the simple truth is that you=\r\nr bias for exploring &quot;patterns and \n&gt; &gt; &gt; regularities&quot;, are utterly destro=\r\nyed by the application of non-\n&gt; &gt; linear \n&gt; &gt; &gt; inequality feasibility con=\r\nstraints. Which routinely happens in \n&gt; the \n&gt; &gt; &gt; domain of engineering op=\r\ntimization/search. \n&gt; &gt; &gt; \n&gt; &gt; &gt; Your operation without the application of =\r\nthe pressures \n&gt; associated \n&gt; &gt; &gt; with these pattern destroying influences=\r\n results in a \nunrealistic \n&gt; &gt; &gt; perspective on the utility of global patt=\r\nern exploitation, and \na \n&gt; &gt; &gt; failure to address the repercussions of the=\r\n sometimes seemingly \n&gt; &gt; &gt; totally arbitrary nature of enforced feasibilit=\r\ny constraints \n&gt; &gt; dictated \n&gt; &gt; &gt; by real-world problems.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Unt=\r\nil you can simultaneously address the exploitation of \nmultiple \n&gt; &gt; &gt; hype=\r\nrspace &quot;regional/sub-volume&quot; patterns/regularities overlaid \n&gt; &gt; with \n&gt; &gt; =\r\n&gt; multiple arbitrary non-linear inequality feasibility \nconstraints, \n&gt; &gt; i=\r\nn \n&gt; &gt; &gt; a computationally practical manner, methodologies such as \n&gt; &gt; Hyp=\r\nerneat \n&gt; &gt; &gt; will be dispatched as &quot;curiosities&quot; only.\n&gt; &gt; &gt; \n&gt; &gt; &gt; These =\r\nkinds of pressures are routinely addressed in the domain \nof \n&gt; &gt; &gt; enginee=\r\nring optimization/search. Your choice of side-stepping \n&gt; &gt; these \n&gt; &gt; &gt; in=\r\nfluences shapes what infrastructure is and is-not developed, \nas \n&gt; &gt; has \n=\r\n&gt; &gt; &gt; been adequately addressed in prior posts.\n&gt; &gt; &gt; \n&gt; &gt; &gt; An applicable =\r\nquote: &quot;I have little patience with scientists \nwho \n&gt; &gt; take \n&gt; &gt; &gt; a boar=\r\nd of wood, look for its thinnest part, and drill a great \n&gt; &gt; number \n&gt; &gt; &gt;=\r\n of holes where drilling is easy.&quot;--Albert Einstein\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In nea=\r\nt@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; \nwrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; An=\r\ndy, I have no problem with the idea of NEAT as a foundation \n&gt; &gt; upon\n&gt; &gt; &gt;=\r\n &gt; which to build.  That&#39;s perfectly aligned with my view that \n&gt; &gt; there i=\r\ns\n&gt; &gt; &gt; &gt; more yet to accomplish.  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Let me respond to some=\r\n of your specific points below.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@...=\r\nm, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; The issues you =\r\nraise, though valid, appear disingenuous for \n&gt; &gt; two \n&gt; &gt; &gt; &gt; &gt; reasons. F=\r\nirst, if you had reviewed the contents and \n&gt; &gt; capabilities \n&gt; &gt; &gt; of \n&gt; &gt;=\r\n &gt; &gt; &gt; the Dakota toolkit, you would have discovered the issues as \n&gt; &gt; bei=\r\nng \n&gt; &gt; &gt; &gt; &gt; essentially addressed. Second, not intending any \ndisrespect,=\r\n \n&gt; &gt; from \n&gt; &gt; &gt; &gt; &gt; external appearances, your efforts appear directed in=\r\n other \n&gt; &gt; &gt; &gt; &gt; directions than that of addressing your self admitted are=\r\nas \n&gt; of \n&gt; &gt; &gt; &gt; &gt; concern.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; From a review of literatu=\r\nre on the subject, there is a \ncommon \n&gt; &gt; &gt; &gt; &gt; understanding that EA is c=\r\nomputationally expensive and slow \n&gt; to \n&gt; &gt; &gt; &gt; &gt; converge, but robust for=\r\n global search in problem domains \n&gt; with \n&gt; &gt; &gt; &gt; &gt; multiple local minima.=\r\n\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; It really just depends who you are talking abo=\r\nut whether \nthere \n&gt; &gt; is a\n&gt; &gt; &gt; &gt; &quot;common understanding&quot; about anything i=\r\nn AI.  It also depends \n&gt; &gt; &gt; whether\n&gt; &gt; &gt; &gt; we are talking about the past=\r\n or the future.  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; For example, it&#39;s often said that &quot;neura=\r\nl networks get caught \n&gt; on \n&gt; &gt; &gt; local\n&gt; &gt; &gt; &gt; optima&quot; (and there is inde=\r\ned a &quot;common understanding&quot; that \nthey \n&gt; &gt; do)\n&gt; &gt; &gt; &gt; but when people say=\r\n that they are almost always only talking \n&gt; &gt; about\n&gt; &gt; &gt; &gt; backprop, whic=\r\nh is just one single neural network learning \n&gt; &gt; &gt; algorithm.\n&gt; &gt; &gt; &gt;  Bac=\r\nkprop is not the only way a neural network can learn.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; The =\r\nproblem is that when we talk about methods in machine \n&gt; &gt; learning \n&gt; &gt; &gt; =\r\nwe\n&gt; &gt; &gt; &gt; often confuse whether we are talking about a *field* or a \n&gt; &gt; p=\r\narticular\n&gt; &gt; &gt; &gt; method.  In the case of EAs, you seem to be talking about=\r\n some\n&gt; &gt; &gt; &gt; existing methods that have been analyzed (often by people who=\r\n \n&gt; &gt; are \n&gt; &gt; &gt; not\n&gt; &gt; &gt; &gt; even aware of the most modern approaches) in t=\r\nhe past.   For \n&gt; &gt; &gt; example,\n&gt; &gt; &gt; &gt; the old-fashioned bit-string based s=\r\nimple EA has been analyzed\n&gt; &gt; &gt; &gt; extensively.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Yet as a f=\r\nield, EAs themselves are evolving.  Problems \n&gt; &gt; identified in\n&gt; &gt; &gt; &gt; the=\r\n past are actively being addressed in the present and \n&gt; future. \n&gt; &gt; &gt; Som=\r\ne\n&gt; &gt; &gt; &gt; modern approaches completely overturn the assumptions and \n&gt; &gt; pr=\r\noblems \n&gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; the past (and of course introduce their own new pr=\r\noblems).  \n&gt; &gt; Check \n&gt; &gt; &gt; out\n&gt; &gt; &gt; &gt; Estimation of Distribution Algorith=\r\nms and the CMA-ES:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; http://en.wikipedia.org/wiki/Estimat=\r\nion_of_distribution_algorithm\n&gt; &gt; &gt; &gt; http://en.wikipedia.org/wiki/CMA-ES\n&gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; When I look at EAs, or any research area for that matter, I=\r\n \n&gt; &gt; always\n&gt; &gt; &gt; &gt; think about what they *could* be, rather than what the=\r\ny are.  \n&gt; &gt; And \n&gt; &gt; &gt; as a\n&gt; &gt; &gt; &gt; researcher, I try to make them what th=\r\ney could be.  To me, \nthat \n&gt; &gt; is \n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; exciting thing about =\r\nresearch: At its best, it overturns \n&gt; dogma.  \n&gt; &gt; I\n&gt; &gt; &gt; &gt; like to view =\r\na limitation as a challenge rather than as a \nbrick \n&gt; &gt; &gt; wall.\n&gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; &gt; And that is from people who are working &quot;hard&quot; problems \n(i.e. \n&gt; =\r\n&gt; &gt; multi-\n&gt; &gt; &gt; &gt; &gt; discipline, multiobjective, non-linear inequality \n&gt; c=\r\nonstraints, \n&gt; &gt; &gt; etc.), \n&gt; &gt; &gt; &gt; &gt; at government laboratories and Fortune=\r\n 100 defense firms. \nNot \n&gt; &gt; &gt; dancing \n&gt; &gt; &gt; &gt; &gt; rag-dolls and computer-a=\r\nided art.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; First, while you often cite multiobje=\r\nctive optimization as \n&gt; &gt; a &quot;hard\n&gt; &gt; &gt; &gt; problem&quot; for EAs, in fact some o=\r\nf the most effective \nalgorithms \n&gt; &gt; in\n&gt; &gt; &gt; &gt; multiobjective optimizatio=\r\nn are EAs.  EAs are naturally \nsuited \n&gt; to\n&gt; &gt; &gt; &gt; maintaining a pareto fr=\r\nont because a pareto front requires a\n&gt; &gt; &gt; &gt; population to hold it.  There=\r\n is vast literature on pareto\n&gt; &gt; &gt; &gt; optimization in EAs, both in multiobj=\r\nective optimization and \nin\n&gt; &gt; &gt; &gt; coevolution.  Here are some seminal exa=\r\nmples:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A =\r\nFast and \n&gt; &gt; Elitist\n&gt; &gt; &gt; &gt; Multiobjective Genetic Algorithm: NSGA-II. IE=\r\nEE Transactions \non\n&gt; &gt; &gt; &gt; Evolutionary Computation, 6(2):182=96197, 2002.=\r\n\n&gt; &gt; &gt; &gt; http://citeseer.ist.psu.edu/530140.html\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; De Jong, =\r\nE.D. (2004). The Incremental Pareto-Coevolution \n&gt; Archive.\n&gt; &gt; &gt; &gt; Proceed=\r\nings of the Genetic and Evolutionary Computation \n&gt; &gt; Conference\n&gt; &gt; &gt; &gt; GE=\r\nCCO-04, pp. 525-536. \n&gt; &gt; &gt; &gt; http://people.cs.uu.nl/dejong/publications/ge=\r\ncco04coev.pdf\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; in fact, some of the most brilliant theorist=\r\ns in pareto \n&gt; &gt; optimization\n&gt; &gt; &gt; &gt; are in evolutionary computation.\n&gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; As for NEAT in government research labs on &quot;serious&quot; \nproblems=\r\n, \n&gt; &gt; here \n&gt; &gt; &gt; is\n&gt; &gt; &gt; &gt; an example:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Shimon Whiteson =\r\nand Daniel Whiteson (2007). &quot;Stochastic \n&gt; &gt; Optimization\n&gt; &gt; &gt; &gt; for Colli=\r\nsion Selection in High Energy Physics&quot;. IAAI 2007:\n&gt; &gt; &gt; &gt; Proceedings of t=\r\nhe Nineteenth Annual Innovative Applications \nof\n&gt; &gt; &gt; &gt; Artificial Intelli=\r\ngence Conference.&#8202;\n&gt; &gt; &gt; &gt; http://arxiv.org/PS_cache/hep-ex/pdf/0607/=\r\n0607012v1.pdf\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; The article itself states, &quot;These NEAT selec=\r\ntors are \ncurrently \n&gt; &gt; in \n&gt; &gt; &gt; use\n&gt; &gt; &gt; &gt; at FermiLab for selecting co=\r\nllisions from real data collected\n&gt; &gt; &gt; &gt; with the Tevatron collider.&quot;  So,=\r\n there you go, NEAT is being \n&gt; &gt; used \n&gt; &gt; &gt; at\n&gt; &gt; &gt; &gt; FermiLab itself to=\r\n select which particle collisions are most \n&gt; &gt; &gt; promising.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; When you mention rag dolls and art, you&#39;re giving me an \n&gt; &gt; opportunity=\r\n \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; comment on some of our own current research.  Our group =\r\nhas \n&gt; &gt; indeed\n&gt; &gt; &gt; &gt; recently produced a number of works in interactive =\r\nevolution,\n&gt; &gt; &gt; &gt; including dance, art, music, and particle effects.  Perh=\r\naps \nit \n&gt; &gt; may\n&gt; &gt; &gt; &gt; seem a somewhat lighthearted departure from more s=\r\nerious \n&gt; &gt; subjects.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Yet the implications of this work ar=\r\ne as serious as any in my \n&gt; &gt; view. \n&gt; &gt; &gt; &gt; All of that work is a probe o=\r\nf the ubiquity of patterns and\n&gt; &gt; &gt; &gt; regularities, in particular through =\r\nthe theory of CPPNs.  The \n&gt; &gt; deeper\n&gt; &gt; &gt; &gt; lesson in that body of work i=\r\ns that the very same encoding is \n&gt; &gt; able \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; produce patter=\r\nns appropriate to what would otherwise appear \nto \n&gt; be\n&gt; &gt; &gt; &gt; disparate d=\r\nomains.  The idea is to develop a theory of \ngeneric \n&gt; &gt; &gt; pattern\n&gt; &gt; &gt; &gt;=\r\n generation and to show that patterns are interchangeable \nacross \n&gt; &gt; many=\r\n\n&gt; &gt; &gt; &gt; domains.  That insight leads to the idea of HyperNEAT, which \n&gt; &gt; =\r\ntakes\n&gt; &gt; &gt; &gt; again the very same encoding that is producing art and music =\r\n\n&gt; and \n&gt; &gt; &gt; uses\n&gt; &gt; &gt; &gt; it to produce a large-scale neural pattern.  The=\r\nrein it \nbecomes\n&gt; &gt; &gt; &gt; serious, because the hard problems you like to foc=\r\nus on \nalmost \n&gt; &gt; &gt; always\n&gt; &gt; &gt; &gt; involve patterns and regularities.  \n&gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; It is no accident that in building a theory of pattern \n&gt; &gt; =\r\ngeneration, a\n&gt; &gt; &gt; &gt; number of interactive evolutionary computation experi=\r\nments \n&gt; would \n&gt; &gt; &gt; need\n&gt; &gt; &gt; &gt; to be performed because understanding th=\r\ne capabilities of a \n&gt; &gt; pattern\n&gt; &gt; &gt; &gt; generator require *exploring* the =\r\nspace of possibilities \nrather \n&gt; &gt; than\n&gt; &gt; &gt; &gt; simply optimizing, and hum=\r\nans are much better explorers than\n&gt; &gt; &gt; &gt; computers.  The theory would nev=\r\ner have gotten off the ground \n&gt; if \n&gt; &gt; we\n&gt; &gt; &gt; &gt; had stuck to more tradi=\r\ntional optimization problems.   \nIndeed, \n&gt; as\n&gt; &gt; &gt; &gt; funny as it sounds, =\r\nthe whole idea began to materialize only \n&gt; &gt; after I\n&gt; &gt; &gt; &gt; evolved a spa=\r\nceship in Mattias Fagerlund&#39;s DelphiNEAT.  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; To put it star=\r\nkly, without that exploration in genetic art, \n&gt; there\n&gt; &gt; &gt; &gt; would have b=\r\neen no HyperNEAT.  And in fact even more new \n&gt; &gt; theories \n&gt; &gt; &gt; with\n&gt; &gt; =\r\n&gt; &gt; practical implications are coming (not yet published) because \nof\n&gt; &gt; &gt;=\r\n &gt; phenomena that became apparent through Picbreeder.  So you \nsee, \n&gt; &gt; in=\r\n\n&gt; &gt; &gt; &gt; building a new algorithm or a new theory with practical \n&gt; &gt; &gt; imp=\r\nlications,\n&gt; &gt; &gt; &gt; often traditional problems are exactly the wrong vehicle=\r\n to \n&gt; &gt; &gt; discovery\n&gt; &gt; &gt; &gt; because they perpetuate the same dogmatic pers=\r\npectives that \n&gt; &gt; already\n&gt; &gt; &gt; &gt; permeate the field to begin with and cau=\r\nse it to be staying \nin \n&gt; &gt; one\n&gt; &gt; &gt; &gt; place.   Thus all of these applica=\r\ntions are chosen with \ncareful\n&gt; &gt; &gt; &gt; scrutiny with a sincere belief in th=\r\neir practical \nramifications.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Not to mention the fact that=\r\n interactive evolution itself has \n&gt; the\n&gt; &gt; &gt; &gt; practical potential to cha=\r\nnge the way we do engineering in \nsome \n&gt; &gt; &gt; cases.\n&gt; &gt; &gt; &gt;  Can you imagi=\r\nne Picbreeder for furinute instead of \npictures?  \n&gt; &gt; Or \n&gt; &gt; &gt; for\n&gt; &gt; &gt; =\r\n&gt; cars?  Someday that may be how we create highly customized \n&gt; &gt; &gt; artifac=\r\nts.\n&gt; &gt; &gt; &gt;    In fact, some of the problems to which you are referring \n&gt; =\r\n&gt; (highly\n&gt; &gt; &gt; &gt; nonlinear and multi-objective) may only be possible to so=\r\nlve \n&gt; &gt; through\n&gt; &gt; &gt; &gt; interactive evolution.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; How many=\r\n times has NEAT, as a monolithic approach, been \ncited \n&gt; &gt; and \n&gt; &gt; &gt; &gt; &gt; =\r\nsuccessfully applied by government laboratories and Fortune \n&gt; &gt; 100 \n&gt; &gt; &gt;=\r\n &gt; &gt; defense firms for these type of &quot;hard&quot; problems?\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; You can refer to the paper on high-energy physics at FermiLab \nif\n&gt; =\r\n&gt; &gt; &gt; you&#39;re interested, but I still think there is a bigger \n&gt; picture.  \n=\r\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; In some ways, as researchers in AI, what practitioners are=\r\n \n&gt; using \n&gt; &gt; to\n&gt; &gt; &gt; &gt; solve hard problems is exactly what we *don&#39;t* wa=\r\nnt to use.  \n&gt; &gt; After\n&gt; &gt; &gt; &gt; all, how is anything ever going to become mo=\r\nre powerful if we \n&gt; &gt; just\n&gt; &gt; &gt; &gt; look to practitioners to show us what m=\r\nethods we should be \n&gt; &gt; using?  \n&gt; &gt; &gt; As\n&gt; &gt; &gt; &gt; researchers, it is our j=\r\nob to give the practitioners *new* \n&gt; &gt; options,\n&gt; &gt; &gt; &gt; not the other way =\r\naround.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Practitioners are often several steps behind algor=\r\nithm \n&gt; &gt; developers, \n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; with good reason.  They often can&#39;=\r\nt afford to take big risks \n&gt; and \n&gt; &gt; &gt; need\n&gt; &gt; &gt; &gt; something practical i=\r\nn the here and now.   You will therefore \n&gt; &gt; find\n&gt; &gt; &gt; &gt; that most cuttin=\r\ng-edge algorithms are not in use in industry \nor \n&gt; &gt; as\n&gt; &gt; &gt; &gt; tools in o=\r\nther scientific disciplines at the very moment that \n&gt; &gt; they \n&gt; &gt; &gt; are\n&gt; =\r\n&gt; &gt; &gt; cutting-edge.  Yet someone has to be developing the \nalgorithms \n&gt; &gt; =\r\nof \n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; future.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}