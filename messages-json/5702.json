{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":159465226,"authorName":"Matthew_Hausknecht","from":"&quot;Matthew_Hausknecht&quot; &lt;matthew_hausknecht@...&gt;","profile":"Matthew_Hausknecht","replyTo":"LIST","senderId":"hNAEk11-SqVJzQ1aF0Bf27jQvinSAvZ1i_v5wHe3gA9rXr8wE-5sQQgXH-PIYfFwlblM8EkdUx2wpHiOku2RuoOd9TOfmy8yAhFQnkAUpXYGisR-Kuqp3HUU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Hyperneat Network Output Layer All Zero","postDate":"1321923024","msgId":5702,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGphZXJrZyttbDNhQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDFGRUZCQTUwLTJDNjItNDg3OS1CMTYwLUMyRTlBM0QxMTVDMUBjb3JuZWxsLmVkdT4="},"prevInTopic":5701,"nextInTopic":5703,"prevInTime":5701,"nextInTime":5703,"topicId":5699,"numMessagesInTopic":7,"msgSnippet":"Thanks for the suggestions Jeff. In my case I have only one layer of hidden nodes. When printing them out for debugging purposes they are all zero after update","rawEmail":"Return-Path: &lt;matthew_hausknecht@...&gt;\r\nX-Sender: matthew_hausknecht@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 70787 invoked from network); 22 Nov 2011 00:50:25 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m8.grp.sp2.yahoo.com with QMQP; 22 Nov 2011 00:50:25 -0000\r\nX-Received: from unknown (HELO n38b.bullet.mail.sp1.yahoo.com) (66.163.168.152)\n  by mta4.grp.sp2.yahoo.com with SMTP; 22 Nov 2011 00:50:25 -0000\r\nX-Received: from [69.147.65.150] by n38.bullet.mail.sp1.yahoo.com with NNFMP; 22 Nov 2011 00:50:25 -0000\r\nX-Received: from [98.137.34.119] by t7.bullet.mail.sp1.yahoo.com with NNFMP; 22 Nov 2011 00:50:25 -0000\r\nDate: Tue, 22 Nov 2011 00:50:24 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;jaerkg+ml3a@...&gt;\r\nIn-Reply-To: &lt;1FEFBA50-2C62-4879-B160-C2E9A3D115C1@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Matthew_Hausknecht&quot; &lt;matthew_hausknecht@...&gt;\r\nSubject: Re: Hyperneat Network Output Layer All Zero\r\nX-Yahoo-Group-Post: member; u=159465226; y=9lA0pZ3BiRoohgNgLgRHVPAj6RIcK0q0N89u3VkFSPsST3WFeg6n_TY0nttQ\r\nX-Yahoo-Profile: Matthew_Hausknecht\r\n\r\nThanks for the suggestions Jeff. In my case I have only one layer of hidden=\r\n nodes. When printing them out for debugging purposes they are all zero aft=\r\ner update is called (also tried calling update multiple times with no succe=\r\nss). \n\n--- In neat@yahoogroups.com, Jeff Clune &lt;jeffclune@...&gt; wrote:\n&gt;\n&gt; H=\r\nello. Make sure you are doing enough updates of the phenotype neural net to=\r\n propagate the info all the way through the network....for debugging you ma=\r\ny wish to print out the values of the first hidden layer after one update..=\r\n.and possibly the values at each hidden layer after each update...so you ca=\r\nn see what is going on. Or just make sure to have the number of updates be =\r\ngreater than or equal to the number of hidden layers. That might not be you=\r\nr issue, but that is a common mistake. \n&gt; \n&gt; \n&gt; Best regards,\n&gt; Jeff Clune\n=\r\n&gt; \n&gt; Postdoctoral Fellow\n&gt; Hod Lipson&#39;s Creative Machines Laboratory\n&gt; Corn=\r\nell University\n&gt; jeffclune@...\n&gt; jeffclune.com\n&gt; \n&gt; On Nov 21, 2011, at 5:5=\r\n7 PM, Matthew_Hausknecht wrote:\n&gt; \n&gt; &gt; Hi, I&#39;m trying to run Hyperneat on a=\r\n simple Atari game and was starting out by replicating some of the experime=\r\nnt examples. My code compiles and runs, but the value of the output node in=\r\n the network always seems to be zero. I suspect I am doing something wrong =\r\nin the initalization/update step, but I&#39;m not sure what... Code is as follo=\r\nws:\n&gt; &gt; \n&gt; &gt; #include &quot;HCUBE_Defines.h&quot;\n&gt; &gt; \n&gt; &gt; #include &quot;Experiments/HCUB=\r\nE_AtariExperiment.h&quot;\n&gt; &gt; #include &lt;boost/foreach.hpp&gt;\n&gt; &gt; \n&gt; &gt; using namesp=\r\nace NEAT;\n&gt; &gt; \n&gt; &gt; enum GamePositionValue {\n&gt; &gt; EMPTY,\n&gt; &gt; CHICKEN,\n&gt; &gt; VEH=\r\nICLE\n&gt; &gt; };\n&gt; &gt; \n&gt; &gt; namespace HCUBE\n&gt; &gt; {\n&gt; &gt; AtariExperiment::AtariExperi=\r\nment(string _experimentName,int _threadID):\n&gt; &gt; Experiment(_experimentName,=\r\n_threadID)\n&gt; &gt; {\n&gt; &gt; layerInfo =3D NEAT::LayeredSubstrateInfo();\n&gt; &gt; layerI=\r\nnfo.layerSizes.push_back(Vector2&lt;int&gt;(8,8));\n&gt; &gt; layerInfo.layerIsInput.pus=\r\nh_back(true);\n&gt; &gt; layerInfo.layerLocations.push_back(Vector3&lt;float&gt;(0,0,0))=\r\n;\n&gt; &gt; layerInfo.layerNames.push_back(&quot;Input&quot;);\n&gt; &gt; \n&gt; &gt; layerInfo.layerSize=\r\ns.push_back(Vector2&lt;int&gt;(8,8));\n&gt; &gt; layerInfo.layerIsInput.push_back(false)=\r\n;\n&gt; &gt; layerInfo.layerLocations.push_back(Vector3&lt;float&gt;(0,4,0));\n&gt; &gt; layerI=\r\nnfo.layerNames.push_back(&quot;Output&quot;);\n&gt; &gt; \n&gt; &gt; layerInfo.layerAdjacencyList.p=\r\nush_back(std::pair&lt;string,string&gt;(&quot;Input&quot;,&quot;Output&quot;));\n&gt; &gt; \n&gt; &gt; layerInfo.no=\r\nrmalize =3D true;\n&gt; &gt; layerInfo.useOldOutputNames =3D false;\n&gt; &gt; layerInfo.=\r\nlayerValidSizes =3D layerInfo.layerSizes;\n&gt; &gt; \n&gt; &gt; substrate =3D NEAT::Laye=\r\nredSubstrate&lt;float&gt;();\n&gt; &gt; substrate.setLayerInfo(layerInfo);\n&gt; &gt; }\n&gt; &gt; \n&gt; =\r\n&gt; NEAT::GeneticPopulation* AtariExperiment::createInitialPopulation(int pop=\r\nulationSize) {\n&gt; &gt; GeneticPopulation *population =3D new GeneticPopulation(=\r\n);\n&gt; &gt; vector&lt;GeneticNodeGene&gt; genes;\n&gt; &gt; \n&gt; &gt; genes.push_back(GeneticNodeG=\r\nene(&quot;Bias&quot;,&quot;NetworkSensor&quot;,0,false));\n&gt; &gt; genes.push_back(GeneticNodeGene(&quot;=\r\nX1&quot;,&quot;NetworkSensor&quot;,0,false));\n&gt; &gt; genes.push_back(GeneticNodeGene(&quot;X2&quot;,&quot;Ne=\r\ntworkSensor&quot;,0,false));\n&gt; &gt; genes.push_back(GeneticNodeGene(&quot;Y1&quot;,&quot;NetworkSe=\r\nnsor&quot;,0,false));\n&gt; &gt; genes.push_back(GeneticNodeGene(&quot;Y2&quot;,&quot;NetworkSensor&quot;,0=\r\n,false));\n&gt; &gt; genes.push_back(GeneticNodeGene(&quot;Output&quot;,&quot;NetworkOutputNode&quot;,=\r\n1,false,ACTIVATION_FUNCTION_SIGMOID));\n&gt; &gt; \n&gt; &gt; for (int a=3D0;a&lt;population=\r\nSize;a++) {\n&gt; &gt; shared_ptr&lt;GeneticIndividual&gt; individual(new GeneticIndivid=\r\nual(genes,true,1.0));\n&gt; &gt; for (int b=3D0;b&lt;0;b++) {\n&gt; &gt; individual-&gt;testMut=\r\nate();\n&gt; &gt; }\n&gt; &gt; population-&gt;addIndividual(individual);\n&gt; &gt; }\n&gt; &gt; \n&gt; &gt; cout=\r\n &lt;&lt; &quot;Finished creating population&#92;n&quot;;\n&gt; &gt; return population;\n&gt; &gt; }\n&gt; &gt; \n&gt; &gt;=\r\n void AtariExperiment::populateSubstrate(shared_ptr&lt;NEAT::GeneticIndividual=\r\n&gt; individual) {\n&gt; &gt; if (currentSubstrateIndividual =3D=3D individual)\n&gt; &gt; r=\r\neturn;\n&gt; &gt; \n&gt; &gt; currentSubstrateIndividual =3D individual;\n&gt; &gt; substrate.po=\r\npulateSubstrate(individual);\n&gt; &gt; }\n&gt; &gt; \n&gt; &gt; void AtariExperiment::processGr=\r\noup(shared_ptr&lt;NEAT::GeneticGeneration&gt; generation)\n&gt; &gt; {\n&gt; &gt; shared_ptr&lt;NE=\r\nAT::GeneticIndividual&gt; individual =3D group.front();\n&gt; &gt; //You get 10 point=\r\ns just for being processed, wahooo!\n&gt; &gt; individual-&gt;setFitness(10);\n&gt; &gt; pop=\r\nulateSubstrate(individual);\n&gt; &gt; runAtariEpisode(individual);\n&gt; &gt; }\n&gt; &gt; \n&gt; &gt;=\r\n void AtariExperiment::runAtariEpisode(shared_ptr&lt;NEAT::GeneticIndividual&gt; =\r\nindividual) {\n&gt; &gt; GamePositionValue gameState[8][8];\n&gt; &gt; \n&gt; &gt; int chic_x =\r\n=3D 4, chic_y =3D 7;\n&gt; &gt; float total_reward =3D 0.0;\n&gt; &gt; \n&gt; &gt; // Initialize=\r\n Game\n&gt; &gt; for (int x=3D0;x&lt;8;x++) {\n&gt; &gt; for (int y=3D0;y&lt;8;y++) {\n&gt; &gt; gameS=\r\ntate[x][y] =3D EMPTY;\n&gt; &gt; }\n&gt; &gt; }\n&gt; &gt; gameState[chic_x][chic_y] =3D CHICKEN=\r\n;\n&gt; &gt; \n&gt; &gt; // Run simulation for t timesteps\n&gt; &gt; int num_timesteps =3D 10;\n=\r\n&gt; &gt; for (int t=3D0; t&lt;num_timesteps; t++) {\n&gt; &gt; substrate.getNetwork()-&gt;rei=\r\nnitialize();\n&gt; &gt; substrate.getNetwork()-&gt;dummyActivation();\n&gt; &gt; \n&gt; &gt; // Set=\r\n substrate values\n&gt; &gt; for (int x=3D0; x&lt;8; ++x) {\n&gt; &gt; for (int y=3D0; y&lt;8; =\r\n++y) {\n&gt; &gt; // if (gameState[x][y] =3D=3D CHICKEN) {\n&gt; &gt; // substrate.setVal=\r\nue((Node(x,y,0)), 1.0);\n&gt; &gt; // } else if (gameState[x][y] =3D=3D VEHICLE) {=\r\n\n&gt; &gt; // substrate.setValue((Node(x,y,0)), -1.0); \n&gt; &gt; // } else {\n&gt; &gt; // su=\r\nbstrate.setValue((Node(x,y,0)), 0.0); \n&gt; &gt; // }\n&gt; &gt; substrate.setValue((Nod=\r\ne(x,y,0)), (float)((7.0-y)/7.0));\n&gt; &gt; }\n&gt; &gt; }\n&gt; &gt; \n&gt; &gt; substrate.getNetwork=\r\n()-&gt;update();\n&gt; &gt; \n&gt; &gt; for (int x=3D0; x&lt;8; ++x) {\n&gt; &gt; for (int y=3D0; y&lt;8;=\r\n ++y) {\n&gt; &gt; float val =3D substrate.getValue((Node(x,y,1)));\n&gt; &gt; if (val !=\r\n=3D 0)\n&gt; &gt; printf(&quot;Got Nonzero val %f at %d,%d&#92;n&quot;,val,x,y);\n&gt; &gt; }\n&gt; &gt; }\n&gt; &gt;=\r\n float chicken_val =3D substrate.getValue((Node(chic_x,chic_y,1)));\n&gt; &gt; flo=\r\nat down_val =3D (chic_y =3D=3D 7) ? chicken_val : substrate.getValue((Node(=\r\nchic_x,chic_y+1,1)));\n&gt; &gt; float up_val =3D (chic_y =3D=3D 0) ? chicken_val =\r\n: substrate.getValue((Node(chic_x,chic_y-1,1)));\n&gt; &gt; \n&gt; &gt; int action;\n&gt; &gt; i=\r\nf (chicken_val &gt;=3D up_val) {\n&gt; &gt; if (chicken_val &gt;=3D down_val) {\n&gt; &gt; acti=\r\non =3D 0;\n&gt; &gt; } else {\n&gt; &gt; action =3D +1;\n&gt; &gt; }\n&gt; &gt; } else {\n&gt; &gt; if (up_val=\r\n &gt;=3D down_val) {\n&gt; &gt; action =3D -1;\n&gt; &gt; } else {\n&gt; &gt; action =3D 1;\n&gt; &gt; }\n&gt;=\r\n &gt; }\n&gt; &gt; \n&gt; &gt; // Update game state with action\n&gt; &gt; gameState[chic_x][chic_y=\r\n] =3D EMPTY;\n&gt; &gt; gameState[chic_x][chic_y+action] =3D CHICKEN;\n&gt; &gt; chic_y +=\r\n=3D action;\n&gt; &gt; \n&gt; &gt; // Compute reward\n&gt; &gt; if (chic_y =3D=3D 0) {\n&gt; &gt; total=\r\n_reward +=3D 1.0;\n&gt; &gt; // Reset the sim\n&gt; &gt; gameState[chic_x][chic_y] =3D EM=\r\nPTY;\n&gt; &gt; gameState[chic_x][7] =3D CHICKEN;\n&gt; &gt; chic_y =3D 7;\n&gt; &gt; }\n&gt; &gt; }\n&gt; =\r\n&gt; //cout &lt;&lt; &quot;Got total reward: &quot; &lt;&lt; total_reward &lt;&lt; endl;\n&gt; &gt; individual-&gt;r=\r\neward(total_reward);\n&gt; &gt; }\n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}