{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"giEJ4YT-ZLJZEPBzP-n-Aj1NTDym12xQPjWLaWX7DBfYDRCg2M56oMP_NHZ6jbIYI4FUnKbEaGzgsy1Y6y3cPdFBGq8fSsD1dA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Neural network optimization details","postDate":"1087936319","msgId":1124,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwRDg5NzNGLjgwNDAyMDdAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PDYuMS4wLjYuMC4yMDA0MDYyMjE0NTMwMS4wMjUxNTFiOEBwb3AubWFpbC55YWhvby5jby51az4=","referencesHeader":"PDQwRDVBODkzLjMwODA0MDZAZHNsLnBpcGV4LmNvbT4gPDYuMS4wLjYuMC4yMDA0MDYyMjE0NTMwMS4wMjUxNTFiOEBwb3AubWFpbC55YWhvby5jby51az4="},"prevInTopic":1123,"nextInTopic":1125,"prevInTime":1123,"nextInTime":1125,"topicId":1106,"numMessagesInTopic":7,"msgSnippet":"... cheers :) ... I agree. I even think there s case for reducing the precision further by using integer connection weights and signals. ... I ve read a","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 66422 invoked from network); 22 Jun 2004 20:32:06 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m14.grp.scd.yahoo.com with QMQP; 22 Jun 2004 20:32:06 -0000\r\nReceived: from unknown (HELO pengo.systems.pipex.net) (62.241.160.193)\n  by mta5.grp.scd.yahoo.com with SMTP; 22 Jun 2004 20:32:06 -0000\r\nReceived: from dsl.pipex.com (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby pengo.systems.pipex.net (Postfix) with ESMTP id 8A3C14C00091\n\tfor &lt;neat@yahoogroups.com&gt;; Tue, 22 Jun 2004 21:31:54 +0100 (BST)\r\nMessage-ID: &lt;40D8973F.8040207@...&gt;\r\nDate: Tue, 22 Jun 2004 21:31:59 +0100\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;40D5A893.3080406@...&gt; &lt;6.1.0.6.0.20040622145301.025151b8@...&gt;\r\nIn-Reply-To: &lt;6.1.0.6.0.20040622145301.025151b8@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.160.193\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Neural network optimization details\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nIan Badcoe wrote:\n\n&gt;At 16:09 20/06/2004, you wrote:\n&gt;  \n&gt;\n&gt;&gt;For those following the &#39;computation time&#39; thread I have written up the\n&gt;&gt;details of the optimizations I have performed on my network code along\n&gt;&gt;with some benchmarks. The details are at\n&gt;&gt;http://www.cgreen.dsl.pipex.com/network_optimization.htm\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Hi,\n&gt;\n&gt;That&#39;s very cool!\n&gt;\n&gt;  \n&gt;\ncheers :)\n\n&gt;floats vs doubles:\n&gt;\n&gt;1) I would think float precision is easily enough for NN purposes\n&gt;2) if it isn&#39;t, won&#39;t they evolve to compensate\n&gt;  \n&gt;\nI agree. I even think there&#39;s case for reducing the precision further by \nusing integer connection weights and signals.\n\n&gt;w.r.t the casts, there is another consideration, values kept in the FPU \n&gt;register stack are (almost) always 80bit values, and this is converted down \n&gt;to 64bits or 32bits when it needs writing to memory.  (This can lead to \n&gt;low-bit differences and C compilers have flags to prioritise speed or \n&gt;precision.)\n&gt;  \n&gt;\nI&#39;ve read a /little/ bit about this sort of thing. Apparently you can \nsometimes get slightly different answers to the same expression \ndepending on how the compiler decided to execute it, e.g. if you did the \nsame expression twice in a row then the second one might get put through \nthe SSE registers/FPU which works differently to the main FPU.\n\n&gt;If your compiler will keep an intermediate value on the FPU (I don&#39;t know \n&gt;about Java), then for a complex expression, the best option would be to do \n&gt;all the maths in double, on the FPU, and just finally convert one value \n&gt;back at the end.  That&#39;s not your situation, however, and I don&#39;t see a lot \n&gt;you could do to better your current case.  I don&#39;t think casts on reals are \n&gt;especially slow -- UNLESS, java does a load of range-checking?\n&gt;  \n&gt;\nI&#39;m looking at some dissasembled code and it looks like your right. More \ninvestigation required I recon.\n\n&gt;p.s. Your tanh would be faster if you used the equivalent exp-based \n&gt;expression, I forget what it was but it&#39;s been on the list already.\n&gt;  \n&gt;\nI don&#39;t really underdstand this. Is the exp equiv a loose approximation \nthat is good enough for our purposes or a mathematically proven \nequivalent? If the latter is true then why isn&#39;t this technique used in \nthe .NET math library, since it is much faster?!\n\n\nColin.\n\n\n"}}