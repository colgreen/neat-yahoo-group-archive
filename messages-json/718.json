{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"96gW1gtN-qG01yAyImQfWPR2xtD08dk6waTcgGY681TUkrEswq6jICZqLhJZojf3iy6dzgzKpsG-MapJec0b5OCBzOiiGhC2uA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Re: Warning: Capping the maximum and minimum link weight may be important!","postDate":"1083012826","msgId":718,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwOEQ3NkRBLjgwNDAzMDFAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PDAxNmIwMWM0MmJjZCQxMzI0NDI5MCQzMzAxYThjMEBORVdBR0U+","referencesHeader":"PGM2anBraitmcm9kQGVHcm91cHMuY29tPiA8MDE2YjAxYzQyYmNkJDEzMjQ0MjkwJDMzMDFhOGMwQE5FV0FHRT4="},"prevInTopic":717,"nextInTopic":719,"prevInTime":717,"nextInTime":719,"topicId":672,"numMessagesInTopic":13,"msgSnippet":"... This is a good point. As an example take a look at the XOR network I ... neuron id= 0 type= bias neuron id= 1 type= in neuron id= 2 type= in neuron","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 92741 invoked from network); 26 Apr 2004 20:53:37 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m25.grp.scd.yahoo.com with QMQP; 26 Apr 2004 20:53:37 -0000\r\nReceived: from unknown (HELO colossus.systems.pipex.net) (62.241.160.73)\n  by mta6.grp.scd.yahoo.com with SMTP; 26 Apr 2004 20:53:36 -0000\r\nReceived: from dsl.pipex.com (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby colossus.systems.pipex.net (Postfix) with ESMTP id BBECD1C003A4\n\tfor &lt;neat@yahoogroups.com&gt;; Mon, 26 Apr 2004 21:53:33 +0100 (BST)\r\nMessage-ID: &lt;408D76DA.8040301@...&gt;\r\nDate: Mon, 26 Apr 2004 21:53:46 +0100\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;c6jpkj+frod@...&gt; &lt;016b01c42bcd$13244290$3301a8c0@NEWAGE&gt;\r\nIn-Reply-To: &lt;016b01c42bcd$13244290$3301a8c0@NEWAGE&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.160.73\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Re: Warning: Capping the maximum and minimum link weight\n may be important!\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nJim O&#39;Flaherty, Jr. wrote:\n\n&gt; Ken,\n&gt;  \n&gt; I have been thinking about this particular area.  It is possible that \n&gt; you *do* want those larger values.  They may indicate that a \n&gt; particular feature (or set of features) are specifically higher in \n&gt; priority.  And the elevated weight values are a way for that node (or \n&gt; set of nodes) to drown out noise to refine the &quot;abstraction&quot;.\n&gt;  \n&gt; Now what this *might* mean is that the other weights would be useful \n&gt; to &quot;remove&quot; so there is less need for the weight (or subset of \n&gt; weights) to have their particular values advance so high to compensate \n&gt; for the noise.\n&gt;  \n&gt; If the value range of the weights is clamped, it could produce a less \n&gt; efficient search.  When the weight that would just keep &quot;elevating&quot; \n&gt; hits the cap, to keep it&#39;s relative value to the other weights feeding \n&gt; the node, all the other weights would need to go down proportionally \n&gt; at the same time.  However, the odds of that happening are just about \n&gt; nil.  As such, I sense that that node will start to lose efficacy and \n&gt; the search will wander away from what might have been a &quot;key \n&gt; abstraction&quot; or &quot;feature discovery&quot;.\n&gt;  \n&gt; I cannot prove any of this.  I am just using my intuition here.\n&gt;\n\nThis is a good point. As an example take a look at the XOR network I \nposted a while ago:\n\n------------------------------------------------\n    neuron id=&quot;0&quot; type=&quot;bias&quot;\n    neuron id=&quot;1&quot; type=&quot;in&quot;\n    neuron id=&quot;2&quot; type=&quot;in&quot;\n    neuron id=&quot;3&quot; type=&quot;out&quot;\n\n    connection src-id=&quot;0&quot; tgt-id=&quot;3&quot; weight=&quot;1.64327624043105&quot;\n    connection src-id=&quot;1&quot; tgt-id=&quot;3&quot; weight=&quot;-3.3017311279049&quot;\n    connection src-id=&quot;2&quot; tgt-id=&quot;3&quot; weight=&quot;-3.3025163810043&quot;\n    connection src-id=&quot;3&quot; tgt-id=&quot;3&quot; weight=&quot;-7.44947553716588&quot;\n------------------------------------------------\n\nThe large recurrent connection on neuron 3 &#39;drowns-out&#39; the signals from other connections from the 2nd timestep onwards, and because the activation function had an output range of 0 to 1 the large negative connection weight pulled the output down towards 0.\n\nAn alternative stragegy might be to not cap the connection weights but to periodically normalize the connection weights. That way you allow for the sometimes useful large weights but bring them back into the range that the weight mutation function is designed for. One problem with this approach though would be that the smaller weights in the rest of the network would be reduced to within a tight range - thus reducing the effectiveness of the search.\n\nI think the correct thing to do here would be to perform some statistical analysis of the network weights, if just one or two are large then normalization isn&#39;t required, but if a large proportion of them are then we should normalize to bring them back in line.\n\nColin.\n\n\n\n\n\n"}}