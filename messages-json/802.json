{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"CKikzZYOKyYyIJdp5K7PG3owElJ3qZyBK5aAhscCTBtrc28twk1VFqN-eT1KpLdZ5u2MmTeA9E9hPNDC3qsvg0V4qob9LENVZCg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] If lemurs can do it ..............","postDate":"1084907317","msgId":802,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMS4wLjYuMC4yMDA0MDUxODE2NDg1NS4wMjRmNDkwMEBwb3AubWFpbC55YWhvby5jby51az4=","inReplyToHeader":"PDE3M2U0MDFjNDM5ODMkNWRmOTEzNDAkNjZjYjAxMGFAbWFpbDJ3b3JsZC5jb20+","referencesHeader":"PDE3M2U0MDFjNDM5ODMkNWRmOTEzNDAkNjZjYjAxMGFAbWFpbDJ3b3JsZC5jb20+"},"prevInTopic":779,"nextInTopic":803,"prevInTime":801,"nextInTime":803,"topicId":775,"numMessagesInTopic":14,"msgSnippet":"Can t resist any call to be philosophical :) ... I see what you mean, but to be picky I have to add that decisions are an artificial concept added by the","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 97176 invoked from network); 18 May 2004 19:08:10 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m13.grp.scd.yahoo.com with QMQP; 18 May 2004 19:08:10 -0000\r\nReceived: from unknown (HELO smtp004.mail.ukl.yahoo.com) (217.12.11.35)\n  by mta4.grp.scd.yahoo.com with SMTP; 18 May 2004 19:08:00 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp004.mail.ukl.yahoo.com with SMTP; 18 May 2004 19:07:51 -0000\r\nMessage-Id: &lt;6.1.0.6.0.20040518164855.024f4900@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.1.0.6\r\nDate: Tue, 18 May 2004 20:08:37 +0100\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;173e401c43983$5df91340$66cb010a@...&gt;\r\nReferences: &lt;173e401c43983$5df91340$66cb010a@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Remote-IP: 217.12.11.35\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] If lemurs can do it ..............\r\nX-Yahoo-Group-Post: member; u=7192225\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nCan&#39;t resist any call to be philosophical :)\n\nAt 08:16 14/05/2004, you wrote:\n&gt;I think the topic of memory has a lot of room for philosophical \n&gt;discussion. In fact, I really think it needs more. My understanding of the \n&gt;word &#39;inteligence&#39; is tied to an ability to make decisions.\n\nI see what you mean, but to be picky I have to add that &quot;decisions&quot; are an \nartificial concept added by the observer.  E.g. the lemurs internal state \ndoes not go through a series of defined stages each corresponding to one \ndecision.  Instead it just acts in a certain way when exposed to certain \nstimuli.  There&#39;s no structure in the way it &quot;thinks&quot; corresponding to each \nof the decisions it makes.  In fact, the only reason that the experimenter \ncan observe decisions at all, is because the experiment has been carefully \ndesigned to define an unambiguous result.  A lemur in the wild will be \nperforming a similar (if not identical) type of thought, but other than \n&quot;left fruit or right fruit&quot; it would be hard to watch it with a clipboard \nlisting the decisions it makes.\n\n[[Of course, philosophically you could say that each muscle in the lemur \nhas some degree of tension, say 16bits worth.  So that everything the lemur \ndoes is just a decision, made (say) 100 times a second, about what value to \nset on each bit of each muscle...  But that&#39;s not such a useful view :) ]]\n\n&gt;  A lemur that selects a series of pictures in historical order is \n&gt; interesting in more ways than a display of memory. It was intelligent \n&gt; enough to decide to select the pictures in some particular order, which \n&gt; it happened to be able to remember. I&#39;m more interested in why the lemur \n&gt; decided to select the pictures in order. Can we evolve an ANN that could \n&gt; make that decision?\n\nHmm, I think you may be a little off track here.  The lemur almost \ncertainly did not make the decision to select the pictures.  I&#39;d imagine \nthat the scientist trained it to do so, in return for a reward, probably \nfood.  The lemur did not do something as interesting as: &quot;Here are \npictures.  They are the same pictures as the other pictures.  The order is \ndifferent.  I wonder what happens if I...&quot;\n\nOTOH, if you were just talking about it &quot;deciding&quot; because it noticed it \ngot a reward then I agree with you, even such simple &quot;behaviour&quot; as that is \ninteresting and beyond the state of the art for any machine-based approach.\n\n&gt;  Normally a programmer assumes &#39;of course we can&#39; and we code it to make \n&gt; sure that happens. If we do that, are we developing something \n&gt; intelligent, or putting our intelligence into a program, like a \n&gt; conventional decision making method?\n\nBy a strange coincidence I just read something exactly about that in a book \n(What is Thought by Eric Baum).  He makes the point that a lot of &quot;hard&quot; \ncomputer science and AI problems become hard only because the scientists \nstudying them abstract them too far.  E.g. the scientists take some real \nworld problem, like object recognition, they abstract it to a high degree, \ne.g. by using only B+W images as input, and then they get poor results.  In \nthe real world, people do score well recognising objects from B+W images \nbut also, given poor visibility (as most programs will have in one way or \nanother), people do things like moving their heads from side to side, or \nmoving the light around the object, or even picking it up and rotating \nit.  As an example, he describes an experiment with robots where they could \nnot learn to distinguish cylinders from walls, but they could learn to pick \ncylinders up and drop them over walls.  Abstracting the problem to: First \nRecognize Cylinder was actually harder than trying to evolve a net for the \nwhole task, because the whole-task net relied on observations during its \nentire approach to the cylinder to make the classification.\n\n         Just some philosophy,\n\n                 Ian Badcoe\n\n\n\nLiving@Home - Open Source Evolving Organisms - \nhttp://livingathome.sourceforge.net/\n\n\n\n\n"}}