{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"n1lcC0owx17rMudkwwNOY1bGauT-746KjjjrRTBjfjeFquY4Dt2HaMfHVPIFTgxDm6P54XoEjUoUS3dSgQGKr4b5","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Evolving Substrates in HyperNEAT","postDate":"1209695634","msgId":4032,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM0M0ZGNUQyLjIyOTMzJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGZ2Y3QxZyttYjRlQGVHcm91cHMuY29tPg=="},"prevInTopic":4030,"nextInTopic":4033,"prevInTime":4031,"nextInTime":4033,"topicId":4026,"numMessagesInTopic":10,"msgSnippet":"This is an exhilarating conversation. I really like the ideas that have been expressed. I agree that, in the spirit of complexification, we would want to start","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 7674 invoked from network); 2 May 2008 02:34:31 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m42.grp.scd.yahoo.com with QMQP; 2 May 2008 02:34:31 -0000\r\nX-Received: from unknown (HELO py-out-1112.google.com) (64.233.166.179)\n  by mta17.grp.scd.yahoo.com with SMTP; 2 May 2008 02:34:31 -0000\r\nX-Received: by py-out-1112.google.com with SMTP id w49so1409729pyg.36\n        for &lt;neat@yahoogroups.com&gt;; Thu, 01 May 2008 19:34:28 -0700 (PDT)\r\nX-Received: by 10.35.36.13 with SMTP id o13mr4819993pyj.23.1209695667787;\n        Thu, 01 May 2008 19:34:27 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?192.168.2.2? ( [67.167.130.112])\n        by mx.google.com with ESMTPS id n45sm4169726pyh.29.2008.05.01.19.34.21\n        (version=TLSv1/SSLv3 cipher=OTHER);\n        Thu, 01 May 2008 19:34:26 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.1.0.080305\r\nDate: Thu, 01 May 2008 22:33:54 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C43FF5D2.22933%jclune@...&gt;\r\nThread-Topic: [neat] Re: Evolving Substrates in HyperNEAT\r\nThread-Index: Acir/PbAg1VpVDCMbEeUPmsFQTbYfA==\r\nIn-Reply-To: &lt;fvct1g+mb4e@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-transfer-encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: Evolving Substrates in HyperNEAT\r\nX-Yahoo-Group-Post: member; u=211599040; y=UWy4js9AXDMeLXzla6ghov7b9uMiYyodoyGcDc6eSiuh8d8i6btv\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nThis is an exhilarating conversation. I really like the ideas that have been\nexpressed. \n\nI agree that, in the spirit of complexification, we would want to start with\na small number of nodes on the substrate and then allow them to increase\n(but not increase too fast).\n\nI also like the idea of getting away from discrete layers.\n\nWhy correlate the CPPN complexity with the substrate complexity, though? My\ninstincts tell me that such a correlation might create evolutionary\npathologies, such as a pressure to increase CPPN complexity to &#39;buy&#39;\nsubstrate complexity. This is only a vague foreboding though. I would be\ninterested to see if it works!\n\nSpeaking of which, what do you all think would be a good test domain to see\nif evolving the substrate is effective? What would prove that it was worth\nthe trouble?\n\n\n\n\nCheers,\nJeff Clune\n\nDigital Evolution Lab, Michigan State University\n\njclune@...\n\n\n\n\n&gt; From: Kenneth Stanley &lt;kstanley@...&gt;\n&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; Date: Thu, 01 May 2008 17:01:36 -0000\n&gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; Subject: [neat] Re: Evolving Substrates in HyperNEAT\n&gt; \n&gt; Peter, these are interesting thoughts and similar to the way I think\n&gt; about it.  When I think about evolving the substrate, I usually think\n&gt; of a distribution of varying densities rather than strict layers or\n&gt; preconceived architectures, which is closest to Jeff&#39;s option (c).\n&gt; One reference for me is the human brain:  It has dense masses that\n&gt; look different from each other architecturally and do not exist in\n&gt; layers with respect to each other (e.g. the cerebellum vs. the basal\n&gt; ganglia).  However, *within* particular masses there is some layering,\n&gt; such as in the neocortex, which is perhaps the most important for\n&gt; high-level intelligence.  It would be nice if all that could just\n&gt; arise on its own to suit the task.\n&gt; \n&gt; What you said about CPPN complexity and substrate complexity\n&gt; increasing together is something I never thought of.  It&#39;s an\n&gt; interesting idea to correlate the two.  You are right that in general\n&gt; there is a problem with letting the nodes evolve in the substrate\n&gt; because it is so easy to express a massive number of nodes, which\n&gt; would not always be needed.\n&gt; \n&gt; One problem I see is that we are talking about astronomical ranges, so\n&gt; the range in density may not really make sense to vary on a continuum.\n&gt;  For example, if you have a number between 0 and 1 that represents a\n&gt; density somehow, then that density may range from several dozen\n&gt; neurons to several billion (if we are talking about natural scales).\n&gt; Does this range really make sense on a continuum between 0 and 1?\n&gt; Maybe we need to scale it exponentially or something like that, but\n&gt; still, then you end up with a tiny mutation potentially increasing the\n&gt; number of neurons by billions.  That seems odd.  In a way, we&#39;d like\n&gt; to not even be in a circumscribed range and just let increases keep\n&gt; happening indefinitely, but not too much at a time.\n&gt; \n&gt; Finally, the inputs and outputs may be a special case.  We may want to\n&gt; preserve the current human control of the geometry there and only let\n&gt; evolution increase density or something like that.\n&gt; \n&gt; Anyway, this is a great topic and a completely untouched area of\n&gt; research with plenty of things left to try.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\n&gt; wrote:\n&gt;&gt; \n&gt;&gt; Hello Jeff, \n&gt;&gt; \n&gt;&gt; I don&#39;t think that such assumptions about layered topology are the\n&gt;&gt; way to achieve this. There are two fundamental things associated with\n&gt;&gt; any substrate in 2D/3D. These are node presence and node density. In\n&gt;&gt; fact, skip the first, it just.. it can be thought of as spatial CPPN\n&gt;&gt; output where the output means the overall node density at that place.\n&gt;&gt; And if the output there is less than 0.2, there are no nodes (sounds\n&gt;&gt; familiar? :)). \n&gt;&gt; \n&gt;&gt; So the same connective CPPN is actually capable of representing its\n&gt;&gt; own substrate. But this approach would generate too big substrates.\n&gt;&gt; Even the most simple CPPNs are able to generate a substrate with\n&gt;&gt; 1000s of nodes and now imagine how many connections there could be.\n&gt;&gt; And this is for the simplest (!) CPPN. That sounds like a huge waste\n&gt;&gt; of computational effort, doesn&#39;t it? ;)\n&gt;&gt; \n&gt;&gt; So what is needed is a way to restrict the substrate complexity for\n&gt;&gt; small CPPNs. Of course more complex CPPNs can be allowed to generate\n&gt;&gt; more complex/dense substrates.\n&gt;&gt; \n&gt;&gt; This is actually just like complexification. First the major concepts\n&gt;&gt; are established on a substrate with very low resolution and as the\n&gt;&gt; CPPNs complexify, the substrate becomes more complex. In fact each\n&gt;&gt; CPPN will generate a substrate based on its complexity (say,\n&gt;&gt; num_nodes+num_links). Oh I think I mentioned that.\n&gt;&gt; \n&gt;&gt; What I am thinking is, if we actually allow substrates to evolve,\n&gt;&gt; does this mean that humans cannot inject that priory geometric\n&gt;&gt; knowledge any more? Or only for the inputs/outputs?\n&gt;&gt; \n&gt;&gt; It essentialy becomes like.. like just a good indirect encoding.\n&gt;&gt; \n&gt;&gt; Peter\n&gt;&gt; \n&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt;&gt;&gt; \n&gt;&gt;&gt; Hello-\n&gt;&gt;&gt; \n&gt;&gt;&gt; Many of you have said that it would be nice if the substrate\n&gt;&gt; configuration\n&gt;&gt;&gt; of HyperNEAT was not pre-defined. What elements of it do you think\n&gt;&gt; are\n&gt;&gt;&gt; important to evolve?\n&gt;&gt;&gt; \n&gt;&gt;&gt; I can think of at least three options (am I missing any?)\n&gt;&gt;&gt; \n&gt;&gt;&gt; 1) The number of hidden layers\n&gt;&gt;&gt; 2) The number of hidden nodes per layer\n&gt;&gt;&gt; 3) The geometric placement of the nodes in every layer\n&gt;&gt;&gt; \n&gt;&gt;&gt; If you think all of them are important, how would you prioritize\n&gt;&gt; them? In\n&gt;&gt;&gt; what order would you prefer researchers tackled them? I am just\n&gt;&gt; curious what\n&gt;&gt;&gt; different people think about these questions.\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt; \n&gt;&gt;&gt; Digital Evolution Lab, Michigan State University\n&gt;&gt;&gt; \n&gt;&gt;&gt; jclune@\n&gt;&gt;&gt; \n&gt;&gt; \n&gt; \n&gt; \n\n\n\n"}}