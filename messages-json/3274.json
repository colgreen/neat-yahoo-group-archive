{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"BAsodDSgv2IagjwVvL-bimjVzLrJr7cgh57CXlFQestdoAqIAe_2JvahRleJHx-nQ6Qo1-rPzEWBC22_fMfIgBDtmq_rCNJ8t7Z_C04wB68S","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Tile Coding and HyperNEAT","postDate":"1179037057","msgId":3274,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYyNmFpMisydGFtQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGYyNXRtbytxYXM0QGVHcm91cHMuY29tPg=="},"prevInTopic":3273,"nextInTopic":3276,"prevInTime":3273,"nextInTime":3275,"topicId":3214,"numMessagesInTopic":27,"msgSnippet":"... at ... identify ... Let s not confuse experiments that have yet to be attempted for a lack of capability; that would be bad scientific practice and jumping","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 53463 invoked from network); 13 May 2007 06:17:43 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m45.grp.scd.yahoo.com with QMQP; 13 May 2007 06:17:43 -0000\r\nReceived: from unknown (HELO n15c.bullet.sp1.yahoo.com) (69.147.64.120)\n  by mta5.grp.scd.yahoo.com with SMTP; 13 May 2007 06:17:43 -0000\r\nReceived: from [216.252.122.217] by n15.bullet.sp1.yahoo.com with NNFMP; 13 May 2007 06:17:39 -0000\r\nReceived: from [66.218.69.1] by t2.bullet.sp1.yahoo.com with NNFMP; 13 May 2007 06:17:39 -0000\r\nReceived: from [66.218.66.75] by t1.bullet.scd.yahoo.com with NNFMP; 13 May 2007 06:17:39 -0000\r\nDate: Sun, 13 May 2007 06:17:37 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f26ai2+2tam@...&gt;\r\nIn-Reply-To: &lt;f25tmo+qas4@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Tile Coding and HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=dcFQD79S8gPbobtr8t4RPlR8rOm-amvkzve8prl9-zio81unCLNg\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n--- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@...&gt; wrote:\n&gt;\n&gt; The extreme =\r\ncited was your referenced example of cutting up a chess \n&gt; board. I complet=\r\nely agree with your statement that the divisions \n&gt; should occur at the dis=\r\ncontinuities. It just appears that you are \n&gt; focusing on extremes to prove=\r\n your point, but at the same time \n&gt; appears to undermine your position. &quot;T=\r\nile coding&quot; focuses on \n&gt; partitioning the design space to facilitate the f=\r\nunctional \n&gt; representation. You seem to acknowledge the need to make divis=\r\nions \nat \n&gt; discontinuities in the design space. It appears that you take i=\r\nssue \n&gt; as to the degree or multiplicity of divisions, or the rational upon=\r\n \n&gt; which the divisions were based upon. Yet the example problems \n&gt; refere=\r\nnced to date for HyperNEAT exclusively deal with lower \n&gt; dimensional geome=\r\ntry which appear to not contain the types of \n&gt; discontinuities which would=\r\n necessitate different functional \n&gt; representation in different sub-region=\r\ns of the design space. \n&gt; Furthermore, to date, no mechanism appears to be =\r\nimplemented which \n&gt; would permit co-evolution of differing functional repr=\r\nesentations \n&gt; along with their necessary mapping functions/data that would=\r\n \nidentify \n&gt; the applicable sub-portion of the design space addressed by a=\r\n given \n&gt; sub-region functional representation.\n&gt; \n&gt; Now I realize that it =\r\nis early on in the development cycle for \n&gt; HyperNEAT, and that the simple =\r\nexamples provided in the papers were \n&gt; selected to best illustrate the abi=\r\nlity and importance of geometric \n&gt; information, but it appears to be prema=\r\nture to degrade an approach \n&gt; which focuses on divisions and HyperNEAT foc=\r\nuses on simplistic sub-\n&gt; regions without capacity for divisions.\n&gt; \n\nLet&#39;s=\r\n not confuse experiments that have yet to be attempted for a \nlack of capab=\r\nility; that would be bad scientific practice and jumping \nthe gun.  \n\n&gt; You=\r\nr point is well taken that divisions should occur at \n&gt; discontinuities. Eq=\r\nually important is the ability handle divisions \n&gt; within the design space.=\r\n I&#39;m just of the opinion that it is not as \n&gt; black and white as you have r=\r\nepresented. If &quot;tile coding&quot; is guilty \n&gt; of irrational division, HyperNEAT=\r\n is guilty of simplistic \n&gt; representation by omission of division, thus fa=\r\nr.\n&gt; \n\nWhen you say that a methodology is guilty &quot;thus far&quot; you are applyin=\r\ng \nthe &quot;guilty until proven innocent&quot; brand of justice.  We should give \nne=\r\nw methods a chance to prove themselves before knocking them for \ntheir init=\r\nial results not demonstrating everything at one time.\n\nIn any case, the pro=\r\nblems with tile coding are just as serious \nregardless of what HyperNEAT en=\r\nds up doing.  Of course, admittedly, I \nam implying that HyperNEAT is anti-=\r\ntile-coding, but even if it \nwasn&#39;t, tile coding would still be no better o=\r\nff for it.\n\nken\n\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstan=\r\nley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; I&#39;m not certain what &quot;the extreme cited&quot; refers to, bu=\r\nt we should \n&gt; not \n&gt; &gt; confuse tile coding with the classic &quot;divide and co=\r\nnquer&quot; \napproach \n&gt; to \n&gt; &gt; problem solving.  No one who follows divide and=\r\n conquer cuts a \n&gt; &gt; problem up into completely arbitrary chunks.  In fact,=\r\n divide and \n&gt; &gt; conquer is based on the idea that when you do divide, you =\r\ndivide \n&gt; *at* \n&gt; &gt; the discontinuities that occur along dimensions of desi=\r\ngn.  Thus \nit \n&gt; &gt; implies an initial assessment of the overall geometry of=\r\n the \n&gt; &gt; problem.  Once again, that&#39;s exactly what tile coding throws away=\r\n.\n&gt; &gt; \n&gt; &gt; By the way, &quot;geometry&quot; does not imply a necessary analogue with =\r\n\nthe \n&gt; &gt; dimensions of physical space.  It only implies that there are \n&gt; =\r\nindeed \n&gt; &gt; orthogonal dimensions.  So the &quot;higher design space \ndimensiona=\r\nlity&quot; \n&gt; &gt; is part of the geometry.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; --- In neat@yahoo=\r\ngroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; IMHO, it appears that th=\r\ne extreme cited dismisses an element \nthat \n&gt; &gt; &gt; holds value. The sole foc=\r\nus on geometry (i.e. 1d, 2d or 3d), is \na \n&gt; &gt; &gt; simplified subset of a pro=\r\nblem dimensionality. Most useful \n&gt; problems \n&gt; &gt; &gt; have a higher design sp=\r\nace dimensionality in which global \n&gt; functions \n&gt; &gt; &gt; are comprised of a c=\r\nollection of regional &quot;global functions&quot; \n&gt; along \n&gt; &gt; &gt; with their individ=\r\nual application sub-domain definitions, which \n&gt; &gt; taken \n&gt; &gt; &gt; together ma=\r\nkeup the whole.\n&gt; &gt; &gt; \n&gt; &gt; &gt; An approach which works well within a regional=\r\n sub-domain isn&#39;t \n&gt; bad \n&gt; &gt; &gt; because it cannot adequately address all of=\r\n the design space, \n&gt; &gt; unless \n&gt; &gt; &gt; of course it can co-evolve different =\r\nfunctions in different sub-\n&gt; &gt; &gt; regions along with the corresponding regi=\r\nonal \n&gt; application /mapping \n&gt; &gt; &gt; between them.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Also, as you=\r\nr example illustrates, it would be seriously \n&gt; &gt; &gt; counterproductive to th=\r\nrow away proximity-based information, \n&gt; &gt; whether \n&gt; &gt; &gt; geometry or other=\r\n higher dimensional information.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Many useful problems are comp=\r\nrised of discontinuities that have \n&gt; to \n&gt; &gt; be \n&gt; &gt; &gt; dealt with individu=\r\nally. &quot;Divide-and-conquer&quot; is a powerful \n&gt; &gt; approach \n&gt; &gt; &gt; when properly=\r\n applied.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley=\r\n&quot; &lt;kstanley@&gt; \nwrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Joe, I agree this is a revealing disc=\r\nussion.  Tile coding to \nme \n&gt; a \n&gt; &gt; &gt; is \n&gt; &gt; &gt; &gt; a telling example of a =\r\nsignificant misdirection of effort in \n&gt; &gt; &gt; machine \n&gt; &gt; &gt; &gt; learning righ=\r\nt now.  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Most of what you said is factually true.  But the=\r\n spin you \nput \n&gt; on \n&gt; &gt; &gt; it \n&gt; &gt; &gt; &gt; is wrong.  It is correct that tile =\r\ncoding breaks up the \n&gt; &gt; &gt; state/action \n&gt; &gt; &gt; &gt; space into little pieces =\r\nto make the right behavior for each \n&gt; &gt; little \n&gt; &gt; &gt; &gt; region easier to c=\r\nompute.  As you put it, &quot;subtiles can \nbetter \n&gt; &gt; fit \n&gt; &gt; &gt; &gt; the value f=\r\nunction being learned. Note that there is very \n&gt; little \n&gt; &gt; &gt; &gt; generaliz=\r\nation desired here.&quot;  You say that like it&#39;s a good \n&gt; &gt; thing.\n&gt; &gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; &gt; However, the fact that there is a need to do something like \n&gt; that \n=\r\n&gt; &gt; is \n&gt; &gt; &gt; &gt; more a symptom of a serious disease in RL than an \n&gt; accomp=\r\nlishment \n&gt; &gt; we \n&gt; &gt; &gt; &gt; should be congratulating ourselves for.  It&#39;s lik=\r\ne using \n&gt; cocaine \n&gt; &gt; to \n&gt; &gt; &gt; &gt; stay awake at work and claiming that it=\r\n was a good idea \nbecause \n&gt; &gt; you \n&gt; &gt; &gt; &gt; were more alert.  The fact is t=\r\nhe whole approach is sick to \n&gt; begin \n&gt; &gt; &gt; &gt; with if it needs cocaine to =\r\nfunction properly.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; And that&#39;s what tile coding is really i=\r\nndicating: Much of RL \nis \n&gt; &gt; &gt; DOA.  \n&gt; &gt; &gt; &gt; Tile coding is a symptom of=\r\n a larger sickness.  You said it \n&gt; &gt; &gt; &gt; yourself: &quot;[most] RL is inherentl=\r\ny incapable of performing \n&gt; model \n&gt; &gt; &gt; &gt; selection.&quot;  Well, if what that=\r\n means is that you can&#39;t \nexploit \n&gt; &gt; &gt; &gt; geometry, it&#39;s all a dead end.  =\r\nI am not certain that RL \n(aside \n&gt; &gt; &gt; from \n&gt; &gt; &gt; &gt; NEAT+Q-type stuff) is=\r\n really incapable of optimizing the \nmodel \n&gt; &gt; &gt; &gt; because who knows what =\r\nwe might realize how to do in the \n&gt; future.  \n&gt; &gt; &gt; &gt; However, for now, RL=\r\n is falling back on tile coding because \nit \n&gt; is \n&gt; &gt; &gt; &gt; moving in the wr=\r\nong direction.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Here is what is really going on:  Each vari=\r\nable in the \n&gt; &gt; state/action \n&gt; &gt; &gt; &gt; space is a dimension along which the=\r\n value function varies.  \nA \n&gt; &gt; good \n&gt; &gt; &gt; &gt; learning algorithm would rep=\r\nresent how the value function \n&gt; varies \n&gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; respect to eac=\r\nh state variable.  However, such variation may \nbe \n&gt; &gt; &gt; &gt; complex, i.e. t=\r\nhe function could be pretty complicated.  The \n&gt; &gt; &gt; learning \n&gt; &gt; &gt; &gt; meth=\r\nods (i.e. supervised function approximators) inside RL \nare \n&gt; &gt; &gt; &gt; suffic=\r\niently bad that they cannot handle approximating \n&gt; functions \n&gt; &gt; &gt; like \n=\r\n&gt; &gt; &gt; &gt; that.  So what do we do?  We break the whole space into \n&gt; chunks. =\r\n \n&gt; &gt; &gt; Now \n&gt; &gt; &gt; &gt; the appropriate action for each little chunk requires =\r\na much \n&gt; &gt; &gt; simpler \n&gt; &gt; &gt; &gt; function, so we have a chance with our poor =\r\nlearning \nalgorithm \n&gt; to \n&gt; &gt; &gt; &gt; maybe get all these little simple functi=\r\nons right instead of \n&gt; only \n&gt; &gt; a \n&gt; &gt; &gt; &gt; few big complicated functions.=\r\n  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; In other words, we have a poor algorithm and the cure i=\r\ns to \n&gt; &gt; destroy \n&gt; &gt; &gt; &gt; what variational structure there was to begin wi=\r\nth so that we \n&gt; can \n&gt; &gt; &gt; &gt; look at every little bit of the problem separ=\r\nately.   So we \n&gt; have \n&gt; &gt; &gt; now \n&gt; &gt; &gt; &gt; lost the ability to exploit all =\r\nthe useful relationships that \n&gt; &gt; &gt; &gt; initially existed in the space.  Sta=\r\ntes that are related are \n&gt; now \n&gt; &gt; &gt; &gt; broken apart and must be learned s=\r\neparately, that is, the \n&gt; &gt; geometry \n&gt; &gt; &gt; &gt; has been destroyed! The fact=\r\n that many see such an operation \nas \n&gt; a \n&gt; &gt; &gt; &gt; step in the right direct=\r\nion is symptomatic of serious \n&gt; &gt; misdirection \n&gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; the fiel=\r\nd.  If that&#39;s the best we can do to make RL easier, \n&gt; than \n&gt; &gt; RL \n&gt; &gt; &gt; =\r\n&gt; is in serious trouble!\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Think of it like this:  Take a ga=\r\nme like chess, which I \nlearned \n&gt; &gt; as \n&gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; little kid.  Now =\r\ntake the 64 squares and cut each piece out \nof \n&gt; &gt; the \n&gt; &gt; &gt; &gt; board indi=\r\nvidually.  Now sprinkle them all randomly all over \n&gt; your \n&gt; &gt; &gt; &gt; living =\r\nroom.  Each square still represents the same location \nit \n&gt; &gt; was \n&gt; &gt; &gt; &gt;=\r\n originally taken from in the board.  It&#39;s just you can&#39;t see \n&gt; &gt; where \n&gt;=\r\n &gt; &gt; &gt; they were anymore.  Now place the chess pieces in the right \n&gt; &gt; &gt; s=\r\ntarting \n&gt; &gt; &gt; &gt; squares and teach a little kid to play chess.  Think he or=\r\n \nshe \n&gt; &gt; &gt; would \n&gt; &gt; &gt; &gt; learn anything at all?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Well, t=\r\nhat&#39;s exactly what tile coding is!  A method that \nlearns \n&gt; &gt; &gt; chess \n&gt; &gt;=\r\n &gt; &gt; (or anything else that has implicit or explicit geometry) \nneeds \n&gt; &gt; =\r\nto \n&gt; &gt; &gt; &gt; know how the positions relate to each other geometrically \n&gt; be=\r\ncause \n&gt; &gt; &gt; &gt; there is massive regularity being lost without that \n&gt; infor=\r\nmation.  \n&gt; &gt; &gt; &gt; What kind of crazy algorithm would purposely put a chess =\r\n\nboard \n&gt; &gt; into \n&gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; meaningless order before learning begins=\r\n?  A method \n&gt; &gt; that &quot;benefits&quot; \n&gt; &gt; &gt; &gt; from such an approach is clearly =\r\nDOA.  RL researchers should \nbe \n&gt; &gt; &gt; &gt; seriously concerned about tile cod=\r\ning being necessary at all, \n&gt; not \n&gt; &gt; &gt; &gt; happy about it.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; =\r\n&gt; So I stick to my position: Tile coding is anti-geometry and \n&gt; anti-\n&gt; &gt; =\r\n&gt; &gt; representation.  It deserves no credit whatsoever \n&gt; &gt; for &quot;respecting&quot;=\r\n \n&gt; &gt; &gt; &gt; anything.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@yahoo=\r\ngroups.com, Joseph Reisinger &lt;joeraii@&gt; \nwrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I&#39;ve be=\r\nen aching to reply to this post for a while, and I \n&gt; &gt; &gt; finally  \n&gt; &gt; &gt; &gt;=\r\n &gt; have enough free time to do so. I think we could have a \n&gt; really  \n&gt; &gt; =\r\n&gt; &gt; &gt; interesting discussion here, hopefully at least more \n&gt; &gt; interesting=\r\n \n&gt; &gt; &gt; &gt; than  \n&gt; &gt; &gt; &gt; &gt; the NFL tangent.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt;&gt; Sure, b=\r\nut tile-coding does respect at least one form of \n&gt; &gt; &gt; geometry:\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt;&gt; Nearby elements in the state space are known to be \nnearby, \n&gt; &gt; and \n&gt;=\r\n &gt; &gt; &gt; thus\n&gt; &gt; &gt; &gt; &gt; &gt;&gt; are grouped in the same tile.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; I have to dispute this characterization of tile coding\n&gt; &gt; &gt; &gt; &gt; &gt; as &quot;=\r\nrespecting at least one form of geometry.&quot; I think \nyou \n&gt; are\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\nbeing unnecessarily equitable toward tile coding.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; W=\r\nhat you are saying is that in effect taking a nice \n&gt; sculpture \n&gt; &gt; &gt; and\n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; cutting it into pieces &quot;respects&quot; its geometry because \n&gt; those=\r\n \n&gt; &gt; &gt; &gt; little\n&gt; &gt; &gt; &gt; &gt; &gt; pieces are not broken up any further than that=\r\n. It&#39;s like \n&gt; &gt; saying\n&gt; &gt; &gt; &gt; &gt; &gt; that someone who cut your head off &quot;res=\r\npected&quot; your head \nby \n&gt; &gt; &gt; &gt; keeping\n&gt; &gt; &gt; &gt; &gt; &gt; its internal integrity i=\r\nntact. In fact, tile coding is \n&gt; &gt; &gt; peforming a\n&gt; &gt; &gt; &gt; &gt; &gt; grievous viol=\r\nation against the existing geometry of the \n&gt; &gt; domain, \n&gt; &gt; &gt; &gt; and\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; does not deserve to be credited with respecting geometry\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\nwhatsoever. I&#39;m hard pressed to imagine how one could do \n&gt; worse\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; beyond cutting things up into even tinier and tinier \nbits; \n&gt; &gt; but \n&gt; =\r\n&gt; &gt; &gt; even\n&gt; &gt; &gt; &gt; &gt; &gt; then, those bits still contain &quot;nearby elements in t=\r\nhe \nstate\n&gt; &gt; &gt; &gt; &gt; &gt; space.&quot; So that isn&#39;t saying much.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;=\r\n &gt; Yeah, from the way your framing this argument, e.g. tile-\n&gt; coding \n&gt; &gt; =\r\n&gt; &gt; used  \n&gt; &gt; &gt; &gt; &gt; in the GA model-selection sense, you&#39;re absolutely rig=\r\nht. \n&gt; I&#39;ll \n&gt; &gt; &gt; get  \n&gt; &gt; &gt; &gt; &gt; back to exactly what I mean by that in a=\r\n bit. For now lets \n&gt; try \n&gt; &gt; &gt; to  \n&gt; &gt; &gt; &gt; &gt; reframe the issue from an R=\r\nL perspective, which is where \ntile-\n&gt; &gt; &gt; &gt; codings  \n&gt; &gt; &gt; &gt; &gt; are predom=\r\ninantly used. In RL, the tile-coding is just a  \n&gt; &gt; &gt; &gt; &gt; representation f=\r\nor a function approximator (in a sense its \n&gt; sort \n&gt; &gt; &gt; of  \n&gt; &gt; &gt; &gt; &gt; li=\r\nke a really simple spline cure) that learns in a \nsupervised \n&gt; &gt; &gt; &gt; manne=\r\nr.  \n&gt; &gt; &gt; &gt; &gt; Tile coding makes a lot of sense in this domain because you =\r\n\n&gt; &gt; can  \n&gt; &gt; &gt; &gt; &gt; calculate with a good deal of precision how much some =\r\n\n&gt; &gt; particular \n&gt; &gt; &gt; &gt; tile  \n&gt; &gt; &gt; &gt; &gt; differs from the expected value o=\r\nf the function being \n&gt; &gt; &gt; approximated  \n&gt; &gt; &gt; &gt; &gt; (in this case the Bell=\r\nman error).\n&gt; &gt; &gt; &gt; &gt; Tiles hat is cover a broad area where the value funct=\r\nion \n&gt; &gt; changes \n&gt; &gt; &gt; a  \n&gt; &gt; &gt; &gt; &gt; lot (&quot;have bad fit&quot;, &quot;are too general=\r\n&quot;, etc) are then split \n&gt; so \n&gt; &gt; &gt; &gt; that  \n&gt; &gt; &gt; &gt; &gt; the subtiles can bet=\r\nter fit the value function being \nlearned. \n&gt; &gt; &gt; Note  \n&gt; &gt; &gt; &gt; &gt; that the=\r\nre is very little generalization desired here; the \n&gt; best \n&gt; &gt; &gt; &gt; thing  =\r\n\n&gt; &gt; &gt; &gt; &gt; given infinite computational resources would be to have a \n&gt; who=\r\nle \n&gt; &gt; &gt; &gt; ton  \n&gt; &gt; &gt; &gt; &gt; of itty-bitty tiles that fit the value function=\r\n perfectly.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Anyway, since we&#39;re in the standard RL fra=\r\nmework, there is \n&gt; &gt; really \n&gt; &gt; &gt; &gt; no  \n&gt; &gt; &gt; &gt; &gt; way of learning the &quot;g=\r\neometry&quot; of a value function (well, \n&gt; &gt; &gt; &gt; technically  \n&gt; &gt; &gt; &gt; &gt; there =\r\nis, but thats a long tangent towards a really \n&gt; &gt; interesting  \n&gt; &gt; &gt; &gt; &gt; =\r\nresearch area). Maybe if the geometry was given by the \n&gt; &gt; &gt; &gt; experimente=\r\nr  \n&gt; &gt; &gt; &gt; &gt; beforehand (this would also lead to an interesting \nextension=\r\n \n&gt; of \n&gt; &gt; &gt; &gt; tile- \n&gt; &gt; &gt; &gt; &gt; codings that you might like a little bette=\r\nr). But in any \n&gt; case, \n&gt; &gt; &gt; &gt; since  \n&gt; &gt; &gt; &gt; &gt; all we&#39;re trying to do i=\r\nn RL is supervised function \n&gt; &gt; &gt; approximation,  \n&gt; &gt; &gt; &gt; &gt; the lack of g=\r\neometry isn&#39;t bad.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; I&#39;m obviously not a bi=\r\ng fan of tile coding :) I&#39;m not \nreally\n&gt; &gt; &gt; &gt; &gt; &gt; concerned whether it mi=\r\nght do better in some cases; the \n&gt; &gt; problem \n&gt; &gt; &gt; &gt; with\n&gt; &gt; &gt; &gt; &gt; &gt; it =\r\nis that it is a dead end for future progress because \nit \n&gt; is \n&gt; &gt; &gt; &gt; abo=\r\nut\n&gt; &gt; &gt; &gt; &gt; &gt; ruining our ability to exploit geometric relationships.\n&gt; &gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Ok, this is where the discussion gets really interesting. =\r\n\n&gt; &gt; &gt; Remember  \n&gt; &gt; &gt; &gt; &gt; when I mentioned GA&#39;s &quot;performing model selecti=\r\non&quot; or \n&gt; something \n&gt; &gt; &gt; &gt; like  \n&gt; &gt; &gt; &gt; &gt; that before? Thats a fundamen=\r\ntal difference in the GA \n&gt; approach \n&gt; &gt; &gt; and  \n&gt; &gt; &gt; &gt; &gt; RL. So what do =\r\nI mean by model selection: roughly speaking, \n&gt; in  \n&gt; &gt; &gt; &gt; &gt; Bayesian inf=\r\nerence you have this idea of some separation of \n&gt; &gt; the  \n&gt; &gt; &gt; &gt; &gt; parame=\r\nters you are optimizing (e.g. the weights in an NN) \nand \n&gt; &gt; &gt; the  \n&gt; &gt; &gt;=\r\n &gt; &gt; model that generates those parameters (e.g. the topology of \n&gt; the \n&gt; =\r\n&gt; &gt; &gt; NN,  \n&gt; &gt; &gt; &gt; &gt; or even whether you use an NN or decision tree or \nso=\r\nmething). \n&gt; &gt; RL \n&gt; &gt; &gt; &gt; is  \n&gt; &gt; &gt; &gt; &gt; inherently incapable of performin=\r\ng model selection (at \nleast \n&gt; &gt; &gt; &gt; outside  \n&gt; &gt; &gt; &gt; &gt; of NEAT+Q and som=\r\ne others). Once you start learning with  a \n&gt; &gt; &gt; given  \n&gt; &gt; &gt; &gt; &gt; value f=\r\nunction representation, you can no longer switch to \na  \n&gt; &gt; &gt; &gt; &gt; differen=\r\nt representation without throwing away everything \n&gt; &gt; you&#39;ve \n&gt; &gt; &gt; &gt; just=\r\n  \n&gt; &gt; &gt; &gt; &gt; learned.  GAs on the other hand learn one parameterized \nmodel=\r\n \n&gt; &gt; &gt; per  \n&gt; &gt; &gt; &gt; &gt; individual. This is an important distinction.\n&gt; &gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Now, what does this have to do with tile coding and \nlearni=\r\nng  \n&gt; &gt; &gt; &gt; &gt; geometry?  When you talk about &quot;cutting up different \n&gt; vari=\r\nables&quot; \n&gt; &gt; &gt; &gt; you  \n&gt; &gt; &gt; &gt; &gt; are inherently making an argument from the =\r\nstandpoint of \n&gt; model  \n&gt; &gt; &gt; &gt; &gt; selection: i.e. what is the best represe=\r\nntation for this \n&gt; &gt; &gt; learning  \n&gt; &gt; &gt; &gt; &gt; problem? This is a valid quest=\r\nion in the GA world, and I \n&gt; agree \n&gt; &gt; &gt; &gt; with  \n&gt; &gt; &gt; &gt; &gt; you tile codi=\r\nng wouldn&#39;t work at all for learning good  \n&gt; &gt; &gt; &gt; &gt; representations that =\r\nallow good future learning. But from \nthe \n&gt; &gt; RL  \n&gt; &gt; &gt; &gt; &gt; standpoint, s=\r\nince all tile-coding is used for is function  \n&gt; &gt; &gt; &gt; &gt; approximation, I d=\r\non&#39;t think they are as problematic as you \n&gt; &gt; &gt; imagine.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; =\r\n&gt; &gt; -- Joe\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}