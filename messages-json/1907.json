{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"_3_DejPb8o4TWGMZd92RI6Jyb-TIYwfPS-Mj6VzPmMA1b-Ah9I-1nRC6Vz86WMXV3l6PxTangj4ySdues82T6CMF_oM8Wr2f-rJ-0q7N0vo1","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Species stagnation","postDate":"1112222876","msgId":1907,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGQyZmFhcys4ZTk3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PEJBWTEwMi1GNDE0MkM5QUM2MEVBM0FDRjQ1ODhERkNBNDQwQHBoeC5nYmw+"},"prevInTopic":1906,"nextInTopic":1908,"prevInTime":1906,"nextInTime":1908,"topicId":1899,"numMessagesInTopic":26,"msgSnippet":"Hi Mike and everyone else involved in this thread.  I am sorry about all the confusion that seems to surround the this topic.  However, I believe I can clarify","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 76832 invoked from network); 30 Mar 2005 22:48:02 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m22.grp.scd.yahoo.com with QMQP; 30 Mar 2005 22:48:02 -0000\r\nReceived: from unknown (HELO n21a.bulk.scd.yahoo.com) (66.94.237.50)\n  by mta2.grp.scd.yahoo.com with SMTP; 30 Mar 2005 22:48:02 -0000\r\nDomainKey-Signature: \r\nReceived: from [66.218.69.3] by n21.bulk.scd.yahoo.com with NNFMP; 30 Mar 2005 22:47:59 -0000\r\nReceived: from [66.218.66.88] by mailer3.bulk.scd.yahoo.com with NNFMP; 30 Mar 2005 22:47:59 -0000\r\nDate: Wed, 30 Mar 2005 22:47:56 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;d2faas+8e97@...&gt;\r\nIn-Reply-To: &lt;BAY102-F4142C9AC60EA3ACF4588DFCA440@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 5026\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Species stagnation\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\nHi Mike and everyone else involved in this thread.  I am sorry about \nall the confusion that seems to surround the this topic.  However, I \nbelieve I can clarify the confusion here...(thanks Mike for pointing \nthese contradictions out)\n\n--- In neat@yahoogroups.com, &quot;Mike Frayn&quot; &lt;redcrocodile@h...&gt; wrote:\n&gt; Hello everyone,\n&gt; \n&gt; Just a reminder: Experienced programmer but very new to \nNEAT/neuroevolution.\n&gt; \n&gt; I am having an issue with species (and population) stagnation in \nmy latest \n&gt; experiment and so I have been looking at the speciation components \nof NEAT \n&gt; quite intently.  I have a couple of questions regarding the \nfitness penalty \n&gt; for species that have gone past the dropoff_age point with no \nimprovement.\n&gt; \n&gt; In the C++ version of NEAT that I downloaded, there doesn&#39;t seem \nto be any \n&gt; check to see if the species being penalized is one of the top (if \nnot *the* \n&gt; top) performers.  The literature I&#39;ve read on NEAT says &quot;in order \nto prevent \n&gt; stagnation, the lowest performing species over N generations old \n[is] not \n&gt; allowed to reproduce&quot;.  I don&#39;t see any such checks for &quot;lowest \nperforming \n&gt; species&quot;.  This leads into my second question.\n&gt; \n\nI know what happened here.  The papers you are talking about are \ncoevolution experiments.  In coevolution, you can&#39;t use absolute \nfitness to check for stagnation since fitness is *relative* in \ncoevolution.  In other words, even if the fitness of a species \nstayed the same for 100 generations, that doesn&#39;t mean that its \nperformance is staying the same in coevolution.  It might be worse \nand it might be better, in an absolute sense, than where it started.\nTherefore, it uses the heuristic you mentioned, where it just culls \nthe worst species as long as it&#39;s been around for a while.\n\nIn my non-coevolution papers (older ones in general) it uses the \nheuristic you see in my code- it kills species that haven&#39;t improved \nin n generations.  It can do this in non-coevolution since fitness \nis an abolute measure of performance.\n\nNote that &quot;haven&#39;t improved&quot; means MAX fitness hasn&#39;t gone up.  I \nsaw some mention of using average fitness in this thread, but that \nshould not be used as a measure of stagnation.\n\nMore below...\n\n&gt; If this is in fact the case, that no checks are made, then surely \nthe \n&gt; population stagnancy check would not do much good, no?  The idea \nhere seems \n&gt; to be not to allow any species to reproduce except for the top two \nif the \n&gt; entire population has not improved best fitness over N+5 \ngenerations (C++ \n&gt; version again).  Surely, since the best species would have been \nsterile -5 \n&gt; generations ago, at this point, only allowing it and the one below \nit to \n&gt; reproduce won&#39;t have much more of an effect than allowing any \nspecies to \n&gt; reproduce.\n&gt; \n\nThe point of this special &quot;delta coding&quot; case is that the entire \npopulation is stuck, and you have nothing available to work with \nother than the current population.  It makes sense in that case to \n*focus in* on the best species, simply because they are most \npromising by virtue of being most fit.  Since basically everyone is \nstagnating, there isn&#39;t anything else to go on.  \n\nFocusing in definitely works in a lot of cases.  The reason is that \nif you dedicate a ton of resources to looking around a single point, \nyou are more likely to find a way up than if you only dedicate a few \nresources.  I frequently see sudden rapid improvements after delta \ncoding (focusing in on the top 2 species).  It makes sense and I did \nnot invent the general idea of zooming in when you&#39;re stuck (i.e. \ndelta coding).\n\n&gt; Obviously I am missing something here, but I don&#39;t seem to be able \nto put my \n&gt; finger on it.  Any help would be greatly appreciated.\n&gt; \n\nWell I hope some of my response here helped clarify the idea for you \nand others here.  I have to agree with some of the comments in the \nthread though: there are a lot of ways you could deal with \nstagnation, and I am not claiming my heuristics are the best.  \nThey&#39;re just the ones that seemed sensible to me when there was \nlittle precedent to go on.  Derek is also right in pointing out that \nspecific implementation details are often not crucial, and therefore \nthere&#39;s no need to get hung up on whether you are following my code \nexactly.  My code is only the first attempt to write such an \nalgorithm; that doesn&#39;t make it the best.  With several years of \nperspective and many people working on it, there will no doubt be \nsome reevaluation of certain implementation decisions I made in the \nbeginning.  What I&#39;m basically saying is that you should by all \nmeans be on the lookout for how to do things better...you may very \nwell have a better idea in mind.\n\nFinally, let me suggest that from reading about your (Mike&#39;s)\nspecific problem that it is probably something about the domain that \nis causing you to get stuck.  It may simply be too hard to evolve \nfrom scratch, or there could be a bug.  But I have a feeling that \nstagnation detection is not the primary factor in this problem.\n\nken\n\n\n\n\n"}}