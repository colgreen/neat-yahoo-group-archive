{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":37465196,"authorName":"Ken Lloyd","from":"&quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;","profile":"kalloyd2","replyTo":"LIST","senderId":"VqYjrb6UtegL2Ehgy0_sHEKSHtAgSveFMFO2Ju9OU9frU2b7olQdgA5JgDV7wuIqz7UC0fSjes7YOVb2E3QHcT2HZIKU_I3J","spamInfo":{"isSpam":false,"reason":"12"},"subject":"RE: [neat] Re: solution for NEAT on CUDA","postDate":"1260535288","msgId":5005,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PERFNEUyNDBCQUY4MTRDQTRBQzNCODQyMjM5NUUzOTUwQHdhdHRwND4=","inReplyToHeader":"PGhmdDQ0MythNGY5QGVHcm91cHMuY29tPg==","referencesHeader":"PDcyN2E0MDZjMDkxMjEwMTI0OHY1M2YxNjIwOWxlZTljY2M3Y2NlMGZhZGFkQG1haWwuZ21haWwuY29tPiA8aGZ0NDQzK2E0ZjlAZUdyb3Vwcy5jb20+"},"prevInTopic":5004,"nextInTopic":5007,"prevInTime":5004,"nextInTime":5006,"topicId":4995,"numMessagesInTopic":8,"msgSnippet":"To all interested, Some insight into the complexity of running HyperNEAT on GPUs is found in: ","rawEmail":"Return-Path: &lt;kalloyd@...&gt;\r\nX-Sender: kalloyd@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 8850 invoked from network); 11 Dec 2009 12:41:30 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m11.grp.re1.yahoo.com with QMQP; 11 Dec 2009 12:41:30 -0000\r\nX-Received: from unknown (HELO QMTA08.emeryville.ca.mail.comcast.net) (76.96.30.80)\n  by mta2.grp.sp2.yahoo.com with SMTP; 11 Dec 2009 12:41:30 -0000\r\nX-Received: from OMTA21.emeryville.ca.mail.comcast.net ([76.96.30.88])\n\tby QMTA08.emeryville.ca.mail.comcast.net with comcast\n\tid FoXW1d0061u4NiLA8ohWKR; Fri, 11 Dec 2009 12:41:30 +0000\r\nX-Received: from wattp4 ([174.56.66.94])\n\tby OMTA21.emeryville.ca.mail.comcast.net with comcast\n\tid FohV1d007221HGW8hohVrz; Fri, 11 Dec 2009 12:41:30 +0000\r\nTo: &lt;neat@yahoogroups.com&gt;\r\nReferences: &lt;727a406c0912101248v53f16209lee9ccc7cce0fadad@...&gt; &lt;hft443+a4f9@...&gt;\r\nDate: Fri, 11 Dec 2009 05:41:28 -0700\r\nMessage-ID: &lt;DE4E240BAF814CA4AC3B8422395E3950@wattp4&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_01D3_01CA7A24.96A8D9E0&quot;\r\nX-Mailer: Microsoft Office Outlook 11\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.5579\r\nThread-Index: Acp6RikjI5jeqJ0pRVyH01Oj9+DyFAAF34QQ\r\nIn-Reply-To: &lt;hft443+a4f9@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken Lloyd&quot; &lt;kalloyd@...&gt;\r\nSubject: RE: [neat] Re: solution for NEAT on CUDA\r\nX-Yahoo-Group-Post: member; u=37465196; y=jBQ5o8fK3ZC4dpCW0WVahqgx9OFzStDHfUE8LCGmtdEJ3YI\r\nX-Yahoo-Profile: kalloyd2\r\n\r\n\r\n------=_NextPart_000_01D3_01CA7A24.96A8D9E0\r\nContent-Type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-Transfer-Encoding: 7bit\r\n\r\nTo all interested,\n \nSome insight into the complexity of running HyperNEAT on GPUs is found in:\n \nhttp://fag.grm.hia.no/ikt502/year2008/projects/reports/Implementation_of_gen\netic_algorithm_on_CUDA.pdf\n \nMy initial attempts at running everything on the GPU were disappointing.  I\nhave now adopted a hybrid approach -some parts of the code run on one or\nmore cores on the CPUs, others run on the SMs of the GPUs.  Furthermore, I\nam investigating running a variant of HyperNEAT on small clusters (Rocks /w\nCUDA rolls).  Andrei is correct, in that it takes HyperNEAT and carves it up\nin ways almost unrecognizable. \n \nI have even started using HyperNEAT to discover better patterns of\nconfiguring the cluster&#39;s optimized compute fabric.  This is not a constant\nconfiguration, or so I&#39;ve found. The devil is in the details.\n \nKen Lloyd\n \n\n  _____  \n\nFrom: neat@yahoogroups.com [mailto:neat@yahoogroups.com] On Behalf Of Andrei\nSent: Friday, December 11, 2009 2:41 AM\nTo: neat@yahoogroups.com\nSubject: [neat] Re: solution for NEAT on CUDA\n\n\n  \n\nI&#39;m afraid that just moving the code to the GPU is not a good approach. The\ncode has to be redesigned with the CUDA architecture in mind to get real\nspeed-ups. \n\nLet me give you just one example: if you don&#39;t pay attention to the memory\nhierarchy in the GPU and just make random array accesses from main GPU\nmemory, your speed-up will be 1.5x instead of, say, 10x. This is because\nindividual memory accesses on a GPU take so much time compared to the cores&#39;\nprocessing speed. On the CPU you seldom have this in mind, since the CPU and\ncompiler put your data in 2 or 3 levels of cache for you. This is just one\nof the things CPU code is blind to, another being the actual order of kernel\nexecution on a GPU. Kernels on current GPUs are serialised, but not for\nlong.\n\nI know that Fermi addresses these problems directly, with better memory\nmanagement and caches and also multiple kernel executions in parallel. I\nwouldn&#39;t wait for that though, because from the [rumour warning] April 2010\nlaunch, it would take at least one year to get it for a decent price. It&#39;s\nnot going to provide straightforward efficient porting anyway.\n\nHope this make a case for redesigning the code with the GPU in mind. \n\nCheers!\nAndrei.\n\n--- In neat@yahoogroups. &lt;mailto:neat%40yahoogroups.com&gt; com, Colin Green\n&lt;colin.green1@...&gt; wrote:\n&gt;\n&gt; 2009/12/10 openmind767 &lt;openmind767@...&gt;\n&gt; &gt;\n&gt; &gt; The whole NEAT lib and experiment are both full of branch. Making the\nwhole things running on CUDA won&#39;t speed up, and it is\n&gt; &gt; not my target.\n&gt; \n&gt; Hi,\n&gt; \n&gt; So your saying that we:\n&gt; \n&gt; 1) Load all of the networks in a population into the GPU\n&gt; 2) Activate them in parallel.\n&gt; 3) Read the outputs.\n&gt; \n&gt; For larger networks (e.g. from HyperNEAT) we may only get one or two\n&gt; networks into the GPU, so it would seem we need to put as many\n&gt; networks as we can into the GPU at a time. I think this should be\n&gt; fairly easy to do and this touches on previous comments from Ken Lloyd\n&gt; who I believe has gone into this in far more detail - e.g. by also\n&gt; loading problem domain code into the GPU and trying to determine how\n&gt; best to divide GPU and CPU resources in the general case (for a wide\n&gt; range of scenarios).\n&gt; \n&gt; Colin.\n&gt;\n\n\n\n\n\n\r\n------=_NextPart_000_01D3_01CA7A24.96A8D9E0\r\nContent-Type: text/html;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;=\r\n\n&lt;META content=3D&quot;text/html; charset=3Dus-ascii&quot; http-equiv=3DContent-Type&gt;=\r\n\n&lt;META name=3DGENERATOR content=3D&quot;MSHTML 8.00.6001.18854&quot;&gt;&lt;/HEAD&gt;\n&lt;BODY st=\r\nyle=3D&quot;BACKGROUND-COLOR: #fff&quot;&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D1=\r\n04592912-11122009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial&gt;To all inter=\r\nested,&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D104592=\r\n912-11122009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nb=\r\nsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D104592912-11122009&gt;&lt;FON=\r\nT color=3D#0000ff \nsize=3D2 face=3DArial&gt;Some insight into the complexity o=\r\nf running HyperNEAT on GPUs \nis found in:&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dlt=\r\nr align=3Dleft&gt;&lt;SPAN class=3D104592912-11122009&gt;&lt;FONT color=3D#0000ff \nsize=\r\n=3D2 face=3DArial&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;S=\r\nPAN class=3D104592912-11122009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial=\r\n&gt;&lt;A \nhref=3D&quot;http://fag.grm.hia.no/ikt502/year2008/projects/reports/Impleme=\r\nntation_of_genetic_algorithm_on_CUDA.pdf&quot;&gt;http://fag.grm.hia.no/ikt502/year=\r\n2008/projects/reports/Implementation_of_genetic_algorithm_on_CUDA.pdf&lt;/A&gt;&lt;/=\r\nFONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV dir=3Dltr align=3Dleft&gt;&lt;SPAN class=3D104592912-1112=\r\n2009&gt;&lt;FONT color=3D#0000ff \nsize=3D2 face=3DArial&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV=\r\n&gt;\n&lt;DIV&gt;&lt;SPAN class=3D104592912-11122009&gt;&lt;/SPAN&gt;&lt;FONT face=3DArial&gt;&lt;FONT \nco=\r\nlor=3D#0000ff&gt;&lt;FONT \nsize=3D2&gt;My&nbsp;initial&nbsp;attempts&nbsp;at&nbsp;ru=\r\nnning&nbsp;everything&nbsp;on&nbsp;the&nbsp;GPU&nbsp;were&nbsp;disappointin=\r\ng.&nbsp;&nbsp;I&nbsp;have&nbsp;now&nbsp;adopted&nbsp;a&nbsp;hybrid&nbsp;app=\r\nroach&nbsp;-some&nbsp;parts&nbsp;of&nbsp;the&nbsp;code&nbsp;run&nbsp;on&nbs=\r\np;&lt;SPAN \nclass=3D104592912-11122009&gt;one or&nbsp;more cores on \nthe&lt;/SPAN&gt;&n=\r\nbsp;CPUs,&nbsp;others&nbsp;run&nbsp;on&nbsp;the&lt;SPAN \nclass=3D104592912-111=\r\n22009&gt; SMs of \nthe&lt;/SPAN&gt;&nbsp;GPUs.&nbsp;&nbsp;Furthermore,&nbsp;I&nbsp;am=\r\n&nbsp;investigating&nbsp;running&nbsp;a&nbsp;variant&nbsp;of&nbsp;HyperNEAT=\r\n&nbsp;on&nbsp;small&nbsp;clusters&nbsp;(Rocks&lt;SPAN \nclass=3D104592912-11122=\r\n009&gt; &lt;/SPAN&gt;/&lt;SPAN class=3D104592912-11122009&gt;w \n&lt;/SPAN&gt;CUDA&lt;SPAN class=3D1=\r\n04592912-11122009&gt; &lt;/SPAN&gt;&lt;SPAN \nclass=3D104592912-11122009&gt;rolls&lt;/SPAN&gt;).&=\r\nnbsp;&nbsp;Andrei&nbsp;is&nbsp;correct,&nbsp;in&nbsp;that&nbsp;it&nbsp;take=\r\ns&nbsp;HyperNEAT&nbsp;and&nbsp;carves&nbsp;it&nbsp;up&nbsp;in&nbsp;ways&nbs=\r\np;almost&nbsp;unrecognizable.&nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT c=\r\nolor=3D#0000ff size=3D2 face=3DArial&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT color=\r\n=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN class=3D104592912-11122009&gt;I have \ne=\r\nven started using HyperNEAT to discover better patterns of configuring the =\r\n\ncluster&#39;s optimized compute fabric.&nbsp; This is not a constant configura=\r\ntion, \nor so I&#39;ve found. The devil is in the details.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;=\r\nDIV&gt;&lt;FONT color=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D104592912-11=\r\n122009&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT color=3D#0000ff size=3D2 face=\r\n=3DArial&gt;&lt;SPAN class=3D104592912-11122009&gt;Ken \nLloyd&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;D=\r\nIV&gt;&lt;FONT color=3D#0000ff size=3D2 face=3DArial&gt;&lt;SPAN \nclass=3D104592912-111=\r\n22009&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;BLOCKQUOTE \nstyle=3D&quot;BORDER-LEFT: #0000ff=\r\n 2px solid; PADDING-LEFT: 5px; MARGIN-LEFT: 5px; MARGIN-RIGHT: 0px&quot;&gt;\n  &lt;DIV=\r\n dir=3Dltr lang=3Den-us class=3DOutlookMessageHeader align=3Dleft&gt;\n  &lt;HR ta=\r\nbIndex=3D-1&gt;\n  &lt;FONT size=3D2 face=3DTahoma&gt;&lt;B&gt;From:&lt;/B&gt; neat@yahoogroups.c=\r\nom \n  [mailto:neat@yahoogroups.com] &lt;B&gt;On Behalf Of &lt;/B&gt;Andrei&lt;BR&gt;&lt;B&gt;Sent:&lt;=\r\n/B&gt; \n  Friday, December 11, 2009 2:41 AM&lt;BR&gt;&lt;B&gt;To:&lt;/B&gt; \n  neat@yahoogroups.=\r\ncom&lt;BR&gt;&lt;B&gt;Subject:&lt;/B&gt; [neat] Re: solution for NEAT on \n  CUDA&lt;BR&gt;&lt;/FONT&gt;&lt;B=\r\nR&gt;&lt;/DIV&gt;\n  &lt;DIV&gt;&lt;/DIV&gt;&lt;SPAN style=3D&quot;DISPLAY: none&quot;&gt;&nbsp;&lt;/SPAN&gt; \n  &lt;DIV i=\r\nd=3Dygrp-text&gt;\n  &lt;P&gt;I&#39;m afraid that just moving the code to the GPU is not =\r\na good approach. The \n  code has to be redesigned with the CUDA architectur=\r\ne in mind to get real \n  speed-ups. &lt;BR&gt;&lt;BR&gt;Let me give you just one exampl=\r\ne: if you don&#39;t pay \n  attention to the memory hierarchy in the GPU and jus=\r\nt make random array \n  accesses from main GPU memory, your speed-up will be=\r\n 1.5x instead of, say, \n  10x. This is because individual memory accesses o=\r\nn a GPU take so much time \n  compared to the cores&#39; processing speed. On th=\r\ne CPU you seldom have this in \n  mind, since the CPU and compiler put your =\r\ndata in 2 or 3 levels of cache for \n  you. This is just one of the things C=\r\nPU code is blind to, another being the \n  actual order of kernel execution =\r\non a GPU. Kernels on current GPUs are \n  serialised, but not for long.&lt;BR&gt;&lt;=\r\nBR&gt;I know that Fermi addresses these \n  problems directly, with better memo=\r\nry management and caches and also multiple \n  kernel executions in parallel=\r\n. I wouldn&#39;t wait for that though, because from \n  the [rumour warning] Apr=\r\nil 2010 launch, it would take at least one year to get \n  it for a decent p=\r\nrice. It&#39;s not going to provide straightforward efficient \n  porting anyway=\r\n.&lt;BR&gt;&lt;BR&gt;Hope this make a case for redesigning the code with the \n  GPU in =\r\nmind. &lt;BR&gt;&lt;BR&gt;Cheers!&lt;BR&gt;Andrei.&lt;BR&gt;&lt;BR&gt;--- In &lt;A \n  href=3D&quot;mailto:neat%40=\r\nyahoogroups.com&quot;&gt;neat@yahoogroups.&lt;WBR&gt;com&lt;/A&gt;, Colin \n  Green &lt;colin.gr=\r\neen1@&lt;WBR&gt;...&gt; wrote:&lt;BR&gt;&gt;&lt;BR&gt;&gt; 2009/12/10 \n  openmind767 &lt;open=\r\nmind767@&lt;WBR&gt;...&gt;&lt;BR&gt;&gt; &gt;&lt;BR&gt;&gt; &gt; The whole \n  NEAT lib and ex=\r\nperiment are both full of branch. Making the whole things \n  running on CUD=\r\nA won&#39;t speed up, and it is&lt;BR&gt;&gt; &gt; not my target.&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt;=\r\n Hi,&lt;BR&gt;&gt; &lt;BR&gt;&gt; So your saying that we:&lt;BR&gt;&gt; &lt;BR&gt;&gt; 1) Load \n  a=\r\nll of the networks in a population into the GPU&lt;BR&gt;&gt; 2) Activate them in=\r\n \n  parallel.&lt;BR&gt;&gt; 3) Read the outputs.&lt;BR&gt;&gt; &lt;BR&gt;&gt; For larger netw=\r\norks \n  (e.g. from HyperNEAT) we may only get one or two&lt;BR&gt;&gt; networks i=\r\nnto the \n  GPU, so it would seem we need to put as many&lt;BR&gt;&gt; networks as=\r\n we can into \n  the GPU at a time. I think this should be&lt;BR&gt;&gt; fairly ea=\r\nsy to do and this \n  touches on previous comments from Ken Lloyd&lt;BR&gt;&gt; wh=\r\no I believe has gone \n  into this in far more detail - e.g. by also&lt;BR&gt;&gt;=\r\n loading problem domain \n  code into the GPU and trying to determine how&lt;BR=\r\n&gt;&gt; best to divide GPU and \n  CPU resources in the general case (for a wi=\r\nde&lt;BR&gt;&gt; range of \n  scenarios).&lt;BR&gt;&gt; &lt;BR&gt;&gt; Colin.&lt;BR&gt;&gt;&lt;BR&gt;&lt;BR&gt;&lt;=\r\n/P&gt;&lt;/DIV&gt;&lt;!-- end group email --&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_01D3_01CA7A24.96A8D9E0--\r\n\n"}}