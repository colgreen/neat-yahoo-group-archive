{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"qq_todRr3AdiJLtLBfMBYmMcpfAUPZzPBDhnS5aBOzJxCoTTBpdMKJNQTCOPukOR8od4yb-oE-LvQSQiO8X8DBc_jEDf","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HyperNEAT Tutorial?","postDate":"1259445625","msgId":4932,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhlczZocCt0dXNvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEE5ODRCM0YxNUFEMDU0NDlBQTNDRDMxNEY2QkQ1Q0NFRUNBQ0E2QGJuZXhjaDAyLmJuZTJrLmxvYz4="},"prevInTopic":4927,"nextInTopic":4961,"prevInTime":4931,"nextInTime":4933,"topicId":4884,"numMessagesInTopic":21,"msgSnippet":"Anthony, We are hoping to make the HyperNEAT Users Page at http://eplex.cs.ucf.edu/hyperNEATpage/HyperNEAT.html into a place where people can have questions","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 19413 invoked from network); 28 Nov 2009 22:00:26 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m12.grp.re1.yahoo.com with QMQP; 28 Nov 2009 22:00:26 -0000\r\nX-Received: from unknown (HELO n39b.bullet.mail.sp1.yahoo.com) (66.163.168.153)\n  by mta3.grp.sp2.yahoo.com with SMTP; 28 Nov 2009 22:00:26 -0000\r\nX-Received: from [69.147.65.148] by n39.bullet.mail.sp1.yahoo.com with NNFMP; 28 Nov 2009 22:00:25 -0000\r\nX-Received: from [98.137.35.12] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 28 Nov 2009 22:00:25 -0000\r\nDate: Sat, 28 Nov 2009 22:00:25 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hes6hp+tuso@...&gt;\r\nIn-Reply-To: &lt;A984B3F15AD05449AA3CD314F6BD5CCEECACA6@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: HyperNEAT Tutorial?\r\nX-Yahoo-Group-Post: member; u=54567749; y=MvEX-E07kcTaZEHGsAsPy0vell-9jQcr1EByV07WlMOytB9NfKUo\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nAnthony,\n\nWe are hoping to make the HyperNEAT Users Page at http://eplex.=\r\ncs.ucf.edu/hyperNEATpage/HyperNEAT.html into a place where people can have =\r\nquestions like yours answered.  The &quot;Introduction / What is HyperNEAT?&quot; sec=\r\ntion on that page is intended to provide some general answers to beginners =\r\nwithout having to read a research paper.  Did that section help you at all?=\r\n  I&#39;d like to make the page as useful as possible and we will continue to i=\r\nmprove it.\n\nTo answer your question, HyperNEAT is a significant step beyond=\r\n NEAT so it involves a lot of new ideas that aren&#39;t part of the original NE=\r\nAT.  Some of those concepts can theoretically be applied on top of non-NEAT=\r\n methods.  For example, in the following paper, NEAT is substituted with GP=\r\n to create a &quot;HyperGP,&quot; in which GP evolves the CPPN:\n\nBuk Z., Koutn=EDk J.=\r\n, =8Anorek M., NEAT in HyperNEAT Substituted with Genetic Programming, In: =\r\nICANNGA 2009.  \nhttp://cig.felk.cvut.cz/research/publications/hypergp.pdf\n\n=\r\nThat said, HyperNEAT addresses a limitation of NEAT, which is a limitation =\r\nof all direct encodings:  In NEAT, there is one gene for every connection i=\r\nn the network.  Even with complexification, that kind of representation can=\r\nnot hope to scale to networks with millions or more connections, because su=\r\nch networks would have millions or more genes, which is an astronomical sea=\r\nrch space.  \n\nHowever, there are in fact 100 trillion connections in the hu=\r\nman brain, which means that in principle it is possible to evolve such stru=\r\nctures.  Yet there are only about 30,000 genes in the human genome, which s=\r\nuggests that any evolutionary approach to evolving large-scale neural netwo=\r\nrks must encode the connection weights in a compressed description, which i=\r\ns called an indirect encoding.\n\nIn HyperNEAT, the indirect encoding is the =\r\nCPPN, which encodes the connectivity of a network as a pattern across its g=\r\neometry.  HyperNEAT combines the idea of indirect encoding with a strong no=\r\ntion of geometry and builds on our understanding of encoding patterns to pr=\r\noduce an algorithm that encodes large-scale topographies (i.e. connection w=\r\neights across a geometry).  Thus it extends NEAT by giving it the power of =\r\nindirect encoding, thereby greatly expanding the scope of networks it can e=\r\nvolve.\n\nOf course NEAT is still there under the hood.  NEAT is evolving the=\r\n CPPNs, which in turn encode neural networks (called substrates in HyperNEA=\r\nT).  The CPPNs themselves are still complexifying.  However, that complexif=\r\nication is no longer literally adding one connection at a time to a neural =\r\nnetwork.  Rather it is adding *information* to the encoding, so that it can=\r\n encode more complex *holistic* connectivity patterns.  In other words, Hyp=\r\nerNEAT means that evolution is no longer limited by the dimensionality of t=\r\nhe inputs and outputs but rather can search for the correct implicit proble=\r\nm complexity, whatever that may be, inside the CPPN.  The substrate (which =\r\nthe CPPN encodes) will then have as many connections as it needs, in princi=\r\nple up to millions or even trillions (with enough CPU power).\n\nIt is true t=\r\nhat geometry may be vague or difficult to decide in some problems.  Those m=\r\nay be more difficult for users to approach with HyperNEAT.  Yet I think mos=\r\nt if not all problems can ultimately be posed within some geometry, even if=\r\n it is abstract or conceptual.  As Jeff Clune has shown (https://www.msu.ed=\r\nu/~jclune/webfiles/publications/Clune-HyperNEATSensitivityToGeometry.pdf), =\r\ngeometry does not need to be perfect, or necessarily even close to perfect,=\r\n for HyperNEAT to still find some regularities to exploit, so while it may =\r\nbe an imperfect art, geometry is still ultimately a useful tool for conveyi=\r\nng exploitable information about a domain.\n\nI hope that provides some insig=\r\nht,\n\nken\n\n\n--- In neat@yahoogroups.com, &quot;Anthony Ison&quot; &lt;anthony.ison@...&gt; w=\r\nrote:\n&gt;\n&gt; I&#39;d like to add my vote to some kind of non-research style tutori=\r\nal -\n&gt; especially towards the HyperNEAT methodology.\n&gt; \n&gt;  \n&gt; \n&gt; Is there s=\r\nomewhere I can get an overview of how the CPPN is actually\n&gt; used and what =\r\nit does?  I&#39;ve looked through a number of papers on the\n&gt; main HyperNEAT si=\r\nte, but I feel like I&#39;m missing something.  I have read\n&gt; that HyperNEAT is=\r\n the future of NEAT - does this apply to problems where\n&gt; there is no usefu=\r\nl input geometry?  I understand how NEAT grows a\n&gt; network by adding nodes =\r\nand connections and overall I love the concept.\n&gt; It makes sense that a lea=\r\nrning network can adjust itself to improve its\n&gt; performance.  What I don&#39;t=\r\n really understand is how a CPPN is involved\n&gt; in this process.  \n&gt; \n&gt;  \n&gt; =\r\n\n&gt; Is anyone able to give a short overview on what HyperNEAT offers over\n&gt; =\r\nNEAT?\n&gt; \n&gt;  \n&gt; \n&gt; Cheers,\n&gt; \n&gt; Anthony\n&gt; \n&gt;  \n&gt; \n&gt;  \n&gt; \n&gt; From: dkuppitz [m=\r\nailto:daniel_kuppitz@...] \n&gt; Sent: Monday, 23 November 2009 9:08 AM\n&gt; To: n=\r\neat@yahoogroups.com\n&gt; Subject: [neat] Re: HyperNEAT Tutorial?\n&gt; \n&gt;  \n&gt; \n&gt;  =\r\n \n&gt; \n&gt; Hello Ken,\n&gt; \n&gt; here&#39;s just another vote for a tutorial, with the di=\r\nfference that I\n&gt; would prefer it for HyperSharpNEAT.\n&gt; \n&gt; It would be grea=\r\nt to see something like a HOL (Hands on Labs) where a\n&gt; new experiment is c=\r\nreated from the scratch. Parameters should be\n&gt; explained in detail, for ex=\r\nample: Which impact has the parameter\n&gt; Treshold, which impact has WeightRa=\r\nnge, etc.? How are the values for\n&gt; each parameter determined, what is take=\r\nn into account when you set the\n&gt; values? There are so many unanswered ques=\r\ntions for those who are new to\n&gt; HyperNEAT and I think most people (includi=\r\nng me) have a really great\n&gt; interest in this topic, but not the time to re=\r\nad (and understand) all\n&gt; the technical papers. So any tutorial should targ=\r\net beginners and\n&gt; explain things that have become self-evident for interme=\r\ndiates. \n&gt; \n&gt; I think one such &quot;official&quot; tutorial that explains every step=\r\n in detail\n&gt; should be enough, more will surely follow from the growing com=\r\nmunity.\n&gt; \n&gt; Cheers,\n&gt; Daniel\n&gt; \n&gt; --- In neat@yahoogroups.com &lt;mailto:neat=\r\n%40yahoogroups.com&gt; , &quot;Ken&quot;\n&gt; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Andrei, =\r\nwhich version of HyperNEAT are you interested in and what\n&gt; references have=\r\n you looked at so far? We can potentially improve the\n&gt; documentation based=\r\n on your comments (and a tutorial is a good idea),\n&gt; but first I want to un=\r\nderstand which &quot;comment-less examples&quot; you are\n&gt; referring to.\n&gt; &gt; \n&gt; &gt; Not=\r\ne that several experiments with complete source code are available\n&gt; in two=\r\n existing HyperNEAT releases of which I am aware. These and a\n&gt; variety of =\r\npublications from several groups are linked from the\n&gt; HyperNEAT Users Page=\r\n, which also provides a brief introduction:\n&gt; &gt; \n&gt; &gt; http://eplex.cs.ucf.ed=\r\nu/hyperNEATpage/HyperNEAT.html\n&gt; &gt; \n&gt; &gt; I understand you may have already b=\r\neen through this site and its\n&gt; associated software and papers, but I wante=\r\nd to point it out in case you\n&gt; had not been aware of it.\n&gt; &gt; \n&gt; &gt; We want =\r\nto make the algorithm as accessible as possible so your\n&gt; comments are appr=\r\neciated.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com &lt;mailto:neat%40y=\r\nahoogroups.com&gt; , &quot;Andrei&quot;\n&gt; &lt;andrei.rusu@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Can anyone p=\r\nlease recommend some HyperNEAT documentation, a\n&gt; tutorial, diagram, some c=\r\nlue, or anything that does not mean reverse\n&gt; engineering the comment-less =\r\nexamples ?\n&gt; &gt; &gt; \n&gt; &gt; &gt; Thanks! Andrei.\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}