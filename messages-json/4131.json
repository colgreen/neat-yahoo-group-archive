{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"IfdRYSnEtSl20mFVGV8zwRlrAIEslb_HPxGQ3zAqBOgdWgxS6_n1eNY84g6frLy8WhxIRhv7l8W-iYX42wR2TYO_I7wVl96bfx9xUccLm0j0","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Can novelty search be treated as an optimization technique?","postDate":"1212868246","msgId":4131,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcyZW9xbSs5N2tlQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIzMGU0NjNlMDgwNjA2MjMzMW43YzkwOGI4ZXM5YjFjOTE2MTI0NDNjMjBmQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4130,"nextInTopic":0,"prevInTime":4130,"nextInTime":4132,"topicId":4113,"numMessagesInTopic":6,"msgSnippet":"Julian, I am sure you are enjoying WCCI and presenting your work there.  I m looking forward to GECCO next month.  Are you planning to be at GECCO? I have","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 31715 invoked from network); 7 Jun 2008 19:50:49 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m55.grp.scd.yahoo.com with QMQP; 7 Jun 2008 19:50:49 -0000\r\nX-Received: from unknown (HELO n17c.bullet.scd.yahoo.com) (66.218.67.205)\n  by mta17.grp.scd.yahoo.com with SMTP; 7 Jun 2008 19:50:49 -0000\r\nX-Received: from [209.73.164.86] by n17.bullet.scd.yahoo.com with NNFMP; 07 Jun 2008 19:50:49 -0000\r\nX-Received: from [66.218.66.73] by t8.bullet.scd.yahoo.com with NNFMP; 07 Jun 2008 19:50:49 -0000\r\nDate: Sat, 07 Jun 2008 19:50:46 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g2eoqm+97ke@...&gt;\r\nIn-Reply-To: &lt;230e463e0806062331n7c908b8es9b1c91612443c20f@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Can novelty search be treated as an optimization technique?\r\nX-Yahoo-Group-Post: member; u=54567749; y=Hjr77s5yYXjb_5Vhp7jd2iIqa0XkEMFRySJW94PKco3bW6h7zOp_\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJulian,\n\nI am sure you are enjoying WCCI and presenting your work there.  I=\r\n&#39;m\nlooking forward to GECCO next month.  Are you planning to be at GECCO?\n\n=\r\nI have indeed heard of EANT and EANT-II.  I know of a couple EANT papers:\n\n=\r\nhttp://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/yk/06_ias.pdf=\r\n\n\nhttp://www.ks.informatik.uni-kiel.de/~yk/ESANN2005EANT.pdf\n\nThe latter ha=\r\ns the only comparison with NEAT that I know of (in pole\nbalancing), but unf=\r\nortunately the authors did not report the result in\nmy dissertation from NE=\r\nAT with a small population, which is actually\nbetter than the one reported =\r\nfor EANT. Instead, they used our older\nresults, even though they cite my di=\r\nssertation.  However, it doesn&#39;t\nreally matter because I think pole balanci=\r\nng has been so\nover-optimized that it is starting to be less meaningful as =\r\na\nbenchmark.  In other words, with several algorithms performing so well\nat=\r\n pole balancing at this point, further gains in performance are more\nlikely=\r\n to be specific to pole balancing.\n\nAnyway, EANT is quite similar to NEAT. =\r\n It&#39;s based on the principles\nof historical marking and complexification, a=\r\nnd has a mechanism\ninspired by the idea of speciation in NEAT:\n\n&quot;In order t=\r\no protect the structural innovations or discoveries of the\nevolution, young=\r\n structures that are less than few generations old\nwith respect to the larg=\r\ner time-scale are carried over along the\nevolution regardless of the result=\r\ns of the selection operator.&quot;\n\nSo then the main question is, what are the m=\r\nain differences?  The\nauthors cite three primary differences they believe a=\r\nre significant:\n\n1. A &quot;linear genome&quot;\n2. The separate loops for evolving we=\r\nights and topologies (which they\ncall &quot;structural exploitation) \n3. Using t=\r\nhe CMA-ES to evolve the weights instead of regular mutation.\n\nI do not real=\r\nly understand the appeal of the linear genome.  It is\nsupposed to be good b=\r\necause it can be activated &quot;as-is&quot; in its linear\nform without having to tra=\r\nnslate it into a network, but since that\ngenotype-&gt;phenotype translation as=\r\npect of neuroevolution is not a\nparticularly significant factor in performa=\r\nnce with a direct encoding,\nI am not sure it is worth the arcane linear enc=\r\noding that they\nintroduced (it&#39;s not easy to understand or read the genomes=\r\n\nintuitively).  \n\nThe separated loops are more interesting.  It is possible=\r\n that it does\nprovide a benefit to separate structure and weight changes in=\r\nto outer\nand inner loops.  However, the two publications I mention above do=\r\n not\nsettle this issue because the only comparison is the pole balancing\nco=\r\nmparison, in which EANT actually doesn&#39;t perform as well at NEAT\nwith a sma=\r\nll population (in my dissertation).  However, Julian, don&#39;t\nyour own result=\r\ns suggest that it may be better to spend time on\nweights until you stagnate=\r\n, and only then switch to mutating\nstructure?  So maybe this idea has some =\r\nweight. Actually, can you\nrefresh my memory on the overall lesson you belie=\r\nve you&#39;ve learned\nwith respect to the separate phases?\n\nThe CMA-ES is the o=\r\nther significant part.  I do believe that combining\nNEAT with CMA-ES could =\r\nbe useful in some problems, and it&#39;s possible\nit is giving a benefit in EAN=\r\nT.  One question is, what is more\nimportant in EANT, the CMA-ES or the inne=\r\nr/outer loops?  I do not know\nthe answer to this question from their result=\r\ns, except in the first\npaper cited above it is clear that CMA-ES makes EANT=\r\n better than EANT\nwithout CMA-ES on the robot servo problem they attempt wi=\r\nth it.  I am\nguessing the CMA-ES helps a lot on the problems they&#39;ve tested=\r\n.\n\nOverall, EANT is conceptually a version of NEAT in which you wait to\nmut=\r\nate structure until the weight optimization stagnates, and with a\nCMA-ES us=\r\ned to optimize the weights.  It is not clear to me from the\nresults I have =\r\nseen if one is better than the other, and I doubt there\nis a single answer =\r\nto the question of which is overall better (NFL),\nbut the main ideas in EAN=\r\nT appear to be sensible modifications to NEAT\nthat might help in some cases=\r\n.  \n\nOne other note for me is that I believe neuroevolution in general\nshou=\r\nld be going in the direction of indirect encodings, so that has to\nbe taken=\r\n into account as well.  It looks like EANT could be used to\nevolve CPPNs to=\r\no, so you could also have &quot;HyperEANT&quot; theoretically. \n\nThere is a final cav=\r\neat that is probably relevant to some people: \nEANT seems more complicated =\r\nto implement than NEAT, with its special\nencoding, different loops (includi=\r\nng switching criteria), and CMA-ES.\n Thus the hope is that the extra effort=\r\n is justified in its returns. \nIn discussing algorithms, it is often overlo=\r\noked that algorithmic\nsimplicity is sometimes as important as performance t=\r\no practitioners\ndeciding what algorithm to use when the respective performa=\r\nnces are\nnot dramatically different, so it&#39;s something to consider.\n\nken\n\n-=\r\n-- In neat@yahoogroups.com, &quot;Julian Togelius&quot; &lt;julian@...&gt; wrote:\n&gt;\n&gt; Ken,\n=\r\n&gt; \n&gt; I presented our first memetic climber paper at WCCI yesterday, and one=\r\n\n&gt; of the people in the audience was Nils T. Siebel, coinventor of the\n&gt; EA=\r\nNT-II algorithm. His algorithm is based on complexification and\n&gt; CMA-ES, a=\r\nnd he claims that it works very well (better than NEAT on his\n&gt; own robot b=\r\nenchmark, apparently). Like in our papers (the PPSN one was\n&gt; accepted) he =\r\nseparates the evolution of weights and topologies. I\n&gt; don&#39;t know exactly h=\r\now he handles the varying dimensionality, but I\n&gt; got the impression from w=\r\nhat he said that he simply restarts the\n&gt; CMA-ES when needed. I was very su=\r\nrprised that I had not heard of this\n&gt; algorithm before - have you?\n&gt; \n&gt; As=\r\n I&#39;m still in Hong Kong, I haven&#39;t had time to read his papers yet,\n&gt; but I=\r\n will definitely look into this.\n&gt; \n&gt; Julian\n&gt; \n&gt; On 06/06/2008, Kenneth St=\r\nanley &lt;kstanley@...&gt; wrote:\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Julian,\n&gt; &gt;\n&gt; &gt; Tha=\r\nnks for the further insight on CMA-ES. I also think there may be a\n&gt; &gt; way =\r\nto combine it &quot;properly&quot; with a variable-dimension encoding.\n&gt; &gt; Somehow th=\r\ne dimensions for which there is no information (e.g. because\n&gt; &gt; they were =\r\njust added) need to be possible to incorporate into the\n&gt; &gt; existing model =\r\nseamlessly on the fly, instead of starting over again.\n&gt; &gt; It seems like in=\r\n principle that should be possible?\n&gt; &gt;\n&gt; &gt; Anyway, like you said, it is st=\r\nill not a panacea since it can be\ngreedy.\n&gt; &gt;\n&gt; &gt; ken\n&gt; &gt;\n&gt; &gt; --- In neat@y=\r\nahoogroups.com, &quot;Julian Togelius&quot; &lt;julian@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi Peter and=\r\n Ken,\n&gt; &gt; &gt;\n&gt; &gt; &gt; We actually just recently combined CMA-ES with topology s=\r\nearch\n(though\n&gt; &gt; &gt; not NEAT-based) in a paper submitted to PPSN. I&#39;ll make=\r\n the paper\n&gt; &gt; &gt; available as soon as it&#39;s accepted and revised, but send m=\r\ne a\nprivate\n&gt; &gt; &gt; mail if you want a draft before that.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Basical=\r\nly, what we found in this respect is that for two standard\n&gt; &gt; &gt; reinforcem=\r\nent learning problems, our &quot;memetic CMA-ES&quot; did much worse\n&gt; &gt; &gt; than stand=\r\nard CMA. This is probably because it takes time to get a\n&gt; &gt; &gt; good covaria=\r\nnce matrix, typically many hundreds of evaluations, and\n&gt; &gt; &gt; everytime you=\r\n change the topology you have to restart the CMA-ES.\n&gt; &gt; &gt; However, in a ve=\r\nrsion of the problem with lots of extra inputs (and\n&gt; &gt; &gt; thus lots of dece=\r\nptiveness) the memetic CMA-ES could outperform\nboth a\n&gt; &gt; &gt; normal CMA-ES a=\r\nnd a memetic ES.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Finding a way of dealing &quot;properly&quot; with varyi=\r\nng number of\ndimensions\n&gt; &gt; &gt; would be very interesting indeed. But I also =\r\nagree with Ken that\n&gt; &gt; &gt; CMA-ES is not a panacea in any way, and in fact m=\r\night be too greedy\n&gt; &gt; &gt; for many problems.\n&gt; &gt; &gt;\n&gt; &gt; &gt; By the way, I just =\r\ndropped down in Hong Kong - any members of this\n&gt; &gt; &gt; group attending WCCI?=\r\n Maybe even know of any interesting papers\nbeing\n&gt; &gt; &gt; presented?\n&gt; &gt; &gt;\n&gt; &gt;=\r\n &gt; Julian\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt; &gt; On 26/05/2008, Kenneth Stanley &lt;kstanley@&gt; =\r\nwrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Peter,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I also think NEAT could work =\r\nwith a CMA-ES (or some kind of\nEDA, which\n&gt; &gt; &gt; &gt; seems to do something sim=\r\nilar). While EANT cycles through\nphases of\n&gt; &gt; &gt; &gt; topology and weight opti=\r\nmization, I think maybe there is a more\n&gt; &gt; &gt; &gt; elegant way to just combine=\r\n the two by dealing properly with\nvariable\n&gt; &gt; &gt; &gt; numbers of dimensions in=\r\n the CMA-ES.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Anyway, that&#39;s not the main point you&#39;re makin=\r\ng. Your main\nquestion\n&gt; &gt; &gt; &gt; is whether something like CMA-ES, which focus=\r\nes on\noptimization, can\n&gt; &gt; &gt; &gt; be used in a novelty search. Of course, nov=\r\nelty search is\n&gt; &gt; &gt; &gt; philosophically almost the antithesis of optimizatio=\r\nn. However, in\n&gt; &gt; &gt; &gt; practice the search for novelty itself could be view=\r\ned as the\n&gt; &gt; &gt; &gt; objective, and then, in principle, an optimization method=\r\n might be\n&gt; &gt; &gt; &gt; able to optimize to that end.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; It is true =\r\nthat from one generation to the next, the scores\nchange and\n&gt; &gt; &gt; &gt; therefo=\r\nre you cannot rely on a constant gradient. However,\nisn&#39;t it\n&gt; &gt; &gt; &gt; true t=\r\nhat CMA-ES (and EDAs) computes its covariance matrix\nfrom only\n&gt; &gt; &gt; &gt; the =\r\ncurrent generation (i.e. current population). If so, it could\n&gt; &gt; &gt; &gt; compu=\r\nte how genetic parameters correlate to novelty scores, and\n&gt; &gt; &gt; &gt; thereby =\r\ntry to optimize novelty for that particular population. In\n&gt; &gt; &gt; &gt; other wo=\r\nrds, in a fixed population, I don&#39;t see a reason it\ncouldn&#39;t\n&gt; &gt; &gt; &gt; be app=\r\nlied (and then reapplied for the next population all over\n&gt; &gt; &gt; &gt; again). H=\r\nowever, I guess you are saying that you can&#39;t just\nlaunch a\n&gt; &gt; &gt; &gt; &quot;phase&quot;=\r\n of CMA-ES on its own since it would not optimize\ntopologies.\n&gt; &gt; &gt; &gt; But I=\r\n don&#39;t think that would necessarily matter. Still, even\nbetter\n&gt; &gt; &gt; &gt; woul=\r\nd be to seamlessly combine the CMA-ES with NEAT instead of\n&gt; &gt; &gt; &gt; splittin=\r\ng them into phases.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Whether or not CMA-ES works better than=\r\n stochastic mutation\nover the\n&gt; &gt; &gt; &gt; long run is a different question, but=\r\n it&#39;s a question even in\nregular\n&gt; &gt; &gt; &gt; objective-based optimization. I ac=\r\ntually think that CMA-ES and the\n&gt; &gt; &gt; &gt; like are greedy, although you say =\r\nit is not. It computes the most\n&gt; &gt; &gt; &gt; promising vector based exclusively =\r\non the current\ndistribution. Thus\n&gt; &gt; &gt; &gt; it is in a sense overly focused o=\r\nn the initial population\n&gt; &gt; &gt; &gt; distribution, which may be highly misleadi=\r\nng with respect to the\n&gt; &gt; &gt; &gt; ultimate objective. Basically, it&#39;s the prob=\r\nlem of deception as\n&gt; &gt; &gt; &gt; usual, but I think CMA-ES is even more suscepti=\r\nble to it\nbecause it\n&gt; &gt; &gt; &gt; actively seeks out a model of the deceptive di=\r\nstribution. That is\n&gt; &gt; &gt; &gt; pretty greedy in my view.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Now, =\r\nif the problem is not deceptive, then that is great,\nbecause the\n&gt; &gt; &gt; &gt; mo=\r\ndel will be way better than random perturbations. So you\nwill find\n&gt; &gt; &gt; &gt; =\r\nsome problems where it will be fantastic. But in highly deceptive\n&gt; &gt; &gt; &gt; p=\r\nroblems I am not sure. Some of the results for CMA-ES reported to\n&gt; &gt; &gt; &gt; d=\r\nate may be misleading because they do not focus on deceptive\n&gt; &gt; &gt; &gt; proble=\r\nms. One way to see this fact is that they use extremely\nsmall\n&gt; &gt; &gt; &gt; popul=\r\nations. That simply cannot work well in a highly deceptive\n&gt; &gt; &gt; &gt; domain. =\r\nIn fact, as you can see in my dissertation, regular\nNEAT is\n&gt; &gt; &gt; &gt; also ex=\r\ntremely fast at pole balancing problems with a tiny\npopulation.\n&gt; &gt; &gt; &gt; So =\r\nthat tells you more about pole balancing having a really large\n&gt; &gt; &gt; &gt; basi=\r\nn of attraction than about either method in general.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Anyway=\r\n, I think ultimately that it can be combined with NEAT\nand that\n&gt; &gt; &gt; &gt; wou=\r\nld be interesting, and such a system could even work with\nnovelty\n&gt; &gt; &gt; &gt; s=\r\nearch. Whether it could work better is an open question.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; ke=\r\nn\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yahoogroups.com&gt;,\n&gt; &gt;=\r\n\n&gt; &gt; &quot;peterberrington&quot;\n&gt; &gt; &gt; &gt; &lt;peterberrington@&gt;\n&gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; I&#39;ve been tinkering with many optimization techniques and\n&gt; &gt; con=\r\nsidering\n&gt; &gt; &gt; &gt; &gt; the possibility of integrating some with the mechanics o=\r\nf neat,\n&gt; &gt; in the\n&gt; &gt; &gt; &gt; &gt; vein of EANT, which sadly has no open source i=\r\nmplementation.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; While I&#39;m trying to add that functionali=\r\nty to the neat-python\n&gt; &gt; &gt; &gt; &gt; implementation I use, I&#39;m really wondering =\r\nif its at all\n&gt; &gt; applicable to\n&gt; &gt; &gt; &gt; &gt; novelty search. In novelty search=\r\n, there is a specific pressure\n&gt; &gt; to do\n&gt; &gt; &gt; &gt; &gt; something new and indeed=\r\n we do assign a numeric novelty value to\n&gt; &gt; each\n&gt; &gt; &gt; &gt; &gt; individual beha=\r\nviour at the time of its evaluation for addition\n&gt; &gt; to the\n&gt; &gt; &gt; &gt; &gt; archi=\r\nve. However, the score an individual receives depends on\n&gt; &gt; who its\n&gt; &gt; &gt; =\r\n&gt; &gt; up against, so its not objective. Without a function to\n&gt; &gt; minimize, t=\r\nhe\n&gt; &gt; &gt; &gt; &gt; dynamics which allow optimization techniques to work may be\n&gt; =\r\n&gt; damaged to\n&gt; &gt; &gt; &gt; &gt; the point of rendering it no better than random sear=\r\nch.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I&#39;m still puzzled on the discussion Peter C raised =\r\nabout\n&gt; &gt; reevaluating\n&gt; &gt; &gt; &gt; &gt; the novelty of behaviours in the archive a=\r\nt future intervals.\n&gt; &gt; &gt; &gt; &gt; Shouldn&#39;t the novelty score assigned to each =\r\npoint be\nuseless after\n&gt; &gt; &gt; &gt; &gt; we&#39;ve decided whether or not to archive th=\r\ne behaviour? I&#39;m\nnot sure\n&gt; &gt; &gt; &gt; &gt; that joint angles over every timestep i=\r\ns really the best way the\n&gt; &gt; &gt; &gt; &gt; characterize behaviour for a 3d ragdoll=\r\n rig, as you are\nessentially\n&gt; &gt; &gt; &gt; &gt; providing no clear way to distinguis=\r\nh a good behaviour from\na bad\n&gt; &gt; &gt; &gt; &gt; behaviour. Although I haven&#39;t been =\r\nable to use optimized\nlibraries\n&gt; &gt; &gt; &gt; &gt; with my current simulation config=\r\nuration (this is hopefully\nchanging\n&gt; &gt; &gt; &gt; &gt; very soon), I have noticed a =\r\nsignificant boost in speed with my\n&gt; &gt; &gt; &gt; &gt; ragdoll evolution by defining =\r\nbehaviour simply as the final\nx y z\n&gt; &gt; &gt; &gt; &gt; triplet for the center of mas=\r\ns. In this way the search quickly\n&gt; &gt; &gt; &gt; &gt; exhausts all the easy ways of f=\r\nalling close to its origin and\n&gt; &gt; pressure\n&gt; &gt; &gt; &gt; &gt; mounts for it explore=\r\n end locations successively farther and\nfarther\n&gt; &gt; &gt; &gt; &gt; away from its ori=\r\ngin; in essence the objective function is\n&gt; &gt; realized in\n&gt; &gt; &gt; &gt; &gt; that ch=\r\naracterization of behavioural distance.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; In any case, we=\r\n are explicitly trying to reward novelty by\nselecting\n&gt; &gt; &gt; &gt; &gt; for further=\r\n evaluation any individuals which satisfy a minimum\n&gt; &gt; &gt; &gt; &gt; threshold of =\r\nhow different their behaviour is. Something\nabout that\n&gt; &gt; &gt; &gt; &gt; gives me a=\r\n feeling that maybe optimization techniques are\n&gt; &gt; applicable,\n&gt; &gt; &gt; &gt; &gt; b=\r\nut only if the dynamics of optimization can be adapted to the\n&gt; &gt; &gt; &gt; &gt; unw=\r\nieldy workings of novelty search.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Rather than maximizin=\r\ng fitness, optimization techniques usually\n&gt; &gt; &gt; &gt; &gt; minimize an objective =\r\nfunction so the fitness scale is simply\n&gt; &gt; reversed\n&gt; &gt; &gt; &gt; &gt; with a perfe=\r\nct score being 0.0\n&gt; &gt; &gt; &gt; &gt; Since in this domain theres no such thing as p=\r\nerfect\nnovelty, can\n&gt; &gt; &gt; &gt; &gt; anyone provide any insights as to a framework=\r\n where optimization\n&gt; &gt; &gt; &gt; &gt; techniques can be harnessed to maximize novel=\r\nty? I feel this\nis a\n&gt; &gt; &gt; &gt; &gt; really important area to focus attention on,=\r\n as it could\npotentially\n&gt; &gt; &gt; &gt; &gt; lead to a dramatic increase in the fitne=\r\nss per number of\n&gt; &gt; evaluations.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; As some background: I=\r\n&#39;ve long been tempted after reading\npapers on\n&gt; &gt; &gt; &gt; &gt; EANT to try droppin=\r\ng in a more advanced optimization\nfunction into\n&gt; &gt; &gt; &gt; &gt; NEAT, like some o=\r\nf the new variations on the covariance matrix\n&gt; &gt; &gt; &gt; &gt; adaption evolution =\r\nstrategy. The way this was implemented in\n&gt; &gt; EANT was\n&gt; &gt; &gt; &gt; &gt; by splitti=\r\nng NEATs main loop into a &quot;structural exploration&quot;\n&gt; &gt; loop for\n&gt; &gt; &gt; &gt; &gt; b=\r\nuilding networks, and optimizing the weight connection values\n&gt; &gt; &gt; &gt; &gt; sep=\r\narately within a nested loop, using CMA-ES. This division\nof work\n&gt; &gt; &gt; &gt; &gt;=\r\n permits the net to be treated as an n-dimensional equation where\n&gt; &gt; n is\n=\r\n&gt; &gt; &gt; &gt; &gt; the number of connection or node weights (or other properties)\n&gt; =\r\n&gt; we wish\n&gt; &gt; &gt; &gt; &gt; to optimize (i.e. everything that isn&#39;t defining the\nto=\r\npology of the\n&gt; &gt; &gt; &gt; &gt; net). I think it can be argued that standard fitnes=\r\ns based\nneat is a\n&gt; &gt; &gt; &gt; &gt; greedier approach because it cartwheels through=\r\n topological\n&gt; &gt; space and\n&gt; &gt; &gt; &gt; &gt; weight parameter space at the same tim=\r\ne. I want to plug in an\n&gt; &gt; &gt; &gt; &gt; optimization function, but I can&#39;t think =\r\nof how anymore, or\neven if\n&gt; &gt; &gt; &gt; &gt; the two search techniques are reconcil=\r\nable.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Theres no point optimizing within a specific net =\r\ntopology in\nnovelty\n&gt; &gt; &gt; &gt; &gt; search because you want to kind of push out a=\r\nnd fill behavioural\n&gt; &gt; space\n&gt; &gt; &gt; &gt; &gt; as evenly as possible, so theres no=\r\n nook or crack which\nescapes the\n&gt; &gt; &gt; &gt; &gt; poking and prodding of your sear=\r\nch; without the\n&gt; &gt; &gt; &gt; &gt; competition/coevolutionary aspect of defining fit=\r\nness\nagainst the\n&gt; &gt; &gt; &gt; &gt; backdrop of current rivals and ancestors, I doub=\r\nt you&#39;d see\nanything\n&gt; &gt; &gt; &gt; &gt; more effective than random selection. If you=\r\n can&#39;t optimize\neach net\n&gt; &gt; &gt; &gt; &gt; topology in a vacuum, is there another w=\r\nay fitness-based\n&gt; &gt; searches and\n&gt; &gt; &gt; &gt; &gt; novelty-based searches can reac=\r\nh a compromise where each\ncomplements\n&gt; &gt; &gt; &gt; &gt; the other?\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; =\r\n&gt; &gt; I&#39;ve given some thought to the idea of phased searching, but you\n&gt; &gt; wo=\r\nuld\n&gt; &gt; &gt; &gt; &gt; have to find some way of defining stopping critera for when\n&gt;=\r\n &gt; you&#39;d want\n&gt; &gt; &gt; &gt; &gt; to optimize an objective function and when you&#39;d wa=\r\nnt to\ndiversify\n&gt; &gt; &gt; &gt; &gt; from bottom up complexity wise.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt;\n&gt; &gt; &gt; &gt; &gt; As an interesting side note, to anyone whos had a sneak peak a=\r\nt\n&gt; &gt; Peter\n&gt; &gt; &gt; &gt; &gt; C&#39;s maze navigation novelty search program, isn&#39;t it\n=\r\nuncanny, the\n&gt; &gt; &gt; &gt; &gt; resemblance between the past behaviours that have ac=\r\ncumulated,\n&gt; &gt; and the\n&gt; &gt; &gt; &gt; &gt; growth of a plant? As more organisms fill =\r\nup the space of\npossible\n&gt; &gt; &gt; &gt; &gt; behaviours its tempting to imagine it as=\r\n molasses which\nslowly oozes\n&gt; &gt; &gt; &gt; &gt; its way into every crack and crevice=\r\n it can reach. Perhaps there\n&gt; &gt; is a\n&gt; &gt; &gt; &gt; &gt; useful insight to be drawn =\r\nfrom that, I have no idea, I just\nthought\n&gt; &gt; &gt; &gt; &gt; it looked very &quot;organic=\r\n&quot;.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; --\n&gt; &gt; &gt; Julia=\r\nn Togelius\n&gt; &gt; &gt; IDSIA\n&gt; &gt; &gt; Galleria 2\n&gt; &gt; &gt; 6928 Manno-Lugano\n&gt; &gt; &gt; Switz=\r\nerland\n&gt; &gt; &gt; julian@\n&gt; &gt; &gt; http://julian.togelius.com\n&gt; &gt; &gt; http://www.idsi=\r\na.ch/~togelius\n&gt; &gt; &gt; +41-764-110679\n&gt; &gt; &gt; +46-705-192088\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n=\r\n&gt; &gt; \n&gt; \n&gt; \n&gt; \n&gt; -- \n&gt; Julian Togelius\n&gt; IDSIA\n&gt; Galleria 2\n&gt; 6928 Manno-Lug=\r\nano\n&gt; Switzerland\n&gt; julian@...\n&gt; http://julian.togelius.com\n&gt; http://www.id=\r\nsia.ch/~togelius\n&gt; +41-764-110679\n&gt; +46-705-192088\n&gt;\n\n\n\n"}}