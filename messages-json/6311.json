{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":434634266,"authorName":"Vassilis Vassiliades","from":"Vassilis Vassiliades &lt;vassilisvas@...&gt;","profile":"v.vassiliades","replyTo":"LIST","senderId":"8pF_gdOh6AksSc_LzVAZVpyOPo3Mjuh78VYsW_957nLnzXzxycT8xp3fJZjP31bxFzQl5u3F5wMJwkMRohZcAcqE22Ma-LmgtML3SNbaloCC0Vs","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Self-adaptive Mutation Rates, Novelty Search and CMA-ES","postDate":"1399285139","msgId":6311,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBTnRYaG10Nitmd25IcFVTQzYxVHljcVF4QjNVNTVhY011dVBXbVdqWW42QUp2ay1FQUBtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PEMwMTk5NzgyLTMwQTMtNDcxRi1CRUM0LTA2MUZDRjM2RDZBQkBnbWFpbC5jb20+","referencesHeader":"PENBTnRYaG1zMXdqek9tN2hXYUNaRG5ZSFQzNE9nUEhuNVJKVXIzOEVkc19fcWlBV2trZ0BtYWlsLmdtYWlsLmNvbT4JPDUxMDBCOUQyLUFDQ0ItNDVCRi04RTc0LTJFMzY3NUE1NTQzN0BnbWFpbC5jb20+CTwwMDJmMDFjZjY2ZWQkMjI2NmFiYjAkNjczNDAzMTAkQHdhdHRzeXMuY29tPgk8Q0ErZHVpbVBHcnc1QTJqUHVoRnhEWmlPMEMrTTJpK0pTOEcwYyt3eUs9VmJvbXE9V2pBQG1haWwuZ21haWwuY29tPgk8bGs0NzhuKzE4MHZuanNAWWFob29Hcm91cHMuY29tPgk8Q0FOdFhobXV6MEVUTDZkYXVPR3NYT3lUQnJIdUYxTnRKcWpYM05oTnp0VjItWnQ2c0NRQG1haWwuZ21haWwuY29tPgk8QzAxOTk3ODItMzBBMy00NzFGLUJFQzQtMDYxRkNGMzZENkFCQGdtYWlsLmNvbT4="},"prevInTopic":6310,"nextInTopic":6312,"prevInTime":6310,"nextInTime":6312,"topicId":6292,"numMessagesInTopic":19,"msgSnippet":"Hello Jeff, I was thinking about the mutation rate and mutation strength/step as being the same thing which is not. I apologize for the confusion. I realized","rawEmail":"Return-Path: &lt;vassilisvas@...&gt;\r\nX-Sender: vassilisvas@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 50324 invoked by uid 102); 5 May 2014 10:19:00 -0000\r\nX-Received: from unknown (HELO mtaq5.grp.bf1.yahoo.com) (10.193.84.36)\n  by m7.grp.bf1.yahoo.com with SMTP; 5 May 2014 10:19:00 -0000\r\nX-Received: (qmail 1386 invoked from network); 5 May 2014 10:19:00 -0000\r\nX-Received: from unknown (HELO mail-pa0-f43.google.com) (209.85.220.43)\n  by mtaq5.grp.bf1.yahoo.com with SMTP; 5 May 2014 10:19:00 -0000\r\nX-Received: by mail-pa0-f43.google.com with SMTP id bj1so2002346pad.2\n        for &lt;neat@yahoogroups.com&gt;; Mon, 05 May 2014 03:18:59 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.66.119.136 with SMTP id ku8mr70860088pab.121.1399285139407;\n Mon, 05 May 2014 03:18:59 -0700 (PDT)\r\nX-Received: by 10.70.50.103 with HTTP; Mon, 5 May 2014 03:18:59 -0700 (PDT)\r\nIn-Reply-To: &lt;C0199782-30A3-471F-BEC4-061FCF36D6AB@...&gt;\r\nReferences: &lt;CANtXhms1wjzOm7hWaCZDnYHT34OgPHn5RJUr38Eds__qiAWkkg@...&gt;\n\t&lt;5100B9D2-ACCB-45BF-8E74-2E3675A55437@...&gt;\n\t&lt;002f01cf66ed$2266abb0$67340310$@...&gt;\n\t&lt;CA+duimPGrw5A2jPuhFxDZiO0C+M2i+JS8G0c+wyK=Vbomq=WjA@...&gt;\n\t&lt;lk478n+180vnjs@...&gt;\n\t&lt;CANtXhmuz0ETL6dauOGsXOyTBrHuF1NtJqjX3NhNztV2-Zt6sCQ@...&gt;\n\t&lt;C0199782-30A3-471F-BEC4-061FCF36D6AB@...&gt;\r\nDate: Mon, 5 May 2014 13:18:59 +0300\r\nMessage-ID: &lt;CANtXhmt6+fwnHpUSC61TycqQxB3U55acMuuPWmWjYn6AJvk-EA@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=e89a8ffbacdfac890b04f8a47513\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Vassilis Vassiliades &lt;vassilisvas@...&gt;\r\nSubject: Re: [neat] Self-adaptive Mutation Rates, Novelty Search and CMA-ES\r\nX-Yahoo-Group-Post: member; u=434634266; y=_cyW_Y6k6D7QRCognmVo2RYTcCBC-fXlh20LaAlQ4Q501XzgDyXIYw\r\nX-Yahoo-Profile: v.vassiliades\r\n\r\n\r\n--e89a8ffbacdfac890b04f8a47513\r\nContent-Type: text/plain; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHello Jeff,\n\nI was thinking about the mutation rate and mutation strength/s=\r\ntep as being\nthe same thing which is not. I apologize for the confusion. I =\r\nrealized that\nafter reading your email. I also apologize for the notation; =\r\nit would be\nnice if we could write some parts of the email in LaTeX (perhap=\r\ns we can and\nI don&#39;t know about it) :-)\n\nLet me clarify:\n\nAs far as I under=\r\nstand, in real-valued optimization with evolution\nstrategies (ES), the conc=\r\nept of mutation rate and mutation strength/step is\ndifferent than in geneti=\r\nc algorithms. In genetic algorithms, a mutation\nrate is a probability that =\r\na value will be mutated by an amount equal to\nthe mutation strength/step. I=\r\nn ES these two concepts are intertwined. That\nis, each individual parameter=\r\n is *always* perturbed by sampling the\nperturbation from a Gaussian distrib=\r\nution with mean 0. The standard\ndeviation of this Gaussian distribution is =\r\ndifferent for each parameter,\nand this value is what is self-adapted and &quot;h=\r\nitchhikes along with the other\nparameters on the genome&quot;. Since the perturb=\r\nation is probabilistic and the\ndistribution (of this perturbation) is cente=\r\nred around 0, there is a high\nprobability that it will be very small. Also,=\r\n note that self-adaptation\nmight make the standard deviation of some of the=\r\n parameters become very\nsmall, which effectively means that their mutation =\r\nrate approaches zero.\n\nSummarizing, in ES there are no self-adaptive mutati=\r\non rates, but there are\nself-adaptive standard deviations of Gaussian distr=\r\nibutions (which\nindirectly affect both the mutation rates and mutation stre=\r\nngths). In\nCMA-ES, a covariance matrix (which captures correlations between=\r\n\ndimensions) is self-adapted as well and this makes convergence to the\nopti=\r\nmum faster.\n\nNote that discrete spaces are differently handled. You need to=\r\n have a\nmutation rate which is usually sampled from a uniform distribution.=\r\n But the\noriginal ES were designed for real-valued spaces.\n\nRegarding the i=\r\nssue of the population, my view is the following. In ES,\nthere is something=\r\n called &quot;plus&quot; selection (&quot;+&quot;) and &quot;comma&quot; selection\n(&quot;,&quot;).\n\n(mu + lambda) =\r\nmeans that there are mu parents that create lambda offspring,\nwith mu &gt; 0, =\r\nlambda &gt; 0. What survives in the next generation is the best\nindividuals fr=\r\nom both parents and offspring. So, the effective population\nsize is the max=\r\nimum of the two.\n\n(mu, lambda) means that there are mu parents that create =\r\nlambda offspring,\nwith lambda &gt;=3D mu, mu &gt; 0. What survives in the next ge=\r\nneration is the best\nindividuals, but only from the offspring. Since lambda=\r\n is at least equal to\nmu, the effective population size is lambda.\n\n\n&quot;You a=\r\nlso mention the 1/5th rule, which is not self-adaptive&quot;.\nI agree. I only me=\r\nntioned it for historical reasons, in order to make the\ntransition to self-=\r\nadaptation.\n\n&quot;It seems like you said that the fitness of organisms does not=\r\n affect the\nmutation rate (the issue of =E2=80=9Cunbiasedness=E2=80=9D)&quot;.\nW=\r\nhat I meant is that when designing the mutation operator one should think\na=\r\nbout exploring the whole search space, i.e., to be unbiased as to which\nspa=\r\nce to explore. Selection is responsible for guiding search using the\nfitnes=\r\ns information. Therefore, by including the standard deviations in the\ngenom=\r\ne, the process becomes self-adaptive.\n\n\nLet me know if anything is unclear.=\r\n\n\n\nBest,\nVassilis\n\n\n\n\nOn Mon, May 5, 2014 at 8:11 AM, Jeff Clune &lt;jclune@gm=\r\nail.com&gt; wrote:\n\n&gt;\n&gt;\n&gt; Hello Vassilis,\n&gt;\n&gt; Thanks for the interest in, and =\r\nexcitement about, the first batch of\n&gt; Evolving AI Lab publications. :-)\n&gt;\n=\r\n&gt; As for CMA-ES, I did not understand from your email if it is indeed\n&gt; sel=\r\nf-adaptive. It seems like you said that the fitness of organisms does\n&gt; not=\r\n affect the mutation rate (the issue of =E2=80=9Cunbiasedness=E2=80=9D). Th=\r\nat would\n&gt; certainly make the problem of self-adaptive mutation rates go aw=\r\nay!\n&gt;\n&gt; You also mention the 1/5th rule, which is not self-adaptive: it doe=\r\ns not\n&gt; have a mutation rate is on each genome that hitchhikes along with t=\r\nhe other\n&gt; parameters on the genome.\n&gt;\n&gt; Does CMA-ES do something different=\r\n? I couldn=E2=80=99t discern the answer from\n&gt; your notion. For example, in=\r\n CMA-ES, is there a parameter that evolves that\n&gt; controls the number of mu=\r\ntations per genome per generation? I thought\n&gt; CMA-ES didn=E2=80=99t even h=\r\nave a population of individuals, so I=E2=80=99m not sure how it\n&gt; could eve=\r\nn have self-adaptive mutation rates.\n&gt;\n&gt;\n&gt; Best regards,\n&gt; *Jeff Clune*\n&gt;\n&gt;=\r\n Assistant Professor\n&gt; Computer Science\n&gt; University of Wyoming\n&gt; jeffclune=\r\n@...\n&gt; jeffclune.com\n&gt;\n&gt; On May 4, 2014, at 8:00 AM, Vassilis Vassilia=\r\ndes &lt;vassilisvas@...&gt;\n&gt; wrote:\n&gt;\n&gt;\n&gt;\n&gt; Hello all,\n&gt;\n&gt; Joel and Ken, I=\r\n think I understand what you are saying about &quot;projecting\n&gt; intuitions abou=\r\nt the objective world into novelty search&quot; and the dynamic\n&gt; and divergent =\r\nnature of Novelty Search (NS)... and also why naively\n&gt; combining Covarianc=\r\ne Matrix Adaptation - Evolution Strategies (CMA-ES)\n&gt; might not work well w=\r\nith NS. A &quot;fitness&quot; peak in generation (g) might\n&gt; diminish in generation (=\r\ng+1), and generally the &quot;fitness&quot; peaks are\n&gt; constantly moving.\n&gt;\n&gt; This r=\r\neminds me a bit of multiagent learning problems, where one could say\n&gt; that=\r\n the &quot;target&quot; is constantly and adaptively being moved. However, I am\n&gt; not=\r\n sure whether/how we could frame NS as a multiagent learning scenario. I\n&gt; =\r\nam also imagining the landscape of NS as a... &quot;boiling soup&quot; where bubbles\n=\r\n&gt; (fitness peaks) keep appearing and disappearing all the time. :) These\n&gt; =\r\nbubbles could be guided by the archive, so that they would never appear at\n=\r\n&gt; the same place, or if we were to bound the archive (or use the\n&gt; probabil=\r\nistic approach), they could appear again after some time (or\n&gt; probabilisti=\r\ncally).\n&gt;\n&gt; Questions:\n&gt;\n&gt; 1) Does anyone think that there is any relations=\r\nhip of NS with\n&gt; thermodynamics?\n&gt;\n&gt; 2) Do you think there are any relation=\r\nships between NS and dynamic\n&gt; optimization?\n&gt;\n&gt; 3) Joel, you often mention=\r\n competitive coevolution when talking about NS.\n&gt; You also said that &quot;there=\r\n exist similar fixed-point concepts for\n&gt; competitive co-evolution (like me=\r\ndiocre stable states and disengagement)&quot;.\n&gt; To be honest, I haven&#39;t read th=\r\ne literature on these concepts. I was\n&gt; thinking, however, that if we were =\r\nto think about coevolution in game\n&gt; theoretic terms, then competitive coev=\r\nolution is like a zero-sum game:\n&gt; the gains of one individual are balanced=\r\n by the losses of the others. Is\n&gt; this correct? Does NS behave in this man=\r\nner? It seems to me that it is not\n&gt; a zero-sum game.\n&gt;\n&gt;\n&gt;\n&gt; Jeff, I agree=\r\n with you that CMA-ES learns correlations. However, allow me\n&gt; to express h=\r\nere my understanding as to how it works and its relationship to\n&gt; self-adap=\r\ntive mutation rates (SAMR). * I included this part at the end of\n&gt; the emai=\r\nl because it got very big :) Anyone who read this please do correct\n&gt; me if=\r\n something is wrong.\n&gt;\n&gt; Jeff you wrote: &quot;my guess is that if you tried CMA=\r\n-ES with and without a\n&gt; mutation rate on the genome, you=E2=80=99d get the=\r\n same result I report in my\n&gt; paper&quot;. CMA-ES by construction uses the mutat=\r\nion rates. It is an important\n&gt; part of the algorithm. I would be very curi=\r\nous to see how CMA-ES behaves in\n&gt; the same setup used in your paper.\n&gt;\n&gt; I=\r\n noticed something in your paper on SAMR. I also noticed that in Joel&#39;s\n&gt; a=\r\nnd Ken&#39;s paper on SAMR with NS (which I still haven&#39;t read very carefully,\n=\r\n&gt; only skimmed though): in both papers the SAMR are updated differently tha=\r\nn\n&gt; the SAMR of ES (see at the end of the email). Do you think that using a=\r\nn ES\n&gt; approach for SAMR in your setups would lead to any different\n&gt; resul=\r\nts/conclusions?\n&gt;\n&gt; &quot;&#39;novelty plateaus&#39;, a concept my students and I introd=\r\nuce in our last,\n&gt; not-yet-announced GECCO paper&quot;\n&gt; Sounds interesting! Con=\r\ngrats by the way on all new papers!\n&gt;\n&gt;\n&gt;\n&gt; Ken Lloyd, thanks for the link =\r\non Adaptive Stochastic Resonance. I haven&#39;t\n&gt; read it yet, but I also notic=\r\ned that there are several works that have\n&gt; similarities with NS (e.g., int=\r\nrinsic motivations, maximization of\n&gt; predictive information, causal entrop=\r\nic forces, empowerment etc.). Does\n&gt; anyone think it would it be interestin=\r\ng to crowdsource a list of similar\n&gt; works on a different thread? I think J=\r\noel and Ken (Stanley) probably know a\n&gt; lot of them already.\n&gt;\n&gt;\n&gt;\n&gt; Oliver=\r\n, you mentioned &quot;some work has probabilistically applied the\n&gt; objective fu=\r\nnction&quot;. I would be interested to see this work if you find the\n&gt; link. If =\r\nI remember correctly Jeff, JBM and Hod Lipson in &quot;The evolutionary\n&gt; origin=\r\ns of modularity&quot; used something similar, but on the secondary\n&gt; objective (=\r\nconnection cost) objective.\n&gt;\n&gt;\n&gt;\n&gt; Best,\n&gt; Vassilis\n&gt;\n&gt;\n&gt; * Notes on CMA-E=\r\nS:\n&gt;\n&gt; In evolution strategies (ES) the mutation operator is usually the pr=\r\nimary\n&gt; source of variation. Thus, we could say that while selection exploi=\r\nts the\n&gt; fitness information in order to guide search into promising region=\r\ns,\n&gt; mutation (or variation) explores the search space and should not use a=\r\nny\n&gt; fitness information to do that, i.e., it should be unbiased. This is a=\r\n\n&gt; theoretical consideration/requirement (called &quot;unbiasedness&quot;), which\n&gt; n=\r\naturally leads to the maximum entropy principle. In the case of\n&gt; real-valu=\r\ned search spaces this leads to gaussian distributions, while it\n&gt; has been =\r\nalso shown in the literature how to potentially handle integer and\n&gt; discre=\r\nte parameters.\n&gt;\n&gt; Let&#39;s stay on real-valued spaces and let&#39;s say that an i=\r\nndividual &quot;a&quot;\n&gt; comprises an object parameter vector &quot;x&quot;, and its fitness f=\r\nunction value\n&gt; &quot;F(x)&quot;: a =3D (x, F(x)). Mutations on x work like this:\n&gt;\n&gt;=\r\n x&#39; =3D x + z\n&gt;\n&gt; with z being related to gaussian distributions.\n&gt;\n&gt; The s=\r\nimplest case is z =3D sigma * ( N_1(0,1), N_2(0,1), ... , N_d(0,1) ),\n&gt; whe=\r\nre sigma is the standard deviation of the normal distribution, d is the\n&gt; d=\r\nimensionality, and N_i(0,1) are independent random samples from the normal\n=\r\n&gt; distribution.\n&gt;\n&gt; People have noticed that when sigma is constant and the=\r\n very\n&gt; simple (1+1)-ES is used (meaning 1 parent creates 1 offspring and t=\r\nhe\n&gt; strongest of them survives), then in very simplified unimodal fitness\n=\r\n&gt; functions (such as the sphere function), the ES initially displays a peri=\r\nod\n&gt; of improvements; however, after a while it becomes very very slow and =\r\nloses\n&gt; its evolvability because when approaching the minimum sigma is too =\r\nbig and\n&gt; tends to overshoot. By analyzing how sigma influences the success=\r\n\n&gt; probability by which an offspring replaces a parent, as well as the\n&gt; pr=\r\nogress rate, people have come up with something called the &quot;evolution\n&gt; win=\r\ndow&quot; as well as the 1/5th control rule that appropriately scales sigma\n&gt; pe=\r\nriodically.\n&gt;\n&gt; Now, the 1/5th rule is a heuristic and very specific to (1+=\r\n1)-ES and the\n&gt; fitness landscape, so people needed something better. Hence=\r\n the following\n&gt; idea:\n&gt;\n&gt; Let&#39;s add an endogenous/evolvable strategy param=\r\neter vector &quot;s&quot; to the\n&gt; individual, that contains any other parameters we =\r\nwant (such as the\n&gt; standard deviation). So now an individual is: a =3D (x,=\r\ns,F(x)). But how do we\n&gt; update sigma / the standard deviation? How do we m=\r\nutate this mutation\n&gt; strength/rate? The maximum entropy principle specifie=\r\ns that we should use\n&gt; gaussian distributions, but using these on the stand=\r\nard deviation could\n&gt; lead to negative values. A neat solution is to do it =\r\nin log scale:\n&gt;\n&gt; ln( sigma&#39; ) =3D ln( sigma ) + zeta\n&gt;\n&gt; which leads to th=\r\ne multiplicative update:\n&gt;\n&gt; sigma&#39; =3D sigma * exp( zeta )\n&gt;\n&gt; where zeta =\r\n=3D tau * N(0,1), and tau is an exogenous learning parameter\n&gt; which determ=\r\nines the rate and precision of self-adaptation. It is usually\n&gt; proportiona=\r\nl to 1/sqrt(d).\n&gt;\n&gt; Until now we were talking about a single strategy param=\r\neter (mutation\n&gt; rate) for the whole genotype, i.e., s =3D sigma, also know=\r\nn as isotropic\n&gt; mutations. We can extend this to the case where we have a =\r\nvector of\n&gt; strategy parameters (mutation rates), i.e., s =3D (sigma_1, sig=\r\nma_2, ...,\n&gt; sigma_d), also known as non-isotropic mutations. This techniqu=\r\ne is more\n&gt; flexible especially in high dimensional problems. However, it i=\r\ns still not\n&gt; very effective in some non-separable problems, e.g., consider=\r\n a fitness\n&gt; landscape that is not aligned with the coordinate system. How =\r\ndo we deal\n&gt; with arbitrary rotations of the fitness landscape, which is th=\r\ne most\n&gt; general situation?\n&gt;\n&gt; Now the idea of Covariance Matrix Adaptatio=\r\nn is introduced: let&#39;s estimate\n&gt; the shape of the fitness landscape and ad=\r\napt a rotation matrix in order to\n&gt; be able to align our coordinate axes wi=\r\nth the principal axes of the fitness\n&gt; landscape. This covariance matrix in=\r\ntroduces correlations between the\n&gt; components of z.\n&gt;\n&gt; So, in:\n&gt;\n&gt; 1) iso=\r\ntropic mutations: z =3D sigma * ( N_1(0,1), N_2(0,1), ... , N_d(0,1) )\n&gt; =\r\n=3D sigma * N(0, I), where I is the identity matrix\n&gt;\n&gt; 2) non-isotropic mu=\r\ntations: z =3D ( sigma_1 * N_1(0,1), sigma_2 * N_2(0,1),\n&gt; ..., sigma_d * N=\r\n_d(0,1) ) =3D D * N(0, I), where D is a diagonal matrix\n&gt; containing all si=\r\ngma values\n&gt;\n&gt; 3) correlated mutations: z =3D M * ( sigma_1 * N_1(0,1), sig=\r\nma_2 * N_2(0,1),\n&gt; ..., sigma_d * N_d(0,1) ) =3D M * D * N(0, I), where M i=\r\ns the rotation matrix\n&gt; that introduces correlations between the components=\r\n of z, and C =3D M^T * M\n&gt; is the covariance matrix (M^T is the transpose o=\r\nf M).\n&gt;\n&gt;\n&gt; I won&#39;t get into more detail (e.g., how to estimate the covaria=\r\nnce matrix\n&gt; etc.), but note that CMA-ES has been shown to work very well i=\r\nn various\n&gt; benchmarks and with small population sizes.\n&gt;\n&gt;\n&gt;\n&gt;  \n&gt;\n\r\n--e89a8ffbacdfac890b04f8a47513\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;Hello Jeff,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I was thinking about the mu=\r\ntation rate and mutation strength/step as being the same thing which is not=\r\n. I apologize for the confusion. I realized that after reading your email. =\r\nI also apologize for the notation; it would be nice if we could write some =\r\nparts of the email in LaTeX (perhaps we can and I don&#39;t know about it) =\r\n:-)&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Let me clarify:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As f=\r\nar as I understand, in real-valued optimization with evolution strategies (=\r\nES), the concept of mutation rate and mutation strength/step is different t=\r\nhan in genetic algorithms. In genetic algorithms, a mutation rate is a prob=\r\nability that a value will be mutated by an amount equal to the mutation str=\r\nength/step. In ES these two concepts are intertwined. That is, each individ=\r\nual parameter is *always* perturbed by sampling the perturbation from a Gau=\r\nssian distribution with mean 0. The standard deviation of this Gaussian dis=\r\ntribution is different for each parameter, and this value is what is self-a=\r\ndapted and &quot;hitchhikes along with the other parameters on the genome&q=\r\nuot;. Since the perturbation is probabilistic and the distribution (of this=\r\n perturbation) is centered around 0, there is a high probability that it wi=\r\nll be very small. Also, note that self-adaptation might make the standard d=\r\neviation of some of the parameters become very small, which effectively mea=\r\nns that their mutation rate approaches zero.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Summ=\r\narizing, in ES there are no self-adaptive mutation rates, but there are sel=\r\nf-adaptive standard deviations of Gaussian distributions (which indirectly =\r\naffect both the mutation rates and mutation strengths). In CMA-ES, a covari=\r\nance matrix (which captures correlations between dimensions) is self-adapte=\r\nd as well and this makes convergence to the optimum faster.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;=\r\n&lt;/div&gt;&lt;div&gt;Note that discrete spaces are differently handled. You need to h=\r\nave a mutation rate which is usually sampled from a uniform distribution. B=\r\nut the original ES were designed for real-valued spaces.&lt;br&gt;&lt;/div&gt;\n&lt;div&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div&gt;Regarding the issue of the population, my view is the following=\r\n. In ES, there is something called &quot;plus&quot; selection (&quot;+&quot=\r\n;) and &quot;comma&quot; selection (&quot;,&quot;).&lt;/div&gt;&lt;div&gt;&lt;br&gt;\n&lt;/div&gt;&lt;d=\r\niv&gt;(mu + lambda) means that there are mu parents that create lambda offspri=\r\nng, with mu &gt; 0, lambda &gt; 0. What survives in the next generation is =\r\nthe best individuals from both parents and offspring. So, the effective pop=\r\nulation size is the maximum of the two.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;(mu, lamb=\r\nda) means that there are mu parents that create lambda offspring, with lamb=\r\nda &gt;=3D mu, mu &gt; 0. What survives in the next generation is the best =\r\nindividuals, but only from the offspring. Since lambda is at least equal to=\r\n mu, the effective population size is lambda.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div&gt;&quot;You also mention the 1/5th rule, which is not self-adapti=\r\nve&quot;.=C2=A0&lt;/div&gt;&lt;div&gt;I agree. I only mentioned it for historical reaso=\r\nns, in order to make the transition to self-adaptation.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/di=\r\nv&gt;&lt;div&gt;&quot;It seems like you said that the fitness of organisms does not =\r\naffect the mutation rate (the issue of =E2=80=9Cunbiasedness=E2=80=9D)&quot=\r\n;.=C2=A0&lt;/div&gt;&lt;div&gt;What I meant is that when designing the mutation operato=\r\nr one should think about exploring the whole search space, i.e., to be unbi=\r\nased as to which space to explore. Selection is responsible for guiding sea=\r\nrch using the fitness information. Therefore, by including the standard dev=\r\niations in the genome, the process becomes self-adaptive.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/=\r\ndiv&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Let me know if anything is unclear.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;=\r\n/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Best,&lt;/div&gt;&lt;div&gt;Vassilis&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;=\r\n&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;div class=3D&quot;gmail=\r\n_quote&quot;&gt;\nOn Mon, May 5, 2014 at 8:11 AM, Jeff Clune &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;=\r\na href=3D&quot;mailto:jclune@...&quot; target=3D&quot;_blank&quot;&gt;jclune@...&lt;/a&gt;&g=\r\nt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0=\r\npx 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);borde=\r\nr-left-style:solid;padding-left:1ex&quot;&gt;\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n \n&lt;div style=3D&quot;b=\r\nackground-color:rgb(255,255,255)&quot;&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n  =\r\n  &lt;div&gt;\n      \n      \n      &lt;p&gt;Hello=C2=A0Vassilis,&lt;/p&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;=\r\nThanks for the interest in, and excitement about, the first batch of Evolvi=\r\nng AI Lab publications. :-)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As for CMA-ES, I did n=\r\not understand from your email if it is indeed self-adaptive. It seems like =\r\nyou said that the fitness of organisms does not affect the mutation rate (t=\r\nhe issue of =E2=80=9Cunbiasedness=E2=80=9D). That would certainly make the =\r\nproblem of self-adaptive mutation rates go away!=C2=A0&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div=\r\n&gt;&lt;div&gt;You also mention the 1/5th rule, which is not self-adaptive: it does =\r\nnot have a mutation rate is on each genome that hitchhikes along with the o=\r\nther parameters on the genome.=C2=A0&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;\nDoes CMA-ES =\r\ndo something different? I couldn=E2=80=99t discern the answer from your not=\r\nion. For example, in CMA-ES, is there a parameter that evolves that control=\r\ns the number of mutations per genome per generation? I thought CMA-ES didn=\r\n=E2=80=99t even have a population of individuals, so I=E2=80=99m not sure h=\r\now it could even have self-adaptive mutation rates.&lt;br&gt;\n&lt;div&gt;\n&lt;span style=\r\n=3D&quot;font-family:Times;font-size:14px;color:rgb(0,0,0)&quot;&gt;&lt;div style=3D&quot;color:=\r\nrgb(0,0,0);font-family:Times;font-style:normal;font-variant:normal;font-wei=\r\nght:normal;letter-spacing:normal;text-indent:0px;text-transform:none;white-=\r\nspace:normal;word-spacing:0px&quot;&gt;\n&lt;span style=3D&quot;font-family:Times;color:rgb(=\r\n0,0,0)&quot;&gt;&lt;div style=3D&quot;color:rgb(0,0,0);font-family:Times;font-style:normal;=\r\nfont-variant:normal;font-weight:normal;letter-spacing:normal;text-indent:0p=\r\nx;text-transform:none;white-space:normal;word-spacing:0px&quot;&gt;\n&lt;span style=3D&quot;=\r\nfont-family:Times;color:rgb(0,0,0)&quot;&gt;&lt;div style=3D&quot;color:rgb(0,0,0);font-fam=\r\nily:Times;font-style:normal;font-variant:normal;font-weight:normal;letter-s=\r\npacing:normal;text-indent:0px;text-transform:none;white-space:normal;word-s=\r\npacing:0px&quot;&gt;\n&lt;div style=3D&quot;color:rgb(0,0,0);font-family:Times;font-style:no=\r\nrmal;font-variant:normal;font-weight:normal;letter-spacing:normal;text-inde=\r\nnt:0px;text-transform:none;white-space:normal;word-spacing:0px&quot;&gt;&lt;span style=\r\n=3D&quot;font-family:Times;color:rgb(0,0,0)&quot;&gt;&lt;div style=3D&quot;color:rgb(0,0,0);font=\r\n-family:Times;font-style:normal;font-variant:normal;font-weight:normal;lett=\r\ner-spacing:normal;text-indent:0px;text-transform:none;white-space:normal;wo=\r\nrd-spacing:0px&quot;&gt;\n&lt;span style=3D&quot;font-family:Times;color:rgb(0,0,0)&quot;&gt;&lt;div st=\r\nyle=3D&quot;color:rgb(0,0,0);font-family:Times;font-style:normal;font-variant:no=\r\nrmal;font-weight:normal;letter-spacing:normal;text-indent:0px;text-transfor=\r\nm:none;white-space:normal;word-spacing:0px&quot;&gt;\n&lt;span style=3D&quot;font-family:Tim=\r\nes;color:rgb(0,0,0)&quot;&gt;&lt;div style=3D&quot;color:rgb(0,0,0);font-family:Times;font-=\r\nstyle:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;t=\r\next-indent:0px;text-transform:none;white-space:normal;word-spacing:0px&quot;&gt;\n&lt;s=\r\npan style=3D&quot;font-family:Times;color:rgb(0,0,0)&quot;&gt;&lt;div style=3D&quot;color:rgb(0,=\r\n0,0);font-family:Times;font-style:normal;font-variant:normal;font-weight:no=\r\nrmal;letter-spacing:normal;text-indent:0px;text-transform:none;white-space:=\r\nnormal;word-spacing:0px&quot;&gt;\n&lt;span style=3D&quot;font-family:Times;color:rgb(0,0,0)=\r\n&quot;&gt;&lt;div style=3D&quot;color:rgb(0,0,0);font-family:Times;font-style:normal;font-v=\r\nariant:normal;font-weight:normal;letter-spacing:normal;text-indent:0px;text=\r\n-transform:none;white-space:normal;word-spacing:0px&quot;&gt;\n&lt;div style=3D&quot;color:r=\r\ngb(0,0,0);font-family:Times;font-style:normal;font-variant:normal;font-weig=\r\nht:normal;letter-spacing:normal;text-indent:0px;text-transform:none;white-s=\r\npace:normal;word-spacing:0px&quot;&gt;&lt;div style=3D&quot;color:rgb(0,0,0);font-family:Ti=\r\nmes;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing=\r\n:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing=\r\n:0px&quot;&gt;\n&lt;span style=3D&quot;border-collapse:separate;color:rgb(0,0,0);font-family=\r\n:Times;font-style:normal;font-variant:normal;font-weight:normal;letter-spac=\r\ning:normal;text-indent:0px;text-transform:none;white-space:normal&quot;&gt;&lt;div&gt;&lt;sp=\r\nan style=3D&quot;border-collapse:separate;color:rgb(0,0,0);font-family:Times;fon=\r\nt-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal=\r\n;text-indent:0px;text-transform:none;white-space:normal&quot;&gt;&lt;div&gt;\n&lt;span style=\r\n=3D&quot;border-collapse:separate;color:rgb(0,0,0);font-variant:normal;letter-sp=\r\nacing:normal;text-indent:0px;text-transform:none;white-space:normal;word-sp=\r\nacing:0px&quot;&gt;&lt;div&gt;&lt;span style=3D&quot;border-collapse:separate;color:rgb(0,0,0);fo=\r\nnt-variant:normal;letter-spacing:normal;text-indent:0px;text-transform:none=\r\n;white-space:normal;word-spacing:0px&quot;&gt;&lt;div&gt;\n&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;fon=\r\nt-weight:normal;font-style:normal&quot;&gt;Best regards,&lt;br&gt;&lt;font color=3D&quot;#0a5d19&quot;=\r\n&gt;&lt;b&gt;Jeff Clune&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;br&gt;Assistant Professor&lt;br&gt;Computer Science&lt;/d=\r\niv&gt;&lt;div style=3D&quot;font-weight:normal;font-style:normal&quot;&gt;\nUniversity of Wyomi=\r\nng&lt;br&gt;&lt;a href=3D&quot;mailto:jeffclune@...&quot; target=3D&quot;_blank&quot;&gt;jeffclune@uwy=\r\no.edu&lt;/a&gt;&lt;br&gt;&lt;a href=3D&quot;http://jeffclune.com&quot; target=3D&quot;_blank&quot;&gt;jeffclune.c=\r\nom&lt;/a&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;\n&lt;/div&gt;&lt;/di=\r\nv&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/=\r\nspan&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;\n&lt;/div&gt;&lt;div&gt;&lt;div class=3D&quot;h5&quot;&gt;\n\n&lt;br&gt;&lt;div&gt;&lt;di=\r\nv&gt;On May 4, 2014, at 8:00 AM, Vassilis Vassiliades &lt;&lt;a href=3D&quot;mailto:va=\r\nssilisvas@...&quot; target=3D&quot;_blank&quot;&gt;vassilisvas@...&lt;/a&gt;&gt; wrote:=\r\n&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n \n&lt;div style=3D&quot;background=\r\n-color:rgb(255,255,255)&quot;&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n\n    &lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;d=\r\niv dir=3D&quot;ltr&quot;&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Hello all,&lt;/div&gt;&lt;div class=3D&quot;gma=\r\nil_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Joel and Ken, I think I unde=\r\nrstand what you are saying about &quot;projecting intuitions about the obje=\r\nctive world into novelty search&quot; and the dynamic and divergent nature =\r\nof Novelty Search (NS)... and also why naively combining Covariance Matrix =\r\nAdaptation - Evolution Strategies (CMA-ES) might not work well with NS. A &=\r\nquot;fitness&quot; peak in generation (g) might diminish in generation (g+1=\r\n), and generally the &quot;fitness&quot; peaks are constantly moving.&lt;/div&gt;=\r\n\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;This remi=\r\nnds me a bit of multiagent learning problems, where one could say that the =\r\n&quot;target&quot; is constantly and adaptively being moved. However, I am =\r\nnot sure whether/how we could frame NS as a multiagent learning scenario. I=\r\n am also imagining the landscape of NS as a... &quot;boiling soup&quot; whe=\r\nre bubbles (fitness peaks) keep appearing and disappearing all the time. :)=\r\n These bubbles could be guided by the archive, so that they would never app=\r\near at the same place, or if we were to bound the archive (or use the proba=\r\nbilistic approach), they could appear again after some time (or probabilist=\r\nically).=C2=A0&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gm=\r\nail_extra&quot;&gt;Questions:&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=\r\n=3D&quot;gmail_extra&quot;&gt;1) Does anyone think that there is any relationship of NS =\r\nwith thermodynamics?&lt;/div&gt;\n&lt;div class=3D&quot;gmail_extra&quot;&gt;\n&lt;br&gt;&lt;/div&gt;&lt;div class=\r\n=3D&quot;gmail_extra&quot;&gt;2) Do you think there are any relationships between NS and=\r\n dynamic optimization?&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=\r\n=3D&quot;gmail_extra&quot;&gt;3) Joel, you often mention competitive coevolution when ta=\r\nlking about NS. You also said that &quot;&lt;span style=3D&quot;font-family:arial,s=\r\nans-serif;font-size:13px&quot;&gt;there exist similar fixed-point concepts for comp=\r\netitive co-evolution (like mediocre stable states and disengagement)&quot;.=\r\n To be honest, I haven&#39;t read the literature on these concepts. I was t=\r\nhinking, however, that if we were to think about coevolution in game theore=\r\ntic terms, then=C2=A0&lt;/span&gt;&lt;span style=3D&quot;font-family:arial,sans-serif;fon=\r\nt-size:13px&quot;&gt;competitive coevolution is like a zero-sum game: the gains of =\r\none individual are balanced by the losses of the others. Is this correct? D=\r\noes NS behave in this manner? It seems to me that it is not a zero-sum game=\r\n.&lt;/span&gt;&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_ex=\r\ntra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_ext=\r\nra&quot;&gt;Jeff, I agree with you that CMA-ES learns correlations. However, allow =\r\nme to express here my understanding as to how it works and its relationship=\r\n to self-adaptive mutation rates (SAMR). * I included this part at the end =\r\nof the email because it got very big :) Anyone who read this please do corr=\r\nect me if something is wrong.&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;=\r\ndiv class=3D&quot;gmail_extra&quot;&gt;Jeff you wrote: &quot;my guess is that if you tri=\r\ned CMA-ES with and without a mutation rate on the genome, you=E2=80=99d get=\r\n the same result I report in my paper&quot;. CMA-ES by construction uses th=\r\ne mutation rates. It is an important part of the algorithm. I would be very=\r\n curious to see how CMA-ES behaves in the same setup used in your paper.&lt;/d=\r\niv&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;I noti=\r\nced something in your paper on SAMR. I also noticed that in Joel&#39;s and =\r\nKen&#39;s paper on SAMR with NS (which I still haven&#39;t read very carefu=\r\nlly, only skimmed though): in both papers the SAMR are updated differently =\r\nthan the SAMR of ES (see at the end of the email). Do you think that using =\r\nan ES approach for SAMR in your setups would lead to any different results/=\r\nconclusions?&lt;br&gt;\n\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;=\r\ngmail_extra&quot;&gt;&quot;&#39;novelty plateaus&#39;, a concept my students and I =\r\nintroduce in our last, not-yet-announced GECCO paper&quot;&lt;/div&gt;&lt;div class=\r\n=3D&quot;gmail_extra&quot;&gt;Sounds interesting! Congrats by the way on all new papers!=\r\n&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Ken =\r\nLloyd, thanks for the link on Adaptive Stochastic Resonance. I haven&#39;t =\r\nread it yet, but I also noticed that there are several works that have simi=\r\nlarities with NS (e.g., intrinsic motivations, maximization of predictive i=\r\nnformation, causal entropic forces, empowerment etc.). Does anyone think it=\r\n would it be interesting to crowdsource a list of similar works on a differ=\r\nent thread? I think Joel and Ken (Stanley) probably know a lot of them alre=\r\nady.&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;=\r\n&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;=\r\nOliver, you mentioned &quot;&lt;span style=3D&quot;font-family:arial,sans-serif;fon=\r\nt-size:13px&quot;&gt;some work has probabilistically applied the objective function=\r\n&quot;. I would be interested to see this work if you find the link. If I r=\r\nemember correctly Jeff, JBM and Hod Lipson in &quot;The evolutionary origin=\r\ns of modularity&quot; used something similar, but on the secondary objectiv=\r\ne (connection cost) objective.&lt;/span&gt;&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;=\r\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Best,&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Vass=\r\nilis&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;\n=\r\n\n&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;* Notes on CMA-ES:&lt;/div&gt;&lt;div class=3D=\r\n&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;div class=3D&quot;gmail_extr=\r\na&quot;&gt;In evolution strategies (ES) the mutation operator is usually the primar=\r\ny source of variation. Thus, we could say that while selection exploits the=\r\n fitness information in order to guide search into promising regions, mutat=\r\nion (or variation) explores the search space and should not use any fitness=\r\n information to do that, i.e., it should be unbiased. This is a theoretical=\r\n consideration/requirement (called &quot;unbiasedness&quot;), which natural=\r\nly leads to the maximum entropy principle. In the case of real-valued searc=\r\nh spaces this leads to gaussian distributions, while it has been also shown=\r\n in the literature how to potentially handle integer and discrete parameter=\r\ns.&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;L=\r\net&#39;s stay on real-valued spaces and let&#39;s say that an individual &q=\r\nuot;a&quot; comprises an object parameter vector &quot;x&quot;, and its fit=\r\nness function value &quot;F(x)&quot;: a =3D (x, F(x)). Mutations on x work =\r\nlike this:&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_=\r\nextra&quot;&gt;x&#39; =3D x + z&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div clas=\r\ns=3D&quot;gmail_extra&quot;&gt;with z being related to gaussian distributions.=C2=A0&lt;/di=\r\nv&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;\n\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;The sim=\r\nplest case is z =3D sigma * ( N_1(0,1), N_2(0,1), ... , N_d(0,1) ), where s=\r\nigma is the standard deviation of the normal distribution, d is the dimensi=\r\nonality, and N_i(0,1) are independent random samples from the normal distri=\r\nbution.&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_ext=\r\nra&quot;&gt;People have noticed that when sigma is constant and the very simple=C2=\r\n=A0(1+1)-ES=C2=A0is used (meaning 1 parent creates 1 offspring and the stro=\r\nngest of them survives), then in very simplified unimodal fitness functions=\r\n (such as the sphere function), the=C2=A0ES initially displays a period of =\r\nimprovements; however, after a while it becomes very very slow and loses it=\r\ns evolvability because when approaching the minimum sigma is too big and te=\r\nnds to overshoot. By analyzing how sigma influences the success probability=\r\n by which an offspring replaces a parent, as well as the progress rate, peo=\r\nple have come up with something called the &quot;evolution window&quot; as =\r\nwell as the 1/5th control rule that appropriately scales sigma periodically=\r\n.&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;No=\r\nw, the 1/5th rule is a heuristic and very specific to (1+1)-ES and the fitn=\r\ness landscape, so people needed something better. Hence the following idea:=\r\n=C2=A0&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;\n\n&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extr=\r\na&quot;&gt;Let&#39;s add an endogenous/evolvable strategy parameter vector &quot;s&=\r\nquot; to the individual, that contains any other parameters we want (such a=\r\ns the standard deviation). So now an individual is: a =3D (x,s,F(x)). But h=\r\now do we update sigma / the standard deviation? How do we mutate this mutat=\r\nion strength/rate? The maximum entropy principle specifies that we should u=\r\nse gaussian distributions, but using these on the standard deviation could =\r\nlead to negative values. A neat solution is to do it in log scale:&lt;/div&gt;\n\n&lt;=\r\ndiv class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;ln( sigma&#3=\r\n9; ) =3D ln( sigma ) + zeta&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div =\r\nclass=3D&quot;gmail_extra&quot;&gt;which leads to the multiplicative update:&lt;/div&gt;&lt;div c=\r\nlass=3D&quot;gmail_extra&quot;&gt;\n\n&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;sigma&#39; =3D =\r\nsigma * exp( zeta )&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D=\r\n&quot;gmail_extra&quot;&gt;where zeta =3D tau * N(0,1), and tau is an exogenous learning=\r\n parameter which determines the rate and precision of self-adaptation. It i=\r\ns usually proportional to 1/sqrt(d).&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;=\r\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Until now we were talking about a single s=\r\ntrategy parameter (mutation rate) for the whole genotype, i.e., s =3D sigma=\r\n, also known as isotropic mutations. We can extend this to the case where w=\r\ne have a vector of strategy parameters (mutation rates), i.e., s =3D (sigma=\r\n_1, sigma_2, ..., sigma_d), also known as non-isotropic mutations. This tec=\r\nhnique is more flexible especially in high dimensional problems. However, i=\r\nt is still not very effective in some non-separable problems, e.g., conside=\r\nr a fitness landscape that is not aligned with the coordinate system. How d=\r\no we deal with arbitrary rotations of the fitness landscape, which is the m=\r\nost general situation?&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div cla=\r\nss=3D&quot;gmail_extra&quot;&gt;Now the idea of Covariance Matrix Adaptation is introduc=\r\ned: let&#39;s estimate the shape of the fitness landscape and adapt a rotat=\r\nion matrix in order to be able to align our coordinate axes with the princi=\r\npal axes of the fitness landscape. This covariance matrix introduces correl=\r\nations between the components of z.&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;=\r\n/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;So, in:&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;1) isotropic mutations: z =3D sigma * ( N=\r\n_1(0,1), N_2(0,1), ... , N_d(0,1) ) =3D sigma * N(0, I), where I is the ide=\r\nntity matrix&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmai=\r\nl_extra&quot;&gt;2) non-isotropic mutations: z =3D ( sigma_1 * N_1(0,1), sigma_2 * =\r\nN_2(0,1), ..., sigma_d * N_d(0,1) ) =3D D * N(0, I), where D is a diagonal =\r\nmatrix containing all sigma values&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/=\r\ndiv&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;3) correlated mutations: z =3D M * ( sigma_1=\r\n * N_1(0,1), sigma_2 * N_2(0,1), ..., sigma_d * N_d(0,1) ) =3D M * D * N(0,=\r\n I), where M is the rotation matrix that introduces correlations between th=\r\ne components of z, and C =3D M^T * M is the covariance matrix (M^T is the t=\r\nranspose of M).&lt;/div&gt;\n\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;g=\r\nmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;I won&#39;t get into more =\r\ndetail (e.g., how to estimate the covariance matrix etc.), but note that CM=\r\nA-ES has been shown to work very well in various benchmarks and with small =\r\npopulation sizes.&lt;/div&gt;\n\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;=\r\ndiv&gt;&lt;br&gt;&lt;/div&gt;\n\n    &lt;/div&gt;\n     \n\n    \n\n&lt;/div&gt;\n\n\n\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;=\r\n&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;div style=3D&quot;color:r=\r\ngb(255,255,255);min-height:0px&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/blockquote&gt;&lt;/=\r\ndiv&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;\n\r\n--e89a8ffbacdfac890b04f8a47513--\r\n\n"}}