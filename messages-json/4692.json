{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"jMUEZQ8OTeSa-Nnru5g6xNW34hFKqLEmDC9iDH438L80XXKGFNcWBOkKrL3SvZLqb4SVBQaVcEZxKePO7CzfZnO2","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: New Paper on Novelty Search and Adaptive Neural Networks","postDate":"1243395884","msgId":4692,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM2NDIyRjZDLjJBNEYxJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGd1ZzhlMytpdmExQGVHcm91cHMuY29tPg=="},"prevInTopic":4663,"nextInTopic":0,"prevInTime":4691,"nextInTime":4693,"topicId":4619,"numMessagesInTopic":8,"msgSnippet":"... Hi Ken. Thanks for expanding on this. You put the point very clearly and succinctly, and I agree with you. ... I look forward to learning more once this","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 92706 invoked from network); 27 May 2009 03:46:31 -0000\r\nX-Received: from unknown (69.147.108.200)\n  by m5.grp.sp2.yahoo.com with QMQP; 27 May 2009 03:46:31 -0000\r\nX-Received: from unknown (HELO yw-out-1718.google.com) (74.125.46.156)\n  by mta1.grp.re1.yahoo.com with SMTP; 27 May 2009 03:46:31 -0000\r\nX-Received: by yw-out-1718.google.com with SMTP id 5so15668044ywm.46\n        for &lt;neat@yahoogroups.com&gt;; Tue, 26 May 2009 20:44:50 -0700 (PDT)\r\nX-Received: by 10.100.108.2 with SMTP id g2mr16337465anc.35.1243395890171;\n        Tue, 26 May 2009 20:44:50 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?10.0.1.2? (c-76-20-191-220.hsd1.mi.comcast.net [76.20.191.220])\n        by mx.google.com with ESMTPS id 7sm1944782ywo.16.2009.05.26.20.44.47\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Tue, 26 May 2009 20:44:48 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.13.0.080930\r\nDate: Tue, 26 May 2009 23:44:44 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C6422F6C.2A4F1%jclune@...&gt;\r\nThread-Topic: [neat] Re: New Paper on Novelty Search and Adaptive Neural\n Networks\r\nThread-Index: AcnefXkNemZMp7yrNE+w40cxRj7xjQ==\r\nIn-Reply-To: &lt;gug8e3+iva1@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-transfer-encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: New Paper on Novelty Search and Adaptive Neural\n Networks\r\nX-Yahoo-Group-Post: member; u=211599040; y=slAqBMwWsNrPR6DPHGGhmw8C-p21oukcLS4Biy-fTv6PCi-NFKjk\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\n&gt; Jeff, my hypothesis is that static heuristics are easier to find than adaptive\n&gt; ones because it is a lot easier to encode knowledge than to encode how to gain\n&gt; knowledge.  Therefore, no matter where you start in the search space, you are\n&gt; probably closer to a static heuristic than an adaptive one.  Furthermore, once\n&gt; you begin to climb the gradient of a static heuristic, you are making no\n&gt; progress towards an adaptive one because adaptive heuristics are not based on\n&gt; a static foundation.  Rather, adaptive heuristics are based on entirely\n&gt; different mechanisms, which means that static gradients are a deceptive trap.\n\nHi Ken. Thanks for expanding on this. You put the point very clearly and\nsuccinctly, and I agree with you.\n\n&gt; In any case, we are actually presently looking quite closely at this issue by\n&gt; analyzing the search space in an adaptive domain.  So like you, we are also\n&gt; interested in a more detailed answer.\n\nI look forward to learning more once this work is ready. Good luck!\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;jeffreyclune&quot; &lt;jclune@...&gt; wrote:\n&gt;&gt; \n&gt;&gt; Hello Ken-\n&gt;&gt; \n&gt;&gt; I agree with you that, from what I have read and personally experienced,\n&gt;&gt; evolution likes to evolve static, rather than adaptive, heuristics. It seems\n&gt;&gt; like your argument is one of induction: evolution tends to evolve static\n&gt;&gt; heuristics, so there must be a valley, cause otherwise it would evolve\n&gt;&gt; adaptive heuristics. That sounds right to me, but it would be very cool for\n&gt;&gt; us as a community to figure out exactly why there is a valley between static\n&gt;&gt; heuristics and adaptive ones...and why evolution tends to gravitate toward\n&gt;&gt; the static instead of the adaptive peaks. That&#39;s not an easy challenge, but\n&gt;&gt; it is probably a worthwhile one. It&#39;s almost like the science is currently at\n&gt;&gt; the point of having an observation of a phenomenon without an understanding\n&gt;&gt; as to why the phenomena occurs. It&#39;ll be hard to solve the problem unless we\n&gt;&gt; understand it. \n&gt;&gt; \n&gt;&gt; If any of you out there have any ideas, it would be cool to hear hypotheses.\n&gt;&gt; \n&gt;&gt; PS. Apologies for the delayed response (to this, and to your other email\n&gt;&gt; about the novelty search paper). I am traveling at the moment and can only\n&gt;&gt; get on for brief spurts. I look forward to properly responding at or after\n&gt;&gt; the CEC. \n&gt;&gt; \n&gt;&gt; -jeff \n&gt;&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt;&gt;&gt; \n&gt;&gt;&gt; Jeff, I see where you&#39;re coming from.  First, I am not necessarily saying\n&gt;&gt;&gt; there is only one valley between these strategies.  There could be many\n&gt;&gt;&gt; valleys, or there could be a long neutral plateau.\n&gt;&gt;&gt; \n&gt;&gt;&gt; But still the question is the same- why should there be one or more valleys\n&gt;&gt;&gt; or a plateau?\n&gt;&gt;&gt; \n&gt;&gt;&gt; A general way to look at this question is just the see that the word\n&gt;&gt;&gt; &quot;harder&quot; generally means there is at least one valley or plateau when you\n&gt;&gt;&gt; are talking about a search problem.  After all, what else would make the\n&gt;&gt;&gt; problem &quot;hard?&quot;  If here is just a straight shot up a hill then the problem\n&gt;&gt;&gt; is easy.  \n&gt;&gt;&gt; \n&gt;&gt;&gt; The other aspect of hardness is dimensionality.  But both novelty-based and\n&gt;&gt;&gt; objective-based NEAT approach high-dimensionality the same way, i.e. through\n&gt;&gt;&gt; complexification, so that is controlled in the experiment.\n&gt;&gt;&gt; \n&gt;&gt;&gt; So if adaptive problems get stuck, it is likely because of a valley or\n&gt;&gt;&gt; plateau.  The plateau idea makes sense especially in the context of this\n&gt;&gt;&gt; type of problem because the fitness function does not recognize differences\n&gt;&gt;&gt; in behavior that actually matter although they appear equally useless.  Such\n&gt;&gt;&gt; fitness equivalence between very different behaviors is shown in the paper\n&gt;&gt;&gt; in one example in figure 5.\n&gt;&gt;&gt; \n&gt;&gt;&gt; More specifically to adaptation, and this is probably more what you are\n&gt;&gt;&gt; looking for, you really have to get into the experience of evolving adaptive\n&gt;&gt;&gt; neural networks to realize how terribly deceiving they are.  I think most\n&gt;&gt;&gt; people who have worked in this area (and there aren&#39;t that many) would agree\n&gt;&gt;&gt; from experience that it is an incredibly frustrating area of research\n&gt;&gt;&gt; because of evolution&#39;s tendency to find non-adaptive solutions (I realize\n&gt;&gt;&gt; your ECAL paper is related to this experience as well).  In fact, my guess\n&gt;&gt;&gt; is that this reason explains why so few people are in this area (i.e.\n&gt;&gt;&gt; evolving adaptive ANNs).  Otherwise, the area is fascinating.  But when you\n&gt;&gt;&gt; start trying to evolve adaptive networks, you face the endless frustration\n&gt;&gt;&gt; of trying to force it to actually use the adaptive capabilities.  It becomes\n&gt;&gt;&gt; intuitively apparent that whatever path there is towards adaptive behavior\n&gt;&gt;&gt; must cross some behaviors that appear entirely useless to the ultimate goal.\n&gt;&gt;&gt; However, this kind of argument will probably not appear in a paper because\n&gt;&gt;&gt; it is anecdotal.  But I still believe it, and others who research adaptive\n&gt;&gt;&gt; ANNs have said similar things.\n&gt;&gt;&gt; \n&gt;&gt;&gt; ken\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Hello Ken-\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Thanks for the thought-provoking response. I&#39;d like to think about your\n&gt;&gt;&gt;&gt; answers a bit before responding.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; However, if you have a second, I would be interested to hear your thoughts\n&gt;&gt;&gt;&gt; on what I originally intended to be my main question, which is this:\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; The paper seems to further suggest that the reason many of these problems\n&gt;&gt;&gt;&gt;&gt;&gt; are deceptive is because (a) it is easier to learn a fixed-heuristic, and\n&gt;&gt;&gt;&gt;&gt;&gt; then (b) there is a fitness valley between that fixed-heuristic and the\n&gt;&gt;&gt;&gt;&gt;&gt; adaptive strategy.\n&gt;&gt;&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt;&gt;&gt; I agree with (a) (in most cases), but why assume (b)?\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Much of analysis in the paper hinges on the fact that there is actually a\n&gt;&gt;&gt;&gt; fitness valley between a fixed-heuristic and learning. But do we know that\n&gt;&gt;&gt;&gt; is the case for your experiment? Is it usually the case? Why?\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; For me, questions on this front are really intriguing and, before your\n&gt;&gt;&gt;&gt; paper, I had not spent much time thinking about them. An understanding of\n&gt;&gt;&gt;&gt; them might really help our field better evolve adaptive agents.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt;&gt; Jeff\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt; \n&gt; \n&gt; \n\n\n\n"}}