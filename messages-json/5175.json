{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":256087559,"authorName":"Andrei","from":"&quot;Andrei&quot; &lt;andrei.rusu@...&gt;","profile":"andrei.rusu","replyTo":"LIST","senderId":"hxbk0cCfang3KxKSyEDP2sbVAgvbkrBuCXcFUnwl3UQRVwdkn8sdQLr62UkZFYioyAF5QifSgxtBQvbxdC1fENAposUp-9w","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Weird substrate output","postDate":"1269341614","msgId":5175,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhvYTZqZSthbzRjQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhvMmdoNitoZWcwQGVHcm91cHMuY29tPg=="},"prevInTopic":5172,"nextInTopic":5176,"prevInTime":5174,"nextInTime":5176,"topicId":5171,"numMessagesInTopic":4,"msgSnippet":"I have set all inputs and biases to 0 and I am getting all 0s in all 3 layers. Which makes sense, because I have SignedActivation 1.0 in the NEAT config.dat","rawEmail":"Return-Path: &lt;andrei.rusu@...&gt;\r\nX-Sender: andrei.rusu@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 32646 invoked from network); 23 Mar 2010 10:56:36 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m4.grp.sp2.yahoo.com with QMQP; 23 Mar 2010 10:56:36 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta1.grp.re1.yahoo.com with SMTP; 23 Mar 2010 10:56:36 -0000\r\nX-Received: from [69.147.65.147] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 23 Mar 2010 10:53:36 -0000\r\nX-Received: from [98.137.34.33] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 23 Mar 2010 10:53:36 -0000\r\nDate: Tue, 23 Mar 2010 10:53:34 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hoa6je+ao4c@...&gt;\r\nIn-Reply-To: &lt;ho2gh6+heg0@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Andrei&quot; &lt;andrei.rusu@...&gt;\r\nSubject: Re: Weird substrate output\r\nX-Yahoo-Group-Post: member; u=256087559; y=Z6oAyAY_N9vwmo_YOhrFk_1T_zE25ogdigalkCKerv13_Kd23UM\r\nX-Yahoo-Profile: andrei.rusu\r\n\r\nI have set all inputs and biases to 0 and I am getting all 0s in all 3 laye=\r\nrs. Which makes sense, because I have &quot;SignedActivation 1.0&quot; in the NEAT co=\r\nnfig.dat file. If I set &quot;SignedActivation 0.0&quot;, layer A is all 0s, and laye=\r\nrs B & C are all (almost) 1.0. I looked into the FastBiaseNetwork.cpp NEAT =\r\ncode to see how the outputs are being computed, and it seems my code needs =\r\nmore debugging. \n\nOne more thing. Would you recommend using tanh sigmoids? =\r\nFrom the way they are computed in the NEAT code, they seem to be just a dif=\r\nferent rescaling of the 1/(1+exp(- a*x)) sigmoid. \n\nShouldn&#39;t that be:\n\nret=\r\nVal =3D (1 - 2 / (1 + exp(2 * tmpVal));  // tanh \n\n// instead of: (signed s=\r\nigmoid case) \nretVal =3D 2 / (1 + exp(-2 * tmpVal)) - 1; // a=3D2 sigmoid\n\n=\r\n\n\nThanks for your input!\nAndrei\n\n--- In neat@yahoogroups.com, &quot;Ken&quot; &lt;kstanl=\r\ney@...&gt; wrote:\n&gt;\n&gt; \n&gt; \n&gt; It may be useful to do a little debugging to see w=\r\nhat&#39;s going on:\n&gt; \n&gt; If you input all zeros to the substrate input layer, w=\r\nhat happens at the hidden layer?  If there are no bias values, and the hidd=\r\nen layer computes unsigned sigmoids (i.e. sigmoids that range between 0 and=\r\n 1), then every sigmoid in the hidden layer should output 0.5 (since they a=\r\nll have zero activation coming on).  If that is not the case, then there is=\r\n something else at play.\n&gt; \n&gt; Then you can check what the output nodes are =\r\ngenerating from there.  For example, look at a single output node and the 8=\r\n1 or so inputs that go into it, and compute for yourself the correct output=\r\n based on the weights and the activations going over them (which would all =\r\nbe 0.5).\n&gt; \n&gt; You may then find out why it is saturating.  Or you may find =\r\na bug.   But it can help to isolate the problem.\n&gt; \n&gt; You can also try mani=\r\npulating the substrate weights by hand to isolate the issue.  For example, =\r\nyou can set all of the hidden-layer-to-output weights to zero except those =\r\ngoing into a single one of the output nodes.  In that case, only that node =\r\nshould have a unique output value.  If that does not happen, then you may i=\r\nsolate what went wrong.\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Andrei&quot;=\r\n &lt;andrei.rusu@&gt; wrote:\n&gt; &gt;\n&gt; &gt; I am using a 3 layered sandwich substrate wi=\r\nth biases, each layer 9x9 nodes, generated by a CPPN with sigmoid outputs. =\r\nThe weights are computed in exactly the same fashion as in the checkers exp=\r\neriment,\n&gt; &gt; with a formula like: (w-0.2)/0.8 * 3.0 for positive weights w =\r\n&gt; 0.2 (etc) \n&gt; &gt; \n&gt; &gt; The output is all 1&#39;s, and the substrate does indeed =\r\nseem to have more positive weighted links than negative ones. I am facing t=\r\nhe same &#39;issue&#39; in later generations. \n&gt; &gt; \n&gt; &gt; The substrate inputs are al=\r\nl between -1 and 1, but I do not normalize the 9x9 input matrix. Might this=\r\n be the issue. \n&gt; &gt; \n&gt; &gt; I changed the formulas to something like: (w-0.2)/=\r\n0.8 * 0.01 and now I get values around 0.44 on all output nodes.\n&gt; &gt; \n&gt; &gt; D=\r\noes this &#39;issue&#39; suggest any misuse of (Hyper)NEAT to anyone?\n&gt; &gt; \n&gt; &gt; Than=\r\nks, \n&gt; &gt; Andrei\n&gt; &gt;\n&gt;\n\n\n\n"}}