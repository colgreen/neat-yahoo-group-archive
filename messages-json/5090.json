{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"lsPRyTIsXxG6nR-QoY_C4R45i4Nj_Pow02hfabfc62FC7TXLjbxZzi9zaPFdm2S3tHHq1wJfvxJgJP5fY-S9FBQzgjFJ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Resolving recurrent structure.","postDate":"1264295148","msgId":5090,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhqZzZkYys0azAzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhqZHR0NCsydGtwQGVHcm91cHMuY29tPg=="},"prevInTopic":5082,"nextInTopic":5093,"prevInTime":5089,"nextInTime":5091,"topicId":5075,"numMessagesInTopic":8,"msgSnippet":"First, it is important to note that the way networks are activated is not part of the NEAT algorithm.  It just evolves the network structure; you can activate","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 50353 invoked from network); 24 Jan 2010 01:06:17 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m4.grp.sp2.yahoo.com with QMQP; 24 Jan 2010 01:06:17 -0000\r\nX-Received: from unknown (HELO n37b.bullet.mail.sp1.yahoo.com) (66.163.168.151)\n  by mta3.grp.sp2.yahoo.com with SMTP; 24 Jan 2010 01:06:17 -0000\r\nX-Received: from [69.147.65.147] by n37.bullet.mail.sp1.yahoo.com with NNFMP; 24 Jan 2010 01:05:50 -0000\r\nX-Received: from [98.137.34.35] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 24 Jan 2010 01:05:50 -0000\r\nDate: Sun, 24 Jan 2010 01:05:48 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hjg6dc+4k03@...&gt;\r\nIn-Reply-To: &lt;hjdtt4+2tkp@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Resolving recurrent structure.\r\nX-Yahoo-Group-Post: member; u=54567749; y=zodBkJqYRr2pOftDuEm5ii-eyZs1x0gjroq672JmQ1oLtx14fAdJ\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nFirst, it is important to note that the way networks are activated is not=\r\n part of the NEAT algorithm.  It just evolves the network structure; you ca=\r\nn activate that structure however you want.\n\nIn practice, most NEAT impleme=\r\nntations follow the procedure in the NEAT Software FAQ at http://www.cs.ucf=\r\n.edu/~kstanley/neat.html under question &quot;How are networks with arbitrary to=\r\npologies activated?&quot;\n\nTo quote from that answer:\n\n&quot;The activation function,=\r\n bool Network::activate(), gives the specifics. The implementation is of co=\r\nurse considerably different than for a simple layered feedforward network. =\r\n Each node adds up the activation from all incoming nodes from the previous=\r\n timestep. (The function also handles a special &quot;time delayed&quot; connection, =\r\nbut that is not used by the current version of NEAT in any experiments that=\r\n we have published.) Another way to understand it is to realize that activa=\r\ntion does not travel all the way from the input layer to the output layer i=\r\nn a single timestep. In a single timestep, activation only travels from one=\r\n neuron to the next. So it takes several timesteps for activation to get fr=\r\nom the inputs to the outputs. If you think about it, this is the way it wor=\r\nks in a real brain, where it takes time for a signal hitting your eyes to g=\r\net to the cortex because it travels over several neural connections. &quot;\n\nSo =\r\nbasically the activation routine does not make any distinction between feed=\r\nforward or recurrent connection:  On each timestep, activations travels the=\r\n length of one connection from every node.  Whether the connection points b=\r\nackwards or forwards doesn&#39;t matter.  This approach thus is somewhat easy t=\r\no program.\n\nHowever, there is some controversy on whether this approach is =\r\nalways best (in terms of computational efficiency) and there are alternativ=\r\nes for arbitrary-topology networks.  This issue has been discussed on this =\r\ngroup in the past.\n\nken\n\n--- In neat@yahoogroups.com, &quot;snapmedown&quot; &lt;snapmed=\r\nown@...&gt; wrote:\n&gt;\n&gt; I mean resolve as in actually getting from inputs to ou=\r\ntputs.  I don&#39;t know what method NEAT and the NEAT family of algorithms use=\r\ns.\n&gt;\n\n\n\n"}}