{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":115403844,"authorName":"John Arrowwood","from":"&quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"QHceUfnKsJhhslZiBiocKge7WMgZYQPioI-lhPLyeTLDALJATtCJyYNbaQTI0NNIoJf0qSaJAvIDE9qcQARcHfh_vwzmSF47TT2u9bIY","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Stephen Thaler","postDate":"1091040514","msgId":1257,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBWTItRjE4Q2w5Rm9wWUM5OEIwMDAyYTczY0Bob3RtYWlsLmNvbT4="},"prevInTopic":0,"nextInTopic":1259,"prevInTime":1256,"nextInTime":1258,"topicId":1257,"numMessagesInTopic":9,"msgSnippet":"... [snip] Funny thing is, his technique is functionally equivalent to the weight-mutation aspect of NEAT.  He randomly tweaks a few weights by a small amount,","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 44181 invoked from network); 28 Jul 2004 18:48:52 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m14.grp.scd.yahoo.com with QMQP; 28 Jul 2004 18:48:52 -0000\r\nReceived: from unknown (HELO hotmail.com) (65.54.247.18)\n  by mta1.grp.scd.yahoo.com with SMTP; 28 Jul 2004 18:48:52 -0000\r\nReceived: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\n\t Wed, 28 Jul 2004 11:48:34 -0700\r\nReceived: from 64.122.44.102 by by2fd.bay2.hotmail.msn.com with HTTP;\n\tWed, 28 Jul 2004 18:48:34 GMT\r\nX-Originating-Email: [jarrowwx@...]\r\nX-Sender: jarrowwx@...\r\nTo: neat@yahoogroups.com\r\nBcc: \r\nDate: Wed, 28 Jul 2004 11:48:34 -0700\r\nMime-Version: 1.0\r\nContent-Type: text/plain; format=flowed\r\nMessage-ID: &lt;BAY2-F18Cl9FopYC98B0002a73c@...&gt;\r\nX-OriginalArrivalTime: 28 Jul 2004 18:48:34.0535 (UTC) FILETIME=[7C49CF70:01C474D3]\r\nX-eGroups-Remote-IP: 65.54.247.18\r\nFrom: &quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;\r\nReply-To: john@...\r\nSubject: Stephen Thaler\r\nX-Yahoo-Group-Post: member; u=115403844\r\nX-Yahoo-Profile: jarrowwx\r\n\r\n&gt;From: Tyler Streeter &lt;tylerstreeter@...&gt;\n&gt;\n&gt; &gt; And what if the network does come to depend on that\n&gt; &gt; noise?  Read up on\n&gt; &gt; Stephen Thaler and his Creativity Machine.\n&gt; &gt; http://www.imagination-engines.com/thaler.htm\n&gt;\n&gt;I remember hearing about this &quot;Creativity Machine&quot; a\n&gt;while ago.  I was just reading some things on his\n&gt;site.  He seems to think that his Creative Machine\n&gt;paradigm is the ultimate solution for everything under\n&gt;the sun.  It sounds like a lot of hype, but I guess\n&gt;time will tell.  He does have some recent applications\n&gt;that sound pretty good.\n&gt;\n&gt;In a few places he talks about the inferiority of GAs\n&gt;to his technique, usually worded in annoying ways.\n&gt;Here&#39;s a sample:\n\n[snip]\n\nFunny thing is, his technique is functionally equivalent to the \nweight-mutation aspect of NEAT.  He randomly tweaks a few weights by a small \namount, to see if it makes things better.\n\nWhere it differs is that it judges the effect immediately, rather than over \na longer evaluation.  And the changing (evolving) continues indefinitely, \nnot just until it has a solution.  Which creates an interesting and \npotential useful behavior.\n\nYou have this fixed topology.  And the network has some built-in ability to \njudge its own fitness (for example, is the walker balanced?).  With every \nactivation, it makes SMALL tweaks to some small portion of the weights.  \nThen it activates.  Did its fitness improve?  If not, the tweaks are rolled \nback.  If so, they remain.  What this means is that it adapts to its present \nsituation, at the expense of the generalized solution.  When the situation \nchanges, it then re-adapts to that one.  If the topology facilitates it, \nthen this constant weight shifting allows it to be as good as it can be at \nthe current task, with a delay while it comes up to speed.  This as opposed \nto dividing your error equally among all situations, which is what a \nfixed-weight network would be forced to do.\n\nBut what his work does show is that randomness can be a valuable tool for \nsearching for an optimal solution.  Which of course, NEAT already proved.  \n:)\n\n&gt;So far I haven&#39;t found any good methods for robot\n&gt;control that are as &quot;self-training&quot; as a GA since the\n&gt;feedback is just so sparse, but apparently Thaler&#39;s\n&gt;method has been used to train robots.  I guess I&#39;m\n&gt;open to new ideas...\n\nPersonally, I see NEAT and Thaler&#39;s approaches being able to co-exist.  \nThaler requires an appropriate topology and works best if that topology is \nalready tuned to the generalized solution.  NEAT evolves that starting \nconfiguration.  But as part of the evaluation cycle, you could have the \nweight tweaking &#39;creativity machine&#39; component.  So the overall fitness \nevaluation given back to NEAT is a function of both whether or not the \ntopology was able to solve the problem, and how far it had to change the \nweights to get there.  Or something to that effect.\n\nCombine that with competitive co-evolution and see what you get. :)\n\n&gt;I&#39;m wondering if anyone has any more info on this.\n&gt;I&#39;d like to get some info from an unbiased source\n&gt;(i.e. not the super-hyped stuff from the Imagination\n&gt;Engines website).\n\nAll I can offer is my analysis of what it is and why it works.  It works \nexactly the same as the means by which NEAT optimizes a single network \ntopology...weight mutation, rewarding the more fit mutations and discarding \nthe less fit ones.  The only difference is that they are rewarded or \npunished immediately, rather than evaluating their fitness over a large \nnumber of possible situations.  Both approaches have their place, and might \nbe quite powerful if combined.\n\nWhich gives me an idea...I imagine a mechanism that helps the network \nremember where it came from, so it is more likely to go back to it as a \nfall-back:\n\nHave the connection weight be a series of numbers, a minimum of 3.  The \nactual weight is the sum of all of them.  The first number is the one that \nis randomly changed if it is perturbed.  That number is propagated to the \nnext number based on fitness change.  If a rise in fitness has recently been \ndetected, then a portion of that perturbation is propagated to the next \nnumber proportionate to how much of a rise there was.  So let&#39;s say there \nwas a good rise in fitness, so 25% of the first number is propagated to the \nsecond.  The first number is lowered by 25%, and the second increased by the \namount that the first was reduced.  The net weight remains unchanged. \nLikewise, a smaller portion of the 2nd number is propagated to the third.  \nThe last number is the &#39;base weight&#39;.  As long as fitness appears to be \nimproving, changes propagate back and modify the base weight, slowly.\n\nWhereas, when there is a reduction in fitness, something else happens.  All \nexcept the base weight are reduced by some percentage.  So the overall value \ntends to return back to its base value.  This allows the weight to \ntemporarily adjust to a value that gives it greater fitness, and then go \nback to what it was when that mutation is no longer beneficial, but without \nhaving to find its way back to that base weight through random chance.  The \nlonger the chain of weight propagation, the longer you can be at a new \nweight value before that new value becomes permanent.  Or you can get the \nsame effect with three numbers, but altering how fast the perturbations \npropagate back to the base weight.\n\nNow if only I was working on controllers, I might actually implement it and \nsee what the effect is...\n\n-- John\n\n\n\n"}}