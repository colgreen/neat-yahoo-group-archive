{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":41639346,"authorName":"Philip Tucker","from":"&quot;Philip Tucker&quot; &lt;tucker0171@...&gt;","profile":"tucker0171","replyTo":"LIST","senderId":"Ja41ieYDsclRdkGhf8Ktt7F9PgTGMsrCj-dq9DKiB6FayhAgj11MV27xQjSx7WZv8sCVd46af93wKLUFKZENCB61RNgryHW4Q-_hlIw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: How Network Activation Should Work","postDate":"1080847051","msgId":606,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGM0aHBzYitwYjE3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGM0Zm9wNCt0MGVnQGVHcm91cHMuY29tPg=="},"prevInTopic":604,"nextInTopic":607,"prevInTime":605,"nextInTime":607,"topicId":534,"numMessagesInTopic":19,"msgSnippet":"... From the FAQ: Each node adds up the activation from all incoming nodes from the previous timestep. How do you add the activation from the previous time","rawEmail":"Return-Path: &lt;tucker0171@...&gt;\r\nX-Sender: tucker0171@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 80240 invoked from network); 1 Apr 2004 19:17:59 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m16.grp.scd.yahoo.com with QMQP; 1 Apr 2004 19:17:59 -0000\r\nReceived: from unknown (HELO n13.grp.scd.yahoo.com) (66.218.66.68)\n  by mta6.grp.scd.yahoo.com with SMTP; 1 Apr 2004 19:17:59 -0000\r\nReceived: from [66.218.67.128] by n13.grp.scd.yahoo.com with NNFMP; 01 Apr 2004 19:17:33 -0000\r\nDate: Thu, 01 Apr 2004 19:17:31 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;c4hpsb+pb17@...&gt;\r\nIn-Reply-To: &lt;c4fop4+t0eg@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 3893\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.68\r\nFrom: &quot;Philip Tucker&quot; &lt;tucker0171@...&gt;\r\nSubject: Re: How Network Activation Should Work\r\nX-Yahoo-Group-Post: member; u=41639346\r\nX-Yahoo-Profile: tucker0171\r\n\r\n&gt; It&#39;s pretty clear from this discussion that the way Derek and Philip\n&gt; are activating their networks is not the standard way it works in\n&gt; NEAT, because in standard NEAT, you don&#39;t need to keep activation in\n&gt; memory from the previous timestep.  \n\nFrom the FAQ:\n&quot;Each node adds up the activation from all incoming nodes from the \nprevious timestep.&quot;\n\nHow do you add the activation from the previous time step if that \nactivation is not in memory?\n\nWe&#39;ve found 2 basic ways to approach activation.\n\n(1) Standard NEAT: For each node, maintain in memory the activation \nof the current and previous time step.  Each node computes its \nactivation based on the previous time step, so you don&#39;t have do do \nany dependency analysis to determine the activation order of the \nnodes, and there&#39;s no deadlock if you have a loop.  I believe this is \nthe standard NEAT approach of which you speak.\n\n(2) Full traversal: Each node maintains only 1 value, the activation \nof the current time step.  Recurrent connections maintain their input \nnode&#39;s value from the previous time step.  At each time step, a node \nreads its non-recurrent incoming connections, which in turn read the \ncurrent value of their incoming nodes.  It also reads its recurrent \nconnections, which return their input node&#39;s value from the previous \ntime step.  Activation flows completely from input to output each \ntime step, but it will take several time steps for recurrent \nconnections to have effect.\n\nStrategy 1 is less efficient in that it takes longer for an \nactivation to propogate through the network.  Whatever the longest \npath between input and output, that&#39;s how many time steps an \nactivation takes.  It also uses memory less efficiently since we&#39;re \nstoring 2 values for every node.  \n\nStrategy 2 has the disadvantage of requiring network analysis to \ndetermine which connections are recurrent.  This is non-trivial, and \nsometimes requires that arbitrary decisions are made.  For example, \nconsider the following topology:\n\n          D\n         / &#92;\n        B===C\n         &#92; /\n          A\n\nThe connections are A-&gt;B, A-&gt;C, B-&gt;C, C-&gt;B, B-&gt;D, C-&gt;D.  This network \ncould be constructed where either or both of B-&gt;C and C-&gt;B are \nrecurrent.  Depending on which you choose, you&#39;ll get slightly \ndifferent behavior.\n\n&gt; Every connection just sends the\n&gt; activation coming in to the the node on the output on each timestep;\n&gt; it&#39;s that simple.  So there is no need to know what connection is\n&gt; recurrent and what isn&#39;t for the purposes of activation.  \n\nSo, does this mean each node stores the previous time step value of \neach of its incoming nodes (multiplied by the connection weight)?\n\n&gt; definitely nonstandard and more complicated then necessary.  Also,\n\nIt may be non-standard in the context of NEAT.  But, other neural net \nimplementations I&#39;ve seen such as JOONE have the concept of recurrent \nconnections.\n\n&gt; such a network will not always behave the same as a network\n&gt; activated the standard way, even with exactly the same structure,\n&gt; which could cause cross-platform confusion.  \n\nThis is true.  However, we&#39;ve done experiments to show both methods \nconverge to the same results over time, at least for fairly simple \nnetworks (~30 genes).  If we think of the input to a node as a stream \nof data as opposed to a number, then an indivual activation is just \none time step in the stream and the diference between the 2 \napproached is negligible.\n\nA tricky situation can occur where it doesn&#39;t converge but hits a \nresonant frequency.  I&#39;m not sure how common this would be in real \nnetworks - I was able to produce it in a simple net.  The pattern is \nthe same, but the frequency different for the 2 activation methods.\n\nSo, the real question is efficiency.  So far our networks aren&#39;t \nlarge enough that the extra memory and time steps required for \nstrategy #1 are substantial.  But, they could be eventually.\n\n\n\n\n"}}