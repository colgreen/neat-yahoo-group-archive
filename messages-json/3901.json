{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"MROFyX05AOW45HntP8jWRV3HWqt0Wgbu-o3DGVAjaZ5K9gYOOah5arJxGDeVWXkq9oG_jc9Ha5KtwtZm19mpfts","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205864854","msgId":3901,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZycDFpbStla2pjQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZybXZlZCtlbmRpQGVHcm91cHMuY29tPg=="},"prevInTopic":3895,"nextInTopic":3905,"prevInTime":3900,"nextInTime":3902,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"To the motivated and intellectually honest, I contend that prior references and explanations are sufficient for discovery and understanding. That said, no","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 7693 invoked from network); 18 Mar 2008 18:27:34 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m48.grp.scd.yahoo.com with QMQP; 18 Mar 2008 18:27:34 -0000\r\nX-Received: from unknown (HELO n27b.bullet.sp1.yahoo.com) (209.131.38.244)\n  by mta16.grp.scd.yahoo.com with SMTP; 18 Mar 2008 18:27:34 -0000\r\nX-Received: from [216.252.122.218] by n27.bullet.sp1.yahoo.com with NNFMP; 18 Mar 2008 18:27:34 -0000\r\nX-Received: from [209.73.164.86] by t3.bullet.sp1.yahoo.com with NNFMP; 18 Mar 2008 18:27:34 -0000\r\nX-Received: from [66.218.66.92] by t8.bullet.scd.yahoo.com with NNFMP; 18 Mar 2008 18:27:34 -0000\r\nDate: Tue, 18 Mar 2008 18:27:34 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frp1im+ekjc@...&gt;\r\nIn-Reply-To: &lt;frmved+endi@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=8zpB2dAYQ4GL5uMLVcqUZj1T-8gbyR5j9SfKo_fD0l82dg\r\nX-Yahoo-Profile: afcarl2\r\n\r\nTo the motivated and intellectually honest, I contend that prior \nreference=\r\ns and explanations are sufficient for discovery and \nunderstanding.\n\nThat s=\r\naid, no reference has been made to disfavor discovery of \npatterns. In the =\r\ncontext of engineering optimization/search, your \npredisposition and creati=\r\non of hyperneat could be viewed as the \nanalogous equivalent of seeking a p=\r\nhysics-based surrogate model, \nthough for differing reasons.\n\nPerhaps withi=\r\nn the confines of your area of expertise, this concept \nis novel, as it app=\r\nears from your statements. But in the larger \nlandscape of engineering opti=\r\nmization/search, there is an entire \nbranch of research associated with sur=\r\nrogate-based models and \noptimization/search. Which, btw, if you take the o=\r\npportunity to \nreview what the other guys are doing outside of your area of=\r\n \nexpertise (i.e. previously provided reference), I believe it may even \nfa=\r\ncilitate your endeavors. And at the very least, it would help to \nconvey an=\r\n impression of genuine motivation to discover, rather than \na &quot;not invented=\r\n here&quot; mentality.\n\nIt is difficult to see the utility of expending the ener=\r\ngy of \nexplanation, when it appears that you are entangled in the conflicts=\r\n \nand differences of opinions within the differing niches of AI, seemly \nun=\r\nable to take a step back to get a perspective which includes more \nthan the=\r\nse differing niches.\n\nIn a nutshell:\na) Multi-discipline: seemly self-evide=\r\nnt, simultaneous or staged, \nanalogous to multiple differing vocabularies a=\r\nnd syntax.\nb) Multi-Objective: simultaneous, multiple arbitrary hyperspaces=\r\n of \narbitrary sub-sets of input parameter dimensionalities.\nc) Linear equa=\r\nlity/inequality feasibility constraints: seemly self-\nevident, multiple arb=\r\nitrary discrete values and/or ranges of \nacceptable values of arbitrary inp=\r\nut parameters.\nd) Non-linear equality/inequality feasibility constraints: m=\r\nultiple \narbitrary discrete values and/or ranges of acceptable values of \nm=\r\nultiple arbitrary hyperspaces of arbitrary sub-sets of input \nparameter dim=\r\nensionalities.\n\nThat said, your predisposition of endeavor appears to be th=\r\ne \ndiscovery of a global pattern (with or w/o variation/elaboration), \nasso=\r\nciated with a given objective hyperspace.\n\nThe fundamental problem is that,=\r\n subsequent to whatever means are \nutilized to apply the arbitrary feasibil=\r\nity constraints (i.e. &quot;c&quot; \nand &quot;d&quot; above), what&#39;s left of the given objecti=\r\nve function \nlandscape &quot;as-delivered&quot; to the EA process, will be difficult =\r\nor \nperhaps impossible to identify a global pattern of the specific \nobject=\r\nive (i.e. &quot;ARBITRARY&quot; feasibility constraints).\n\nThe issue then becomes one=\r\n of economy. How much computational \nresources should be expended for the s=\r\nole purpose of discovery of \na &quot;GLOBAL&quot; pattern (w/ or w/o variation/elabor=\r\nation) of a given \nobjective of a multi-objective problem?\n\nIt soon becomes=\r\n evident that it is more computationally feasible to \naccept &quot;REGIONAL&quot; pat=\r\nterns/correlations/curve-fits.\n\nThis is one of the reasons there is an enti=\r\nre research area \nassociated w/ surrogate-based models and optimization/sea=\r\nrch. In your \nfield you appear to refer to it as &quot;representation&quot;.\n\nNo refe=\r\nrence has been made to disfavor use or applicability of EA for \ndeterminati=\r\non of pareto front solution sets. On the contrary, they \nare favored and we=\r\nll suited for this application. The issue was that \nthe computational resou=\r\nrces required for pareto front determination \nonly magnifies/multiplies the=\r\n computational costs issues associated \nwith EA methodologies. \n\nFurthermor=\r\ne, it is self-evident that the application of a given set \nof weights to a =\r\nmultiobjective problem to transform it to a mono-\nobjective problem (i.e. N=\r\nEAT), the solution of which constitutes only \na single point of a pareto fr=\r\nont solution set.\n\nSimply put, the utility of stove-pipe focus on discovery=\r\n of global \npatterns on mono-objective problems w/o application of arbitrar=\r\ny \nfeasibility constraints is marginal at best. And inapplicable to real \nw=\r\norld problems at worst.\n\nIMHO, I believe your endevor associated with &quot;repr=\r\nesentation&quot;, would \nbe well served by a review of surrogate-based \nmodels/o=\r\nptimization/search. But then, that may not be considered \na &quot;breakthrough&quot;.=\r\n\n\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt;=\r\n Andy, maybe you can provide an example of &quot;non-linear inequality \n&gt; feasib=\r\nility constraints&quot; that &quot;utterly destroy&quot; patterns and \n&gt; regularities? \n&gt; =\r\n\n&gt; I think most people would agree that many practical problems \ninvolve \n&gt;=\r\n some kind of pattern.  The human brain itself is filled with \n&gt; spectacula=\r\nr examples of neural patterns, both spatially and \n&gt; temporally.   Is the h=\r\numan brain &quot;utterly destroyed&quot; by &quot;non-linear \n&gt; inequality feasibility con=\r\nstraints?&quot;\n&gt; \n&gt; I get your broader point, though.  You&#39;re saying that I&#39;m g=\r\netting a \n&gt; distorted perspective because I&#39;m conentrating on patterns when=\r\n \n&gt; there are other factors in the world than just patterns.  Yet we \n&gt; can=\r\nnot expect every new algorithm to simultaneously address every \n&gt; challenge=\r\n faced by man.  Any researcher who would try to do that \n&gt; would never get =\r\nanywhere.  With HyperNEAT we have taken a step in a \n&gt; promising direction;=\r\n no more, no less.  If you feel it should be \n&gt; expanded to take into accou=\r\nnt additional particular concerns that \n&gt; you have (which for me are still =\r\nfuzzy), I encourage you to extend \n&gt; it in that direction.  \n&gt; \n&gt; I think y=\r\nour quote from Einstein is delivered in entirely the wrong \n&gt; context.  The=\r\n problem of representation is largely ignored by the \n&gt; machine learning co=\r\nmmunity because it *is* the difficult part.  \n&gt; The &quot;thin part of the wood&quot;=\r\n is the minutia of gradient \noptimization, \n&gt; which have been beaten to dea=\r\nth; yet scientists to this day still \n&gt; focus on it intently.  The reason t=\r\nhey do that is because it&#39;s the \n&gt; easy part, not the hard part.  It is eas=\r\ny to climb a hill once you \n&gt; see it; it is hard to move the hill itself.  =\r\nRepresentation means \n&gt; moving the hills.  I believe Einstein would have no=\r\n objection to \n&gt; rearranging the intellectual landscape.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; -=\r\n-- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Ken,\n&gt; &gt; \n&gt; =\r\n&gt; I can appreciate the need to choose applications &quot;with careful \n&gt; &gt; scrut=\r\niny with a sincere belief in their practical ramifications&quot;, \n&gt; but \n&gt; &gt; th=\r\ne simple truth is that your bias for exploring &quot;patterns and \n&gt; &gt; regularit=\r\nies&quot;, are utterly destroyed by the application of non-\n&gt; linear \n&gt; &gt; inequa=\r\nlity feasibility constraints. Which routinely happens in \nthe \n&gt; &gt; domain o=\r\nf engineering optimization/search. \n&gt; &gt; \n&gt; &gt; Your operation without the app=\r\nlication of the pressures \nassociated \n&gt; &gt; with these pattern destroying in=\r\nfluences results in a unrealistic \n&gt; &gt; perspective on the utility of global=\r\n pattern exploitation, and a \n&gt; &gt; failure to address the repercussions of t=\r\nhe sometimes seemingly \n&gt; &gt; totally arbitrary nature of enforced feasibilit=\r\ny constraints \n&gt; dictated \n&gt; &gt; by real-world problems.\n&gt; &gt; \n&gt; &gt; Until you c=\r\nan simultaneously address the exploitation of multiple \n&gt; &gt; hyperspace &quot;reg=\r\nional/sub-volume&quot; patterns/regularities overlaid \n&gt; with \n&gt; &gt; multiple arbi=\r\ntrary non-linear inequality feasibility constraints, \n&gt; in \n&gt; &gt; a computati=\r\nonally practical manner, methodologies such as \n&gt; Hyperneat \n&gt; &gt; will be di=\r\nspatched as &quot;curiosities&quot; only.\n&gt; &gt; \n&gt; &gt; These kinds of pressures are routi=\r\nnely addressed in the domain of \n&gt; &gt; engineering optimization/search. Your =\r\nchoice of side-stepping \n&gt; these \n&gt; &gt; influences shapes what infrastructure=\r\n is and is-not developed, as \n&gt; has \n&gt; &gt; been adequately addressed in prior=\r\n posts.\n&gt; &gt; \n&gt; &gt; An applicable quote: &quot;I have little patience with scientis=\r\nts who \n&gt; take \n&gt; &gt; a board of wood, look for its thinnest part, and drill =\r\na great \n&gt; number \n&gt; &gt; of holes where drilling is easy.&quot;--Albert Einstein\n&gt;=\r\n &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; Andy, I have no problem with the idea of NEAT as a foundation \n&gt;=\r\n upon\n&gt; &gt; &gt; which to build.  That&#39;s perfectly aligned with my view that \n&gt; =\r\nthere is\n&gt; &gt; &gt; more yet to accomplish.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; Let me respond to som=\r\ne of your specific points below.\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, =\r\n&quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; The issues you raise, th=\r\nough valid, appear disingenuous for \n&gt; two \n&gt; &gt; &gt; &gt; reasons. First, if you =\r\nhad reviewed the contents and \n&gt; capabilities \n&gt; &gt; of \n&gt; &gt; &gt; &gt; the Dakota t=\r\noolkit, you would have discovered the issues as \n&gt; being \n&gt; &gt; &gt; &gt; essential=\r\nly addressed. Second, not intending any disrespect, \n&gt; from \n&gt; &gt; &gt; &gt; extern=\r\nal appearances, your efforts appear directed in other \n&gt; &gt; &gt; &gt; directions t=\r\nhan that of addressing your self admitted areas \nof \n&gt; &gt; &gt; &gt; concern.\n&gt; &gt; &gt;=\r\n &gt; \n&gt; &gt; &gt; &gt; From a review of literature on the subject, there is a common \n=\r\n&gt; &gt; &gt; &gt; understanding that EA is computationally expensive and slow \nto \n&gt; =\r\n&gt; &gt; &gt; converge, but robust for global search in problem domains \nwith \n&gt; &gt; =\r\n&gt; &gt; multiple local minima.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; It really just depends who=\r\n you are talking about whether there \n&gt; is a\n&gt; &gt; &gt; &quot;common understanding&quot; a=\r\nbout anything in AI.  It also depends \n&gt; &gt; whether\n&gt; &gt; &gt; we are talking abo=\r\nut the past or the future.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; For example, it&#39;s often said that=\r\n &quot;neural networks get caught \non \n&gt; &gt; local\n&gt; &gt; &gt; optima&quot; (and there is ind=\r\need a &quot;common understanding&quot; that they \n&gt; do)\n&gt; &gt; &gt; but when people say tha=\r\nt they are almost always only talking \n&gt; about\n&gt; &gt; &gt; backprop, which is jus=\r\nt one single neural network learning \n&gt; &gt; algorithm.\n&gt; &gt; &gt;  Backprop is not=\r\n the only way a neural network can learn.\n&gt; &gt; &gt; \n&gt; &gt; &gt; The problem is that =\r\nwhen we talk about methods in machine \n&gt; learning \n&gt; &gt; we\n&gt; &gt; &gt; often confu=\r\nse whether we are talking about a *field* or a \n&gt; particular\n&gt; &gt; &gt; method. =\r\n In the case of EAs, you seem to be talking about some\n&gt; &gt; &gt; existing metho=\r\nds that have been analyzed (often by people who \n&gt; are \n&gt; &gt; not\n&gt; &gt; &gt; even =\r\naware of the most modern approaches) in the past.   For \n&gt; &gt; example,\n&gt; &gt; &gt;=\r\n the old-fashioned bit-string based simple EA has been analyzed\n&gt; &gt; &gt; exten=\r\nsively.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Yet as a field, EAs themselves are evolving.  Problems=\r\n \n&gt; identified in\n&gt; &gt; &gt; the past are actively being addressed in the presen=\r\nt and \nfuture. \n&gt; &gt; Some\n&gt; &gt; &gt; modern approaches completely overturn the as=\r\nsumptions and \n&gt; problems \n&gt; &gt; of\n&gt; &gt; &gt; the past (and of course introduce t=\r\nheir own new problems).  \n&gt; Check \n&gt; &gt; out\n&gt; &gt; &gt; Estimation of Distribution=\r\n Algorithms and the CMA-ES:\n&gt; &gt; &gt; \n&gt; &gt; &gt; \nhttp://en.wikipedia.org/wiki/Esti=\r\nmation_of_distribution_algorithm\n&gt; &gt; &gt; http://en.wikipedia.org/wiki/CMA-ES\n=\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; When I look at EAs, or any research area for that matter, I \n&gt;=\r\n always\n&gt; &gt; &gt; think about what they *could* be, rather than what they are. =\r\n \n&gt; And \n&gt; &gt; as a\n&gt; &gt; &gt; researcher, I try to make them what they could be. =\r\n To me, that \n&gt; is \n&gt; &gt; the\n&gt; &gt; &gt; exciting thing about research: At its bes=\r\nt, it overturns \ndogma.  \n&gt; I\n&gt; &gt; &gt; like to view a limitation as a challeng=\r\ne rather than as a brick \n&gt; &gt; wall.\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; And that is from people =\r\nwho are working &quot;hard&quot; problems (i.e. \n&gt; &gt; multi-\n&gt; &gt; &gt; &gt; discipline, multi=\r\nobjective, non-linear inequality \nconstraints, \n&gt; &gt; etc.), \n&gt; &gt; &gt; &gt; at gove=\r\nrnment laboratories and Fortune 100 defense firms. Not \n&gt; &gt; dancing \n&gt; &gt; &gt; =\r\n&gt; rag-dolls and computer-aided art.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; First, while you =\r\noften cite multiobjective optimization as \n&gt; a &quot;hard\n&gt; &gt; &gt; problem&quot; for EAs=\r\n, in fact some of the most effective algorithms \n&gt; in\n&gt; &gt; &gt; multiobjective =\r\noptimization are EAs.  EAs are naturally suited \nto\n&gt; &gt; &gt; maintaining a par=\r\neto front because a pareto front requires a\n&gt; &gt; &gt; population to hold it.  T=\r\nhere is vast literature on pareto\n&gt; &gt; &gt; optimization in EAs, both in multio=\r\nbjective optimization and in\n&gt; &gt; &gt; coevolution.  Here are some seminal exam=\r\nples:\n&gt; &gt; &gt; \n&gt; &gt; &gt; K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A Fast =\r\nand \n&gt; Elitist\n&gt; &gt; &gt; Multiobjective Genetic Algorithm: NSGA-II. IEEE Transa=\r\nctions on\n&gt; &gt; &gt; Evolutionary Computation, 6(2):182=96197, 2002.\n&gt; &gt; &gt; http:=\r\n//citeseer.ist.psu.edu/530140.html\n&gt; &gt; &gt; \n&gt; &gt; &gt; De Jong, E.D. (2004). The I=\r\nncremental Pareto-Coevolution \nArchive.\n&gt; &gt; &gt; Proceedings of the Genetic an=\r\nd Evolutionary Computation \n&gt; Conference\n&gt; &gt; &gt; GECCO-04, pp. 525-536. \n&gt; &gt; =\r\n&gt; http://people.cs.uu.nl/dejong/publications/gecco04coev.pdf\n&gt; &gt; &gt; \n&gt; &gt; &gt; i=\r\nn fact, some of the most brilliant theorists in pareto \n&gt; optimization\n&gt; &gt; =\r\n&gt; are in evolutionary computation.\n&gt; &gt; &gt; \n&gt; &gt; &gt; As for NEAT in government r=\r\nesearch labs on &quot;serious&quot; problems, \n&gt; here \n&gt; &gt; is\n&gt; &gt; &gt; an example:\n&gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; Shimon Whiteson and Daniel Whiteson (2007). &quot;Stochastic \n&gt; Optimiza=\r\ntion\n&gt; &gt; &gt; for Collision Selection in High Energy Physics&quot;. IAAI 2007:\n&gt; &gt; =\r\n&gt; Proceedings of the Nineteenth Annual Innovative Applications of\n&gt; &gt; &gt; Art=\r\nificial Intelligence Conference.&#8202;\n&gt; &gt; &gt; http://arxiv.org/PS_cache/hep=\r\n-ex/pdf/0607/0607012v1.pdf\n&gt; &gt; &gt; \n&gt; &gt; &gt; The article itself states, &quot;These N=\r\nEAT selectors are currently \n&gt; in \n&gt; &gt; use\n&gt; &gt; &gt; at FermiLab for selecting =\r\ncollisions from real data collected\n&gt; &gt; &gt; with the Tevatron collider.&quot;  So,=\r\n there you go, NEAT is being \n&gt; used \n&gt; &gt; at\n&gt; &gt; &gt; FermiLab itself to selec=\r\nt which particle collisions are most \n&gt; &gt; promising.\n&gt; &gt; &gt; \n&gt; &gt; &gt; When you =\r\nmention rag dolls and art, you&#39;re giving me an \n&gt; opportunity \n&gt; &gt; to\n&gt; &gt; &gt;=\r\n comment on some of our own current research.  Our group has \n&gt; indeed\n&gt; &gt; =\r\n&gt; recently produced a number of works in interactive evolution,\n&gt; &gt; &gt; inclu=\r\nding dance, art, music, and particle effects.  Perhaps it \n&gt; may\n&gt; &gt; &gt; seem=\r\n a somewhat lighthearted departure from more serious \n&gt; subjects.\n&gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; Yet the implications of this work are as serious as any in my \n&gt; view. =\r\n\n&gt; &gt; &gt; All of that work is a probe of the ubiquity of patterns and\n&gt; &gt; &gt; re=\r\ngularities, in particular through the theory of CPPNs.  The \n&gt; deeper\n&gt; &gt; &gt;=\r\n lesson in that body of work is that the very same encoding is \n&gt; able \n&gt; &gt;=\r\n to\n&gt; &gt; &gt; produce patterns appropriate to what would otherwise appear to \nb=\r\ne\n&gt; &gt; &gt; disparate domains.  The idea is to develop a theory of generic \n&gt; &gt;=\r\n pattern\n&gt; &gt; &gt; generation and to show that patterns are interchangeable acr=\r\noss \n&gt; many\n&gt; &gt; &gt; domains.  That insight leads to the idea of HyperNEAT, wh=\r\nich \n&gt; takes\n&gt; &gt; &gt; again the very same encoding that is producing art and m=\r\nusic \nand \n&gt; &gt; uses\n&gt; &gt; &gt; it to produce a large-scale neural pattern.  Ther=\r\nein it becomes\n&gt; &gt; &gt; serious, because the hard problems you like to focus o=\r\nn almost \n&gt; &gt; always\n&gt; &gt; &gt; involve patterns and regularities.  \n&gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; It is no accident that in building a theory of pattern \n&gt; generation, a\n&gt;=\r\n &gt; &gt; number of interactive evolutionary computation experiments \nwould \n&gt; &gt;=\r\n need\n&gt; &gt; &gt; to be performed because understanding the capabilities of a \n&gt; =\r\npattern\n&gt; &gt; &gt; generator require *exploring* the space of possibilities rath=\r\ner \n&gt; than\n&gt; &gt; &gt; simply optimizing, and humans are much better explorers th=\r\nan\n&gt; &gt; &gt; computers.  The theory would never have gotten off the ground \nif =\r\n\n&gt; we\n&gt; &gt; &gt; had stuck to more traditional optimization problems.   Indeed, =\r\n\nas\n&gt; &gt; &gt; funny as it sounds, the whole idea began to materialize only \n&gt; a=\r\nfter I\n&gt; &gt; &gt; evolved a spaceship in Mattias Fagerlund&#39;s DelphiNEAT.  \n&gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; To put it starkly, without that exploration in genetic art, \nthere\n=\r\n&gt; &gt; &gt; would have been no HyperNEAT.  And in fact even more new \n&gt; theories =\r\n\n&gt; &gt; with\n&gt; &gt; &gt; practical implications are coming (not yet published) becau=\r\nse of\n&gt; &gt; &gt; phenomena that became apparent through Picbreeder.  So you see,=\r\n \n&gt; in\n&gt; &gt; &gt; building a new algorithm or a new theory with practical \n&gt; &gt; i=\r\nmplications,\n&gt; &gt; &gt; often traditional problems are exactly the wrong vehicle=\r\n to \n&gt; &gt; discovery\n&gt; &gt; &gt; because they perpetuate the same dogmatic perspect=\r\nives that \n&gt; already\n&gt; &gt; &gt; permeate the field to begin with and cause it to=\r\n be staying in \n&gt; one\n&gt; &gt; &gt; place.   Thus all of these applications are cho=\r\nsen with careful\n&gt; &gt; &gt; scrutiny with a sincere belief in their practical ra=\r\nmifications.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Not to mention the fact that interactive evolutio=\r\nn itself has \nthe\n&gt; &gt; &gt; practical potential to change the way we do enginee=\r\nring in some \n&gt; &gt; cases.\n&gt; &gt; &gt;  Can you imagine Picbreeder for furinute ins=\r\ntead of pictures?  \n&gt; Or \n&gt; &gt; for\n&gt; &gt; &gt; cars?  Someday that may be how we c=\r\nreate highly customized \n&gt; &gt; artifacts.\n&gt; &gt; &gt;    In fact, some of the probl=\r\nems to which you are referring \n&gt; (highly\n&gt; &gt; &gt; nonlinear and multi-objecti=\r\nve) may only be possible to solve \n&gt; through\n&gt; &gt; &gt; interactive evolution.\n&gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; How many times has NEAT, as a monolithic approach, been cited=\r\n \n&gt; and \n&gt; &gt; &gt; &gt; successfully applied by government laboratories and Fortun=\r\ne \n&gt; 100 \n&gt; &gt; &gt; &gt; defense firms for these type of &quot;hard&quot; problems?\n&gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; \n&gt; &gt; &gt; You can refer to the paper on high-energy physics at FermiLab=\r\n if\n&gt; &gt; &gt; you&#39;re interested, but I still think there is a bigger \npicture. =\r\n \n&gt; &gt; &gt; \n&gt; &gt; &gt; In some ways, as researchers in AI, what practitioners are \n=\r\nusing \n&gt; to\n&gt; &gt; &gt; solve hard problems is exactly what we *don&#39;t* want to us=\r\ne.  \n&gt; After\n&gt; &gt; &gt; all, how is anything ever going to become more powerful =\r\nif we \n&gt; just\n&gt; &gt; &gt; look to practitioners to show us what methods we should=\r\n be \n&gt; using?  \n&gt; &gt; As\n&gt; &gt; &gt; researchers, it is our job to give the practit=\r\nioners *new* \n&gt; options,\n&gt; &gt; &gt; not the other way around.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Pract=\r\nitioners are often several steps behind algorithm \n&gt; developers, \n&gt; &gt; and\n&gt;=\r\n &gt; &gt; with good reason.  They often can&#39;t afford to take big risks \nand \n&gt; &gt;=\r\n need\n&gt; &gt; &gt; something practical in the here and now.   You will therefore \n=\r\n&gt; find\n&gt; &gt; &gt; that most cutting-edge algorithms are not in use in industry o=\r\nr \n&gt; as\n&gt; &gt; &gt; tools in other scientific disciplines at the very moment that=\r\n \n&gt; they \n&gt; &gt; are\n&gt; &gt; &gt; cutting-edge.  Yet someone has to be developing the=\r\n algorithms \n&gt; of \n&gt; &gt; the\n&gt; &gt; &gt; future.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}