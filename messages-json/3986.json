{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"zhGFER7Vq9rX1CvLTSnll8AgbQKcgpxldtYF_gL0Fq_x702hVsSfzj8gDbocmrBkrKGAobM-aayvETPl4eLHEtkct7vXkoMGmdNfF5pMm2ft","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Another New Paper:  Multiagent HyperNEAT","postDate":"1209066623","msgId":3986,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ1cW85ditxc205QGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM0MzY0NDI3LjIyNjg1JWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":3984,"nextInTopic":3987,"prevInTime":3985,"nextInTime":3987,"topicId":3955,"numMessagesInTopic":49,"msgSnippet":"Jeff, perhaps the issue is partly a matter of degree: I agree that we want the algorithm to discover on its own the regularities in the geometry (and HyperNEAT","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 34623 invoked from network); 24 Apr 2008 19:50:23 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m36.grp.scd.yahoo.com with QMQP; 24 Apr 2008 19:50:23 -0000\r\nX-Received: from unknown (HELO n42c.bullet.mail.sp1.yahoo.com) (66.163.168.176)\n  by mta16.grp.scd.yahoo.com with SMTP; 24 Apr 2008 19:50:23 -0000\r\nX-Received: from [216.252.122.216] by n42.bullet.mail.sp1.yahoo.com with NNFMP; 24 Apr 2008 19:50:23 -0000\r\nX-Received: from [66.218.69.6] by t1.bullet.sp1.yahoo.com with NNFMP; 24 Apr 2008 19:50:23 -0000\r\nX-Received: from [66.218.67.197] by t6.bullet.scd.yahoo.com with NNFMP; 24 Apr 2008 19:50:23 -0000\r\nDate: Thu, 24 Apr 2008 19:50:23 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fuqo9v+qsm9@...&gt;\r\nIn-Reply-To: &lt;C4364427.22685%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Another New Paper:  Multiagent HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=et9ZG0K6we0ZAEJXTzWofWkFzdkyAYFDPb7xsdnqUv6EzfFoRdQ2\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, perhaps the issue is partly a matter of degree: I agree that we\nwant =\r\nthe algorithm to discover on its own the regularities in the\ngeometry (and =\r\nHyperNEAT is designed to be able to do so), but at some\npoint, it becomes a=\r\nlmost pedantic to withhold such information when it\nis at the most very bas=\r\nic core of the problem description.  For\nexample, it does not seem rational=\r\n to me to pose a multiagent problem\nto a learning algorithm and ask that th=\r\ne learner *figure out* that the\nproblem is multiagent.  In effect, that is =\r\nhow I would interpret\nstarting HyperNEAT without the r(x) repeating frame. =\r\n \n\nIt&#39;s like saying, first you have to discover what kind of problem this\ni=\r\ns, then you can go on and figure out how to solve it.  Or, it is like\ngivin=\r\ng a person a keyboard to control of a fleet of ships, but not\ntelling them =\r\nthat in fact different keys on the keyboard are assigned\nto different ships=\r\n, or even that that there is more than one ship in\nthe first place! (All th=\r\ne person finds out is who gets killed in the\nend and how badly.)  I&#39;m not s=\r\nure even a great general intelligence\nshould be expected to solve such an u=\r\nnreasonable problem in any nice\namount of time?\n\nI do see that you can alwa=\r\nys argue that we should want our algorithm\nto be able to do everything, inc=\r\nluding that.  I think that&#39;s actually\na more interesting subject, because i=\r\nt&#39;s about the grand goals of AI:\nAre we trying to create a general intellig=\r\nence that precludes us from\nneeding to provide any prior information?   \n\nA=\r\nnd I think the answer is yes.  So I agree with you.  So then, you\nask, how =\r\ncan I believe that and then be advocating systems where we\nprovide prior in=\r\nformation?\n\nThe answer to that is question is that I think you are seeing p=\r\nrogress\nmoving in a different order than I see it moving.  I believe that t=\r\nhe\nmost ambitious general intelligence is far far away, and is basically\nso=\r\nmething like human intelligence: Not the kind of thing you just get\nby impr=\r\noving your encoding or diversity.  It&#39;s more like an\nastronomical paradigm =\r\nshift from what we have now.\n\nYet I am still genuinely trying to make steps=\r\n down that road.  And I\nbelieve it will only be possible to create that gen=\r\neral intelligence\nwith an algorithm that *itself* can leverage every bit of=\r\n prior\ninformation that could possibly be useful.  In other words, I am\nwor=\r\nking with my students on the algorithm that will create the AI\nsomeday.  In=\r\n contrast, you are seeing our algorithm as a candidate for\nthat AI itself. =\r\n That is, HyperNEAT is not an embryonic form of\ngeneral AI; rather, it is a=\r\nn embryonic form of an algorithm that will\neventually generate a general AI=\r\n.\n\nFor example, if I could create a world champion Go player, it would\nnot =\r\nmatter how much information I stuffed in at the start.  The point\nof the ex=\r\nercise would be to achieve my ultimate goal, not to satisfy a\nparticular pe=\r\ndagogical criterion for purist learning.  In the same way\n, if I can create=\r\n a human-level intelligence (which itself is a\ngeneral learner), it does no=\r\nt matter either whether I stuff in some\nregularities from the start or not.=\r\n  The more I give myself the\ncapability to do that, the better.  Does anyon=\r\ne really believe that\ngeneral AI can be most effectively evolved by *limiti=\r\nng* the amount of\nprior information?\n\nSo the ability to provide a priori co=\r\nntext is in my view directly on\nthe track to the ultimate goal.  In fact, I=\r\n believe the universe\nprovides this type of information implicitly, which i=\r\ns one reason\nevolution did succeed as it did.  For example, the brain *does=\r\n* exist\nin physical geometry that is the same geometry as that which is\nout=\r\nside the brain, which thereby provided a strong bias to the kinds\nof struct=\r\nures it contains being correlated to the real world.  In this\nway, the univ=\r\nerse is not without its biases, and we hardly fault it\nfor cheating to reac=\r\nh its grandest achievements.\n\nIn any case, on the road the general AI, any =\r\nshortcut is fair game. \nThe goal should be to find ways to provide all kind=\r\ns of dramatic\nshortcuts, not to weed them out.\n\nken\n\n\n--- In neat@yahoogrou=\r\nps.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; &gt; Perhaps one way to explain why=\r\n we thought about that first is to\n&gt; &gt; consider that one important philosop=\r\nhical motivation behind HyperNEAT\n&gt; &gt; is that machine learning needs a way =\r\nfor humans to convey to the\n&gt; &gt; learner a priori known domain geometry.  In=\r\n effect, we are running\n&gt; &gt; away from the black box of No Free Lunch (which=\r\n is a nasty trap) by\n&gt; &gt; finding new ways to convey critical a priori domai=\r\nn information.\n&gt; &gt; While arguments can be made that because certain techniq=\r\nues align with\n&gt; &gt; certain problem classes we should not pay too much heed =\r\nto NFL, why\n&gt; &gt; would we purposefully move *towards* the black box when we =\r\ndon&#39;t have\n&gt; &gt; to?  The real excitement, I think, is to find very general t=\r\nechniques\n&gt; &gt; for conveying to the learner standard kinds of a priori pract=\r\nical\n&gt; &gt; information (or bias), e.g. geometry.\n&gt; \n&gt; Hi Ken. I think it is i=\r\nndeed cool that you demonstrate an easy way\nto inject\n&gt; user knowledge in a=\r\n way that appropriately biases the algorithm toward\n&gt; better solutions. How=\r\never, in my opinion, the reason we are\ninterested in\n&gt; machine learning is =\r\nbecause it can solve the problems we *don&#39;t*\nknow how to\n&gt; solve. The reaso=\r\nn we use simple toy problems is because we know what the\n&gt; expected solutio=\r\nns should look like, and we want to demonstrate that our\n&gt; algorithms can f=\r\nind them. That gives us some confidence that, when\nwe start\n&gt; showing our a=\r\nlgorithms problems where we don&#39;t know what the solutions\n&gt; should look lik=\r\ne, they will discover good solutions to these problems.\n&gt; Specifically, wit=\r\nh regards to generative encodings, one touted\nbenefit is\n&gt; their ability to=\r\n exploit regularities that exist in the problem\ndomain. It\n&gt; is the hope th=\r\nat on complex domains there will be many such regularities\n&gt; that can be ex=\r\nploited. It is implied that humans will not always\nknow what\n&gt; those regula=\r\nrities are. Even if we did, it would be nice if we did\nnot have\n&gt; to tell t=\r\nhe algorithm about each type of regularity. The hope is that\n&gt; generative e=\r\nncodings can discover them and exploit them without our\naid. So,\n&gt; while it=\r\n is nice to be able to inject knowledge, it is also important to\n&gt; devise a=\r\nlgorithms that don&#39;t require such knowledge. Clearly the logical\n&gt; extremes=\r\n of either position are untenable: it is uninteresting to\ntell the\n&gt; networ=\r\nk how to do everything but one trivial thing and have it learn\nthat,\n&gt; and =\r\nNFL tells us we can&#39;t have it be a jack of all trades. But I\nthink there\n&gt; =\r\nare reasons to explore the intermediate ranges of both positions.\n&gt; \n&gt; &gt; Th=\r\nat said, if you really did start without the repeating coordinate\n&gt; &gt; frame=\r\ns, I am guessing it would perform worse as you predict, though I\n&gt; &gt; don&#39;t =\r\nknow by how much.  It is probably worth doing just to see what\n&gt; &gt; happens.=\r\n  Yet my personal view is that there would not be a very deep\n&gt; &gt; insight t=\r\no gain from such a result.  After all, why would we expect it\n&gt; &gt; to consis=\r\ntently discover the right regularity simply by chance every\n&gt; &gt; time?  Reme=\r\nmber that early in evolution, simply discovering this\n&gt; &gt; regularity may no=\r\nt even be rewarded; just because it somehow gets\n&gt; &gt; lucky and figures out =\r\nexactly the right repeating frame of reference,\n&gt; &gt; that does not necessari=\r\nly mean that within those coordinate frames it\n&gt; &gt; is doing anything useful=\r\n (i.e. it could be a repetition of a bad\n&gt; &gt; policy), so the discovery is l=\r\nikely to go unnoticed and die out, just\n&gt; &gt; as easily as it might be levera=\r\nged and elaborated properly.\n&gt; \n&gt; I agree that this is a challenging proble=\r\nm, but I think that it is very\n&gt; important for us to figure out algorithms =\r\nthat can cope with it. Clearly\n&gt; nature figured out ways to deal with this =\r\nissue. How can we set up\n&gt; algorithms such that if the population early on =\r\ndiscovers a bauplan that\n&gt; keeps it trapped on a local peak, it can eventua=\r\nlly discover a\nbauplan that\n&gt; gives it access to a higher peak?  To me this=\r\n is a fundamental issue\nfor our\n&gt; field. If we cannot improve upon it, we w=\r\nill be stuck evolving\nrelatively\n&gt; trivial solutions and never evolve thing=\r\ns as impressive as jaguars\nor poets.\n&gt; I am surprised you don&#39;t think resea=\r\nrch on this front is important\nor would\n&gt; provide deep insights. Or, is it =\r\nthat you think we can&#39;t make\nprogress here,\n&gt; so documenting a further fail=\r\nure isn&#39;t deep?\n&gt; &gt; \n&gt; &gt; This problem is related to that discussion we had =\r\na while back about\n&gt; &gt; &quot;target-based evolution&quot; and the phenomena of Picbre=\r\neder.  Often the\n&gt; &gt; stepping stones (such as discovering the right basic r=\r\negularity) are\n&gt; &gt; not recognized by the ultimate objective function, so it=\r\n&#39;s pretty much\n&gt; &gt; up to luck to find them and keep them around long enough=\r\n to take\n&gt; &gt; advantage of them.  My feeling is that it is not fruitful for =\r\nany\n&gt; &gt; indirect encoding to try to solve that problem, because it is not a=\r\n\n&gt; &gt; problem with the encoding per say but rather with the way fitness is\n&gt;=\r\n &gt; assigned.\n&gt; \n&gt; Fitness is one part of the mix. But there are also issues=\r\n of population\n&gt; diversity, representation flexibility and evolvability, et=\r\nc. Any of\nthese\n&gt; could assist in allowing deep switches in bauplan.\n&gt;  \n&gt; =\r\nI&#39;d like to say one last thing. One of the great innovations of\nHyperNEAT\n&gt;=\r\n was that you provided the geometry of the problem such that the\nalgorithm\n=\r\n&gt; could exploit it. That strikes me as a bit different than telling the\n&gt; a=\r\nlgorithm *how* to go about exploiting that geometry. I think that\n&gt; distinc=\r\ntion is important, and might be being conflated a bit here. I\nagree\n&gt; unequ=\r\nivocally that providing access to the geometry is important, but it\n&gt; seems=\r\n to me that it is an interesting field of research to figure\nout how to\n&gt; c=\r\nreate algorithms that learn how to exploit that geometry, and its\n&gt; regular=\r\nities, on their own.\n&gt; \n&gt; \n&gt; Cheers,\n&gt; Jeff Clune\n&gt; \n&gt; Digital Evolution La=\r\nb, Michigan State University\n&gt; \n&gt; jclune@...\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; &gt; \n&gt; &gt; --- In ne=\r\nat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt;&gt; \n&gt; &gt;&gt; Hello-\n&gt; &gt;&gt; \n&gt; &gt;=\r\n&gt; I enjoyed reading this. Thanks for posting it.\n&gt; &gt;&gt; \n&gt; &gt;&gt; A question: how=\r\n did HyperNEAT perform when you did not provide it\n&gt; &gt; with the\n&gt; &gt;&gt; repeat=\r\ning coordinate frame for each agent? As you mention in the\n&gt; &gt; paper, this\n=\r\n&gt; &gt;&gt; is something that HyperNEAT could learn on its own. I assume from\n&gt; &gt; =\r\nthe fact\n&gt; &gt;&gt; that you added it that HyperNEAT was not doing a good job of\n=\r\n&gt; &gt; learning this.\n&gt; &gt;&gt; \n&gt; &gt;&gt; If that assumption is right, how bad was it a=\r\nt learning this problem\n&gt; &gt;&gt; decomposition? One of the touted benefits of H=\r\nyperNEAT, and\ngenerative\n&gt; &gt;&gt; encodings in general, is the ability to evolv=\r\ne a module and reuse it\n&gt; &gt; many\n&gt; &gt;&gt; times (potentially with variation).  =\r\nHere the modularity of the\n&gt; &gt; problem was\n&gt; &gt;&gt; cleanly divided, and should=\r\n have been relatively easy for\nHyperNEAT to\n&gt; &gt;&gt; discover. Do you find it d=\r\nisconcerting that it couldn&#39;t do so?\n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; Cheers,\n&gt; &gt;&gt; Je=\r\nff Clune\n&gt; &gt;&gt; \n&gt; &gt;&gt; Digital Evolution Lab, Michigan State University\n&gt; &gt;&gt; \n=\r\n&gt; &gt;&gt; jclune@\n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt;&gt; From: Kenneth Stanley &lt;kstanley@=\r\n&gt;\n&gt; &gt;&gt;&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt;&gt;&gt; Date:=\r\n Wed, 16 Apr 2008 22:48:44 -0000\n&gt; &gt;&gt;&gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yah=\r\noogroups.com&gt;\n&gt; &gt;&gt;&gt; Subject: [neat] Another New Paper:  Multiagent HyperNEA=\r\nT\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; David D&#39;Ambrosio and I discuss the potential for HyperNEAT\n&gt;=\r\n &gt;&gt;&gt; controlling multiple heterogeneous agents in this new\n&gt; &gt;&gt;&gt; paper, &quot;Ge=\r\nnerative Encoding for Multiagent Learning,&quot; to appear at\n&gt; &gt;&gt;&gt; GECCO 2008:\n=\r\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; http://eplex.cs.ucf.edu/index.php?\n&gt; &gt;&gt;&gt; option=3Dcom_content&=\r\ntask=3Dview&id=3D14&Itemid=3D28#dambrosio.gecco08\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; Direct Link:=\r\n\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; http://eplex.cs.ucf.edu/papers/dambrosio_gecco08.pdf\n&gt; &gt;&gt;&gt; \n&gt;=\r\n &gt;&gt;&gt; We also have a nice sample of videos that depict various evolved\n&gt; &gt;&gt;&gt;=\r\n teams in action:\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; http://eplex.cs.ucf.edu/multiagenthyperneat\n=\r\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; The interesting idea in this paper is that just as a single\n&gt; =\r\n&gt;&gt;&gt; connective CPPN can encode how a single network varies over space,\n&gt; &gt;&gt;=\r\n&gt; it can also encode how a *set* of networks (each representing the\n&gt; &gt;&gt;&gt; p=\r\nolicy of one agent on the team) varies over space.  In this way,\n&gt; &gt;&gt;&gt; Hype=\r\nrNEAT can learn an expression that encodes how policies vary\n&gt; &gt;&gt;&gt; over the=\r\n team geometry.  For example, in a soccer team agents vary\n&gt; &gt;&gt;&gt; from defen=\r\nsive to offensive as you move away from the goal.  Part of\n&gt; &gt;&gt;&gt; the power =\r\nof this approach is that it means basic skills can be\n&gt; &gt;&gt;&gt; learned and sha=\r\nred among the whole team, since the CPPN encodes how\n&gt; &gt;&gt;&gt; those skills var=\r\ny across the field.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; ken\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}