{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":403065338,"authorName":"stephane.doncieux","from":"&quot;stephane.doncieux&quot; &lt;stephane.doncieux@...&gt;","profile":"stephane.doncieux","replyTo":"LIST","senderId":"ouoShIlhiPagLzu4UukhoJXBs3M8oBbx8-jwd_kc6__huoineRXPVgyShtetckrhdXY-Vq2txDJznO1h3ZZH_VAkwg_y43451jGIOJUS4lt1pb-5EVkkwA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: New paper on why modules evolve, and how to evolve modular artif","postDate":"1362577092","msgId":6016,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtoN2dzNCtuYmxiQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtndTE5MStzdDJpQGVHcm91cHMuY29tPg=="},"prevInTopic":6015,"nextInTopic":6017,"prevInTime":6015,"nextInTime":6017,"topicId":6011,"numMessagesInTopic":10,"msgSnippet":"Hi Ken, We are getting closer to the point. I think one ambiguity comes with the expectations of models like that of Jean-Baptiste, Jeff and Hod. I agree that","rawEmail":"Return-Path: &lt;stephane.doncieux@...&gt;\r\nX-Sender: stephane.doncieux@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 69364 invoked from network); 6 Mar 2013 13:38:13 -0000\r\nX-Received: from unknown (10.193.84.135)\n  by m8.grp.bf1.yahoo.com with QMQP; 6 Mar 2013 13:38:13 -0000\r\nX-Received: from unknown (HELO ng7-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.48)\n  by mta1.grp.bf1.yahoo.com with SMTP; 6 Mar 2013 13:38:13 -0000\r\nX-Received: from [98.139.164.123] by ng7.bullet.mail.bf1.yahoo.com with NNFMP; 06 Mar 2013 13:38:13 -0000\r\nX-Received: from [10.193.94.45] by tg4.bullet.mail.bf1.yahoo.com with NNFMP; 06 Mar 2013 13:38:13 -0000\r\nDate: Wed, 06 Mar 2013 13:38:12 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kh7gs4+nblb@...&gt;\r\nIn-Reply-To: &lt;kgu191+st2i@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;stephane.doncieux&quot; &lt;stephane.doncieux@...&gt;\r\nSubject: Re: New paper on why modules evolve, and how to evolve modular artif\r\nX-Yahoo-Group-Post: member; u=403065338; y=tIFxqCYjCvhHRUHGFCquK0wapk-V62m2Z6wNvuul_40Sv0DnW61aXhDl_4k\r\nX-Yahoo-Profile: stephane.doncieux\r\n\r\nHi Ken,\n\nWe are getting closer to the point.\n\nI think one ambiguity comes w=\r\nith the expectations of models like that of Jean-Baptiste, Jeff and Hod. I =\r\nagree that it does not answer the whole question of open-ended evolution (e=\r\nven with regards to modularity), but I don&#39;t think it was their intention (=\r\nI haven&#39;t seen such claims in the paper). I don&#39;t believe in a global model=\r\n that would take into account every single aspect of natural evolution, at =\r\nleast not until every piece of the puzzle has been well understood. This is=\r\n the classical reductionnist approach to try to separate each aspect. It is=\r\n clearly not easy to apply such a methodology for these questions as many d=\r\nifferent aspects are dependent one from the other. It anyway remains a clas=\r\nsical and efficient approach in Science. Succeeding in isolating a single e=\r\nffect is, for me, a major breakthrough because of the difficulty to do it. =\r\nIt should actually be what we are looking for, because the contribution is =\r\nthen highly localized and it makes it easier to build upon it and this is r=\r\neally what I like in Jeff, JB and Hod work.\n\nThe question of knowing to wha=\r\nt extent multi-objective evolutionary algorithms are a good model of natura=\r\nl (i.e. open-ended) evolution is not critical in the work we are talking ab=\r\nout. MOEA have interesting features, but also drawbacks, as you have mentio=\r\nnned, Ken. Jeff, JB and Hod have proposed a mechanism to adress these limit=\r\nations with their stochastic domination and I think it is enough to address=\r\n their problem. The results of the article should not be overestimated as w=\r\nell as it should not be underestimated. What it shows is that a pressure to=\r\nwards a low connectivity (i.e. a goal independent selection pressure) has t=\r\nhe nice side effect of creating more modular structures. This is an interes=\r\nting and valuable result. How to use such pressures in an open-ended perspe=\r\nctive is another (and in my opinion different and also interesting) questio=\r\nn. I completely agree with you Ken when you say that this question is not p=\r\nroperly adressed by the model, but once more I am not sure that it is their=\r\n point. \n\nI agree with your point Ken that a constant fitness pressure that=\r\n remains the same all over the course of evolution is very unlikely to lead=\r\n to a truly open-ended evolution. By the way, it seems to me that you sugge=\r\nst to discard all fitness pressures (i.e. all goal-oriented objectives, may=\r\n it be constant or not). It is in line with novelty search, but I don&#39;t thi=\r\nnk that it is a good idea. You will have solved one part of the problem, bu=\r\nt also introduced other limitations. One of them is related to the size of =\r\nthe search space. If your behavior space is large enough, you will just beg=\r\nin to do something interesting and switch to something else without trying =\r\nto push what you have discovered to its limits. \n\nLots of biologists actual=\r\nly think in terms of fitness pressures and try to find what fitness pressur=\r\ne has favored a given transition (apparition of an organ, of a particular b=\r\none, etc). Lots of those pressures have been proposed in the litterature to=\r\n explain the evolution of birds wings, legs etc. Does it mean that such pre=\r\nssures were the same during all evolution ? Of course not. It does not mean=\r\n either that it hasn&#39;t played a critical role at some time along evolution.=\r\n Thinking in terms of fitness pressures is no more than a convenient way to=\r\n model what happens in evolution at a relatively local scale. You are true =\r\nKen to say that most of our work remains local. If I were to study open-end=\r\ned evolution, I would try to study under what conditions these fitness pres=\r\nsures changes do occur and I would propose algorithms to reproduce it. In t=\r\nhis perspective, any meaningful fitness pressure is interesting and is a po=\r\ntentially significant piece of the puzzle. From your point of view, I guess=\r\n that your research program is different. Which one will lead to a better u=\r\nnderstanding of natural evolution is a question that we cannot decide now. =\r\nInterestingly your work on novelty search with local competion is actually =\r\na nice way to combine both aspects.\n\nBy the way, I really think that it is =\r\nuseless to work on the encoding without also studying selection pressures t=\r\nhat would take the best of it (may they be constant or not, goal-oriented o=\r\nr goal-independent). So that is why I disagree with the dichotomy you make =\r\nbetween encoding and fitness pressures. Anyway considering all the work you=\r\n have made in the field on both aspects, I guess that it is more a question=\r\n of terminology than a deep disagreement.\n\nBest,\n\nstef\n\n--- In neat@yahoogr=\r\noups.com, &quot;Ken&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; \n&gt; \n&gt; Hi Jeff, Stef, and Martin, =\r\nI hope you don&#39;t mind since all of you addressed me if I try to reply to al=\r\nl of you at once to keep the thread (and my brain) from branching in three =\r\ndirections.  Many of your points follow a similar theme so I think it makes=\r\n sense to respond collectively.  This response is practically an article, b=\r\nut oh well, it&#39;s nice to get the ideas down even if it&#39;s a bit too long (it=\r\n just shows you are asking me great questions that are challenging).\n&gt; \n&gt; M=\r\nartin offers a good unifying question: &quot;My question to Ken would be here: w=\r\nhat is the additional ingredient that makes a\n&gt; bias in the encoding better=\r\n / more plausible than *any* implementation of the bias in the fitness func=\r\ntion?&quot;\n&gt; \n&gt; After some thought, I believe one of the difficulties in this d=\r\niscussion is that we often conflate artificial EC-style fitness-based exper=\r\niments with open-ended scenarios when these are entirely different situatio=\r\nns (I take blame myself as well for this tendency).  That is, when we talk =\r\nabout something being &quot;better&quot; or &quot;solving&quot; a problem, we are often talking=\r\n about artificial and unnatural experimental setups that have little relati=\r\nonship to open-ended evolutionary scenarios like nature.  \n&gt; \n&gt; Why does th=\r\nat matter?  It matters because in discussions that try to dovetail engineer=\r\ning-oriented mechanisms (like a connectivity penalty) with explanations of =\r\nwhat happened in nature (such as the emergence of modular connectivity), it=\r\n cannot simply be ignored that nature in fact is first and foremost an open=\r\n-ended evolutionary system, and that that open-ended dynamic is a significa=\r\nnt factor in the explanation of its products.   What that means to me is th=\r\nat if you think your proposed mechanism actually *explains* something that =\r\nhappened in nature, then it is essential that the explanation speaks to the=\r\n question of how the particular mechanism you are advancing combined histor=\r\nically with the open-ended evolutionary dynamics in nature to produce the r=\r\nesult you expect.\n&gt; \n&gt; But because we conflate very closed-ended artificial=\r\n scenarios with monumentally open-ended searches like nature, it leads to a=\r\n lot of dangerous inferences.   So ideas that would make sense in one conte=\r\nxt end up sounding reasonable when they don&#39;t really make any sense in the =\r\nother context.  The difficulty of squaring fitness-pressure objectives with=\r\n nature is more serious when you consider it in this perspective.  (Note th=\r\nat I am defining &quot;fitness pressure&quot; as selection based on relative performa=\r\nnce to other organisms on a measure of some property that varies over a ran=\r\nge of possible values, such as degree of connectivity.)\n&gt; \n&gt; The problem is=\r\n that fitness pressures that preserve a degenerate niche for eternity are d=\r\nefinitively not like nature, so whether they work or not, or whether I am s=\r\nomehow indicting them or not, should not be the issue.  The issue should be=\r\n that we should be worried that nature does not use a mechanism even remote=\r\nly like that yet still achieves the &quot;same&quot; result (i.e. beautiful variation=\r\ns of pseudo-modular design).  If you are advancing the hypothesis that this=\r\n kind of constant &quot;pressure&quot; is somehow essential to the emergence of modul=\r\narity in nature, then you must somehow explain why you needed to use a setu=\r\np with these bizarre and unnatural side effects (like eternal degenerate ni=\r\nches) instead of whatever nature actually supposedly does use.\n&gt; \n&gt; And the=\r\n fact that you cannot come up with anything similar to what nature does, i.=\r\ne. something that does not involve creating such a deadweight pocket, reaso=\r\nnably may suggest that your hypothesis about nature could be wrong.  That i=\r\ns, it may not be this endless &quot;fitness pressure&quot; after all that explains wh=\r\nat is happening there, because fitness pressure in general in EC is almost =\r\nalways creating some kind of unintended deadweight niche.\n&gt; \n&gt; I think it i=\r\ns particularly fascinating that in fact nature obtains not really the same =\r\nresult, but a far more awesome result (in terms of modularity or anything e=\r\nlse), without such an ad hoc mechanism. \n&gt; If you think about it, as long a=\r\ns you insist on cheering for fitness pressure, it prevents you from asking =\r\nhow this could be - how is it possible that you can get these kinds of resu=\r\nlts without such an unnatural side effect?\n&gt; \n&gt; I need to emphasize here th=\r\ne difference between being a better engineering mechanism and a better expl=\r\nanation.  I am focusing now primarily on the explanatory power of the propo=\r\nsed mechanism.  But because nature is so much more accomplished than anythi=\r\nng artificial, the explanatory gap here implies a dangerous potential to ov=\r\nerlook what will ultimately amount also to a major engineering gap as well.=\r\n  There is no evidence that anything except nature in its open-ended way ca=\r\nn create anything like the connectivity of natural brains.\n&gt; \n&gt; Furthermore=\r\n, it is always important to acknowledge nuance and subtlety in nature, whic=\r\nh has not really been acknowledged yet in this conversation.  Nature is alm=\r\nost never all one way.  So it is misleading and potentially confusing to ta=\r\nlk about brains as simply modular or not.  The recent discussion on the Con=\r\nnectionists list, where scientists have been giving all kinds of subtle and=\r\n conflicting perspectives on modularity in natural brains in response to Je=\r\nff and JBM&#39;s article,  echoes this nuance.   The beauty of the human brain =\r\nto me is not that it is modular, but that it is modular to an extent, but n=\r\not entirely so, and what modularity there is is hard to pin down.  This kin=\r\nd of nuance is not to me a mere footnote to the achievement of nature, but =\r\nthe central point of it:  what nature achieves in spades is nuance. \n&gt; \n&gt; A=\r\nnd the idea of a constant pressure of any kind is directly in conflict with=\r\n the achievement of nuance, because nuance is a delicate balancing act that=\r\n is easily tipped off its perch if constant pressure in *any* direction is =\r\napplied without relief.  Jeff is concerned with short-term versus long-term=\r\n issues (which isn&#39;t really as clearly defined in an open-ended context), b=\r\nut even if we honor that concern, it is potentially na=EFve to believe that=\r\n pressure in either direction from the start, or even an encoding bias in e=\r\nither direction from the start, is somehow going to directly align with the=\r\n level of nuance observed millions of years in the future.  However, while =\r\nfitness pressure is eternal, encoding bias is malleable, so pushing in the =\r\n&quot;right&quot; direction from the start is not essential for encoding.  It&#39;s more =\r\nlike a hint to get you started, whereas fitness pressure is more like a gun=\r\n forever pointed at your back.\n&gt; \n&gt; For example, who is to say that we shou=\r\nld not have the opposite short-term worry as Jeff does =96 he worries that =\r\nan encoding bias towards low connectivity &quot;might evolve away because of fit=\r\nness pressure,&quot; but can&#39;t we just as easily worry about *too much* modulari=\r\nty?  In that case, Jeff&#39;s evil twin &quot;opposite-Jeff&quot; might be worried that a=\r\nn initial encoding bias towards *high* connectivity might evolve away.  It =\r\nis not clear nor established fact (see Connectionists) that the exact form =\r\nof the final &quot;solution&quot; is particularly modular or non-modular.  What it is=\r\n, is subtle and somewhere in the middle.  So none of this kind of panicking=\r\n about what nature &quot;needs&quot; to harass it into such an astronomically complex=\r\n future configuration makes much sense.  We cannot say definitively the ext=\r\nent to which the final structure is &quot;closer&quot; to modular or non-modular, wha=\r\ntever that even means.  Fortunately, an encoding that begins with a bias to=\r\nwards modularity can tone it down as needed, or ramp it up even more.\n&gt; \n&gt; =\r\nYet Jeff also worries about about the radiation of evolutionary lineages be=\r\ning blocked because of implicit penalties: He says, &quot;You assume that evolut=\r\nion will branch out and explore all these options even in the face of fitne=\r\nss penalties for that exploration. But that is not how evolution works.&quot;\n&gt; =\r\n\n&gt; But branching out and exploring many (not necessarily all of course) of =\r\nthe options is the only way that natural evolution works.  That&#39;s what open=\r\n-endedness is (unless you don&#39;t believe natural evolution to be open-ended)=\r\n.  The tree of life is ever-branching.  The worry about &quot;fitness penalties&quot;=\r\n here is a red herring because it originates from closed-ended artificial E=\r\nC experiments where you can end up on the wrong path.  But nature does not =\r\nhave any single &quot;fitness penalty&quot; or &quot;right path&quot; throughout its run becaus=\r\ne the landscape is always changing as it branches and branches.  For exampl=\r\ne, before trees, being an extremely tall herbivore would incur a fitness pe=\r\nnalty, but after trees giraffes were perfectly viable.  The penalty is not =\r\nconsistent.\n&gt; \n&gt; More generally, how can there be what you call a &quot;default =\r\nfitness penalty&quot; if there is no final goal?  Penalty with respect to what? =\r\n Keep in mind here that the origin of pseudo-modular organization in nature=\r\n likely predates the emergence even of neurons.  The first neural structure=\r\ns piggy-backed on previously evolved organizational structure that likely i=\r\nnfluenced the subtle pseudo-modularity of connectivity from the start for r=\r\neasons entirely unrelated to connection cost because these organizational c=\r\nonventions evolved long before neurons even existed:  the bias in the encod=\r\ning was in part already there.\n&gt; \n&gt; Which brings me back to the origin of a=\r\nll such conventions - canalization - which is the key here.   Stephane talk=\r\ns about a bias that exists &quot;all along&quot; in evolution, but ultimately the abi=\r\nlity to *change* bias eclipses choosing one up front.  Again, in the contex=\r\nt of artificial scenarios, it&#39;s a good engineering hack to force in some ki=\r\nnd of bias into the encoding or into fitness that you expect to control thi=\r\nngs for a moderate number of generations.  But in nature the scope is so va=\r\nst that it can&#39;t be the final word; it&#39;s only the initial hint.  While that=\r\n hint can help, nature in the long term needs to choose and commit to its o=\r\nwn biases, and to slither out of them from time to time, and only encoding =\r\noffers that potential.  Canalization is the way nature can make long-term (=\r\nthough not necessarily permanent) commitments.  It&#39;s how conventions are es=\r\ntablished in specific lineages.\n&gt; \n&gt; In a genuine open-ended scenario like =\r\nnature, modularity will emerge and proliferate over vast stretches of time =\r\nonly if modularity leads to more species emerging.  Of course, the species =\r\nwe observe at the end are the consequence of organizational principles that=\r\n supported generating many species (which is almost tautological).   So it =\r\nneed not relate to being better or worse, or &quot;solving&quot; anything.  It has to=\r\n do with open-ended dynamics.  Air will escape a hole in a balloon if you w=\r\nait long enough.  If that hole leads to a whole other world, you will event=\r\nually see that other world.  Modularity, to the extent it actually exists i=\r\nn nature, has served as such a hole.  But the only way such a hole can be e=\r\nxploited, the only way you can keep focused on that area, is if it can be c=\r\nanalized.  An encoding that can be canalized allows you to maintain the sub=\r\ntle convention that is responsible for spreading diversity.   \n&gt; \n&gt; Stef ne=\r\nvertheless reminds me that &quot;selection pressure has strong impact,&quot; and I en=\r\ntirely agree of course.  But there are two very different classes of select=\r\nion pressure.  One is about pushing you towards the new, and the other is a=\r\nbout forcing you to commit to the old.  There are many ways to push towards=\r\n the new, and novelty search is just one.  In contrast, these things we cal=\r\nl &quot;fitness pressures&quot; (whether part of a MOEA or not) are the opposite =96 =\r\nthey are toxic strait jackets applied for eternity.  They presume that we k=\r\nnow what we need with no nuance whatsoever eons before anything remotely re=\r\nlated has appeared.   Again, in engineering, fair enough =96 it can work.  =\r\nBut it is not an *explanation* of the products of open-ended evolution in n=\r\nature, and likely is not a good way to produce open-endedness artificially =\r\neither.  \n&gt; \n&gt; So the only escape I see here from my argument is if you can=\r\n argue somehow that you can do all these amazing things *without* open-ende=\r\nd evolution.  Then all your pressures and constraints might make sense.  Bu=\r\nt I don&#39;t think you can argue that, which, to finally circle back to Martin=\r\n&#39;s broad question, is why encoding is ultimately superior.  A canalizeable =\r\nencoding is the perfect partner for an open-ended process.  But it is not (=\r\nas Martin puts it) because it makes a particular &quot;bias in the encoding bett=\r\ner.&quot;  Rather, it is because encoding lets evolution delicately modify its o=\r\nwn biases on the fly and explore all of them in parallel.  That is, the abi=\r\nlity to change, the ability to flexible, to commit but to uncommit in incre=\r\nments of subtlety, to radiate diversity while still committing to certain b=\r\niases in certain chains, is the power that made everything happen.  Any for=\r\nced competition, any constant bias, any eternal relative judgment, which ar=\r\ne all things that constant fitness pressure offers, will diminish that flex=\r\nibility.  It will not necessarily destroy the open-ended process, but it wi=\r\nll reduce its power and ultimately therefore cannot explain or account for =\r\nit.\n&gt; \n&gt; \n&gt; Best,\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;martin_pyk=\r\na&quot; &lt;martin.pyka@&gt; wrote:\n&gt; &gt;\n&gt; &gt; I just would like to point out that, in my=\r\n opinion, part of the disagreement between you and Jeff and Ken comes from =\r\nthe fact that Ken somehow made the statement &quot;it is better to implement the=\r\n bias in the encoding than in the fitness function&quot; but in actual fact argu=\r\nes for a specific type of implementation in the encoding.\n&gt; &gt; \n&gt; &gt; Thus, I =\r\nthing the discussion should not center around the general question whether =\r\na bias should be incorporated in the fitness or in the encoding because in =\r\nboth areas there are better and worse ways to do it. The question is more, =\r\nwhy a specific implementation (that Ken has obviously in mind, my impressio=\r\nn was he thought about approaches similar to LEO) is better than another.\n&gt;=\r\n &gt; \n&gt; &gt; My question to Ken would be here: what is the additional ingredient=\r\n that makes a bias in the encoding better / more plausible than *any* imple=\r\nmentation of the bias in the fitness function?\n&gt; &gt;\n&gt;\n\n\n\n"}}