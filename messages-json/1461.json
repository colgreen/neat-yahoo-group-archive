{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"_VKHDfT9HASBxAfHPlsbYlmltLGjX2V5ZUBe8YGWZMgY8_hnmdWJe83TgIcMBQMW4Fl8NTS7iwEoIohRDj2U00ekjE5zH-376p-HKSiYDSdR","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: OCR Update","postDate":"1093388689","msgId":1461,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNnZ2hpaCtvcWh2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDE5YjEwZDUxMDQwODI0MTQxMWIzYTBjNTlAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":1460,"nextInTopic":1462,"prevInTime":1460,"nextInTime":1462,"topicId":1460,"numMessagesInTopic":6,"msgSnippet":"Derek, Those are really nice initial results.  It seems like this is a promising research direction.  Some things I m wondering...How many generations does it","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 19520 invoked from network); 24 Aug 2004 23:05:00 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m25.grp.scd.yahoo.com with QMQP; 24 Aug 2004 23:05:00 -0000\r\nReceived: from unknown (HELO n35.grp.scd.yahoo.com) (66.218.66.103)\n  by mta1.grp.scd.yahoo.com with SMTP; 24 Aug 2004 23:05:00 -0000\r\nReceived: from [66.218.66.119] by n35.grp.scd.yahoo.com with NNFMP; 24 Aug 2004 23:04:50 -0000\r\nDate: Tue, 24 Aug 2004 23:04:49 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;cgghih+oqhv@...&gt;\r\nIn-Reply-To: &lt;19b10d510408241411b3a0c59@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2080\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.218.66.103\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: OCR Update\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nDerek,\n\nThose are really nice initial results.  It seems like this is a \npromising research direction.  Some things I&#39;m wondering...How many \ngenerations does it take to get the &quot;A&quot; discriminator eye?  How much \nCPU time does it require? How complex is the network?\n\nken\n\n--- In neat@yahoogroups.com, Derek James &lt;djames@g...&gt; wrote:\n&gt; I thought I&#39;d give a brief update of the stuff Philip and I are\n&gt; working on these days, in case anyone&#39;s interested.  I&#39;ve alluded \nto\n&gt; it in a couple of messages already.\n&gt; \n&gt; Basically, we&#39;re applying the active vision approach similiar to\n&gt; Darren Izzard&#39;s OCR experiments and Ken&#39;s roving eye approach to \nGo.\n&gt; \n&gt; Our active vision system includes movement along the x and y axes,\n&gt; zoom, rotation, and mirror flip capabilities.  The resolution of \nthe\n&gt; eye is parameterized.\n&gt; \n&gt; We started by simply testing whether or not our networks could\n&gt; discriminate between all-black canvasses and all-white ones.  That\n&gt; done, we moved on to basic shapes, solid black circles and solid \nblack\n&gt; squares on white backgrounds.  All images are 50x50 pixel tifs. \n&gt; Between each generation we add both positional and rotational \nvariance\n&gt; to the images, so that they are repositioned +/- 10 pixels along \nthe\n&gt; x/y axes based on randomly generated values, and are rotated about \n+/-\n&gt; 20 degrees.  With 10 circle images and 10 squares, we were able to\n&gt; evolve networks that could discriminate between the two sets with \n100%\n&gt; accuracy.\n&gt; \n&gt; Now we&#39;re working with character recognition, specifically capital\n&gt; letters in san-serif font, again on a 50x50 canvas.  I&#39;ve uploaded \nour\n&gt; base images as .jpgs in the Photos section:\n&gt; \n&gt; \nhttp://photos.groups.yahoo.com/group/neat/lst?.dir=/Derek+and+Philip%\n27s+OCR+Test+Cases&.src=gr&.order=&.view=t&.done=http%\n3a//briefcase.yahoo.com/\n&gt; \n&gt; So far we&#39;ve just worked with discriminating sets of two letters: A\n&gt; and B.  And we&#39;ve also done some experiments trying to \ndiscriminate A\n&gt; from all other letters.  So far, we&#39;ve acheived about 95% accuracy\n&gt; rates in these types of tasks.\n&gt; \n&gt; Derek\n\n\n"}}