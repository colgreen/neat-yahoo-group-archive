{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"r0gXwgyHlhUNtRUE788wRDwD8EutvSweGaaLhUH_Srm7aXXOokU3QR2PlfBS8v2E8NNdfPn2ZqYEbCwu1y8KqxNrvExInHKG4IeB2HL0DeXD","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Image Sampling for Scaling","postDate":"1095662853","msgId":1558,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNpbHVlNStwcW1zQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDE5YjEwZDUxMDQwOTE4MTAzOTM1OTM0YUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":1552,"nextInTopic":1559,"prevInTime":1557,"nextInTime":1559,"topicId":1552,"numMessagesInTopic":7,"msgSnippet":"Derek, Unfortunately I don t know the best way to sample images.  However, your project is really cutting edge and I am looking forward to hearing what you","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 72424 invoked from network); 20 Sep 2004 06:47:42 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m13.grp.scd.yahoo.com with QMQP; 20 Sep 2004 06:47:42 -0000\r\nReceived: from unknown (HELO n38.grp.scd.yahoo.com) (66.218.66.106)\n  by mta3.grp.scd.yahoo.com with SMTP; 20 Sep 2004 06:47:42 -0000\r\nReceived: from [66.218.67.250] by n38.grp.scd.yahoo.com with NNFMP; 20 Sep 2004 06:47:33 -0000\r\nDate: Mon, 20 Sep 2004 06:47:33 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;cilue5+pqms@...&gt;\r\nIn-Reply-To: &lt;19b10d51040918103935934a@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2553\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.218.66.106\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Image Sampling for Scaling\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nDerek,\n\nUnfortunately I don&#39;t know the best way to sample images.  However, \nyour project is really cutting edge and I am looking forward to \nhearing what you accomplish.  What made your decision to first \nsubmit to a journal as opposed to a conference?  I think it would \nprobably be a lot of fun to present this kind of exciting work at a \nconference where you can see people&#39;s reactions.\n\nken\n\n\n--- In neat@yahoogroups.com, Derek James &lt;djames@g...&gt; wrote:\n&gt; Hi all,\n&gt; \n&gt; We continue to work on our active vision implementation for object\n&gt; recognition.  We&#39;ve formalized some experiments and are aiming to\n&gt; write a paper for a special edition of Pattern Recogition Letters \n(the\n&gt; deadline is October 31st).\n&gt; \n&gt; But we have an issue we thought we&#39;d open to the group.  Our\n&gt; implementation has a zoom feature, and if for example the eye is \nfully\n&gt; zoomed out and centered on the canvas, there are a number of ways \nof\n&gt; sampling or filtering the image for input into the neural network.\n&gt; \n&gt; If the canvas is 100x100, for example, and the eye resolution is \n5x5,\n&gt; then if the eye is fully zoomed out and centered, there are 25 \n20x20\n&gt; regions.  So how do you get the value for each region to input into\n&gt; each visual input in your eye?\n&gt; \n&gt; Standard interpolation methods include nearest neighber, bilinear, \nand\n&gt; bicubic, which sample either a single pixel in the field, an \naverage\n&gt; of two, or an average of four, respectively.  The problem with \nthese\n&gt; approximations is, there is often loss of information.  We thought \na\n&gt; method that averaged every pixel in a given region would be best, \nbut\n&gt; it is very computationally expensive.\n&gt; \n&gt; In the Kato/Floreano paper which evolved networks to discriminate\n&gt; between triangles and squares, the network can has an output which \ncan\n&gt; choose the sampling method for each timestep.  The two sampling\n&gt; methods are: 1) take the value of the upper-leftmost pixel, 2) full\n&gt; area averaging.  Their paper reports that given the choice, the\n&gt; networks use the first, simpler form of sampling 61% of the time. \n&gt; They speculate that harsher, blockier edges are easier to discern \nthan\n&gt; fuzzy, grey ones.\n&gt; \n&gt; This seems to correlate with some of the ad hoc experiments we&#39;re\n&gt; doing.  Simpler sampling methods seem to provide better results for\n&gt; the task than area averaging.  This seems a little \ncounterintuitive,\n&gt; since the simpler method results in loss of information and worse\n&gt; distortion of the image at higher zoom factors.\n&gt; \n&gt; Anybody have any thoughts on this?\n&gt; \n&gt; Thanks,\n&gt; Derek\n\n\n"}}