{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"K8U9Vj-EUILKymB1hGpbyviC3VjrIuv7RPGhBMXyGYtS1vjItM4wzGcSs_AswSINMTQ3u7ZyAlVTmMnjnqLc2Hq8xaCBgV3G8Q","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: 378 days later...","postDate":"1142984874","msgId":2580,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0MjA5MEFBLjcwMDA2MDNAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PGR2cDV1Yit1c25lQGVHcm91cHMuY29tPg==","referencesHeader":"PGR2cDV1Yit1c25lQGVHcm91cHMuY29tPg=="},"prevInTopic":2577,"nextInTopic":2581,"prevInTime":2579,"nextInTime":2581,"topicId":2571,"numMessagesInTopic":6,"msgSnippet":"... Just had a peek at the project page and it lok spretty good, I ll make a note to maybe switch over. I purposely fixed the size of my graphs in sharpneat","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 25451 invoked from network); 21 Mar 2006 23:47:53 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m28.grp.scd.yahoo.com with QMQP; 21 Mar 2006 23:47:53 -0000\r\nReceived: from unknown (HELO ranger.systems.pipex.net) (62.241.162.32)\n  by mta10.grp.scd.yahoo.com with SMTP; 21 Mar 2006 23:47:53 -0000\r\nReceived: from [10.0.0.11] (81-86-161-87.dsl.pipex.com [81.86.161.87])\n\tby ranger.systems.pipex.net (Postfix) with ESMTP id 49F09E0004D1\n\tfor &lt;neat@yahoogroups.com&gt;; Tue, 21 Mar 2006 23:47:52 +0000 (GMT)\r\nMessage-ID: &lt;442090AA.7000603@...&gt;\r\nDate: Tue, 21 Mar 2006 23:47:54 +0000\r\nUser-Agent: Mozilla Thunderbird 1.0.7 (Windows/20050923)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;dvp5ub+usne@...&gt;\r\nIn-Reply-To: &lt;dvp5ub+usne@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Re: 378 days later...\r\nX-Yahoo-Group-Post: member; u=127853030; y=7gJ_xjgnA9y6bSciK8J0VFy1oqN4Yse7SPz5iKRBWVSJPc4DWis0\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nMike Woodhouse wrote:\n\n&gt;--- In neat@yahoogroups.com, Colin Green &lt;cgreen@...&gt; wrote:\n&gt;  \n&gt;\n&gt;&gt;ahh ok, how did that work out? I realise my graphs are [intentionally]\n&gt;&gt;minimal/lightweight, I take it ZedGraph is a bit more developed?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;It seems pretty fully-featured - I just happended to come across it in\n&gt;an unrelated application. I&#39;ve only used the simplest line graphs but\n&gt;they look nice. The stimulus came from wanting to see visually the\n&gt;relationship between evaluations per second (or generation evaluation\n&gt;time) and complexity. I threw in a lot of cheap resizing using the\n&gt;splitter panels (which I think were  new in VS2005). I&#39;ll upload a\n&gt;screen grab and the code when I get back to my development machine.\n&gt;  \n&gt;\n\nJust had a peek at the project page and it lok spretty good, I&#39;ll make a \nnote to maybe switch over. I purposely fixed the size of my graphs in \nsharpneat because they use GDI+ and I noticed it gets real slow as the \npainting area increases - exponentially so. ZedGraph may suffer from \nthis also, so just be aware that graph refreshes may be eating more CPU \nthan you would like.\n\n\n&gt;\n&gt;I&#39;m already a fan of pruning! \n&gt;\n\nWell I think were beginning to undertsand that it&#39;s just a sticking \nplaster - it&#39;s tackling the symptom of a problem rather than the cause. \nBut for now it does it&#39;s job I think.\n\n\n&gt;I have also found myself rather captivated\n&gt;by the way the compatibility threshold is adjusted to keep the species\n&gt;count within specified bounds - enough that I have played with setting\n&gt;deliberatley bad starting values, just to watch the balancing machanism\n&gt;in action...\n&gt;\n&gt;  \n&gt;\n\n&lt;deep frown&gt; Just because you /can/ set silly values doesn&#39;t mean you \nshould! ;)  If the # of species does crash then you risk loosing \ndiversity in your population, diversity that may take a long time to \nreacquire, especially if you are well into a search and your genomes are \nquite large. In fact at such an advance stage the crash in diversity \nwould be quite bad I think.\n\n\n&gt;\n&gt;  \n&gt;\n&gt;&gt;Have you tried a fixed number of activations? If not then it&#39;s worth a\n&gt;&gt;try, just stick with 4 or 5 - it should be faster becasue relaxation\n&gt;&gt;    \n&gt;&gt;\n&gt;has\n&gt;  \n&gt;\n&gt;&gt;the overhead of testing each neuron activation value over and over, so\n&gt;&gt;if it&#39;s not helping then it&#39;s best avoided.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;I&#39;ve looked at the number of evaluations taken to converge to a 0.01\n&gt;delta. With simple random networks it averages between 1 and 2, as able\n&gt;networks evolve it stretches to 4 to 6. Looking at the networks that are\n&gt;emerging, there&#39;s considerable connecting between the output nodes, so\n&gt;multi-stepping looks appropriate. Results have been generally better\n&gt;than single-step models (where the output layer connectivity doesn&#39;t\n&gt;tend to help much). And CPU cycles are cheap!\n&gt;  \n&gt;\n\nSingle step? So have you tried fixing the # of activations at 4 or 5? \nThe extra overhead of RelaxNetwork() is probably about equal to a whole \nactivation, so if you end up with solutions around the 4/5 activations \nmark then it might make sense to just fix it. It is potentially  more \ncomplex than this because e.g. networks that relax may be more \ncompatible during crossover, but I&#39;ve no reason to believe that this is \nor isn&#39;t the case at this time.\n\n\n&gt;I&#39;ve taken steps (via bet selection\n&gt;algorithm and fitness function tuning) to prevent it learning a dozen\n&gt;long-odds shots and punting the maximum on them. \n&gt;  \n&gt;\n\n Yes that definitely makes sense. Like I say you want consistently ok \nrather than one or two succesful long shots. Sounds like you&#39;ve got it \ncovered with your BetManager class.\n\n&gt;\n&gt;\n&gt;Sadly my original data source dried up, although I have a couple of\n&gt;years&#39; self-captured data. I have to spend a few hours on tedious\n&gt;data-cleansing before I have a test set. I&#39;ll be mightily pleased if\n&gt;there isn&#39;t a significant drop-off in performance - every non-NEAT\n&gt;approach (GEP being the most sophisticated) I&#39;ve tried tested a lot\n&gt;worse than it trained.\n&gt;  \n&gt;\n\nCould you not just split off some of your existing training data into a \ntest set?  Well, I&#39;m guessing your already invested in the existing \ntrainign data as it is, so maybe not eh.\n\n&gt;  \n&gt;\n&gt;&gt;&gt;2. How robust is the calibration/memory aspect? Would the network\n&gt;&gt;&gt;arrive at the same result if, say, the first seasons&#39; data were excluded?\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;\n&gt;I&#39;ve tried this - very similar results, both in profitability and in\n&gt;final team &quot;memory block&quot; outputs. When I get the chance I&#39;ll try\n&gt;several starting points - I also want to follow the evolution of team\n&gt;rating values over time against results to see if I can infer what the\n&gt;network is interested in.\n&gt;  \n&gt;\n\n\nIn my experience analysis of this type of data will lead to insights, \nalthough in my case it&#39;s usually discovering something both really \nobvious (in hindsight) and bad and that needs some rethinking to avoid. \nIn fact it&#39;s an observation of mine that I NEAT often finds some really \ninteresting and clever ways of cheating at my fitness functions, but \nwhen I finally close all of the loopholes that clerverness just sort of \nevaporates :(  Ok that&#39;s not entirely correct, there have been some \npretty good successes really.\n\n\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;A) Putting &quot;final solution&quot; in quotes made that sentence far more\n&gt;&gt;sinister than it otherwise would have done :-|\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;(evil laugh)\n&gt;  \n&gt;\n\n[mental note - amend license agreement to limit usage by evil-doers]\n\n&gt;  \n&gt;\n&gt;&gt;B) I think it&#39;s odds on that RealLife(TM) will scupper your plans\n&gt;&gt;somewhere along the line. That&#39;s not meant to be a reflection on you\n&gt;&gt;personally BTW, I&#39;ll take that bet on anyone any day! (it&#39;s in our DNA\n&gt;&gt;I&#39;m afraid).\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;I&#39;m taking the precaution of reworking the model to utilise a Manager\n&gt;class that understands working with a day&#39;s matches at a time. The front\n&gt;end could then be little more than a console app and some text files,\n&gt;which stands half a chance...\n&gt;  \n&gt;\n\nYeh, don&#39;t get bogged down in GUI stuff.  It&#39;s nice to have but not \nalways essential, and also a bit boring really (IMHO).\n\n\n\n\n&gt;&gt; E.g.\n&gt;&gt;evaulation using serial bets on your test data will give you an\n&gt;&gt;indication of how often your betting series will end up in profit/loss\n&gt;&gt;in the real world.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;I think the combination of large starting bank and heavily-constrained\n&gt;bets as a small proportion help to protect the models here - they can\n&gt;sustain an initial losing run without too much long-term impact.\n&gt;\n\nAgreed.\n\n&gt; I&#39;m\n&gt;thinking about ways to reward networks for other attributes such as good\n&gt;statistical reliabilty - chi-squared or similar, indicating that the\n&gt;results aren&#39;t just luck. Networks that learn to bet big on a few\n&gt;long-odds winners would be penalised undr this. I have already\n&gt;experimented with scaling fitness down for networks selecting verysmall\n&gt;numbers of  possible bets.\n&gt;  \n&gt;\n\nSure, although you shouldn&#39;t discount the possibility that your champ \nnetwork(s) may actually be able to accurately spot some very specific \nbut rare scenario and profit from it with high a success rate.\n\n\n&gt;  \n&gt;\n&gt;&gt;P.S. If you make your fortune then mines a pint. ;)\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;I already owe you at least one for the code you&#39;ve written so far!\n&gt;\n&gt;\n&gt;\n&gt;  \n&gt;\nOk well throw in a packet of crisps as well then.\n\n\nColin\n\n"}}