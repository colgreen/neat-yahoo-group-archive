{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":403065338,"authorName":"stephane.doncieux","from":"&quot;stephane.doncieux&quot; &lt;stephane.doncieux@...&gt;","profile":"stephane.doncieux","replyTo":"LIST","senderId":"uHZhLAlRQrbgaOsj5hi_A1CYsOwbd6E3urULIAkYtqywN_3uqF2_JvgycM1dPJMnaiKC9CL_SHqM3cy6ZNSzjovQFZT7YEyntqMFOZt_1ZkHUf4YJfeUOw","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: New paper on why modules evolve, and how to evolve modular artificial neural networks","postDate":"1361389735","msgId":6004,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtnMzliOCt2cTYwQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDc3NDVBMTQwLTQ1QzctNDFDQS04ODE3LTY2RjVDNUJDNkZFNkB1d3lvLmVkdT4="},"prevInTopic":6003,"nextInTopic":6005,"prevInTime":6003,"nextInTime":6005,"topicId":5976,"numMessagesInTopic":30,"msgSnippet":"Hi, Congratulations to JB, Jeff and Hod for their great work on the evolution of modularity ! The length and multiplicity of the comments undoubtedly show the","rawEmail":"Return-Path: &lt;stephane.doncieux@...&gt;\r\nX-Sender: stephane.doncieux@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 10143 invoked from network); 20 Feb 2013 19:48:58 -0000\r\nX-Received: from unknown (10.193.84.168)\n  by m10.grp.bf1.yahoo.com with QMQP; 20 Feb 2013 19:48:58 -0000\r\nX-Received: from unknown (HELO ng4-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.18)\n  by mta6.grp.bf1.yahoo.com with SMTP; 20 Feb 2013 19:48:57 -0000\r\nX-Received: from [98.139.164.121] by ng4.bullet.mail.bf1.yahoo.com with NNFMP; 20 Feb 2013 19:48:57 -0000\r\nX-Received: from [10.193.94.108] by tg2.bullet.mail.bf1.yahoo.com with NNFMP; 20 Feb 2013 19:48:57 -0000\r\nDate: Wed, 20 Feb 2013 19:48:55 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kg39b8+vq60@...&gt;\r\nIn-Reply-To: &lt;7745A140-45C7-41CA-8817-66F5C5BC6FE6@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;stephane.doncieux&quot; &lt;stephane.doncieux@...&gt;\r\nSubject: Re: New paper on why modules evolve, and how to evolve modular artificial neural networks\r\nX-Yahoo-Group-Post: member; u=403065338; y=6Qd-qiijlICsVCQga2HVEabeGbR-mLxX-0un8QlJR6vyb31eQy1uFFNcTIQ\r\nX-Yahoo-Profile: stephane.doncieux\r\n\r\n\n\nHi,\n\nCongratulations to JB, Jeff and Hod for their great work on the\nevol=\r\nution of modularity !\n\nThe length and multiplicity of the comments undoubte=\r\ndly show the value\nof this work. I would like to comment on the debate betw=\r\neen encoding bias and fitness manipulations that this paper has provoked in=\r\n the mailing list (a debate that actually goes beyond the connection cost o=\r\nbjective for modularity). \n\nAfter having spent a long time on encodings, I =\r\nfind it fruitful to\nwork on selection pressures. We have actually worked on=\r\n the definition\nof such fitness pressures and have proposed objectives to p=\r\nromote\ndiversity (Behavioral diversity [1]), generalization [2], behavior\nc=\r\nonsistency [3,4] or to cross the reality gap with robots [5].  I\ndon&#39;t want=\r\n to say that it is the only way to solve the problems that\nthese objectives=\r\n are designed for, nor that it is the best way to do\nit, but I will just me=\r\nntion the advantages I find with such an\napproach relative to work on the e=\r\nncoding.\n\nThe great advantage of the works on selection pressures is that i=\r\nt is\nhighly localized. The contribution is limited to the definition of an\n=\r\nobjective that is then easy to integrate to a third party work than\nwhen it=\r\n comes with its own specific selection algorithm and\nencoding. Such work do=\r\nes not highly depend on an encoding, nor on a\nparticular selection algorith=\r\nm (as long as it is a multi-objective\nalgorithm). It is trivial to make com=\r\nparisons with-without a\nparticular objective and all these works are, at le=\r\nast from a\ntechnical point of view, compatible. You can then use, besides a=\r\n\ngoal-oriented objective, the connection cost objective for modularity toge=\r\nther with a behavioral diversity or novelty objective to increase the explo=\r\nration. What is even more interesting in my opinion, is that\nanyone interes=\r\nted in optimizing complex neural networks or graphs and\nthat may have his o=\r\nwn encoding for whatever reasons (to be\nbiologically plausible for instance=\r\n) can use these objectives in his\nown work with very few, if any, technical=\r\n modifications. It represents\nthen a lower investment and makes such kind o=\r\nf work more prone to be\nused outside of our own field, it is at least my op=\r\ninion on the\nsubject. Likewise, all the works mentionned above rely on NSGA=\r\n-II,\ni.e. a classic multi-objective evolutioanry algorithm. Any\nnew and mor=\r\ne efficient MOEA can by used without any particular\ntechnical problem.\n\nTo =\r\ncome back to the performance issue, in all of our experiments,\nusing a simp=\r\nle direct encoding with two objectives\n(fitness+behavioral diversity) gave =\r\nbetter results than NEAT, no\nmatter how we define behavioral diversity [1].=\r\n What is nice with these\nresults, is that it is not incompatible with NEAT.=\r\n A\nmulti-objective version of NEAT can exploit the benefits gained with\nbeh=\r\navioral diversity (it has actually been proposed in a GECCO paper\nby Morigu=\r\nchi and Honiden). A quite surprising result for us is that a\nsimple direct =\r\nencoding can solve a complex sequential tasks (ball\ncollecting task) with a=\r\n discrete and simple fitness function (a number\nof collected balls) togethe=\r\nr with a simple behavioral diversity\nobjective (see a video here: http://yo=\r\nutu.be/Trj0_A1ZfNo).\n\nOf course, there are limitations. If you use more tha=\r\nn three\nobjectives, for instance, the performance of multi-objective\nalgori=\r\nthms is known to be very low. This is a limitation that people\nfrom the mul=\r\nti-objective optimization community are aware of. They\nwork on it and many-=\r\nobjectives optimization algorithms will probably\nbe released in a near futu=\r\nre (some have already been proposed\nactually).  Likewise, as pointed out by=\r\n Jeff, the dead weights\nmentionned by Ken are really a consequence of curre=\r\nnt multi-objective\nevolutionary algorithms inner workings. Several adaptati=\r\nons can be\nproposed, as the &quot;probabilistic pareto dominance&quot; developped by =\r\nJeff\nand Jean-Baptiste or any other preference or thresholding system. It\ni=\r\ns not an inherant limitation of these approaches, just a proof that\nthere i=\r\ns still some work to do in multi-objective optimization\nfield. It should be=\r\n noted that this is not a problem of our community\nonly. Multi-objective op=\r\ntimization is a very dynamic field of research\nso we can expect solutions t=\r\no these problems in a forthcoming future.\n \nSo to conclude, I agree that it=\r\n is important to work on the encoding,\nbut my point is that it is also wort=\r\nh to work on selection pressures. The nice thing is\nthat the works on both =\r\naspects are quite complementary.\n\n\nBest,\n\nStephane Doncieux\n\n[1] Mouret, J.=\r\n-B. and Doncieux, S. (2012). Encouraging Behavioral Diversity in Evolutiona=\r\nry Robotics: an Empirical Study.\nEvolutionary Computation. Vol 20 No 1 Page=\r\ns 91-133.\n\n[2] Pinville, T. and Koos, S. and Mouret, J-B. and Doncieux,\nS. =\r\n(2011). How to Promote Generalisation in Evolutionary Robotics: the\nProGAb =\r\nApproach. GECCO&#39;11. Pages 259--266.\n\n[3] Ollion, Charles and Doncieux, St=\r\n=E9phane (2012). Towards Behavioral Consistency in Neuroevolution.\nFrom Ani=\r\nmals to Animats: Proceedings of the 12th International\nConference on Adapti=\r\nve Behaviour (SAB 2012), Springer, publisher. \n\n[4] Ollion, C. and Pinville=\r\n, T. and Doncieux, S. (2012). With a little\nhelp from selection pressures: =\r\nevolution of memory in robot\ncontrollers. Proc. Alife XIII.\n\n[5] Koos, S. a=\r\nnd Mouret, J.-B. and Doncieux, S. (2013). The\nTransferability Approach: Cro=\r\nssing the Reality Gap in Evolutionary\nRobotics. IEEE Transactions on Evolut=\r\nionary Computation. Vol 17 No 1 Pages 122 - 145 .\n\n\n\n--- In neat@yahoogroup=\r\ns.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello Ken,\n&gt; \n&gt; Please see my inl=\r\nined comments. \n&gt; \n&gt; &gt; \n&gt; &gt; Hi Jeff, I wanted to follow up on the &quot;dead wei=\r\nght&quot; concept I brought up, because I feel I may not have made it entirely c=\r\nlear what that is. In a multiobjective formulation, if one of the objective=\r\ns is low connectivity, then you can dominate on that objective by having ex=\r\ntremely low connectivity and no other saving grace whatsoever. In other wor=\r\nds we are talking about completely nonfunctional and essentially inert garb=\r\nage that does well on that one objective by effectively being brain dead. I=\r\nn effect, you have created a special &quot;niche&quot; for brain-dead networks with r=\r\nadically low connectivity.\n&gt; &gt; \n&gt; &gt; \n&gt; That&#39;s true. Of course, you could ch=\r\noose to have a cutoff to minimize this problem. For example, you could not =\r\ngive credit to any orgs that do not have a path from inputs to outputs, or =\r\nthat have a total connectivity below X, or some other solution (including a=\r\n cutoff that changes over time). \n&gt; \n&gt; &gt; Perhaps early on this niche is a f=\r\nruitful point of departure for better places, but the problem is that this =\r\nniche will never go away. You will always have this protective pocket for b=\r\nrain-dead low-connectivity networks for as long as evolution runs. In fact =\r\nit&#39;s a very attractive niche because it&#39;s so easy - you don&#39;t have to worry=\r\n about performance and simply need to keep your structure down. So these ty=\r\npes of inert blobs will be around forever.\n&gt; &gt; \n&gt; &gt; You suggest that my con=\r\ncern about this &quot;unfit&quot; niche is not consistent with my support of novelty =\r\nsearch, but novelty search is not really analogous. Novelty search is about=\r\n constantly searching for *new* departure points. Your dead-weight niche is=\r\n about keeping around the same bottom-level junk forever. Novelty search wo=\r\nuld quickly tire of such a black hole and abandon it (it doesn&#39;t stay novel=\r\n). But multiobjective search will embrace it for eternity.\n&gt; &gt; \n&gt; &gt; \n&gt; That=\r\n&#39;s true, but on many complex/multi-dimensional tasks there are often infini=\r\ntely many ways to be uninteresting, yet novel. For example, in your unenclo=\r\nsed map in the NS journal paper, only a few runs solve the problem (the sam=\r\ne as random search), likely because of the permanent dead-weight of an infi=\r\nnite number of places to end up that are far away from the target. \n&gt; \n&gt; &gt; =\r\nNature doesn&#39;t have anything analogous either, which means there is at leas=\r\nt some evidence that the &quot;fitness bias&quot; analogy with nature is not lining u=\r\np perfectly. You might point to the continuing existence of single-celled o=\r\nrganisms as something similar to the perpetual dead-weight in this formulat=\r\nion, but they aren&#39;t really analogous because single-celled organisms are f=\r\nunctional - they retain the ability to make copies of themselves and contin=\r\nue to evolve in their own right - while the low-connectivity deadweight mai=\r\nntains no capability whatsoever. On the other hand, suspiciously, as in nat=\r\nure, nothing similar to such a deadweight niche is perpetuated by a biased =\r\nencoding.\n&gt; &gt; \n&gt; &gt; \n&gt; That&#39;s also true, but that fault does not lie with th=\r\ne fitness cost concept, it lies with the fact that multi-objective algorith=\r\nms, which are the cause of the dead weight, do not perfectly analogize to n=\r\nature. They&#39;re just better than a weighted sum for other reasons, but the f=\r\nitness cost concept could easily be implemented in a weighted sum fitness f=\r\nunction and not have this dead weight issue.  \n&gt; \n&gt; &gt; Doesn&#39;t it seem a lit=\r\ntle strange that the price we have to pay to obtain modular structure is to=\r\n maintain a perpetual dead pool of genetic junk? Note that it doesn&#39;t sugge=\r\nst that such a system won&#39;t work in some cases, but it&#39;s inelegant enough t=\r\no raise questions about the best realization of the concept..\n&gt; &gt; \n&gt; \n&gt; All=\r\n I think that calls into question is the optimality of multi-objective algo=\r\nrithms when you don&#39;t want the extreme of one objective. But that problem a=\r\nlmost always occurs in multi-objective algorithms, so your really indicting=\r\n the whole field of MOEA instead of our approach of using a fitness penalty=\r\n instead of a biased encoding, no?\n&gt; \n&gt; &gt; \n&gt; &gt; Also on the analogy with nat=\r\nure, while your argument for fitness pressure in nature based on the size o=\r\nf the head is logically possible (and the kind of argument that is probably=\r\n attractive to a lot of people), it&#39;s only speculative. In fact what little=\r\n evidence there is on such a speculative issue (i.e. whether a baby&#39;s head =\r\nmight fit through a mother&#39;s pelvis in some alternate evolutionary path) do=\r\nesn&#39;t support the idea that size is the main issue here. After all, whale b=\r\nrains are far bigger than human brains and I&#39;m sure they are also dominated=\r\n by local connectivity.\n&gt; &gt; \n&gt; Yes, but they float in water! You couldn&#39;t h=\r\nave a creature with that big of a brain on land (I speculate, not being an =\r\nexpert in these things). Interesting side note: I believe whale brains are =\r\npretty tiny as a fraction of body size compared to primates, and (for some =\r\nreason I don&#39;t get) we think that relative brain size matters more for inte=\r\nlligence than absolute brain size.  \n&gt; \n&gt; &gt; Conversely, human brains, or br=\r\nains of any size for that matter, could have been exactly the same size but=\r\n dominated by long-range connections rather than short range ones. In fact,=\r\n in such a situation connectivity would actually be lower overall because l=\r\nong-range connections take up more space. But the mother&#39;s anatomy poses no=\r\n obstacle to such a scenario. The fact that we don&#39;t see such a connectivit=\r\ny in any species is therefore plausibly a result of the fact that the encod=\r\ning simply can&#39;t describe it easily.\n&gt; &gt; \n&gt; &gt; \n&gt; Such a brain could exist, =\r\nbut because of the extra space taken up by the connections, there would hav=\r\ne to be either fewer neurons, fewer connections (as you point out), or both=\r\n. That certainly sounds like a cost to me! Moreover, longer connections are=\r\n less reliable, cost more to build and maintain, and they are energetically=\r\n more expensive due to signal drop along the length of the wire. So there a=\r\nre a whole host of costs associated with such a strategy, making me think i=\r\nt much, much more likely that these costs are the reason we don&#39;t see this =\r\ntype of brain, instead of it being difficult to encode. Evolution has produ=\r\nced amazing things, and it already produces many long-range connections in =\r\nthe brain, so I do not think the difficulty of encoding such a brain is wha=\r\nt prevented it from existing. \n&gt; \n&gt; &gt; \n&gt; &gt; I feel that you may not see what=\r\n I&#39;m saying about encoding here, because you speak about encoding as if it =\r\nhas similar effects to fitness pressure, but I think it&#39;s not the same. You=\r\n say: \n&gt; &gt; \n&gt; &gt; &quot;The reasons biases work is because they do bias search tow=\r\nards some areas and away from others: so I think both encoding biases and f=\r\nitness penalties have similar effects in this regard.&quot;\n&gt; &gt; \n&gt; &gt; But I don&#39;t=\r\n think that&#39;s true for encoding. The difference with encoding is that it is=\r\n not pushing the search towards any particular area within the space it ind=\r\nuces. Absent any kind of fitness function or selective pressure, encoding s=\r\nays nothing about which areas are accessible. Rather it simply says which t=\r\nypes of phenotypes are overrepresented or underrepresented throughout the w=\r\nhole space of genotypes. In other words, even if an encoding is &quot;biased&quot; to=\r\nwards low connectivity, if you happen to get into an area of the space with=\r\n high connectivity, the encoding does not have to push you out of that area=\r\n (it could be a dense subspace full of high-connectivity structures). But f=\r\nitness bias would have to push you out because all it does it push you out.=\r\n It can&#39;t bend or change depending on where you go. Encoding can change wit=\r\nh the times and has the wonderful additional potential for canalization, a =\r\nbonus entirely absent from fitness pressure.\n&gt; &gt; \n&gt; &gt; \n&gt; First of all, an e=\r\nncoding can actually prevent you from accessing a space. If I encode the le=\r\nngth of all table legs in one number, than I have eliminated the possibilit=\r\ny of a table having legs of different lengths. L-systems tend to produce su=\r\nch overly rigid biases (unless they are parameterized and/or made context-d=\r\nependent). But more relevant to our discussion are biases that are strong l=\r\nikelihoods, but not strict edicts. Even these, though, in practice do mean =\r\nthat entire areas of the search space go unexplored. In our TEC paper, for =\r\nexample, the HyperNEAT generative encoding far outperformed the direct enco=\r\nding, even though the fitness function was the exact same. Why? Because the=\r\n direct encoding was biased towards an entirely different area of the searc=\r\nh space. We know that there was a selection pressure for certain types of A=\r\nNNs (namely, the ones HyperNEAT produced), and we know that the direct enco=\r\nding can express those phenotypes (they actually do in HybrID), but evoluti=\r\non with the direct encoding did not do so because biases have a huge effect=\r\n on the subset of the search space you visit. In fact, it is precisely beca=\r\nuse encodings have biases of large effect that we all care about generative=\r\n encodings, no? All of these arguments are also supported by Hornby&#39;s compa=\r\nrison of L-systems to a direct encoding, including his maps of the types of=\r\n phenotypes produced (there are huge differences between the two encodings)=\r\n. I&#39;d argue that any comparison of direct and indirect encodings shows that=\r\n these biases are not subtle, but grossly change the types of phenotypes ex=\r\nplored, and for all practical purposes eliminate large swathes of the searc=\r\nh space. For these reasons I think you&#39;ll get huge unintended consequences =\r\nby playing around with encodings, and those consequences will not be overri=\r\ndden by the fitness function, because we&#39;ve seen it happen time and time ag=\r\nain. Note that I agree that you also have unintended consequences when play=\r\ning with fitness functions. \n&gt; \n&gt; NB: I agree with you about canalization, =\r\nwhich is one of many reasons I like generative encodings. :-)\n&gt; \n&gt; &gt; The ri=\r\nght level of modularity is likely on a delicate continuum - not entirely on=\r\ne way or another, and probably varies by species. You believe evolution can=\r\n pay a kind of tax for going against the pressure towards low connectivity:=\r\n &quot;if a certain phenotype pays for its wiring by increasing fitness, it can =\r\nadd high-connectivity areas anywhere that they are useful.&quot; But in a delica=\r\nte balancing act where the best option is likely some middle ground, that s=\r\nounds too much like gambling and it&#39;s vulnerable to deception in cases wher=\r\ne there is no immediate fitness benefit (whereas encoding is orthogonal to =\r\nfitness). With encoding you don&#39;t have the play that game. Encoding can cre=\r\nate its own tendency towards some middle ground and canalize that tendency =\r\nover time.\n&gt; &gt; \n&gt; If there is no fitness gradient toward such a bias toward=\r\n intermediate connectivity, why would it evolve? Evolution can only think s=\r\nhort term. I&#39;ll give you that an encoding bias might override the fitness g=\r\nradient by making it impossible to follow, but I don&#39;t buy that evolution c=\r\nan magically figure out biases that are helpful in the long-term if the sho=\r\nrt-term fitness gradients all point in another direction. Or, at least, tha=\r\nt&#39;s something we hope that evolution might do, but it&#39;s a controversial, un=\r\nproven, and theoretically tricky issue that I certain don&#39;t think we can ba=\r\nnk on happening until we understand it a lot more. \n&gt; \n&gt; &gt; While you worry =\r\nthat modularity might &quot;evolve away,&quot; the idea that it cannot evolve away to=\r\n varying degrees sounds worse to me. Natural evolution is generally good ab=\r\nout not keeping all its eggs in one basket - a trait may evolve away in som=\r\ne branches but not in others. But for you to make an all-out attempt to bar=\r\n such a deviation from square one is making a lot of strong assumptions abo=\r\nut what we want to see 1 billion years in the future.\n&gt; &gt; \n&gt; &gt; \n&gt; I&#39;d argue=\r\n that your bias in the first replicator without any sustained fitness press=\r\nure would have zero effect on creatures a billion years later, especially i=\r\nn the case where there is an active fitness gradient by default away from m=\r\nodularity (which we know there is, since modularity never evolves without a=\r\n bias or fitness pressure). Evolution would not keep any eggs in a basket w=\r\nith an active fitness penalty, at least not for a billion years. My 1-billi=\r\non-years-later influence may thus be imperfect, but it at least exists!\n&gt; \n=\r\n&gt; &gt; So I&#39;m still a fan of manipulating encoding over manipulating fitness. =\r\nBut I would not entirely despair on fitness because there will still be cas=\r\nes where there is no clear option for manipulating the encoding. But such s=\r\ncenarios are not ones we should be hoping for.\n&gt; &gt; \n&gt; &gt; \n&gt; I do think you m=\r\nake some great arguments for encodings, but I cannot envision a case in whi=\r\nch an initial bias only makes a huge difference in the long-term. That&#39;s tr=\r\nue even if the bias is neutral with respect to fitness (because it would dr=\r\nift away), but seems a certainty to me if it relates to a bias that has an =\r\nactive fitness penalty. The whole point of canalization is that it figures =\r\nout what produces fit offspring and generates that type of organism: if mod=\r\nular creatures are less fit in the short term, evolution will canalize away=\r\n from modularity, not toward it. That said, as I mentioned at the beginning=\r\n of this conversation, I do think that a sustained encoding bias of some so=\r\nrt is an interesting approach that could work, although it may be that all =\r\nwe have to do is provide a fitness cost and then the encoding will canalize=\r\n in a way that produces such a sustained bias. :-)\n&gt; \n&gt; As always, an inter=\r\nesting conversation!\n&gt; Best,\n&gt; Jeff\n&gt; \n&gt; \n&gt; &gt; Best,\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; -=\r\n-- In neat@yahoogroups.com, Jeff Clune wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hello all,\n&gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; As Ken mentioned, we&#39;ve discussed these issues in private. I&#39;m going=\r\n to include some of my comments from one of those email threads with slight=\r\n modification, as I believe they summarize the views of Jean-Baptiste and I=\r\n on the issues Ken raises. I&#39;ll then respond to a few individual comments b=\r\ny Ken afterwards. \n&gt; &gt; &gt; \n&gt; &gt; &gt; ---------------\n&gt; &gt; &gt; Ken,\n&gt; &gt; &gt; \n&gt; &gt; &gt; It&#39;=\r\ns great to hear your feedback on our paper. Thanks for sending it.\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; First off, thanks for the kind words. We&#39;re very glad you liked the pa=\r\nper and think it is important. \n&gt; &gt; &gt; \n&gt; &gt; &gt; Regarding a selection pressure=\r\n vs. an encoding bias. We&#39;re not convinced that an initial encoding bias is=\r\n a good way to encourage properties that one wants in phenotypes throughout=\r\n evolution, such as modularity. If there is any deceptiveness (or even neut=\r\nrality) regarding modularity at any point during the run then the bias will=\r\n disappear, and then for the rest of evolutionary time nothing will encoura=\r\nge modularity. We are more convinced of the power of mutational bias in the=\r\n encoding (i.e. a constant encoding bias instead of just an initial encodin=\r\ng bias), and we think it would be interesting to investigate area. However,=\r\n if the encoding bias is under selection, then you have the same issue wher=\r\ne it might evolve away. Selective pressures are interesting because they ar=\r\ne constant, so you&#39;re more likely to get what you want. That raises the poi=\r\nnt you mention about our pressure being too strong, such that evolution cou=\r\nld not deviate when it would be beneficial not to have modularity. That mig=\r\nht be a problem if the pressure is too strong, but it seems likely that in =\r\nmany cases the benefits in terms of performance for being non-modular will =\r\noutweigh the cost. In other words, evolution can decide to pay the cost of =\r\nnon-modularity when it is useful (e.g. in your example of a hub of connecti=\r\nons between modules).\n&gt; &gt; &gt; \n&gt; &gt; &gt; Regarding playing with an encoding being=\r\n safer than playing with selection pressures. Our view is that both are ver=\r\ny complicated and can have unintended consequences, so playing with one is =\r\njust as bad as the other. I think our field is more familiar with unintende=\r\nd consequences of selective pressures just because we historically tend to =\r\nplay with them more (and make simple encodings), but it is also very hard t=\r\no intuit the consequences of choices regarding biases in complex encodings.=\r\n In your case the consequences are relatively intuitive, precisely because =\r\nthey are so minimally interventionist...but that is also why I think they a=\r\nre not strong enough to cause modularity except in cases (like retina) wher=\r\ne all you have to do is initially place evolution in the right attractor ba=\r\nsin.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Regarding the resource hog waste of having a cost objecti=\r\nve. I have to have a little fun here and point out the irony of the co-cham=\r\npion of novelty search worrying about the resources consumed by non-high-pe=\r\nrforming individuals! Hehe. As you&#39;ve persuaded me, I&#39;m more interested in =\r\nan algorithm that is interesting or that works than spending a little compu=\r\ntation inefficiently.\n&gt; &gt; &gt; \n&gt; &gt; &gt; I&#39;d also like to point out an innovation=\r\n we came up with to mitigate the problem of preventing evolution from explo=\r\nring solutions that are contrary to one of the objectives. We recognized th=\r\nat the cost objective is ultimately less important than the performance obj=\r\nective. We wanted evolution to periodically ignore the cost objective to ex=\r\nplore stepping stones that had higher connectivity. To do that, we invented=\r\n a technique that involves &quot;probabilistic pareto dominance&quot;, wherein second=\r\nary objectives (in this case cost) are factored into pareto dominance only =\r\na small percentage of the time. That won&#39;t solve the problem you mention if=\r\n you have to take a long, many-multi-generational walk through high-connect=\r\nivity areas of the search space, but it does allow quick forays into that t=\r\nerrain without any fitness penalty. This technique could be used for any co=\r\nst (or other) objective, so it is not specific to connectivity costs. \n&gt; &gt; =\r\n&gt; \n&gt; &gt; &gt; See below for a few specific responses to your comments. I should =\r\nnote that below this the thoughts are my own and Jean-Baptiste should not b=\r\ne blamed for any of them! (Feel free to blame him for things above this lin=\r\ne=85we went over that text together a while back). ;-)\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; More =\r\ngenerally the issue is the usual problem of deception, which is compounded =\r\nby anything you do with fitness. For example, in a complex search space, th=\r\nere is a reasonable chance that the stepping stone to a good low-connectivi=\r\nty solution is something with higher connectivity. By manipulating fitness,=\r\n you are cutting out all chances of encountering such a deceptive stepping =\r\nstone. But even if you don&#39;t believe that could be true, the single-mindedn=\r\ness of always favoring low-connectivity could deceive you from many parts o=\r\nf the search space that might be stepping stones to something worthwhile, r=\r\nelating to connection density or not.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; True. But the=\r\n same exact thing can be said for biases in the encoding: they prevent you =\r\nfrom searching large areas of the search space. You may reply that it is on=\r\nly a bias, not a strict ban, but of course we know that in large search spa=\r\nces biases hugely affect the landscape such that certain areas will practic=\r\nally never be visited. \n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; On the other hand, manipulating the =\r\nencoding is different because in effect it actually reorganizes the structu=\r\nre of the search space itself, which seems to me a more principled thing to=\r\n do (if you can figure out a way to do it). Because the thing is, in that c=\r\nase, you do not need to worry about a permanent dead weight taking up some =\r\nproportion of your population forever. Instead, while the encoding may *ten=\r\nd* to produce e.g. low-connectivity solutions, it can still escape that ten=\r\ndency without any penalty to fitness.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; My instincts tell me t=\r\nhat we create dead weight with encoding biases too. For example, an overly =\r\nregular generative encoding (e.g. context free L-systems) is great if good =\r\nsolutions are perfectly regular, but if what is required is a mix of regula=\r\nrity and irregularity, then you spend your entire time producing only highl=\r\ny regular phenotypes that never wander into the appropriately irregular are=\r\nas of the search space. Our IEEE TEC paper, for example, shows that HyperNE=\r\nAT can spend thousands of generations spinning its wheels never generating =\r\nsolutions that HybrID could easily generate, demonstrating a &quot;overly regula=\r\nr&quot; dead weight associated with the biases of even the best known* generativ=\r\ne encoding! Both fitness penalties and biases can cause you to focus your s=\r\nearch in unproductive areas=85which is ultimately what dead weight is. \n&gt; &gt;=\r\n &gt; \n&gt; &gt; &gt; * in our opinion! :0)\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Furthermore, in reality the =\r\nbest situation regarding modularity and connectivity is probably rather sub=\r\ntle, with most of the brain respecting the principle of low connectivity, b=\r\nut with a number of critical exceptions in key areas, such as major inter-m=\r\nodule hubs. A sophisticated encoding can allow its bias to bend to make suc=\r\nh nuanced exceptions (e.g. based on locations within a geometry), whereas a=\r\n fitness penalty is a heavy hand and blunt instrument that cannot but help =\r\nalways to demand global and holistic subservience to dogmatic universals (u=\r\nnless you are willing to take a hit in fitness).\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; I =\r\nthink the last clause you offer is the key exception though. As I mentioned=\r\n above, if a certain phenotype pays for its wiring by increasing fitness, i=\r\nt can add high-connectivity areas anywhere that they are useful (without ev=\r\nen needing to carve out that area in geometric space, which is often a diff=\r\nicult task for CPPNs). Instead of being a blunt instrument, a fitness penal=\r\nty can be quite subtle, because it can allow connection-by-connection excep=\r\ntions if they produce fitness improvements, and do so without any search ov=\r\nerhead. \n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; An interesting question in nature (where our brains=\r\n evolved modular structure) is whether its tendency towards low connectivit=\r\ny is a result of an aspect of fitness in the wild, or an aspect of encoding=\r\n bias. I think there is a lot of room in this question for arguing either w=\r\nay, but my hunch is that the bias is mostly in the encoding. My logic is th=\r\nat I think the reason that the connectivity of the brain is so much lower t=\r\nhan what it could be (e.g. it is a tiny fraction of everything-to-everythin=\r\ng connectivity) is an artifact of physics rather than an artifact of fitnes=\r\ns. It is simply physically impossible for a giant 100-billion-to-100-billio=\r\nn connectivity to fit in a head anything close to our size. And physical im=\r\npossibility is in some sense a property of encoding. That is, mutations tha=\r\nt could step from a low-connectivity brain to a high one are few and far be=\r\ntween simply because of physical constraint. So high-connectivity structure=\r\ns are simply a very small part of the search space of brains in the physica=\r\nl universe. However, at the same time, you can still get long-range connect=\r\nions from time to time because there is no universal penalty for doing so, =\r\njust a lower a priori probability of such mutations occurring.\n&gt; &gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; Here I completely disagree with you. I see the force preventing=\r\n the volume of neural connections from getting too large as a direct fitnes=\r\ns cost, not an encoding bias. If mutations increase the size of the head, t=\r\nhe baby and the mother are more likely to die in childbirth. Anthropologist=\r\ns have long known that evolution&#39;s desire to have larger and larger brains =\r\nis the main reason why humans have such ridiculously high maternal and infa=\r\nnt mortality &quot;in the wild&quot; (pre modern health care, and even post). Our enc=\r\noding keeps producing such mutants, and it&#39;s death (via the physical constr=\r\naints of the pelvis) that keep them from being kept around. The historical =\r\naccident of birthing through the pelvis aside, there would still be fitness=\r\n consequences for more vastly neural connections (e.g. neurons are metaboli=\r\ncally expensive, neural connections require energy to build and maintain, a=\r\nnd housing such large brains would create a large, clunky bobble head of a =\r\nbeing that would be ungainly). It is possible that low connectivity is an e=\r\nncoding bias, but were that true I think it would look like some sort of gr=\r\nowth rule that only grew a few connections per neuron (e.g. 10k). Evolution=\r\n could have learned such a rule, and canalized that rule in a way that make=\r\ns it unlikely to have mutations that produce orders of magnitude more neuro=\r\nns, but my guess is that if it has done so, it was because of the fitness c=\r\nosts associated with large numbers of neurons, not because of evolvability =\r\n(or due to some historical accident). I do think it is interesting to study=\r\n whether such biases exist in the encoding of neural growth rules, but even=\r\n if they do exist I don&#39;t think that shows that a fitness cost was not the =\r\nultimate cause. Note: I recognize that you admit that this could be argued =\r\n&quot;either way&quot;=85are these the sorts of arguments you envisioned as being the=\r\n other way?\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; In summary, the key difference between the alter=\r\nnatives is that with fitness you are saying &quot;stay out of this part of the s=\r\nearch space&quot; whereas with encoding you are saying &quot;this part of the search =\r\nspace is much smaller and hence less likely to encounter.&quot;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; I don&#39;t precisely understand your latter clause, but I think I unde=\r\nrstand the spirit of it. I disagree, though. The reasons biases work is bec=\r\nause they do bias search towards some areas and away from others: so I thin=\r\nk both encoding biases and fitness penalties have similar effects in this r=\r\negard. \n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; So, my speculation is that if you want to bias the s=\r\nearch in highly complex domains, the best way is through the encoding. Fitn=\r\ness is a nasty quagmire that is deceptively tempting to manipulate, but nev=\r\ner plays by the rules you wish it would. Of course, these are merely my own=\r\n unproven intuitions and their veracity remains to be demonstrated. But at =\r\nleast it&#39;s something to think about.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Thanks =\r\nagain for your feedback. As always, I appreciate your input and enjoy discu=\r\nssing these fascinating subjects. \n&gt; &gt; &gt; \n&gt; &gt; &gt; I want to end by clarifying=\r\n that I agree that there are positives and negatives to both approaches. I =\r\ndo not see it as such an obvious choice between the two as you do. As I men=\r\ntioned up top: I definitely don&#39;t think initial encoding biases that select=\r\nion can get rid of will get us very far. For simple problems they will work=\r\n, but for any challenging problem the initial bias will have long disappear=\r\ned by the time it will matter. What we need is some constant force encourag=\r\ning search to take promising paths. A fitness cost is one way to do that, b=\r\nut a *constant* (or, at least, *periodic*) encoding bias could do that just=\r\n as well, and perhaps better. \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Best regards,\n&gt; &gt; &gt; Jeff=\r\n Clune\n&gt; &gt; &gt; \n&gt; &gt; &gt; Assistant Professor\n&gt; &gt; &gt; Computer Science\n&gt; &gt; &gt; Univer=\r\nsity of Wyoming\n&gt; &gt; &gt; jeffclune@\n&gt; &gt; &gt; jeffclune.com\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\nBest,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, Al=\r\nexandre Devert wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Hi,\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =C2 Simp=\r\nle, clean experiment, with sharp results, congrats on that, definitely\n&gt; &gt; =\r\n&gt; &gt; &gt; a step forward ! Of course, it begs for more questions. I would love =\r\nto hear\n&gt; &gt; &gt; &gt; &gt; you on such (fairly open) questions\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =\r\n=C2 =C2 1) Do you think that selection pressure for low connectivity is suf=\r\nficient in\n&gt; &gt; &gt; &gt; &gt; itself to evolve large coherent networks, or is it jus=\r\nt a piece of the puzzle ?\n&gt; &gt; &gt; &gt; &gt; =C2 =C2 2) Do you see your work as an i=\r\nndication that any approach biased to low\n&gt; &gt; &gt; &gt; &gt; connectivity would repr=\r\noduce the result ? Or does the way you guys enforced\n&gt; &gt; &gt; &gt; &gt; this bias ma=\r\ntters ?\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; To me=C2 \n&gt; &gt; &gt; &gt; &gt; 1) =3D&gt; Part of the puzzle=\r\n. Should see how well it scales for increasingly\n&gt; &gt; &gt; &gt; &gt; complex task, wh=\r\nen the connection graph gets bigger. A randomized=C2 \n&gt; &gt; &gt; &gt; &gt; search proc=\r\ness=C2 on large graph sounds not so efficient, need something to guide it.\n=\r\n&gt; &gt; &gt; &gt; &gt; I advocate construction process that have a feedback from what th=\r\ne neuron=C2 \n&gt; &gt; &gt; &gt; &gt; network is computing. Don&#39;t know how to do it withou=\r\nt creepling computational\n&gt; &gt; &gt; &gt; &gt; cost tho...\n&gt; &gt; &gt; &gt; &gt; 2) =3D&gt; I guess t=\r\nhat the bias alone is enough, the way to introduce it might\n&gt; &gt; &gt; &gt; &gt; not b=\r\ne such a big deal.=C2 \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Again, great work, very helpful=\r\n contribution :)\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Alex\n&gt; &gt; &gt; &gt; &gt; =C2 \n&gt; &gt; &gt; &gt; &gt; Dr. Dev=\r\nert Alexandre\n&gt; &gt; &gt; &gt; &gt; Researcher at the Nature Inspired Computation and A=\r\npplications Laboratory (NICAL)\n&gt; &gt; &gt; &gt; &gt; Lecturer at School Of Software Eng=\r\nineering of USTC\n&gt; &gt; &gt; &gt; &gt; ------------------------------------------------=\r\n----\n&gt; &gt; &gt; &gt; &gt; Homepage :=C2 http://www.marmakoide.org\n&gt; &gt; &gt; &gt; &gt; ----------=\r\n------------------------------------------\n&gt; &gt; &gt; &gt; &gt; 166 Renai Road, Dushu =\r\nLake Higher Education Town\n&gt; &gt; &gt; &gt; &gt; Suzhou Industrial Park,\n&gt; &gt; &gt; &gt; &gt; Suzh=\r\nou, Jiangsu, People&#39;s Republic of China\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; ___=\r\n_____________________________\n&gt; &gt; &gt; &gt; &gt; From: Jeff Clune \n&gt; &gt; &gt; &gt; &gt; To: nea=\r\nt users group group \n&gt; &gt; &gt; &gt; &gt; Cc: Jean-Baptiste Mouret ; Hod Lipson \n&gt; &gt; &gt;=\r\n &gt; &gt; Sent: Thursday, February 7, 2013 1:57 AM\n&gt; &gt; &gt; &gt; &gt; Subject: [neat] New=\r\n paper on why modules evolve, and how to evolve modular artificial neural n=\r\networks\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =C2 \n&gt; &gt; &gt; &gt; &gt; Hello all,\n&gt; &gt; &gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; &gt; &gt; I&#39;m extremely pleased to announce a new paper on a subject that=\r\n many--including myself--think is critical to making significant progress i=\r\nn our field: the evolution of modularity.=C2 \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Jean-Bap=\r\ntiste Mouret, Hod Lipson and I have a new paper that=C2 \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;=\r\n &gt; 1) sheds light on why modularity may evolve in biological networks (e.g.=\r\n neural, genetic, metabolic, protein-protein, etc.)\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; 2)=\r\n provides a simple technique for evolving neural networks that are modular =\r\nand have increased evolvability, in that they adapt faster to new environme=\r\nnts. The modules that formed solved subproblems in the domain.=C2 \n&gt; &gt; &gt; &gt; =\r\n&gt; Cite:=C2 Clune J, Mouret J-B, Lipson H (2013) The evolutionary origins of=\r\n modularity. Proceedings of the Royal Society B. 280: 20122863.=C2 http://d=\r\nx.doi.org/10.1098/rspb.2012.2863=C2 (pdf)\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Abstract: A =\r\ncentral biological question is how natural organisms are so evolvable (capa=\r\nble of quickly adapting to new environments). A key driver of evolvability =\r\nis the widespread modularity of biological networks=E2=80&quot;their organizatio=\r\nn as functional, sparsely connected subunits=E2=80&quot;but there is no consensu=\r\ns regarding why modularity itself evolved. Although most hypotheses assume =\r\nindirect selection for evolvability, here we demonstrate that the ubiquitou=\r\ns, direct selection pressure to reduce the cost of connections between netw=\r\nork nodes causes the emergence of modular networks. Computational evolution=\r\n experiments with selection pressures to maximize network performance and m=\r\ninimize connection costs yield networks that are significantly more modular=\r\n and more evolvable than control experiments that only select for performan=\r\nce. These results will catalyse research in numerous disciplines, such as n=\r\neuroscience and genetics, and enhance our ability to harness\n&gt; &gt; &gt; &gt; &gt; evol=\r\nution for engineering purposes.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Video:=C2 http://www.y=\r\noutube.com/watch?feature=3Dplayer_embedded&v=3DSG4_aW8LMng\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; &gt; There has been some nice coverage of this work in the popular press, i=\r\nn case you are interested:\n&gt; &gt; &gt; &gt; &gt; National Geographic:=C2 http://phenome=\r\nna.nationalgeographic.com/2013/01/30/the-parts-of-life/MIT&#39;s Technology Rev=\r\niew:=C2 http://www.technologyreview.com/view/428504/computer-scientists-rep=\r\nroduce-the-evolution-of-evolvability/=C2 Fast Company:=C2 http://www.fastco=\r\nmpany.com/3005313/evolved-brains-robots-creep-closer-animal-learningCornell=\r\n Chronicle:=C2 http://www.news.cornell.edu/stories/Jan13/modNetwork.htmlSci=\r\nenceDaily:=C2 http://www.sciencedaily.com/releases/2013/01/130130082300.htm=\r\n\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Please let me know what you think and if you have any=\r\n questions. I hope this work will help our field move forward!\n&gt; &gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Best regards,\n&gt; &gt; &gt; &gt; &gt; Jeff Clun=\r\ne\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Assistant Professor\n&gt; &gt; &gt; &gt; &gt; Computer Science\n&gt; &gt; &gt;=\r\n &gt; &gt; University of Wyoming\n&gt; &gt; &gt; &gt; &gt; jclune@\n&gt; &gt; &gt; &gt; &gt; jeffclune.com\n&gt; &gt; &gt; =\r\n&gt; &gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}