{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"TiAYeI3lCEIrrwZMMKMBfYVPPhwNh4ZIkXE-o1etzFuR8mD6A1KxvqcEHQ7UgAFC4N862g3D8c__1FsU8uFGETmt__ck1Q9OyDRBYl5BDjj-b_t3ZNE","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1210877861","msgId":4073,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwaTEzNSt0cTNtQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGcwaHFmbStscTZnQGVHcm91cHMuY29tPg=="},"prevInTopic":4072,"nextInTopic":4075,"prevInTime":4072,"nextInTime":4074,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"I am about to implement my first novelty search experiment but I encountered a problem I need to ask you about. Is it really necessary to use steady state","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 76491 invoked from network); 15 May 2008 18:57:42 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m55.grp.scd.yahoo.com with QMQP; 15 May 2008 18:57:42 -0000\r\nX-Received: from unknown (HELO n28b.bullet.scd.yahoo.com) (66.94.237.30)\n  by mta17.grp.scd.yahoo.com with SMTP; 15 May 2008 18:57:42 -0000\r\nX-Received: from [66.218.69.3] by n28.bullet.scd.yahoo.com with NNFMP; 15 May 2008 18:57:42 -0000\r\nX-Received: from [66.218.66.48] by t3.bullet.scd.yahoo.com with NNFMP; 15 May 2008 18:57:42 -0000\r\nDate: Thu, 15 May 2008 18:57:41 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g0i135+tq3m@...&gt;\r\nIn-Reply-To: &lt;g0hqfm+lq6g@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=283334584; y=p3q6VvkcU4-DyCAer7dmIjLhLHY1h5j3eOioxyxSh6ZwP7pJarKUTb1mYQ\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nI am about to implement my first novelty search experiment but I \nencounter=\r\ned a problem I need to ask you about. Is it really necessary \nto use steady=\r\n state evolution in the way Joel and you did? How can \nthe same dynamics wo=\r\nuld be applied with the generational-based NEAT? \nCan you give me a suggest=\r\nion? I appreciate any help. \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Kenneth =\r\nStanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Peter, it will probably take some time t=\r\no have well-researched \nanswers\n&gt; to this kind of question, but here is my =\r\nguess for the moment:  \nFirst,\n&gt; novelty search may have a tendency to avoi=\r\nd stagnation already \nbecause\n&gt; it includes the current population along wi=\r\nth the archive when it\n&gt; measures novelty.  So in effect, even if nothing i=\r\ns new \nhistorically,\n&gt; the population is still repelling itself away from w=\r\nhere it is\n&gt; currently.  That means that over time the population will kind=\r\n of\n&gt; dance around the behavior space until it hits a stepping stone to\n&gt; s=\r\nomething different.  It could take a long time, but at least it \nwill\n&gt; nev=\r\ner just sit still and &quot;give up&quot; the way fitness-based evolution\n&gt; tends to =\r\ndo when it converges prematurely.  Novelty search never\n&gt; &quot;feels&quot; like it h=\r\nas found an optimum because it is effectively\n&gt; coevolutionary and always l=\r\nooking to break free.\n&gt; \n&gt; There also may be something more active we can d=\r\no to push it out\n&gt; beyond this inherent dynamic.  Maybe there is a method o=\r\nf detecting\n&gt; that things are not diversifying well anymore and then pushin=\r\ng \nthings\n&gt; out.  Yet we would need to be careful because simply e.g. uppin=\r\ng the\n&gt; mutation rate might make things worse by knocking our population of=\r\nf\n&gt; the current set of behaviors back to something more primitive.  \nStill,=\r\n\n&gt; since this research direction is in its infancy, I&#39;d guess there \nwill\n&gt;=\r\n end up many creative ideas for dealing with various bad situations,\n&gt; just=\r\n as people have come up with all kinds of tricks to deal with\n&gt; pathologies=\r\n in fitness-based search. \n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com,=\r\n &quot;petar_chervenski&quot; &lt;petar_chervenski@&gt;\n&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Ken,\n&gt; &gt; \n&gt; &gt; t=\r\nhanks for this great post again, it answered many questions and \nit \n&gt; &gt; he=\r\nlped me get more insight in the philosophy behind NS. \n&gt; &gt; One question I h=\r\nave, how we could deal with stagnation even in \n&gt; &gt; novelty search, i.e. wh=\r\nen every new genome happens to be a known \n&gt; &gt; behavior? Is this possible a=\r\nt all? \n&gt; &gt; \n&gt; &gt; Peter\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanl=\r\ney&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Jeff,\n&gt; &gt; &gt; \n&gt; &gt; &gt; Thanks for asking the=\r\nse questions.  These are likely the kinds \nof\n&gt; &gt; &gt; questions we are going =\r\nto face over time so it&#39;s a good chance \nto \n&gt; &gt; work\n&gt; &gt; &gt; on our response=\r\n.  I&#39;m going to start with a technical response \nbut\n&gt; &gt; &gt; move to philosop=\r\nhical.  It&#39;s a bit of an essay but hopefully \nworth \n&gt; &gt; the\n&gt; &gt; &gt; read.\n&gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; Your first set of questions regards the relationship between \nno=\r\nvelty\n&gt; &gt; &gt; search (NS) and exhaustive search of behavioral space.  Do we \n=\r\nthink\n&gt; &gt; &gt; these are effectively the same thing?\n&gt; &gt; &gt; \n&gt; &gt; &gt; I think it&#39;s=\r\n a tricky subject but in the end I would not equate \nNS \n&gt; &gt; to\n&gt; &gt; &gt; exhau=\r\nstive search.  While NS indeed does attempt to essentially \n&gt; &gt; visit\n&gt; &gt; &gt;=\r\n every behavior in behavioral space, the way it does it is not \nthe \n&gt; &gt; sa=\r\nme\n&gt; &gt; &gt; as what is usually meant by exhaustive search.  We usually \nthink =\r\nof \n&gt; &gt; an\n&gt; &gt; &gt; exhaustive search as a purposeful enumeration, where if I =\r\njust \ntry\n&gt; &gt; &gt; every combination of something, one will be the answer.  A =\r\nkey \n&gt; &gt; feature\n&gt; &gt; &gt; of this type of search is that it does not require o=\r\nr utilize\n&gt; &gt; &gt; information or feedback of any kind as a guide.  Rather, it=\r\n \nsimply\n&gt; &gt; &gt; makes sure it does not visit the same point twice.  (It is \n=\r\nsimilar \n&gt; &gt; to\n&gt; &gt; &gt; random search except that random search might indeed =\r\nvisit the \nsame\n&gt; &gt; &gt; point twice.)\n&gt; &gt; &gt; \n&gt; &gt; &gt; One clear difference betwe=\r\nen such a search and NS is that we \ncannot\n&gt; &gt; &gt; purposefully enumerate all=\r\n possible behaviors because our \nsearch \n&gt; &gt; space\n&gt; &gt; &gt; is the genotype sp=\r\nace, which maps indirectly to the behavior \nspace. \n&gt; &gt; &gt; Therefore, there =\r\nis actually no way to simply say &quot;list all \npossible\n&gt; &gt; &gt; behaviors&quot; and t=\r\nry each one in succession.  We must seek them \nout.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Furthermor=\r\ne, in novelty search there is *information* guiding \nthe\n&gt; &gt; &gt; order of poi=\r\nnts we visit (the information is the novelty \nmeasure). \n&gt; &gt; &gt; The points a=\r\nlso have an inherent order (perhaps quite useful) \n&gt; &gt; induced\n&gt; &gt; &gt; by the=\r\n genetic encoding (hence the promise of combining it with\n&gt; &gt; &gt; HyperNEAT).=\r\n In other words, we are not simply enumerating in an\n&gt; &gt; &gt; arbitrary non-ov=\r\nerlapping order.  Rather, we follow the most \n&gt; &gt; promising\n&gt; &gt; &gt; trails th=\r\nat seem to be leading to something new.\n&gt; &gt; &gt; \n&gt; &gt; &gt; One significant conseq=\r\nuence of this fact is that the actual \nsearch\n&gt; &gt; &gt; space (which is the gen=\r\notype space) will almost certainly never \nneed\n&gt; &gt; &gt; to be exhaustively sea=\r\nrched.  So we effectively avoided wasting \nour\n&gt; &gt; &gt; time examining all kin=\r\nds of genetic combinations that would have\n&gt; &gt; &gt; produced redundant behavio=\r\nrs.  In its usual meaning, exhaustive \n&gt; &gt; search\n&gt; &gt; &gt; would be just such =\r\na search through genotype space.  So \ncertainly it\n&gt; &gt; &gt; is not normal exha=\r\nustive search.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Yet if you still want to talk about exhaustivel=\r\ny searching \nbehavior\n&gt; &gt; &gt; space, it is still not a typical exhaustive sea=\r\nrch because of \nthe \n&gt; &gt; fact\n&gt; &gt; &gt; it proceeds in an order guided by infor=\r\nmation- not typical of\n&gt; &gt; &gt; exhaustive search.  Another corollary is that =\r\nit is impossible \nto\n&gt; &gt; &gt; perform a typical exhaustive search of behavior =\r\nspace because \nwe \n&gt; &gt; have\n&gt; &gt; &gt; no method to enumerate it:  It must be ex=\r\nplored.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Yet you might still say, fine, semantically perhaps it=\r\n is \nsomething\n&gt; &gt; &gt; different, but still, in spirit are you not essentiall=\r\ny doing\n&gt; &gt; &gt; something equally inefficient, i.e. looking for absolutely \n&gt;=\r\n &gt; everything?  \n&gt; &gt; &gt; \n&gt; &gt; &gt; And it is true that in effect we are searchin=\r\ng for every \nbehavior, \n&gt; &gt; or\n&gt; &gt; &gt; at least every behavior that looks dis=\r\ntinguishable from each \nother\n&gt; &gt; &gt; with respect to the novelty metric and =\r\nin an order from \nsimplicity \n&gt; &gt; to\n&gt; &gt; &gt; high complexity.  Yet therein li=\r\nes the fundamental insight: \nWhile \n&gt; &gt; such\n&gt; &gt; &gt; a search might sound bad=\r\n, it is a lot better to look at \neverything \n&gt; &gt; (in\n&gt; &gt; &gt; some meaningful =\r\norder) and eventually run across what you want\n&gt; &gt; &gt; (perhaps after a very =\r\nlong time) than to look for one specific \nthing\n&gt; &gt; &gt; and *never* find it.\n=\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; We are indeed suggesting that this rather tortured choice \n(be=\r\ntween\n&gt; &gt; &gt; looking for something without hope and looking for everything) =\r\n\nis\n&gt; &gt; &gt; sometimes the real choice that we face with the most ambitious\n&gt; =\r\n&gt; &gt; problems.  In other words, objective-based fitness is literally \n&gt; &gt; do=\r\nomed\n&gt; &gt; &gt; when it comes to evolving many incredibly complex systems from\n&gt;=\r\n &gt; &gt; scratch.  It will simply never happen because at high levels of\n&gt; &gt; &gt; =\r\ncomplexity, there is going to be massive deception at many \nlevels, \n&gt; &gt; an=\r\nd\n&gt; &gt; &gt; fitness becomes as bad as random search in such a problem.  In \nfac=\r\nt,\n&gt; &gt; &gt; as our results show, you don&#39;t even have to make the problem \nall =\r\n\n&gt; &gt; that\n&gt; &gt; &gt; hard to cause fitness to crumble into something as bad as r=\r\nandom\n&gt; &gt; &gt; search.  What do you think will happen if you are trying to \nev=\r\nolve a\n&gt; &gt; &gt; neural network into the mind of a quantum physicist based on h=\r\now\n&gt; &gt; &gt; brilliant it is at quantum physics?  The answer: Nothing.\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; A more down-to-earth example is the car that I evolved on \n&gt; &gt; Picbree=\r\nder.\n&gt; &gt; &gt;  It could never have evolved if evolving a car had been the\n&gt; &gt; =\r\n&gt; *objective* because it was preceded by an alien face (evolved by\n&gt; &gt; &gt; so=\r\nmeone else).  It just so happens that the alien face is a \nstepping\n&gt; &gt; &gt; s=\r\ntone to a car, but if we had judged the alien face on it &quot;car-\n&gt; &gt; ness,&quot;\n&gt;=\r\n &gt; &gt; it would have failed miserably and been deleted.  Hence if we \nwere\n&gt; =\r\n&gt; &gt; looking for a car we would never have found one.\n&gt; &gt; &gt; \n&gt; &gt; &gt; In nature=\r\n, if we had bred flatworms (the earliest chordates) \nbased \n&gt; &gt; on\n&gt; &gt; &gt; th=\r\neir humanity, they too would have never evolved into \namphibians,\n&gt; &gt; &gt; the=\r\nn reptiles, then mammals, as they did.  The objective in \nlong-run\n&gt; &gt; &gt; pr=\r\noblems is totally blind to the necessary stepping stones.  \nUnless \n&gt; &gt; we\n=\r\n&gt; &gt; &gt; know them a priori, we are lost.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Why do you suppose we h=\r\nave never seen a flowering of diversity \nand\n&gt; &gt; &gt; complexity such as seen =\r\nin nature in evolutionary computation?  \nIn \n&gt; &gt; 30\n&gt; &gt; &gt; or 40 years of th=\r\nis field, which is inspired by nature, we have \n&gt; &gt; never\n&gt; &gt; &gt; seen someth=\r\ning that comes even close to even nature&#39;s modest\n&gt; &gt; &gt; achievements.  The =\r\nproblem is that we have been blinded by \n&gt; &gt; objectives.\n&gt; &gt; &gt;    As soon a=\r\ns we set an objective, the stepping stones to it \noften\n&gt; &gt; &gt; vanish into t=\r\nhin air.  There is no escape from this very \nsobering\n&gt; &gt; &gt; fact.  It will =\r\nhave to be accepted, though it will be hard to \n&gt; &gt; accept.\n&gt; &gt; &gt; \n&gt; &gt; &gt; No=\r\nvelty search cures this problem, although admittedly in a \npainful\n&gt; &gt; &gt; wa=\r\ny, because it forces us to let go of our natural desire to \n&gt; &gt; *control*\n&gt;=\r\n &gt; &gt; what is happening.  We feel compelled to demand to the search\n&gt; &gt; &gt; al=\r\ngorithm that it go in a certain direction.  It is difficult to\n&gt; &gt; &gt; relinq=\r\nuish this feeling of control, yet if we recognize that in \nthe\n&gt; &gt; &gt; end th=\r\ne setting of such goals is its own worst enemy, then we \ncan\n&gt; &gt; &gt; begin to=\r\n be liberated from this longstanding compulsion.\n&gt; &gt; &gt; \n&gt; &gt; &gt; (Note that I =\r\nam not saying fitness is always useless; obviously \nthat\n&gt; &gt; &gt; is not the c=\r\nase.  I am talking about very ambitious problems, \nbeyond\n&gt; &gt; &gt; the kind we=\r\n have been able to solve yet- though even the &quot;hard \nmaze&quot;\n&gt; &gt; &gt; is borderi=\r\nng on such a problem.)\n&gt; &gt; &gt; \n&gt; &gt; &gt; You point out that novelty search may g=\r\net &quot;lost&quot; in a kind of \n&gt; &gt; endless\n&gt; &gt; &gt; offshoot in behavior space.  And =\r\nyes, in some situations, it \nvery \n&gt; &gt; well\n&gt; &gt; &gt; may.  Yet I believe it wi=\r\nll not do so in many interesting \ndomains. \n&gt; &gt; &gt; For example, if there was=\r\n indeed a long offshoot of the maze, \nfirst,\n&gt; &gt; &gt; since there is a time li=\r\nmit for each robot, it would make little\n&gt; &gt; &gt; difference and would quickly=\r\n be filled up by novelty search.  \nIf \n&gt; &gt; there\n&gt; &gt; &gt; are no obstacles in =\r\nthe offshoot, it would be filled especially \n&gt; &gt; fast.\n&gt; &gt; &gt;  But at the sa=\r\nme time, novelty search is not likely to go off \nin \n&gt; &gt; only\n&gt; &gt; &gt; one dir=\r\nection anyway.  Because it is a population, it will go \noff in\n&gt; &gt; &gt; many d=\r\nirections at once.  While some parts may shoot down the\n&gt; &gt; &gt; diversionary =\r\noffshoot, at the same time others will begin to \nflow \n&gt; &gt; down\n&gt; &gt; &gt; the p=\r\naths we want.  If it happens to take the wrong paths, it \nwill\n&gt; &gt; &gt; fill t=\r\nhat areas first and eventually be pushed back into the \nareas \n&gt; &gt; we\n&gt; &gt; &gt;=\r\n care about (only if each individual was given infinite time \ncould it\n&gt; &gt; =\r\n&gt; be stuck in one area forever)\n&gt; &gt; &gt; \n&gt; &gt; &gt; In the end, of course there is=\r\n a chance it will fail to go the \nright\n&gt; &gt; &gt; way in reasonable time; after=\r\n all, it has no objective!  In \nfact, in\n&gt; &gt; &gt; the hard maze experiment, it=\r\n did once fail to find a solution \nin 40\n&gt; &gt; &gt; runs.  Yet look at how much =\r\nmore consistent it is than fitness-\nbased\n&gt; &gt; &gt; search.  So the point is no=\r\nt that this is a guarantee (there \nwill\n&gt; &gt; &gt; never be one).  Rather, it is=\r\n a profoundly different kind of \nsearch,\n&gt; &gt; &gt; which is likely to reach pla=\r\nces that fitness-based search can \nnever\n&gt; &gt; &gt; hope to touch.  So it opens =\r\nup a whole new world of \npossibilities to\n&gt; &gt; &gt; evolutionary computation.  =\r\nThat does not mean it solves \neverything; \n&gt; &gt; of\n&gt; &gt; &gt; course it may still=\r\n not always give us what we want.  There is \nno\n&gt; &gt; &gt; method that will ever=\r\n always give you what you want.  Yet \nobjective\n&gt; &gt; &gt; fitness is often even=\r\n worse.  That is the sobering moral of the \n&gt; &gt; story.\n&gt; &gt; &gt; \n&gt; &gt; &gt; So in m=\r\ny view, NS is actually suited for exactly those &quot;large \n&gt; &gt; spaces&quot;\n&gt; &gt; &gt; t=\r\nhat you suggest it will have trouble in.  And by large I mean \n&gt; &gt; LARGE.\n&gt;=\r\n &gt; &gt;  Those are the ones where objective-based fitness has no hope.  \n&gt; &gt; T=\r\nhese\n&gt; &gt; &gt; are spaces like life on earth, where it would be futile (and \nsi=\r\nlly) \n&gt; &gt; to\n&gt; &gt; &gt; start with a single cell and select offspring based on r=\r\nelative\n&gt; &gt; &gt; humanity.  The only reason we got to humans in nature is beca=\r\nuse\n&gt; &gt; &gt; nobody said we had to get there.  It&#39;s almost paradoxical, but \ni=\r\nf \n&gt; &gt; you\n&gt; &gt; &gt; accept it, it is an exciting liberation.  If we let go of =\r\nthe\n&gt; &gt; &gt; compulsion to be in control, we may find something we did not \nex=\r\npect\n&gt; &gt; &gt; that is quite significant.\n&gt; &gt; &gt; \n&gt; &gt; &gt; So actually the idea of =\r\nrunning fitness-based search and then \n&gt; &gt; novelty\n&gt; &gt; &gt; search is less exc=\r\niting to us although we raise it as a \npractical\n&gt; &gt; &gt; matter.  In some dom=\r\nains, objective fitness is simply impotent, \nand\n&gt; &gt; &gt; the compulsion to ha=\r\nve some shred of guidance to hang onto is a \n&gt; &gt; false\n&gt; &gt; &gt; comfort.  We w=\r\nill have to let go, and then, strangely, we will \nend \n&gt; &gt; up\n&gt; &gt; &gt; where w=\r\ne want to be.  It&#39;s like when your grandparents told you \nthat\n&gt; &gt; &gt; if you=\r\n stop worrying so much about making things work out, they \nwill\n&gt; &gt; &gt; work =\r\nout on their own.  Did you believe them?  Maybe there is \nmore\n&gt; &gt; &gt; wisdom=\r\n in it than there appeared to be.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; --- =\r\nIn neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hello.=\r\n \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Thanks for the thought provoking paper. Here is my main =\r\n\nquestion\n&gt; &gt; &gt; regarding\n&gt; &gt; &gt; &gt; the work: How would you differentiate the=\r\n NSA (novelty search \n&gt; &gt; algorithm)\n&gt; &gt; &gt; &gt; from exhaustive search in the =\r\nbehavior space?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; If you think there is a relevant differenc=\r\ne between the NSA \nand\n&gt; &gt; &gt; exhaustive\n&gt; &gt; &gt; &gt; behavioral search, have you=\r\n tried using the former as a \ncontrol \n&gt; &gt; and\n&gt; &gt; &gt; seeing\n&gt; &gt; &gt; &gt; how the=\r\ny compare?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; If the NSA is effectively exhaustive search in =\r\nbehavior \nspace, it\n&gt; &gt; &gt; seems to\n&gt; &gt; &gt; &gt; me that, while it will work well=\r\n (and better than a GA) in \nsmall,\n&gt; &gt; &gt; deceptive\n&gt; &gt; &gt; &gt; landscapes, it w=\r\nill not perform very well in large search \nspaces.\n&gt; &gt; &gt; Imagine,\n&gt; &gt; &gt; &gt; f=\r\nor example, the paper&#39;s &quot;medium map&quot; but with a huge (near\n&gt; &gt; &gt; infinite) =\r\nopen\n&gt; &gt; &gt; &gt; area to the left of the starting condition. It could easily \ng=\r\net \n&gt; &gt; lost\n&gt; &gt; &gt; over\n&gt; &gt; &gt; &gt; there indefinitely.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; You me=\r\nntion that it helps to have the domain constrain the \nsearch \n&gt; &gt; space.\n&gt; =\r\n&gt; &gt; &gt; Does this just mean that the (behavioral) search space has to \nbe \n&gt; =\r\n&gt; small\n&gt; &gt; &gt; &gt; enough that it can an exhaustive search can deal with it? H=\r\now \nwill\n&gt; &gt; &gt; it fare\n&gt; &gt; &gt; &gt; in the much larger search spaces of real-wor=\r\nld problems, like \n&gt; &gt; checkers?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Using the NSA as somethin=\r\ng to bail out objective-search when \nit\n&gt; &gt; &gt; stagnates is\n&gt; &gt; &gt; &gt; an inter=\r\nesting suggestion. But at that point it should be \n&gt; &gt; compared to\n&gt; &gt; &gt; &gt; =\r\nfitness sharing. Would it do better than fitness sharing? I \ncan \n&gt; &gt; think=\r\n of\n&gt; &gt; &gt; &gt; reasons it might (because it truly is not tempted by deceptive\n=\r\n&gt; &gt; &gt; traps), but\n&gt; &gt; &gt; &gt; it would useful to see it compared to fitness sha=\r\nring \ncontrols.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Just my 2 cents. Thanks for putting this o=\r\nut there.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; &gt; Jeff Clune\n&gt; &gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; &gt; Digital Evolution Lab, Michigan State University\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; jclu=\r\nne@\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; From: Kenneth Stanley &lt;ks=\r\ntanley@&gt;\n&gt; &gt; &gt; &gt; &gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; Date: Fri, 09 May 2008 02:00:33 -0000\n&gt; &gt; &gt; &gt; &gt; To: &quot;neat@yahoogr=\r\noups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; &gt; &gt; Subject: [neat] Introducing a Ne=\r\nw Approach to Search: \nNovelty\n&gt; &gt; &gt; Search (New\n&gt; &gt; &gt; &gt; &gt; Paper)\n&gt; &gt; &gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; &gt; &gt; Joel Lehman and I are excited to announce our new \npublication =\r\nto\n&gt; &gt; &gt; &gt; &gt; appear in the Eleventh International Conference on \nArticifial=\r\n \n&gt; &gt; Life\n&gt; &gt; &gt; &gt; &gt; (ALIFE XI), called &quot;Exploiting Open-Endedness to Solve=\r\n \nProblems\n&gt; &gt; &gt; &gt; &gt; Through the Search for Novelty.&quot;\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =\r\nThe paper is here:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; http://eplex.cs.ucf.edu/publication=\r\ns.html#lehman.alife08\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Direct link: \nhttp://eplex.cs.uc=\r\nf.edu/papers/lehman_alife08.pdf\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; This paper is about a =\r\nnew kind of search (which works with \n&gt; &gt; NEAT) that\n&gt; &gt; &gt; &gt; &gt; abandons the=\r\n longstanding notion in all of machine learning \n&gt; &gt; that the\n&gt; &gt; &gt; &gt; &gt; gra=\r\ndient of search should be measured with respect to the \n&gt; &gt; ultimate\n&gt; &gt; &gt; =\r\n&gt; &gt; objective.  In other words, it entirely abandons objectives \nand\n&gt; &gt; &gt; =\r\n&gt; &gt; thereby also abandons fitness functions as the impetus for \n&gt; &gt; search.=\r\n\n&gt; &gt; &gt; &gt; &gt; Yet remarkably, we still show that such an algorithm can \nperfor=\r\nm\n&gt; &gt; &gt; &gt; &gt; *better* than one that actually tries to achieve the \n&gt; &gt; objec=\r\ntive!  I\n&gt; &gt; &gt; &gt; &gt; believe this strange result has fascinating implications=\r\n \nfor \n&gt; &gt; machine\n&gt; &gt; &gt; &gt; &gt; learning, artificial life, and even biology.\n&gt;=\r\n &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Lately on this forum we have often discussed the naggin=\r\ng \n&gt; &gt; problem that\n&gt; &gt; &gt; &gt; &gt; the fitness function often does not properly =\r\nrecognize or \n&gt; &gt; reward the\n&gt; &gt; &gt; &gt; &gt; stepping stones on the way to the so=\r\nlution.  I went as far \nas\n&gt; &gt; &gt; &gt; &gt; suggesting that the fitness function c=\r\nan become an \n*obstacle* to\n&gt; &gt; &gt; &gt; &gt; success (e.g. when we discussed creat=\r\nivity in Picbreeder).\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; While this discussion was largel=\r\ny philosophical, Joel \nLehman \n&gt; &gt; and I\n&gt; &gt; &gt; &gt; &gt; decided to make it concr=\r\nete and actually introduce an \nalgorithm \n&gt; &gt; that\n&gt; &gt; &gt; &gt; &gt; makes an autom=\r\nated evolutionary process in *any* domain \nbehave \n&gt; &gt; like\n&gt; &gt; &gt; &gt; &gt; human=\r\ns in Picbreeder, that is, like open-ended evolution.  \nThis\n&gt; &gt; &gt; &gt; &gt; appro=\r\nach is called &quot;novelty search.&quot;  The algorithm simply \n&gt; &gt; searches\n&gt; &gt; &gt; &gt;=\r\n &gt; for behavior that is novel with respect to what has come \nbefore.\n&gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; &gt; The benefit of this approach is that it is immune to \ndecept=\r\nion \n&gt; &gt; because\n&gt; &gt; &gt; &gt; &gt; it does not even try to achieve the objective.  =\r\nI know it \nseems\n&gt; &gt; &gt; &gt; &gt; strange but, counterintuitively, we show that in=\r\n fact it is \nfar \n&gt; &gt; more\n&gt; &gt; &gt; &gt; &gt; effective at solving a difficult probl=\r\nem in a deceptive \n&gt; &gt; landscape than\n&gt; &gt; &gt; &gt; &gt; fitness-based search.\n&gt; &gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; In other words, what we are saying is that to achieve some =\r\n\nof \n&gt; &gt; the most\n&gt; &gt; &gt; &gt; &gt; ambitious objectives we might have for evolutio=\r\nn, we must \n&gt; &gt; abandon\n&gt; &gt; &gt; &gt; &gt; trying to explicitly achieve them.  To qu=\r\note from the end \nof our\n&gt; &gt; &gt; &gt; &gt; Discussion section:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;=\r\n &quot;In summary, almost like a riddle, novelty search suggests\n&gt; &gt; &gt; &gt; &gt; a sur=\r\nprising new perspective on achievement: To achieve\n&gt; &gt; &gt; &gt; &gt; your highest g=\r\noals, you must be willing to abandon them.&quot;\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; I believe =\r\nthis lesson is true in practice and is therefore \n&gt; &gt; beyond a\n&gt; &gt; &gt; &gt; &gt; ph=\r\nilosophical curiosity.  In fact, we are instinctively \n&gt; &gt; familiar with\n&gt; =\r\n&gt; &gt; &gt; &gt; it in life in general when people say things like &quot;You are \n&gt; &gt; try=\r\ning too\n&gt; &gt; &gt; &gt; &gt; hard&quot; or when we focus so much on something so far ahead =\r\nof \nus \n&gt; &gt; in life\n&gt; &gt; &gt; &gt; &gt; that we forget completely to solve the short =\r\nterm problems \nthat \n&gt; &gt; stand\n&gt; &gt; &gt; &gt; &gt; in our way.  It is no less true in=\r\n evolution or search in \n&gt; &gt; general.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; For NEAT, novelt=\r\ny search should open up new opportunities \nfor\n&gt; &gt; &gt; &gt; &gt; discovery that wer=\r\ne previously closed off to us.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; I look forward to heari=\r\nng your thoughts on this work.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt;=\r\n &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}