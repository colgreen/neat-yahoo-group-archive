{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":150549975,"authorName":"Jeff Morton","from":"&quot;Jeff Morton&quot; &lt;jeffrmorton@...&gt;","profile":"jeffm02860","replyTo":"LIST","senderId":"2XQ9PU3tRqUlUvqSLCWLEMwWPxd-3z-v3gJY4kuGkg7FfaSQUNHy7gRSTHJcnIl_bE-4rUSqw6qcem6HPvDx0N5FTxJ701dqph0","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Evolving a Trading Strategy: Update","postDate":"1157771740","msgId":2737,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwMGEwMWM2ZDNiZSQzYTg4ODNmMCQwMjAyYThjMEBIb3VzZT4=","referencesHeader":"PDQ0RkY0ODNCLjMwNDA0MDZAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":2734,"nextInTopic":2738,"prevInTime":2736,"nextInTime":2738,"topicId":2733,"numMessagesInTopic":13,"msgSnippet":"I d like to introduce myself since I m basically doing the same thing you are and would like to interact with other idividuals about this.  I ve read a","rawEmail":"Return-Path: &lt;jeffrmorton@...&gt;\r\nX-Sender: jeffrmorton@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 13511 invoked from network); 9 Sep 2006 03:16:41 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m29.grp.scd.yahoo.com with QMQP; 9 Sep 2006 03:16:41 -0000\r\nReceived: from unknown (HELO eastrmmtao02.cox.net) (68.230.240.37)\n  by mta6.grp.scd.yahoo.com with SMTP; 9 Sep 2006 03:16:40 -0000\r\nReceived: from eastrmimpo01.cox.net ([68.1.16.119]) by eastrmmtao02.cox.net\n          (InterMail vM.6.01.06.01 201-2131-130-101-20060113) with ESMTP\n          id &lt;20060909031514.ROKM10599.eastrmmtao02.cox.net@...&gt;\n          for &lt;neat@yahoogroups.com&gt;; Fri, 8 Sep 2006 23:15:14 -0400\r\nReceived: from House ([72.200.154.46])\n\tby eastrmimpo01.cox.net with bizsmtp\n\tid L3Ez1V00c10KtFs0000000\n\tFri, 08 Sep 2006 23:15:00 -0400\r\nMessage-ID: &lt;000a01c6d3be$3a8883f0$0202a8c0@House&gt;\r\nTo: &lt;neat@yahoogroups.com&gt;\r\nReferences: &lt;44FF483B.3040406@...&gt;\r\nDate: Fri, 8 Sep 2006 23:15:40 -0400\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_0007_01C6D39C.B3308C20&quot;\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2900.2869\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.2962\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: &quot;Jeff Morton&quot; &lt;jeffrmorton@...&gt;\r\nSubject: Re: [neat] Evolving a Trading Strategy: Update\r\nX-Yahoo-Group-Post: member; u=150549975; y=C_phY_-Fjzj3zp_6V03NuchxujIe1vsFsIOb0NBCG-lpD7Vn-w\r\nX-Yahoo-Profile: jeffm02860\r\n\r\n\r\n------=_NextPart_000_0007_01C6D39C.B3308C20\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nI&#39;d like to introduce myself since I&#39;m basically doing the same thing you a=\r\nre and would like to interact with other idividuals about this.  I&#39;ve read =\r\na significant number of published academic papers on the subject of using n=\r\neural networks to forecast financial markets, and it appears to me that the=\r\n majority of experiments produce results which are better than chance.  I&#39;v=\r\ne also read several news articles in recent past about these techniques bei=\r\nng used by financial institutions, but the actual information on how they w=\r\nork is always missing.  Clearly there is a natural human instinct to defend=\r\n information which is advantageous to survival, and I believe the evidence =\r\nfor this occuring here is intuitively obvious.\n\nI&#39;ve been working on an app=\r\nlication (a toolbox of sorts) which is capable of evolving trading strategi=\r\nes based on common technical indicators  with variable time frames through =\r\nthe use of basic genetic algorithms.  I am interested in creating component=\r\n indicators based on simple neural networks and intend to utilize the Shapr=\r\nNEAT code (btw, thank you to the author who ported this) to build these net=\r\nworks.\n\nSince you are already doing this I was wondering if you would be wi=\r\nlling to share the code you&#39;ve developed so far.  You mentioned that you we=\r\nre lacking in market data to train your networks.  I&#39;ve developed a simple =\r\ntool to import US market data from YAHOO finance if you are interested.  Co=\r\nmpressed, the data is approximately 500 megs and contians the nasdaq, nyse,=\r\n amex, nasdaq fund market, and some of the otcbb issues.  I have a tool to =\r\nscan this data for logical anomalies and the data seems very clean. \n\n\n  --=\r\n--- Original Message ----- \n  From: Colin Green \n  To: neat@yahoogroups.com=\r\n \n  Sent: Wednesday, September 06, 2006 6:14 PM\n  Subject: [neat] Evolving =\r\na Trading Strategy: Update\n\n\n  Hi,\n\n  OK so over the weekend I modified my =\r\nexperiments to use Z-Score inputs \n  along with continuous means and standa=\r\nrd deviations. I&#39;ve been running \n  an experiment for a few days now over 1=\r\n63 days worth of data for 521 of \n  the most traded companies on the LSE, a=\r\nnd in terms of profit/fitness the \n  result so far is about 40% higher than=\r\n my previous best strategy. \n\n  So in terms of presenting the data in a way=\r\n that an ANN and NEAT can \n  capitalise upon this approach would seem to be=\r\n much better, but as far \n  as evolving a useable trading strategy is conce=\r\nrned this has just \n  highighted once again that the data set is far too sm=\r\nall and that \n  overfitting is therefore a serious problem. Now I don&#39;t kno=\r\nw how much of \n  this high score is due to overfitting, but from previous e=\r\nxperience and \n  common sense I estimate it to be close to 100% ! To try an=\r\nd answer this \n  question I&#39;ll be running the experiment again over the nex=\r\nt few days \n  with a subset of that 163 day data set, plus I&#39;ll have an ext=\r\nra 10 days \n  worth of data at the end of this week which will also give so=\r\nme clues - \n  actually I already have 5 days of data it wasn&#39;t trained agai=\r\nnst and it \n  makes two losing trades on that :(\n\n  Part of the problem is =\r\nthat although I have data for 521 companies, \n  these aren&#39;t 521 independen=\r\nt data sets because the price graph for a lot \n  of these companies is very=\r\n similar. Mostly the champ trader is \n  capitalising on a sharp fall in the=\r\n markets in May and the subsequent \n  partial recovery. So a strategy that =\r\ndetects and capitalises on that \n  scenario matches a lot of those 521 comp=\r\nanies and therefore scores well.\n\n  So going forward it looks like I&#39;ll be =\r\nputting my &#39;high quality&#39; data \n  (with buy/sell volume, buy/sell trades an=\r\nd bid/offer spread) to one side \n  and using a data set with a far longer h=\r\nistory but probably less \n  quality, e.g. just the closing [mid] price and =\r\nvolume (actually I use \n  money flow which =3D volume * share price) simply=\r\n on the basis that high \n  quality data costs a lot of money. Although init=\r\nially I might look at \n  trading the major indices (FTSE, DJIA, S&P etc.) o=\r\nr perhaps currency \n  markets if the data is available.\n\n  One problem I en=\r\nvisage with longer histories is that older data may be \n  fairly useless in=\r\n evolving a trading strategy for the present, since no \n  doubt automated t=\r\nrading and semi-automatic analysis/trading has probably \n  been progressing=\r\n in leaps and bounds in the last 5 years or so, thus \n  fundamentally alter=\r\ning the short term dynamics of the markets. However \n  if that is the case =\r\nit might actually show up in experiments - e.g. if a \n  strategy evolves th=\r\nat does really well for several years in a row and \n  then starts doing bad=\r\nly for a long period.\n\n  So on the whole it&#39;s very interesting that NEAT ha=\r\ns found a strategy \n  that performs really well over the provided data set,=\r\n but all this does \n  for now is provide food for thought for the next roun=\r\nd of experimentation.\n\n  Regards,\n\n  Colin\n\n\n\n   \r\n------=_NextPart_000_0007_01C6D39C.B3308C20\r\nContent-Type: text/html;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.=\r\nw3c.org/TR/1999/REC-html401-19991224/loose.dtd&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;\n&lt;META http-eq=\r\nuiv=3DContent-Type content=3D&quot;text/html; charset=3Diso-8859-1&quot;&gt;&lt;!-- Network=\r\n content --&gt;\n&lt;META content=3D&quot;MSHTML 6.00.2900.2963&quot; name=3DGENERATOR&gt;&lt;/HEA=\r\nD&gt;\n&lt;BODY style=3D&quot;BACKGROUND-COLOR: #ffffff&quot; bgColor=3D#ffffff&gt;\n&lt;DIV&gt;&lt;FONT =\r\nface=3DArial size=3D2&gt;I&#39;d like to introduce myself since I&#39;m basically \ndoi=\r\nng the same thing you&nbsp;are and would like to interact with other \nidivi=\r\nduals about this.&nbsp;&nbsp;I&#39;ve read a significant number of published \na=\r\ncademic papers on the subject of using neural networks to forecast financia=\r\nl \nmarkets, and it appears to me that the majority of experiments produce r=\r\nesults \nwhich are better than chance.&nbsp; I&#39;ve also read several news art=\r\nicles in \nrecent past about these techniques being used by financial instit=\r\nutions, but the \nactual information on how they work is always missing.&nbs=\r\np; Clearly there is a \nnatural human instinct to defend information which i=\r\ns advantageous to survival, \nand I believe the evidence for this occuring h=\r\nere is intuitively \nobvious.&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT face=3DArial size=3D2&gt;=\r\n&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT face=3DArial size=3D2&gt;I&#39;ve been working on a=\r\nn application (a toolbox of \nsorts) which is capable of evolving trading st=\r\nrategies based on common technical \nindicators&nbsp; with variable time fra=\r\nmes through the use of basic genetic \nalgorithms.&nbsp; I am interested in =\r\ncreating component indicators based on \nsimple neural networks and intend t=\r\no utilize the ShaprNEAT code (btw, thank you \nto the author who ported this=\r\n) to build these networks.&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT face=\r\n=3DArial size=3D2&gt;Since you are already doing this I&nbsp;was \nwondering if=\r\n you would be willing to share the code you&#39;ve developed so \nfar.&nbsp;&nbs=\r\np;You mentioned that you were lacking in market data to train your \nnetwork=\r\ns.&nbsp; I&#39;ve developed a simple tool to import US market data from YAHOO \n=\r\nfinance if you are interested.&nbsp; Compressed, the data is approximately =\r\n500 \nmegs and contians the nasdaq, nyse, amex, nasdaq fund market, and some=\r\n of the \notcbb&nbsp;issues.&nbsp; I have&nbsp;a tool to scan this data for =\r\nlogical \nanomalies and the data seems very clean.&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;=\r\nFONT face=3DArial size=3D2&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT face=3DArial size=\r\n=3D2&gt;&lt;/FONT&gt;&lt;FONT face=3DArial size=3D2&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;BLOCKQUOTE \nst=\r\nyle=3D&quot;PADDING-RIGHT: 0px; PADDING-LEFT: 5px; MARGIN-LEFT: 5px; BORDER-LEFT=\r\n: #000000 2px solid; MARGIN-RIGHT: 0px&quot;&gt;\n  &lt;DIV style=3D&quot;FONT: 10pt arial&quot;&gt;=\r\n----- Original Message ----- &lt;/DIV&gt;\n  &lt;DIV \n  style=3D&quot;BACKGROUND: #e4e4e4;=\r\n FONT: 10pt arial; font-color: black&quot;&gt;&lt;B&gt;From:&lt;/B&gt; \n  &lt;A title=3Dcgreen@dsl=\r\n.pipex.com href=3D&quot;mailto:cgreen@...&quot;&gt;Colin \n  Green&lt;/A&gt; &lt;/DIV&gt;\n =\r\n &lt;DIV style=3D&quot;FONT: 10pt arial&quot;&gt;&lt;B&gt;To:&lt;/B&gt; &lt;A title=3Dneat@yahoogroups.com=\r\n \n  href=3D&quot;mailto:neat@yahoogroups.com&quot;&gt;neat@yahoogroups.com&lt;/A&gt; &lt;/DIV&gt;\n  =\r\n&lt;DIV style=3D&quot;FONT: 10pt arial&quot;&gt;&lt;B&gt;Sent:&lt;/B&gt; Wednesday, September 06, 2006 =\r\n6:14 \n  PM&lt;/DIV&gt;\n  &lt;DIV style=3D&quot;FONT: 10pt arial&quot;&gt;&lt;B&gt;Subject:&lt;/B&gt; [neat] E=\r\nvolving a Trading \n  Strategy: Update&lt;/DIV&gt;\n  &lt;DIV&gt;&lt;BR&gt;&lt;/DIV&gt;\n  &lt;DIV id=3Dy=\r\ngrp-text&gt;\n  &lt;P&gt;Hi,&lt;BR&gt;&lt;BR&gt;OK so over the weekend I modified my experiments =\r\nto use Z-Score \n  inputs &lt;BR&gt;along with continuous means and standard devia=\r\ntions. I&#39;ve been \n  running &lt;BR&gt;an experiment for a few days now over 163 d=\r\nays worth of data for \n  521 of &lt;BR&gt;the most traded companies on the LSE, a=\r\nnd in terms of \n  profit/fitness the &lt;BR&gt;result so far is about 40% higher =\r\nthan my previous best \n  strategy. &lt;BR&gt;&lt;BR&gt;So in terms of presenting the da=\r\nta in a way that an ANN and \n  NEAT can &lt;BR&gt;capitalise upon this approach w=\r\nould seem to be much better, but \n  as far &lt;BR&gt;as evolving a useable tradin=\r\ng strategy is concerned this has just \n  &lt;BR&gt;highighted once again that the=\r\n data set is far too small and that \n  &lt;BR&gt;overfitting is therefore a serio=\r\nus problem. Now I don&#39;t know how much of \n  &lt;BR&gt;this high score is due to o=\r\nverfitting, but from previous experience and \n  &lt;BR&gt;common sense I estimate=\r\n it to be close to 100% ! To try and answer this \n  &lt;BR&gt;question I&#39;ll be ru=\r\nnning the experiment again over the next few days \n  &lt;BR&gt;with a subset of t=\r\nhat 163 day data set, plus I&#39;ll have an extra 10 days \n  &lt;BR&gt;worth of data =\r\nat the end of this week which will also give some clues - \n  &lt;BR&gt;actually I=\r\n already have 5 days of data it wasn&#39;t trained against and it \n  &lt;BR&gt;makes =\r\ntwo losing trades on that :(&lt;BR&gt;&lt;BR&gt;Part of the problem is that \n  although=\r\n I have data for 521 companies, &lt;BR&gt;these aren&#39;t 521 independent data \n  se=\r\nts because the price graph for a lot &lt;BR&gt;of these companies is very similar=\r\n. \n  Mostly the champ trader is &lt;BR&gt;capitalising on a sharp fall in the mar=\r\nkets in \n  May and the subsequent &lt;BR&gt;partial recovery. So a strategy that =\r\ndetects and \n  capitalises on that &lt;BR&gt;scenario matches a lot of those 521 =\r\ncompanies and \n  therefore scores well.&lt;BR&gt;&lt;BR&gt;So going forward it looks li=\r\nke I&#39;ll be putting \n  my &#39;high quality&#39; data &lt;BR&gt;(with buy/sell volume, buy=\r\n/sell trades and \n  bid/offer spread) to one side &lt;BR&gt;and using a data set =\r\nwith a far longer \n  history but probably less &lt;BR&gt;quality, e.g. just the c=\r\nlosing [mid] price and \n  volume (actually I use &lt;BR&gt;money flow which =3D v=\r\nolume * share price) simply on \n  the basis that high &lt;BR&gt;quality data cost=\r\ns a lot of money. Although initially \n  I might look at &lt;BR&gt;trading the maj=\r\nor indices (FTSE, DJIA, S&amp;P etc.) or \n  perhaps currency &lt;BR&gt;markets if=\r\n the data is available.&lt;BR&gt;&lt;BR&gt;One problem I \n  envisage with longer histor=\r\nies is that older data may be &lt;BR&gt;fairly useless in \n  evolving a trading s=\r\ntrategy for the present, since no &lt;BR&gt;doubt automated \n  trading and semi-a=\r\nutomatic analysis/trading has probably &lt;BR&gt;been progressing \n  in leaps and=\r\n bounds in the last 5 years or so, thus &lt;BR&gt;fundamentally altering \n  the s=\r\nhort term dynamics of the markets. However &lt;BR&gt;if that is the case it \n  mi=\r\nght actually show up in experiments - e.g. if a &lt;BR&gt;strategy evolves that \n=\r\n  does really well for several years in a row and &lt;BR&gt;then starts doing bad=\r\nly \n  for a long period.&lt;BR&gt;&lt;BR&gt;So on the whole it&#39;s very interesting that =\r\nNEAT has \n  found a strategy &lt;BR&gt;that performs really well over the provide=\r\nd data set, but \n  all this does &lt;BR&gt;for now is provide food for thought fo=\r\nr the next round of \n  experimentation.&lt;BR&gt;&lt;BR&gt;Regards,&lt;BR&gt;&lt;BR&gt;Colin&lt;BR&gt;&lt;BR=\r\n&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;!--End group email --&gt;&lt;/BLOCKQUOTE&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_0007_01C6D39C.B3308C20--\r\n\n"}}