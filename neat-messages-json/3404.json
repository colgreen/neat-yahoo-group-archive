{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"TQZZxzw8IxqhFBk1B3BoiiXcrRRyKsv1DM6MDwd2UFkLdMWS6zxG26yzvcAqQ8pgeYmRiWMaGViG7GMQNEaiGABqlh8BjBxMUnxbgREMQwBu0AYcWyk","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: ANJI : NEAT implementation (fingerprint implementation issues)","postDate":"1181852040","msgId":3404,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY0czdpOCtoYmsyQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDhkOGZmZTM0MDcwNjE0MTI0MG8zMTdjYzFjNnY4YzlmMTY0YjBhZGZlNGFAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":3403,"nextInTopic":3405,"prevInTime":3403,"nextInTime":3405,"topicId":3384,"numMessagesInTopic":37,"msgSnippet":"This is not rotation, but a mirror image. This would not preserve, say a triangle in the input space will be very deformed as a result. The way to realize","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 84662 invoked from network); 14 Jun 2007 20:16:28 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m45.grp.scd.yahoo.com with QMQP; 14 Jun 2007 20:16:28 -0000\r\nReceived: from unknown (HELO n28.bullet.scd.yahoo.com) (66.94.237.21)\n  by mta7.grp.scd.yahoo.com with SMTP; 14 Jun 2007 20:16:28 -0000\r\nReceived: from [66.218.69.4] by n28.bullet.scd.yahoo.com with NNFMP; 14 Jun 2007 20:14:01 -0000\r\nReceived: from [66.218.66.75] by t4.bullet.scd.yahoo.com with NNFMP; 14 Jun 2007 20:14:01 -0000\r\nDate: Thu, 14 Jun 2007 20:14:00 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f4s7i8+hbk2@...&gt;\r\nIn-Reply-To: &lt;8d8ffe340706141240o317cc1c6v8c9f164b0adfe4a@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: ANJI : NEAT implementation (fingerprint implementation issues)\r\nX-Yahoo-Group-Post: member; u=283334584; y=5cK0aMYM8IiVv-BOazSDF4bIAWloADocsuwDbAAHh-oTxz9cR5qRafstbw\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nThis is not rotation, but a mirror image. This would not preserve, \nsay a t=\r\nriangle in the input space will be very deformed as a result. \nThe way to r=\r\nealize rotation is probably distinct inputs/outputs, as \nKen said. \n\nA poss=\r\nible implementation for this is to divide the incoming \nconnections by 2 in=\r\n two separate parts every time, and the outgoing \nalso. \n\nLet&#39;s think only =\r\nfor spaces now, please. The 2D space is rotated into \nanother 2D space. One=\r\n linear space into another linear space. We need \na neuron that takes 2 and=\r\n returns 2. Anyone has an idea about it? \n\nIn fact it is incorrect to say &quot;=\r\nactivation functions&quot;, it is correct \nto say &quot;space warping functions&quot;... \n=\r\n\nThere is a way to combine the equation so the neuron would output \n(x+y) i=\r\nnstead of (x) and (y), but this has no sense. \n\nI think this is a major iss=\r\nue about HyperNEAT and CPPNs. \n\nPeter\n\n\n\n--- In neat@yahoogroups.com, &quot;Jaso=\r\nn G&quot; &lt;jgmath2000@...&gt; wrote:\n&gt;\n&gt; Maybe if we thought of a rotation as two r=\r\neflections it would make \nit easier\n&gt; to create such a thing with HyperNEAT=\r\n?\n&gt; \n&gt; A reflection can be constructed if we used a negation activation \nfu=\r\nnction.\n&gt; Then again, this is the same as having no activation function and=\r\n a \nnegative\n&gt; weight.   Of course, it&#39;s easier to have a sum-negation acti=\r\nvation \nfunction\n&gt; than to enforce that every outgoing weight is negative, =\r\nand that&#39;s \nassuming\n&gt; you have a direct summation activation function\n&gt; \n&gt;=\r\n \n&gt; On 6/14/07, petar_chervenski &lt;petar_chervenski@...&gt; wrote:\n&gt; &gt;\n&gt; &gt;   He=\r\nllo, Jan-Jaap,\n&gt; &gt;\n&gt; &gt; It is good to see that you are experimenting with NE=\r\nAT, but this \nis\n&gt; &gt; an CPPN/HyperNEAT issue we are discussing right now.\n&gt;=\r\n &gt; Your suggestion is interesting, but a roving eye cannot be used \nin a\n&gt; =\r\n&gt; CPPN.\n&gt; &gt; The problem about it is that the basic coordinate frames that a=\r\nre\n&gt; &gt; passed in the CPPN must be static all the time. If they are not, \nth=\r\nen\n&gt; &gt; evolution would break down. I mean, the space itself that we build\n&gt;=\r\n &gt; our phenotypes in should not bend, twist or move in any way.\n&gt; &gt; A rovin=\r\ng eye can be used with the HyperNEAT neural substrate, but \nmy\n&gt; &gt; first ex=\r\nperiments showed that this is hard for the evolution to\n&gt; &gt; master.\n&gt; &gt;\n&gt; &gt;=\r\n HyperNEAT allows very large input/output spaces and recognition of\n&gt; &gt; who=\r\nle images, without roving eyes and so on.\n&gt; &gt; Are you familiar with the con=\r\ncept of CPPNs and HyperNEAT?\n&gt; &gt; Check out this excellent paper on the conc=\r\nept of CPPNs:\n&gt; &gt; http://eplex.cs.ucf.edu/papers/stanley_gpem07.pdf\n&gt; &gt; And=\r\n also this one, on HyperNEAT:\n&gt; &gt; http://eplex.cs.ucf.edu/papers/gauci_gecc=\r\no07.pdf\n&gt; &gt;\n&gt; &gt; P.S. Derek James has a paper about his experiments with a r=\r\noving \neye\n&gt; &gt; visual discrimination system in ANJI that includes rotatitng=\r\n \nroving\n&gt; &gt; eye, too. It is interesting that the system has better perform=\r\nance\n&gt; &gt; without rotation.\n&gt; &gt;\n&gt; &gt; Peter\n&gt; &gt;\n&gt; &gt; --- In neat@...=\r\nm &lt;neat%40yahoogroups.com&gt;, &quot;Jan-Jaap \nvan de\n&gt; &gt; Velde&quot;\n&gt; &gt; &lt;janjaap.vande=\r\nvelde@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hello,\n&gt; &gt; &gt;\n&gt; &gt; &gt; I&#39;ve been reading this emailg=\r\nroup for a couple of weeks now with\n&gt; &gt; great\n&gt; &gt; &gt; interest and started ex=\r\nperimenting with Neat also.\n&gt; &gt; &gt;\n&gt; &gt; &gt; As I see your problem it shouldn&#39;t =\r\nbe needed to evolve rotation \nin\n&gt; &gt; your\n&gt; &gt; &gt; network.\n&gt; &gt; &gt; Concider a w=\r\noman rotating a map to be able to read it. You \ncould do\n&gt; &gt; the same\n&gt; &gt; &gt;=\r\n with a &#39;roving eye&#39; and present the data in every angle or maybe\n&gt; &gt; just =\r\na\n&gt; &gt; &gt; couple of orientations.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Maybe this could give some bett=\r\ner results.\n&gt; &gt; &gt;\n&gt; &gt; &gt; I&#39;m looking forward to reading you&#39;re results. I&#39;m =\r\nstill \nlearning\n&gt; &gt; to program\n&gt; &gt; &gt; in Java and C++ in the process, so my =\r\nown experiments are still\n&gt; &gt; waiting to\n&gt; &gt; &gt; get started.\n&gt; &gt; &gt;\n&gt; &gt; &gt; gre=\r\netz,\n&gt; &gt; &gt; Jan-Jaap\n&gt; &gt; &gt;\n&gt; &gt; &gt; from the Netherlands\n&gt; &gt; &gt;\n&gt; &gt; &gt; On 6/13/07=\r\n, Kenneth Stanley &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hi Peter,\n&gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; I agree with your statement of the problem. In a way, \ntranslation\n&gt; &gt; =\r\n&gt; &gt; and scaling are both natural, but rotation is particularly\n&gt; &gt; difficul=\r\nt\n&gt; &gt; &gt; &gt; to evolve. If it did evolve, it would take significant effort \nfo=\r\nr\n&gt; &gt; &gt; &gt; HyperNEAT to discover the concept of rotation.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Th=\r\nat suggests that perhaps there is a way to make rotation a\n&gt; &gt; &gt; &gt; canonica=\r\nl activation function instead of something that needs \nto\n&gt; &gt; be\n&gt; &gt; &gt; &gt; co=\r\nmposed from several parts. However, like you say, it&#39;s hard \nto\n&gt; &gt; &gt; &gt; ima=\r\ngine how a single (traditional) neuron could implement a\n&gt; &gt; rotation\n&gt; &gt; &gt;=\r\n &gt; function that requires multiple variables.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; One idea is t=\r\no create a new kind of neuron that actually has\n&gt; &gt; &gt; &gt; distinct input entr=\r\nances. That way, it is possible to have \nan &quot;x&quot;\n&gt; &gt; &gt; &gt; and a &quot;y&quot; entrance =\r\nto the rotation node. Each entrance could\n&gt; &gt; itself\n&gt; &gt; &gt; &gt; be a summation=\r\n of activation coming from elsewhere, just like \na\n&gt; &gt; &gt; &gt; regaular node in=\r\nput.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Another issue is the alpha argument. I need to think a=\r\nbout \nthat a\n&gt; &gt; &gt; &gt; little more because we do not want to explicitly enter=\r\n an \nalpha.\n&gt; &gt; &gt; &gt; Yet then what is the rotation operating on?\n&gt; &gt; &gt; &gt;\n&gt; &gt;=\r\n &gt; &gt; ken\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yahoogroups.co=\r\nm&gt; &lt;neat%\n&gt; &gt; 40yahoogroups.com&gt;, &quot;petar_chervenski&quot;\n&gt; &gt; &gt; &gt; &lt;petar_cherven=\r\nski@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I made the eye=\r\n static as you suggested in one previous\n&gt; &gt; disscussion\n&gt; &gt; &gt; &gt; &gt; about th=\r\nis experiment, using HyperNEAT for visual \nrecognition.\n&gt; &gt; &gt; &gt; &gt; (Roving e=\r\nye & HyperNEAT is an overkill). It is &quot;alive&quot; for\n&gt; &gt; about 5\n&gt; &gt; &gt; &gt; &gt; tim=\r\nesteps, in order to use some reccurence.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I think about =\r\nthe rotation.. So, let&#39;s clear things out.\n&gt; &gt; &gt; &gt; &gt; A point (X,Y) is rotat=\r\ned with angle (Aplha) to (X1, Y1).\n&gt; &gt; &gt; &gt; &gt; This is a function, taking 3 a=\r\nrguments and returning 2.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; x1=3D y*sin(alpha) + x*cos(al=\r\npha)\n&gt; &gt; &gt; &gt; &gt; y1=3D y*cos(alpha) - x*sin(alpha)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I thin=\r\nk this cannot be covered by a single neuron, but a \ncluster\n&gt; &gt; &gt; &gt; of\n&gt; &gt; =\r\n&gt; &gt; &gt; neurons with sin() and cos() activation functions.. Am I \nright?\n&gt; &gt; =\r\n&gt; &gt; &gt; Let&#39;s say that we have 2 inputs (x, y) and a bias node in \nthe\n&gt; &gt; &gt; =\r\n&gt; CPPN.\n&gt; &gt; &gt; &gt; &gt; Further, we have 2 hidden nodes, one is &quot;sine&quot; other\n&gt; &gt; =\r\nis &quot;cosine&quot;.\n&gt; &gt; &gt; &gt; &gt; These hidden nodes are both connected to the bias. T=\r\nhe bias \nhere\n&gt; &gt; &gt; &gt; is\n&gt; &gt; &gt; &gt; &gt; our &quot;alpha&quot; value.\n&gt; &gt; &gt; &gt; &gt; Then, we ca=\r\nn imagine how these nodes should be connected to\n&gt; &gt; &gt; &gt; construct\n&gt; &gt; &gt; &gt; =\r\n&gt; this formula above. We need linear outputs, and maybe some\n&gt; &gt; &gt; &gt; additi=\r\nonal\n&gt; &gt; &gt; &gt; &gt; linear nodes with multiplying summing functions (to \nreprese=\r\nnt\n&gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; multiplications by x and y)...\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Sim=\r\nilar, translation can be handled even easier. The main\n&gt; &gt; &gt; &gt; coordinate\n&gt;=\r\n &gt; &gt; &gt; &gt; frames has to be connected to 2 linear nodes, where an \naddition\n&gt;=\r\n &gt; to\n&gt; &gt; &gt; &gt; a\n&gt; &gt; &gt; &gt; &gt; bias occurs in each.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Scaling =\r\nis in fact everywhere, since the weights of the\n&gt; &gt; &gt; &gt; connections\n&gt; &gt; &gt; &gt;=\r\n &gt; can be thought of as scalars of the coordinate frames.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt; So, that were the 3 main transformations.. :)\n&gt; &gt; &gt; &gt; &gt; But the rotation=\r\n seems hard to evolve.. And using linear \nnodes\n&gt; &gt; and\n&gt; &gt; &gt; &gt; &gt; multiplyi=\r\nng summing functions (before the activation) is\n&gt; &gt; important.\n&gt; &gt; &gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; &gt; &gt; Peter\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yahoo=\r\ngroups.com&gt;&lt;neat%\n40yahoogroups.com&gt;, &quot;Kenneth\n&gt; &gt; Stanley&quot;\n&gt; &gt; &gt; &gt; &lt;kstanl=\r\ney@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yah=\r\noogroups.com&gt;&lt;neat%\n40yahoogroups.com&gt;,\n&gt; &gt; &gt; &gt; &quot;petar_chervenski&quot;\n&gt; &gt; &gt; &gt; =\r\n&lt;petar_chervenski@&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; - My current experimen=\r\nts with ActiveVision show that it \nis\n&gt; &gt; &gt; &gt; hard\n&gt; &gt; &gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; evolve substrates that recognize simple shapes that are\n&gt; &gt; &gt; &gt; randomly=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; rotated. Perhaps I should tweak the NEAT parameters or \nthe\n=\r\n&gt; &gt; set\n&gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; activation functions?\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Peter, in the experiment you are describing, are you \nusi=\r\nng a\n&gt; &gt; &gt; &gt; roving\n&gt; &gt; &gt; &gt; &gt; eye\n&gt; &gt; &gt; &gt; &gt; &gt; or just inputting a whole ima=\r\nge into the substrate? With\n&gt; &gt; &gt; &gt; &gt; HyperNEAT, it\n&gt; &gt; &gt; &gt; &gt; &gt; should be p=\r\nossible to do recognition tasks without \nneeding a\n&gt; &gt; &gt; &gt; roving\n&gt; &gt; &gt; &gt; &gt;=\r\n eye.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; In any case, I believe rotational invariance =\r\nis indeed an\n&gt; &gt; &gt; &gt; &gt; activation\n&gt; &gt; &gt; &gt; &gt; &gt; function issue. The problem i=\r\ns that you need to get the \nsame\n&gt; &gt; &gt; &gt; &gt; pattern\n&gt; &gt; &gt; &gt; &gt; &gt; of connects =\r\nrepeated in a rotating fashion, so that they \ncan\n&gt; &gt; &gt; &gt; &gt; recognize\n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; rotated images. This kind of rotation is not a very \nnatural\n&gt; &gt; &gt; &gt;=\r\n &gt; byproduct\n&gt; &gt; &gt; &gt; &gt; &gt; of the usual set of activation functions. I believ=\r\ne there \nis\n&gt; &gt; &gt; &gt; &gt; probably\n&gt; &gt; &gt; &gt; &gt; &gt; a rotational activation function=\r\n that would be quite \nhelpful,\n&gt; &gt; &gt; &gt; but I\n&gt; &gt; &gt; &gt; &gt; &gt; have not resolved =\r\nwhat function that should be.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; \n&gt; \n&gt; -- \n&gt; Jason G\n&gt;=\r\n\n\n\n\n"}}