{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"osjoqnz2dr6GRXj7egByaVdcSgjFeUzaj0nBJKf1JcdFNdjjnII8HwFSM6JjELiAZeph4UlrSAQcMmSQm0HspUGM3ucI8hTB0iXIyQqt4Pl9","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: &quot;radar&quot; vision","postDate":"1088052917","msgId":1136,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNiZG1ybCtsMjd2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGNiZGk2ZStuMW0zQGVHcm91cHMuY29tPg=="},"prevInTopic":1135,"nextInTopic":1138,"prevInTime":1135,"nextInTime":1137,"topicId":1105,"numMessagesInTopic":6,"msgSnippet":"Timmy, Let me try to explain the idea.  The sensors are like radars.  Each one is a pie slice coming out of the robot at a certain angle.  If there is an","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 21191 invoked from network); 24 Jun 2004 04:58:38 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m7.grp.scd.yahoo.com with QMQP; 24 Jun 2004 04:58:38 -0000\r\nReceived: from unknown (HELO n9.grp.scd.yahoo.com) (66.218.66.93)\n  by mta5.grp.scd.yahoo.com with SMTP; 24 Jun 2004 04:58:38 -0000\r\nReceived: from [66.218.66.114] by n9.grp.scd.yahoo.com with NNFMP; 24 Jun 2004 04:55:20 -0000\r\nDate: Thu, 24 Jun 2004 04:55:17 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;cbdmrl+l27v@...&gt;\r\nIn-Reply-To: &lt;cbdi6e+n1m3@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2490\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.93\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: &quot;radar&quot; vision\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nTimmy, \n\nLet me try to explain the idea.  The sensors are like radars.  Each \none is a pie slice coming out of the robot at a certain angle.  If \nthere is an object within that pie slice, the sensor registers it, \nwith a higher value for closer distance.  If there are multiple \nobjects in the same slice, the sensor adds up their values.  So for \nexample, if there are two enemies between 30 and 60 degrees from the \nrobot&#39;s heading, then the sensor representing the slice between 30 \nand 60 degrees will add up the values of the two objects and feed \nthat value to the network.  There may be several radars of this \ntype, for example, between 0 and 60, 60 and 120, and 120 and 180.  \n(Note that&#39;s just an example, not meant to be literally used).  The \nrobot knows where things are by seeing which sensor is lighting up, \nand thereby knowing within which angle range objects are located.  \nOf course, it is possible that several such sensors may light up at \nthe same time if there are multiple objects at different angles.\n\nLet me know if this helps.\n\nken\n\n--- In neat@yahoogroups.com, &quot;t_bommel&quot; &lt;t_bommel@y...&gt; wrote:\n&gt; hey ken,\n&gt; \n&gt; yeah i read you&#39;re paper and looked over it several more times. i \n&gt; guess what i don&#39;t understand is how exactly the camera&#39;s work. \nfor \n&gt; example, how are they coded to take in information and how does \nthe \n&gt; distance to the object only come down to one input into the neural \n&gt; network.\n&gt; \n&gt; timmy\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@c...&gt; \nwrote:\n&gt; &gt; Timmy,\n&gt; &gt; \n&gt; &gt; Did you read our paper &quot;Competitive Coevolution through \n&gt; Evolutionary \n&gt; &gt; Complexification?&quot;  I believe it describes the robot duel domain \nin \n&gt; &gt; detail.  If you&#39;ve already read it let me know and I can give \nyou \n&gt; &gt; more specific details if you still need them.\n&gt; &gt; \n&gt; &gt; The paper is here:\n&gt; &gt; \n&gt; &gt; http://nn.cs.utexas.edu/keyword?stanley:jair04\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;t_bommel&quot; &lt;t_bommel@y...&gt; wrote:\n&gt; &gt; &gt; hey ken,\n&gt; &gt; &gt; \n&gt; &gt; &gt; for your robot dual domain, does each piece of food require an \n&gt; &gt; input \n&gt; &gt; &gt; into the neural network? does 1 node take in the range to 1 \npiece \n&gt; &gt; of \n&gt; &gt; &gt; food? lastly, if you you changed the environment such that \nthere \n&gt; &gt; was \n&gt; &gt; &gt; a random number of food how would the neural network take that \n&gt; &gt; into \n&gt; &gt; &gt; account. i guess basically i want to understand how your radar \n&gt; &gt; type \n&gt; &gt; &gt; vision works that you mentioned in my last posting. thanks\n&gt; &gt; &gt; \n&gt; &gt; &gt; timmy\n\n\n"}}