{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":115403844,"authorName":"John Arrowwood","from":"&quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"qir21KfqEoC7jP3Lm0GJgUokorBm1h_MHHNsre7f2Sl6U8aVeCmTF60CPSFku4fiG0PorEEsJb3QJzb9beZI2qv_OdS_BtixGYM1JMWS","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Human fitness function","postDate":"1086912630","msgId":1061,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBWTItRjc2WUlMb3lnWExzeHAwMDAwZjg2OUBob3RtYWlsLmNvbT4="},"prevInTopic":1060,"nextInTopic":1062,"prevInTime":1060,"nextInTime":1062,"topicId":1059,"numMessagesInTopic":5,"msgSnippet":"... I don t know.  I don t know what characteristics to input.  I might just feed scaled-down pixel data for two images with a single 0/1 output.  In which","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 35168 invoked from network); 11 Jun 2004 00:10:30 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m23.grp.scd.yahoo.com with QMQP; 11 Jun 2004 00:10:30 -0000\r\nReceived: from unknown (HELO hotmail.com) (65.54.247.76)\n  by mta5.grp.scd.yahoo.com with SMTP; 11 Jun 2004 00:10:30 -0000\r\nReceived: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\n\t Thu, 10 Jun 2004 17:10:30 -0700\r\nReceived: from 64.122.44.102 by by2fd.bay2.hotmail.msn.com with HTTP;\n\tFri, 11 Jun 2004 00:10:30 GMT\r\nX-Originating-Email: [jarrowwx@...]\r\nX-Sender: jarrowwx@...\r\nTo: neat@yahoogroups.com\r\nBcc: \r\nDate: Thu, 10 Jun 2004 17:10:30 -0700\r\nMime-Version: 1.0\r\nContent-Type: text/plain; format=flowed\r\nMessage-ID: &lt;BAY2-F76YILoygXLsxp0000f869@...&gt;\r\nX-OriginalArrivalTime: 11 Jun 2004 00:10:30.0618 (UTC) FILETIME=[81BE2BA0:01C44F48]\r\nX-eGroups-Remote-IP: 65.54.247.76\r\nFrom: &quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;\r\nReply-To: john@...\r\nSubject: Re: [neat] Human fitness function\r\nX-Yahoo-Group-Post: member; u=115403844\r\nX-Yahoo-Profile: jarrowwx\r\n\r\n&gt;From: &quot;Chad Bohannan&quot; &lt;chad@...&gt;\n&gt;\n&gt; &gt; I&#39;d like to extract a bunch of &#39;characteristics&#39; from each image, and\n&gt;use\n&gt; &gt;those as inputs into a neural network, and use that data as the\n&gt;training\n&gt; &gt;data. Then, when I add a bunch of new pictures to the database, I can\n&gt;let\n&gt; &gt;the network pre-classify their relationship to the others. If the\n&gt;network\n&gt; &gt;doesn&#39;t have a CLEAR preference, it passes on the comparison. When it\n&gt;is\n&gt; &gt;done, the best pictures automatically end up near the top, the dogs\n&gt; &gt;automatically fall to the bottom.\n&gt;\n&gt;\n&gt;I&#39;ve thinking about how to do exactly that ( with the intention of\n&gt;processing motion picture data for a vision system ) and combining it\n&gt;with ideas from the emergent behaviour theory. If you develop a set of\n&gt;networks, one for each &#39;charachteristic&#39; your looking for, and all work\n&gt;in parrellel from the same input. They become the &#39;input layer of\n&gt;networks&#39; and then you can evolve a network who&#39;s input is from that\n&gt;input layer to actually judge the quality/fitness of the image, from\n&gt;those charachteristics.\n&gt;I havn&#39;t actually tried this approach yet, myself, but I&#39;m working\n&gt;toward it. The &quot;real job&quot; has been too much fun. If you go for this\n&gt;approach, there will be some decisions you have to make about how to\n&gt;decide if charachteristics exists or not, and I would really like to see\n&gt;how you choose to filter for them. It could be as simple as having a\n&gt;list of pictures, with corrosponding values for magnitude of\n&gt;charachteristic. A sticky point is things like curves vs lines. Do you\n&gt;have two different networks, one to detect curves, the other lines? Or\n&gt;can one network decide that there are more lines than curves, and make a\n&gt;decision....\n&gt;Quick question: what do you think your input resolution will be?\n\nI don&#39;t know.  I don&#39;t know what characteristics to input.  I might just \nfeed scaled-down pixel data for two images with a single 0/1 output.  In \nwhich case, probably 256x256 pixels per image, times 2 for two images, times \n3 for RGB.  That&#39;s a lot of inputs, though.  It would take a long time to \nlearn to distinguish.  But eventually, it would learn, I&#39;m sure of that.  \nJust not necessarily in my lifetime. :)\n\nI&#39;ll do some research first, see what kinds of things I can do to an image \nto help me determine useful and relevant characteristics.  I know that some \nof the important features are color, saturation, balance (both of colors and \nof content), focus, and stuff like that.  But what I don&#39;t know (yet) is how \nto extract those kinds of features from an image.  Thus, the need for \nresearch.\n\n\n\n"}}