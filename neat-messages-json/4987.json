{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":203001720,"authorName":"Wesley Tansey","from":"Wesley Tansey &lt;tansey@...&gt;","profile":"tansey4","replyTo":"LIST","senderId":"U_DDti9rr8yDwrp1sg6Ebod-_I8NDp-VSCeCPmBhHFSv3YcqiDinEZBI-E8YexnueQ_mulE1UlxK0Tdf8WxuMdVbVNY","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Discrete Neural Networks","postDate":"1260310942","msgId":4987,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDU2YzJmY2UwMDkxMjA4MTQyMnM1ZjM1NDc4MHM2NDYyNmVlMWE2NjE1MzE3QG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PDcyN2E0MDZjMDkxMjA4MTM1OGc1ZWFlYmQ5MnYzNjlhMzkyOGEwMWI0NzhiQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PGhmbTlvZStmbjc0QGVHcm91cHMuY29tPgkgPDcyN2E0MDZjMDkxMjA4MTM1OGc1ZWFlYmQ5MnYzNjlhMzkyOGEwMWI0NzhiQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4986,"nextInTopic":4988,"prevInTime":4986,"nextInTime":4988,"topicId":4984,"numMessagesInTopic":16,"msgSnippet":"Maybe I m missing something, but would the search space reduction (in terms of range of valid weight values) really lend to improved search? I could see this","rawEmail":"Return-Path: &lt;tansey@...&gt;\r\nX-Sender: tansey@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 66254 invoked from network); 8 Dec 2009 22:22:24 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m1.grp.sp2.yahoo.com with QMQP; 8 Dec 2009 22:22:24 -0000\r\nX-Received: from unknown (HELO lennier.cc.vt.edu) (198.82.162.213)\n  by mta3.grp.re1.yahoo.com with SMTP; 8 Dec 2009 22:22:24 -0000\r\nX-Received: from zidane.cc.vt.edu (zidane.cc.vt.edu [198.82.163.227])\n\tby lennier.cc.vt.edu (8.13.8/8.13.8) with ESMTP id nB8MMOfI015806\n\tfor &lt;neat@yahoogroups.com&gt;; Tue, 8 Dec 2009 17:22:24 -0500\r\nX-Received: from mail-iw0-f190.google.com (EHLO mail-iw0-f190.google.com) ([209.85.223.190])\n\tby zidane.cc.vt.edu (MOS 4.1.8-GA FastPath queued)\n\twith ESMTP id DYM88484;\n\tTue, 08 Dec 2009 17:22:23 -0500 (EST)\r\nX-Received: by mail-iw0-f190.google.com with SMTP id 28so4774061iwn.13\n        for &lt;neat@yahoogroups.com&gt;; Tue, 08 Dec 2009 14:22:23 -0800 (PST)\r\nMIME-Version: 1.0\r\nX-Received: by 10.231.61.195 with SMTP id u3mr283166ibh.12.1260310943044; Tue, \n\t08 Dec 2009 14:22:23 -0800 (PST)\r\nIn-Reply-To: &lt;727a406c0912081358g5eaebd92v369a3928a01b478b@...&gt;\r\nReferences: &lt;hfm9oe+fn74@...&gt;\n\t &lt;727a406c0912081358g5eaebd92v369a3928a01b478b@...&gt;\r\nDate: Tue, 8 Dec 2009 14:22:22 -0800\r\nMessage-ID: &lt;56c2fce00912081422s5f354780s64626ee1a6615317@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=00151774149c111442047a3f02b3\r\nX-Mirapoint-Received-SPF: 209.85.223.190 mail-iw0-f190.google.com tansey@... 4 softfail\r\nX-Mirapoint-IP-Reputation: reputation=Good-1,\n\tsource=Queried,\n\trefid=0001.0A020301.4B1ECB01.007D,\n\tactions=TAG SPF\r\nX-Junkmail-Info: (0) HTML_MESSAGE\r\nX-Junkmail-Status: score=10/50, host=zidane.cc.vt.edu\r\nX-Junkmail-SD-Raw: score=unknown,\n\trefid=str=0001.0A020207.4B1ED1A0.005D,ss=1,fgs=0,\n\tip=0.0.0.0,\n\tso=2009-09-22 00:05:22,\n\tdmn=2009-09-10 00:05:08,\n\tmode=multiengine\r\nX-Junkmail-IWF: false\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Wesley Tansey &lt;tansey@...&gt;\r\nSubject: Re: [neat] Discrete Neural Networks\r\nX-Yahoo-Group-Post: member; u=203001720; y=h3y_I6U49rEOI5xCXk7aNdDQR3g4jpjgDKcSBp356ExB5Q\r\nX-Yahoo-Profile: tansey4\r\n\r\n\r\n--00151774149c111442047a3f02b3\r\nContent-Type: text/plain; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nMaybe I&#39;m missing something, but would the search space reduction (in terms=\r\n\nof range of valid weight values) really lend to improved search? I could s=\r\nee\nthis as being true if one were to use a bit-flipping type of mutation, b=\r\nut\nassuming you&#39;re using a Gaussian mutation, would it really matter?\n\nThis=\r\n is particularly true if networks are self-adaptive, though I don&#39;t\nthink a=\r\nny NEAT framework supports self-adaptation. Not to hijack the thread,\nbut I=\r\n don&#39;t see any reason why it couldn&#39;t be incorporated. All that&#39;s\nnecessary=\r\n is for every gene to have its own sigma to be used in the mutation\noperato=\r\nr; the custom sigma is mutated as (C# code):\n\nSigma =3D Math.Max(0, Sigma *=\r\n Math.Exp(GaussianMutation(0,1)));\n//GaussianMutation(mean, stdev)\n\nSelf-ad=\r\naptation helps evolution home-in on precise answers better than using\na fix=\r\ned sigma for mutation.\n\nWesley\n\nOn Tue, Dec 8, 2009 at 1:58 PM, Colin Green=\r\n &lt;colin.green1@...&gt;wrote:\n\n&gt;\n&gt;\n&gt; 2009/12/8 snapmedown &lt;snapmedow=\r\nn@... &lt;snapmedown%40yahoo.com&gt;&gt;\n&gt;\n&gt; &gt;\n&gt; &gt; What are the thoughts on a =\r\nneural network that has inputs and outputs\n&gt; digitized? Perhaps 8\n&gt; &gt; bits =\r\nor even less? This would reduce the search space, but encourage\n&gt; larger st=\r\nructures.\n&gt;\n&gt; Hi,\n&gt;\n&gt; Strictly speaking the signals and weights and already=\r\n digitized in\n&gt; that they&#39;re represented by a 32 bit floating point binary\n=\r\n&gt; representation (or 64bit for double precision). However your question\n&gt; e=\r\nssentially then becomes how much precision is necessary for a given\n&gt; probl=\r\nem domain? and that&#39;s certainly an interesting question both from\n&gt; the per=\r\nspective of the maths of neural networks but also at the\n&gt; implementation l=\r\nevel where an 8 bit based ANN is is a lot less\n&gt; computing resource hungry =\r\ncompared to a 64bit one of the same\n&gt; structural size/complexity.\n&gt;\n&gt; You m=\r\night be interested in the short article I wrote abotu\n&gt; implementing neural=\r\n nets with integer maths and /fixed/ point\n&gt; arithmetic:\n&gt;\n&gt; http://sharpne=\r\nat.sourceforge.net/integer_network.html\n&gt;\n&gt; In terms of pushing NEAT to it&#39;=\r\ns limits I think something like 16bit\n&gt; maths running on CUDA or equivalent=\r\n platforms is a logical goal in the\n&gt; near term. There&#39;s potentially a thre=\r\ne orders of magnitude speedup to\n&gt; be achieved there.\n&gt;\n&gt; Colin.\n&gt;  \n&gt;\n\r\n--00151774149c111442047a3f02b3\r\nContent-Type: text/html; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nMaybe I&#39;m missing something, but would the search space reduction (in t=\r\nerms of range of valid weight values) really lend to improved search? I cou=\r\nld see this as being true if one were to use a bit-flipping type of mutatio=\r\nn, but assuming you&#39;re using a Gaussian mutation, would it really matte=\r\nr?&lt;br&gt;\n&lt;br&gt;This is particularly true if networks are self-adaptive, though =\r\nI don&#39;t think any NEAT framework supports self-adaptation. Not to hijac=\r\nk the thread, but I don&#39;t see any reason why it couldn&#39;t be incorpo=\r\nrated. All that&#39;s necessary is for every gene to have its own sigma to =\r\nbe used in the mutation operator; the custom sigma is mutated as (C# code):=\r\n&lt;br&gt;\n&lt;br&gt;Sigma =3D Math.Max(0, Sigma * Math.Exp(GaussianMutation(0,1))); //=\r\nGaussianMutation(mean, stdev)&lt;br&gt;&lt;br&gt;Self-adaptation helps evolution home-i=\r\nn on precise answers better than using a fixed sigma for mutation.&lt;br&gt;&lt;br&gt;W=\r\nesley&lt;br&gt;\n&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On Tue, Dec 8, 2009 at 1:58 PM, Co=\r\nlin Green &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:colin.green1@googlemail.c=\r\nom&quot;&gt;colin.green1@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote class=\r\n=3D&quot;gmail_quote&quot; style=3D&quot;border-left: 1px solid rgb(204, 204, 204); margin=\r\n: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;&quot;&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;div style=3D&quot;backg=\r\nround-color: rgb(255, 255, 255);&quot;&gt;\n&lt;span&gt;=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n    &lt;=\r\ndiv&gt;\n      \n      \n      &lt;p&gt;2009/12/8 snapmedown &lt;&lt;a href=3D&quot;mailto:snap=\r\nmedown%40yahoo.com&quot; target=3D&quot;_blank&quot;&gt;snapmedown@...&lt;/a&gt;&gt;&lt;/p&gt;&lt;div =\r\nclass=3D&quot;im&quot;&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; What are the thoughts on a neural network t=\r\nhat has inputs and outputs digitized? Perhaps 8&lt;br&gt;\n&gt; bits or even less?=\r\n This would reduce the search space, but encourage larger structures.&lt;br&gt;\n&lt;=\r\nbr&gt;&lt;/div&gt;\nHi,&lt;br&gt;\n&lt;br&gt;\nStrictly speaking the signals and weights and alread=\r\ny digitized in&lt;br&gt;\nthat they&#39;re represented by a 32 bit floating point =\r\nbinary&lt;br&gt;\nrepresentation (or 64bit for double precision). However your que=\r\nstion&lt;br&gt;\nessentially then becomes how much precision is necessary for a gi=\r\nven&lt;br&gt;\nproblem domain? and that&#39;s certainly an interesting question bo=\r\nth from&lt;br&gt;\nthe perspective of the maths of neural networks but also at the=\r\n&lt;br&gt;\nimplementation level where an 8 bit based ANN is is a lot less&lt;br&gt;\ncom=\r\nputing resource hungry compared to a 64bit one of the same&lt;br&gt;\nstructural s=\r\nize/complexity.&lt;br&gt;\n&lt;br&gt;\nYou might be interested in the short article I wro=\r\nte abotu&lt;br&gt;\nimplementing neural nets with integer maths and /fixed/ point&lt;=\r\nbr&gt;\narithmetic:&lt;br&gt;\n&lt;br&gt;\n&lt;a href=3D&quot;http://sharpneat.sourceforge.net/intege=\r\nr_network.html&quot; target=3D&quot;_blank&quot;&gt;http://sharpneat.sourceforge.net/integer_=\r\nnetwork.html&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\nIn terms of pushing NEAT to it&#39;s limits I thi=\r\nnk something like 16bit&lt;br&gt;\nmaths running on CUDA or equivalent platforms i=\r\ns a logical goal in the&lt;br&gt;\nnear term. There&#39;s potentially a three orde=\r\nrs of magnitude speedup to&lt;br&gt;\nbe achieved there.&lt;br&gt;\n&lt;br&gt;\nColin.&lt;br&gt;\n\n\n   =\r\n &lt;/div&gt;\n     \n\n    \n    &lt;div style=3D&quot;color: rgb(255, 255, 255); min-height=\r\n: 0pt;&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;\n\r\n--00151774149c111442047a3f02b3--\r\n\n"}}