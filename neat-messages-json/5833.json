{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234577593,"authorName":"Oliver Coleman","from":"Oliver Coleman &lt;oliver.coleman@...&gt;","profile":"olivercoleman04","replyTo":"LIST","senderId":"YVheiLMHMPnScjdFNsVg-A3fMpX-WWAte9lgp1-AM0dLLMbgYqQewJLSfuzcAvDDpMPKcS1S1iTBjaevrRpKtXv6NrSXOqh5l5wcR8WUl5U","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Models of brains, what should we borrow from biology?","postDate":"1343006268","msgId":5833,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBK2R1aW1PbUp0czktLTRoND1GLVBOU19DdEFSRlpEcDNHLUVUaVpKQnRKYjVNWVo4Z0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PENBTHV1dzNQaD1GaDdKX3ptdW16dzlrWUFBVm03VnpUUXFwdmtuVFArQzBwODZwNE1YQUBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PENBTHV1dzNPcnMyUzEwRk9VMFFQRkpia2owNnZfTFFyLWczN1AyUCtkUExiRVVCcC1QQUBtYWlsLmdtYWlsLmNvbT4JPGp1YXM3dCtiMHRxQGVHcm91cHMuY29tPgk8Q0FMdXV3M1BoPUZoN0pfem11bXp3OWtZQUFWbTdWelRRcXB2a25UUCtDMHA4NnA0TVhBQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":5832,"nextInTopic":5834,"prevInTime":5832,"nextInTime":5834,"topicId":5801,"numMessagesInTopic":16,"msgSnippet":"Hi Jeff, Thanks so much for your interesting and useful comments on parameter evolution and exploration and exploitation trade off, I will have to take this","rawEmail":"Return-Path: &lt;oliver.coleman@...&gt;\r\nX-Sender: oliver.coleman@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 12869 invoked from network); 23 Jul 2012 01:17:49 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m11.grp.sp2.yahoo.com with QMQP; 23 Jul 2012 01:17:49 -0000\r\nX-Received: from unknown (HELO mail-yw0-f54.google.com) (209.85.213.54)\n  by mta4.grp.sp2.yahoo.com with SMTP; 23 Jul 2012 01:17:49 -0000\r\nX-Received: by yhfs35 with SMTP id s35so4925331yhf.41\n        for &lt;neat@yahoogroups.com&gt;; Sun, 22 Jul 2012 18:17:48 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.50.159.196 with SMTP id xe4mr13109097igb.43.1343006268508;\n Sun, 22 Jul 2012 18:17:48 -0700 (PDT)\r\nX-Received: by 10.231.46.209 with HTTP; Sun, 22 Jul 2012 18:17:48 -0700 (PDT)\r\nIn-Reply-To: &lt;CALuuw3Ph=Fh7J_zmumzw9kYAAVm7VzTQqpvknTP+C0p86p4MXA@...&gt;\r\nReferences: &lt;CALuuw3Ors2S10FOU0QPFJbkj06v_LQr-g37P2P+dPLbEUBp-PA@...&gt;\n\t&lt;juas7t+b0tq@...&gt;\n\t&lt;CALuuw3Ph=Fh7J_zmumzw9kYAAVm7VzTQqpvknTP+C0p86p4MXA@...&gt;\r\nDate: Mon, 23 Jul 2012 11:17:48 +1000\r\nMessage-ID: &lt;CA+duimOmJts9--4h4=F-PNS_CtARFZDp3G-ETiZJBtJb5MYZ8g@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=14dae934059b90ca8404c575034d\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Oliver Coleman &lt;oliver.coleman@...&gt;\r\nSubject: Re: [neat] Re: Models of brains, what should we borrow from biology?\r\nX-Yahoo-Group-Post: member; u=234577593; y=8yrXMfGaE_JNCx-EHGMwlt1DR5w-hz2hWc2U_gkd7Tq4Ab2WwhbMBAFMfuvGCK4-vtRdI2za1Q\r\nX-Yahoo-Profile: olivercoleman04\r\n\r\n\r\n--14dae934059b90ca8404c575034d\r\nContent-Type: text/plain; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Jeff,\n\nThanks so much for your interesting and useful comments on parame=\r\nter\nevolution and exploration and exploitation trade off, I will have to ta=\r\nke\nthis into consideration and read up on the work you mention. In reviewin=\r\ng\nthe literature on evolution of plastic networks I had found that often, a=\r\nnd\ncounter-intuitively, increasing the complexity/parameter space of the\nne=\r\ntwork model improved evolvability (speed and reliability of producing\nsolut=\r\nions), but only to a point. I have been somewhat swayed by this\nfinding, an=\r\nd concluded that introducing many evolvable parameters would not\nsignifican=\r\ntly affect evolvability, but clearly I need to consider this more\ncarefully=\r\n. (I&#39;ve submitted my findings in a review paper for a conference,\nhaven&#39;t h=\r\neard back about acceptance yet, I hear it can be hard to get\nreview papers =\r\naccepted... I&#39;d be happy to provide it here if you&#39;re\ninterested).\n\nAlso th=\r\nanks for suggestion re interaction effects and SVM feature\nselection, very =\r\ninteresting!\n\nAs it turns out I&#39;ve been working on a blog post on the signi=\r\nficance of\npositive results on one or a few tasks. It&#39;s been stagnating for=\r\n a few\nweeks, I wasn&#39;t sure about its significance...  but your comments on=\r\n this\nhave provided me with the motivation to get it out the door (as well =\r\nas a\nfew more interesting words to add to it):\nhttp://ojcoleman.com/content=\r\n/are-positive-results-one-or-two-tasks-significant\nthanks!\n\nCheers,\nOliver\n=\r\n\nOn 22 July 2012 00:12, Madan Dabbeeru &lt;iitk.madan@...&gt; wrote:\n\n&gt; **\n=\r\n&gt;\n&gt;\n&gt; Thanks Peter.\n&gt;\n&gt; I will check that now.\n&gt;\n&gt; Regards,\n&gt; Madan\n&gt;\n&gt;\n&gt; O=\r\nn Fri, Jul 20, 2012 at 2:01 AM, petar_chervenski &lt;\n&gt; petar_chervenski@yahoo=\r\n.com&gt; wrote:\n&gt;\n&gt;&gt; **\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; You can check out my NEAT implementation whic=\r\nh I just uploaded to the\n&gt;&gt; file section of the group (NEAT.tar.bz2). It is=\r\n written in C++ and has\n&gt;&gt; Python bindings for running generational evoluti=\r\non (later versions will\n&gt;&gt; feature running rtNEAT/HyperNEAT/Novelty Search =\r\nfrom Python).\n&gt;&gt;\n&gt;&gt; --- In neat@yahoogroups.com, Madan Dabbeeru &lt;iitk.madan=\r\n@...&gt; wrote:\n&gt;&gt; &gt;\n&gt;&gt; &gt; Hello,\n&gt;&gt; &gt;\n&gt;&gt; &gt; I am looking for NEAT in Python. I =\r\nam not able to find any file in the\n&gt;&gt; &gt; download like provided. (\n&gt;&gt; http:=\r\n//code.google.com/p/neat-python/downloads/list\n&gt;&gt; &gt; ).\n&gt;&gt; &gt;\n&gt;&gt; &gt; Please sha=\r\nre me if anybody has this package.\n&gt;&gt; &gt;\n&gt;&gt; &gt; Thanks & Regards,\n&gt;&gt; &gt; Madan\n&gt;=\r\n&gt; &gt;\n&gt;&gt; &gt; On Wed, Jul 11, 2012 at 11:42 AM, Jeff Clune &lt;jeffclune@...&gt; wrote=\r\n:\n&gt;&gt; &gt;\n&gt;&gt; &gt; &gt; Hello Oliver,\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; I&#39;m much delayed in reading all o=\r\nf this as I have been insanely busy\n&gt;&gt; &gt; &gt; lately, but I have a few thought=\r\ns that might help you out:\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; 1) Be careful with meta-evolution =\r\n(evolving the parameters of\n&gt;&gt; evolutionary\n&gt;&gt; &gt; &gt; algorithms). It sounds g=\r\nood in theory, but can be tricky in practice\n&gt;&gt; &gt; &gt; because evolution is sh=\r\nort-sighted and conservative, preferring\n&gt;&gt; &gt; &gt; exploitation over explorati=\r\non, which can be very harmful vis a vis\n&gt;&gt; &gt; &gt; long-term adaptation. Check =\r\nout my PLoS Computational Biology paper\n&gt;&gt; for a\n&gt;&gt; &gt; &gt; smoking gun on this=\r\n front (the evolution of mutation rates). You may\n&gt;&gt; face\n&gt;&gt; &gt; &gt; the exact =\r\nsame problem if you go down this road. [Note, however, that\n&gt;&gt; using\n&gt;&gt; &gt; &gt;=\r\n a divergent search algorithm like novelty search may allow you to take\n&gt;&gt; =\r\n&gt; &gt; better advantage of meta-evolution: see Joel and Ken&#39;s 2012 alife\n&gt;&gt; re=\r\nview\n&gt;&gt; &gt; &gt; article on that subject.]\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; 2) Another reason peopl=\r\ne do not throw all of the biology into the\n&gt;&gt; soup to\n&gt;&gt; &gt; &gt; see what happe=\r\nns is because scientifically you end up in an\n&gt;&gt; impenetrable\n&gt;&gt; &gt; &gt; quagmi=\r\nre where you can&#39;t figure out what is going on and you end up\n&gt;&gt; not\n&gt;&gt; &gt; &gt;=\r\n learning much/anything. The scientific method demands keeping all else\n&gt;&gt; =\r\n&gt; &gt; equal, and if you have a lot of variables you don&#39;t perfectly\n&gt;&gt; unders=\r\ntand,\n&gt;&gt; &gt; &gt; it takes years to figure out what is going on if you are lucky=\r\n! Even\n&gt;&gt; if you\n&gt;&gt; &gt; &gt; keep all else equal, if you are doing so against a =\r\nbackdrop that\n&gt;&gt; involves a\n&gt;&gt; &gt; &gt; lot of complexity you don&#39;t understand, =\r\nany difference you see may be\n&gt;&gt; due\n&gt;&gt; &gt; &gt; to an interaction effect with o=\r\nne of the features in your\n&gt;&gt; backdrop...and\n&gt;&gt; &gt; &gt; that may invalidate gen=\r\neralizing your result to other backdrops of\n&gt;&gt; &gt; &gt; interest. In my limited =\r\nexperience, I have found that most new\n&gt;&gt; scientists\n&gt;&gt; &gt; &gt; want to throw a=\r\n million things into their model--especially\n&gt;&gt; biologically\n&gt;&gt; &gt; &gt; motivat=\r\ned phenomena--to see what happens, and as they grow older/more\n&gt;&gt; &gt; &gt; jaded=\r\n/wiser/more experienced/gun shy/etc. they increasingly keep\n&gt;&gt; things as\n&gt;&gt;=\r\n &gt; &gt; simple as possible. In fact, a pretty good heuristic for good\n&gt;&gt; &gt; &gt; h=\r\nypothesis-testing science is to keep things absolutely as simple as\n&gt;&gt; &gt; &gt; =\r\npossible while allowing the question to be asked. However, that may\n&gt;&gt; not =\r\nbe\n&gt;&gt; &gt; &gt; a good heuristic for more exploratory science where you just set =\r\nout\n&gt;&gt; and\n&gt;&gt; &gt; &gt; see what you discover.\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; 3) You should check =\r\nout Julian Miller&#39;s papers on evolving a checkers\n&gt;&gt; &gt; &gt; player (with his s=\r\ntudent M. Khan, I believe). Or, better, email/Skype\n&gt;&gt; him\n&gt;&gt; &gt; &gt; (he&#39;s an =\r\nextremely nice guy and I&#39;m sure he would be happy to talk to\n&gt;&gt; you).\n&gt;&gt; &gt; =\r\n&gt; He decided in the last few years that he is running out of time as a\n&gt;&gt; &gt;=\r\n &gt; scientist and has tenure and he has spent years keeping things as\n&gt;&gt; sim=\r\nple as\n&gt;&gt; &gt; &gt; possible, and he now just wants to do what he originally want=\r\ned to do\n&gt;&gt; when\n&gt;&gt; &gt; &gt; he started: throw as much biology in the soup as po=\r\nssible and see if a\n&gt;&gt; &gt; &gt; golem crawls out. He has incorporated a ton of b=\r\niologically inspired\n&gt;&gt; &gt; &gt; low-level mechanisms in evolving neural network=\r\ns. From what I recall,\n&gt;&gt; &gt; &gt; however, it did become very difficult to figu=\r\nre out which ingredients\n&gt;&gt; were\n&gt;&gt; &gt; &gt; essential and exactly what was goin=\r\ng on because of all the involved\n&gt;&gt; &gt; &gt; complexity. He may have updated res=\r\nults since I last checked in,\n&gt;&gt; however.\n&gt;&gt; &gt; &gt; So, you may benefit the ac=\r\ntual work that he has done on this front\n&gt;&gt; and,\n&gt;&gt; &gt; &gt; more generally, fro=\r\nm his opinions on the general scientific approach\n&gt;&gt; you\n&gt;&gt; &gt; &gt; are proposi=\r\nng.\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; I hope that helps. Best of luck, and I look forward to he=\r\naring what\n&gt;&gt; you\n&gt;&gt; &gt; &gt; learn!\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Best regards,\n&gt;&gt; &gt; &gt; Jeff Clu=\r\nne\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Postdoctoral Fellow\n&gt;&gt; &gt; &gt; Cornell University\n&gt;&gt; &gt; &gt; jeffc=\r\nlune@...\n&gt;&gt;\n&gt;&gt; &gt; &gt; jeffclune.com\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; On May 11, 2012, at 6:34 AM,=\r\n Oliver Coleman wrote:\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt; Hi Ken,\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt; Y=\r\nes, I&#39;m pretty sure that not all of the phenomena I listed are\n&gt;&gt; &gt; &gt; impor=\r\ntant; and that a good starting point in general is to assume\n&gt;&gt; that they\n&gt;=\r\n&gt; &gt; &gt; are not. I also agree with your argument that a lot of the low-level\n=\r\n&gt;&gt; &gt; &gt; phenomena we see may be a result of implementation with particular\n&gt;=\r\n&gt; physical\n&gt;&gt; &gt; &gt; systems (and I would add perhaps as a result of evolution=\r\nary\n&gt;&gt; happenstance).\n&gt;&gt; &gt; &gt; The CPPN is a particularly compelling example =\r\nof significant\n&gt;&gt; abstraction of\n&gt;&gt; &gt; &gt; developmental processes, producing =\r\nmany of the same features of the\n&gt;&gt; end\n&gt;&gt; &gt; &gt; result of developmental proc=\r\nesses. One thing it does abstract away,\n&gt;&gt; in the\n&gt;&gt; &gt; &gt; context of plastic=\r\n networks, is the effect of external input on the\n&gt;&gt; &gt; &gt; developmental proc=\r\ness (which may or may not be an issue depending on\n&gt;&gt; &gt; &gt; details of implem=\r\nentation, problem domain, etc...).\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt; Perhaps we could also =\r\nassume that, rather than some specific set of\n&gt;&gt; &gt; &gt; functions being the on=\r\nly workable set, what matters is having a\n&gt;&gt; workable\n&gt;&gt; &gt; &gt; combination of=\r\n functions, and that there are many possible\n&gt;&gt; combinations\n&gt;&gt; &gt; &gt; that wo=\r\nuld work equally well. In this framework we could assume that\n&gt;&gt; &gt; &gt; biolog=\r\nical neural networks represent at least a reasonably good\n&gt;&gt; combination\n&gt;&gt;=\r\n &gt; &gt; of low-level functions, and so we could use this combination as a\n&gt;&gt; g=\r\nuide\n&gt;&gt; &gt; &gt; (but of course this doesn&#39;t answer what functions in this combi=\r\nnation\n&gt;&gt; are\n&gt;&gt; &gt; &gt; actually important, or what things can be abstracted a=\r\nway). Also, some\n&gt;&gt; &gt; &gt; combinations may be workable, but are far harder to=\r\n evolve solutions\n&gt;&gt; with,\n&gt;&gt; &gt; &gt; or require much larger networks, etc (eg =\r\nevolving networks\n&gt;&gt; incorporating\n&gt;&gt; &gt; &gt; neuromodulation of synaptic plast=\r\nicity can be much easier for some\n&gt;&gt; tasks\n&gt;&gt; &gt; &gt; than for those without th=\r\nis type of neuromodulation).\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt; I&#39;m intending to run some ex=\r\nperiments to explore these questions\n&gt;&gt; (which\n&gt;&gt; &gt; &gt; phenomena are importa=\r\nnt, acceptable level of abstraction, etc), but of\n&gt;&gt; &gt; &gt; course to try and =\r\nthoroughly explore all of these functions in many\n&gt;&gt; &gt; &gt; combinations would=\r\n be a massive undertaking, and is not my main\n&gt;&gt; interest,\n&gt;&gt; &gt; &gt; so at som=\r\ne point I will have to pick a model and run with it after\n&gt;&gt; only a\n&gt;&gt; &gt; &gt; =\r\nfew, hopefully well chosen, experiments... Perhaps one approach is to\n&gt;&gt; &gt; =\r\n&gt; create flexible parameterised versions of these functions, and let\n&gt;&gt; &gt; &gt;=\r\n evolution determine what combination is right (like your approach\n&gt;&gt; descr=\r\nibed\n&gt;&gt; &gt; &gt; in &quot;Evolving adaptive neural networks with and without adaptive=\r\n\n&gt;&gt; synapses&quot;,\n&gt;&gt; &gt; &gt; but perhaps more flexible and applied to more functio=\r\nns).\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt; Do you mind if I post/quote some/all of this discuss=\r\nion in the\n&gt;&gt; comments\n&gt;&gt; &gt; &gt; of my blog post?\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt; Cheers,\n&gt;&gt;=\r\n &gt; &gt; &gt; Oliver\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt; &gt;\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; ---------------=\r\n---------------------\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Yahoo! Groups Links\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; =\r\n&gt;\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt;\n&gt;&gt;\n&gt;  \n&gt;\n\r\n--14dae934059b90ca8404c575034d\r\nContent-Type: text/html; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Jeff,&lt;br&gt;&lt;br&gt;Thanks so much for your interesting and useful comments on =\r\nparameter evolution and exploration and exploitation trade off, I will have=\r\n to take this into consideration and read up on the work you mention. In re=\r\nviewing the literature on evolution of plastic networks I had found that of=\r\nten, and counter-intuitively, increasing the complexity/parameter space of =\r\nthe network model improved evolvability (speed and reliability of producing=\r\n solutions), but only to a point. I have been somewhat swayed by this findi=\r\nng, and concluded that introducing many evolvable parameters would not sign=\r\nificantly affect evolvability, but clearly I need to consider this more car=\r\nefully. (I&#39;ve submitted my findings in a review paper for a conference,=\r\n haven&#39;t heard back about acceptance yet, I hear it can be hard to get =\r\nreview papers accepted... I&#39;d be happy to provide it here if you&#39;re=\r\n interested).&lt;br&gt;\n&lt;br&gt;Also thanks for suggestion re interaction effects and=\r\n SVM feature selection, very interesting!&lt;br&gt;&lt;br&gt;As it turns out I&#39;ve b=\r\neen working on a blog post on the significance of positive results on one o=\r\nr a few tasks. It&#39;s been stagnating for a few weeks, I wasn&#39;t sure =\r\nabout its significance...=A0 but your comments on this have provided me wit=\r\nh the motivation to get it out the door (as well as a few more interesting =\r\nwords to add to it): &lt;a href=3D&quot;http://ojcoleman.com/content/are-positive-r=\r\nesults-one-or-two-tasks-significant&quot;&gt;http://ojcoleman.com/content/are-posit=\r\nive-results-one-or-two-tasks-significant&lt;/a&gt;=A0 thanks!&lt;br&gt;\n&lt;br&gt;Cheers,&lt;br&gt;=\r\nOliver&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On 22 July 2012 00:12, Madan Dabbe=\r\neru &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:iitk.madan@...&quot; target=3D=\r\n&quot;_blank&quot;&gt;iitk.madan@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote class=3D=\r\n&quot;gmail_quote&quot; style=3D&quot;margin:0 0 0 .8ex;border-left:1px #ccc solid;padding=\r\n-left:1ex&quot;&gt;\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n\n&lt;div style&gt;\n&lt;span&gt;=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;di=\r\nv&gt;\n\n\n    &lt;div&gt;\n      \n      \n      &lt;p&gt;Thanks Peter.&lt;/p&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;=\r\nI will check that now.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Madan&lt;di=\r\nv&gt;&lt;div class=3D&quot;h5&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On Fri, Jul 20, 2012=\r\n at 2:01 AM, petar_chervenski &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:petar=\r\n_chervenski@...&quot; target=3D&quot;_blank&quot;&gt;petar_chervenski@...&lt;/a&gt;&gt;=\r\n&lt;/span&gt; wrote:&lt;br&gt;\n\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;border-left:=\r\n1px #ccc solid&quot;&gt;\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n\n&lt;div&gt;\n&lt;span&gt;=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;=\r\n\n\n\n    &lt;div&gt;\n      \n      \n      &lt;p&gt;You can check out my NEAT implementatio=\r\nn which I just uploaded to the file section of the group (NEAT.tar.bz2). It=\r\n is written in C++ and has Python bindings for running generational evoluti=\r\non (later versions will feature running rtNEAT/HyperNEAT/Novelty Search fro=\r\nm Python). &lt;br&gt;\n\n&lt;/p&gt;&lt;div&gt;\n&lt;br&gt;\n--- In &lt;a href=3D&quot;mailto:neat%40yahoogroups=\r\n.com&quot; target=3D&quot;_blank&quot;&gt;neat@yahoogroups.com&lt;/a&gt;, Madan Dabbeeru &lt;iitk.m=\r\nadan@...&gt; wrote:&lt;br&gt;\n&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;\n&gt; Hello,&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; =\r\nI am looking for NEAT in Python. I am not able to find any file in the&lt;br&gt;\n=\r\n&gt; download like provided. (&lt;a href=3D&quot;http://code.google.com/p/neat-pyth=\r\non/downloads/list&quot; target=3D&quot;_blank&quot;&gt;http://code.google.com/p/neat-python/d=\r\nownloads/list&lt;/a&gt;&lt;br&gt;\n&gt; ).&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Please share me if anybody=\r\n has this package.&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Thanks &amp; Regards,&lt;br&gt;\n&gt; Madan&lt;=\r\nbr&gt;\n&gt; &lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;\n&gt; On Wed, Jul 11, 2012 at 11:42 AM, Jeff C=\r\nlune &lt;jeffclune@...&gt; wrote:&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &gt; Hello Oliver,&lt;br&gt;=\r\n\n&gt; &gt;&lt;br&gt;\n&gt; &gt; I&#39;m much delayed in reading all of this as I h=\r\nave been insanely busy&lt;br&gt;\n&gt; &gt; lately, but I have a few thoughts that=\r\n might help you out:&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; 1) Be careful with meta-ev=\r\nolution (evolving the parameters of evolutionary&lt;br&gt;\n&gt; &gt; algorithms).=\r\n It sounds good in theory, but can be tricky in practice&lt;br&gt;\n&gt; &gt; beca=\r\nuse evolution is short-sighted and conservative, preferring&lt;br&gt;\n&gt; &gt; e=\r\nxploitation over exploration, which can be very harmful vis a vis&lt;br&gt;\n&gt; =\r\n&gt; long-term adaptation. Check out my PLoS Computational Biology paper fo=\r\nr a&lt;br&gt;\n&gt; &gt; smoking gun on this front (the evolution of mutation rate=\r\ns). You may face&lt;br&gt;\n&gt; &gt; the exact same problem if you go down this r=\r\noad. [Note, however, that using&lt;br&gt;\n&gt; &gt; a divergent search algorithm =\r\nlike novelty search may allow you to take&lt;br&gt;\n&gt; &gt; better advantage of=\r\n meta-evolution: see Joel and Ken&#39;s 2012 alife review&lt;br&gt;\n&gt; &gt; art=\r\nicle on that subject.]&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; 2) Another reason people=\r\n do not throw all of the biology into the soup to&lt;br&gt;\n&gt; &gt; see what ha=\r\nppens is because scientifically you end up in an impenetrable&lt;br&gt;\n&gt; &gt;=\r\n quagmire where you can&#39;t figure out what is going on and you end up no=\r\nt&lt;br&gt;\n&gt; &gt; learning much/anything. The scientific method demands keepi=\r\nng all else&lt;br&gt;\n&gt; &gt; equal, and if you have a lot of variables you don=\r\n&#39;t perfectly understand,&lt;br&gt;\n&gt; &gt; it takes years to figure out wha=\r\nt is going on if you are lucky! Even if you&lt;br&gt;\n&gt; &gt; keep all else equ=\r\nal, if you are doing so against a backdrop that involves a&lt;br&gt;\n&gt; &gt; lo=\r\nt of complexity you don&#39;t understand, any difference you see may be due=\r\n&lt;br&gt;\n&gt; &gt; to an interaction effect with one of the features in your ba=\r\nckdrop...and&lt;br&gt;\n&gt; &gt; that may invalidate generalizing your result to =\r\nother backdrops of&lt;br&gt;\n&gt; &gt; interest. In my limited experience, I have=\r\n found that most new scientists&lt;br&gt;\n&gt; &gt; want to throw a million thing=\r\ns into their model--especially biologically&lt;br&gt;\n&gt; &gt; motivated phenome=\r\nna--to see what happens, and as they grow older/more&lt;br&gt;\n&gt; &gt; jaded/wi=\r\nser/more experienced/gun shy/etc. they increasingly keep things as&lt;br&gt;\n&gt;=\r\n &gt; simple as possible. In fact, a pretty good heuristic for good&lt;br&gt;\n&gt=\r\n; &gt; hypothesis-testing science is to keep things absolutely as simple as=\r\n&lt;br&gt;\n&gt; &gt; possible while allowing the question to be asked. However, t=\r\nhat may not be&lt;br&gt;\n&gt; &gt; a good heuristic for more exploratory science =\r\nwhere you just set out and&lt;br&gt;\n&gt; &gt; see what you discover.&lt;br&gt;\n&gt; &g=\r\nt;&lt;br&gt;\n&gt; &gt; 3) You should check out Julian Miller&#39;s papers on evol=\r\nving a checkers&lt;br&gt;\n&gt; &gt; player (with his student M. Khan, I believe).=\r\n Or, better, email/Skype him&lt;br&gt;\n&gt; &gt; (he&#39;s an extremely nice guy =\r\nand I&#39;m sure he would be happy to talk to you).&lt;br&gt;\n&gt; &gt; He decide=\r\nd in the last few years that he is running out of time as a&lt;br&gt;\n&gt; &gt; s=\r\ncientist and has tenure and he has spent years keeping things as simple as&lt;=\r\nbr&gt;\n&gt; &gt; possible, and he now just wants to do what he originally want=\r\ned to do when&lt;br&gt;\n&gt; &gt; he started: throw as much biology in the soup a=\r\ns possible and see if a&lt;br&gt;\n&gt; &gt; golem crawls out. He has incorporated=\r\n a ton of biologically inspired&lt;br&gt;\n&gt; &gt; low-level mechanisms in evolv=\r\ning neural networks. From what I recall,&lt;br&gt;\n&gt; &gt; however, it did beco=\r\nme very difficult to figure out which ingredients were&lt;br&gt;\n&gt; &gt; essent=\r\nial and exactly what was going on because of all the involved&lt;br&gt;\n&gt; &gt;=\r\n complexity. He may have updated results since I last checked in, however.&lt;=\r\nbr&gt;\n&gt; &gt; So, you may benefit the actual work that he has done on this =\r\nfront and,&lt;br&gt;\n&gt; &gt; more generally, from his opinions on the general s=\r\ncientific approach you&lt;br&gt;\n&gt; &gt; are proposing.&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; =\r\n&gt; I hope that helps. Best of luck, and I look forward to hearing what yo=\r\nu&lt;br&gt;\n&gt; &gt; learn!&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; Best regards,&lt;br&gt;\n&gt; &=\r\ngt; Jeff Clune&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; Postdoctoral Fellow&lt;br&gt;\n&gt; &gt=\r\n; Cornell University&lt;br&gt;&lt;/div&gt;&lt;/div&gt;\n&gt; &gt; jeffclune@...&lt;div&gt;&lt;div&gt;&lt;br&gt;\n=\r\n&gt; &gt; &lt;a href=3D&quot;http://jeffclune.com&quot; target=3D&quot;_blank&quot;&gt;jeffclune.com&lt;=\r\n/a&gt;&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; On May 11, 2012, at 6:34 AM, Oliver Coleman=\r\n wrote:&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; &gt; Hi Ken,&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt=\r\n; &gt; &gt;&lt;br&gt;\n&gt; &gt; &gt; Yes, I&#39;m pretty sure that not all of the=\r\n phenomena I listed are&lt;br&gt;\n&gt; &gt; important; and that a good starting p=\r\noint in general is to assume that they&lt;br&gt;\n&gt; &gt; are not. I also agree =\r\nwith your argument that a lot of the low-level&lt;br&gt;\n&gt; &gt; phenomena we s=\r\nee may be a result of implementation with particular physical&lt;br&gt;\n&gt; &gt;=\r\n systems (and I would add perhaps as a result of evolutionary happenstance)=\r\n.&lt;br&gt;\n&gt; &gt; The CPPN is a particularly compelling example of significan=\r\nt abstraction of&lt;br&gt;\n&gt; &gt; developmental processes, producing many of t=\r\nhe same features of the end&lt;br&gt;\n&gt; &gt; result of developmental processes=\r\n. One thing it does abstract away, in the&lt;br&gt;\n&gt; &gt; context of plastic =\r\nnetworks, is the effect of external input on the&lt;br&gt;\n&gt; &gt; developmenta=\r\nl process (which may or may not be an issue depending on&lt;br&gt;\n&gt; &gt; deta=\r\nils of implementation, problem domain, etc...).&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt;=\r\n &gt; &gt; Perhaps we could also assume that, rather than some specific set=\r\n of&lt;br&gt;\n&gt; &gt; functions being the only workable set, what matters is ha=\r\nving a workable&lt;br&gt;\n&gt; &gt; combination of functions, and that there are =\r\nmany possible combinations&lt;br&gt;\n&gt; &gt; that would work equally well. In t=\r\nhis framework we could assume that&lt;br&gt;\n&gt; &gt; biological neural networks=\r\n represent at least a reasonably good combination&lt;br&gt;\n&gt; &gt; of low-leve=\r\nl functions, and so we could use this combination as a guide&lt;br&gt;\n&gt; &gt; =\r\n(but of course this doesn&#39;t answer what functions in this combination a=\r\nre&lt;br&gt;\n&gt; &gt; actually important, or what things can be abstracted away)=\r\n. Also, some&lt;br&gt;\n&gt; &gt; combinations may be workable, but are far harder=\r\n to evolve solutions with,&lt;br&gt;\n&gt; &gt; or require much larger networks, e=\r\ntc (eg evolving networks incorporating&lt;br&gt;\n&gt; &gt; neuromodulation of syn=\r\naptic plasticity can be much easier for some tasks&lt;br&gt;\n&gt; &gt; than for t=\r\nhose without this type of neuromodulation).&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt; &gt=\r\n; &gt; I&#39;m intending to run some experiments to explore these questions=\r\n (which&lt;br&gt;\n&gt; &gt; phenomena are important, acceptable level of abstract=\r\nion, etc), but of&lt;br&gt;\n&gt; &gt; course to try and thoroughly explore all of=\r\n these functions in many&lt;br&gt;\n&gt; &gt; combinations would be a massive unde=\r\nrtaking, and is not my main interest,&lt;br&gt;\n&gt; &gt; so at some point I will=\r\n have to pick a model and run with it after only a&lt;br&gt;\n&gt; &gt; few, hopef=\r\nully well chosen, experiments... Perhaps one approach is to&lt;br&gt;\n&gt; &gt; c=\r\nreate flexible parameterised versions of these functions, and let&lt;br&gt;\n&gt; =\r\n&gt; evolution determine what combination is right (like your approach desc=\r\nribed&lt;br&gt;\n&gt; &gt; in &quot;Evolving adaptive neural networks with and wit=\r\nhout adaptive synapses&quot;,&lt;br&gt;\n&gt; &gt; but perhaps more flexible and a=\r\npplied to more functions).&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt; &gt; &gt; Do you min=\r\nd if I post/quote some/all of this discussion in the comments&lt;br&gt;\n&gt; &gt;=\r\n of my blog post?&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt; &gt; &gt; Cheers,&lt;br&gt;\n&gt; &g=\r\nt; &gt; Oliver&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt; &gt; &gt;&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt;=\r\n &gt;&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt; ------------------------------------&lt;br&gt;\n=\r\n&gt; &gt;&lt;br&gt;\n&gt; &gt; Yahoo! Groups Links&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt; &gt;&lt;br&gt;=\r\n\n&gt; &gt;&lt;br&gt;\n&gt; &gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n=\r\n     \n\n    \n    &lt;div style=3D&quot;color:#fff&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/div=\r\n&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n=\r\n\n    \n    &lt;div style=3D&quot;color:#fff;min-height:0&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n=\r\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;\n\r\n--14dae934059b90ca8404c575034d--\r\n\n"}}