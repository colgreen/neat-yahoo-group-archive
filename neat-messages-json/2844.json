{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"8aHDttBWvZt6W8g6YMnqUZ62yTPGGqPfLMhE-LTV3e--XOlkEohK5matJE4QG8pDr85MWNYbAhU9dWzo5Jk_7blR8QSwk4zgpZB3DOsmWwOQ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: SharpNEAT code optimizations","postDate":"1164150535","msgId":2844,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVrMDB1Nys0NmtmQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ1NUQwOTMzLjUwNjAyMDVAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":2817,"nextInTopic":2847,"prevInTime":2843,"nextInTime":2845,"topicId":2816,"numMessagesInTopic":16,"msgSnippet":"Colin, thanks very much for all the info.  I have to congratulate you on making SharpNEAT such a great system.  It s incredibly fast, has a nice GUI, and","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 16410 invoked from network); 21 Nov 2006 23:10:17 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m25.grp.scd.yahoo.com with QMQP; 21 Nov 2006 23:10:17 -0000\r\nReceived: from unknown (HELO n17a.bullet.scd.yahoo.com) (66.94.237.46)\n  by mta4.grp.scd.yahoo.com with SMTP; 21 Nov 2006 23:10:17 -0000\r\nReceived: from [66.218.69.4] by n17.bullet.scd.yahoo.com with NNFMP; 21 Nov 2006 23:08:55 -0000\r\nReceived: from [66.218.66.72] by t4.bullet.scd.yahoo.com with NNFMP; 21 Nov 2006 23:08:55 -0000\r\nDate: Tue, 21 Nov 2006 23:08:55 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ek00u7+46kf@...&gt;\r\nIn-Reply-To: &lt;455D0933.5060205@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: SharpNEAT code optimizations\r\nX-Yahoo-Group-Post: member; u=54567749; y=-vj-9gpFcBeJegLEH73ieLx1JT1qZwz3kmn0FqhtNsoTX6SmbRlB\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nColin, thanks very much for all the info.  I have to congratulate \nyou on m=\r\naking SharpNEAT such a great system.  It&#39;s incredibly fast, \nhas a nice GUI=\r\n, and implements an efficient version of NEAT.  Some \nof my students are no=\r\nw choosing to use it inside their projects.\n\nThe next version sounds exciti=\r\nng and I&#39;ll be looking forward to it.\n\nken\n\n--- In neat@yahoogroups.com, Co=\r\nlin Green &lt;cgreen@...&gt; wrote:\n&gt;\n&gt; Kenneth Stanley wrote:\n&gt; &gt; Colin, I apolo=\r\ngize if this is something that was discussed \nearlier, \n&gt; &gt; but could you c=\r\nomment on what makes SharpNEAT so fast?  I was \nplaying \n&gt; &gt; with the lates=\r\nt version and was pretty surprised that it runs 25 \n&gt; &gt; generations of e.g.=\r\n tic tac toe in what seems like 1 second.  \nHow is \n&gt; &gt; that possible?  \n&gt; =\r\n&gt;   \n&gt; \n&gt; Hi Ken, sure no problem. It&#39;s easiest if I explain from the \nbegi=\r\nnning so \n&gt; apologies if some of the explanation seems obvious and/or long =\r\n\nwinded...\n&gt; \n&gt; One of the top design goals for me has always been to make =\r\n\nsharpneat as \n&gt; fast as possible. This is on the basis that once we have a=\r\n genetic \n&gt; algorithm with no /theoretical/ limit to the complexity of \nsol=\r\nutions it \n&gt; can evolve, the next barrier to progression in what we do come=\r\ns \nfrom \n&gt; /practical/ limits - speed of hardware and efficiency of the \nal=\r\ngorithm \n&gt; code. So if we have two algorithms that do exactly the same thin=\r\ng \nbut \n&gt; one is twice as fast as the other then in the realm of GA&#39;s the \n=\r\nfaster \n&gt; GA is twice as likely to find a solution to a given problem in a =\r\n\ngiven \n&gt; amount of time on a given piece of hardware.\n&gt; \n&gt; So where GA&#39;s a=\r\nre concerned I would say that optimisation is a \ngood \n&gt; thing, at least up=\r\n to a point. Of course this goes against the \ngrain in \n&gt; many software dev=\r\nelopment and computer science circles where \nKnuth&#39;s \n&gt; phrase &quot;optimisatio=\r\nn is the root of all evil&quot; is often [mis]\nquoted. \n&gt; Optimisation is probab=\r\nly unnecessary in 99% of the code that gets \n&gt; written in the world, especi=\r\nally the commercial world, and \nactually this \n&gt; &quot;optimisation is bad&quot; idea=\r\n seems to be quite prevalent. I \npersonally in \n&gt; my day job come across al=\r\ngorithms that need to run within certain \ntime \n&gt; limits, e.g. syntax colou=\r\nring of textual documents, or simply as \nfast as \n&gt; possible, e.g. in web s=\r\nerver based applications where the number \nof \n&gt; concurrent users per serve=\r\nr box is proportional to the CPU and \nmemory \n&gt; efficiency of the code. The=\r\n commercial people often just don&#39;t get \nthat \n&gt; the extra time spent optim=\r\nising some code is a commercially sound \n&gt; choice, I guess because of the t=\r\nendency of some coders to optimise \nall \n&gt; code regardless of whether it ma=\r\nkes sense or not, thus going over \n&gt; deadlines and creating over-complex ha=\r\nrd to maintain code.\n&gt; \n&gt; Anyway the point is that sometimes optimisation i=\r\ns a good thing \nand I \n&gt; personally took the decision to spend time on opti=\r\nmising each \nlittle \n&gt; nook and cranny of sharpneat. Actually there have be=\r\nen areas where \nI&#39;ve \n&gt; taken the easy/quick approach where the code isn&#39;t =\r\nparticularly \ncritical \n&gt; to the overall speed of the GA as a whole or wher=\r\ne at the \nbeginning of \n&gt; the project I just wanted to get it up and runnin=\r\ng, but eventually \nI did \n&gt; go back over the code and optimise distinct chu=\r\nnks of it. A good \nexample \n&gt; would be the neural network optimisations I d=\r\nid sometime ago:\n&gt; \n&gt; http://sharpneat.sourceforge.net/network_optimization=\r\n.html\n&gt; \n&gt; and of course there&#39;s my fast random number generator article:\n&gt;=\r\n \n&gt; http://www.codeproject.com/csharp/FastRandom.asp\n&gt; \n&gt; \n&gt; But even with =\r\nthe quick/easy code I was still trying to structure \nthe \n&gt; code in such a =\r\nway that it could be optimised in future, but this \n&gt; basically boils down =\r\nto breaking the code down into discrete, \nloosely \n&gt; coupled chunks of func=\r\ntionality that could be re-written with \nminimal \n&gt; impact on other areas o=\r\nf code.\n&gt; \n&gt; Beyond this I used a performance profiler (nprof) to highlight=\r\n \nwhere the \n&gt; CPU was spending the most amount of time and thus which area=\r\ns need \nto be \n&gt; looked at and possibly re-written. E.g. one simple modific=\r\nation I \nmade \n&gt; was to modify the GetHashCode() method on one of my classe=\r\ns that \ngot \n&gt; placed into a HashTable because it turned out that Microsoft=\r\n&#39;s \nbuilt in \n&gt; hash code method was especially inefficient in the particul=\r\nar \nscenario I \n&gt; was using it. That&#39;s not something you&#39;re ever likely to =\r\nknow \nabout so \n&gt; profiling is definitely a useful tool.\n&gt; \n&gt; I also make h=\r\neavy use of things like Hashtables and storing of \nindexes \n&gt; into arrays i=\r\nnstead of looping/searching for objects,  and \nbasically \n&gt; think about wha=\r\nt is the crux of what I&#39;m trying to achieve with a \npiece \n&gt; of code and wh=\r\nat is the absolute bare minimum amount of work(code) \nI \n&gt; need to do to ac=\r\nhieve that. Sometimes with a bit of thought you \ncan \n&gt; factor out whole ch=\r\nunks of code and gain orders of magnitude in \nspeed.\n&gt; \n&gt; The only problem =\r\nwith all this is that there is a balance between \neasy \n&gt; readability of co=\r\nde and optimisation. If you&#39;re writing a library \nthat \n&gt; you and others wi=\r\nll be experimenting with and modifying then you \nwant it \n&gt; to be readable,=\r\n flexible code. Optimised code can often be very \nrigid, \n&gt; inflexible and =\r\nhard to modify. With sharpneat my intention was(and \nis) \n&gt; to optimise all=\r\n the core algorithm and genetic (crossover, \nmutation, \n&gt; genome comparison=\r\n, etc) code as much as possible without getting \nreally \n&gt; silly, e.g. it&#39;s=\r\n usually possible to squeze a bit more speed out \nof a \n&gt; given piece of co=\r\nde but the law of diminishing returns kicks in, \ne.g. \n&gt; twice as much effo=\r\nrt and/or complexity for just a small gain in \n&gt; performance. This optimisa=\r\ntion isn&#39;t greatly detrimental to \nsharpneat&#39;s \n&gt; usability since mostly yo=\r\nu just want to plug in a new experiment \nor (in \n&gt; future) a new genome typ=\r\ne or type of neural network.\n&gt; \n&gt; So in summation it&#39;s down to meticulous c=\r\noding of algorithms and \n&gt; performance profiling. It can be quite time cons=\r\numing hence the \ntensions \n&gt; optimisation can cause in the commercial world=\r\n, but it&#39;s quite \n&gt; interesting sometimes to see just how much faster you c=\r\nan make an \nalgorithm.\n&gt; \n&gt; As a final note I am still working on SharpNEAT=\r\n version 2.0 in \nfits and \n&gt; bursts. This is partly to gain some extra perf=\r\normance from the use \nof \n&gt; generics, but mainly it&#39;s a restructuring of th=\r\ne code to make it \nfar \n&gt; more flexible, e.g. allowing the genome class and=\r\n neural network \nclasses \n&gt; to be easily switched and essentially making sh=\r\narpneat a general \npurpose \n&gt; GA code library that happens to support NEAT.=\r\n\n&gt; \n&gt; Regards,\n&gt; \n&gt; Colin.\n&gt;\n\n\n\n\n"}}