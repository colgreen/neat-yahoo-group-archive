{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"p6aSBHf0wPLWmR-SuKmE-ZccmiKp1I0W_zEi19Nm1p-wBZ5tGZzonZyX1ev9jTBq9vWye8BfBGgfjap0upG5CCQ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Need Help","postDate":"1187287797","msgId":3525,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZhMjN0bCtycGpnQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZhMjM5Mys3aTN1QGVHcm91cHMuY29tPg=="},"prevInTopic":3524,"nextInTopic":3527,"prevInTime":3524,"nextInTime":3526,"topicId":3524,"numMessagesInTopic":5,"msgSnippet":"Wael, Take a look at ALN s ( Adaptive Logic Network ) at the below two web links. http://www.dendronic.com/main.htm http://www.cs.cmu.edu/afs/cs/project/ai- ","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 31345 invoked from network); 16 Aug 2007 18:10:25 -0000\r\nReceived: from unknown (66.218.66.70)\n  by m44.grp.scd.yahoo.com with QMQP; 16 Aug 2007 18:10:25 -0000\r\nReceived: from unknown (HELO n30a.bullet.sp1.yahoo.com) (209.131.38.252)\n  by mta12.grp.scd.yahoo.com with SMTP; 16 Aug 2007 18:10:24 -0000\r\nReceived: from [216.252.122.217] by n30.bullet.sp1.yahoo.com with NNFMP; 16 Aug 2007 18:09:58 -0000\r\nReceived: from [66.218.69.2] by t2.bullet.sp1.yahoo.com with NNFMP; 16 Aug 2007 18:09:58 -0000\r\nReceived: from [66.218.66.88] by t2.bullet.scd.yahoo.com with NNFMP; 16 Aug 2007 18:09:57 -0000\r\nDate: Thu, 16 Aug 2007 18:09:57 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fa23tl+rpjg@...&gt;\r\nIn-Reply-To: &lt;fa2393+7i3u@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Need Help\r\nX-Yahoo-Group-Post: member; u=281645563; y=NnldqHBPKKIs4WWtoFdDb4jkIFFUv4VP0cJnNphaUHoYeg\r\nX-Yahoo-Profile: afcarl2\r\n\r\nWael,\n\nTake a look at ALN&#39;s (&quot;Adaptive Logic Network&quot;) at the below two web=\r\n \nlinks.\n\nhttp://www.dendronic.com/main.htm\n\nhttp://www.cs.cmu.edu/afs/cs/p=\r\nroject/ai-\nrepository/ai/areas/neural/systems/atree/0.html\n\n\n\n\n--- In neat@=\r\nyahoogroups.com, &quot;Wael&quot; &lt;lepacha@...&gt; wrote:\n&gt;\n&gt; I am developing an ANN for=\r\n a smart card platform, which is from\n&gt; experience, the worst to work with,=\r\n its tedious and very \nrestricted. I\n&gt; am trying to implement an ANN to lea=\r\nrn the XOR function, i can only\n&gt; use shorts or  integers. i designed it on=\r\n a pc, and it used to work\n&gt; fine until i changed everything to integer, it=\r\n stopped giving the\n&gt; right results. it should learn the XOR function which=\r\n it used to do\n&gt; with double or float weights. i am using a tanh activation=\r\n function,\n&gt; which i know will not work with the Integer weights. Below is =\r\nmy \ncode\n&gt; its short, can any one help please with this. i think i need the=\r\n \nright\n&gt; activation function. or may be i have some other bugs, please let=\r\n me\n&gt; know if u can spot any....\n&gt; \n&gt; \n&gt; import java.lang.Math;\n&gt; import ja=\r\nva.util.*;\n&gt; import java.io.*;\n&gt; import java.lang.*;\n&gt; \n&gt; public class Java=\r\nMLP\n&gt; {\n&gt; \n&gt;  //user defineable variables\n&gt;  public static int numEpochs =\r\n=3D 500;   //number of training cycles\n&gt;  public static int numInputs  =3D =\r\n3;    //number of inputs - this\n&gt; includes the input bias\n&gt;  public static =\r\nint numHidden  =3D 4;    //number of hidden units\n&gt;  public static int numP=\r\natterns =3D 4;   //number of training patterns\n&gt; \n&gt; \n&gt;  //process variables=\r\n\n&gt;  public static int patNum;\n&gt;  public static int errThisPat;\n&gt;  public st=\r\natic int outPred;\n&gt;  \n&gt;  \n&gt; \n&gt;  //training data\n&gt; \n&gt;  public static int [] =\r\nInputs =3D new int [12];\n&gt; \n&gt;  public static int [] Output =3D new int[numP=\r\natterns];\n&gt; \n&gt;  //the outputs of the hidden neurons\n&gt;  public static int []=\r\n hiddnValue  =3D new int [numHidden];\n&gt; \n&gt;  //the weights\n&gt;  public static =\r\nint [] weghtsInH =3D new int [12];\n&gt; \n&gt;  public static int [] weghtsOutH =\r\n=3D new int [numHidden];\n&gt; \n&gt; \n&gt; //=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; =\r\n//********** THIS IS THE MAIN PROGRAM **************************\n&gt; //=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; \n&gt;  public static void main(String[] args)=\r\n throws IOException {\n&gt; \t\tBufferedReader in =3D new BufferedReader(new\n&gt; In=\r\nputStreamReader(System.in));\n&gt; \t\t\n&gt;   // intialize user&#39;s secret data\n&gt;  \n&gt;=\r\n   //initiate the weights\n&gt;   initWeights();\n&gt; \n&gt;   //load in the data\n&gt;   =\r\ninitData();\n&gt;     \n&gt;   //train the network\n&gt;     for(int j =3D 0;j &lt;=3D num=\r\nEpochs;j++)\n&gt;     {\n&gt;         for(int i =3D 0;i&lt;numPatterns;i++)\n&gt;         =\r\n{\n&gt; \n&gt;             //select a pattern at random\n&gt;             patNum =3D (i=\r\nnt)((Math.random()*numPatterns)-0.001);\n&gt;             //System.out.println(=\r\n &quot;************&quot; +patNum +\n&gt; &quot;*****************&quot;);\n&gt; \n&gt;             //calcul=\r\nate the current network output\n&gt;             //and error for this pattern\n&gt;=\r\n             calcNet();\n&gt; \n&gt;             //change network weights\n&gt;        =\r\n     WeightChangesOutH();\n&gt;             WeightChangesInH();\n&gt;         }\n&gt; \n=\r\n&gt;     }\n&gt; \n&gt;     //training has finished\n&gt;     //display the results\n&gt;     =\r\ndisplayResults();\n&gt;       \n&gt;  }\n&gt; \n&gt; //=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; //*=\r\n********* END OF THE MAIN PROGRAM **************************\n&gt; //=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D\n&gt; \n&gt; \n&gt; //************************************\n&gt; p=\r\nublic static void calcNet()\n&gt;  {\n&gt;  \tint t =3D 0;\n&gt;     //calculate the out=\r\nputs of the hidden neurons\n&gt;     //the hidden neurons are tanh\n&gt;     for(in=\r\nt i =3D 0;i&lt;numHidden;i++)\n&gt;     {\n&gt;     \t\n&gt; \thiddnValue[i] =3D 0;\n&gt; \n&gt;    =\r\n     for(int j =3D 0;j&lt;numInputs;j++)\n&gt;         {\n&gt;         \tt =3D ((3*i)+j=\r\n);\n&gt;         \thiddnValue[i] =3D (int)(hiddnValue[i] +\n&gt; (int)((Inputs[(patN=\r\num*3)+j] * weghtsInH[t])));\t\n&gt;         }\n&gt;         hiddnValue[i] =3D tanh(h=\r\niddnValue[i]);\n&gt;     }\n&gt; \n&gt;    //calculate the output of the network\n&gt;    /=\r\n/the output neuron is linear\n&gt;    outPred =3D 0;\n&gt; \n&gt;    for(int i =3D 0;i&lt;=\r\nnumHidden;i++)\n&gt;     outPred =3D outPred + hiddnValue[i] * weghtsOutH[i];\n&gt;=\r\n \n&gt;     //calculate the error\n&gt;     errThisPat =3D (int)(outPred - Output[p=\r\natNum]);\n&gt;  }\n&gt;  \n&gt;  \n&gt; \n&gt; //************************************\n&gt;  public=\r\n static void WeightChangesOutH()\n&gt;  //adjust the weights hidden-output\n&gt;  {=\r\n\n&gt;    for(int k =3D 0;k&lt;numHidden;k++)\n&gt;    {\n&gt;     int weightChange =3D 7 =\r\n* errThisPat * hiddnValue[k] / 100;\n&gt;     weghtsOutH[k] =3D weghtsOutH[k] -=\r\n weightChange;\n&gt; \n&gt;     //regularisation on the output weights\n&gt;     if (we=\r\nghtsOutH[k] &lt; -5)\n&gt;         weghtsOutH[k] =3D -5;\n&gt;     else if (weghtsOutH=\r\n[k] &gt; 5)\n&gt;         weghtsOutH[k] =3D 5;\n&gt;    }\n&gt;  }\n&gt; \n&gt; \n&gt; //*************=\r\n***********************\n&gt;  public static void WeightChangesInH()\n&gt;  //adjus=\r\nt the weights input-hidden\n&gt;  {\n&gt;  \tint g=3D0;\n&gt;   for(int i =3D 0;i&lt;numHid=\r\nden;i++)\n&gt;   {\n&gt;    for(int k =3D 0;k&lt;numInputs;k++)\n&gt;    {\n&gt;     int x =3D=\r\n 1 - (hiddnValue[i] * hiddnValue[i]);\n&gt;     x =3D x * weghtsOutH[i] * errTh=\r\nisPat * 7 / 10;\n&gt;     x =3D(int) (x * Inputs[(patNum*3)+k]);\n&gt;     int weig=\r\nhtChange =3D x;\n&gt;     g=3D((3*i)+k);\n&gt;     weghtsInH[g] =3D weghtsInH[g] - =\r\nweightChange;\n&gt;     \n&gt;    }\n&gt;   }\n&gt;  }\n&gt;  \n&gt; //****************************=\r\n*******\n&gt; \n&gt;  public static void initWeights()\n&gt;  {\n&gt;   weghtsOutH[0] =3D -=\r\n4276;\n&gt;   weghtsOutH[1] =3D 8910;\n&gt;   weghtsOutH[2] =3D -3127;\n&gt;   weghtsOu=\r\ntH[3] =3D 1711;\n&gt;   \n&gt;   weghtsInH[0] =3D -4393;\n&gt;   weghtsInH[1] =3D -1816=\r\n;\n&gt;   weghtsInH[2] =3D 7144;\n&gt;   weghtsInH[3] =3D 536;\n&gt;   weghtsInH[4] =3D=\r\n -5010;\n&gt;   weghtsInH[5] =3D -1463;\n&gt;   weghtsInH[6] =3D 6082;\n&gt;   weghtsIn=\r\nH[7] =3D -7693;\n&gt;   weghtsInH[8] =3D 3435;\n&gt;   weghtsInH[9] =3D 9213;\n&gt;   w=\r\neghtsInH[10]=3D 4044;\n&gt;   weghtsInH[11]=3D 2009;\n&gt;   }\n&gt;  \n&gt;  \n&gt;  \n&gt; //****=\r\n********************************\n&gt;  public static void initData()\n&gt;  {\n&gt; \n&gt;=\r\n     System.out.println(&quot;initialising data&quot;);\n&gt; \n&gt;     // the data here is =\r\nthe XOR data\n&gt;     // it has been rescaled to the range\n&gt;     // [-1][1]\n&gt; =\r\n    // an extra input valued 1 is also added\n&gt;     // to act as the bias\n&gt; =\r\n\n&gt;     Inputs[0]  =3D 1;\n&gt;     Inputs[1]  =3D -1;\n&gt;     Inputs[2]  =3D 1;//=\r\nbias\n&gt;     Output[0]  =3D 1;\n&gt; \n&gt;     Inputs[3]  =3D -1;\n&gt;     Inputs[4]  =\r\n=3D 1;\n&gt;     Inputs[5]  =3D 1;//bias\n&gt;     Output[1]  =3D 1;\n&gt; \n&gt;     Input=\r\ns[6]  =3D 1;\n&gt;     Inputs[7]  =3D 1;\n&gt;     Inputs[8]  =3D 1;//bias\n&gt;     Ou=\r\ntput[2]  =3D -1;\n&gt; \n&gt;     Inputs[9]  =3D -1;\n&gt;     Inputs[10] =3D -1;\n&gt;    =\r\n Inputs[11] =3D 1;//bias\n&gt;     Output[3]  =3D -1;\n&gt; \n&gt; \n&gt;  }\n&gt; \n&gt; \n&gt; //****=\r\n********************************\n&gt;  public static int tanh(double x)\n&gt;  {\n&gt;=\r\n     if (x &gt; 20)\n&gt;         return 1;\n&gt;     else if (x &lt; -20)\n&gt;         retu=\r\nrn -1;\n&gt;     else\n&gt;         {\n&gt;         int a =3D (int)(Math.exp(x));\n&gt;    =\r\n     int b =3D (int)(Math.exp(-x));\n&gt;         return (a-b)/(a+b);\n&gt;        =\r\n }\n&gt;  }\n&gt; \n&gt; \n&gt; //************************************\n&gt;  public static voi=\r\nd displayResults()\n&gt;     {\n&gt;      for(int i =3D 0;i&lt;numPatterns;i++)\n&gt;     =\r\n    {\n&gt;         patNum =3D i;\n&gt;         calcNet();\n&gt;         System.out.pri=\r\nntln(&quot;pat =3D &quot; + (patNum+1) + &quot; actual =3D &quot; +\n&gt; Output[patNum] + &quot; neural=\r\n model =3D &quot; + outPred);\n&gt;         }\n&gt;     }\n&gt; \n&gt; //***********************=\r\n****************************************/*\n&gt; \n&gt; }\n&gt;\n\n\n\n"}}