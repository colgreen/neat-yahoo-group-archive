{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"bUYIcp6brbCV_YVWW6hENPMzCOziH-xuedvKiqm0ue2z_rUkjkU7dEY1aHi5up_i-4jmCI1EdSp6-b7RDDe-sr0","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Question Re: HyperNEAT","postDate":"1178059308","msgId":3245,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYxOGZuZCt0MWRrQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGYxOGNqaitla2pxQGVHcm91cHMuY29tPg=="},"prevInTopic":3244,"nextInTopic":3246,"prevInTime":3244,"nextInTime":3246,"topicId":3234,"numMessagesInTopic":13,"msgSnippet":"Ken, Two issues come to mind. The first is degree of required user intervention in the determination of substrate topology. The second issue is embedability. ","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 20367 invoked from network); 1 May 2007 22:42:17 -0000\r\nReceived: from unknown (66.218.66.71)\n  by m42.grp.scd.yahoo.com with QMQP; 1 May 2007 22:42:17 -0000\r\nReceived: from unknown (HELO n32c.bullet.scd.yahoo.com) (66.94.237.10)\n  by mta13.grp.scd.yahoo.com with SMTP; 1 May 2007 22:42:17 -0000\r\nReceived: from [209.73.164.83] by n32.bullet.scd.yahoo.com with NNFMP; 01 May 2007 22:41:50 -0000\r\nReceived: from [66.218.66.75] by t7.bullet.scd.yahoo.com with NNFMP; 01 May 2007 22:41:50 -0000\r\nDate: Tue, 01 May 2007 22:41:48 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f18fnd+t1dk@...&gt;\r\nIn-Reply-To: &lt;f18cjj+ekjq@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Question Re: HyperNEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=wn0ofJRKjtsvuoTDEpKEd28ot56GnPJewLrWvFCJApu3OA\r\nX-Yahoo-Profile: afcarl2\r\n\r\nKen,\n\n   Two issues come to mind. The first is degree of required user \nint=\r\nervention in the determination of substrate topology. The second \nissue is =\r\nembedability.\n\n   It seems reasonable that the Hypercube network only has m=\r\neaning in \nthe context of the specific substrate employed during the \nevolu=\r\ntionary process. The addition of hidden nodes to the substrate \ntopology fa=\r\nlls outside the scalability of a Hypercube network \nassociated with an incr=\r\nease in resolution in the original dimensions \nof the substrate input and o=\r\nutput nodes.\n\n   Taking your position regarding attempting to cast the prob=\r\nlem in a \nmanner that facilitates the geometric relationships (I&#39;m using th=\r\ne \nterm geometric to represent the larger n-dimensional design space), \nit =\r\nwould appear that a reasonable approach would be to let the \nproblem dictat=\r\ne the substrate input and output nodes, and then simply \nduplicate the subs=\r\ntrate input and output nodes as substrate hidden \nnodes, and let the thresh=\r\nolding of weights in the Hypercube network \nseparate the wheat from the cha=\r\nff. If there are input-to-input or \noutput-to-output proximity relationship=\r\ns, they will emerge through \nevolution of the Hypercube network.\n\n   I&#39;m ju=\r\nst trying to somehow automate the process and let the user \nfocus on proble=\r\nm definition (i.e. substrate input and output nodes). \nIf this approach is =\r\ntaken, then the genome would need to include both \nthe substrate and hyperc=\r\nube topology definitions. \n\n   This leads into the second issue of embedabi=\r\nlity, or taking what \nyou have evolved and have the ability to embed it int=\r\no a higher level \nnetwork. Which is another one of the &quot;multiple reasons&quot; w=\r\nhy I believe \nthe ability to maintain multiple unique inputs and outputs fo=\r\nr a node \nin a network, substrate or hypercube, is essential to the develop=\r\nment \nof more &quot;brain-like&quot; networks.\n\nThanks,\n   Andy Carl\n\n\n--- In neat@ya=\r\nhoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Andy,\n&gt; \n&gt; Sure,=\r\n I understand it was just an example.  I went with the example \n&gt; just for =\r\nillustration, but let me give a shot at a more general \n&gt; answer:\n&gt; \n&gt; I th=\r\nink the most general answer is that to the extent inputs and \n&gt; outputs rea=\r\nlly are apples and oranges there is still valuable \n&gt; information that can =\r\nbe included with respect to how they are \n&gt; separately arranged.  It is not=\r\n only the relationship of inputs to \n&gt; outputs, but the relations of inputs=\r\n to each other (and outputs to \n&gt; each other) that is potentially valuable.=\r\n  \n&gt; \n&gt; On the other hand, I don&#39;t think inputs and outputs are really \noft=\r\nen \n&gt; going to truly be apples and oranges since both normally will be at \n=\r\n&gt; least about the same world, i.e. what I see in the world vs. what I \n&gt; do=\r\n in the world; so there is an inherent conceptual relationship \n&gt; between t=\r\nhem in most contexts.  While it is possible to pose a \n&gt; problem in a way t=\r\nhat removes some of that relationship (such as in \n&gt; your example), it shou=\r\nld normally be possible to recast the problem \n&gt; at least in part to restor=\r\ne it.  That is, there is more than one \nway \n&gt; to pose a problem from a geo=\r\nmetric standpoint.  In general if the \n&gt; inputs and outputs are both about =\r\nthe same world, then some method \n&gt; is probably available.\n&gt; \n&gt; At the same=\r\n time, even in cases where there is really no \n&gt; relationship whatsoever, t=\r\nhere is still utility in arranging the \n&gt; inputs and outputs separately in =\r\nways that correspond to their \n&gt; respective geometric contexts.\n&gt; \n&gt; ken\n&gt; =\r\n\n&gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Ken,\n&gt; &gt;=\r\n \n&gt; &gt;    The cited example modification of the paper geometry problem \n&gt; wa=\r\ns \n&gt; &gt; only to provide an instance in which the dimensionality of the \n&gt; &gt; =\r\nsubstrate inputs and outputs, as applied to the Hypercube inputs, \n&gt; as \n&gt; =\r\n&gt; stated in the original attempted general characterization, were \nof \n&gt; &gt; =\r\ndiffering dimensionality.\n&gt; &gt; \n&gt; &gt;    I believe the jist of your other cont=\r\nemporaneous conversations \n&gt; is \n&gt; &gt; that additional a priori knowledge may=\r\nbe interjected via the \n&gt; &gt; Hypercube inputs, since:\n&gt; &gt; \n&gt; &gt; (a) this addi=\r\ntional information is associated with the substrate \n&gt; &gt; input/output node,=\r\n though not expressly represented in same, and\n&gt; &gt; \n&gt; &gt; (b) this additional=\r\n information is segregated to either \nthe &quot;from&quot; \n&gt; &gt; or &quot;to&quot; nodes associa=\r\nted with the current substrate link under \n&gt; &gt; consideration.\n&gt; &gt; \n&gt; &gt;    I=\r\n am only attempting to clarify the seemly more general \n&gt; condition \n&gt; &gt; in=\r\n which the additional &quot;information&quot; associated with a substrate \n&gt; &gt; input =\r\nnode is of different content and/or dimensionality than the \n&gt; &gt; additional=\r\n &quot;information&quot; associated with a substrate output node \n&gt; &gt; (i.e. apples an=\r\nd oranges, not just oranges and oranges). The \n&gt; &gt; specifics of the cited m=\r\nodified example is irrelevant except in \n&gt; its \n&gt; &gt; attempt to illustrate t=\r\nhis point.\n&gt; &gt; \n&gt; &gt; Thanks,\n&gt; &gt;    Andy Carl\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yaho=\r\nogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Andy,\n&gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; There are still a lot of ways to configure the substrate for \n&gt; such =\r\na \n&gt; &gt; &gt; problem, so it&#39;s difficult to give a general answer.  For \n&gt; examp=\r\nle, \n&gt; &gt; &gt; you might have a single 2D input layer connecting to a single \n&gt;=\r\n &gt; output \n&gt; &gt; &gt; node (yes/no); or you could have a multilayer 3D input fie=\r\nld \n&gt; (where \n&gt; &gt; &gt; each 2D layer is a type of object) connecting to a 2D o=\r\nutput \n&gt; field \n&gt; &gt; &gt; (where each pixel answers the question, is there over=\r\nlap \n&gt; here?).  \n&gt; &gt; &gt; You might have a hidden layer, and you might not.  Y=\r\nou might \n&gt; allow \n&gt; &gt; &gt; the hidden layer to express lateral connections, a=\r\nnd you might \n&gt; &gt; not.  \n&gt; &gt; &gt; You might have a 3D hidden layer or a 2D hid=\r\nden layer.  You \n&gt; might \n&gt; &gt; &gt; embed everything in 3D, or you might map a =\r\n3D coordinate to a \n&gt; 2D, \n&gt; &gt; or \n&gt; &gt; &gt; a 2D or a 3D, etc..\n&gt; &gt; &gt; \n&gt; &gt; &gt; I=\r\nn each case, the implications are different about how \n&gt; proximities \n&gt; &gt; &gt;=\r\n are incorporated or expressed.  In some cases it can be \nexplicit \n&gt; &gt; &gt; w=\r\nithin parts of the substrate; in some cases it is implicit.  \n&gt; For \n&gt; &gt; &gt; =\r\nexample, if there is only a single output node and a 2D sheet \nof \n&gt; &gt; &gt; in=\r\nputs, then the CPPN does not even need to take a target \n&gt; location \n&gt; &gt; &gt; =\r\nas input, since there is only one target.  In that case you \njust \n&gt; &gt; &gt; qu=\r\nery for each input node what weight is coming out of it.  In \n&gt; such \n&gt; &gt; &gt;=\r\n a case, it is true that you do not explicitly provide a \n&gt; proximity \n&gt; &gt; =\r\n&gt; input to the CPPN; however proximity is still implicit within \n&gt; the \n&gt; &gt;=\r\n &gt; representation since input nodes that are near each other are \n&gt; also \n&gt;=\r\n &gt; &gt; nearby in the function domain of the CPPN, that is, it can use \n&gt; that=\r\n \n&gt; &gt; &gt; nearness even though it is not explicitly provided as input.  \n&gt; &gt; =\r\n&gt; \n&gt; &gt; &gt; Please let me know if I didn&#39;t answer adequately and I can try \n&gt; =\r\nto \n&gt; &gt; be \n&gt; &gt; &gt; more specific, but I might need more detail on the precis=\r\ne \n&gt; scenario \n&gt; &gt; &gt; you are considering.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n Ken,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;    One troubling &quot;detail&quot; is that of differences in =\r\n\n&gt; &gt; dimensionality \n&gt; &gt; &gt; &gt; between substrate inputs and outputs. In the e=\r\nxamples used in \n&gt; the \n&gt; &gt; &gt; &gt; various papers, the dimensionality of the s=\r\nubstrate input and \n&gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; nodes, as applied to the Hypercub=\r\ne inputs, were identical \n&gt; (i.e. \n&gt; &gt; &gt; x_in, \n&gt; &gt; &gt; &gt; y_in, x_out, y_out)=\r\n. This simplifies the concept of distance. \n&gt; But \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; probl=\r\nem could just as easily have been: Do the two squares on \n&gt; the \n&gt; &gt; &gt; &gt; vi=\r\nsual field overlap? (yes/no). In this case, dimensionality \n&gt; of \n&gt; &gt; &gt; the=\r\n \n&gt; &gt; &gt; &gt; substrate input and output nodes, as applied to the Hypercube \n&gt; =\r\n&gt; &gt; inputs, \n&gt; &gt; &gt; &gt; have differing dimensionality, even though the answer =\r\nis \n&gt; strongly \n&gt; &gt; &gt; &gt; dependent on proximity in the input visual field. A=\r\nny \n&gt; experience \n&gt; &gt; &gt; or \n&gt; &gt; &gt; &gt; comments on this seemly more common gen=\r\neral condition?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt;    Andy Carl \n&gt; &gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; \n&gt; wrote:\n&gt;=\r\n &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Andy, I&#39;d say this is a about right.  I elaborate a bit =\r\n\n&gt; below \n&gt; &gt; &gt; each \n&gt; &gt; &gt; &gt; &gt; part of your question:\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;=\r\n --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; Jason or Ken,\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt;    I am attempting to understa=\r\nnd the nature of inputs & \n&gt; &gt; &gt; outputs \n&gt; &gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; &gt; &gt; applied t=\r\no both the Hypercube and substrate networks, \n&gt; without \n&gt; &gt; &gt; &gt; being \n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; limited to the geometric nature of the visual-based \n&gt; examples. \n=\r\n&gt; &gt; &gt; The \n&gt; &gt; &gt; &gt; &gt; &gt; examples provided were helpful, but I am striving fo=\r\nr a \n&gt; more \n&gt; &gt; &gt; &gt; &gt; general \n&gt; &gt; &gt; &gt; &gt; &gt; guideline for application to mo=\r\nre general problems.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt;    Would it be correct to say=\r\n that:\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; (a) Substrate Network: Inputs & Outputs ide=\r\nntified as \n&gt; typical \n&gt; &gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; application of conventional NE=\r\nAT to a problem of interest;\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; This stateme=\r\nnt is correct although you might do things that \n&gt; you \n&gt; &gt; &gt; &gt; would \n&gt; &gt; =\r\n&gt; &gt; &gt; avoid doing in conventional NEAT because HyperNEAT can deal \n&gt; &gt; with=\r\n \n&gt; &gt; &gt; so \n&gt; &gt; &gt; &gt; &gt; many more inputs and outputs.  So you might for examp=\r\nle \n&gt; output \n&gt; &gt; a \n&gt; &gt; &gt; &gt; high \n&gt; &gt; &gt; &gt; &gt; resolution representation of y=\r\nour possible decisions, which \n&gt; is \n&gt; &gt; &gt; &gt; &gt; something you normally would=\r\nn&#39;t do in regular NEAT.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; (b) Hypercube Network: (i) I=\r\nnputs: Other \n&gt; &gt; &gt; descriptors/parameters \n&gt; &gt; &gt; &gt; &gt; (i.e. \n&gt; &gt; &gt; &gt; &gt; &gt; ge=\r\nometric coordinates being a subset thereof), associated \n&gt; &gt; with \n&gt; &gt; &gt; a =\r\n\n&gt; &gt; &gt; &gt; &gt; given \n&gt; &gt; &gt; &gt; &gt; &gt; substrate network node (i.e. like a timestamp=\r\n associated \n&gt; with \n&gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; coordinate point comprising a tra=\r\njectory), mutually \n&gt; exclusive \n&gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; descr=\r\niptor/parameter expressly identified in the \nsubstrate \n&gt; &gt; &gt; node, \n&gt; &gt; &gt; =\r\n&gt; &gt; each \n&gt; &gt; &gt; &gt; &gt; &gt; being collected together and collectively identified =\r\nas \n&gt; &gt; either \n&gt; &gt; &gt; &gt; &gt; a &quot;from&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; or &quot;to&quot; terminator of a lin=\r\nk between any two substrate \n&gt; nodes; \n&gt; &gt; &gt; and \n&gt; &gt; &gt; &gt; &gt; (ii) \n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; Output: Weight of link between the currently \n&gt; &gt; identified &quot;from&quot; \n&gt; &gt;=\r\n &gt; &gt; &gt; and &quot;to&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; substrate nodes.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; &gt; I think this characterizes it well, although there is even \n&gt; more \n&gt; =\r\n&gt; &gt; &gt; &gt; flexibility.  You can for example use additional outputs on \n&gt; the =\r\n\n&gt; &gt; &gt; &gt; CPPN \n&gt; &gt; &gt; &gt; &gt; to represent additional attributes of links and/or=\r\n nodes.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; The timestamp idea is interesting- if I unde=\r\nrstand \ncorrectly \n&gt; it \n&gt; &gt; &gt; &gt; would \n&gt; &gt; &gt; &gt; &gt; cause the network to chan=\r\nge over time in a deterministic \n&gt; way.  \n&gt; &gt; &gt; &gt; &gt; Although maybe I&#39;m misu=\r\nnderstanding.  But certainly things \n&gt; like \n&gt; &gt; &gt; &gt; that \n&gt; &gt; &gt; &gt; &gt; are po=\r\nssible.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; It&#39;s difficult to write an accurate general =\r\ndescription of \n&gt; &gt; &gt; exactly \n&gt; &gt; &gt; &gt; &gt; what goes in and comes out of the =\r\nCPPN at this point \nbecause \n&gt; I \n&gt; &gt; &gt; have \n&gt; &gt; &gt; &gt; &gt; no doubt that at th=\r\nis early stage that new ideas are going \n&gt; to \n&gt; &gt; &gt; &gt; broaden \n&gt; &gt; &gt; &gt; &gt; t=\r\nhe possibilities beyond what I am currently aware of.   \nBut \n&gt; &gt; &gt; what \n&gt;=\r\n &gt; &gt; &gt; you \n&gt; &gt; &gt; &gt; &gt; said captures it pretty well for now.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}