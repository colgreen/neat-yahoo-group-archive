{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"PnFE4rJOWwo4zbZlRqKTcQ2RYAN5QML19txN9WeUqn13FDsS2Y4MJ5lDEyuE_6KDtZAP4h-eYzHFUPhp54O2eW2fz-Gz_Vqz1whTOCF0dVT4","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Learning How to Learn","postDate":"1067627988","msgId":182,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGJudWNraythcXVhQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDMxMDMwMTc1NzQ2LjQ3OTg5LnFtYWlsQHdlYjIxNDAyLm1haWwueWFob28uY29tPg=="},"prevInTopic":181,"nextInTopic":183,"prevInTime":181,"nextInTime":183,"topicId":170,"numMessagesInTopic":15,"msgSnippet":"... What about neurons with continuous activation functions, like sigmoid.  Do you think that increases the effective storage capacity of the network? ken","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 82327 invoked from network); 31 Oct 2003 19:19:51 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m4.grp.scd.yahoo.com with QMQP; 31 Oct 2003 19:19:51 -0000\r\nReceived: from unknown (HELO n4.grp.scd.yahoo.com) (66.218.66.88)\n  by mta1.grp.scd.yahoo.com with SMTP; 31 Oct 2003 19:19:51 -0000\r\nReceived: from [66.218.67.134] by n4.grp.scd.yahoo.com with NNFMP; 31 Oct 2003 19:19:50 -0000\r\nDate: Fri, 31 Oct 2003 19:19:48 -0000\r\nTo: neat@yahoogroups.com\r\nSubject: Re: Learning How to Learn\r\nMessage-ID: &lt;bnuckk+aqua@...&gt;\r\nIn-Reply-To: &lt;20031030175746.47989.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 807\r\nX-Mailer: Yahoo Groups Message Poster\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n--- In neat@yahoogroups.com, Mitchell Timin &lt;zenguyuno@y...&gt; wrote:\n&gt; Ken wrote:\n&gt; &lt;snip&gt;\n&gt; &gt; And what is the\n&gt; &gt; capacity of a\n&gt; &gt; fixed-weight recurrent network to remember\n&gt; &gt; information?\n&gt; \n&gt; The total amount of RAM is quite clearly defined:  N\n&gt; bits in the case of N binary neurons.   So N bits is\n&gt; clearly an upper limit on the memory capacity of a\n&gt; fully recurrent binary ANN with N neurons.  Since this\n&gt; ANN has more than two thousand weights, the memory\n&gt; capacity seems tiny, in proportion.  Furthermore, some\n&gt; of it is probably required to support the computation,\n&gt; and hence not available for the requirements of the\n&gt; problem domain.\n\nWhat about neurons with continuous activation functions,\nlike sigmoid.  Do you think that increases the effective\nstorage capacity of the network?\n\nken\n\n\n"}}