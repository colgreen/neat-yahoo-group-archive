{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":151231063,"authorName":"Joseph Reisinger","from":"Joseph Reisinger &lt;joeraii@...&gt;","profile":"joeraii","replyTo":"LIST","senderId":"SI5dxWi5vqHn-swbEKie7UhnQE2rkmM4dkp1Yb2olyohi6vQIIAMUE1_oc_QQhicuBlsjvjcW73uwLUM5eCQmxTU5PvMV2XmQofdcaERSw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"HyperNEAT and No Free Lunch","postDate":"1177904418","msgId":3218,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDU4QTgwRTYxLTEwMEQtNEEwQy1CMUNBLUY5NDMyRjZCMjVGMUBjcy51dGV4YXMuZWR1Pg==","inReplyToHeader":"PGYxM2ViOCtsbTB1QGVHcm91cHMuY29tPg==","referencesHeader":"PGYxM2ViOCtsbTB1QGVHcm91cHMuY29tPg=="},"prevInTopic":3217,"nextInTopic":3219,"prevInTime":3217,"nextInTime":3219,"topicId":3214,"numMessagesInTopic":27,"msgSnippet":"(I ve changed the thread title so that this post will be easier to ignore.) Sorry for dragging us deeper into a discussion of NFL, but I think this point is","rawEmail":"Return-Path: &lt;joeraii@...&gt;\r\nX-Sender: joeraii@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 15024 invoked from network); 30 Apr 2007 03:41:25 -0000\r\nReceived: from unknown (66.218.66.70)\n  by m51.grp.scd.yahoo.com with QMQP; 30 Apr 2007 03:41:25 -0000\r\nReceived: from unknown (HELO spunkymail-a7.g.dreamhost.com) (208.97.132.177)\n  by mta12.grp.scd.yahoo.com with SMTP; 30 Apr 2007 03:41:25 -0000\r\nReceived: from [10.0.0.115] (72-48-75-214.dyn.grandenetworks.net [72.48.75.214])\n\tby spunkymail-a7.g.dreamhost.com (Postfix) with ESMTP id E14DE5C21E\n\tfor &lt;neat@yahoogroups.com&gt;; Sun, 29 Apr 2007 20:40:21 -0700 (PDT)\r\nMime-Version: 1.0 (Apple Message framework v752.2)\r\nIn-Reply-To: &lt;f13eb8+lm0u@...&gt;\r\nReferences: &lt;f13eb8+lm0u@...&gt;\r\nContent-Type: text/plain; charset=US-ASCII; delsp=yes; format=flowed\r\nMessage-Id: &lt;58A80E61-100D-4A0C-B1CA-F9432F6B25F1@...&gt;\r\nContent-Transfer-Encoding: 7bit\r\nDate: Sun, 29 Apr 2007 22:40:18 -0500\r\nTo: neat@yahoogroups.com\r\nX-Mailer: Apple Mail (2.752.2)\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Joseph Reisinger &lt;joeraii@...&gt;\r\nSubject: HyperNEAT and No Free Lunch\r\nX-Yahoo-Group-Post: member; u=151231063; y=1UuoQ3PCGCvAsQBYOux3ZI8Fkv10IvygXAE2zjY9Uc4s3w\r\nX-Yahoo-Profile: joeraii\r\n\r\n(I&#39;ve changed the thread title so that this post will be easier to  \nignore.)\n\nSorry for dragging us deeper into a discussion of NFL, but I think  \nthis point is really important, especially if you are going to be  \nmaking these claims in front of a broader audience. Also I think it  \nis helpful for the audience here to be crystal clear on the NFL  \nissue. Its a very important theorem and it has been quite often  \nmisapplied (for instance, there is some evidence that Wolpert  \ninitially came up with NFL specifically to critique GAs).\n\n&gt; That&#39;s why I said it &quot;may&quot; be better for evolving very large scale  \n&gt; brains.\n&gt; The &quot;may&quot; hinges on the issues you bring up and others.  However,\n&gt; even the opportunity to be better is an advantage over having no such\n&gt; opportunity.  The opportunity of course can be squandered with the\n&gt; wrong a priori knowledge.   Yet part of my point is that it will\n&gt; often be the case that the natural geometry of a task is all you need\n&gt; to provide a powerful bias (or at least a bias that is better than\n&gt; nothing), so it will often be possible to seize the opportunity\n&gt; without a great deal of effort.\n\nOk, note your use of the word &quot;often&quot; instead of the word &quot;always.&quot;  \nJust that word substitution means that you aren&#39;t within the realm of  \nsituations that NFL covers. I totally agree with you that the  \napplication of such geometry can be useful. I just don&#39;t think you  \ncan leverage NFL to back up the argument you are making.\n\n&gt; It is true too that NEAT and other neural network algorithms do\n&gt; indeed allow for some inclusion of prior knowledge through their\n&gt; input/output encoding.  However, note how I phrased my\n&gt; claim: &quot;HyperNEAT is not subject to the No Free Lunch theorem when\n&gt; comparing to algorithms that do not allow injecting such a priori\n&gt; knowledge.&quot;  That is, among algorithms that allow you to decide on an\n&gt; input encoding in the traditional way, the provision of such encoding\n&gt; does not give one algorithm a leg up over another since they all\n&gt; allow for such knowledge to be included.  HyperNEAT, on the other\n&gt; hand, allows a new kind of knowledge (i.e. geometry) to be included\n&gt; and therefore does have a potential leg up on that class of\n&gt; algorithms.\n\nBut this leg up would necessarily be different for each problem,  \nhence my original critique. You can&#39;t build the experimenter into the  \nsystem and still talk about NFL. Its just not applicable because you  \nare no longer doing any generalization across classes of problems.  \nTherefore you can&#39;t use it to build your case.\n\nYour argument runs something like: &quot;HyperNEAT has more parameters  \nthan the experimenter can set than other Non-Hyper NEATs that allow  \nhim/her to build in even better prior knowledge.&quot; But you are  \nneglecting the fact that the experimenter now has more possible  \nparameters to set incorrectly! At the very least, you should limit  \nyour statement just to problems where the geometry is known /to the  \nexperimenter/.  In the case where the experimenter knows the geometry  \na priori, and he is correct in that knowledge, then yes, HyperNEAT  \nwould outperform other Non-Hyper algorithms in the NFL sense.\n\n&gt; Of course it depends on how well the user takes\n&gt; advantage of the opportunity, but the opportunity is now there.  This\n&gt; fact does indeed mean that statements about HyperNEAT vs. other\n&gt; neuroevolution (or even machine learning) algorithms can cite an\n&gt; opportunity to genuinely be better on average, which in effect brings\n&gt; it outside NFL in one particular sense.\n\nIt can be better on average, if the experimenter always makes the  \ncorrect choices w.r.t. the geometry. But I don&#39;t think you can use  \nsuch &quot;oracle&quot; experimenters as a basis for comparison. And anyway,  \nNFL still holds, in a broader sense: For example, imagine the class  \nof problems that /seem/ to have an underlying geometry feature, lets  \ncall it &quot;A.&quot; There could possibly be instances of this class of  \nproblems where naively exploiting A would actually cause the learning  \nalgorithm to perform worse than not exploiting it. And in fact we  \ncould probably construct such a class.\n\nAgain, to sum up, I think the way you are framing the benefits of  \nHyperNEAT&#39;s geometry exploiting features rely solely on an  \nintelligent experimenter, and in that sense do sort of bypass NFL.  \nBut making such a statement is meaningless, because it basically  \nassumes that the experimenter always guesses right. And if I were  \nthat experimenter, then I wouldn&#39;t be here talking to you, I would  \nhave already solved strong AI :)\n\nHumbly,\n\n-- Joe\n\n"}}