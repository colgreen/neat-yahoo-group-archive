{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":487025037,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;afcarl2@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"UOrwqKO5LsGySJBLejUJPx-7uPgJDbatoRFCiNnS4h1KL9mxVhmix_RWPtEpC7JM6NAMJ0KpAyNS6c974InftYRtxbQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Python NEAT","postDate":"1310085781","msgId":5614,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGl2NWpxbCs1djFvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGl2M3VxcytobmRsQGVHcm91cHMuY29tPg=="},"prevInTopic":5613,"nextInTopic":5615,"prevInTime":5613,"nextInTime":5615,"topicId":535,"numMessagesInTopic":47,"msgSnippet":"Peter, A couple of thoughts. First, IMO one of the primary values of NEAT are the various methods of managing complexification of structure, not how the","rawEmail":"Return-Path: &lt;afcarl2@...&gt;\r\nX-Sender: afcarl2@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 73607 invoked from network); 8 Jul 2011 02:31:38 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m16.grp.re1.yahoo.com with QMQP; 8 Jul 2011 02:31:38 -0000\r\nX-Received: from unknown (HELO n40b.bullet.mail.sp1.yahoo.com) (66.163.168.154)\n  by mta2.grp.re1.yahoo.com with SMTP; 8 Jul 2011 02:31:38 -0000\r\nX-Received: from [69.147.65.151] by n40.bullet.mail.sp1.yahoo.com with NNFMP; 08 Jul 2011 00:43:02 -0000\r\nX-Received: from [98.137.34.72] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 08 Jul 2011 00:43:02 -0000\r\nDate: Fri, 08 Jul 2011 00:43:01 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;iv5jql+5v1o@...&gt;\r\nIn-Reply-To: &lt;iv3uqs+hndl@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;afcarl2&quot; &lt;afcarl2@...&gt;\r\nSubject: Re: Python NEAT\r\nX-Yahoo-Group-Post: member; u=487025037; y=7ypmvg5YFKujSMBDPM6TY24IjjGFp8jcLpfTWwtZwRr93w\r\nX-Yahoo-Profile: afcarl2\r\n\r\n\n\n\nPeter,\n\nA couple of thoughts. First, IMO one of the primary values of NE=\r\nAT are the various methods of managing complexification of structure, not h=\r\now the infrastructure is constrained to match NN evaluation. Many profoundl=\r\ny useful applications are entirely non-NN in nature, and the genome itself =\r\nis the answer, not the NN evaluation or activation output. The genome is pa=\r\nssed thru a translator and the evaluation is handled by a separate analysis=\r\n code. An example being the propulsion schematic of a rocket, where the gen=\r\nome directly represents the schematic, and the objective function is define=\r\nd by how closely the resulting prediction matches desired performance on a =\r\nweight and/or cost basis. The ability to seed the initial population with p=\r\nrevious &quot;simular-to&quot; designs/genomes, allows the incorporation human expert=\r\n input directly, and an obvious interpretation of best resulting genomes ou=\r\ntput. In this instance, the determination of directed/non-directed/multigra=\r\nph is moot within NEAT, the appropriate interpretation is made within the t=\r\nranslator prior to execution by the external analysis code, given proper an=\r\nd adequate meta-data.\n\nIn the other instance of direct evaluation of the ne=\r\ntwork, the generality on varying number of node inputs/output, evaluation f=\r\nunctions of nodes and embedded networks within a node can be addressed by i=\r\nnterpretation of node type and genome definition nomenclature. It would see=\r\nm that the explosion in size of the search space would tend to be addressed=\r\n via the complexification process as additional dimensionality is justified=\r\n as a consequence of incremental improved objective function value.\n\nAndy\n\n=\r\n--- In neat@yahoogroups.com, &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt; wrot=\r\ne:\n&gt;\n&gt; Hi Andy, \n&gt; \n&gt; The implementation is not yet complete, but things ar=\r\ne really good so far. NetworkX is a very good choice for the genomes, as it=\r\n gives me a lot of freedom, many bonus functions for the graphs, and saves =\r\nme debugging time. Basically this implementation allows any kind of graph t=\r\no be evolved. For example, nodes and edges can represent numeric data (inte=\r\nger & float) or objects from a set (like characters from an alphabet, class=\r\n instances or functions, etc.). When you define the graph type, you have to=\r\n write a distance function if you have objects from a set in the graph - li=\r\nke the distance between characters in the alphabet), and also a few more fu=\r\nnctions like mutators, which, of course, will change the objects randomly o=\r\nr the way you like. You can have any number of properties for nodes/edges. =\r\nYou can also have an undirected graph, or a multigraph where many edges con=\r\nnect the same nodes. You can even have nested genomes, where genomes are th=\r\ne objects from a set, which are attached to nodes or edges. This makes thin=\r\ngs mind-blowing and lifts NEAT to a much broader set of domains. I even thi=\r\nnk that the N in NEAT is somehow unnecessary here, as the primary objective=\r\n in this implementation is not neural networks. Neural networks will be der=\r\nived from a special function that will translate the graph and then build a=\r\n C++ object from it. They will be directed graphs with sigmoid or whatever =\r\nfunctions attached to nodes and floats attached to edges. (Node types also =\r\nattached to nodes - to know what is input and output). Perhaps I&#39;ll make a =\r\nseparate project designed for neural networks that will use the core module=\r\n. \n&gt; I will release the first version of the code soon, which will probably=\r\n not have rtNEAT and novelty search built in. CPPNs and HyperNEAT are just =\r\nspecial cases of graph evolution and interpretation, like neural networks. =\r\nThe special code about them will be added later as the project evolves. Per=\r\nhaps the community will like it and contribute some code. I can&#39;t promise a=\r\n release date, but work is progressing. Any ideas to minimize the search sp=\r\nace (which blows up as you add more properties to nodes and edges) are appr=\r\neciated. Also I could use some help about innovation numbers and crossover =\r\nbetween undirected and multi graphs. I&#39;m so afraid of bugs in these cases t=\r\nhat I haven&#39;t even started to think about it. :D\n&gt; \n&gt; Peter\n&gt; \n&gt; --- In nea=\r\nt@yahoogroups.com, &quot;afcarl2&quot; &lt;afcarl2@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Peter,\n&gt; &gt; \n&gt; &gt; H=\r\now is your python implementation going? Took a look at the NetworkX module.=\r\n It looks very interesting! In my C++ version, I had added variable input/o=\r\nutput connections, network within a node and seeding of the initial populat=\r\nion with the required infrastructure updates and a distributed processing b=\r\nackend. But what you are doing goes so much farther, that I am eager to get=\r\n a look at it!\n&gt; &gt; \n&gt; &gt; Andy\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;petar_c=\r\nhervenski&quot; &lt;petar_chervenski@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi all, \n&gt; &gt; &gt; \n&gt; &gt; &gt; I a=\r\nm almost done with the basic code and I&#39;ll mention some of its features now=\r\n. I decided to use NetworkX for the genomes, because this module has lots o=\r\nf useful algorithms and allows any python object to be a node and edges can=\r\n be associated with anything. This makes the evolution of neural networks a=\r\n tiny part of what&#39;s really possible. Any graph can be evolved, including u=\r\nndirected graphs and nodes/edges containing discrete one-of-N values (integ=\r\ners, lists of python objects, etc). So given that an evaluation function ex=\r\nists for any kind of graph, you can quickly setup evolution. Neural network=\r\ns are a particular kind of graphs and the package will have built in code n=\r\necessary to evolve neural networks - the initialization functions, mutators=\r\n, and a C++ interface to a class that represents the phenotypes. CPPNs supp=\r\nort is trivial to make, and given that python functions themselves can be a=\r\nttached to nodes, it&#39;s possible to have algorithmic nodes working with more=\r\n than one variable and .. well, infinite stuff. OK, I gotta go. Wish me luc=\r\nk debugging. Talk to you soon. :) \n&gt; &gt; &gt; \n&gt; &gt; &gt; Peter\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In n=\r\neat@yahoogroups.com, Jan van der Lugt &lt;janlugt@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hi =\r\nPeter,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Sound like an ambitious and noble plan. Good luck c=\r\noding, I&#39;m looking\n&gt; &gt; &gt; &gt; forward to seeing your results!\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;=\r\n Regards,\n&gt; &gt; &gt; &gt; Jan\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; On Mon, Mar 14, 2011 at 12:43, petar=\r\n_chervenski\n&gt; &gt; &gt; &gt; &lt;petar_chervenski@&gt;wrote:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; Hi people,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; For about a month I&#39;ll be writing =\r\na Python implementation of NEAT, which\n&gt; &gt; &gt; &gt; &gt; includes all advances in t=\r\nhe recent years, including rtNEAT, phased\n&gt; &gt; &gt; &gt; &gt; searching, leaky integr=\r\nators, HyperNEAT, HyperNEAT with evolving substrates,\n&gt; &gt; &gt; &gt; &gt; and novelty=\r\n search. Coevolution code and visualizations will be included.\n&gt; &gt; &gt; &gt; &gt; Op=\r\ntimized C++ code for running the NNs too. This code will be free and I\n&gt; &gt; =\r\n&gt; &gt; &gt; promise this will be the best NEAT code I can write. No bugs, no mean=\r\ningless\n&gt; &gt; &gt; &gt; &gt; NNs, etc.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Peter\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;  =\r\n\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}