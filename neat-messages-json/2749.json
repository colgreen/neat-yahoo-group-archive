{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"RCcgAMnmzfdy5_yxE-aK7X7b2GH6eBMLCj3QLvOVzbppEIEDrskGDyGW5RF2zjLiTSGOb5y49Z7t5-oAbqLBg84","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Evolving a Trading Strategy: Update","postDate":"1158451026","msgId":2749,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVlaTMwaStrMDc4QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ1MEM4NzBBLjMwMzA2MDhAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":2748,"nextInTopic":0,"prevInTime":2748,"nextInTime":2750,"topicId":2733,"numMessagesInTopic":13,"msgSnippet":"Why not consider expanding the definition of the genome to include a designated portion which defines a shallow GP program tree, utilizing a limited number of","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 85644 invoked from network); 16 Sep 2006 23:57:55 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m31.grp.scd.yahoo.com with QMQP; 16 Sep 2006 23:57:55 -0000\r\nReceived: from unknown (HELO n15a.bullet.scd.yahoo.com) (66.94.237.32)\n  by mta1.grp.scd.yahoo.com with SMTP; 16 Sep 2006 23:57:55 -0000\r\nReceived: from [66.218.69.2] by n15.bullet.scd.yahoo.com with NNFMP; 16 Sep 2006 23:57:08 -0000\r\nReceived: from [66.218.66.86] by t2.bullet.scd.yahoo.com with NNFMP; 16 Sep 2006 23:57:08 -0000\r\nDate: Sat, 16 Sep 2006 23:57:06 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;eei30i+k078@...&gt;\r\nIn-Reply-To: &lt;450C870A.3030608@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Evolving a Trading Strategy: Update\r\nX-Yahoo-Group-Post: member; u=281645563; y=gRwOVNSubqjc2V-pU6ZmPB8MuNRvg0mgy2MPXWvoRO2KfQ\r\nX-Yahoo-Profile: afcarl2\r\n\r\n\nWhy not consider expanding the definition of the genome to include a \ndesi=\r\ngnated portion which defines a shallow GP program tree, utilizing \na limite=\r\nd number of pre-defined functions on portions of the raw data \nstream, the =\r\noutput of each would feed the neat inputs, acting as a \nconventional neat i=\r\nnput pre-processor.\n\n--- In neat@yahoogroups.com, Colin Green &lt;cgreen@...&gt; =\r\nwrote:\n&gt;\n&gt; Hi Jeff,\n&gt; \n&gt; Jeff Morton wrote:\n&gt; \n&gt; &gt;There really aren&#39;t any s=\r\ntudies I can personally attest to since I \nhave really just begun this lear=\r\nning process myself.  I will note \nthat it appears to me based solely on ob=\r\nservation that using just the \ntechnical bar data is inadequate.  This kind=\r\n of reminds me of the \nproblem faced when trying to use neural networks to =\r\nrecognize \nspeech.  In this instance a simple frame by frame fourier transf=\r\norm \nof the data will not produce the patterns necessary for detection.  \nY=\r\nou actually have to analyze the spectrogram of varying time periods \nfor th=\r\nose patterns to develop properly.  \n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; \n&gt; I don&#39;t know much abo=\r\nut speech recognition but I am aware of the \nbasic \n&gt; concept of analysing =\r\nthe frequency spectrogram generated using \nfixed \n&gt; length moving time fram=\r\nes ( the last n milliseconds). Now I realise \n&gt; you&#39;re not necesarily sugge=\r\nsting using spectrograms but my \nimmediate \n&gt; reaction to the idea is that =\r\nfinancial time series data oscillates \nat \n&gt; much lower frequencies than mo=\r\nst audio signals and therefore a much \n&gt; longer time frame would be needed =\r\nto produce a meaningful \nspectrogram. \n&gt; Actually though I quite like the i=\r\ndea. And I suppose the longer \ntime \n&gt; frames would pick up on very low fre=\r\nquency signals whereas the \nshorter \n&gt; time frames would give a more immedi=\r\nate response to higher \nfrequency \n&gt; components.\n&gt; \n&gt; &gt;It might be more use=\r\nful to include standard indicators over \ndiffering time periods with other =\r\nfundamental financial data, etc.  \nPerhaps using statistics like those used=\r\n in digital signal processing \nwould be a better idea as well.  \n&gt; &gt;  \n&gt; &gt;\n=\r\n&gt; \n&gt; \n&gt; You mean something like this (taken from wikipedia page on digitla =\r\n\n&gt; signal processing:\n&gt; \n&gt; &quot;There are some commonly used frequency domain t=\r\nransformations. For \n&gt; example, the cepstrum &lt;http://en.wikipedia.org/wiki/=\r\nCepstrum&gt; \nconverts a \n&gt; signal to the frequency domain through Fourier tra=\r\nnsform, takes the \n&gt; logarithm, then applies another Fourier transform. Thi=\r\ns emphasizes \nthe \n&gt; frequency components with smaller magnitude while reta=\r\nining the \norder of \n&gt; magnitudes of frequency components.&quot;\n&gt; \n&gt; \n&gt; &gt;I thin=\r\nk the biggest problem at this point is that PCs just aren&#39;t \nquite fast eno=\r\nugh or are limited by available RAM.  this is bound to \nchange very quickly=\r\n though so developing these systems now makes a \nlot of sense to me.  \n&gt; &gt; =\r\n \n&gt; &gt;\n&gt; \n&gt; \n&gt; I think there&#39;s a lot that can be done with existing PC&#39;s so =\r\nlong \nas \n&gt; you&#39;re not too wasteful. E.g. you would want to pre-calculate \n=\r\nfrequency \n&gt; spectrograms where possible (liek where the time frame(s) is/a=\r\nre \nfixed). \n&gt; Currently all of my derived signals are currenly pre-calcula=\r\nted and \n&gt; placed into a data structure that is organised into the order th=\r\nat \ndata \n&gt; is normally accessed, thus improving CPU cache utilisation.\n&gt; \n=\r\n&gt; \n&gt; &gt;As far as my current implementation is concerned.  Bascially what \nI&#39;=\r\nve done is developed a backtesting engine which is utilized by an \nagent of=\r\n sorts which randomly selects techical indicators with \nvarying parameters =\r\nand runs them against the market data.  This has \nbeen marginally effective=\r\n and I think this has just brought home the \npoint to me that technical ind=\r\nicators alone are not enough.\n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; \n&gt; I do pretty much the same t=\r\nhing but I try to evolve a single ANN \nagent \n&gt; (or that gives buy sell sig=\r\nnals to an agent) and that takes some \nsimple \n&gt; derived signals at its inp=\r\nuts. Now I provide the same complete set \nof \n&gt; signals to all of my ANNs, =\r\nbut they can of course choose to ignore \n&gt; signals, modify them. What they =\r\ncan&#39;t do is provide parametrs to \nthe \n&gt; routine that generates the derived=\r\n signals, not least because as I \nsaid \n&gt; above, the signals are pre-calcul=\r\nated.\n&gt; \n&gt; &gt;My current idea is to replace those algorithmic technical \nindi=\r\ncators with small neural networks that I can train to act as \ntechnical ind=\r\nicators.  Not because I necessarily believe this will \nproduce better resul=\r\nts but because I intend to modify my current \nsystem to handle neural netwo=\r\nrks instead of the predefined indicator \nclasses I&#39;m currently using.  NEAT=\r\n looks like a good place to start \ndigging into code to do this.\n&gt; &gt;  \n&gt; &gt;\n=\r\n&gt; \n&gt; Assuming your agent utilises a sub-set of all available indicators, \n&gt;=\r\n could you not simply add some additional ANN indicators to the set \nof \n&gt; =\r\nexisting algorithmic ones?\n&gt; \n&gt; \n&gt; &gt;BTW, I&#39;m working in C#.\n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; =\r\n\n&gt; That&#39;s fine by me. Just in case you hadn&#39;t already realised, I&#39;m \nthe gu=\r\ny \n&gt; who wrote SharpNEAT :)\n&gt; \n&gt; &gt;As far as the time series data, if all yo=\r\nu are looking for are a \ncouple of data sets than you should definately che=\r\nck out \nfinance.yahoo.com.  You can download CSV files for free.  The oldes=\r\nt \nI have going back to the 1960&#39;s (IBM on the NYSE).\n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; oh wow=\r\n, yes you&#39;re right. I just downloaded the Dow Jones \n&gt; open/high/low/close =\r\nall the way back to 1928 in about 10 seconds! \nNow \n&gt; I&#39;m thinking I should=\r\n probably adjust for inflation.\n&gt; \n&gt; \n&gt; \n&gt; &gt;If you think you might have a n=\r\need for ALL of it then we can make \narangements for me to transmit this to =\r\nyou over the internet.  That \nfile which covers all historical data for all=\r\n US markets compressed \nto just over 500meg using RAR.\n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; Thank=\r\ns for the offer. I&#39;ve got enough to be going on with for a \nwhile, \n&gt; but m=\r\naybe at a alter date.\n&gt; \n&gt; Regards,\n&gt; \n&gt; Colin\n&gt;\n\n\n\n\n\n"}}