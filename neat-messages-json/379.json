{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":115403844,"authorName":"John Arrowwood","from":"&quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"nkUQ5Ix3xKPoOJh9RkZnMfl_C4A0zJDBBhgFrJaHjY4edaA8D19DklFVW7PI_kQgvVvg5zet3keZ2CQxzWY4UZg8IoC_FwCJMab7-unD","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [neat] Image Enlargement Project","postDate":"1076700822","msgId":379,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBWTItRjk1aXFYZTdpaGN0VEkwMDAyMDYxNEBob3RtYWlsLmNvbT4="},"prevInTopic":378,"nextInTopic":380,"prevInTime":378,"nextInTime":380,"topicId":371,"numMessagesInTopic":22,"msgSnippet":"... I have almost 3000 pictures that I have taken with my digital camera.  I don t want to enlarge all of them, but since I want to be able to enlarge any one","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 47018 invoked from network); 13 Feb 2004 19:33:42 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m5.grp.scd.yahoo.com with QMQP; 13 Feb 2004 19:33:42 -0000\r\nReceived: from unknown (HELO hotmail.com) (65.54.247.95)\n  by mta4.grp.scd.yahoo.com with SMTP; 13 Feb 2004 19:33:42 -0000\r\nReceived: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\n\t Fri, 13 Feb 2004 11:33:42 -0800\r\nReceived: from 64.122.44.102 by by2fd.bay2.hotmail.msn.com with HTTP;\n\tFri, 13 Feb 2004 19:33:42 GMT\r\nX-Originating-Email: [jarrowwx@...]\r\nX-Sender: jarrowwx@...\r\nTo: neat@yahoogroups.com\r\nBcc: \r\nDate: Fri, 13 Feb 2004 11:33:42 -0800\r\nMime-Version: 1.0\r\nContent-Type: text/plain; format=flowed\r\nMessage-ID: &lt;BAY2-F95iqXe7ihctTI00020614@...&gt;\r\nX-OriginalArrivalTime: 13 Feb 2004 19:33:42.0700 (UTC) FILETIME=[49E87EC0:01C3F268]\r\nX-eGroups-Remote-IP: 65.54.247.95\r\nFrom: &quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;\r\nReply-To: john@...\r\nSubject: RE: [neat] Image Enlargement Project\r\nX-Yahoo-Group-Post: member; u=115403844\r\nX-Yahoo-Profile: jarrowwx\r\n\r\n&gt;From: Derek James &lt;blue5432@...&gt;\n&gt;\n&gt;--- John Arrowwood &lt;jarrowwx@...&gt; wrote:\n&gt; &gt; The bigger problem for the moment is extracting the\n&gt; &gt; training data within\n&gt; &gt; this lifetime. :)\n&gt;\n&gt;What is your source for a training set?\n\nI have almost 3000 pictures that I have taken with my digital camera.  I \ndon&#39;t want to enlarge all of them, but since I want to be able to enlarge \nany one I want, it seems reasonable to build a &#39;general&#39; mechanism that \nworks well for all the pictures, and hopefully for future ones as well.\n\n&gt; &gt; I was thinking that I would start out with only\n&gt; &gt; connections between the one\n&gt; &gt; pixel that represents the average of the output\n&gt; &gt; pixels in the same area.\n&gt; &gt; That would be one connection per output node for a\n&gt; &gt; total of 64 connections\n&gt; &gt; only involving 4 inputs.  The rest of the inputs\n&gt; &gt; would be initially ignored.\n&gt;\n&gt;Just to try to clarify...your network topology is a\n&gt;4x16 fully-connected feedforward network?  Is that\n&gt;right?\n\nActually, it&#39;s an 8x8 input (64 nodes) and 8x8 output, with an initial \nconfiguration of only the center 2x2  input nodes connected via a single \nconnection with weight 1 to the output node that is in the corresponding \nlocation in the enlarged image.\n\nTo illustrate:\n\nInput\n[ ][ ][ ][ ][ ][ ][ ][ ]\n[ ][ ][ ][ ][ ][ ][ ][ ]\n[ ][ ][ ][ ][ ][ ][ ][ ]\n[ ][ ][ ][a][b][ ][ ][ ]\n[ ][ ][ ][c][d][ ][ ][ ]\n[ ][ ][ ][ ][ ][ ][ ][ ]\n[ ][ ][ ][ ][ ][ ][ ][ ]\n[ ][ ][ ][ ][ ][ ][ ][ ]\n\nOutput\n[a][a][a][a][b][b][b][b]\n[a][a][a][a][b][b][b][b]\n[a][a][a][a][b][b][b][b]\n[a][a][a][a][b][b][b][b]\n[c][c][c][c][d][d][d][d]\n[c][c][c][c][d][d][d][d]\n[c][c][c][c][d][d][d][d]\n[c][c][c][c][d][d][d][d]\n\nInput node &#39;a&#39; is connected with weight 1 to all output nodes &#39;a&#39;.  Same for \nb, c, and d.  This corresponds exactly to a &#39;nearest neighbor&#39; or &#39;pixel \nenlargement&#39; algorithm.  The remaining input nodes are unconnected in the \nhopes that NEAT will decide for itself which nodes it needs and which it \ndoes not.  I expect it to ultimately connect to all of them, but with how \nmany hidden nodes? Other experiments show that good results are obtained \nwith a single hidden layer of about 30 nodes.  But that may have been for 2x \nenlargement.  And who knows if a different structure would not be more \nefficient?\n\nI chose a 4x enlargement so as to reduce errors that might be introduced by \ndoing to successive 2x enlargements.  And I expect to enlarge by at least 4x \nwhenever I do enlargements.  Usually more.  So if this experiment succeeds, \nI&#39;ll probably repeat it with larger output spaces, though probably not \nsignificantly larger input spaces.  That is, if it finishes in this \nlifetime... :)\n\n&gt;See the thread starting here:\n&gt;\n&gt;http://groups.yahoo.com/group/neat/message/8\n&gt;\n&gt;But it sounds like your already using this approach\n&gt;(unless I&#39;m misunderstanding what you&#39;re doing).\n\nOkay, I have now read all of the archives for the lits, so I&#39;m up to speed \non the &#39;roving eye&#39; concept...  Yes, it is very similar, except it has no \ncontrol over the roving.  It is applied successively to every 8x8 chunk of \nthe image.\n\n&gt;What are the dimensions of the images you are\n&gt;enlarging?  I&#39;m getting the impression that you&#39;re\n&gt;starting with something like a 100x100 pixel image and\n&gt;enlarging it to 200x200, in 2x2 chunks at a time.  Is\n&gt;that right?\n\nThe original image is 1984x1488 pixels.  The enlarged image will be \n7936x5952.  Now suppose we are taking the 8x8 chunk starting at 1,1.  The 64 \npixels starting at position 1,1 are fed into the network.  The input covers \nthe area 1,1 through 7,7 in the image.  Since the enlargement is 4x, the \narea that the input covers in the output image is 1,1 through 32,32.  \nHowever, the ouput is only 8x8, and represents only the center portion of \nthat area.  Thus, the output represents only pixels 12,12 through 20,20 in \nthe output image.  Then, when you start with the input image at 2,1, the \noutput will represent pixels 16,12 through 24,20.  Note the deliberate \noverlap between outputs.\n\nThis whole process is repeated for every value of x and y, including those \noff the edge of the photo using the average of visible pixels as the values \nfor those off the edge.  The end result is that every pixel in the output \nimage will have four possible values assigned to it from the four \nneighboring evaluations.  Others have done it where the area of only one \ninput pixel is output, reducing computational costs.  But I felt that having \noverlap would allow me to have a &#39;degree of confidence&#39; in particular \npixels.  If all four evaluations produced the same value for a pixel, it is \nprobably correct given the input.  I haven&#39;t yet decided exactly what I will \ndo when confidence is low for a pixel, but I figure I have some time to \nthink about it while I&#39;m busy training or generating the enlargement \nnetwork.\n\nI&#39;ve made progress in figuring out how I&#39;m going to extract the training \ndata.  I came up with a &#39;hashing&#39; algorithm that represents the input sample \n(8x8x16-bits) in 32 bits.  A lot of input images would hash to the same \nvalue, which is the intent.  Then, when evaluating a genome for fitness, I \nonly compare it to one (randomly selected) sample per hash value.\n\nI intend to fold &#39;transformations&#39; of the input samples together so that \nthey have the same hash value.  Then, for every sample that I test a genome \nagainst, I would also test it against all the transformations of it, too, to \nencourage symetry of the final network.  That way if it learns to enlarge a \nsample one way, it should be able to enlarge it if it encounters it rotated, \ntoo.\n\nMy biggest problem at this point is time and disk space. :)  For now...\n\n_________________________________________________________________\nGet some great ideas here for your sweetheart on Valentine&#39;s Day - and \nbeyond. http://special.msn.com/network/celebrateromance.armx\n\n\n"}}