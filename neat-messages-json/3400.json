{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"MRJaBJtKOn18aOUIYSGv0W5X15xoe5BGEPaJkyiO_UQN6AI5mK-SyvJPcllGFrKBv10Gem5rG-UXvAsBek47ZBXnwkVy6EYsxs7bvyKhixnwzgmtbfw","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: ANJI : NEAT implementation (fingerprint implementation issues)","postDate":"1181826603","msgId":3400,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY0cmVuYyt0MDJ0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGY2ODQ0Y2ZjMDcwNjE0MDA0OXkzMzU0MDNlNG9jODE1NzZiNmE3OGExOWM5QG1haWwuZ21haWwuY29tPg=="},"prevInTopic":3399,"nextInTopic":3401,"prevInTime":3399,"nextInTime":3401,"topicId":3384,"numMessagesInTopic":37,"msgSnippet":"Hello, Jan-Jaap, It is good to see that you are experimenting with NEAT, but this is an CPPN/HyperNEAT issue we are discussing right now. Your suggestion is","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 52268 invoked from network); 14 Jun 2007 13:10:44 -0000\r\nReceived: from unknown (66.218.66.72)\n  by m45.grp.scd.yahoo.com with QMQP; 14 Jun 2007 13:10:44 -0000\r\nReceived: from unknown (HELO n7b.bullet.sp1.yahoo.com) (69.147.64.166)\n  by mta14.grp.scd.yahoo.com with SMTP; 14 Jun 2007 13:10:44 -0000\r\nReceived: from [216.252.122.217] by n7.bullet.sp1.yahoo.com with NNFMP; 14 Jun 2007 13:10:04 -0000\r\nReceived: from [66.218.69.4] by t2.bullet.sp1.yahoo.com with NNFMP; 14 Jun 2007 13:10:04 -0000\r\nReceived: from [66.218.66.87] by t4.bullet.scd.yahoo.com with NNFMP; 14 Jun 2007 13:10:04 -0000\r\nDate: Thu, 14 Jun 2007 13:10:03 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f4renc+t02t@...&gt;\r\nIn-Reply-To: &lt;f6844cfc0706140049y335403e4oc81576b6a78a19c9@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: ANJI : NEAT implementation (fingerprint implementation issues)\r\nX-Yahoo-Group-Post: member; u=283334584; y=PVFnEtpF3GredcvCnB3BoVA8Xk13Wto1hK3SDrseG43GyrPuEnBNUALD9w\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHello, Jan-Jaap, \n\nIt is good to see that you are experimenting with NEAT, =\r\nbut this is \nan CPPN/HyperNEAT issue we are discussing right now.\nYour sugg=\r\nestion is interesting, but a roving eye cannot be used in a \nCPPN. \nThe pro=\r\nblem about it is that the basic coordinate frames that are \npassed in the C=\r\nPPN must be static all the time. If they are not, then \nevolution would bre=\r\nak down. I mean, the space itself that we build \nour phenotypes in should n=\r\not bend, twist or move in any way. \nA roving eye can be used with the Hyper=\r\nNEAT neural substrate, but my \nfirst experiments showed that this is hard f=\r\nor the evolution to \nmaster. \n\nHyperNEAT allows very large input/output spa=\r\nces and recognition of \nwhole images, without roving eyes and so on. \nAre y=\r\nou familiar with the concept of CPPNs and HyperNEAT?\nCheck out this excelle=\r\nnt paper on the concept of CPPNs: \nhttp://eplex.cs.ucf.edu/papers/stanley_g=\r\npem07.pdf\nAnd also this one, on HyperNEAT: \nhttp://eplex.cs.ucf.edu/papers/=\r\ngauci_gecco07.pdf\n\nP.S. Derek James has a paper about his experiments with =\r\na roving eye \nvisual discrimination system in ANJI that includes rotatitng =\r\nroving \neye, too. It is interesting that the system has better performance =\r\n\nwithout rotation. \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Jan-Jaap van de V=\r\nelde&quot; \n&lt;janjaap.vandevelde@...&gt; wrote:\n&gt;\n&gt; Hello,\n&gt; \n&gt; I&#39;ve been reading th=\r\nis emailgroup for a couple of weeks now with \ngreat\n&gt; interest and started =\r\nexperimenting with Neat also.\n&gt; \n&gt; As I see your problem it shouldn&#39;t be ne=\r\neded to evolve rotation in \nyour\n&gt; network.\n&gt; Concider a woman rotating a m=\r\nap to be able to read it. You could do \nthe same\n&gt; with a &#39;roving eye&#39; and =\r\npresent the data in every angle or maybe \njust a\n&gt; couple of orientations.\n=\r\n&gt; \n&gt; Maybe this could give some better results.\n&gt; \n&gt; I&#39;m looking forward to=\r\n reading you&#39;re results. I&#39;m still learning \nto program\n&gt; in Java and C++ i=\r\nn the process, so my own experiments are still \nwaiting to\n&gt; get started.\n&gt;=\r\n \n&gt; greetz,\n&gt; Jan-Jaap\n&gt; \n&gt; from the Netherlands\n&gt; \n&gt; On 6/13/07, Kenneth S=\r\ntanley &lt;kstanley@...&gt; wrote:\n&gt; &gt;\n&gt; &gt;   Hi Peter,\n&gt; &gt;\n&gt; &gt; I agree with your =\r\nstatement of the problem. In a way, translation\n&gt; &gt; and scaling are both na=\r\ntural, but rotation is particularly \ndifficult\n&gt; &gt; to evolve. If it did evo=\r\nlve, it would take significant effort for\n&gt; &gt; HyperNEAT to discover the con=\r\ncept of rotation.\n&gt; &gt;\n&gt; &gt; That suggests that perhaps there is a way to make=\r\n rotation a\n&gt; &gt; canonical activation function instead of something that nee=\r\nds to \nbe\n&gt; &gt; composed from several parts. However, like you say, it&#39;s hard=\r\n to\n&gt; &gt; imagine how a single (traditional) neuron could implement a \nrotati=\r\non\n&gt; &gt; function that requires multiple variables.\n&gt; &gt;\n&gt; &gt; One idea is to cr=\r\neate a new kind of neuron that actually has\n&gt; &gt; distinct input entrances. T=\r\nhat way, it is possible to have an &quot;x&quot;\n&gt; &gt; and a &quot;y&quot; entrance to the rotati=\r\non node. Each entrance could \nitself\n&gt; &gt; be a summation of activation comin=\r\ng from elsewhere, just like a\n&gt; &gt; regaular node input.\n&gt; &gt;\n&gt; &gt; Another issu=\r\ne is the alpha argument. I need to think about that a\n&gt; &gt; little more becau=\r\nse we do not want to explicitly enter an alpha.\n&gt; &gt; Yet then what is the ro=\r\ntation operating on?\n&gt; &gt;\n&gt; &gt; ken\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com &lt;neat%=\r\n\n40yahoogroups.com&gt;, &quot;petar_chervenski&quot;\n&gt; &gt; &lt;petar_chervenski@&gt; wrote:\n&gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt;\n&gt; &gt; &gt; I made the eye static as you suggested in one p=\r\nrevious \ndisscussion\n&gt; &gt; &gt; about this experiment, using HyperNEAT for visua=\r\nl recognition.\n&gt; &gt; &gt; (Roving eye & HyperNEAT is an overkill). It is &quot;alive&quot;=\r\n for \nabout 5\n&gt; &gt; &gt; timesteps, in order to use some reccurence.\n&gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n I think about the rotation.. So, let&#39;s clear things out.\n&gt; &gt; &gt; A point (X,=\r\nY) is rotated with angle (Aplha) to (X1, Y1).\n&gt; &gt; &gt; This is a function, tak=\r\ning 3 arguments and returning 2.\n&gt; &gt; &gt;\n&gt; &gt; &gt; x1=3D y*sin(alpha) + x*cos(alp=\r\nha)\n&gt; &gt; &gt; y1=3D y*cos(alpha) - x*sin(alpha)\n&gt; &gt; &gt;\n&gt; &gt; &gt; I think this cannot=\r\n be covered by a single neuron, but a cluster\n&gt; &gt; of\n&gt; &gt; &gt; neurons with sin=\r\n() and cos() activation functions.. Am I right?\n&gt; &gt; &gt; Let&#39;s say that we hav=\r\ne 2 inputs (x, y) and a bias node in the\n&gt; &gt; CPPN.\n&gt; &gt; &gt; Further, we have 2=\r\n hidden nodes, one is &quot;sine&quot; other \nis &quot;cosine&quot;.\n&gt; &gt; &gt; These hidden nodes a=\r\nre both connected to the bias. The bias here\n&gt; &gt; is\n&gt; &gt; &gt; our &quot;alpha&quot; value=\r\n.\n&gt; &gt; &gt; Then, we can imagine how these nodes should be connected to\n&gt; &gt; con=\r\nstruct\n&gt; &gt; &gt; this formula above. We need linear outputs, and maybe some\n&gt; &gt;=\r\n additional\n&gt; &gt; &gt; linear nodes with multiplying summing functions (to repre=\r\nsent \nthe\n&gt; &gt; &gt; multiplications by x and y)...\n&gt; &gt; &gt;\n&gt; &gt; &gt; Similar, transla=\r\ntion can be handled even easier. The main\n&gt; &gt; coordinate\n&gt; &gt; &gt; frames has t=\r\no be connected to 2 linear nodes, where an addition \nto\n&gt; &gt; a\n&gt; &gt; &gt; bias oc=\r\ncurs in each.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Scaling is in fact everywhere, since the weights =\r\nof the\n&gt; &gt; connections\n&gt; &gt; &gt; can be thought of as scalars of the coordinate=\r\n frames.\n&gt; &gt; &gt;\n&gt; &gt; &gt; So, that were the 3 main transformations.. :)\n&gt; &gt; &gt; Bu=\r\nt the rotation seems hard to evolve.. And using linear nodes \nand\n&gt; &gt; &gt; mul=\r\ntiplying summing functions (before the activation) is \nimportant.\n&gt; &gt; &gt;\n&gt; &gt;=\r\n &gt; Peter\n&gt; &gt; &gt;\n&gt; &gt; &gt; --- In neat@yahoogroups.com &lt;neat%40yahoogroups.com&gt;, =\r\n&quot;Kenneth \nStanley&quot;\n&gt; &gt; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; --- In neat@yahoo=\r\ngroups.com &lt;neat%40yahoogroups.com&gt;,\n&gt; &gt; &quot;petar_chervenski&quot;\n&gt; &gt; &lt;petar_cher=\r\nvenski@&gt;\n&gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; - My current experiments with ActiveVisio=\r\nn show that it is\n&gt; &gt; hard\n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; evolve substrates that recogn=\r\nize simple shapes that are\n&gt; &gt; randomly\n&gt; &gt; &gt; &gt; &gt; rotated. Perhaps I should=\r\n tweak the NEAT parameters or the \nset\n&gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; activation function=\r\ns?\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Peter, in the experiment you are describing, a=\r\nre you using a\n&gt; &gt; roving\n&gt; &gt; &gt; eye\n&gt; &gt; &gt; &gt; or just inputting a whole image=\r\n into the substrate? With\n&gt; &gt; &gt; HyperNEAT, it\n&gt; &gt; &gt; &gt; should be possible to=\r\n do recognition tasks without needing a\n&gt; &gt; roving\n&gt; &gt; &gt; eye.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n &gt; In any case, I believe rotational invariance is indeed an\n&gt; &gt; &gt; activati=\r\non\n&gt; &gt; &gt; &gt; function issue. The problem is that you need to get the same\n&gt; &gt;=\r\n &gt; pattern\n&gt; &gt; &gt; &gt; of connects repeated in a rotating fashion, so that they=\r\n can\n&gt; &gt; &gt; recognize\n&gt; &gt; &gt; &gt; rotated images. This kind of rotation is not a=\r\n very natural\n&gt; &gt; &gt; byproduct\n&gt; &gt; &gt; &gt; of the usual set of activation functi=\r\nons. I believe there is\n&gt; &gt; &gt; probably\n&gt; &gt; &gt; &gt; a rotational activation func=\r\ntion that would be quite helpful,\n&gt; &gt; but I\n&gt; &gt; &gt; &gt; have not resolved what =\r\nfunction that should be.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt;\n=\r\n\n\n\n"}}