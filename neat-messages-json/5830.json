{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"EOJQpqYDa4QmFOt31M4069PO7djuGaEWG8DCI6WLG6e7slQl-AfxK7qwPyqHyFEtOizFDTMn_07M1_wMEa6pDUBi2DGI6YCctDookXcXyz8IJmSIZd4","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Models of brains, what should we borrow from biology?","postDate":"1342764093","msgId":5830,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGp1YXM3dCtiMHRxQGVHcm91cHMuY29tPg==","inReplyToHeader":"PENBTHV1dzNPcnMyUzEwRk9VMFFQRkpia2owNnZfTFFyLWczN1AyUCtkUExiRVVCcC1QQUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":5828,"nextInTopic":5831,"prevInTime":5829,"nextInTime":5831,"topicId":5801,"numMessagesInTopic":16,"msgSnippet":"You can check out my NEAT implementation which I just uploaded to the file section of the group (NEAT.tar.bz2). It is written in C++ and has Python bindings","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 33876 invoked from network); 20 Jul 2012 06:01:37 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m13.grp.sp2.yahoo.com with QMQP; 20 Jul 2012 06:01:37 -0000\r\nX-Received: from unknown (HELO ng16-vm5.bullet.mail.gq1.yahoo.com) (98.136.219.200)\n  by mta3.grp.sp2.yahoo.com with SMTP; 20 Jul 2012 06:01:37 -0000\r\nX-Received: from [98.137.0.88] by ng16.bullet.mail.gq1.yahoo.com with NNFMP; 20 Jul 2012 06:01:36 -0000\r\nX-Received: from [98.137.34.184] by tg8.bullet.mail.gq1.yahoo.com with NNFMP; 20 Jul 2012 06:01:36 -0000\r\nDate: Fri, 20 Jul 2012 06:01:33 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;juas7t+b0tq@...&gt;\r\nIn-Reply-To: &lt;CALuuw3Ors2S10FOU0QPFJbkj06v_LQr-g37P2P+dPLbEUBp-PA@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Models of brains, what should we borrow from biology?\r\nX-Yahoo-Group-Post: member; u=283334584; y=p_oLQn6eGYXyDiQDK2oYkyk0w6bBoCTYSCCw__YZe7oJPPOdzj-kFIpSNg\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nYou can check out my NEAT implementation which I just uploaded to the file =\r\nsection of the group (NEAT.tar.bz2). It is written in C++ and has Python bi=\r\nndings for running generational evolution (later versions will feature runn=\r\ning rtNEAT/HyperNEAT/Novelty Search from Python). \n\n--- In neat@yahoogroups=\r\n.com, Madan Dabbeeru &lt;iitk.madan@...&gt; wrote:\n&gt;\n&gt; Hello,\n&gt; \n&gt; I am looking f=\r\nor NEAT in Python. I am not able to find any file in the\n&gt; download like pr=\r\novided. (http://code.google.com/p/neat-python/downloads/list\n&gt; ).\n&gt; \n&gt; Plea=\r\nse share me if anybody has this package.\n&gt; \n&gt; Thanks & Regards,\n&gt; Madan\n&gt; \n=\r\n&gt; On Wed, Jul 11, 2012 at 11:42 AM, Jeff Clune &lt;jeffclune@...&gt; wrote:\n&gt; \n&gt; =\r\n&gt; Hello Oliver,\n&gt; &gt;\n&gt; &gt; I&#39;m much delayed in reading all of this as I have b=\r\neen insanely busy\n&gt; &gt; lately, but I have a few thoughts that might help you=\r\n out:\n&gt; &gt;\n&gt; &gt; 1) Be careful with meta-evolution (evolving the parameters of=\r\n evolutionary\n&gt; &gt; algorithms). It sounds good in theory, but can be tricky =\r\nin practice\n&gt; &gt; because evolution is short-sighted and conservative, prefer=\r\nring\n&gt; &gt; exploitation over exploration, which can be very harmful vis a vis=\r\n\n&gt; &gt; long-term adaptation. Check out my PLoS Computational Biology paper fo=\r\nr a\n&gt; &gt; smoking gun on this front (the evolution of mutation rates). You ma=\r\ny face\n&gt; &gt; the exact same problem if you go down this road. [Note, however,=\r\n that using\n&gt; &gt; a divergent search algorithm like novelty search may allow =\r\nyou to take\n&gt; &gt; better advantage of meta-evolution: see Joel and Ken&#39;s 2012=\r\n alife review\n&gt; &gt; article on that subject.]\n&gt; &gt;\n&gt; &gt; 2) Another reason peopl=\r\ne do not throw all of the biology into the soup to\n&gt; &gt; see what happens is =\r\nbecause scientifically you end up in an impenetrable\n&gt; &gt; quagmire where you=\r\n can&#39;t figure out what is going on and you end up not\n&gt; &gt; learning much/any=\r\nthing. The scientific method demands keeping all else\n&gt; &gt; equal, and if you=\r\n have a lot of variables you don&#39;t perfectly understand,\n&gt; &gt; it takes years=\r\n to figure out what is going on if you are lucky! Even if you\n&gt; &gt; keep all =\r\nelse equal, if you are doing so against a backdrop that involves a\n&gt; &gt; lot =\r\nof complexity you don&#39;t understand, any difference you see may be due\n&gt; &gt; t=\r\no an interaction effect with one of the features in your backdrop...and\n&gt; &gt;=\r\n that may invalidate generalizing your result to other backdrops of\n&gt; &gt; int=\r\nerest. In my limited experience, I have found that most new scientists\n&gt; &gt; =\r\nwant to throw a million things into their model--especially biologically\n&gt; =\r\n&gt; motivated phenomena--to see what happens, and as they grow older/more\n&gt; &gt;=\r\n jaded/wiser/more experienced/gun shy/etc. they increasingly keep things as=\r\n\n&gt; &gt; simple as possible. In fact, a pretty good heuristic for good\n&gt; &gt; hypo=\r\nthesis-testing science is to keep things absolutely as simple as\n&gt; &gt; possib=\r\nle while allowing the question to be asked. However, that may not be\n&gt; &gt; a =\r\ngood heuristic for more exploratory science where you just set out and\n&gt; &gt; =\r\nsee what you discover.\n&gt; &gt;\n&gt; &gt; 3) You should check out Julian Miller&#39;s pape=\r\nrs on evolving a checkers\n&gt; &gt; player (with his student M. Khan, I believe).=\r\n Or, better, email/Skype him\n&gt; &gt; (he&#39;s an extremely nice guy and I&#39;m sure h=\r\ne would be happy to talk to you).\n&gt; &gt; He decided in the last few years that=\r\n he is running out of time as a\n&gt; &gt; scientist and has tenure and he has spe=\r\nnt years keeping things as simple as\n&gt; &gt; possible, and he now just wants to=\r\n do what he originally wanted to do when\n&gt; &gt; he started: throw as much biol=\r\nogy in the soup as possible and see if a\n&gt; &gt; golem crawls out. He has incor=\r\nporated a ton of biologically inspired\n&gt; &gt; low-level mechanisms in evolving=\r\n neural networks. From what I recall,\n&gt; &gt; however, it did become very diffi=\r\ncult to figure out which ingredients were\n&gt; &gt; essential and exactly what wa=\r\ns going on because of all the involved\n&gt; &gt; complexity. He may have updated =\r\nresults since I last checked in, however.\n&gt; &gt; So, you may benefit the actua=\r\nl work that he has done on this front and,\n&gt; &gt; more generally, from his opi=\r\nnions on the general scientific approach you\n&gt; &gt; are proposing.\n&gt; &gt;\n&gt; &gt; I h=\r\nope that helps. Best of luck, and I look forward to hearing what you\n&gt; &gt; le=\r\narn!\n&gt; &gt;\n&gt; &gt; Best regards,\n&gt; &gt; Jeff Clune\n&gt; &gt;\n&gt; &gt; Postdoctoral Fellow\n&gt; &gt; C=\r\nornell University\n&gt; &gt; jeffclune@...\n&gt; &gt; jeffclune.com\n&gt; &gt;\n&gt; &gt; On May 11, 20=\r\n12, at 6:34 AM, Oliver Coleman wrote:\n&gt; &gt;\n&gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; Y=\r\nes, I&#39;m pretty sure that not all of the phenomena I listed are\n&gt; &gt; importan=\r\nt; and that a good starting point in general is to assume that they\n&gt; &gt; are=\r\n not. I also agree with your argument that a lot of the low-level\n&gt; &gt; pheno=\r\nmena we see may be a result of implementation with particular physical\n&gt; &gt; =\r\nsystems (and I would add perhaps as a result of evolutionary happenstance).=\r\n\n&gt; &gt; The CPPN is a particularly compelling example of significant abstracti=\r\non of\n&gt; &gt; developmental processes, producing many of the same features of t=\r\nhe end\n&gt; &gt; result of developmental processes. One thing it does abstract aw=\r\nay, in the\n&gt; &gt; context of plastic networks, is the effect of external input=\r\n on the\n&gt; &gt; developmental process (which may or may not be an issue dependi=\r\nng on\n&gt; &gt; details of implementation, problem domain, etc...).\n&gt; &gt; &gt;\n&gt; &gt; &gt; P=\r\nerhaps we could also assume that, rather than some specific set of\n&gt; &gt; func=\r\ntions being the only workable set, what matters is having a workable\n&gt; &gt; co=\r\nmbination of functions, and that there are many possible combinations\n&gt; &gt; t=\r\nhat would work equally well. In this framework we could assume that\n&gt; &gt; bio=\r\nlogical neural networks represent at least a reasonably good combination\n&gt; =\r\n&gt; of low-level functions, and so we could use this combination as a guide\n&gt;=\r\n &gt; (but of course this doesn&#39;t answer what functions in this combination ar=\r\ne\n&gt; &gt; actually important, or what things can be abstracted away). Also, som=\r\ne\n&gt; &gt; combinations may be workable, but are far harder to evolve solutions =\r\nwith,\n&gt; &gt; or require much larger networks, etc (eg evolving networks incorp=\r\norating\n&gt; &gt; neuromodulation of synaptic plasticity can be much easier for s=\r\nome tasks\n&gt; &gt; than for those without this type of neuromodulation).\n&gt; &gt; &gt;\n&gt;=\r\n &gt; &gt; I&#39;m intending to run some experiments to explore these questions (whic=\r\nh\n&gt; &gt; phenomena are important, acceptable level of abstraction, etc), but o=\r\nf\n&gt; &gt; course to try and thoroughly explore all of these functions in many\n&gt;=\r\n &gt; combinations would be a massive undertaking, and is not my main interest=\r\n,\n&gt; &gt; so at some point I will have to pick a model and run with it after on=\r\nly a\n&gt; &gt; few, hopefully well chosen, experiments... Perhaps one approach is=\r\n to\n&gt; &gt; create flexible parameterised versions of these functions, and let\n=\r\n&gt; &gt; evolution determine what combination is right (like your approach descr=\r\nibed\n&gt; &gt; in &quot;Evolving adaptive neural networks with and without adaptive sy=\r\nnapses&quot;,\n&gt; &gt; but perhaps more flexible and applied to more functions).\n&gt; &gt; =\r\n&gt;\n&gt; &gt; &gt; Do you mind if I post/quote some/all of this discussion in the comm=\r\nents\n&gt; &gt; of my blog post?\n&gt; &gt; &gt;\n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; Oliver\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n=\r\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ------------------------------------\n&gt; &gt;\n&gt; &gt; Yahoo! Groups Link=\r\ns\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}