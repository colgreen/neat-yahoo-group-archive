{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":203001720,"authorName":"Wesley Tansey","from":"Wesley Tansey &lt;tansey@...&gt;","profile":"tansey4","replyTo":"LIST","senderId":"Z-mH0pGJYJd3c5TWNwfDvojU4T8gq9NPn4TlahdeZPa29DTX1CU80jCsgd8Hs2RcSRJp5NGmY00IEaM4jFoPda9G3JQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Backpropagation and NEAT","postDate":"1205779901","msgId":3887,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3REVCREJELjUwNzA3MDhAdnQuZWR1Pg==","inReplyToHeader":"PGZybWMzaSt0YTQ1QGVHcm91cHMuY29tPg==","referencesHeader":"PGZybWMzaSt0YTQ1QGVHcm91cHMuY29tPg=="},"prevInTopic":3886,"nextInTopic":3888,"prevInTime":3886,"nextInTime":3888,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"Ken, It s interesting that you mention value-function RL, as I remember reading the NEAT journal paper in ML where you describe NEAT as a policy-search","rawEmail":"Return-Path: &lt;tansey@...&gt;\r\nX-Sender: tansey@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 30996 invoked from network); 17 Mar 2008 18:51:51 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m54.grp.scd.yahoo.com with QMQP; 17 Mar 2008 18:51:51 -0000\r\nX-Received: from unknown (HELO lennier.cc.vt.edu) (198.82.162.213)\n  by mta15.grp.scd.yahoo.com with SMTP; 17 Mar 2008 18:51:50 -0000\r\nX-Received: from dagger.cc.vt.edu (evil-dagger.cc.vt.edu [10.1.1.11])\n\tby lennier.cc.vt.edu (8.12.11.20060308/8.12.11) with ESMTP id m2HIpoRA015226\n\tfor &lt;neat@yahoogroups.com&gt;; Mon, 17 Mar 2008 14:51:50 -0400\r\nX-Received: from [10.0.2.5] (chaos.cs.vt.edu [128.173.236.168])\n\tby dagger.cc.vt.edu (MOS 3.8.6-GA)\n\twith ESMTP id JFK16196;\n\tMon, 17 Mar 2008 14:51:50 -0400 (EDT)\r\nMessage-ID: &lt;47DEBDBD.5070708@...&gt;\r\nDate: Mon, 17 Mar 2008 14:51:41 -0400\r\nUser-Agent: Thunderbird 2.0.0.12 (Windows/20080213)\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;frmc3i+ta45@...&gt;\r\nIn-Reply-To: &lt;frmc3i+ta45@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Wesley Tansey &lt;tansey@...&gt;\r\nSubject: Re: [neat] Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=203001720; y=xC6xgGNAGxhzlhcvklkVpPDEzHboBjuu5IGrFKxqgjlaZg\r\nX-Yahoo-Profile: tansey4\r\n\r\nKen,\n\nIt&#39;s interesting that you mention value-function RL, as I remember \nreading the NEAT journal paper in ML where you describe NEAT as a \n&quot;policy-search reinforcement learning algorithm.&quot; I recall thinking to \nmyself &quot;that had to be a political maneuver...&quot; and it looks like I was \nright. :)\n\nThe academic lineage issue is an interesting one. I wish there was an \nacademic AI genealogy that was on par with the software engineering one \n(http://people.engr.ncsu.edu/txie/sefamily.htm). The one at UT Austin \nseems to have a lot of entries, but as far as visualization goes (e.g., \nseeing the trace from Schank -&gt; Lehnert -&gt; Dyer -&gt; Miikkulainen -&gt; \nStanley) it is relatively non-existent. I think it would shed a lot of \nlight on the issues and provide some useful guidance to incoming \ngraduate students looking to find an advisor.\n\nI&#39;m curious though, you mentioned that you envision EAs making their way \nback into the mainstream eventually. Would you mind elaborating on that? \nHow do you see things progressing over the next ~10 years?\n\nWesley\n\n\nKenneth Stanley wrote:\n&gt; Great points, Wesley.  You do a great job characterizing the situation.\n&gt;\n&gt; As for your last question on why there is not a top tier conference in\n&gt; EAs, that is a serious problem in the community.  You mentioned\n&gt; &quot;Foundations on EAs&quot; but I think your meant &quot;Foundations of Genetic\n&gt; Algorithms&quot; (FOGA), which indeed has a low acceptance rate.  But FOGA\n&gt; is not the conference you&#39;re looking for unless your paper is\n&gt; theoretical because FOGA is a theory conference.  For the rest of us,\n&gt; there is no venue with a low acceptance rate.\n&gt;\n&gt; The reason for this lack of a selective venue is historical and\n&gt; complicated.  Many of the major figures in EA history had different\n&gt; views about how a conference should be run and what its goals should\n&gt; be than people in other areas of machine learning.  There was an\n&gt; emphasis on inclusiveness and some had the philosophy that the prism\n&gt; of history, rather than a few reviewers, should have the final say on\n&gt; what paper is great or not great.\n&gt;\n&gt; Unfortunately for those of us in academia, that philosophy is no help\n&gt; to us (as you point out) when we are tying to get jobs or tenure,\n&gt; where acceptance rates are scrutinized.  It really needs to change,\n&gt; and I believe it will, but it is probably going to take a generational\n&gt; change in leadership.  So unfortunately it could take a long time.\n&gt;\n&gt; In the meantime, we can still submit to conferences like AAAI and\n&gt; ICML.  The only problem is that the barrier to entry for EAs is higher\n&gt; than for other areas because of their lack of mainstream acceptance in\n&gt; machine learning.  So we have to first justify using an EA at all,\n&gt; whereas another method like value-function RL can just start from the\n&gt; premise that it&#39;s a good idea to begin with.  Still, people have\n&gt; succeeded in getting into these conferences with EA-based work, and it\n&gt; is seeping in more and more.\n&gt;\n&gt; In fact, the floodgates could open if EAs really start to have\n&gt; significantly better results.  I believe that is possible because the\n&gt; emphasis on representation in EAs is going to lead to new domains\n&gt; being accessible.  We will see.\n&gt;\n&gt; Another historical factor is that in America, the academic lineages\n&gt; coming out of other areas of AI for whatever reason established\n&gt; themselves in the top departments before EAs became popular, which\n&gt; means EAs are not well-represented in US computer science departments,\n&gt; which is a self-perpetuating problem.  Interestingly, the situation is\n&gt; somewhat different in Europe than in the US.  In Europe, EAs are more\n&gt; mainstream.  In the UK for example most faculties that have AI\n&gt; researchers include EA researchers.  There is just a different history\n&gt; there.\n&gt;\n&gt; ken\n&gt;\n&gt; --- In neat@yahoogroups.com, Wesley Tansey &lt;tansey@...&gt; wrote:\n&gt;   \n&gt;&gt; I just want to add to two of the issues raised here.\n&gt;&gt;\n&gt;&gt;     \n&gt;&gt;&gt;  So you see, in\n&gt;&gt;&gt; building a new algorithm or a new theory with practical implications,\n&gt;&gt;&gt; often traditional problems are exactly the wrong vehicle to discovery\n&gt;&gt;&gt; because they perpetuate the same dogmatic perspectives that already\n&gt;&gt;&gt; permeate the field to begin with and cause it to be staying in one\n&gt;&gt;&gt; place.   Thus all of these applications are chosen with careful\n&gt;&gt;&gt; scrutiny with a sincere belief in their practical ramifications.\n&gt;&gt;&gt;   \n&gt;&gt;&gt;       \n&gt;&gt; This is really starting to be recognized by a lot of the machine \n&gt;&gt; learning crowd. At ILP 2007, Pedro Domingos gave an invited\n&gt;&gt;     \n&gt; presentation \n&gt;   \n&gt;&gt; entitled &quot;Structured Machine Learning: Ten Problems for the Next Ten \n&gt;&gt; Years.&quot; (http://www.cs.washington.edu/homes/pedrod/papers/ilp07.pdf) \n&gt;&gt; While it&#39;s a different subdomain of machine learning, he had the same \n&gt;&gt; thoughts on &quot;traditional&quot; problems as targets for new research. From\n&gt;&gt;     \n&gt; the \n&gt;   \n&gt;&gt; article:\n&gt;&gt;\n&gt;&gt;     \n&gt;&gt;&gt; We need to avoid falling into local optima in our research: once a \n&gt;&gt;&gt; problem is solved\n&gt;&gt;&gt; &quot;80/20,&quot; we should move on to the next larger one that includes it, \n&gt;&gt;&gt; not continue to refine our\n&gt;&gt;&gt; solution with diminishing returns. Our natural tendency to do the \n&gt;&gt;&gt; latter greatly slows down the\n&gt;&gt;&gt; progress of research. Moreover, the best solutions to subproblems \n&gt;&gt;&gt; taken in isolation are often not\n&gt;&gt;&gt; the best ones in combination. Because of this, refining solutions to \n&gt;&gt;&gt; subproblems can in fact be\n&gt;&gt;&gt; counterproductiveï¿½digging deeper into the local optimum instead of \n&gt;&gt;&gt; escaping it.\n&gt;&gt;&gt;       \n&gt;&gt; The second point I want to address is on the use of NEAT, or more \n&gt;&gt; generally EAs, in &quot;Fortune 100 defense firms.&quot; I recently\n&gt;&gt;     \n&gt; interviewed at \n&gt;   \n&gt;&gt; BBN Technologies, and they told me about one project their Cambridge \n&gt;&gt; team worked on and is now deployed in Iraq. When a convoy of troops is \n&gt;&gt; traveling and a sniper fires a shot, an array of microphones mounted on \n&gt;&gt; top of one of the vehicles records the sound, then runs a \n&gt;&gt; multi-objective evolutionary algorithm to determine the distance, \n&gt;&gt; elevation, etc., that the shot originated from. The result is that when \n&gt;&gt; an insurgent sniper fires a shot, within 3 seconds the entire convoy \n&gt;&gt; turns around and fires everything at that spot. Apparently the mic\n&gt;&gt;     \n&gt; array \n&gt;   \n&gt;&gt; system works well enough that it has been nicknamed the &quot;Octopus of\n&gt;&gt;     \n&gt; Death.&quot;\n&gt;   \n&gt;&gt; Warning: the rest of this message is extremely off topic.\n&gt;&gt;\n&gt;&gt; That&#39;s just my thoughts/experiences though. For what it&#39;s worth, I\n&gt;&gt;     \n&gt; think \n&gt;   \n&gt;&gt; it&#39;s pretty hard to deny that EAs have fallen out of favor with the \n&gt;&gt; mainstream machine learning crowd. To a large degree, I believe this is \n&gt;&gt; the result of an easily satisfied community. Groucho Marx said, &quot;I \n&gt;&gt; wouldn&#39;t want to belong to any club that would have me as a member&quot; and \n&gt;&gt; the same is true of research communities. Conference quality is \n&gt;&gt; determined almost entirely by acceptance rates. The &quot;top tier&quot; \n&gt;&gt; conferences in AI like AAAI, IJCAI, ICML, etc. all have acceptance\n&gt;&gt;     \n&gt; rates \n&gt;   \n&gt;&gt; around or below 25%. The EA community decided to break off and form\n&gt;&gt;     \n&gt; lots \n&gt;   \n&gt;&gt; of specialized conferences, which would be fine, except that these \n&gt;&gt; conferences have ridiculous acceptance rates of around ~45% or higher. \n&gt;&gt; With such a low barrier to entry, the amount of rigor applied to EA \n&gt;&gt; papers is routinely unacceptable and occasionally shameful. The result \n&gt;&gt; is that work by Ken&#39;s group at UCF or Risto&#39;s group at UT Austin gets \n&gt;&gt; best paper at GECCO or CEC, but among a lot of machine learning faculty \n&gt;&gt; it still isn&#39;t considered as prestigious as a paper accepted to one of \n&gt;&gt; the top tier conferences mentioned above, despite the fact that the\n&gt;&gt;     \n&gt; work \n&gt;   \n&gt;&gt; is more likely to have a significant impact on practical machine\n&gt;&gt;     \n&gt; learning.\n&gt;   \n&gt;&gt; As a Software Engineering student, I know what it&#39;s like to be on the \n&gt;&gt; other extreme end of the spectrum. SE conference acceptance rates at\n&gt;&gt;     \n&gt; the \n&gt;   \n&gt;&gt; top tier are dipping into the low teens or even single digits. This \n&gt;&gt; certainly has a lot of negative implications for researchers. Many \n&gt;&gt; times, reviewers simply look for any little way to reject a paper, and \n&gt;&gt; you typically have to resubmit 2 or 3 times, with major revisions and \n&gt;&gt; additions each time, before a paper is accepted. However, when a \n&gt;&gt; graduating PhD. student has several publications at ICSE, OOPSLA, FSE, \n&gt;&gt; etc., their resume automatically gets them considered for tenure-track \n&gt;&gt; positions at top 10 schools. There are just no such conferences in the \n&gt;&gt; EA domain where people would look at a set of publications and say\n&gt;&gt;     \n&gt; &quot;Wow, \n&gt;   \n&gt;&gt; he got in there--TWICE!&quot;\n&gt;&gt;\n&gt;&gt; So I guess the question that I&#39;m throwing in here is: why isn&#39;t there a \n&gt;&gt; top tier conference for EAs? How about Foundations of Evolutionary \n&gt;&gt; Algorithms (FEA)?\n&gt;&gt;\n&gt;&gt; Wesley\n&gt;&gt;\n&gt;&gt;     \n&gt;\n&gt;\n&gt;\n&gt;   \n\n"}}