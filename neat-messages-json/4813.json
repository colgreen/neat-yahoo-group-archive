{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"Cb2kEqfly3ywPnA_bzAtsi_qzTy7_T8eFZeBo9ianXciX5Svp2orv-_Zq67wvSknRuY_blxJ7u7DTxJ33I6tbIbCVBJP70RWpsaGOtVwgd4x","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: hyperneat questions","postDate":"1249792583","msgId":4813,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGg1bGpvNytwY2M1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGg1Zml0NithamdwQGVHcm91cHMuY29tPg=="},"prevInTopic":4808,"nextInTopic":4814,"prevInTime":4812,"nextInTime":4814,"topicId":4808,"numMessagesInTopic":10,"msgSnippet":"Nikolai, you have the main idea right but the one aspect of your description that I would correct is the idea that the substrate must be a perceptron.  In","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 10000 invoked from network); 9 Aug 2009 04:37:46 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m2.grp.re1.yahoo.com with QMQP; 9 Aug 2009 04:37:46 -0000\r\nX-Received: from unknown (HELO n43d.bullet.mail.sp1.yahoo.com) (66.163.169.157)\n  by mta2.grp.re1.yahoo.com with SMTP; 9 Aug 2009 04:37:46 -0000\r\nX-Received: from [69.147.65.149] by n43.bullet.mail.sp1.yahoo.com with NNFMP; 09 Aug 2009 04:36:24 -0000\r\nX-Received: from [98.137.34.72] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 09 Aug 2009 04:36:24 -0000\r\nDate: Sun, 09 Aug 2009 04:36:23 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;h5ljo7+pcc5@...&gt;\r\nIn-Reply-To: &lt;h5fit6+ajgp@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: hyperneat questions\r\nX-Yahoo-Group-Post: member; u=54567749; y=-ALCX3ckWwXwozGTKVZ3DKcPGNffDkPv3VZvKvYooHiN5sx_RK4b\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nNikolai, you have the main idea right but the one aspect of your descriptio=\r\nn that I would correct is the idea that the substrate must be a perceptron.=\r\n  In fact, the substrate can be any type of network, and substrates do not =\r\nneed to be &quot;joined together&quot; from separate CPPNs to create substrates with =\r\nhidden layers.  There are two ways that CPPNs can represent networks with h=\r\nidden layers:\n\n1) The CPPN can have multiple outputs, where the different o=\r\nutputs are interpreted as the weights of different layers of the substrate.=\r\n  This method can encode a substrate with an arbitrary number of layers (de=\r\npending on the number of outputs of the CPPN).  This approach was used in o=\r\nur 2008 publication in which a 2-layer checkers-player was evolved by Hyper=\r\nNEAT:\n\nhttp://eplex.cs.ucf.edu/papers/gauci_aaai08.pdf\n\nThe second picture =\r\non the HyperNEAT Users Page also depicts this idea:\n\nhttp://eplex.cs.ucf.ed=\r\nu/hyperNEATpage/HyperNEAT.html\n\n2) The second way to create a network with =\r\nmultiple layers is simply\nto use a z-axis coordinate in addition to x and y=\r\n (if the substrate is 3-D).  If the networks is 2-D, then the y-axis in eff=\r\nect becomes the layer designation.  So the CPPN could input x1 y1 z1 x2 y2 =\r\nz2 to create a 3-D network with an arbitrary number of layers.  A 2-D netwo=\r\nrk with multiple layers only needs x1 y1 x2 y2.  This type of (2-D) multila=\r\nyer network is used in our 2008 publication on multiagent HyperNEAT:\n\nhttp:=\r\n//eplex.cs.ucf.edu/papers/dambrosio_gecco08.pdf\n\n...\n\nThus it turns out tha=\r\nt CPPNs naturally encode networks with multiple layers, and there are a cou=\r\nple options for doing so.\n\nOne last correction I would make is that HyperNE=\r\nAT can also evolve the topology of the substrate.  In our implementations s=\r\no far, by convention, if the output weight magnitude  is less than some thr=\r\neshold, then the connection is not expressed.  If the magnitude is above th=\r\ne threshold, then its weight magnitude is scaled to between 0 and a max-wei=\r\nght.  Thus the CPPN in effect determines both the topology and weights of t=\r\nhe network.\n\nWhat the CPPN does not yet determine (at present) is the place=\r\nment of the nodes in the substrate.  In HyperNEAT, nodes exist at geometric=\r\n locations, and those locations are currently selected by the experimenter.=\r\n  A number of people in the group are interested in what we have been calli=\r\nng &quot;evolving the substrate,&quot; which means finding a way for HyperNEAT to dec=\r\nide where the nodes are placed on its own.\n\nken\n\n\n\n\n\n--- In neat@yahoogroup=\r\ns.com, &quot;Nikolai&quot; &lt;ker_31_toluca@...&gt; wrote:\n&gt;\n&gt; I had a hard time understan=\r\nding how exactly HyperNEAT works,\n&gt; so , here i summarized all the ideas, h=\r\noping someone could clear my doubts:\n&gt; \n&gt; So far i understood that:\n&gt; \n&gt; - =\r\nHyperNEAT uses 2 types of networks: CPPNs and Perceptron-type, CPPNs are ev=\r\nolved, perceptron-type are not because depend directly on CPPN weights\n&gt; - =\r\nA CPPN outputs weights only and it doesn&#39;t connect inputs or outpus of the =\r\nproblem domain, so, no real data passes through CPPN\n&gt; - Weights produced b=\r\ny a CPPN are used to build perceptron type neural networks which are connec=\r\nted to input/outputs of the problem domain.\n&gt; - There are 2 type of activat=\r\nion functions, for each network type\n&gt;   1. Activation function of the CPPN=\r\n, which can be of any type, and it can output any floating point value\n&gt;   =\r\n2. Activation function of the perceptron-type network in form of (1/(1+(exp=\r\n(-(slope*activesum))))) which output values are in range from 0 to 1\n&gt; - Th=\r\nere is no evolution mechanism for the topology of perceptron-type networks =\r\nwich is fixed from the begining,  The only evolution that takes place is ev=\r\nolution of the CPPN, wich is based on the coordinates of the source and des=\r\ntination node to produce the weight\n&gt; - The perceptron-type networks have o=\r\nnly 2 layers (input & output) and it is not possible to have hidden layers,=\r\n because CPPN can not produce them by definition, so all the hidden layers =\r\nmust be engineered by hand of the designer. \n&gt;   For example, in order to h=\r\nave one hidden layer in HyperNEAT for a particular problem, 2 perceptron-ty=\r\npe networks (which will be produced by 2 separated CPPNs)  must be joined t=\r\nogether, the outputs of the first perceptron-type network (produced by the =\r\nfirst CPPN) must be connected with the input of the second perceptron-type =\r\nnetwork (produced by the second CPPN). \n&gt; \n&gt; \n&gt; Is this how HyperNEAT works=\r\n?\n&gt; \n&gt; \n&gt; Thanks in advance\n&gt;\n\n\n\n"}}