{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"Zr_euM28Ea4U0O1NJqU6ST0rmvAQ_0irV7A_klOyPer9txrsKuBFJ-VZFaBcEHmnw1W5K_fVIiWofncBhtqZStfzFspi","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Quantitative vs. Qualitative Results","postDate":"1366499903","msgId":6059,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtrdjdvMCt0b3RnQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDJCODc1QzE4LUNCODktNDlDNy05NDhFLTI3RTU3MUZDNjgyNUBoYXBweWNvZGVycy5vcmc+"},"prevInTopic":6058,"nextInTopic":6060,"prevInTime":6058,"nextInTime":6060,"topicId":6038,"numMessagesInTopic":46,"msgSnippet":"Hi JBM, thanks for getting deeper into this fascinating issue of how we can be confident that a paper has strong results.  I hope you don t mind that I changed","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 54170 invoked by uid 102); 20 Apr 2013 23:18:24 -0000\r\nX-Received: from unknown (HELO mta2.grp.bf1.yahoo.com) (10.193.84.150)\n  by m3.grp.bf1.yahoo.com with SMTP; 20 Apr 2013 23:18:24 -0000\r\nX-Received: (qmail 29984 invoked from network); 20 Apr 2013 23:18:24 -0000\r\nX-Received: from unknown (HELO ng14-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.118)\n  by mta2.grp.bf1.yahoo.com with SMTP; 20 Apr 2013 23:18:24 -0000\r\nX-Received: from [98.139.164.122] by ng14.bullet.mail.bf1.yahoo.com with NNFMP; 20 Apr 2013 23:18:24 -0000\r\nX-Received: from [10.193.94.45] by tg3.bullet.mail.bf1.yahoo.com with NNFMP; 20 Apr 2013 23:18:24 -0000\r\nDate: Sat, 20 Apr 2013 23:18:23 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kkv7o0+totg@...&gt;\r\nIn-Reply-To: &lt;2B875C18-CB89-49C7-948E-27E571FC6825@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Quantitative vs. Qualitative Results\r\nX-Yahoo-Group-Post: member; u=54567749; y=OaqoyrMJcgssKfVi0DMhp3cdXVDyiYPXLQiVtyfgsCMZQ2Xo3x-M\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi JBM, thanks for getting deeper into this fascinating issue of how we c=\r\nan be confident that a paper has strong results.  I hope you don&#39;t mind tha=\r\nt I changed the subject line to make this thread easier to find in the futu=\r\nre.\n\nI think we all broadly agree that there is no single formula for a goo=\r\nd paper and you and Jeff are arguing more about matters of degree.  I am ve=\r\nry interested in this subject as you know and I think it merits a lot more =\r\nattention than it usually gets, which is one reason I&#39;m glad you got deeper=\r\n into it.  So here I want to add some more weight to the case for qualitati=\r\nve papers.  I should warn everyone up front that I took this opportunity ba=\r\nsically to write an essay, so this is a long post full of my thoughts on th=\r\nis issue.\n\nI believe most people in our field would agree with JBM&#39;s assert=\r\nion that there is &quot;a strong correlation between weak papers and papers with=\r\nout strong quantitative results.&quot;\n\nI want to question that assumption becau=\r\nse I do not believe it is true even though it is widely assumed to be true =\r\nand in fact is perhaps the engine behind the entire reviewing philosophy in=\r\n AI.  In fact, this issue of how science should progress is ultimately not =\r\na scientific issue but a philosophical issue.  That is, when you begin to d=\r\niscuss which kinds of results are most useful for future progress, it is a =\r\nmeta-discussion about how science progresses.  Paul Feyerabend, who was a k=\r\nind of radical philosopher of science, has a really nice quote on this issu=\r\ne that I find inspirational: \n\n&quot;To those who look at the rich material prov=\r\nided by history, and who are not intent on impoverishing it in order to ple=\r\nase their lower instincts, their craving for intellectual security in the f=\r\norm of clarity, precision, &#39;objectivity&#39;, &#39;truth&#39;, it will become clear tha=\r\nt there is only one principle that can be defended under all circumstances =\r\nand in all stages of human development. It is the principle: anything goes.=\r\n&quot; \nAgainst Method: Outline of an Anarchistic Theory of Knowledge (1975)\n\nMy=\r\n personal experience fits very well with this idea.  There will be times in=\r\n history where quantification is what we need, and other times when it is t=\r\nhe last thing we need.  And I believe the worship of quantification has rec=\r\nently, at this point in the history of our field, been mostly an obstacle t=\r\no progress put in place by those &quot;craving for intellectual security,&quot; as Fe=\r\nyerabend puts it.  But insecurity is not a good foundation for the building=\r\n of wisdom because exploration requires courage and a willingness to confro=\r\nnt ambiguity.  Quantification at this time in AI is largely an attempt to e=\r\nscape from ambiguity, and thereby becomes a form of deception.\n\nConsider wh=\r\nat I have called the &quot;objective paradox&quot;: often if you measure the ability =\r\nof a method or encoding in EC to achieve a specific objective, your conclus=\r\nions about what that method can achieve in general will be entirely skewed =\r\nand misleading.  Target-based benchmarks, rather than giving confidence, ar=\r\ne causing us to miss the forest for the trees.  Think how in my paper with =\r\nBrian Woolley (http://eplex.cs.ucf.edu/publications/2011/woolley-gecco11) w=\r\ne could not re-evolve many images on Picbreeder with NEAT and CPPNs (which =\r\nare the very methods behind Picbreeder).  So in the quantitative world we w=\r\nould conclude that CPPNs cannot evolve such images.  And in fact results of=\r\n this sort (showing method X cannot solve problem A) are published all the =\r\ntime, and almost entirely misleading.  \n\t\nThey are also the basis of highly=\r\n deceptive comparisons between method X and Y.  We like to say if method X =\r\n&quot;performs significantly better&quot; than method Y on task A then method X is so=\r\nmehow &quot;better.&quot;  But the truth is that often the ability of an encoding to =\r\nevolve to a specific target is a bad sign for its ability to ever produce a=\r\nnything interesting.  Think about direct encodings:  they will always win o=\r\nn low-dimensional target-matching problems but are a dead end for evolving =\r\nanything truly complex.  We are fooling ourselves with quantification.\n\nEve=\r\nn people who are aware of Woolley&#39;s result and agree with our conclusions *=\r\nstill* publish this kind of result because our culture is so deeply entrenc=\r\nhed in this kind of quantification that we simply have no idea what else to=\r\n do.  If we were willing to truly embrace the absurdity of this kind of ana=\r\nlysis, someone would have the courage to proclaim that DNA is incapable of =\r\nevolving humans (which were of course never set as the objective of evoluti=\r\non).  After all, if humans were set as objective targets for evolution from=\r\n the start, there would be no humans.  \n\nHow many of us have tried to test =\r\nmethod X on objective A and found method X wanting and then published the r=\r\nesult?  And how many such papers would you consider &quot;strong?&quot;  Our culture =\r\nof worshipping quantification has often led us astray on the real power of =\r\nevolution and the potential of different encodings.  If intuition trumped q=\r\nuantification (a heretical suggestion) this fundamental confusion would not=\r\n have arisen so severely.\n\nNow I want to look at this issue from the opposi=\r\nte direction, where my own experience has been much more positive: how qual=\r\nitative observations often lead to unexpected leaps of insight in a way qua=\r\nntitative results rarely have for me.  In fact, almost every idea in which =\r\nI have been involved is the result of a qualitative observation, exactly th=\r\ne kind that worshipers of quantification seem to want to prevent us from pu=\r\nblishing and sharing with each other.  \n\nFor example, before I thought of N=\r\nEAT I read dozens of neuroevolution papers (this was in the Fall of 1999). =\r\n There were tons of quantitative results and comparisons, but at the end of=\r\n four months of reading all this literature, I did not remember any of the =\r\nquantitative results.  Instead, what was left with me was a &quot;feeling&quot; that =\r\nsomething qualitative was missing:  Regardless of performance, none of thes=\r\ne methods had the feel of nature when it came to the tendency for complexit=\r\ny to increase elegantly and indefinitely.  And that is where the inspiratio=\r\nn for NEAT began, by ignoring quantitative results.  If I had followed them=\r\n, I would simply have built upon the &quot;best&quot; neuroevolution method of the ti=\r\nme, which had been my original plan, having been brought up too in the cult=\r\nure of quantification.  So then there would be no NEAT.\n\nMy idea for CPPNs =\r\nwas also from an entirely qualitative observation.  It actually came before=\r\n Picbreeder.  The main insight was actually from evolving a spaceship image=\r\n in Mattias Fagerlund&#39;s old NEAT-based Genetic Art program.  The experience=\r\n of evolving the spaceship was so exciting to me at the time that I put up =\r\na whole website on it: http://www.cs.utexas.edu/users/kstanley/rocket.html =\r\n \n\nThere was not a single quantitative result, but I was convinced that I h=\r\nad seen something, qualitatively, that resonated with nature.  It was that =\r\nqualitative feeling, that recognition of something deep in the results, tha=\r\nt led to CPPNs.  It was a couple years later that the whole theory solidifi=\r\ned and I wrote the journal article on CPPNS: http://eplex.cs.ucf.edu/public=\r\nations/2007/stanley-gpem07\n\nOne interesting thing about that CPPN journal a=\r\nrticle is that it is almost entirely qualitative.  As you can imagine, that=\r\n posed problems for review, but I was determined not to pollute it with mea=\r\nningless quantification. For me, the images speak for themselves.\n\nThose ob=\r\nservations on CPPNs and their resulting symmetries and regularities are als=\r\no what led to David D&#39;Ambrosio, Jason Gauci and myself creating HyperNEAT -=\r\n again, the inspiration for the idea was not any quantitative demonstration=\r\n of anything.  \n\nAnd finally, as some of you know, novelty search itself wa=\r\ns not inspired by a quantitative result.  Rather, it comes *again* from evo=\r\nlving pictures - in this case it was my experience of evolving the Picbreed=\r\ner Car: picbreeder.org/search/showgenome.php?sid=3D464\nWhat shocked me from=\r\n the experience of evolving the car was that I had not been trying to evolv=\r\ne a car.  I could not stop thinking about that, about how I did something r=\r\neally hard (from a qualitative perspective) by not trying to do it.  I late=\r\nr noticed that almost every interesting image on the site has the same stra=\r\nnge story.  I discussed the implications of these observations with Joel Le=\r\nhman, which led us both to novelty search.\n\nNow someone could argue that th=\r\nese ideas may all turn out &quot;weak&quot; in the end.  But that would be a strange =\r\nphilosophy of science; it would suggest that we should never have explored =\r\ndown these roads in the first place.  Of course we cannot know where any ro=\r\nad leads until we take it - and I think at least it&#39;s clear these were road=\r\ns worth exploring though no one can say they lead ultimately to the greates=\r\nt truths.  But it&#39;s still worth the lessons along the way.  \n\nSomeone might=\r\n also think, okay, your inspirations may have been qualitative but your *re=\r\nsults* were mainly quantitative, and somehow that&#39;s what matters (though re=\r\ncall the CPPN paper does not have quantitative results).  As JBM points out=\r\n, our novelty search paper did have quantitative results that ultimately co=\r\nnvinced him something interesting was going on.  But I think again the focu=\r\ns here on &quot;results&quot; misses the forest for the trees.  What is more importan=\r\nt for the progress of science than the results is the *inspiration* that le=\r\nads to the ideas that produced the results.  If the inspiration is withheld=\r\n, if I cannot share with you the analogue of the spaceship or the car in th=\r\ne future, then you can never draw from those inspirations to find new roads=\r\n for us to travel.  The kind of science that I believe JBM and many others =\r\nidealize cuts out all the inspiration from the public sphere and leaves us =\r\nonly to share its fruits when someone is lucky enough in private to see som=\r\nething interesting (and try to quantify it then).\n\nNevertheless, JBM says, =\r\n&quot;I think that it is much harder to write a convincing paper without any qua=\r\nntitative test than with the help of measures/comparisons/etc.&quot;  Again, man=\r\ny would share this sentiment.  But if you think about it, what exactly do w=\r\ne need to be &quot;convinced&quot; of?  Why do we think science (or AI especially) is=\r\n about convincing someone of something?  Why do we need e.g. 30 strangers t=\r\no validate an intuition we already feel deeply that something is interestin=\r\ng?  The links in the chain of progress are from inspiration, not from convi=\r\nncing.  There are many ideas that are neither right nor wrong anyway, but w=\r\north exploring because they will lead us to new revelations.  To me, captur=\r\ning the essence of nature is as much about a feeling as it is about a resul=\r\nt.  And my experience in practice bears that out.\n\nHere is where I want to =\r\nreturn to the intellectual insecurity that Feyerabend raises.  I think our =\r\nquantitative culture all boils down to this problem of insecurity.  We do n=\r\not trust ourselves to have valid intuitions.  We dismiss our own ability to=\r\n think, as with JBM&#39;s tongue-in-cheeck parody, &quot;look, cool simulated robots=\r\n.&quot;  But I want to question why we are so insecure in our own qualitative ju=\r\ndgments?  \n\nFor those of us with PhDs, our countries invested something lik=\r\ne 25 years into our education.  Shouldn&#39;t someone who supposedly succeeded =\r\nin jumping through intellectual hoop after hoop after hoop - eventually imp=\r\nressing their peers enough to be hired, even eventually to be tenured or pr=\r\nomoted - be able to think for themselves sufficiently to decide whether the=\r\n &quot;cool robots&quot; are worth sharing with other scientists because they might i=\r\nnspire new ideas?  If we are really entirely unqualified after all those ye=\r\nars of supposedly learning to be a scientist, then what was the use of all =\r\nthat public investment?  Was it simply to validate that we are able to chec=\r\nk p-values that someone else reports in an X vs. Y quantitative comparison?=\r\n  That&#39;s all we&#39;re qualified to do?  Why do we deny our intellectual curios=\r\nity and ability to think for ourselves?  \n\nYou may think it can&#39;t be done. =\r\n Maybe you think my personal experience with NEAT, CPPNs, HyperNEAT, novelt=\r\ny search, etc. is some kind of fluke that doesn&#39;t really represent science =\r\nand how it works.  Maybe you think that kind of qualitative approach may wo=\r\nrk for Ken for some reason but it can&#39;t work in general.  But why would tha=\r\nt be?  Isn&#39;t it possible that we are all prematurely discrediting our intel=\r\nlectual potential to think for ourselves?  We have created a culture in whi=\r\nch the spaceships and cars of science must be hidden, buried until their di=\r\nscoverers figure out (or give up figuring out) their deeper implications.  =\r\nI do not support publishing a paper simply because of some &quot;cool robots,&quot; b=\r\nut I do support qualified scientists deciding for themselves, from their ex=\r\nperience and intuitions, whether those cool robots might be the seed of an =\r\nimportant chain of ideas.  And I do not want those cool robots hidden from =\r\nme as a reader of scientific literature if they might be such a seed.  When=\r\n I looked at Jeff&#39;s recent video of his cool robots, I could feel those whe=\r\nels of intuition turning in my mind.  I still don&#39;t know if it leads to any=\r\nthing, but I don&#39;t need any quantification to know that that feeling is mor=\r\ne than enough to justify publishing that paper, and I&#39;m grateful he and his=\r\n coauthors did not try to obfuscate it with a veil of needless quantificati=\r\non.\n\nBest,\n\nken\n\n\n\n--- In neat@yahoogroups.com, Jean-Baptiste Mouret &lt;mando=\r\nr@...&gt; wrote:\n&gt;\n&gt; Hi Jeff,\n&gt; \n&gt; On 20 avr. 2013, at 20:35, Jeff Clune wrote=\r\n:\n&gt; &gt; However, my point is that you don&#39;t *always* need a quantitative test=\r\n. I agree that there are many papers that describe some very complex system=\r\n, show some cool results, and we don&#39;t learn anything. But sometimes there =\r\nare papers that show something extremely impressive and don&#39;t have any info=\r\nrmative quantitative measures, and we learn a lot. It is the job of the rev=\r\niewer to judge whether there is a contribution: but a reviewer should not s=\r\ntart with the assumption that &quot;if there is no quantitative test, it&#39;s not s=\r\ncience and is not publishable.&quot; My guess is that you agree with that, right=\r\n?\n&gt; \n&gt; I agree. What I was trying to explain in the previous e-mail was: (1=\r\n) we need to learn something from the paper and (2) quantitative analysis i=\r\ns an easy way to argue something in a convincing way.\n&gt; \n&gt; I agree that the=\r\n reviewer should not start with the assumption &quot;if there is no quantitative=\r\n test, it&#39;s not science and is not publishable.&quot; However, I think that it i=\r\ns much harder to write a convincing paper without any quantitative test tha=\r\nn with the help of measures/comparisons/etc. As a result, as a reviewer, I =\r\nstart being suspicious when I see a paper without strong quantitative resul=\r\nts. I may accept it, but I know that the challenge =97 for the author =97 w=\r\nill be more difficult.\n&gt; \n&gt; Another important point is that there is, in my=\r\n opinion, a strong correlation between weak papers and papers without stron=\r\ng quantitative results. Correlation does not imply causation, but we someho=\r\nw learn to have an intuitive bad feeling when we see a paper without quanti=\r\ntative results.\n&gt; \n&gt; &gt; Here is one strong argument for not mandating a quan=\r\ntitative test: we have not created AI yet, so there are many things that hu=\r\nmans can judge better than computers/quantitative tests. Take computer visi=\r\non, for example. All of us are blown away by the images that resulted on Pi=\r\ncbreeder,\n&gt; \n&gt; [Picbreeder is not related at all with computer vision]\n&gt; \n&gt;=\r\n \n&gt; &gt; Picbreeder taught us a lot about why CPPNs are powerful and interesti=\r\nng, but they did not do so with numbers. My guess is that the Picbreeder pa=\r\npers did jump through some hoops to provide numbers to satisfy reviewers th=\r\nat insist on them (I forget at this point, it&#39;s been a while since I read t=\r\nhose papers), but those numbers likely taught us very little about the cent=\r\nral advance. \n&gt; \n&gt; Agreed. Sometimes, examples can teach us many things. Bu=\r\nt, again, it&#39;s hard to make a strong points with examples. I&#39;m not saying i=\r\nt&#39;s impossible and your example is probably a good example. \n&gt; \n&gt; &gt; The sam=\r\ne is true for many domains: if I come up with a new story-telling algorithm=\r\n, the judgement of whether it is a huge advance would be you listening to t=\r\nhe stories and thinking about whether they feel more natural and impressive=\r\n than what came before.\n&gt; \n&gt; This is typically quantified by taking 30 peop=\r\nle and make them grade your story. My subjective opinion does not count tha=\r\nt much.\n&gt; \n&gt; &gt; Do you agree?\n&gt; \n&gt; I agree with you. Nevertheless, our field=\r\n is young and I think we have to put pressure to have strong papers on whic=\r\nh we can build strong foundations for future researches. One way to put thi=\r\ns pressure is to have high standards and encourage to measure everything th=\r\nat is measurable/comparable, so that the average paper is as good as possib=\r\nle. Keep in mind that papers like &quot;look, cool simulated robots!&quot; are making=\r\n our field weaker.\n&gt; \n&gt; Again, I&#39;m advocating that we should judge papers b=\r\ny how much they teach us. I think we agree on this. Quantitative analysis i=\r\ns an easy way to teach something to the reader, other ways are possible. Bu=\r\nt they are harder.\n&gt; \n&gt; Best regards,\n&gt; =97 JBM\n&gt;\n\n\n\n"}}