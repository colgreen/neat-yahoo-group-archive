{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"H_KWa8k8tYz1N5aJ3wog8j3TGLiVhyg967GxLKCXbxhQ4HAhg5pQ7KVHsUcScyMX2frvxF6s_G_yHcs5UH1twLo","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Backpropagation and NEAT","postDate":"1205779047","msgId":3886,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZybWRwNytxNmF2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZybTI2cyt1MjBrQGVHcm91cHMuY29tPg=="},"prevInTopic":3884,"nextInTopic":3887,"prevInTime":3885,"nextInTime":3887,"topicId":3846,"numMessagesInTopic":41,"msgSnippet":"Ken, I can appreciate the need to choose applications with careful scrutiny with a sincere belief in their practical ramifications , but the simple truth is","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 7568 invoked from network); 17 Mar 2008 18:37:31 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m46.grp.scd.yahoo.com with QMQP; 17 Mar 2008 18:37:31 -0000\r\nX-Received: from unknown (HELO n18a.bullet.sp1.yahoo.com) (69.147.64.127)\n  by mta18.grp.scd.yahoo.com with SMTP; 17 Mar 2008 18:37:31 -0000\r\nX-Received: from [216.252.122.217] by n18.bullet.sp1.yahoo.com with NNFMP; 17 Mar 2008 18:37:28 -0000\r\nX-Received: from [209.73.164.83] by t2.bullet.sp1.yahoo.com with NNFMP; 17 Mar 2008 18:37:28 -0000\r\nX-Received: from [66.218.66.77] by t7.bullet.scd.yahoo.com with NNFMP; 17 Mar 2008 18:37:28 -0000\r\nDate: Mon, 17 Mar 2008 18:37:27 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;frmdp7+q6av@...&gt;\r\nIn-Reply-To: &lt;frm26s+u20k@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Backpropagation and NEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=9fy_0WUROgYPMy1cqHv-sKWGjyazdT3k2jxoHtbcFGjlFQ\r\nX-Yahoo-Profile: afcarl2\r\n\r\nKen,\n\nI can appreciate the need to choose applications &quot;with careful \nscrut=\r\niny with a sincere belief in their practical ramifications&quot;, but \nthe simpl=\r\ne truth is that your bias for exploring &quot;patterns and \nregularities&quot;, are u=\r\ntterly destroyed by the application of non-linear \ninequality feasibility c=\r\nonstraints. Which routinely happens in the \ndomain of engineering optimizat=\r\nion/search. \n\nYour operation without the application of the pressures assoc=\r\niated \nwith these pattern destroying influences results in a unrealistic \np=\r\nerspective on the utility of global pattern exploitation, and a \nfailure to=\r\n address the repercussions of the sometimes seemingly \ntotally arbitrary na=\r\nture of enforced feasibility constraints dictated \nby real-world problems.\n=\r\n\nUntil you can simultaneously address the exploitation of multiple \nhypersp=\r\nace &quot;regional/sub-volume&quot; patterns/regularities overlaid with \nmultiple arb=\r\nitrary non-linear inequality feasibility constraints, in \na computationally=\r\n practical manner, methodologies such as Hyperneat \nwill be dispatched as &quot;=\r\ncuriosities&quot; only.\n\nThese kinds of pressures are routinely addressed in the=\r\n domain of \nengineering optimization/search. Your choice of side-stepping t=\r\nhese \ninfluences shapes what infrastructure is and is-not developed, as has=\r\n \nbeen adequately addressed in prior posts.\n\nAn applicable quote: &quot;I have l=\r\nittle patience with scientists who take \na board of wood, look for its thin=\r\nnest part, and drill a great number \nof holes where drilling is easy.&quot;--Alb=\r\nert Einstein\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;=\r\n wrote:\n&gt;\n&gt; Andy, I have no problem with the idea of NEAT as a foundation u=\r\npon\n&gt; which to build.  That&#39;s perfectly aligned with my view that there is\n=\r\n&gt; more yet to accomplish.  \n&gt; \n&gt; Let me respond to some of your specific po=\r\nints below.\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; =\r\n\n&gt; &gt; \n&gt; &gt; The issues you raise, though valid, appear disingenuous for two \n=\r\n&gt; &gt; reasons. First, if you had reviewed the contents and capabilities \nof \n=\r\n&gt; &gt; the Dakota toolkit, you would have discovered the issues as being \n&gt; &gt; =\r\nessentially addressed. Second, not intending any disrespect, from \n&gt; &gt; exte=\r\nrnal appearances, your efforts appear directed in other \n&gt; &gt; directions tha=\r\nn that of addressing your self admitted areas of \n&gt; &gt; concern.\n&gt; &gt; \n&gt; &gt; Fro=\r\nm a review of literature on the subject, there is a common \n&gt; &gt; understandi=\r\nng that EA is computationally expensive and slow to \n&gt; &gt; converge, but robu=\r\nst for global search in problem domains with \n&gt; &gt; multiple local minima.\n&gt; =\r\n&gt; \n&gt; \n&gt; It really just depends who you are talking about whether there is a=\r\n\n&gt; &quot;common understanding&quot; about anything in AI.  It also depends \nwhether\n&gt;=\r\n we are talking about the past or the future.  \n&gt; \n&gt; For example, it&#39;s ofte=\r\nn said that &quot;neural networks get caught on \nlocal\n&gt; optima&quot; (and there is i=\r\nndeed a &quot;common understanding&quot; that they do)\n&gt; but when people say that the=\r\ny are almost always only talking about\n&gt; backprop, which is just one single=\r\n neural network learning \nalgorithm.\n&gt;  Backprop is not the only way a neur=\r\nal network can learn.\n&gt; \n&gt; The problem is that when we talk about methods i=\r\nn machine learning \nwe\n&gt; often confuse whether we are talking about a *fiel=\r\nd* or a particular\n&gt; method.  In the case of EAs, you seem to be talking ab=\r\nout some\n&gt; existing methods that have been analyzed (often by people who ar=\r\ne \nnot\n&gt; even aware of the most modern approaches) in the past.   For \nexam=\r\nple,\n&gt; the old-fashioned bit-string based simple EA has been analyzed\n&gt; ext=\r\nensively.\n&gt; \n&gt; Yet as a field, EAs themselves are evolving.  Problems ident=\r\nified in\n&gt; the past are actively being addressed in the present and future.=\r\n \nSome\n&gt; modern approaches completely overturn the assumptions and problems=\r\n \nof\n&gt; the past (and of course introduce their own new problems).  Check \no=\r\nut\n&gt; Estimation of Distribution Algorithms and the CMA-ES:\n&gt; \n&gt; http://en.w=\r\nikipedia.org/wiki/Estimation_of_distribution_algorithm\n&gt; http://en.wikipedi=\r\na.org/wiki/CMA-ES\n&gt; \n&gt; When I look at EAs, or any research area for that ma=\r\ntter, I always\n&gt; think about what they *could* be, rather than what they ar=\r\ne.  And \nas a\n&gt; researcher, I try to make them what they could be.  To me, =\r\nthat is \nthe\n&gt; exciting thing about research: At its best, it overturns dog=\r\nma.  I\n&gt; like to view a limitation as a challenge rather than as a brick \nw=\r\nall.\n&gt; \n&gt; &gt; And that is from people who are working &quot;hard&quot; problems (i.e. \n=\r\nmulti-\n&gt; &gt; discipline, multiobjective, non-linear inequality constraints, \n=\r\netc.), \n&gt; &gt; at government laboratories and Fortune 100 defense firms. Not \n=\r\ndancing \n&gt; &gt; rag-dolls and computer-aided art.\n&gt; &gt; \n&gt; \n&gt; First, while you o=\r\nften cite multiobjective optimization as a &quot;hard\n&gt; problem&quot; for EAs, in fac=\r\nt some of the most effective algorithms in\n&gt; multiobjective optimization ar=\r\ne EAs.  EAs are naturally suited to\n&gt; maintaining a pareto front because a =\r\npareto front requires a\n&gt; population to hold it.  There is vast literature =\r\non pareto\n&gt; optimization in EAs, both in multiobjective optimization and in=\r\n\n&gt; coevolution.  Here are some seminal examples:\n&gt; \n&gt; K. Deb, A. Pratap, S.=\r\n Agarwal, and T. Meyarivan. A Fast and Elitist\n&gt; Multiobjective Genetic Alg=\r\norithm: NSGA-II. IEEE Transactions on\n&gt; Evolutionary Computation, 6(2):182=\r\n=96197, 2002.\n&gt; http://citeseer.ist.psu.edu/530140.html\n&gt; \n&gt; De Jong, E.D. =\r\n(2004). The Incremental Pareto-Coevolution Archive.\n&gt; Proceedings of the Ge=\r\nnetic and Evolutionary Computation Conference\n&gt; GECCO-04, pp. 525-536. \n&gt; h=\r\nttp://people.cs.uu.nl/dejong/publications/gecco04coev.pdf\n&gt; \n&gt; in fact, som=\r\ne of the most brilliant theorists in pareto optimization\n&gt; are in evolution=\r\nary computation.\n&gt; \n&gt; As for NEAT in government research labs on &quot;serious&quot; =\r\nproblems, here \nis\n&gt; an example:\n&gt; \n&gt; Shimon Whiteson and Daniel Whiteson (=\r\n2007). &quot;Stochastic Optimization\n&gt; for Collision Selection in High Energy Ph=\r\nysics&quot;. IAAI 2007:\n&gt; Proceedings of the Nineteenth Annual Innovative Applic=\r\nations of\n&gt; Artificial Intelligence Conference.&#8202;\n&gt; http://arxiv.org/P=\r\nS_cache/hep-ex/pdf/0607/0607012v1.pdf\n&gt; \n&gt; The article itself states, &quot;Thes=\r\ne NEAT selectors are currently in \nuse\n&gt; at FermiLab for selecting collisio=\r\nns from real data collected\n&gt; with the Tevatron collider.&quot;  So, there you g=\r\no, NEAT is being used \nat\n&gt; FermiLab itself to select which particle collis=\r\nions are most \npromising.\n&gt; \n&gt; When you mention rag dolls and art, you&#39;re g=\r\niving me an opportunity \nto\n&gt; comment on some of our own current research. =\r\n Our group has indeed\n&gt; recently produced a number of works in interactive =\r\nevolution,\n&gt; including dance, art, music, and particle effects.  Perhaps it=\r\n may\n&gt; seem a somewhat lighthearted departure from more serious subjects.\n&gt;=\r\n \n&gt; Yet the implications of this work are as serious as any in my view. \n&gt; =\r\nAll of that work is a probe of the ubiquity of patterns and\n&gt; regularities,=\r\n in particular through the theory of CPPNs.  The deeper\n&gt; lesson in that bo=\r\ndy of work is that the very same encoding is able \nto\n&gt; produce patterns ap=\r\npropriate to what would otherwise appear to be\n&gt; disparate domains.  The id=\r\nea is to develop a theory of generic \npattern\n&gt; generation and to show that=\r\n patterns are interchangeable across many\n&gt; domains.  That insight leads to=\r\n the idea of HyperNEAT, which takes\n&gt; again the very same encoding that is =\r\nproducing art and music and \nuses\n&gt; it to produce a large-scale neural patt=\r\nern.  Therein it becomes\n&gt; serious, because the hard problems you like to f=\r\nocus on almost \nalways\n&gt; involve patterns and regularities.  \n&gt; \n&gt; It is no=\r\n accident that in building a theory of pattern generation, a\n&gt; number of in=\r\nteractive evolutionary computation experiments would \nneed\n&gt; to be performe=\r\nd because understanding the capabilities of a pattern\n&gt; generator require *=\r\nexploring* the space of possibilities rather than\n&gt; simply optimizing, and =\r\nhumans are much better explorers than\n&gt; computers.  The theory would never =\r\nhave gotten off the ground if we\n&gt; had stuck to more traditional optimizati=\r\non problems.   Indeed, as\n&gt; funny as it sounds, the whole idea began to mat=\r\nerialize only after I\n&gt; evolved a spaceship in Mattias Fagerlund&#39;s DelphiNE=\r\nAT.  \n&gt; \n&gt; To put it starkly, without that exploration in genetic art, ther=\r\ne\n&gt; would have been no HyperNEAT.  And in fact even more new theories \nwith=\r\n\n&gt; practical implications are coming (not yet published) because of\n&gt; pheno=\r\nmena that became apparent through Picbreeder.  So you see, in\n&gt; building a =\r\nnew algorithm or a new theory with practical \nimplications,\n&gt; often traditi=\r\nonal problems are exactly the wrong vehicle to \ndiscovery\n&gt; because they pe=\r\nrpetuate the same dogmatic perspectives that already\n&gt; permeate the field t=\r\no begin with and cause it to be staying in one\n&gt; place.   Thus all of these=\r\n applications are chosen with careful\n&gt; scrutiny with a sincere belief in t=\r\nheir practical ramifications.\n&gt; \n&gt; Not to mention the fact that interactive=\r\n evolution itself has the\n&gt; practical potential to change the way we do eng=\r\nineering in some \ncases.\n&gt;  Can you imagine Picbreeder for furinute instead=\r\n of pictures?  Or \nfor\n&gt; cars?  Someday that may be how we create highly cu=\r\nstomized \nartifacts.\n&gt;    In fact, some of the problems to which you are re=\r\nferring (highly\n&gt; nonlinear and multi-objective) may only be possible to so=\r\nlve through\n&gt; interactive evolution.\n&gt; \n&gt; &gt; How many times has NEAT, as a m=\r\nonolithic approach, been cited and \n&gt; &gt; successfully applied by government =\r\nlaboratories and Fortune 100 \n&gt; &gt; defense firms for these type of &quot;hard&quot; pr=\r\noblems?\n&gt; &gt; \n&gt; \n&gt; You can refer to the paper on high-energy physics at Ferm=\r\niLab if\n&gt; you&#39;re interested, but I still think there is a bigger picture.  =\r\n\n&gt; \n&gt; In some ways, as researchers in AI, what practitioners are using to\n&gt;=\r\n solve hard problems is exactly what we *don&#39;t* want to use.  After\n&gt; all, =\r\nhow is anything ever going to become more powerful if we just\n&gt; look to pra=\r\nctitioners to show us what methods we should be using?  \nAs\n&gt; researchers, =\r\nit is our job to give the practitioners *new* options,\n&gt; not the other way =\r\naround.\n&gt; \n&gt; Practitioners are often several steps behind algorithm develop=\r\ners, \nand\n&gt; with good reason.  They often can&#39;t afford to take big risks an=\r\nd \nneed\n&gt; something practical in the here and now.   You will therefore fin=\r\nd\n&gt; that most cutting-edge algorithms are not in use in industry or as\n&gt; to=\r\nols in other scientific disciplines at the very moment that they \nare\n&gt; cut=\r\nting-edge.  Yet someone has to be developing the algorithms of \nthe\n&gt; futur=\r\ne.\n&gt; \n&gt; ken\n&gt;\n\n\n\n"}}