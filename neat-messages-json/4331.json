{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"RDiAjcZZUImY3EwWQ-lxQpfeNt1iSPWBw4anxzHLtP7mp27B1H1_bC8Yp_Y1LXPQEsw7sarmMQ2zpx3Eziht5hI0","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Article Documenting How Natural Selection is Not Good at Choosing At Least One of Its Own Parameters (Mutation Rate)","postDate":"1222823525","msgId":4331,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM1MDg0NkE1LjI1MkE2JWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGdiczV0ZSszNDE2QGVHcm91cHMuY29tPg=="},"prevInTopic":4330,"nextInTopic":4332,"prevInTime":4330,"nextInTime":4332,"topicId":4326,"numMessagesInTopic":12,"msgSnippet":"Hello Ken- Thank you kindly for your interest in my article. Please see my responses below. ... I do not remember you saying so. But there were at least a","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 51342 invoked from network); 1 Oct 2008 01:12:10 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m56.grp.scd.yahoo.com with QMQP; 1 Oct 2008 01:12:10 -0000\r\nX-Received: from unknown (HELO mail-gx0-f10.google.com) (209.85.217.10)\n  by mta15.grp.scd.yahoo.com with SMTP; 1 Oct 2008 01:12:09 -0000\r\nX-Received: by gxk3 with SMTP id 3so14097901gxk.0\n        for &lt;neat@yahoogroups.com&gt;; Tue, 30 Sep 2008 18:12:09 -0700 (PDT)\r\nX-Received: by 10.151.46.3 with SMTP id y3mr11040401ybj.95.1222823529334;\n        Tue, 30 Sep 2008 18:12:09 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?192.168.2.2? (c-98-209-38-75.hsd1.mi.comcast.net [98.209.38.75])\n        by mx.google.com with ESMTPS id k47sm2735524rnd.2.2008.09.30.18.12.07\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Tue, 30 Sep 2008 18:12:08 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.12.0.080729\r\nDate: Tue, 30 Sep 2008 21:12:05 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C50846A5.252A6%jclune@...&gt;\r\nThread-Topic: [neat] Re: Article Documenting How Natural Selection is Not Good\n at Choosing At Least One of Its Own Parameters (Mutation Rate)\r\nThread-Index: AckjYreM0bjJIVzBtEm2qlhkLhp+5w==\r\nIn-Reply-To: &lt;gbs5te+3416@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;ISO-8859-1&quot;\r\nContent-transfer-encoding: quoted-printable\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: Article Documenting How Natural Selection is Not Good\n at Choosing At Least One of Its Own Parameters (Mutation Rate)\r\nX-Yahoo-Group-Post: member; u=211599040; y=G7SanN5m8fsdmkhjxcobyqi63GGcYW6Qw1Qjg6wf5MUQCwEfH9Eq\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nHello Ken-\n\nThank you kindly for your interest in my article. Please see my=\r\n responses\nbelow. \n\n&gt; Do you remember if I was advocating natural selection=\r\n choosing its own\n&gt; parameters?  I don&#39;t recall the specific discussion.\n\nI=\r\n do not remember you saying so. But there were at least a couple people on\n=\r\nthe list who did. I remember someone even saying something like &quot;even if yo=\r\nu\nhave a paper about it, I still don&#39;t believe that evolution cannot do a g=\r\nood\njob of  managing its own parameters.&quot; It is my hope that this manuscrip=\r\nt is\nmore convincing than the last one I posted, mainly because it uses a s=\r\nimpler\nsystem to really demonstrate the point conclusively.\n\n&gt; I think what=\r\n caused me to become a skeptic about these kinds of\n&gt; meta-evolutionary app=\r\nroaches is speaking to people who advocate the\n&gt; idea that evolution should=\r\n &quot;evolve its own encoding.&quot;  That idea is\n&gt; connected to evolvability, whic=\r\nh suggests that evolution can figure\n&gt; out its own best parametrizations to=\r\n become most effective at evolving\n&gt; in a particular type of domain.  Worki=\r\nng on encodings started to make\n&gt; me think that the search space of encodin=\r\ngs is simply too vast to\n&gt; expect evolution itself to optimize the encoding=\r\n.  It is basically a\n&gt; vast meta-search, far vaster than the problem domain=\r\n itself (which is\n&gt; already vast to begin with in ambitious cases), and the=\r\n actual problem\n&gt; domain would seem to locally obfuscate the landscape of\n&gt;=\r\n meta-parameters (just as your results show).\n\nWell said. However, at some =\r\npoint we need recognize that evolution did get\nus to jaguars, hawks and hum=\r\nans. That may be because it had enough time and\nparallelization to deal wit=\r\nh such vast search spaces, because it got lucky\nto have certain physical co=\r\nnstraints (e.g. it is impossible to reduce the\nmutation rate to zero in the=\r\n natural world), because of the immense amount\nof co-evolution, or other at=\r\ntributes. Given that we won&#39;t be able to take\nadvantage of some of those fe=\r\natures (e.g. the vastness of the &#39;natural\ncomputer&#39;), we need shortcuts. Ma=\r\nybe these shortcuts involve doing things\ndifferently, such that we should n=\r\not always look to the natural process for\ninspiration.  \n\n&gt; Overall, I star=\r\nted to feel like human intuition is a better bet for\n&gt; solving these meta-q=\r\nuestions, or at least for addressing them\n&gt; effectively.  Also, as we start=\r\ned to think about novelty search, I\n&gt; started to realize that evolution oft=\r\nen innovates *despite* selection\n&gt; rather than because of it, which is even=\r\n more complicating at the\n&gt; meta-level.  That is, at a meta-level like enco=\r\ndings, if something\n&gt; good came about, it might actually be because selecti=\r\non pressure was\n&gt; low for a time.  In other words, if selection pressure ha=\r\ns been high,\n&gt; the steps towards whatever optimal meta-parameter was found =\r\nwould\n&gt; never have been taken because the stepping stones are meta-suboptim=\r\nal.\n&gt;  Just talking about this issue with all these &quot;metas&quot; reminds me why\n=\r\n&gt; it seems like wishful thinking to rely on evolution to determine\n&gt; everyt=\r\nhing.  Luck and happenstance have to be accepted as factors.\n\nI like this i=\r\ndea: adaptation in spite of selection, not because of it. My\nco-authors on =\r\nthis work are about to publish a paper that supports this\nidea. I&#39;ll try to=\r\n remember to post it when it comes out.\n\n&gt; In another sense, evolving meta-=\r\nparameters optimally sounds\n&gt; dangerously close to a free lunch.   If there=\r\n is an algorithm that can\n&gt; evolve the right meta-parameters reliably, whic=\r\nh in turn causes it to\n&gt; always find the right solution, when would that al=\r\ngorithm fail?\n\nIf I understand NFL right (and I may not), the algorithm doe=\r\nsn&#39;t have to\nfail, just perform worse, no? The meta-search algorithm will u=\r\nnderperform an\nalgorithm that has the right meta-parameters hard-coded in f=\r\nrom the start,\nright?\n\n&gt; By the way, Jeff (here I go contradicting myself),=\r\n there are\n&gt; reportedly evolutionary algorithms that seem to show that they=\r\n benefit\n&gt; from mutating mutation parameters.  Evolution Strategies come to=\r\n mind.\n&gt;  ES has done this kind of thing for years.  CMA-ES now uses\n&gt; stat=\r\nistical techniques to predict optimal mutation distributions.\n&gt; What do you=\r\nr results suggest about such approaches?  Are they just\n&gt; working on &quot;toy p=\r\nroblems&quot; or is there some explanation for why they\n&gt; claim to derive benefi=\r\nt from evolving the parameters?\n\nAs Alexandre points out in the following e=\r\nmail, there is an important\ndistinction to be made between &#39;adaptive&#39; and &#39;=\r\nself-adaptive&#39; parameter\nchanges. I consider self-adaptive parameter regime=\r\ns those that *evolve* the\nparameters. Adaptive regimes use an external heur=\r\nistic to change the\nparameter settings. For example, simulated annealing an=\r\nd Rechenberg&#39;s 1/5th\nrule (for Evolutionary Strategies) use an adaptive ext=\r\nernal heuristic. It\nhas been shown that such adaptive mutation rates can be=\r\n better than fixed\nmutation rates on certain problems. Thomas Back did this=\r\n in his paper (cited\nin mine) with counting ones. When a population is far =\r\nfrom the global peak\nit is good to have a higher mutation rate, but once th=\r\ne population is on the\nglobal peak it is better to lower the mutation rate.=\r\n\n\nFor this reason, I think that adapting parameters during a run is helpful=\r\n,\nif you know how to do it properly. What my current paper from PLoS CB sho=\r\nws\nis that it is not a good idea, at least with respect to mutation rates, =\r\nto\n*evolve* the parameter settings.\n\nI think this discussion is helpful, th=\r\nough, because it is very common for\npeople in our field to assume that beca=\r\nuse adaptive regimes are good,\nself-adaptive regimes are good. It is partly=\r\n my hope that this paper will\nhighlight that the one does not imply the oth=\r\ner.\n\nSo, I am going to throw down this provocative statement, because I am\n=\r\ncurious to see if there is evidence to the contrary. Claim: whenever people=\r\n\nsay that self-adaptation works, they are working on a toy problem with a\ns=\r\nmooth fitness landscape.\n\nI have seen a couple papers that claimed that sel=\r\nf-adaptation worked. But\nwhenever I looked under the hood and or talked wit=\r\nh the authors, I ended up\nfinding either that they used a smooth fitness la=\r\nndscape, or that they did\nnot check whether a fixed mutation rate would hav=\r\ne performed better than\ntheir self-adapted mutation rate.\n\nAlexandre, you m=\r\nention that CMAES are faster than SAES. Does that imply that\nSAES has also =\r\nbeen shown to work? If so, was it on a smooth fitness\nlandscape?\n\nThanks al=\r\nl for the interesting conversation.\nJeff\n\n\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoog=\r\nroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;&gt; \n&gt;&gt; Hello all-\n&gt;&gt; \n&gt;&gt; A while =\r\nback we had a discussion about whether natural selection is\n&gt; good at\n&gt;&gt; ch=\r\noosing its own parameters. Many people assume that it would be\n&gt; beneficial=\r\n\n&gt;&gt; to evolve the parameters of a run (e.g. mutation rate, crossover rate,\n=\r\n&gt;&gt; etc.). After having done some research in the area I have concluded\n&gt; th=\r\nat it\n&gt;&gt; does not work well.\n&gt;&gt; \n&gt;&gt; When I expressed this view previously, =\r\nsome of you were very\n&gt; skeptical. At\n&gt;&gt; that point, I promised to share a =\r\nmanuscript that investigates the issue\n&gt;&gt; once it was published.\n&gt;&gt; \n&gt;&gt; Tha=\r\nt manuscript finally came out yesterday in the journal PLoS\n&gt; Computational=\r\n\n&gt;&gt; Biology. I am rather excited because they chose it for the cover of the=\r\n\n&gt;&gt; September issue.\n&gt;&gt; \n&gt;&gt; You can see it here:\n&gt;&gt; www.ploscompbiol.org\n&gt;&gt;=\r\n \n&gt;&gt; Clune, et. al. =B3Natural Selection Fails to Optimize Mutation Rates f=\r\nor\n&gt;&gt; Long-Term Adaptation on Rugged Fitness Landscapes.=B2\n&gt;&gt; \n&gt;&gt; I am int=\r\nerested to see what you think. In particular, I would like\n&gt; to hear\n&gt;&gt; fro=\r\nm those of you that were skeptical of my claim. Do you still feel\n&gt; that\n&gt;&gt;=\r\n evolution can manage itself in light of this work? Note: I recognize\n&gt; tha=\r\nt\n&gt;&gt; this paper only covers mutation rates. However, the mutation rate is\n&gt;=\r\n one of\n&gt;&gt; the most important parameters. Furthermore, I think similar issu=\r\nes will\n&gt;&gt; arise with other parameters that result in the perturbation of\n&gt;=\r\n genomes (e.g.\n&gt;&gt; crossover type and rate).\n&gt;&gt; \n&gt;&gt; \n&gt;&gt; PS. PLoS allows read=\r\ners to rate articles. If you enjoyed the\n&gt; article, and\n&gt;&gt; have a second, p=\r\nlease rate it highly. I would really appreciate it!\n&gt;&gt; \n&gt;&gt; PPS. If you are =\r\nreading this email after October 25th or so, here is a\n&gt;&gt; direct link to th=\r\ne article.\n&gt;&gt; \n&gt;&gt; http://www.ploscompbiol.org/doi/pcbi.1000187\n&gt;&gt; \n&gt;&gt; PPPS.=\r\n I have another paper that found that evolving parameters did\n&gt; not work\n&gt;&gt;=\r\n tremendously well. That paper covered more than just mutation rates.\n&gt; You=\r\n can\n&gt;&gt; check that out here:\n&gt;&gt; \n&gt;&gt; https://www.msu.edu/~jclune/publication=\r\ns/CluneEtAl-meta-GAs.pdf\n&gt;&gt; \n&gt;&gt; \n&gt;&gt; Cheers,\n&gt;&gt; Jeff Clune\n&gt;&gt; \n&gt;&gt; Digital Ev=\r\nolution Lab, Michigan State University\n&gt;&gt; \n&gt;&gt; jclune@...\n&gt;&gt; \n&gt; \n&gt; \n\n\n\n"}}