{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":464818732,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"TNQ8rhpmxgKNqBj3u1tri2gnkbF25ro_vKHSrYwA9IOKhNhRZ7k6w20eDi0adDzyPJ9LHHHf7NG7UPpy1KgwyeYwzzA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New paper on why modules evolve, and how to evolve modular artif","postDate":"1362714565","msgId":6017,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDlBQkU2N0ZDLUZBMTAtNDUwMy1BQjY2LUM3QzQ0MUM3M0E5REB1d3lvLmVkdT4=","inReplyToHeader":"PGtndTE5MStzdDJpQGVHcm91cHMuY29tPg==","referencesHeader":"PGtndTE5MStzdDJpQGVHcm91cHMuY29tPg=="},"prevInTopic":6016,"nextInTopic":6018,"prevInTime":6016,"nextInTime":6018,"topicId":6011,"numMessagesInTopic":10,"msgSnippet":"Thanks for clarifying your positions Ken. I believe we have reached the point at which reasonable minds can respectably disagree, as you put it. Were I to","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 834 invoked from network); 8 Mar 2013 03:49:21 -0000\r\nX-Received: from unknown (10.193.84.168)\n  by m9.grp.bf1.yahoo.com with QMQP; 8 Mar 2013 03:49:21 -0000\r\nX-Received: from unknown (HELO mail-pa0-f52.google.com) (209.85.220.52)\n  by mta6.grp.bf1.yahoo.com with SMTP; 8 Mar 2013 03:49:20 -0000\r\nX-Received: by mail-pa0-f52.google.com with SMTP id fb1so974869pad.25\n        for &lt;neat@yahoogroups.com&gt;; Thu, 07 Mar 2013 19:49:20 -0800 (PST)\r\nX-Received: by 10.66.163.168 with SMTP id yj8mr1999666pab.50.1362714560025;\n        Thu, 07 Mar 2013 19:49:20 -0800 (PST)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from [10.0.1.3] (host-69-146-94-113.lar-wy.client.bresnan.net. [69.146.94.113])\n        by mx.google.com with ESMTPS id in5sm3938811pbc.20.2013.03.07.19.49.17\n        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);\n        Thu, 07 Mar 2013 19:49:18 -0800 (PST)\r\nContent-Type: multipart/alternative; boundary=&quot;Apple-Mail=_A0B19A2D-0C01-4290-A65B-192D3A57BF3E&quot;\r\nMessage-Id: &lt;9ABE67FC-FA10-4503-AB66-C7C441C73A9D@...&gt;\r\nMime-Version: 1.0 (Mac OS X Mail 6.2 &#92;(1499&#92;))\r\nDate: Thu, 7 Mar 2013 20:49:25 -0700\r\nReferences: &lt;kgu191+st2i@...&gt;\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;kgu191+st2i@...&gt;\r\nX-Mailer: Apple Mail (2.1499)\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nX-eGroups-From: Jeff Clune &lt;jeffclune@...&gt;\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] New paper on why modules evolve, and how to evolve modular artif\r\nX-Yahoo-Group-Post: member; u=464818732; y=JsA-XsoUL3aozc_Lu6c4nZVUMJCXyTYXeMnztV1CP965kDaKb7Ah\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\n\r\n--Apple-Mail=_A0B19A2D-0C01-4290-A65B-192D3A57BF3E\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/plain;\n\tcharset=windows-1252\r\n\r\nThanks for clarifying your positions Ken. I believe we have reached the poi=\r\nnt at which reasonable minds can respectably disagree, as you put it. Were =\r\nI to respond, I believe I would mostly repeat myself as the ideas I believe=\r\n answer your comments and questions I&#39;ve already expressed earlier in this =\r\nthread. That usually is an indication of coming to an agreement, even if th=\r\ne agreement is to disagree. :-) \n\nThat said, I&#39;ll summarize my main points:=\r\n I do think nature has default fitness penalties, and all we have done is c=\r\nhange the default to one that encourages modularity and evolvability. As su=\r\nch, I don&#39;t think we&#39;re subject to general attacks on fitness pressures, be=\r\ncause by default there are fitness pressures (e.g. a cost for materials), w=\r\ne just change them to be better with respect to modularity and evolvability=\r\n. Moreover, I think a connection cost encourages modularity in a way simila=\r\nr to how things work in nature, even if nature more resembles a combination=\r\n of performance and costs into a single objective instead of multi-objectiv=\r\ne algorithms. Our work is not dependent on an MOEA: we suspect a connection=\r\n cost will encourage modularity in general irrespective of the details of t=\r\nhe algorithm. As I&#39;ve mentioned, I think nuance and subtlety are possible w=\r\nith a connection cost because nature can pay for more connectivity via perf=\r\normance gains, allowing all sorts of exceptions to the general rule. I stil=\r\nl don&#39;t see how an initial encoding bias will have any long-term effect on =\r\nevolution, so the only hope for canalization and helpful encoding biases is=\r\n via fitness. I thus believe that fitness penalties are a great way to enco=\r\nurage good encodings via canalization. For example, we know that default pe=\r\nnalties exist (such as a default tendency to NOT produce modularity, which =\r\nhas been empirically observed in our systems repeatedly), and nature will n=\r\not explore those areas unless the fitness function is changed (just as natu=\r\nre never explored certain classes of extremely inefficient metabolisms, or =\r\nbirds with bones made of lead). Ultimately, since the effect of your initia=\r\nl encoding bias hint will vanish over millennia, your argument amounts to s=\r\naying that we should not try to bias evolution at all. But this whole conve=\r\nrsation was on the best way to bias evolution, so maybe your position is th=\r\nat we shouldn&#39;t be biasing evolution at all. That&#39;s fine if we don&#39;t have a=\r\nny default fitness penalties in the environment that will hurt us, but we h=\r\nave no guarantee of that. As you point out, Nature has done impressive thin=\r\ngs, but it also had a very different environment than the environment in ou=\r\nr setups so far. What we&#39;ve shown in this paper is that some things that we=\r\n originally thought just happened to exist in nature, but were unnecessary =\r\nvis a vis evolvability (such as a cost for materials) actually may play a r=\r\nole in the evolution of modularity and evolvability. I think it is worthwhi=\r\nle to investigate what else we may have skipped from the natural world that=\r\n may be an important driver of evolvability and, ultimately, open-ended evo=\r\nlution.\n\nA final point: your criticism that &#39;nothing we learn matters if we=\r\n don&#39;t have an open-ended algorithm&#39; discounts all the work that has been d=\r\none to date in computational evolutionary biology, not just our paper. You =\r\nmay be right that all of our lessons are worthless once we figure out an op=\r\nen-ended evolutionary algorithm, but I doubt that will be the case. I think=\r\n a lot of interesting, worthwhile understandings have been gained by simula=\r\nted evolution, and that much of that work will prove informative even if th=\r\ne underlying algorithms change. \n\n\nBest regards,\nJeff Clune\n\nAssistant Prof=\r\nessor\nComputer Science\nUniversity of Wyoming\njeffclune@...\njeffclune.c=\r\nom\n\nOn Mar 2, 2013, at 4:16 PM, Ken &lt;kstanley@...&gt; wrote:\n\n&gt; \n&gt; \n=\r\n&gt; Hi Jeff, Stef, and Martin, I hope you don&#39;t mind since all of you address=\r\ned me if I try to reply to all of you at once to keep the thread (and my br=\r\nain) from branching in three directions. Many of your points follow a simil=\r\nar theme so I think it makes sense to respond collectively. This response i=\r\ns practically an article, but oh well, it&#39;s nice to get the ideas down even=\r\n if it&#39;s a bit too long (it just shows you are asking me great questions th=\r\nat are challenging).\n&gt; \n&gt; Martin offers a good unifying question: &quot;My quest=\r\nion to Ken would be here: what is the additional ingredient that makes a\n&gt; =\r\nbias in the encoding better / more plausible than *any* implementation of t=\r\nhe bias in the fitness function?&quot;\n&gt; \n&gt; After some thought, I believe one of=\r\n the difficulties in this discussion is that we often conflate artificial E=\r\nC-style fitness-based experiments with open-ended scenarios when these are =\r\nentirely different situations (I take blame myself as well for this tendenc=\r\ny). That is, when we talk about something being &quot;better&quot; or &quot;solving&quot; a pro=\r\nblem, we are often talking about artificial and unnatural experimental setu=\r\nps that have little relationship to open-ended evolutionary scenarios like =\r\nnature. \n&gt; \n&gt; Why does that matter? It matters because in discussions that =\r\ntry to dovetail engineering-oriented mechanisms (like a connectivity penalt=\r\ny) with explanations of what happened in nature (such as the emergence of m=\r\nodular connectivity), it cannot simply be ignored that nature in fact is fi=\r\nrst and foremost an open-ended evolutionary system, and that that open-ende=\r\nd dynamic is a significant factor in the explanation of its products. What =\r\nthat means to me is that if you think your proposed mechanism actually *exp=\r\nlains* something that happened in nature, then it is essential that the exp=\r\nlanation speaks to the question of how the particular mechanism you are adv=\r\nancing combined historically with the open-ended evolutionary dynamics in n=\r\nature to produce the result you expect.\n&gt; \n&gt; But because we conflate very c=\r\nlosed-ended artificial scenarios with monumentally open-ended searches like=\r\n nature, it leads to a lot of dangerous inferences. So ideas that would mak=\r\ne sense in one context end up sounding reasonable when they don&#39;t really ma=\r\nke any sense in the other context. The difficulty of squaring fitness-press=\r\nure objectives with nature is more serious when you consider it in this per=\r\nspective. (Note that I am defining &quot;fitness pressure&quot; as selection based on=\r\n relative performance to other organisms on a measure of some property that=\r\n varies over a range of possible values, such as degree of connectivity.)\n&gt;=\r\n \n&gt; The problem is that fitness pressures that preserve a degenerate niche =\r\nfor eternity are definitively not like nature, so whether they work or not,=\r\n or whether I am somehow indicting them or not, should not be the issue. Th=\r\ne issue should be that we should be worried that nature does not use a mech=\r\nanism even remotely like that yet still achieves the &quot;same&quot; result (i.e. be=\r\nautiful variations of pseudo-modular design). If you are advancing the hypo=\r\nthesis that this kind of constant &quot;pressure&quot; is somehow essential to the em=\r\nergence of modularity in nature, then you must somehow explain why you need=\r\ned to use a setup with these bizarre and unnatural side effects (like etern=\r\nal degenerate niches) instead of whatever nature actually supposedly does u=\r\nse.\n&gt; \n&gt; And the fact that you cannot come up with anything similar to what=\r\n nature does, i.e. something that does not involve creating such a deadweig=\r\nht pocket, reasonably may suggest that your hypothesis about nature could b=\r\ne wrong. That is, it may not be this endless &quot;fitness pressure&quot; after all t=\r\nhat explains what is happening there, because fitness pressure in general i=\r\nn EC is almost always creating some kind of unintended deadweight niche.\n&gt; =\r\n\n&gt; I think it is particularly fascinating that in fact nature obtains not r=\r\neally the same result, but a far more awesome result (in terms of modularit=\r\ny or anything else), without such an ad hoc mechanism. \n&gt; If you think abou=\r\nt it, as long as you insist on cheering for fitness pressure, it prevents y=\r\nou from asking how this could be - how is it possible that you can get thes=\r\ne kinds of results without such an unnatural side effect?\n&gt; \n&gt; I need to em=\r\nphasize here the difference between being a better engineering mechanism an=\r\nd a better explanation. I am focusing now primarily on the explanatory powe=\r\nr of the proposed mechanism. But because nature is so much more accomplishe=\r\nd than anything artificial, the explanatory gap here implies a dangerous po=\r\ntential to overlook what will ultimately amount also to a major engineering=\r\n gap as well. There is no evidence that anything except nature in its open-=\r\nended way can create anything like the connectivity of natural brains.\n&gt; \n&gt;=\r\n Furthermore, it is always important to acknowledge nuance and subtlety in =\r\nnature, which has not really been acknowledged yet in this conversation. Na=\r\nture is almost never all one way. So it is misleading and potentially confu=\r\nsing to talk about brains as simply modular or not. The recent discussion o=\r\nn the Connectionists list, where scientists have been giving all kinds of s=\r\nubtle and conflicting perspectives on modularity in natural brains in respo=\r\nnse to Jeff and JBM&#39;s article, echoes this nuance. The beauty of the human =\r\nbrain to me is not that it is modular, but that it is modular to an extent,=\r\n but not entirely so, and what modularity there is is hard to pin down. Thi=\r\ns kind of nuance is not to me a mere footnote to the achievement of nature,=\r\n but the central point of it: what nature achieves in spades is nuance. \n&gt; =\r\n\n&gt; And the idea of a constant pressure of any kind is directly in conflict =\r\nwith the achievement of nuance, because nuance is a delicate balancing act =\r\nthat is easily tipped off its perch if constant pressure in *any* direction=\r\n is applied without relief. Jeff is concerned with short-term versus long-t=\r\nerm issues (which isn&#39;t really as clearly defined in an open-ended context)=\r\n, but even if we honor that concern, it is potentially na=EFve to believe t=\r\nhat pressure in either direction from the start, or even an encoding bias i=\r\nn either direction from the start, is somehow going to directly align with =\r\nthe level of nuance observed millions of years in the future. However, whil=\r\ne fitness pressure is eternal, encoding bias is malleable, so pushing in th=\r\ne &quot;right&quot; direction from the start is not essential for encoding. It&#39;s more=\r\n like a hint to get you started, whereas fitness pressure is more like a gu=\r\nn forever pointed at your back.\n&gt; \n&gt; For example, who is to say that we sho=\r\nuld not have the opposite short-term worry as Jeff does =96 he worries that=\r\n an encoding bias towards low connectivity &quot;might evolve away because of fi=\r\ntness pressure,&quot; but can&#39;t we just as easily worry about *too much* modular=\r\nity? In that case, Jeff&#39;s evil twin &quot;opposite-Jeff&quot; might be worried that a=\r\nn initial encoding bias towards *high* connectivity might evolve away. It i=\r\ns not clear nor established fact (see Connectionists) that the exact form o=\r\nf the final &quot;solution&quot; is particularly modular or non-modular. What it is, =\r\nis subtle and somewhere in the middle. So none of this kind of panicking ab=\r\nout what nature &quot;needs&quot; to harass it into such an astronomically complex fu=\r\nture configuration makes much sense. We cannot say definitively the extent =\r\nto which the final structure is &quot;closer&quot; to modular or non-modular, whateve=\r\nr that even means. Fortunately, an encoding that begins with a bias towards=\r\n modularity can tone it down as needed, or ramp it up even more.\n&gt; \n&gt; Yet J=\r\neff also worries about about the radiation of evolutionary lineages being b=\r\nlocked because of implicit penalties: He says, &quot;You assume that evolution w=\r\nill branch out and explore all these options even in the face of fitness pe=\r\nnalties for that exploration. But that is not how evolution works.&quot;\n&gt; \n&gt; Bu=\r\nt branching out and exploring many (not necessarily all of course) of the o=\r\nptions is the only way that natural evolution works. That&#39;s what open-ended=\r\nness is (unless you don&#39;t believe natural evolution to be open-ended). The =\r\ntree of life is ever-branching. The worry about &quot;fitness penalties&quot; here is=\r\n a red herring because it originates from closed-ended artificial EC experi=\r\nments where you can end up on the wrong path. But nature does not have any =\r\nsingle &quot;fitness penalty&quot; or &quot;right path&quot; throughout its run because the lan=\r\ndscape is always changing as it branches and branches. For example, before =\r\ntrees, being an extremely tall herbivore would incur a fitness penalty, but=\r\n after trees giraffes were perfectly viable. The penalty is not consistent.=\r\n\n&gt; \n&gt; More generally, how can there be what you call a &quot;default fitness pen=\r\nalty&quot; if there is no final goal? Penalty with respect to what? Keep in mind=\r\n here that the origin of pseudo-modular organization in nature likely preda=\r\ntes the emergence even of neurons. The first neural structures piggy-backed=\r\n on previously evolved organizational structure that likely influenced the =\r\nsubtle pseudo-modularity of connectivity from the start for reasons entirel=\r\ny unrelated to connection cost because these organizational conventions evo=\r\nlved long before neurons even existed: the bias in the encoding was in part=\r\n already there.\n&gt; \n&gt; Which brings me back to the origin of all such convent=\r\nions - canalization - which is the key here. Stephane talks about a bias th=\r\nat exists &quot;all along&quot; in evolution, but ultimately the ability to *change* =\r\nbias eclipses choosing one up front. Again, in the context of artificial sc=\r\nenarios, it&#39;s a good engineering hack to force in some kind of bias into th=\r\ne encoding or into fitness that you expect to control things for a moderate=\r\n number of generations. But in nature the scope is so vast that it can&#39;t be=\r\n the final word; it&#39;s only the initial hint. While that hint can help, natu=\r\nre in the long term needs to choose and commit to its own biases, and to sl=\r\nither out of them from time to time, and only encoding offers that potentia=\r\nl. Canalization is the way nature can make long-term (though not necessaril=\r\ny permanent) commitments. It&#39;s how conventions are established in specific =\r\nlineages.\n&gt; \n&gt; In a genuine open-ended scenario like nature, modularity wil=\r\nl emerge and proliferate over vast stretches of time only if modularity lea=\r\nds to more species emerging. Of course, the species we observe at the end a=\r\nre the consequence of organizational principles that supported generating m=\r\nany species (which is almost tautological). So it need not relate to being =\r\nbetter or worse, or &quot;solving&quot; anything. It has to do with open-ended dynami=\r\ncs. Air will escape a hole in a balloon if you wait long enough. If that ho=\r\nle leads to a whole other world, you will eventually see that other world. =\r\nModularity, to the extent it actually exists in nature, has served as such =\r\na hole. But the only way such a hole can be exploited, the only way you can=\r\n keep focused on that area, is if it can be canalized. An encoding that can=\r\n be canalized allows you to maintain the subtle convention that is responsi=\r\nble for spreading diversity. \n&gt; \n&gt; Stef nevertheless reminds me that &quot;selec=\r\ntion pressure has strong impact,&quot; and I entirely agree of course. But there=\r\n are two very different classes of selection pressure. One is about pushing=\r\n you towards the new, and the other is about forcing you to commit to the o=\r\nld. There are many ways to push towards the new, and novelty search is just=\r\n one. In contrast, these things we call &quot;fitness pressures&quot; (whether part o=\r\nf a MOEA or not) are the opposite =96 they are toxic strait jackets applied=\r\n for eternity. They presume that we know what we need with no nuance whatso=\r\never eons before anything remotely related has appeared. Again, in engineer=\r\ning, fair enough =96 it can work. But it is not an *explanation* of the pro=\r\nducts of open-ended evolution in nature, and likely is not a good way to pr=\r\noduce open-endedness artificially either. \n&gt; \n&gt; So the only escape I see he=\r\nre from my argument is if you can argue somehow that you can do all these a=\r\nmazing things *without* open-ended evolution. Then all your pressures and c=\r\nonstraints might make sense. But I don&#39;t think you can argue that, which, t=\r\no finally circle back to Martin&#39;s broad question, is why encoding is ultima=\r\ntely superior. A canalizeable encoding is the perfect partner for an open-e=\r\nnded process. But it is not (as Martin puts it) because it makes a particul=\r\nar &quot;bias in the encoding better.&quot; Rather, it is because encoding lets evolu=\r\ntion delicately modify its own biases on the fly and explore all of them in=\r\n parallel. That is, the ability to change, the ability to flexible, to comm=\r\nit but to uncommit in increments of subtlety, to radiate diversity while st=\r\nill committing to certain biases in certain chains, is the power that made =\r\neverything happen. Any forced competition, any constant bias, any eternal r=\r\nelative judgment, which are all things that constant fitness pressure offer=\r\ns, will diminish that flexibility. It will not necessarily destroy the open=\r\n-ended process, but it will reduce its power and ultimately therefore canno=\r\nt explain or account for it.\n&gt; \n&gt; Best,\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogrou=\r\nps.com, &quot;martin_pyka&quot; wrote:\n&gt; &gt;\n&gt; &gt; I just would like to point out that, i=\r\nn my opinion, part of the disagreement between you and Jeff and Ken comes f=\r\nrom the fact that Ken somehow made the statement &quot;it is better to implement=\r\n the bias in the encoding than in the fitness function&quot; but in actual fact =\r\nargues for a specific type of implementation in the encoding.\n&gt; &gt; \n&gt; &gt; Thus=\r\n, I thing the discussion should not center around the general question whet=\r\nher a bias should be incorporated in the fitness or in the encoding because=\r\n in both areas there are better and worse ways to do it. The question is mo=\r\nre, why a specific implementation (that Ken has obviously in mind, my impre=\r\nssion was he thought about approaches similar to LEO) is better than anothe=\r\nr.\n&gt; &gt; \n&gt; &gt; My question to Ken would be here: what is the additional ingred=\r\nient that makes a bias in the encoding better / more plausible than *any* i=\r\nmplementation of the bias in the fitness function?\n&gt; &gt;\n&gt; \n&gt; \n\n\r\n--Apple-Mail=_A0B19A2D-0C01-4290-A65B-192D3A57BF3E\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/html;\n\tcharset=windows-1252\r\n\r\n&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=3D&quot;Content-Type&quot; content=3D&quot;text/html charset=\r\n=3Dwindows-1252&quot;&gt;&lt;/head&gt;&lt;body style=3D&quot;word-wrap: break-word; -webkit-nbsp-=\r\nmode: space; -webkit-line-break: after-white-space; ; font-family: &#39;Times&#39;;=\r\n font-size: 14px; color: rgb( 0,  0,  0); &quot;&gt;&lt;span style=3D&quot;font-family: &#39;Ti=\r\nmes&#39;; font-size: 14px; color: rgb( 0,  0,  0)&quot;&gt;Thanks for clarifying your p=\r\nositions Ken. I believe we have reached the point at which reasonable minds=\r\n can respectably&nbsp;disagree, as you put it. Were I to respond, I believe=\r\n I would mostly repeat myself as the ideas I believe answer your&nbsp;comme=\r\nnts and questions I&#39;ve already expressed earlier in this thread. That usual=\r\nly is an indication of coming to an&nbsp;agreement, even if the agreement i=\r\ns to disagree. :-)&nbsp;&lt;br&gt;&lt;br&gt;That said, I&#39;ll summarize my main points: I=\r\n do think nature has default fitness penalties, and all we have done is cha=\r\nnge the&nbsp;default to one that encourages modularity and evolvability. As=\r\n such, I don&#39;t think we&#39;re subject to general attacks on fitness&nbsp;press=\r\nures, because by default there are fitness pressures (e.g. a cost for mater=\r\nials), we just change them to be better with respect to modularity and&nbsp=\r\n;evolvability. Moreover, I think a connection cost encourages modularity in=\r\n a way similar to how things work in nature,&nbsp;even if nature more resem=\r\nbles a combination of performance and costs into a single objective instead=\r\n of multi-objective&nbsp;algorithms. Our work is not dependent on an MOEA: =\r\nwe suspect a connection cost will encourage modularity in general&nbsp;irre=\r\nspective of the details of the algorithm. As I&#39;ve mentioned, I think nuance=\r\n and subtlety are possible with a connection&nbsp;cost because nature can p=\r\nay for more connectivity via performance gains, allowing all sorts of excep=\r\ntions to the general&nbsp;rule. I still don&#39;t see how an initial encoding b=\r\nias will have any long-term effect on evolution, so the only hope for&nbsp;=\r\ncanalization and helpful encoding biases is via fitness. I thus believe tha=\r\nt fitness penalties are a great way to encourage&nbsp;good encodings via ca=\r\nnalization. For example, we know that default penalties exist (such as a de=\r\nfault tendency to NOT&nbsp;produce modularity, which has been empirically o=\r\nbserved in our systems repeatedly), and nature will not explore those&nbsp;=\r\nareas unless the fitness function is changed (just as nature never explored=\r\n certain classes of extremely inefficient&nbsp;metabolisms, or birds with b=\r\nones made of lead). Ultimately, since the effect of your initial encoding b=\r\nias hint will vanish&nbsp;over millennia, your argument amounts to saying t=\r\nhat we should not try to bias evolution at all. But this whole conversation=\r\n&nbsp;was on the best way to bias evolution, so maybe your position is that=\r\n we shouldn&#39;t be biasing evolution at all. That&#39;s fine if&nbsp;we don&#39;t hav=\r\ne any default fitness penalties in the environment that will hurt us, but w=\r\ne have no guarantee of that. As you&nbsp;point out, Nature has done impress=\r\nive things, but it also had a very different environment than the environme=\r\nnt in our setups so far. What we&#39;ve shown in this paper&nbsp;is that some t=\r\nhings that we originally thought just happened to exist in nature, but were=\r\n unnecessary &lt;i&gt;vis a vis&lt;/i&gt; evolvability (such&nbsp;as a cost for materia=\r\nls) actually may play a role in the evolution of modularity and evolvabilit=\r\ny. I think it is worthwhile to&nbsp;investigate what else we may have skipp=\r\ned from the natural world that may be an important driver of evolvability a=\r\nnd,&nbsp;ultimately, open-ended evolution.&lt;br&gt;&lt;br&gt;A final point: your criti=\r\ncism that &#39;nothing we learn matters if we don&#39;t have an open-ended algorith=\r\nm&#39; discounts all the work that has been done to date in computational evolu=\r\ntionary biology, not just our paper. You may be right that all of our lesso=\r\nns are worthless once we figure out an open-ended evolutionary algorithm, b=\r\nut I doubt that will be the case. I think a lot of interesting, worthwhile =\r\nunderstandings have been gained by simulated evolution, and that much of th=\r\nat work will prove informative even if the underlying algorithms change.&nb=\r\nsp;&lt;br&gt;&lt;div apple-content-edited=3D&quot;true&quot;&gt;\n&lt;div style=3D&quot;orphans: 2; text-a=\r\nlign: -webkit-auto; text-indent: 0px; widows: 2; word-wrap: break-word; -we=\r\nbkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div style=\r\n=3D&quot;orphans: 2; text-align: -webkit-auto; text-indent: 0px; widows: 2; word=\r\n-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-whit=\r\ne-space; &quot;&gt;&lt;div style=3D&quot;orphans: 2; text-align: -webkit-auto; text-indent:=\r\n 0px; widows: 2; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-l=\r\nine-break: after-white-space; &quot;&gt;&lt;div style=3D&quot;orphans: 2; text-align: -webk=\r\nit-auto; text-indent: 0px; widows: 2; word-wrap: break-word; -webkit-nbsp-m=\r\node: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div style=3D&quot;orphans:=\r\n 2; text-align: -webkit-auto; text-indent: 0px; widows: 2; word-wrap: break=\r\n-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;=\r\ndiv style=3D&quot;orphans: 2; text-align: -webkit-auto; text-indent: 0px; widows=\r\n: 2; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: a=\r\nfter-white-space; &quot;&gt;&lt;div style=3D&quot;orphans: 2; text-align: -webkit-auto; tex=\r\nt-indent: 0px; widows: 2; word-wrap: break-word; -webkit-nbsp-mode: space; =\r\n-webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; s=\r\ntyle=3D&quot;border-collapse: separate; border-spacing: 0px; &quot;&gt;&lt;div style=3D&quot;wor=\r\nd-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-whi=\r\nte-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;border-collapse: sepa=\r\nrate; orphans: 2; text-align: -webkit-auto; text-indent: 0px; widows: 2; bo=\r\nrder-spacing: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode=\r\n: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-styl=\r\ne-span&quot; style=3D&quot;border-collapse: separate; orphans: 2; text-align: -webkit=\r\n-auto; text-indent: 0px; widows: 2; border-spacing: 0px; &quot;&gt;&lt;div style=3D&quot;wo=\r\nrd-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-wh=\r\nite-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;border-collapse: sep=\r\narate; orphans: 2; text-align: -webkit-auto; text-indent: 0px; widows: 2; b=\r\norder-spacing: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mod=\r\ne: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;br class=3D&quot;Apple-inter=\r\nchange-newline&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: T=\r\nimes; font-size: 14px; font-style: normal; font-variant: normal; font-weigh=\r\nt: normal; letter-spacing: normal; line-height: normal; text-transform: non=\r\ne; white-space: normal; word-spacing: 0px; -webkit-text-decorations-in-effe=\r\nct: none; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; w=\r\nord-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-w=\r\nhite-space; &quot;&gt;Best regards,&lt;br&gt;&lt;font class=3D&quot;Apple-style-span&quot; color=3D&quot;#0=\r\na5d19&quot;&gt;&lt;b&gt;Jeff Clune&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;br&gt;Assistant Professor&lt;br&gt;Computer Scie=\r\nnce&lt;/div&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-size: =\r\n14px; font-style: normal; font-variant: normal; font-weight: normal; letter=\r\n-spacing: normal; line-height: normal; text-transform: none; white-space: n=\r\normal; word-spacing: 0px; -webkit-text-decorations-in-effect: none; -webkit=\r\n-text-size-adjust: auto; -webkit-text-stroke-width: 0px; word-wrap: break-w=\r\nord; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;Uni=\r\nversity of Wyoming&lt;br&gt;&lt;a href=3D&quot;mailto:jeffclune@...&quot;&gt;jeffclune@uwyo.=\r\nedu&lt;/a&gt;&lt;br&gt;jeffclune.com&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span=\r\n&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;/div&gt;\n&lt;br&gt;&lt;div&gt;&lt;div&gt;On Mar 2, =\r\n2013, at 4:16 PM, Ken &lt;&lt;a href=3D&quot;mailto:kstanley@...&quot;&gt;kstanle=\r\ny@...&lt;/a&gt;&gt; wrote:&lt;/div&gt;&lt;br class=3D&quot;Apple-interchange-newline&quot;=\r\n&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;div style=3D&quot;background-color: #f=\r\nff;&quot;&gt;\n&lt;span style=3D&quot;display:none&quot;&gt;&nbsp;&lt;/span&gt;\n\n\n\n    &lt;div id=3D&quot;ygrp-tex=\r\nt&quot;&gt;&lt;p&gt;&lt;br&gt;\n&lt;br&gt;\nHi Jeff, Stef, and Martin, I hope you don&#39;t mind since all =\r\nof you addressed me if I try to reply to all of you at once to keep the thr=\r\nead (and my brain) from branching in three directions.  Many of your points=\r\n follow a similar theme so I think it makes sense to respond collectively. =\r\n This response is practically an article, but oh well, it&#39;s nice to get the=\r\n ideas down even if it&#39;s a bit too long (it just shows you are asking me gr=\r\neat questions that are challenging).&lt;br&gt;\n&lt;br&gt;\nMartin offers a good unifying=\r\n question: &quot;My question to Ken would be here: what is the additional ingred=\r\nient that makes a&lt;br&gt;\nbias in the encoding better / more plausible than *an=\r\ny* implementation of the bias in the fitness function?&quot;&lt;br&gt;\n&lt;br&gt;\nAfter some=\r\n thought, I believe one of the difficulties in this discussion is that we o=\r\nften conflate artificial EC-style fitness-based experiments with open-ended=\r\n scenarios when these are entirely different situations (I take blame mysel=\r\nf as well for this tendency).  That is, when we talk about something being =\r\n&quot;better&quot; or &quot;solving&quot; a problem, we are often talking about artificial and =\r\nunnatural experimental setups that have little relationship to open-ended e=\r\nvolutionary scenarios like nature.  &lt;br&gt;\n&lt;br&gt;\nWhy does that matter?  It mat=\r\nters because in discussions that try to dovetail engineering-oriented mecha=\r\nnisms (like a connectivity penalty) with explanations of what happened in n=\r\nature (such as the emergence of modular connectivity), it cannot simply be =\r\nignored that nature in fact is first and foremost an open-ended evolutionar=\r\ny system, and that that open-ended dynamic is a significant factor in the e=\r\nxplanation of its products.   What that means to me is that if you think yo=\r\nur proposed mechanism actually *explains* something that happened in nature=\r\n, then it is essential that the explanation speaks to the question of how t=\r\nhe particular mechanism you are advancing combined historically with the op=\r\nen-ended evolutionary dynamics in nature to produce the result you expect.&lt;=\r\nbr&gt;\n&lt;br&gt;\nBut because we conflate very closed-ended artificial scenarios wit=\r\nh monumentally open-ended searches like nature, it leads to a lot of danger=\r\nous inferences.   So ideas that would make sense in one context end up soun=\r\nding reasonable when they don&#39;t really make any sense in the other context.=\r\n  The difficulty of squaring fitness-pressure objectives with nature is mor=\r\ne serious when you consider it in this perspective.  (Note that I am defini=\r\nng &quot;fitness pressure&quot; as selection based on relative performance to other o=\r\nrganisms on a measure of some property that varies over a range of possible=\r\n values, such as degree of connectivity.)&lt;br&gt;\n&lt;br&gt;\nThe problem is that fitn=\r\ness pressures that preserve a degenerate niche for eternity are definitivel=\r\ny not like nature, so whether they work or not, or whether I am somehow ind=\r\nicting them or not, should not be the issue.  The issue should be that we s=\r\nhould be worried that nature does not use a mechanism even remotely like th=\r\nat yet still achieves the &quot;same&quot; result (i.e. beautiful variations of pseud=\r\no-modular design).  If you are advancing the hypothesis that this kind of c=\r\nonstant &quot;pressure&quot; is somehow essential to the emergence of modularity in n=\r\nature, then you must somehow explain why you needed to use a setup with the=\r\nse bizarre and unnatural side effects (like eternal degenerate niches) inst=\r\nead of whatever nature actually supposedly does use.&lt;br&gt;\n&lt;br&gt;\nAnd the fact =\r\nthat you cannot come up with anything similar to what nature does, i.e. som=\r\nething that does not involve creating such a deadweight pocket, reasonably =\r\nmay suggest that your hypothesis about nature could be wrong.  That is, it =\r\nmay not be this endless &quot;fitness pressure&quot; after all that explains what is =\r\nhappening there, because fitness pressure in general in EC is almost always=\r\n creating some kind of unintended deadweight niche.&lt;br&gt;\n&lt;br&gt;\nI think it is =\r\nparticularly fascinating that in fact nature obtains not really the same re=\r\nsult, but a far more awesome result (in terms of modularity or anything els=\r\ne), without such an ad hoc mechanism. &lt;br&gt;\nIf you think about it, as long a=\r\ns you insist on cheering for fitness pressure, it prevents you from asking =\r\nhow this could be - how is it possible that you can get these kinds of resu=\r\nlts without such an unnatural side effect?&lt;br&gt;\n&lt;br&gt;\nI need to emphasize her=\r\ne the difference between being a better engineering mechanism and a better =\r\nexplanation.  I am focusing now primarily on the explanatory power of the p=\r\nroposed mechanism.  But because nature is so much more accomplished than an=\r\nything artificial, the explanatory gap here implies a dangerous potential t=\r\no overlook what will ultimately amount also to a major engineering gap as w=\r\nell.  There is no evidence that anything except nature in its open-ended wa=\r\ny can create anything like the connectivity of natural brains.&lt;br&gt;\n&lt;br&gt;\nFur=\r\nthermore, it is always important to acknowledge nuance and subtlety in natu=\r\nre, which has not really been acknowledged yet in this conversation.  Natur=\r\ne is almost never all one way.  So it is misleading and potentially confusi=\r\nng to talk about brains as simply modular or not.  The recent discussion on=\r\n the Connectionists list, where scientists have been giving all kinds of su=\r\nbtle and conflicting perspectives on modularity in natural brains in respon=\r\nse to Jeff and JBM&#39;s article,  echoes this nuance.   The beauty of the huma=\r\nn brain to me is not that it is modular, but that it is modular to an exten=\r\nt, but not entirely so, and what modularity there is is hard to pin down.  =\r\nThis kind of nuance is not to me a mere footnote to the achievement of natu=\r\nre, but the central point of it:  what nature achieves in spades is nuance.=\r\n &lt;br&gt;\n&lt;br&gt;\nAnd the idea of a constant pressure of any kind is directly in c=\r\nonflict with the achievement of nuance, because nuance is a delicate balanc=\r\ning act that is easily tipped off its perch if constant pressure in *any* d=\r\nirection is applied without relief.  Jeff is concerned with short-term vers=\r\nus long-term issues (which isn&#39;t really as clearly defined in an open-ended=\r\n context), but even if we honor that concern, it is potentially na=EFve to =\r\nbelieve that pressure in either direction from the start, or even an encodi=\r\nng bias in either direction from the start, is somehow going to directly al=\r\nign with the level of nuance observed millions of years in the future.  How=\r\never, while fitness pressure is eternal, encoding bias is malleable, so pus=\r\nhing in the &quot;right&quot; direction from the start is not essential for encoding.=\r\n  It&#39;s more like a hint to get you started, whereas fitness pressure is mor=\r\ne like a gun forever pointed at your back.&lt;br&gt;\n&lt;br&gt;\nFor example, who is to =\r\nsay that we should not have the opposite short-term worry as Jeff does =96 =\r\nhe worries that an encoding bias towards low connectivity &quot;might evolve awa=\r\ny because of fitness pressure,&quot; but can&#39;t we just as easily worry about *to=\r\no much* modularity?  In that case, Jeff&#39;s evil twin &quot;opposite-Jeff&quot; might b=\r\ne worried that an initial encoding bias towards *high* connectivity might e=\r\nvolve away.  It is not clear nor established fact (see Connectionists) that=\r\n the exact form of the final &quot;solution&quot; is particularly modular or non-modu=\r\nlar.  What it is, is subtle and somewhere in the middle.  So none of this k=\r\nind of panicking about what nature &quot;needs&quot; to harass it into such an astron=\r\nomically complex future configuration makes much sense.  We cannot say defi=\r\nnitively the extent to which the final structure is &quot;closer&quot; to modular or =\r\nnon-modular, whatever that even means.  Fortunately, an encoding that begin=\r\ns with a bias towards modularity can tone it down as needed, or ramp it up =\r\neven more.&lt;br&gt;\n&lt;br&gt;\nYet Jeff also worries about about the radiation of evol=\r\nutionary lineages being blocked because of implicit penalties: He says, &quot;Yo=\r\nu assume that evolution will branch out and explore all these options even =\r\nin the face of fitness penalties for that exploration. But that is not how =\r\nevolution works.&quot;&lt;br&gt;\n&lt;br&gt;\nBut branching out and exploring many (not necess=\r\narily all of course) of the options is the only way that natural evolution =\r\nworks.  That&#39;s what open-endedness is (unless you don&#39;t believe natural evo=\r\nlution to be open-ended).  The tree of life is ever-branching.  The worry a=\r\nbout &quot;fitness penalties&quot; here is a red herring because it originates from c=\r\nlosed-ended artificial EC experiments where you can end up on the wrong pat=\r\nh.  But nature does not have any single &quot;fitness penalty&quot; or &quot;right path&quot; t=\r\nhroughout its run because the landscape is always changing as it branches a=\r\nnd branches.  For example, before trees, being an extremely tall herbivore =\r\nwould incur a fitness penalty, but after trees giraffes were perfectly viab=\r\nle.  The penalty is not consistent.&lt;br&gt;\n&lt;br&gt;\nMore generally, how can there =\r\nbe what you call a &quot;default fitness penalty&quot; if there is no final goal?  Pe=\r\nnalty with respect to what?  Keep in mind here that the origin of pseudo-mo=\r\ndular organization in nature likely predates the emergence even of neurons.=\r\n  The first neural structures piggy-backed on previously evolved organizati=\r\nonal structure that likely influenced the subtle pseudo-modularity of conne=\r\nctivity from the start for reasons entirely unrelated to connection cost be=\r\ncause these organizational conventions evolved long before neurons even exi=\r\nsted:  the bias in the encoding was in part already there.&lt;br&gt;\n&lt;br&gt;\nWhich b=\r\nrings me back to the origin of all such conventions - canalization - which =\r\nis the key here.   Stephane talks about a bias that exists &quot;all along&quot; in e=\r\nvolution, but ultimately the ability to *change* bias eclipses choosing one=\r\n up front.  Again, in the context of artificial scenarios, it&#39;s a good engi=\r\nneering hack to force in some kind of bias into the encoding or into fitnes=\r\ns that you expect to control things for a moderate number of generations.  =\r\nBut in nature the scope is so vast that it can&#39;t be the final word; it&#39;s on=\r\nly the initial hint.  While that hint can help, nature in the long term nee=\r\nds to choose and commit to its own biases, and to slither out of them from =\r\ntime to time, and only encoding offers that potential.  Canalization is the=\r\n way nature can make long-term (though not necessarily permanent) commitmen=\r\nts.  It&#39;s how conventions are established in specific lineages.&lt;br&gt;\n&lt;br&gt;\nIn=\r\n a genuine open-ended scenario like nature, modularity will emerge and prol=\r\niferate over vast stretches of time only if modularity leads to more specie=\r\ns emerging.  Of course, the species we observe at the end are the consequen=\r\nce of organizational principles that supported generating many species (whi=\r\nch is almost tautological).   So it need not relate to being better or wors=\r\ne, or &quot;solving&quot; anything.  It has to do with open-ended dynamics.  Air will=\r\n escape a hole in a balloon if you wait long enough.  If that hole leads to=\r\n a whole other world, you will eventually see that other world.  Modularity=\r\n, to the extent it actually exists in nature, has served as such a hole.  B=\r\nut the only way such a hole can be exploited, the only way you can keep foc=\r\nused on that area, is if it can be canalized.  An encoding that can be cana=\r\nlized allows you to maintain the subtle convention that is responsible for =\r\nspreading diversity.   &lt;br&gt;\n&lt;br&gt;\nStef nevertheless reminds me that &quot;selecti=\r\non pressure has strong impact,&quot; and I entirely agree of course.  But there =\r\nare two very different classes of selection pressure.  One is about pushing=\r\n you towards the new, and the other is about forcing you to commit to the o=\r\nld.  There are many ways to push towards the new, and novelty search is jus=\r\nt one.  In contrast, these things we call &quot;fitness pressures&quot; (whether part=\r\n of a MOEA or not) are the opposite =96 they are toxic strait jackets appli=\r\ned for eternity.  They presume that we know what we need with no nuance wha=\r\ntsoever eons before anything remotely related has appeared.   Again, in eng=\r\nineering, fair enough =96 it can work.  But it is not an *explanation* of t=\r\nhe products of open-ended evolution in nature, and likely is not a good way=\r\n to produce open-endedness artificially either.  &lt;br&gt;\n&lt;br&gt;\nSo the only esca=\r\npe I see here from my argument is if you can argue somehow that you can do =\r\nall these amazing things *without* open-ended evolution.  Then all your pre=\r\nssures and constraints might make sense.  But I don&#39;t think you can argue t=\r\nhat, which, to finally circle back to Martin&#39;s broad question, is why encod=\r\ning is ultimately superior.  A canalizeable encoding is the perfect partner=\r\n for an open-ended process.  But it is not (as Martin puts it) because it m=\r\nakes a particular &quot;bias in the encoding better.&quot;  Rather, it is because enc=\r\noding lets evolution delicately modify its own biases on the fly and explor=\r\ne all of them in parallel.  That is, the ability to change, the ability to =\r\nflexible, to commit but to uncommit in increments of subtlety, to radiate d=\r\niversity while still committing to certain biases in certain chains, is the=\r\n power that made everything happen.  Any forced competition, any constant b=\r\nias, any eternal relative judgment, which are all things that constant fitn=\r\ness pressure offers, will diminish that flexibility.  It will not necessari=\r\nly destroy the open-ended process, but it will reduce its power and ultimat=\r\nely therefore cannot explain or account for it.&lt;br&gt;\n&lt;br&gt;\nBest,&lt;br&gt;\n&lt;br&gt;\nken=\r\n&lt;br&gt;\n&lt;br&gt;\n--- In &lt;a href=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups=\r\n.com&lt;/a&gt;, &quot;martin_pyka&quot;  wrote:&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; I just would like to poin=\r\nt out that, in my opinion, part of the disagreement between you and Jeff an=\r\nd Ken comes from the fact that Ken somehow made the statement &quot;it is better=\r\n to implement the bias in the encoding than in the fitness function&quot; but in=\r\n actual fact argues for a specific type of implementation in the encoding.&lt;=\r\nbr&gt;\n&gt; &lt;br&gt;\n&gt; Thus, I thing the discussion should not center around th=\r\ne general question whether a bias should be incorporated in the fitness or =\r\nin the encoding because in both areas there are better and worse ways to do=\r\n it. The question is more, why a specific implementation (that Ken has obvi=\r\nously in mind, my impression was he thought about approaches similar to LEO=\r\n) is better than another.&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; My question to Ken would be he=\r\nre: what is the additional ingredient that makes a bias in the encoding bet=\r\nter / more plausible than *any* implementation of the bias in the fitness f=\r\nunction?&lt;br&gt;\n&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n\n&lt;/div&gt;\n\n\n\n&lt;!-- end=\r\n group email --&gt;\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;\n\r\n--Apple-Mail=_A0B19A2D-0C01-4290-A65B-192D3A57BF3E--\r\n\n"}}