{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"jQLrlXFSS_sz3wIaEEietAfb0G3eH9qpmzHnKcdUatHFpAsj1q2xJLUABk_TxZLqLYGWZpBeBPTdpFJXeGFDJYPpssGBfLlveCRzNyO1SUvR","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1210531815","msgId":4043,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwN2Y1NytpNm1AZUdyb3Vwcy5jb20+","inReplyToHeader":"PGcwNzdqcitkYmY1QGVHcm91cHMuY29tPg=="},"prevInTopic":4042,"nextInTopic":4064,"prevInTime":4042,"nextInTime":4044,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"Peter, just to add on to what Joel said, as Joel mentions, we ve been further investigating some of the issues that you raise.  For example, it appears likely","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 42142 invoked from network); 11 May 2008 18:50:17 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m52.grp.scd.yahoo.com with QMQP; 11 May 2008 18:50:17 -0000\r\nX-Received: from unknown (HELO n19.bullet.sp1.yahoo.com) (69.147.64.216)\n  by mta18.grp.scd.yahoo.com with SMTP; 11 May 2008 18:50:16 -0000\r\nX-Received: from [216.252.122.219] by n19.bullet.sp1.yahoo.com with NNFMP; 11 May 2008 18:50:16 -0000\r\nX-Received: from [209.73.164.83] by t4.bullet.sp1.yahoo.com with NNFMP; 11 May 2008 18:50:16 -0000\r\nX-Received: from [66.218.66.80] by t7.bullet.scd.yahoo.com with NNFMP; 11 May 2008 18:50:16 -0000\r\nDate: Sun, 11 May 2008 18:50:15 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g07f57+i6m@...&gt;\r\nIn-Reply-To: &lt;g077jr+dbf5@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=54567749; y=LiHLjc967BFA3OPkGRF3bBclTF3LzRNITZbxgnGRj_GJ8YaIZo0o\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nPeter, just to add on to what Joel said, as Joel mentions, we&#39;ve been\nfurth=\r\ner investigating some of the issues that you raise.  For example,\nit appear=\r\ns likely at least in some cases that the penalty for\nconflating multiple be=\r\nhaviors as a single behavior is not necessarily\nsevere and thus does not ne=\r\ngate the advantage of novelty search over\nfitness-based search.  In other w=\r\nords, it looks like it may be\npossible to perform effective novelty searche=\r\ns with only approximate\nbehavior characterizations that even may throw out =\r\na lot of specific\ninformation about what actually happened.  If that turns =\r\nout to be the\ncase in a lot of domains, of course it would be good news.  W=\r\nhat seems\nto be most important is the *type* of conflation as opposed to th=\r\ne\namount of it.\n\nAnother interesting and subtle issue in novelty search is =\r\nthat I am\nnot sure that the ratio of behaviors to possible genomes (i.e. th=\r\ne\nextent to which many different genetic sequences collapse into a\nsingle b=\r\nehavior) is really the instrumental issue in the search&#39;s\nviability.  Altho=\r\nugh that is a helpful way to look at it, it may\nrather turn out that what i=\r\ns more important is the way that behaviors\nare *connected* through the latt=\r\nice of behavior space.  In other\nwords, even if every genome represents a d=\r\nifferent behavior from every\nother genome, the behavioral characterization =\r\nmay carve out many clear\npaths through novelty space whereas there would be=\r\n no direct paths\nthrough the fitness space, in which case the collapsing is=\r\nsue would\nnot be the primary factor in performance.\n\nYou also made an inter=\r\nesting point about characterizing behavior\nbecoming more difficult in compl=\r\nex domains.  Yet there is one\nintriguing fact to consider:  In any simulati=\r\non, the entire state of\nthe world is always completely represented at some =\r\ntime somewhere in\nthe computer.  In other words, we *do* know everything ab=\r\nout every\nbehavior, assuming we need to know.  I agree that the outputs of =\r\nthe\nneural network are not a good place to measure behavior (that indeed\nwo=\r\nuld turn in to an exhaustive search) but rather the state variables\nthat de=\r\nfine what is happening in the environment, which must exist in\nany simulati=\r\non in their entirety, are the right place to look.  So\ntheoretically, as lo=\r\nng as what is happening is in simulation, all the\nrelevant information at l=\r\neast is available.  Of course, how to measure\ndistances and how to distill =\r\nit down (if that is indeed necessary) are\nstill going to be challenges.\n\nIt=\r\n is interesting to think of the maze domain as a proxy for other\npotential =\r\ndomains.  As you mention, going through a maze involves a\nwhole sequence of=\r\n states rather than just an end state.  Here is\nsomething interesting to po=\r\nnder:  What kind of domain is fundamentally\ndifferent than that?  \n\nThere i=\r\ns clearly a lot left to learn and a very different kind of\nthinking involve=\r\nd in understanding this type of search.\n\nken\n\n--- In neat@yahoogroups.com, =\r\n&quot;joel278&quot; &lt;lehman.154@...&gt; wrote:\n&gt;\n&gt; Hi Peter,\n&gt; \n&gt; I am glad that you fou=\r\nnd this paper thought-provoking, while we were\n&gt; writing it my understandin=\r\ng of EC went through some large changes as\n&gt; well! You bring up many intere=\r\nsting points.\n&gt; \n&gt; I agree that one of the most challenging aspects of appl=\r\nying novelty\n&gt; search is coming up with an effective behavioral characteriz=\r\nation, but\n&gt; for problems where fitness-based search fails, the effort may =\r\nbe worth\n&gt; the payoff of a potentially more powerful search.\n&gt; \n&gt; What you =\r\nsay about our choice of behavioral measure in the maze domain\n&gt; is true, it=\r\n will conflate two navigators that end on the same point\n&gt; but use differen=\r\nt methods of locomotion to get there. And it is\n&gt; interesting that you brou=\r\nght that up, because this question of\n&gt; conflation and choice of behavioral=\r\n measure has been an area we have\n&gt; been further investigating. Unless you =\r\n*completely* characterize\n&gt; behavior (i.e. the maze navigator&#39;s position & =\r\nangle over all time\n&gt; steps), there will be some conflation -- the question=\r\n is whether for\n&gt; many domains there is a level of conflation that is accep=\r\ntable (or\n&gt; even beneficial).\n&gt; \n&gt; Your next point seems to be related, tha=\r\nt to completely specify\n&gt; behavior in a very complex domain may be very har=\r\nd or even infeasible.\n&gt; This is true. However, it may be sufficient to use =\r\na succinct summary\n&gt; of behavior instead of trying to completely specify it=\r\n (e.g. when\n&gt; playing a fixed opponent what is the end configuration of the=\r\n board\n&gt; for a checkers player). Once again, by using a summary of behavior=\r\n\n&gt; instead of a complete specification, conflation is introduced between\n&gt; =\r\ndifferent individuals that have different behaviors, but appear the\n&gt; same =\r\nto the behavioral measure.\n&gt; \n&gt; Behavioral distance is another tricky aspec=\r\nt, and we are looking into\n&gt; ways of doing it in a principled fashion for h=\r\nigher-dimensional\n&gt; behavioral spaces that have multiple types of informati=\r\non (e.g.\n&gt; integrating heading information along with Cartesian location of=\r\n the \n&gt; navigator).\n&gt; \n&gt; Joel\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;petar_cher=\r\nvenski&quot; &lt;petar_chervenski@&gt;\n&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Joal and Ken,\n&gt; &gt; \n&gt; &gt; This=\r\n papers and the results presented there really turned my \n&gt; &gt; understanding=\r\ns for EC upside down. This kind of search is really \n&gt; &gt; innovative concept=\r\n that needs to be explored. But I have several \n&gt; &gt; questions about it. \n&gt; =\r\n&gt; \n&gt; &gt; It is obvious that you have to define what is a network&#39;s behaviour =\r\n\n&gt; &gt; in the task domain and find a way to measure distance between two \n&gt; &gt;=\r\n behaviours. I think this is the hardest part of setting up a novelty \n&gt; &gt; =\r\nsearch. For example, in the task domain of maze navigation, you can \n&gt; &gt; si=\r\nmply say that a robot&#39;s ending point is its behaviour, but I can \n&gt; &gt; argue=\r\n that this is not all, but the way the robot reaches this point \n&gt; &gt; can al=\r\nso be considered a behaviour. For example the robot may go from \n&gt; &gt; point =\r\nA to point B straight forward, but it can reach the same point \n&gt; &gt; by goin=\r\ng forward and spinning. Your model will consider both as the \n&gt; &gt; same beha=\r\nviour while it is obvious the behaviours are different. \n&gt; &gt; \n&gt; &gt; Another t=\r\nhing is that as the task becomes more complex, it is nearly \n&gt; &gt; impossible=\r\n to define what a behaviour *is* and how to measure \n&gt; &gt; distance between t=\r\nhem. Consider the tennis playing robot. Or the \n&gt; &gt; checkers playing networ=\r\nk. How can you define the behaviour then? And \n&gt; &gt; more, how can you measur=\r\ne *distance* between behaviours? It&#39;s like \n&gt; &gt; you have two persons that y=\r\nou know very well and you try to say &quot;the \n&gt; &gt; distance between your behavi=\r\nours is 56.1 units&quot;... I don&#39;t say it is \n&gt; &gt; impossible, it is just too ha=\r\nrd. \n&gt; &gt; \n&gt; &gt; The simplest approach is to track the network&#39;s output patter=\r\nn and \n&gt; &gt; have this as its behaviour. But then a slight change will mean a=\r\n \n&gt; &gt; different behaviour and the algorithm will end up adding and adding \n=\r\n&gt; &gt; more members to the pool, nearly every new thing in fact, thus the \n&gt; &gt;=\r\n algorithm will end up as a slightly optimized version of exhaustive \n&gt; &gt; s=\r\nearch. \n&gt; &gt; \n&gt; &gt; But it is really interesting to see novelty search combine=\r\nd with \n&gt; &gt; CPPN/HyperNEAT on tasks like my biped or just regular NEAT with=\r\n \n&gt; &gt; novelty search on the cool demos I saw in DephiNEAT like the Hopper \n=\r\n&gt; &gt; and the snake. \n&gt; &gt; \n&gt; &gt; By the way I support the idea that novelty sea=\r\nrch should sometimes be \n&gt; &gt; biased with fitness-based search, once a good =\r\nnumber of approximate \n&gt; &gt; solutions is found. Especially in domains where =\r\nthe search/behaviour \n&gt; &gt; space is vast. \n&gt; &gt; \n&gt; &gt; I believe that the searc=\r\nh space that NEAT searches directly (the \n&gt; &gt; genotype space) is much more =\r\nbig than the behaviour space, simply \n&gt; &gt; because many many different struc=\r\ntures/weight configurations can \n&gt; &gt; represent the same exact behaviour. Th=\r\ne task domain can restrict the \n&gt; &gt; possible behaviours further, but not in=\r\n all task domains. But even if \n&gt; &gt; there are infinite possible behaviours =\r\nin a space, novelty search is \n&gt; &gt; still better than random search because =\r\nit searches explicitly for \n&gt; &gt; new behaviours, so new genomes that do the =\r\nsame thing will not be \n&gt; &gt; rewarded. \n&gt; &gt; \n&gt; &gt; Peter\n&gt; &gt; \n&gt; &gt; --- In neat@=\r\nyahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Joel Lehm=\r\nan and I are excited to announce our new publication to\n&gt; &gt; &gt; appear in the=\r\n Eleventh International Conference on Articifial Life\n&gt; &gt; &gt; (ALIFE XI), cal=\r\nled &quot;Exploiting Open-Endedness to Solve Problems\n&gt; &gt; &gt; Through the Search f=\r\nor Novelty.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; The paper is here:\n&gt; &gt; &gt; \n&gt; &gt; &gt; http://eplex.cs.u=\r\ncf.edu/publications.html#lehman.alife08\n&gt; &gt; &gt; \n&gt; &gt; &gt; Direct link: http://ep=\r\nlex.cs.ucf.edu/papers/lehman_alife08.pdf\n&gt; &gt; &gt; \n&gt; &gt; &gt; This paper is about a=\r\n new kind of search (which works with NEAT) \n&gt; &gt; that\n&gt; &gt; &gt; abandons the lo=\r\nngstanding notion in all of machine learning that the\n&gt; &gt; &gt; gradient of sea=\r\nrch should be measured with respect to the ultimate\n&gt; &gt; &gt; objective.  In ot=\r\nher words, it entirely abandons objectives and\n&gt; &gt; &gt; thereby also abandons =\r\nfitness functions as the impetus for search. \n&gt; &gt; &gt; Yet remarkably, we stil=\r\nl show that such an algorithm can perform\n&gt; &gt; &gt; *better* than one that actu=\r\nally tries to achieve the objective!  I\n&gt; &gt; &gt; believe this strange result h=\r\nas fascinating implications for machine\n&gt; &gt; &gt; learning, artificial life, an=\r\nd even biology.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Lately on this forum we have often discussed t=\r\nhe nagging problem \n&gt; &gt; that\n&gt; &gt; &gt; the fitness function often does not prop=\r\nerly recognize or reward the\n&gt; &gt; &gt; stepping stones on the way to the soluti=\r\non.  I went as far as\n&gt; &gt; &gt; suggesting that the fitness function can become=\r\n an *obstacle* to\n&gt; &gt; &gt; success (e.g. when we discussed creativity in Picbr=\r\needer).\n&gt; &gt; &gt; \n&gt; &gt; &gt; While this discussion was largely philosophical, Joel =\r\nLehman and I\n&gt; &gt; &gt; decided to make it concrete and actually introduce an al=\r\ngorithm that\n&gt; &gt; &gt; makes an automated evolutionary process in *any* domain =\r\nbehave like\n&gt; &gt; &gt; humans in Picbreeder, that is, like open-ended evolution.=\r\n  This\n&gt; &gt; &gt; approach is called &quot;novelty search.&quot;  The algorithm simply sea=\r\nrches\n&gt; &gt; &gt; for behavior that is novel with respect to what has come before=\r\n.\n&gt; &gt; &gt; \n&gt; &gt; &gt; The benefit of this approach is that it is immune to decepti=\r\non \n&gt; &gt; because\n&gt; &gt; &gt; it does not even try to achieve the objective.  I kno=\r\nw it seems\n&gt; &gt; &gt; strange but, counterintuitively, we show that in fact it i=\r\ns far more\n&gt; &gt; &gt; effective at solving a difficult problem in a deceptive la=\r\nndscape \n&gt; &gt; than\n&gt; &gt; &gt; fitness-based search.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; In other words=\r\n, what we are saying is that to achieve some of the \n&gt; &gt; most\n&gt; &gt; &gt; ambitio=\r\nus objectives we might have for evolution, we must abandon\n&gt; &gt; &gt; trying to =\r\nexplicitly achieve them.  To quote from the end of our\n&gt; &gt; &gt; Discussion sec=\r\ntion:\n&gt; &gt; &gt; \n&gt; &gt; &gt; &quot;In summary, almost like a riddle, novelty search sugges=\r\nts\n&gt; &gt; &gt; a surprising new perspective on achievement: To achieve\n&gt; &gt; &gt; your=\r\n highest goals, you must be willing to abandon them.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; I believ=\r\ne this lesson is true in practice and is therefore beyond a\n&gt; &gt; &gt; philosoph=\r\nical curiosity.  In fact, we are instinctively familiar \n&gt; &gt; with\n&gt; &gt; &gt; it =\r\nin life in general when people say things like &quot;You are trying \n&gt; &gt; too\n&gt; &gt;=\r\n &gt; hard&quot; or when we focus so much on something so far ahead of us in \n&gt; &gt; l=\r\nife\n&gt; &gt; &gt; that we forget completely to solve the short term problems that \n=\r\n&gt; &gt; stand\n&gt; &gt; &gt; in our way.  It is no less true in evolution or search in g=\r\neneral.\n&gt; &gt; &gt; \n&gt; &gt; &gt; For NEAT, novelty search should open up new opportunit=\r\nies for\n&gt; &gt; &gt; discovery that were previously closed off to us.  \n&gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; I look forward to hearing your thoughts on this work.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt;=\r\n &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}