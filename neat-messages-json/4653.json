{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"H-3qFb7OODhv6-JuujnF-zhgkOIp3eH27UWzsTc1_bjrfpDcBv6QFkdKYRfcQ19-WvyoQ1mMKhhM2ag_CTOiV42IxIZ8qixyU-7nSJYrGe1s","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: New Paper on Novelty Search and Adaptive Neural Networks","postDate":"1241125423","msgId":4653,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGd0ZDNuZis3MTFmQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM2MUY2MkQ0LjJBOTRDJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4652,"nextInTopic":4660,"prevInTime":4652,"nextInTime":4654,"topicId":4619,"numMessagesInTopic":8,"msgSnippet":"Jeff, I see where you re coming from.  First, I am not necessarily saying there is only one valley between these strategies.  There could be many valleys, or","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 28504 invoked from network); 30 Apr 2009 21:03:54 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m4.grp.re1.yahoo.com with QMQP; 30 Apr 2009 21:03:54 -0000\r\nX-Received: from unknown (HELO n43d.bullet.mail.sp1.yahoo.com) (66.163.169.157)\n  by mta2.grp.sp2.yahoo.com with SMTP; 30 Apr 2009 21:03:54 -0000\r\nX-Received: from [69.147.65.147] by n43.bullet.mail.sp1.yahoo.com with NNFMP; 30 Apr 2009 21:03:43 -0000\r\nX-Received: from [98.137.34.35] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 30 Apr 2009 21:03:43 -0000\r\nDate: Thu, 30 Apr 2009 21:03:43 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gtd3nf+711f@...&gt;\r\nIn-Reply-To: &lt;C61F62D4.2A94C%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New Paper on Novelty Search and Adaptive Neural Networks\r\nX-Yahoo-Group-Post: member; u=54567749; y=GFocvRLjICOlVPZkFRIKyjmORUzvE4BJIZQ8e_XlM2gTr0p98vtA\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, I see where you&#39;re coming from.  First, I am not necessarily saying t=\r\nhere is only one valley between these strategies.  There could be many vall=\r\neys, or there could be a long neutral plateau.\n\nBut still the question is t=\r\nhe same- why should there be one or more valleys or a plateau?\n\nA general w=\r\nay to look at this question is just the see that the word &quot;harder&quot; generall=\r\ny means there is at least one valley or plateau when you are talking about =\r\na search problem.  After all, what else would make the problem &quot;hard?&quot;  If =\r\nhere is just a straight shot up a hill then the problem is easy.  \n\nThe oth=\r\ner aspect of hardness is dimensionality.  But both novelty-based and object=\r\nive-based NEAT approach high-dimensionality the same way, i.e. through comp=\r\nlexification, so that is controlled in the experiment.\n\nSo if adaptive prob=\r\nlems get stuck, it is likely because of a valley or plateau.  The plateau i=\r\ndea makes sense especially in the context of this type of problem because t=\r\nhe fitness function does not recognize differences in behavior that actuall=\r\ny matter although they appear equally useless.  Such fitness equivalence be=\r\ntween very different behaviors is shown in the paper in one example in figu=\r\nre 5.\n\nMore specifically to adaptation, and this is probably more what you =\r\nare looking for, you really have to get into the experience of evolving ada=\r\nptive neural networks to realize how terribly deceiving they are.  I think =\r\nmost people who have worked in this area (and there aren&#39;t that many) would=\r\n agree from experience that it is an incredibly frustrating area of researc=\r\nh because of evolution&#39;s tendency to find non-adaptive solutions (I realize=\r\n your ECAL paper is related to this experience as well).  In fact, my guess=\r\n is that this reason explains why so few people are in this area (i.e. evol=\r\nving adaptive ANNs).  Otherwise, the area is fascinating.  But when you sta=\r\nrt trying to evolve adaptive networks, you face the endless frustration of =\r\ntrying to force it to actually use the adaptive capabilities.  It becomes i=\r\nntuitively apparent that whatever path there is towards adaptive behavior m=\r\nust cross some behaviors that appear entirely useless to the ultimate goal.=\r\n  However, this kind of argument will probably not appear in a paper becaus=\r\ne it is anecdotal.  But I still believe it, and others who research adaptiv=\r\ne ANNs have said similar things.\n\nken\n\n\n\n--- In neat@yahoogroups.com, Jeff =\r\nClune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello Ken-\n&gt; \n&gt; Thanks for the thought-provok=\r\ning response. I&#39;d like to think about your\n&gt; answers a bit before respondin=\r\ng.\n&gt; \n&gt; However, if you have a second, I would be interested to hear your t=\r\nhoughts\n&gt; on what I originally intended to be my main question, which is th=\r\nis:\n&gt; \n&gt; &gt;&gt; The paper seems to further suggest that the reason many of thes=\r\ne problems\n&gt; &gt;&gt; are deceptive is because (a) it is easier to learn a fixed-=\r\nheuristic, and\n&gt; &gt;&gt; then (b) there is a fitness valley between that fixed-h=\r\neuristic and the\n&gt; &gt;&gt; adaptive strategy.\n&gt; &gt;&gt; \n&gt; &gt;&gt; I agree with (a) (in mo=\r\nst cases), but why assume (b)?\n&gt; \n&gt; Much of analysis in the paper hinges on=\r\n the fact that there is actually a\n&gt; fitness valley between a fixed-heurist=\r\nic and learning. But do we know that\n&gt; is the case for your experiment? Is =\r\nit usually the case? Why?\n&gt; \n&gt; For me, questions on this front are really i=\r\nntriguing and, before your\n&gt; paper, I had not spent much time thinking abou=\r\nt them. An understanding of\n&gt; them might really help our field better evolv=\r\ne adaptive agents.\n&gt; \n&gt; \n&gt; Cheers,\n&gt; Jeff\n&gt;\n\n\n\n"}}