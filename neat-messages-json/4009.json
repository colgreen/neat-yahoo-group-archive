{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"WQL8E1NuUDnma69fX6OTZaEWDYstyef78JY6-pnuKEwAV-Sqe0rsljJ0qLBRsGWJib1QeCGYmTytn_cLFzETTvY","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Machine Learning and the Long View of AI","postDate":"1209488677","msgId":4009,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ2N2tmNStkM3YwQGVHcm91cHMuY29tPg==","inReplyToHeader":"PFdvcmxkQ2xpZW50LUYyMDA4MDQyOTA4MTQuQUExNDMxMDAyM0BvY3RhZ2F0ZS5jb20+"},"prevInTopic":4007,"nextInTopic":4010,"prevInTime":4008,"nextInTime":4010,"topicId":3955,"numMessagesInTopic":49,"msgSnippet":"Ken / Mattias, The application of the 0.2 threshold is simply a mechanism to blank out insignificant terms. The entire CPPN/indirect encoding approach utilized","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 10671 invoked from network); 29 Apr 2008 17:04:37 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m57.grp.scd.yahoo.com with QMQP; 29 Apr 2008 17:04:37 -0000\r\nX-Received: from unknown (HELO n48b.bullet.mail.sp1.yahoo.com) (66.163.168.162)\n  by mta16.grp.scd.yahoo.com with SMTP; 29 Apr 2008 17:04:37 -0000\r\nX-Received: from [216.252.122.216] by n48.bullet.mail.sp1.yahoo.com with NNFMP; 29 Apr 2008 17:04:37 -0000\r\nX-Received: from [209.73.164.83] by t1.bullet.sp1.yahoo.com with NNFMP; 29 Apr 2008 17:04:37 -0000\r\nX-Received: from [66.218.66.92] by t7.bullet.scd.yahoo.com with NNFMP; 29 Apr 2008 17:04:37 -0000\r\nDate: Tue, 29 Apr 2008 17:04:37 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fv7kf5+d3v0@...&gt;\r\nIn-Reply-To: &lt;WorldClient-F200804290814.AA14310023@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Machine Learning and the Long View of AI\r\nX-Yahoo-Group-Post: member; u=281645563; y=J_pUtPL51eiYpsFsP9m3KPQ92jEUvL2VHGMEWnB8S0GbtA\r\nX-Yahoo-Profile: afcarl2\r\n\r\nKen / Mattias,\n\nThe application of the 0.2 threshold is simply a mechanism =\r\nto blank \nout insignificant terms. The entire CPPN/indirect encoding approa=\r\nch \nutilized in Hyperneat could be characterized as a neural net approach \n=\r\nto a multidimensional curve fit, and thus attempting to maintain the \ngener=\r\nalized &quot;black-box&quot; approximate characteristic associated with \nneural netwo=\r\nrks.\n\nWhat I view as the major disconnect in the approach taken with \nhyper=\r\nneat may be summarized as follows:\n\na) No effort to separate &quot;separable&quot; po=\r\nrtions of the design space, \nsuch as multiple objectives when they exist, s=\r\no as to simplify the \npatterns being characterized by individual CPPN&#39;s,\n\nb=\r\n) No mechanism to quantify &quot;goodness&quot; of fit, except indirectly via \nfitnes=\r\ns,\n\nc) No mechanism to provide feedback as to when patterns and \nvariations=\r\n being characterized are the same identical ones that are \nblanked-out with=\r\n the 0.2 threshold, like trying to chase a tail that \nkeeps being chopped-o=\r\nff as soon as it appears,\n\nd) No mechanism to descretize the design space a=\r\nnd apply separate \nCPPNs, so as to simplify the sought patterns/variations,=\r\n\n\ne) No mechanism to embed prior evolved &quot;knowledge&quot;, so as to support \na s=\r\ncientific investigation of the value of incorporating &quot;building-\nblocks&quot; of=\r\n various sizes and complexity, rather than simply \ndismissing it&#39;s value wi=\r\nthout evidence to support the position.\n\nIn reality, the threshold should b=\r\ne adaptive based upon some goodness \nof fit criteria, so that computational=\r\n resources are being \neffectively applied in a progressive level-of-detail =\r\nmanner.\n\nThe lack of scientific/methodical approach in demonstrating abilit=\r\ny \nto discover patterns, a priori known patterns, before attempting to \ndem=\r\nonstrate a &quot;killer-application&quot;, for which there is no known \nfigure of mer=\r\nit to compare &quot;ability to discover patterns&quot;, is \ndisturbing, and expecting=\r\n an inordinate level of faith on the part of \nthe reader.\n\nThe lack of any =\r\ncomparative computational cost data is equally \ndisturbing, and begs the qu=\r\nestion, especially since there appears to \nbe a growing body of user experi=\r\nence that the computational cost is \nsteep. But the information should be u=\r\np-front going in rather than \nwithheld and unanswered.\n\nI couldn&#39;t be a big=\r\nger fan of NEAT and indirect encoding \n(appropriately applied). I just refu=\r\nse to drink the cool-aid as its \ncurrently being served, without the eviden=\r\nce to back it up.\n\nBarrowing from Jim O&#39;Flaherty: &quot;I invite you to put your=\r\n time/money \nwhere your words are.&quot;\n\n\n--- In neat@yahoogroups.com, &quot;Mattias=\r\n Fagerlund&quot; &lt;mattias@...&gt; wrote:\n&gt;\n&gt; Hi guys!\n&gt; \n&gt; Ken, you&#39;re saying that =\r\nNE will eventually be able to do what one \nmight\n&gt; call symbolic reasoning?=\r\n I can&#39;t wrap my head around that (a \nfailing on my\n&gt; part), any papers I s=\r\nhould read that broaches the subject? Clearly, \nour\n&gt; brain which does symb=\r\nolic reasoning can handle it, so NE should be \nable to\n&gt; do the same, but h=\r\now to represent it with input, output and hidden \nnodes,\n&gt; that&#39;s a little =\r\nbeyond me at the moment.\n&gt; \n&gt; One practical problem I have with HyperNEAT i=\r\ns that we&#39;re back to \ndeciding\n&gt; the number of hidden node layers, and the =\r\nnumber of nodes in each \nlayer\n&gt; for the phenotype. Any thoughts on how to =\r\nhandle that gracefully? A \nbrute\n&gt; force solution would simply be to provid=\r\ne each genotype with some \nkind of\n&gt; evolvable descriptor that would determ=\r\nine the hidden nodes. But \nmaybe that\n&gt; could be represented within the gen=\r\notype instead?\n&gt; \n&gt; One very interesting experiment I&#39;d like to see done (o=\r\nr do \nmyself); if\n&gt; the genotype decides the hidden nodes, can HyperNEAT su=\r\nccessfully \ncross\n&gt; two genotypes which different hidden node targets? It s=\r\nhould be \npossible,\n&gt; consider humans with our 46 chromosomes. There must h=\r\nave been a \npoint\n&gt; where one person had say 44 chromosomes but doubled up =\r\non one of \nthem,\n&gt; ending up with 46. Then that person mated with another p=\r\nerson with \nthe\n&gt; usual 44 chromosomes, and successfully so. The reason it =\r\nworked at \nall is\n&gt; probably because the chomosomes were very similar, or e=\r\nven \nidentical,\n&gt; making the evolutionary landscape _fairly_ even when it c=\r\nomes to\n&gt; chromosome duplications (99.9999...% of all chromosome duplicatio=\r\nns \nmust\n&gt; have resulted in abortion or sterility, but still).\n&gt; \n&gt; Since H=\r\nyperNEAT uses continuous functions to describe the connection\n&gt; weights, th=\r\nat could possibly imply that the same evenness. It&#39;s \nimpossible\n&gt; to know =\r\nwithout testing, but if we could mate one individual with \none\n&gt; hidden lay=\r\ner with another individual with two hidden layers and get \nviable\n&gt; offspri=\r\nng (preferably stronger), that would be spectacular. Well, I \nwould\n&gt; think=\r\n so anyway ;)\n&gt; \n&gt; As for the 0.2 weight threshold being arbitrary, sure it=\r\n&#39;s \narbitrary, but\n&gt; it&#39;s the landscape that evolution works with, it&#39;s as =\r\narbitrary as g\n&gt; (gravity)=3D9.81, if g would have been say 5, animals woul=\r\nd have been\n&gt; different but no less successfull. Thus using a weight thresh=\r\nold of\n&gt; 0.1-0.3 would probably not change the results significantly - \nano=\r\nther\n&gt; interesting experiment though. Where are the limits for the \nthresho=\r\nld? Too\n&gt; close to 0 and the number of connections will explode. To close t=\r\no \n1 and\n&gt; sigmoid nodes will have a hard time generating connections, and =\r\n\ntheir\n&gt; connection weight resolution would be seriously compromised.\n&gt; \n&gt; =\r\nwith regards,\n&gt; mattias\n&gt;\n\n\n\n"}}