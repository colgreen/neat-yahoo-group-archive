{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":197999825,"authorName":"John Arrowwood","from":"John Arrowwood &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"5pwHYDy_KgPhNaRbKAT37qUWL_HLQ9Ca79PBhOwba00xaB0AJWtTn19ye0iY7pTaGrKBJ4G3QlUOLdFiJgLfcOLaiQr8kzwcsCY","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Refining Search","postDate":"1099886747","msgId":1703,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUxN2ZhNmYxMDQxMTA3MjAwNTRmYmQ3NmUzQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PDE5YjEwZDUxMDQxMTA3MTExNzYxMGVjZDkzQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDE5YjEwZDUxMDQxMTA3MTExNzYxMGVjZDkzQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":1701,"nextInTopic":1707,"prevInTime":1702,"nextInTime":1704,"topicId":1698,"numMessagesInTopic":40,"msgSnippet":"... I m assuming that all 30 are the same throughout the evolution run. If that isn t the case, then that changes things... ... One thing you could *try* is","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 42300 invoked from network); 8 Nov 2004 04:05:52 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m1.grp.scd.yahoo.com with QMQP; 8 Nov 2004 04:05:52 -0000\r\nReceived: from unknown (HELO rproxy.gmail.com) (64.233.170.201)\n  by mta3.grp.scd.yahoo.com with SMTP; 8 Nov 2004 04:05:52 -0000\r\nReceived: by rproxy.gmail.com with SMTP id r35so262699rna\n        for &lt;neat@yahoogroups.com&gt;; Sun, 07 Nov 2004 20:05:47 -0800 (PST)\r\nDomainKey-Signature: a=rsa-sha1; q=dns; c=nofws;\n        s=beta; d=gmail.com;\n        h=received:message-id:date:from:reply-to:to:subject:in-reply-to:mime-version:content-type:content-transfer-encoding:references;\n        b=IsLcXkdbh2z+zVKH3xkPXxJ+VSR36EGy9/1tZ+UNpAApLj+Tdpl/QatV3PCOGBmOCTNtD9WAtoXoca47ezB/GN5EarREMLsCl9ru2Nf3D+TNhR8gJlMXgOq4DhdAngUk7CBMra2oLIS4otXhJoQ0I9OtKq9W8FvFx9DV01p7DXs=\r\nReceived: by 10.38.22.46 with SMTP id 46mr38910rnv;\n        Sun, 07 Nov 2004 20:05:47 -0800 (PST)\r\nReceived: by 10.38.81.72 with HTTP; Sun, 7 Nov 2004 20:05:47 -0800 (PST)\r\nMessage-ID: &lt;517fa6f104110720054fbd76e3@...&gt;\r\nDate: Sun, 7 Nov 2004 20:05:47 -0800\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;19b10d510411071117610ecd93@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=US-ASCII\r\nContent-Transfer-Encoding: 7bit\r\nReferences: &lt;19b10d510411071117610ecd93@...&gt;\r\nX-eGroups-Remote-IP: 64.233.170.201\r\nFrom: John Arrowwood &lt;jarrowwx@...&gt;\r\nReply-To: John@...\r\nSubject: Re: [neat] Refining Search\r\nX-Yahoo-Group-Post: member; u=197999825\r\nX-Yahoo-Profile: jarrowwx\r\n\r\nOn Sun, 7 Nov 2004 13:17:32 -0600, Derek James &lt;djames@...&gt; wrote:\n\n&gt; We can evolve eyes that get in the upper 90s percentage-wise for\n&gt; identifying objects, but that last 2 or 3 percent is eluding us.  When\n&gt; evolving, we have a pop size of 100, and 30 randomized objects for\n&gt; evaluation.  But a best-evolved individual may have identifed all 30\n&gt; correctly, but when shown a test set of 100, for example, it will\n&gt; still miss two or three.  It seems like the evaluation set may be too\n&gt; small to generalize *all* possible randomizations.\n\nI&#39;m assuming that all 30 are the same throughout the evolution run. \nIf that isn&#39;t the case, then that changes things...\n\n&gt; So we thought about increasing the evaluation set, but our image\n&gt; processing is our big bottleneck, and the more evaluations we add, the\n&gt; slower runs take.\n\nOne thing you could *try* is start with a small training/evaluation\nset (like you have), and when the population plateaus, add another one\n(or one of each shape), but without restarting the experiment.  Repeat\nuntil you get a champion that consistently gets 100% on the 100 test\nsamples. Success with this approach requires that there is a smooth\ntransition from the generalization of the smaller set to the\ngeneralization required to accommodate the additional example(s).  But\nI would be surprised if that wasn&#39;t possible here.\n\nAnother thing I would do is add the test of the 100 test images\nseparate from the experiment.  Let the experiment keep running.  As\nsoon as it gets a champion that gets 100%, it saves that champion off\nfor further evaluation, adds another test sample to the set, and keeps\ngoing.  Then, another process (preferably on another CPU) performs the\ntest of champion on 100 or more random samples to see if it scores\nhigh enough.  As soon as it is satisfied, it sets a flag which the\nexperiment recognizes and terminates the evolution at the end of the\ncurrent generation.\n\nNow, if there isn&#39;t a smooth slope from 30 to 31 test samples\n(unlikely), you could try testing it with a random evaluation set. \nBut that creates its own complexities for you.  In order to be certain\nof your fitness evaluation, you have to keep evaluating it until you\nreach a level of statistical certainty.  That is probably more\nexpensive.\n\nAnother option is to replace one of each shape every generation.  Say\nyou have 5 shapes, and you have 6 examples of each.  Every generation,\npick one of each shape, throw it away, and add in another example of\nit.  It&#39;ll keep things more stable for fitness evaluations than\nreplacing the whole set every generation, but will still require the\nwinner to be a true generalization and not just memorize the training\nsamples.\n\n-- John\n\n"}}