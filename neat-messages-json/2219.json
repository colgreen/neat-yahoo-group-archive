{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"_GdYlIT4RrOGnV0qmCoIFi3m2xR9rPr2DuvwNctvyGt1aBwwPzpVCLugD3H90k_kpdu663pLmyfSNaedA9bUkCiXsSn1jOcKCUc","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Recurrency Pseudocode","postDate":"1124967836","msgId":2219,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMi4wLjE0LjAuMjAwNTA4MjUxMTQzMzcuMDMzNzEwMDhAcG9wLm1haWwueWFob28uY28udWs+","inReplyToHeader":"PDE2NjYuNjkuMTQzLjExMC4yNTMuMTEyNDk0ODU2NS5zcXVpcnJlbEBlYWdsZS5kZWFyZG9yZmYuY28gbT4=","referencesHeader":"PGRlaXVyMiszaHZsQGVHcm91cHMuY29tPiA8MTY2Ni42OS4xNDMuMTEwLjI1My4xMTI0OTQ4NTY1LnNxdWlycmVsQGVhZ2xlLmRlYXJkb3JmZi5jb20+"},"prevInTopic":2217,"nextInTopic":2220,"prevInTime":2218,"nextInTime":2220,"topicId":2216,"numMessagesInTopic":4,"msgSnippet":"At 06:42 25/08/2005, you wrote:\n I ve been working on my own implementation of neat for some time now and\n my networks are all assumed to be recurrent (at","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 77242 invoked from network); 25 Aug 2005 11:00:01 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m14.grp.scd.yahoo.com with QMQP; 25 Aug 2005 11:00:01 -0000\r\nReceived: from unknown (HELO smtp002.mail.ukl.yahoo.com) (217.12.11.33)\n  by mta5.grp.scd.yahoo.com with SMTP; 25 Aug 2005 11:00:00 -0000\r\nReceived: (qmail 1362 invoked from network); 25 Aug 2005 10:59:51 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp002.mail.ukl.yahoo.com with SMTP; 25 Aug 2005 10:59:50 -0000\r\nMessage-Id: &lt;6.2.0.14.0.20050825114337.03371008@...&gt;\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.2.0.14\r\nDate: Thu, 25 Aug 2005 12:03:56 +0100\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;1666.69.143.110.253.1124948565.squirrel@...\n m&gt;\r\nReferences: &lt;deiur2+3hvl@...&gt;\n &lt;1666.69.143.110.253.1124948565.squirrel@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] Recurrency Pseudocode\r\nX-Yahoo-Group-Post: member; u=7192225; y=VrrPuNrTCJu7D2qaWAttFcBbwxEQCwcrxCAuR7wO900Hq4MmTg\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nAt 06:42 25/08/2005, you wrote:\n&gt;I&#39;ve been working on my own implementation of neat for some time now and\n&gt;my networks are all assumed to be recurrent (at least, there is no concept\n&gt;of layers or feed ordering).  As an ee, I simply viewed the nodes as\n&gt;flip-flops with more complex transfer functions.  Each node has a source\n&gt;and a sink.  The network is run in three stages with each of these\n&gt;operations being performed on every neuron before the next stage:\n&gt;\n&gt;Reset(Relax) - zero all sources\n\nDon&#39;t you mean zero all _sinks_?\n\n&gt;Collect - sum all sources from upstream neurons into our sink\n&gt;Transfer - transfer sinks to sources via xfer(*)\n\nIs xfer the activation (sigmoid) function?\n\n\n&gt;where a neuron is ---&gt;( sink | source )---&gt;\n&gt;\n&gt;If you&#39;re clever about defining your networks using pointers and minimal\n&gt;structures, this is extraordinarily fast.  I&#39;ll eventually get around to\n&gt;posting my code as well which hopefully will lead to discussion or\n&gt;something.\n&gt;\n&gt;- jeff\n\nWell it is fast and it also isn&#39;t.  It all comes down to definitions.  A \nnon-recurrent network is a state function of its inputs and as such can be \n&quot;activated&quot; by a series of operations to produce the unique output for the \ncurrent input.  So for that just evaluating in the right order is fastest \nand one &quot;activation&quot; updates the whole network.\n\nFor a recurrent network, the concept of activating the whole network is \nmeaningless.  This is because it is a dynamical system, not a \nstate-function.  You cannot activate it to a unique output, because it does \nnot have a unique output.  All you can do is &quot;iterate&quot; it from one \ntime-step to the next (*) You can use mathematical tricks to try and force \na recurrent network to converge on a single value but (i) why?, (ii) they \ncannot be guaranteed to work and (iii) why?\n\nIf you are iterating a recurrent network, then you have choices about how \nto define iteration and more choices about when to read the outputs, but \nnone of them is definitive.  The sources/sinks approach (AKA \ncurrent/previous values approach) is fairly standard, and nice because \nactivation order does not affect results.  It is essentially a simulation \nof a massively-parallel neurone machine (**).\n\nFor a recurrent network, the definition of speed is harder, because you can \nnever complete the process.  For the efficiency of this the speed of the \ngather operations that fetch values from upstream neurones is often the \nlimiting factor and you need to look at the long technical discussion that \nColin Green, John Arrowwood and I (and others) had about a year ago.  There \nis also Colin&#39;s write-up of his results from it: \nhttp://sharpneat.sourceforge.net/network_optimization.html\n\nIan\n\n(*) using iterate in this contexts is based on the standard approach of \nsimulating each neurone as a clocked device.  the alternative approach \nwould be to treat them as (time) continuous devices, in which case one \nwould represent them as partial differential equations:\n\ndSink/dTime = Sum(Source * Connection_Speed)\n\ndSource/dTime = ActivationFunction(Sink) * Activation_Speed\n\nIn which case it would be integration rather than activation...\n\n(**) You can get a little more efficiency if you short-circuit parts of the \ncalculation and do them in series.  e.g. if a sub-net is non-recurrent you \ncould ignore the parallelism within it and just evaluate the nodes in the \nright order within it.  But whether you would want to is debatable, you \nneed to analyze the net to find the serial sections and you are altering \nthe results, if only in timing...\n\n\n&gt; &gt; I have it working now and thought I would post the quasi-pseudocode\n&gt; &gt; for how this works in my implementation:\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; For Each neuron\n&gt; &gt;     if not input neuron, init TotalInput=0\n&gt; &gt;     Init Fired=False\n&gt; &gt; Next\n&gt; &gt;\n&gt; &gt; For each TimeStep\n&gt; &gt;     For each Neuron\n&gt; &gt;         init fired switch to false\n&gt; &gt;         For each Link\n&gt; &gt;             IF link is active &&\n&gt; &gt;                links output neuron=currentNeuron &&\n&gt; &gt;                links input neurons totalValue &gt; 0 THEN\n&gt; &gt;                 IF link has fired=FALSE THEN\n&gt; &gt;                    IF links input neuron &gt; threshold THEN\n&gt; &gt;                       FIRE Neuron by adding its weight to the links\n&gt; &gt;                         output neuron\n&gt; &gt;                       Store the fired neurons ID\n&gt; &gt;                     END\n&gt; &gt;                 END\n&gt; &gt;              END\n&gt; &gt;          NEXT Link\n&gt; &gt;      NEXT Neuron\n&gt; &gt;      FOR EACH Link that fired, set its fired value to TRUE\n&gt; &gt; NEXT Timestep\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt;\n\n\nIn fifteen minutes, everybody will be in the future.\n\n\n\n\t\t\n___________________________________________________________ \nTo help you stay safe and secure online, we&#39;ve developed the all new Yahoo! Security Centre. http://uk.security.yahoo.com\r\n\n"}}