{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":344770077,"authorName":"Colin Green","from":"Colin Green &lt;colin.green1@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"4HEaTddwqCUSljU-t5rtm3WpL9eLdkbsoBSqhaV5_TVxGlYS7k23rN4ezSUJ-LJzr03SJY3IHjfOJATGrsHlhcAvbVRXKB1eDPJu","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] New paper on Evolution Rivaling Backprop","postDate":"1464001844","msgId":6638,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBRTBNK1lkZEt1U3ZmOU5nVT0zaE02LVRPUkdkS2lraDU2NlE5NEFrUXNvb1ZPdWU0Z0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":6637,"nextInTopic":6639,"prevInTime":6637,"nextInTime":6639,"topicId":6630,"numMessagesInTopic":18,"msgSnippet":"On 5 May 2016 at 21:53, kstanley@cs.utexas.edu [neat] ... Thanks Ken. A few thoughts came to mind from reading this paper... I see both SGD and EAs as methods","rawEmail":"Return-Path: &lt;colin.green1@...&gt;\r\nX-Sender: colin.green1@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 22055 invoked by uid 102); 23 May 2016 11:11:24 -0000\r\nX-Received: from unknown (HELO mtaq3.grp.bf1.yahoo.com) (10.193.84.142)\n  by m9.grp.bf1.yahoo.com with SMTP; 23 May 2016 11:11:24 -0000\r\nX-Received: (qmail 32380 invoked from network); 23 May 2016 11:11:24 -0000\r\nX-Received: from unknown (HELO mta1004.groups.mail.bf1.yahoo.com) (98.139.245.163)\n  by mtaq3.grp.bf1.yahoo.com with SMTP; 23 May 2016 11:11:24 -0000\r\nX-Original-Return-Path: &lt;colin.green1@...&gt;\r\nX-Received-SPF: pass (domain of gmail.com designates 209.85.218.51 as permitted sender)\r\nX-YMailISG: Yuwqm04WLDvYtv.RP9zDz4xoRmWwIegthGOx1hoGoxwYq1eU\n BYAszeEV5.10QcryV73j2KoHQlCecG7simb99RGLnyfciRw0esNWBR_.pXK9\n IZdo6FiLvZK3pAaeu6jswaZ7ZAFV7lcN1NghmZNRYFw2tjTLjmibvu.cJB1x\n CdpJ.QleM4w.yORGt4aAx7ORheqZ2yEmqPCOHrGDpETpbm2BzA6obz2NY.yp\n j5g94gch.U9yL1kyq4RXGI_W8gMtowyL2uEjsfqLLNeD.9ITB3LXj1EwQu2V\n 4tvx5R_vDfgPrgFJ4JRtXLLZS8Lwl4y.egehuXiZt7aFLfsh7SlvENgtJ2nO\n IeflhyG88D9bb3J6zeVYBxnOtIDb.Y2K5ziuKSv7VbCt1Paa64BjXN0fQkJW\n xj5ieHMQffPTQX0XAs.Vc6QpaxOuFEhM3ppI4gD5qBR9aqOyAAxiWzhCsY0V\n VD1zzHIIZ6GQrkNvB7Gez_wulUHngfWsJ4hGOY_DJC0XXeb97O8gSOJugqhE\n is3TwyJ2NB_sR8t_l.BBITcvMO.1juPsmXX3jfav5HV2LEQIo8E5f7SRJ49a\n ejVLj3RBWoTFqfxxIRRu0Y04iPJqRZzB1NHEk1pBTpS9SAsHg9q1Hfzidm7X\n d_GmAqV_kjiOXpJ1yr6v2OqHCtA.0GrTDTDs03RBmnZo1PZ2JVqdkHcVS.0C\n dUvaou0sLhnSVqxlYfnWvuLGrhdOo.osz.m3lYMWwz5JojsaOAzQZ76mAEj_\n Hi5nXwZN6rW.ROndVMOohqWbG6c1oAtQvg2099AL2ASURSEZkqKx71vbCl0H\n LVXWQasEGDrgb4hDuEO8ulSKPNCyhbbKoEAi_GKz8gxkZn9iKpCw1VP19JxX\n e3kV_8YcQjJWonlV595V48ULmoEnkf9l82SaMoDWd33lhn7VAp8vFVC9AVOH\n VqgDML8TyzBM6gjnixOhNhORuyOuJl.1gxhgZECAiasWS4GR6xp8wZtpscZC\n dY0Vs3njdxINwSctIojXW1AygWFk0K6vz.XdBrDIlw1oKgHwRG4TYnZpfA5B\n JuISDmicHS2qaTtd7AXMMgtgpMR_JL_pvB6s1SlZYHReGcXXwZCR2O5cOSOD\n fePgjP8VDyqKSmpIlgBEBltaKBCx0SuHGpTsjFWwxyZXOmJAjRc.t8NEowT2\n BjFep.VF4kxZGxqeVbsmZkP5Glp1z7mhxYY1TqNAWGohvmEkMLo3WO5_SKqG\n ohkFlnzjvIj7t75s_NDEhHfIbIL5StBON3Nn8wB7sliJFq9ONH_tdDP8s9EN\n nxdxa_M-\r\nAuthentication-Results: mta1004.groups.mail.bf1.yahoo.com  from=gmail.com; domainkeys=neutral (no sig);  from=gmail.com; dkim=pass (ok)\r\nX-Received: from 127.0.0.1  (EHLO mail-oi0-f51.google.com) (209.85.218.51)\n  by mta1004.groups.mail.bf1.yahoo.com with SMTPS; Mon, 23 May 2016 11:11:24 +0000\r\nX-Received: by mail-oi0-f51.google.com with SMTP id b65so127373053oia.1\n        for &lt;neat@yahoogroups.com&gt;; Mon, 23 May 2016 04:11:23 -0700 (PDT)\r\nX-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;\n        d=1e100.net; s=20130820;\n        h=x-gm-message-state:mime-version:from:date:message-id:subject:to;\n        bh=I4WurQB65le4cODBIL5f2QoCkCeU0QZx6EChryQFEpU=;\n        b=a87OCFWprEv8xO49KRmoOauLAh0CSs+veapFfkcRVaqUE8wIjglelexi1YAxG+4JO5\n         4YhGFAkI6aIwxMhzyJrzeb4vzrX0jA/HIpsXvYwVKjez0MrrUcC1GuSXNdg/cWF4Kgs+\n         6ClHFA0v8hrNHf1iL18PUYXTI4CdSoWK0WclrqWXiqMRGNqozLfkbMeN0WckMjhDH+5z\n         pkCAAGktvcAh7XLtlvD2EEXy2dUeFiZzZ+bHojIGc3qXky8xGjQU2SowGjEA8nb5Jz65\n         hj9ScX9yzUQT3QYFHJp++1ziQgDrQIVdNGyZpJtkidg1P+AonMNLLb0ymquwxEHVPxzU\n         DkIQ==\r\nX-Gm-Message-State: AOPr4FXYxo3RgPk6QuLVeXNp+NDXzRH3M+SQN4K1QDLZY92gR/N6p14g1stTzapgM1KOeArYswmDXsZwY4D1Ow==\r\nX-Received: by 10.202.69.134 with SMTP id s128mr9008223oia.97.1464001883667;\n Mon, 23 May 2016 04:11:23 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.157.56.90 with HTTP; Mon, 23 May 2016 04:10:44 -0700 (PDT)\r\nDate: Mon, 23 May 2016 12:10:44 +0100\r\nMessage-ID: &lt;CAE0M+YddKuSvf9NgU=3hM6-TORGdKikh566Q94AkQsooVOue4g@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=UTF-8\r\nSubject: Re: [neat] New paper on Evolution Rivaling Backprop\r\nX-Yahoo-Group-Post: member; u=344770077; y=JuU5E9X1zZjXlDZRjyzKIdCKm74vUDe-ebYW4ecfTrqMM1qlxhHb\r\nX-Yahoo-Profile: alienseedpod\r\nFrom: Colin Green &lt;colin.green1@...&gt;\r\n\r\nOn 5 May 2016 at 21:53, kstanley@... [neat]\n&lt;neat@yahoogroups.com&gt; wrote:\n&gt;\n&gt;\n&gt; Greg Morse and I are pleased to announce our new paper to appear at\n&gt; GECCO-16, titled &quot;Simple Evolutionary Optimization Can Rival Stochastic\n&gt; Gradient Descent in Neural Networks.&quot;\n&gt;\n&gt;\n&gt; http://eplex.cs.ucf.edu/papers/morse_gecco16.pdf\n&gt;\n\nThanks Ken. A few thoughts came to mind from reading this paper...\n\nI see both SGD and EAs as methods that follow a gradient, the\ndistinction being that SGD explicitly computes a gradient and moves\nthrough the search space accordingly, whereas an EA takes proximal\nrandom samples, each sample being a mini experiment of sorts with an\nunarguable empirical result.\n\nTechniques such as RMSProp are exploring different ways of following a\ngradient, e.g. the paper alluded to the saddle problem and whether we\nshould follow shallow gradients with the same priority as steep ones,\nso I think it would be interesting to explore how EAs are actually\nfollowing gradients with respect to developments in that sub-field. So\nfor instance, in a given population the offspring that followed a\nsteep gradient would score better and would therefore have high\nselection probability, although you&#39;ve also got the shallow gradient\nsearching mixed in there to some extent, until it lags behind so much\nit drops out of the population (potentially). So there&#39;s a potential\nangle there to explore I think. There&#39;s also the gradient momentum\naspects of RMSProp (and similar) to consider, e.g. could we modify EAs\nto bias weight mutation based on past good mutations.\n\nI also note you used a mutation power decay factor - again in the SGD\nworld there are attempts to eliminate such &#39;magic sauce&#39; factors. For\nmore on that, my knowledge of that world is mostly from this set of\nslides (from Geoff Hinton):\n\n    http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\n\n\nIt&#39;s nice to see the question being asked (and explored) regarding\nwhether it&#39;s necessary to follow (and therefore compute) exact\ngradients, and I think this paper demonstrates that this is not always\nthe case. The main remaining question for me would be whether exact\ngradient following is necessary with much larger networks, because the\nnumber of possible directions of travel is so large that we cannot\nafford to randomly sample the nearby space to find a good direction\n(i.e. the volume of the unit sphere as D increases becomes vast very\nquickly, and unintuitively so). But then again, computing gradients\nisn&#39;t necessarily cheap either, so I think there are open questions\nthere. Basically we really don&#39;t have good information about the\ntopology of these very high D search spaces - which one would think is\na necessity in devising algorithms to traverse paths through them.\n\nI liked the fitness inheritance idea. Side note:  I would be tempted\nto normalise f&#39; such that it&#39;s a weighted average of current f and the\nparents, otherwise adjusting d gives fitnesses of different scales,\nwhich in turn can affect the roulette wheel selection. It&#39;s a nice\nsimple idea though that we could plug-in to NEAT.\n\nI also liked that you chose to use fixed topology here, it makes the\ncomparison with SGD a straightforward one. It&#39;s also worth noting that\nit&#39;s probably going to be easier to optimise fixed topology nets since\nthere&#39;s lots of support out there for doing standard maths (vector and\nmatrix operations) and neural net calcs with optimised back-end\ncalculation engines that use GPUs, CUDA, Intel Math Kernel Lib, Atlas,\nOpenBLAS, etc. The trouble with adding a new weight and/or node to an\nexisting net is that to run the network calcs optimally the new\nnode/weight belongs in the middle of some large data structure, which\nmeans shifting data round which is a problem if you do it a lot.\n\nOverall my instinct is that the underlying algorithmic complexity of\nan EA style search is going to be higher than following calculated\ngradients, but (A) we need good evidence before we make that call, (B)\nthere might be niche problems that EAs can solve that gradient\nfollowing can&#39;t, and (C) those niche problems might be key to solving\nsome key problems in AI generally.\n\nRegards,\n\nColin\n\n"}}