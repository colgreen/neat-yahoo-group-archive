{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":130984297,"authorName":"joel278","from":"&quot;joel278&quot; &lt;lehman.154@...&gt;","profile":"joel278","replyTo":"LIST","senderId":"CgpwoYsMwl0N-NHcHOI0Je-6vI509IpPiiEFuAZGxQs0j_w7ZUPc7_PSiepzTlPHkI75RVcrU3eOZWKQgOaG64JBgBbc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1210882574","msgId":4075,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwaTVtZStxamhxQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGcwaTEzNSt0cTNtQGVHcm91cHMuY29tPg=="},"prevInTopic":4073,"nextInTopic":4076,"prevInTime":4074,"nextInTime":4076,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"Hi Peter, I would highly recommend using a steady-state GA with novelty search. I realize this poses a problem for many people who use NEAT because the only","rawEmail":"Return-Path: &lt;lehman.154@...&gt;\r\nX-Sender: lehman.154@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 71651 invoked from network); 15 May 2008 20:16:17 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m56.grp.scd.yahoo.com with QMQP; 15 May 2008 20:16:17 -0000\r\nX-Received: from unknown (HELO n17a.bullet.sp1.yahoo.com) (69.147.64.124)\n  by mta15.grp.scd.yahoo.com with SMTP; 15 May 2008 20:16:17 -0000\r\nX-Received: from [216.252.122.219] by n17.bullet.sp1.yahoo.com with NNFMP; 15 May 2008 20:16:14 -0000\r\nX-Received: from [66.218.69.3] by t4.bullet.sp1.yahoo.com with NNFMP; 15 May 2008 20:16:14 -0000\r\nX-Received: from [66.218.66.89] by t3.bullet.scd.yahoo.com with NNFMP; 15 May 2008 20:16:14 -0000\r\nDate: Thu, 15 May 2008 20:16:14 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g0i5me+qjhq@...&gt;\r\nIn-Reply-To: &lt;g0i135+tq3m@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;joel278&quot; &lt;lehman.154@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=130984297; y=pFrfCqsSFBbT3BwMHF0SRKqoYgjtynUJZQX1PUNmAV92v5LNpr1A\r\nX-Yahoo-Profile: joel278\r\n\r\nHi Peter,\n\nI would highly recommend using a steady-state GA with novelty se=\r\narch.\nI realize this poses a problem for many people who use NEAT because\nt=\r\nhe only steady-state capable distribution I am aware of is the C++\nrtNEAT p=\r\nackage. Using novelty search with a generational GA may cause\nthe dynamics =\r\nof novelty search to be hurt. \n\nThe reason a generational GA may not work a=\r\ns well is that novelty\nsearch uses an archive of past behaviors plus the be=\r\nhaviors of the\ncurrent population to calculate the novelty scores. In a gen=\r\nerational\nGA, this will lead to large discrete changes in the novelty lands=\r\ncape\n(as the entire population changes at once), and will complicate the\nse=\r\narch process. The gradients of novelty may completely change with\neach pass=\r\ning generation, and lead to little global progress in the\nsearch for novelt=\r\ny. A possible solution would be simply *not* to\ninclude the current generat=\r\nion in the novelty scores with a\ngenerational GA.\n\nHowever, this also has a=\r\n downside: without the population being\nincluded in the novelty scores, the=\r\nre would then be no impetus for\nnovelty search to maintain a behaviorally d=\r\niverse population (although\nNEAT&#39;s speciation functions may cause this to n=\r\not be disastrous).\nWithout a behaviorally diverse population, there may be =\r\na &quot;forgetting&quot;\nproblem where the novelty search population converges on a p=\r\narticular\narea of the behavioral space, and other previous areas of novelty=\r\n\nspace no longer have representation in the population (potential\nstepping =\r\nstones have been lost). To combat this problem, you could\nintroduce an oper=\r\nator that will clone individuals from the archive of\npast behaviors, and pl=\r\nace them back into the population.\n\nIt may be easier/more effective to exte=\r\nnd whatever NEAT distribution\nyou are using to be steady state, or switch t=\r\no the rtNEAT distribution.\n\nJoel\n\n--- In neat@yahoogroups.com, &quot;petar_cherv=\r\nenski&quot; &lt;petar_chervenski@...&gt;\nwrote:\n&gt;\n&gt; I am about to implement my first n=\r\novelty search experiment but I \n&gt; encountered a problem I need to ask you a=\r\nbout. Is it really necessary \n&gt; to use steady state evolution in the way Jo=\r\nel and you did? How can \n&gt; the same dynamics would be applied with the gene=\r\nrational-based NEAT? \n&gt; Can you give me a suggestion? I appreciate any help=\r\n. \n&gt; \n&gt; Peter\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley=\r\n@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Peter, it will probably take some time to have well-resea=\r\nrched \n&gt; answers\n&gt; &gt; to this kind of question, but here is my guess for the=\r\n moment:  \n&gt; First,\n&gt; &gt; novelty search may have a tendency to avoid stagnat=\r\nion already \n&gt; because\n&gt; &gt; it includes the current population along with th=\r\ne archive when it\n&gt; &gt; measures novelty.  So in effect, even if nothing is n=\r\new \n&gt; historically,\n&gt; &gt; the population is still repelling itself away from =\r\nwhere it is\n&gt; &gt; currently.  That means that over time the population will k=\r\nind of\n&gt; &gt; dance around the behavior space until it hits a stepping stone t=\r\no\n&gt; &gt; something different.  It could take a long time, but at least it \n&gt; w=\r\nill\n&gt; &gt; never just sit still and &quot;give up&quot; the way fitness-based evolution\n=\r\n&gt; &gt; tends to do when it converges prematurely.  Novelty search never\n&gt; &gt; &quot;f=\r\neels&quot; like it has found an optimum because it is effectively\n&gt; &gt; coevolutio=\r\nnary and always looking to break free.\n&gt; &gt; \n&gt; &gt; There also may be something=\r\n more active we can do to push it out\n&gt; &gt; beyond this inherent dynamic.  Ma=\r\nybe there is a method of detecting\n&gt; &gt; that things are not diversifying wel=\r\nl anymore and then pushing \n&gt; things\n&gt; &gt; out.  Yet we would need to be care=\r\nful because simply e.g. upping the\n&gt; &gt; mutation rate might make things wors=\r\ne by knocking our population off\n&gt; &gt; the current set of behaviors back to s=\r\nomething more primitive.  \n&gt; Still,\n&gt; &gt; since this research direction is in=\r\n its infancy, I&#39;d guess there \n&gt; will\n&gt; &gt; end up many creative ideas for de=\r\naling with various bad situations,\n&gt; &gt; just as people have come up with all=\r\n kinds of tricks to deal with\n&gt; &gt; pathologies in fitness-based search. \n&gt; &gt;=\r\n \n&gt; &gt; ken\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;petar_chervenski=\r\n&quot; &lt;petar_chervenski@&gt;\n&gt; &gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; \n&gt; &gt; &gt; thanks fo=\r\nr this great post again, it answered many questions and \n&gt; it \n&gt; &gt; &gt; helped=\r\n me get more insight in the philosophy behind NS. \n&gt; &gt; &gt; One question I hav=\r\ne, how we could deal with stagnation even in \n&gt; &gt; &gt; novelty search, i.e. wh=\r\nen every new genome happens to be a known \n&gt; &gt; &gt; behavior? Is this possible=\r\n at all? \n&gt; &gt; &gt; \n&gt; &gt; &gt; Peter\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Ken=\r\nneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Jeff,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Tha=\r\nnks for asking these questions.  These are likely the kinds \n&gt; of\n&gt; &gt; &gt; &gt; q=\r\nuestions we are going to face over time so it&#39;s a good chance \n&gt; to \n&gt; &gt; &gt; =\r\nwork\n&gt; &gt; &gt; &gt; on our response.  I&#39;m going to start with a technical response=\r\n \n&gt; but\n&gt; &gt; &gt; &gt; move to philosophical.  It&#39;s a bit of an essay but hopefull=\r\ny \n&gt; worth \n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; read.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Your first set of ques=\r\ntions regards the relationship between \n&gt; novelty\n&gt; &gt; &gt; &gt; search (NS) and e=\r\nxhaustive search of behavioral space.  Do we \n&gt; think\n&gt; &gt; &gt; &gt; these are eff=\r\nectively the same thing?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I think it&#39;s a tricky subject but=\r\n in the end I would not equate \n&gt; NS \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; exhaustive search.  =\r\nWhile NS indeed does attempt to essentially \n&gt; &gt; &gt; visit\n&gt; &gt; &gt; &gt; every beha=\r\nvior in behavioral space, the way it does it is not \n&gt; the \n&gt; &gt; &gt; same\n&gt; &gt; =\r\n&gt; &gt; as what is usually meant by exhaustive search.  We usually \n&gt; think of =\r\n\n&gt; &gt; &gt; an\n&gt; &gt; &gt; &gt; exhaustive search as a purposeful enumeration, where if I=\r\n just \n&gt; try\n&gt; &gt; &gt; &gt; every combination of something, one will be the answer=\r\n.  A key \n&gt; &gt; &gt; feature\n&gt; &gt; &gt; &gt; of this type of search is that it does not =\r\nrequire or utilize\n&gt; &gt; &gt; &gt; information or feedback of any kind as a guide. =\r\n Rather, it \n&gt; simply\n&gt; &gt; &gt; &gt; makes sure it does not visit the same point t=\r\nwice.  (It is \n&gt; similar \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; random search except that random=\r\n search might indeed visit the \n&gt; same\n&gt; &gt; &gt; &gt; point twice.)\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; One clear difference between such a search and NS is that we \n&gt; cannot\n&gt;=\r\n &gt; &gt; &gt; purposefully enumerate all possible behaviors because our \n&gt; search =\r\n\n&gt; &gt; &gt; space\n&gt; &gt; &gt; &gt; is the genotype space, which maps indirectly to the be=\r\nhavior \n&gt; space. \n&gt; &gt; &gt; &gt; Therefore, there is actually no way to simply say=\r\n &quot;list all \n&gt; possible\n&gt; &gt; &gt; &gt; behaviors&quot; and try each one in succession.  =\r\nWe must seek them \n&gt; out.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Furthermore, in novelty search t=\r\nhere is *information* guiding \n&gt; the\n&gt; &gt; &gt; &gt; order of points we visit (the =\r\ninformation is the novelty \n&gt; measure). \n&gt; &gt; &gt; &gt; The points also have an in=\r\nherent order (perhaps quite useful) \n&gt; &gt; &gt; induced\n&gt; &gt; &gt; &gt; by the genetic e=\r\nncoding (hence the promise of combining it with\n&gt; &gt; &gt; &gt; HyperNEAT). In othe=\r\nr words, we are not simply enumerating in an\n&gt; &gt; &gt; &gt; arbitrary non-overlapp=\r\ning order.  Rather, we follow the most \n&gt; &gt; &gt; promising\n&gt; &gt; &gt; &gt; trails that=\r\n seem to be leading to something new.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; One significant cons=\r\nequence of this fact is that the actual \n&gt; search\n&gt; &gt; &gt; &gt; space (which is t=\r\nhe genotype space) will almost certainly never \n&gt; need\n&gt; &gt; &gt; &gt; to be exhaus=\r\ntively searched.  So we effectively avoided wasting \n&gt; our\n&gt; &gt; &gt; &gt; time exa=\r\nmining all kinds of genetic combinations that would have\n&gt; &gt; &gt; &gt; produced r=\r\nedundant behaviors.  In its usual meaning, exhaustive \n&gt; &gt; &gt; search\n&gt; &gt; &gt; &gt;=\r\n would be just such a search through genotype space.  So \n&gt; certainly it\n&gt; =\r\n&gt; &gt; &gt; is not normal exhaustive search.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Yet if you still wa=\r\nnt to talk about exhaustively searching \n&gt; behavior\n&gt; &gt; &gt; &gt; space, it is st=\r\nill not a typical exhaustive search because of \n&gt; the \n&gt; &gt; &gt; fact\n&gt; &gt; &gt; &gt; i=\r\nt proceeds in an order guided by information- not typical of\n&gt; &gt; &gt; &gt; exhaus=\r\ntive search.  Another corollary is that it is impossible \n&gt; to\n&gt; &gt; &gt; &gt; perf=\r\norm a typical exhaustive search of behavior space because \n&gt; we \n&gt; &gt; &gt; have=\r\n\n&gt; &gt; &gt; &gt; no method to enumerate it:  It must be explored.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\nYet you might still say, fine, semantically perhaps it is \n&gt; something\n&gt; &gt; =\r\n&gt; &gt; different, but still, in spirit are you not essentially doing\n&gt; &gt; &gt; &gt; s=\r\nomething equally inefficient, i.e. looking for absolutely \n&gt; &gt; &gt; everything=\r\n?  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; And it is true that in effect we are searching for eve=\r\nry \n&gt; behavior, \n&gt; &gt; &gt; or\n&gt; &gt; &gt; &gt; at least every behavior that looks distin=\r\nguishable from each \n&gt; other\n&gt; &gt; &gt; &gt; with respect to the novelty metric and=\r\n in an order from \n&gt; simplicity \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; high complexity.  Yet the=\r\nrein lies the fundamental insight: \n&gt; While \n&gt; &gt; &gt; such\n&gt; &gt; &gt; &gt; a search mi=\r\nght sound bad, it is a lot better to look at \n&gt; everything \n&gt; &gt; &gt; (in\n&gt; &gt; &gt;=\r\n &gt; some meaningful order) and eventually run across what you want\n&gt; &gt; &gt; &gt; (=\r\nperhaps after a very long time) than to look for one specific \n&gt; thing\n&gt; &gt; =\r\n&gt; &gt; and *never* find it.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; We are indeed suggesting that thi=\r\ns rather tortured choice \n&gt; (between\n&gt; &gt; &gt; &gt; looking for something without =\r\nhope and looking for everything) \n&gt; is\n&gt; &gt; &gt; &gt; sometimes the real choice th=\r\nat we face with the most ambitious\n&gt; &gt; &gt; &gt; problems.  In other words, objec=\r\ntive-based fitness is literally \n&gt; &gt; &gt; doomed\n&gt; &gt; &gt; &gt; when it comes to evol=\r\nving many incredibly complex systems from\n&gt; &gt; &gt; &gt; scratch.  It will simply =\r\nnever happen because at high levels of\n&gt; &gt; &gt; &gt; complexity, there is going t=\r\no be massive deception at many \n&gt; levels, \n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; fitness become=\r\ns as bad as random search in such a problem.  In \n&gt; fact,\n&gt; &gt; &gt; &gt; as our re=\r\nsults show, you don&#39;t even have to make the problem \n&gt; all \n&gt; &gt; &gt; that\n&gt; &gt; =\r\n&gt; &gt; hard to cause fitness to crumble into something as bad as random\n&gt; &gt; &gt; =\r\n&gt; search.  What do you think will happen if you are trying to \n&gt; evolve a\n&gt;=\r\n &gt; &gt; &gt; neural network into the mind of a quantum physicist based on how\n&gt; &gt;=\r\n &gt; &gt; brilliant it is at quantum physics?  The answer: Nothing.\n&gt; &gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; &gt; A more down-to-earth example is the car that I evolved on \n&gt; &gt; &gt; Picbr=\r\needer.\n&gt; &gt; &gt; &gt;  It could never have evolved if evolving a car had been the\n=\r\n&gt; &gt; &gt; &gt; *objective* because it was preceded by an alien face (evolved by\n&gt; =\r\n&gt; &gt; &gt; someone else).  It just so happens that the alien face is a \n&gt; steppi=\r\nng\n&gt; &gt; &gt; &gt; stone to a car, but if we had judged the alien face on it &quot;car-\n=\r\n&gt; &gt; &gt; ness,&quot;\n&gt; &gt; &gt; &gt; it would have failed miserably and been deleted.  Henc=\r\ne if we \n&gt; were\n&gt; &gt; &gt; &gt; looking for a car we would never have found one.\n&gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; In nature, if we had bred flatworms (the earliest chordates)=\r\n \n&gt; based \n&gt; &gt; &gt; on\n&gt; &gt; &gt; &gt; their humanity, they too would have never evolv=\r\ned into \n&gt; amphibians,\n&gt; &gt; &gt; &gt; then reptiles, then mammals, as they did.  T=\r\nhe objective in \n&gt; long-run\n&gt; &gt; &gt; &gt; problems is totally blind to the necess=\r\nary stepping stones.  \n&gt; Unless \n&gt; &gt; &gt; we\n&gt; &gt; &gt; &gt; know them a priori, we ar=\r\ne lost.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Why do you suppose we have never seen a flowering =\r\nof diversity \n&gt; and\n&gt; &gt; &gt; &gt; complexity such as seen in nature in evolutiona=\r\nry computation?  \n&gt; In \n&gt; &gt; &gt; 30\n&gt; &gt; &gt; &gt; or 40 years of this field, which i=\r\ns inspired by nature, we have \n&gt; &gt; &gt; never\n&gt; &gt; &gt; &gt; seen something that come=\r\ns even close to even nature&#39;s modest\n&gt; &gt; &gt; &gt; achievements.  The problem is =\r\nthat we have been blinded by \n&gt; &gt; &gt; objectives.\n&gt; &gt; &gt; &gt;    As soon as we se=\r\nt an objective, the stepping stones to it \n&gt; often\n&gt; &gt; &gt; &gt; vanish into thin=\r\n air.  There is no escape from this very \n&gt; sobering\n&gt; &gt; &gt; &gt; fact.  It will=\r\n have to be accepted, though it will be hard to \n&gt; &gt; &gt; accept.\n&gt; &gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; &gt; Novelty search cures this problem, although admittedly in a \n&gt; painful=\r\n\n&gt; &gt; &gt; &gt; way, because it forces us to let go of our natural desire to \n&gt; &gt; =\r\n&gt; *control*\n&gt; &gt; &gt; &gt; what is happening.  We feel compelled to demand to the =\r\nsearch\n&gt; &gt; &gt; &gt; algorithm that it go in a certain direction.  It is difficul=\r\nt to\n&gt; &gt; &gt; &gt; relinquish this feeling of control, yet if we recognize that i=\r\nn \n&gt; the\n&gt; &gt; &gt; &gt; end the setting of such goals is its own worst enemy, then=\r\n we \n&gt; can\n&gt; &gt; &gt; &gt; begin to be liberated from this longstanding compulsion.=\r\n\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; (Note that I am not saying fitness is always useless; obv=\r\niously \n&gt; that\n&gt; &gt; &gt; &gt; is not the case.  I am talking about very ambitious =\r\nproblems, \n&gt; beyond\n&gt; &gt; &gt; &gt; the kind we have been able to solve yet- though=\r\n even the &quot;hard \n&gt; maze&quot;\n&gt; &gt; &gt; &gt; is bordering on such a problem.)\n&gt; &gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; &gt; You point out that novelty search may get &quot;lost&quot; in a kind of \n&gt; &gt; =\r\n&gt; endless\n&gt; &gt; &gt; &gt; offshoot in behavior space.  And yes, in some situations,=\r\n it \n&gt; very \n&gt; &gt; &gt; well\n&gt; &gt; &gt; &gt; may.  Yet I believe it will not do so in ma=\r\nny interesting \n&gt; domains. \n&gt; &gt; &gt; &gt; For example, if there was indeed a long=\r\n offshoot of the maze, \n&gt; first,\n&gt; &gt; &gt; &gt; since there is a time limit for ea=\r\nch robot, it would make little\n&gt; &gt; &gt; &gt; difference and would quickly be fill=\r\ned up by novelty search.  \n&gt; If \n&gt; &gt; &gt; there\n&gt; &gt; &gt; &gt; are no obstacles in th=\r\ne offshoot, it would be filled especially \n&gt; &gt; &gt; fast.\n&gt; &gt; &gt; &gt;  But at the =\r\nsame time, novelty search is not likely to go off \n&gt; in \n&gt; &gt; &gt; only\n&gt; &gt; &gt; &gt;=\r\n one direction anyway.  Because it is a population, it will go \n&gt; off in\n&gt; =\r\n&gt; &gt; &gt; many directions at once.  While some parts may shoot down the\n&gt; &gt; &gt; &gt;=\r\n diversionary offshoot, at the same time others will begin to \n&gt; flow \n&gt; &gt; =\r\n&gt; down\n&gt; &gt; &gt; &gt; the paths we want.  If it happens to take the wrong paths, i=\r\nt \n&gt; will\n&gt; &gt; &gt; &gt; fill that areas first and eventually be pushed back into =\r\nthe \n&gt; areas \n&gt; &gt; &gt; we\n&gt; &gt; &gt; &gt; care about (only if each individual was give=\r\nn infinite time \n&gt; could it\n&gt; &gt; &gt; &gt; be stuck in one area forever)\n&gt; &gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; &gt; In the end, of course there is a chance it will fail to go the \n&gt; r=\r\night\n&gt; &gt; &gt; &gt; way in reasonable time; after all, it has no objective!  In \n&gt;=\r\n fact, in\n&gt; &gt; &gt; &gt; the hard maze experiment, it did once fail to find a solu=\r\ntion \n&gt; in 40\n&gt; &gt; &gt; &gt; runs.  Yet look at how much more consistent it is tha=\r\nn fitness-\n&gt; based\n&gt; &gt; &gt; &gt; search.  So the point is not that this is a guar=\r\nantee (there \n&gt; will\n&gt; &gt; &gt; &gt; never be one).  Rather, it is a profoundly dif=\r\nferent kind of \n&gt; search,\n&gt; &gt; &gt; &gt; which is likely to reach places that fitn=\r\ness-based search can \n&gt; never\n&gt; &gt; &gt; &gt; hope to touch.  So it opens up a whol=\r\ne new world of \n&gt; possibilities to\n&gt; &gt; &gt; &gt; evolutionary computation.  That =\r\ndoes not mean it solves \n&gt; everything; \n&gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; course it may stil=\r\nl not always give us what we want.  There is \n&gt; no\n&gt; &gt; &gt; &gt; method that will=\r\n ever always give you what you want.  Yet \n&gt; objective\n&gt; &gt; &gt; &gt; fitness is o=\r\nften even worse.  That is the sobering moral of the \n&gt; &gt; &gt; story.\n&gt; &gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; &gt; So in my view, NS is actually suited for exactly those &quot;large \n&gt; &gt; =\r\n&gt; spaces&quot;\n&gt; &gt; &gt; &gt; that you suggest it will have trouble in.  And by large I=\r\n mean \n&gt; &gt; &gt; LARGE.\n&gt; &gt; &gt; &gt;  Those are the ones where objective-based fitne=\r\nss has no hope.  \n&gt; &gt; &gt; These\n&gt; &gt; &gt; &gt; are spaces like life on earth, where =\r\nit would be futile (and \n&gt; silly) \n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; start with a single cel=\r\nl and select offspring based on relative\n&gt; &gt; &gt; &gt; humanity.  The only reason=\r\n we got to humans in nature is because\n&gt; &gt; &gt; &gt; nobody said we had to get th=\r\nere.  It&#39;s almost paradoxical, but \n&gt; if \n&gt; &gt; &gt; you\n&gt; &gt; &gt; &gt; accept it, it i=\r\ns an exciting liberation.  If we let go of the\n&gt; &gt; &gt; &gt; compulsion to be in =\r\ncontrol, we may find something we did not \n&gt; expect\n&gt; &gt; &gt; &gt; that is quite s=\r\nignificant.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; So actually the idea of running fitness-based =\r\nsearch and then \n&gt; &gt; &gt; novelty\n&gt; &gt; &gt; &gt; search is less exciting to us althou=\r\ngh we raise it as a \n&gt; practical\n&gt; &gt; &gt; &gt; matter.  In some domains, objectiv=\r\ne fitness is simply impotent, \n&gt; and\n&gt; &gt; &gt; &gt; the compulsion to have some sh=\r\nred of guidance to hang onto is a \n&gt; &gt; &gt; false\n&gt; &gt; &gt; &gt; comfort.  We will ha=\r\nve to let go, and then, strangely, we will \n&gt; end \n&gt; &gt; &gt; up\n&gt; &gt; &gt; &gt; where w=\r\ne want to be.  It&#39;s like when your grandparents told you \n&gt; that\n&gt; &gt; &gt; &gt; if=\r\n you stop worrying so much about making things work out, they \n&gt; will\n&gt; &gt; &gt;=\r\n &gt; work out on their own.  Did you believe them?  Maybe there is \n&gt; more\n&gt; =\r\n&gt; &gt; &gt; wisdom in it than there appeared to be.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n=\r\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Hello. \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Thanks for the thought pro=\r\nvoking paper. Here is my main \n&gt; question\n&gt; &gt; &gt; &gt; regarding\n&gt; &gt; &gt; &gt; &gt; the w=\r\nork: How would you differentiate the NSA (novelty search \n&gt; &gt; &gt; algorithm)\n=\r\n&gt; &gt; &gt; &gt; &gt; from exhaustive search in the behavior space?\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\n&gt; If you think there is a relevant difference between the NSA \n&gt; and\n&gt; &gt; &gt; =\r\n&gt; exhaustive\n&gt; &gt; &gt; &gt; &gt; behavioral search, have you tried using the former a=\r\ns a \n&gt; control \n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; seeing\n&gt; &gt; &gt; &gt; &gt; how they compare?\n&gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; &gt; If the NSA is effectively exhaustive search in behavior \n&gt; s=\r\npace, it\n&gt; &gt; &gt; &gt; seems to\n&gt; &gt; &gt; &gt; &gt; me that, while it will work well (and b=\r\netter than a GA) in \n&gt; small,\n&gt; &gt; &gt; &gt; deceptive\n&gt; &gt; &gt; &gt; &gt; landscapes, it wi=\r\nll not perform very well in large search \n&gt; spaces.\n&gt; &gt; &gt; &gt; Imagine,\n&gt; &gt; &gt; =\r\n&gt; &gt; for example, the paper&#39;s &quot;medium map&quot; but with a huge (near\n&gt; &gt; &gt; &gt; inf=\r\ninite) open\n&gt; &gt; &gt; &gt; &gt; area to the left of the starting condition. It could =\r\neasily \n&gt; get \n&gt; &gt; &gt; lost\n&gt; &gt; &gt; &gt; over\n&gt; &gt; &gt; &gt; &gt; there indefinitely.\n&gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; &gt; You mention that it helps to have the domain constrain the \n=\r\n&gt; search \n&gt; &gt; &gt; space.\n&gt; &gt; &gt; &gt; &gt; Does this just mean that the (behavioral) =\r\nsearch space has to \n&gt; be \n&gt; &gt; &gt; small\n&gt; &gt; &gt; &gt; &gt; enough that it can an exha=\r\nustive search can deal with it? How \n&gt; will\n&gt; &gt; &gt; &gt; it fare\n&gt; &gt; &gt; &gt; &gt; in th=\r\ne much larger search spaces of real-world problems, like \n&gt; &gt; &gt; checkers?\n&gt;=\r\n &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Using the NSA as something to bail out objective-search=\r\n when \n&gt; it\n&gt; &gt; &gt; &gt; stagnates is\n&gt; &gt; &gt; &gt; &gt; an interesting suggestion. But a=\r\nt that point it should be \n&gt; &gt; &gt; compared to\n&gt; &gt; &gt; &gt; &gt; fitness sharing. Wou=\r\nld it do better than fitness sharing? I \n&gt; can \n&gt; &gt; &gt; think of\n&gt; &gt; &gt; &gt; &gt; re=\r\nasons it might (because it truly is not tempted by deceptive\n&gt; &gt; &gt; &gt; traps)=\r\n, but\n&gt; &gt; &gt; &gt; &gt; it would useful to see it compared to fitness sharing \n&gt; co=\r\nntrols.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Just my 2 cents. Thanks for putting this out t=\r\nhere.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; &gt; &gt; Jeff Clune\n&gt; &gt; &gt; &gt; =\r\n&gt; \n&gt; &gt; &gt; &gt; &gt; Digital Evolution Lab, Michigan State University\n&gt; &gt; &gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; &gt; &gt; jclune@\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Fro=\r\nm: Kenneth Stanley &lt;kstanley@&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Reply-To: &quot;neat@yahoogroups.com&quot;=\r\n &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Date: Fri, 09 May 2008 02:00:33 -0000\n&gt;=\r\n &gt; &gt; &gt; &gt; &gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Su=\r\nbject: [neat] Introducing a New Approach to Search: \n&gt; Novelty\n&gt; &gt; &gt; &gt; Sear=\r\nch (New\n&gt; &gt; &gt; &gt; &gt; &gt; Paper)\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Joel Lehman and I are e=\r\nxcited to announce our new \n&gt; publication to\n&gt; &gt; &gt; &gt; &gt; &gt; appear in the Elev=\r\nenth International Conference on \n&gt; Articifial \n&gt; &gt; &gt; Life\n&gt; &gt; &gt; &gt; &gt; &gt; (ALI=\r\nFE XI), called &quot;Exploiting Open-Endedness to Solve \n&gt; Problems\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\nThrough the Search for Novelty.&quot;\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; The paper is here=\r\n:\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; http://eplex.cs.ucf.edu/publications.html#lehman=\r\n.alife08\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Direct link: \n&gt; http://eplex.cs.ucf.edu/p=\r\napers/lehman_alife08.pdf\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; This paper is about a new=\r\n kind of search (which works with \n&gt; &gt; &gt; NEAT) that\n&gt; &gt; &gt; &gt; &gt; &gt; abandons th=\r\ne longstanding notion in all of machine learning \n&gt; &gt; &gt; that the\n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; gradient of search should be measured with respect to the \n&gt; &gt; &gt; ultimate=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; objective.  In other words, it entirely abandons objectives \n&gt;=\r\n and\n&gt; &gt; &gt; &gt; &gt; &gt; thereby also abandons fitness functions as the impetus for=\r\n \n&gt; &gt; &gt; search.\n&gt; &gt; &gt; &gt; &gt; &gt; Yet remarkably, we still show that such an algo=\r\nrithm can \n&gt; perform\n&gt; &gt; &gt; &gt; &gt; &gt; *better* than one that actually tries to a=\r\nchieve the \n&gt; &gt; &gt; objective!  I\n&gt; &gt; &gt; &gt; &gt; &gt; believe this strange result has=\r\n fascinating implications \n&gt; for \n&gt; &gt; &gt; machine\n&gt; &gt; &gt; &gt; &gt; &gt; learning, artif=\r\nicial life, and even biology.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Lately on this forum=\r\n we have often discussed the nagging \n&gt; &gt; &gt; problem that\n&gt; &gt; &gt; &gt; &gt; &gt; the fi=\r\ntness function often does not properly recognize or \n&gt; &gt; &gt; reward the\n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; stepping stones on the way to the solution.  I went as far \n&gt; as\n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; suggesting that the fitness function can become an \n&gt; *obstacle* t=\r\no\n&gt; &gt; &gt; &gt; &gt; &gt; success (e.g. when we discussed creativity in Picbreeder).\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; While this discussion was largely philosophical, Joe=\r\nl \n&gt; Lehman \n&gt; &gt; &gt; and I\n&gt; &gt; &gt; &gt; &gt; &gt; decided to make it concrete and actual=\r\nly introduce an \n&gt; algorithm \n&gt; &gt; &gt; that\n&gt; &gt; &gt; &gt; &gt; &gt; makes an automated evo=\r\nlutionary process in *any* domain \n&gt; behave \n&gt; &gt; &gt; like\n&gt; &gt; &gt; &gt; &gt; &gt; humans =\r\nin Picbreeder, that is, like open-ended evolution.  \n&gt; This\n&gt; &gt; &gt; &gt; &gt; &gt; app=\r\nroach is called &quot;novelty search.&quot;  The algorithm simply \n&gt; &gt; &gt; searches\n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; for behavior that is novel with respect to what has come \n&gt; before=\r\n.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; The benefit of this approach is that it is immun=\r\ne to \n&gt; deception \n&gt; &gt; &gt; because\n&gt; &gt; &gt; &gt; &gt; &gt; it does not even try to achiev=\r\ne the objective.  I know it \n&gt; seems\n&gt; &gt; &gt; &gt; &gt; &gt; strange but, counterintuit=\r\nively, we show that in fact it is \n&gt; far \n&gt; &gt; &gt; more\n&gt; &gt; &gt; &gt; &gt; &gt; effective =\r\nat solving a difficult problem in a deceptive \n&gt; &gt; &gt; landscape than\n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; fitness-based search.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; In other words, what we=\r\n are saying is that to achieve some \n&gt; of \n&gt; &gt; &gt; the most\n&gt; &gt; &gt; &gt; &gt; &gt; ambit=\r\nious objectives we might have for evolution, we must \n&gt; &gt; &gt; abandon\n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; trying to explicitly achieve them.  To quote from the end \n&gt; of our\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; Discussion section:\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &quot;In summary, almost =\r\nlike a riddle, novelty search suggests\n&gt; &gt; &gt; &gt; &gt; &gt; a surprising new perspec=\r\ntive on achievement: To achieve\n&gt; &gt; &gt; &gt; &gt; &gt; your highest goals, you must be=\r\n willing to abandon them.&quot;\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; I believe this lesson i=\r\ns true in practice and is therefore \n&gt; &gt; &gt; beyond a\n&gt; &gt; &gt; &gt; &gt; &gt; philosophic=\r\nal curiosity.  In fact, we are instinctively \n&gt; &gt; &gt; familiar with\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; it in life in general when people say things like &quot;You are \n&gt; &gt; &gt; trying=\r\n too\n&gt; &gt; &gt; &gt; &gt; &gt; hard&quot; or when we focus so much on something so far ahead o=\r\nf \n&gt; us \n&gt; &gt; &gt; in life\n&gt; &gt; &gt; &gt; &gt; &gt; that we forget completely to solve the s=\r\nhort term problems \n&gt; that \n&gt; &gt; &gt; stand\n&gt; &gt; &gt; &gt; &gt; &gt; in our way.  It is no l=\r\ness true in evolution or search in \n&gt; &gt; &gt; general.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n For NEAT, novelty search should open up new opportunities \n&gt; for\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; discovery that were previously closed off to us.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; I look forward to hearing your thoughts on this work.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}