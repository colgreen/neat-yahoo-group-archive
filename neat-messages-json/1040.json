{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"fy97Ksj6QHVn7jUyqsPIPqHTtEXSaSVH6CNzb-vJKK2U6TT2x837UV1qSIDyoGsMfMh5TS24R1X_6h1U3SBhiDl8sQmSLUx_mg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Re: Computation Time","postDate":"1086732496","msgId":1040,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwQzYzOEQwLjEwNjA0MDJAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PGNhMzl2ays0djFhQGVHcm91cHMuY29tPg==","referencesHeader":"PGNhMzl2ays0djFhQGVHcm91cHMuY29tPg=="},"prevInTopic":1035,"nextInTopic":1067,"prevInTime":1039,"nextInTime":1041,"topicId":845,"numMessagesInTopic":99,"msgSnippet":"... Hi Philip, My curiosity got the better of me :) I tried the above functions using optimized C# on an AMD Athlon 2400+ (actually 2.17Ghz). The results are ","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 11324 invoked from network); 8 Jun 2004 22:08:22 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m23.grp.scd.yahoo.com with QMQP; 8 Jun 2004 22:08:22 -0000\r\nReceived: from unknown (HELO colossus.systems.pipex.net) (62.241.160.73)\n  by mta5.grp.scd.yahoo.com with SMTP; 8 Jun 2004 22:08:22 -0000\r\nReceived: from dsl.pipex.com (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby colossus.systems.pipex.net (Postfix) with ESMTP id 9C4341C00257\n\tfor &lt;neat@yahoogroups.com&gt;; Tue,  8 Jun 2004 23:08:16 +0100 (BST)\r\nMessage-ID: &lt;40C638D0.1060402@...&gt;\r\nDate: Tue, 08 Jun 2004 23:08:16 +0100\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;ca39vk+4v1a@...&gt;\r\nIn-Reply-To: &lt;ca39vk+4v1a@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.160.73\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Re: Computation Time\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nPhilip Tucker wrote:\n\n&gt;--- In neat@yahoogroups.com, &quot;zenguyuno&quot; &lt;zenguyuno@y...&gt; wrote:\n&gt;  \n&gt;\n&gt;&gt;Unless it&#39;s already been done!  Here is a ready-to-use sigmoid \n&gt;&gt;approximator in C, taken from the file neursubs.c of the EvSail \n&gt;&gt;package:\n&gt;&gt;\n&gt;&gt;/* This 4 piece curve is a good sigmoid approximator. */\n&gt;&gt;float sigAprox(register float x)  {\n&gt;&gt;    register float z;             \n&gt;&gt;    \n&gt;&gt;    if(x &lt;= -4.0)\n&gt;&gt;\treturn 0.0;\n&gt;&gt;    else if(x &lt;= 0.0) {\n&gt;&gt;        z = x + 4.0;\n&gt;&gt;        return z*z/32;\n&gt;&gt;    } \n&gt;&gt;    else if(x &lt; 4.0)  {\n&gt;&gt;        z = x - 4.0;\n&gt;&gt;        return 1.0 - z*z/32;   \n&gt;&gt;    }    \n&gt;&gt;    else\n&gt;&gt;\treturn 1.0;\n&gt;&gt;}    \n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;If anyone&#39;s interested, I just did an analysis of this function vs \n&gt;the traditional sigmoid, and the inverse absolute value function Ian \n&gt;posted earlier vs tanh.  I added a spread sheet \n&gt;(activation_functions.xls) to the files section comparing the \n&gt;values.  Here are the functions ...\n&gt;\n&gt;sigmoid:  y = 1 / ( 1 + EXP( -( x * 4.924273 ) ) )\n&gt;evsail:   &lt;see above&gt;\n&gt;tanh:     y = -1 + ( 2 / ( 1 + EXP( -2 * ( x ) ) ) )\n&gt;inv-abs:  y = x / ( 1 + ABS( x ) )\n&gt;\n&gt;... where EXP is exponential function (i.e., EXP(x) is e raised to \n&gt;the power of x) and ABS is absolute value.  We got the sigmoid and \n&gt;tanh functions from JOONE source (http://www.jooneworld.com/).\n&gt;\n&gt;I ran 2 million activations each with each one to compare \n&gt;performance.  This is all on my laptop (PIII, 850MHz, 256MB RAM) on \n&gt;JVM 1.4.  Results:\n&gt;\n&gt;- the EvSail sigmoid approximation was about 4 times faster than the \n&gt;traditional sigmoid; ~90ms vs ~360ms.\n&gt;- the inverse absolute value function was about 2.5 times faster \n&gt;than the traditional tanh; ~170ms vs ~400ms.\n&gt;\n&gt;I&#39;d be interested to know if similar performance benefits can be had \n&gt;in C, or any other languages.  I&#39;m also curious to know if there are \n&gt;any other pitfalls from using such approximation functions, or even \n&gt;simple step functions.  For example, is it crucial that the function \n&gt;be continuous?  I assume it is since the evolutionary algorithm is a \n&gt;form of hill climbing.  But, how smooth/steep is the optimal curve?  \n&gt;Or is it domain dependant?\n&gt;  \n&gt;\nHi Philip,\n\nMy curiosity got the better of me :) I tried the above functions using \noptimized C# on an AMD Athlon 2400+ (actually 2.17Ghz). The results are \nslightly bizarre,\n oh BTW I think you quoted the tanh function wrong, so I used y = \ntanh(0.9*x) which gives a nice sigmoid. Firstly I had to use 100 million \n(10^8) loops to get readable results, the approx. 50x difference is \npartly due to the CPU (obviously!) but maybe the rest is due to my \noversimplistic implementation whereby I used the same value for x every \ntime - did you generate random numbers perhaps? Also I know that Java \nhas JIT compilers but sometime only optimize in code hot-spots during \ncode execution, they can also run in interpreter mode - my run was with \nJITed code.\n\nHere are the figures:\n\nsigmoid:  3625ms\nevsail:    2359ms\ninv-abs:  188ms\ntanh:     12,400ms\n\nweird huh.  The tanh loop took 66x longer then the ins-abs one!\n\n\nNow to put all this into perspective 10^8 activations is a LOT. I just \nran a 53 node network with 413 connections (7.8 a node on avg.) and it \ntook 4700ms to do100,000 epochs. If you then add in the extra time for \nactivation functions this will be 53*100,000 = 5,300,000 activations. \nWhich in turn should take between 657ms (slowest fn) and 10ms(fastest) \nextra in total - for 100,000 epochs of what is quite a big network. In \nother words the activation fn is small beer! (well, in my code at least)\n\nSo then I tried to eek out a liitle more performance from my Network \ncode using some of the hints Ian has been posting - result... hardly any \nimprovement at all!  I wonder though if the technqiue of trying to do \nmany sequentail ops in order wll only become beneficial when the \nnetworks get *really* big, simply because the memory caches in modern \nCPU&#39;s are so large. So there may be some network size at which we would \nsee a dramatic slow down of our code if it&#39;s not optimized in such a way.\n\nAnother way of estimating how efficient my code is is to caclulate the \naverage number of clock cycles that it requires per neuron and \nconnection. So e.g. My 53 neuron / 413 connection network performs 413 \nadditions and 53 activations per epoch. So that&#39;s 466 necessary \noperations in all, this is an absolute minimum. ok, plus a couple \nbecause the activation fn is several operations (but this is just a \nrough bit of maths). Using a simple bit of maths I can then determine:\n\nops per epoch = 466\nops per test run = 466 * 100,000 (loops) = 46,600,000\nops per second = 46,600,000 / 5000ms(approx) = 9,320,000\nCPU clock cycles per op = 2.17Ghz / 9,320,000 = 232.\n\n\nNow 232 isn&#39;t all that bad when you consider this doesn&#39;t take into \naccount the extra code that is required to do the looping/indexing \nthrough all of the neurons and connections. So perhaps hand optimized \nassembler could get this down to 100 cylcles or maybe 50, but this is in \nthe same ball park as optimum - and therefore I wouldn&#39;t expect any \nmassive improvements. Well, not unless you start using SIMD \ninstructions, which I&#39;m definitely NOT! :)\n\nColin.\n\n\n"}}