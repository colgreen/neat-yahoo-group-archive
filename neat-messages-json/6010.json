{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":464818732,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"oK3HKNgCQQowM4CY_jMIQDk38JWKpBhFwVAHWSzIwKKTsEnYKyMiGtqqz1zsxdUedhSXrNevj312uyiBxJ9ZDo-fOyQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New paper on why modules evolve, and how to evolve modular artificial neural networks","postDate":"1361949201","msgId":6010,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEY3M0QyMkFGLTEwQkItNDYwOC05OENFLTJEQTBBREVBOUREN0B1d3lvLmVkdT4=","inReplyToHeader":"PGtnODgzaSticWlzQGVHcm91cHMuY29tPg==","referencesHeader":"PGtnODgzaSticWlzQGVHcm91cHMuY29tPg=="},"prevInTopic":6009,"nextInTopic":0,"prevInTime":6009,"nextInTime":6011,"topicId":5976,"numMessagesInTopic":30,"msgSnippet":"Hello Ken, Please see below. Note: I don t respond to everything you say if my reply would be something I ve already said (in this response or earlier). ... I","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 60654 invoked from network); 27 Feb 2013 07:13:35 -0000\r\nX-Received: from unknown (10.193.84.151)\n  by m5.grp.bf1.yahoo.com with QMQP; 27 Feb 2013 07:13:35 -0000\r\nX-Received: from unknown (HELO mail-pb0-f43.google.com) (209.85.160.43)\n  by mta5.grp.bf1.yahoo.com with SMTP; 27 Feb 2013 07:13:35 -0000\r\nX-Received: by mail-pb0-f43.google.com with SMTP id md12so193593pbc.30\n        for &lt;neat@yahoogroups.com&gt;; Tue, 26 Feb 2013 23:13:34 -0800 (PST)\r\nX-Received: by 10.68.56.232 with SMTP id d8mr1756368pbq.162.1361949214652;\n        Tue, 26 Feb 2013 23:13:34 -0800 (PST)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from [10.0.1.3] (host-69-146-94-113.lar-wy.client.bresnan.net. [69.146.94.113])\n        by mx.google.com with ESMTPS id g4sm4364805pax.4.2013.02.26.23.13.23\n        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);\n        Tue, 26 Feb 2013 23:13:30 -0800 (PST)\r\nContent-Type: multipart/alternative; boundary=&quot;Apple-Mail=_360DE789-E71E-4509-A97F-583F302EDB04&quot;\r\nMessage-Id: &lt;F73D22AF-10BB-4608-98CE-2DA0ADEA9DD7@...&gt;\r\nMime-Version: 1.0 (Mac OS X Mail 6.2 &#92;(1499&#92;))\r\nDate: Wed, 27 Feb 2013 00:13:21 -0700\r\nReferences: &lt;kg883i+bqis@...&gt;\r\nTo: neat users group group &lt;neat@yahoogroups.com&gt;\r\nIn-Reply-To: &lt;kg883i+bqis@...&gt;\r\nX-Mailer: Apple Mail (2.1499)\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nX-eGroups-From: Jeff Clune &lt;jeffclune@...&gt;\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] New paper on why modules evolve, and how to evolve modular artificial neural networks\r\nX-Yahoo-Group-Post: member; u=464818732; y=LUbuTU_OtrlFSP3LWiW03BVhHO2jMnaVcy3xBXN0Xu7wjdE6PLmV\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\n\r\n--Apple-Mail=_360DE789-E71E-4509-A97F-583F302EDB04\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/plain;\n\tcharset=windows-1252\r\n\r\nHello Ken,\n\nPlease see below. Note: I don&#39;t respond to everything you say i=\r\nf my reply would be something I&#39;ve already said (in this response or earlie=\r\nr). \n\n&gt;&gt; Nature doesn&#39;t have anything analogous either, which means there i=\r\ns at least some evidence that the &quot;fitness bias&quot; analogy with nature is not=\r\n lining up perfectly. You might point to the continuing existence of single=\r\n-celled organisms as something similar to the perpetual dead-weight in this=\r\n formulation, but they aren&#39;t really analogous because single-celled organi=\r\nsms are functional - they retain the ability to make copies of themselves a=\r\nnd continue to evolve in their own right - while the low-connectivity deadw=\r\neight maintains no capability whatsoever. On the other hand, suspiciously, =\r\nas in nature, nothing similar to such a deadweight niche is perpetuated by =\r\na biased encoding.\n&gt;&gt; \n&gt;&gt; \n&gt; That&#39;s also true, but that fault does not lie =\r\nwith the fitness cost concept, it lies with the fact that multi-objective a=\r\nlgorithms, which are the cause of the dead weight, do not perfectly analogi=\r\nze to nature. They&#39;re just better than a weighted sum for other reasons, bu=\r\nt the fitness cost concept could easily be implemented in a weighted sum fi=\r\ntness function and not have this dead weight issue.  \n&gt; \n&gt;&gt; Doesn&#39;t it seem=\r\n a little strange that the price we have to pay to obtain modular structure=\r\n is to maintain a perpetual dead pool of genetic junk? Note that it doesn&#39;t=\r\n suggest that such a system won&#39;t work in some cases, but it&#39;s inelegant en=\r\nough to raise questions about the best realization of the concept..\n&gt;&gt; \n&gt; \n=\r\n&gt; All I think that calls into question is the optimality of multi-objective=\r\n algorithms when you don&#39;t want the extreme of one objective. But that prob=\r\nlem almost always occurs in multi-objective algorithms, so your really indi=\r\ncting the whole field of MOEA instead of our approach of using a fitness pe=\r\nnalty instead of a biased encoding, no?\n&gt; \n&gt; No I don&#39;t think I&#39;m indicting=\r\n MOEAs in general.  The problem here is not some inherent problem with MOEA=\r\ns, but that MOEAs were not designed for the purpose for which you have borr=\r\nowed them.   MOEAs are designed to return a Pareto front given a number of =\r\nobjective trade-offs.  They are doing that perfectly well in your experimen=\r\nt.  It&#39;s just that your interest is not perfectly aligned with that design:=\r\n  Your interest is in the &quot;best tradeoff&quot; (which is inherently slippery to =\r\nformalize and not formalized by a traditional  MOEA), while some trade-offs=\r\n that MOEAs are by design made to preserve and elevate (such as total domin=\r\nance on low connectivity) are of almost no interest in this domain, as you&#39;=\r\nve agreed.  So my general critique of manipulating the fitness function has=\r\n nothing to do with MOEAs specifically.\n&gt; \n\nI still think you are indicting=\r\n all (or at least most) of MOEAs. In many applications (e.g. fitness and di=\r\nversity, or solving task A and task B), we&#39;re rarely interested in the very=\r\n extreme solutions that totally dominate on only one of the objectives. If =\r\nwe were interested in those organisms, we&#39;d just be rewarding performance o=\r\nn that task and not use MOEAs at all. I feel it is the same story with a co=\r\nnnection cost objective. \n\n&gt; Rather, what we are observing is simply the st=\r\nruggle to find some kind of expression of fitness that aligns with what you=\r\n actually want to see (and thereby incentivizes following the right path th=\r\nrough the search space).  And the fact that you settled on MOEAs as the bes=\r\nt option, and that they do not align all that well, just illustrates how na=\r\nsty this little problem of tweaking fitness really is.  \n&gt; \n&gt; You noted tha=\r\nt MOEAs are &quot;just better than a weighted sum for other reasons,&quot; but that&#39;s=\r\n exactly the problem.  Those &quot;other reasons&quot; are indeed unrelated to the pr=\r\noblem you are trying to solve here.  That is, MOEAs are a blunt kludge in t=\r\nhis particular context.  But although you defend fitness in general with th=\r\ne response that &quot;the fitness cost concept could easily be implemented in a =\r\nweighted sum fitness function and not have this dead weight issue,&quot; the pro=\r\nblem there is that you once again end up with similarly unnatural and incon=\r\ngruous implications:\n&gt; \n&gt; If you make fitness a weighted sum and one compon=\r\nent of that weighted sum is &quot;low connectivity,&quot; then there will *still* be =\r\na special eternally protected pocket for non-functional low-connectivity st=\r\nructure.  The reason is that if there is any progress on actually solving t=\r\nhe problem (aside from connectivity), then those networks that are moving t=\r\nowards solving it will be more connected than the lowest possible connectiv=\r\nity.  Very often, because of mutation, some of these more connected network=\r\ns will break, leading to an inevitable (and unavoidable) subpopulation  of =\r\nhigher-connectivity networks that are broken and nonfunctional.  Because of=\r\n this inevitable subset of failures in every generation, a great strategy f=\r\nor some of the population is to stay as minimally connected as possible whi=\r\nle ignoring functionality (just as in the MOEA) because they can be just ba=\r\nrely  &quot;good enough&quot; to keep perpetuating merely by their connectivity fitne=\r\nss bonus versus those who are more connected and also nonfunctional.\n&gt; \n&gt; N=\r\now you may then reason that there is some more complicated way to counterac=\r\nt this problem.  For example, you may say, well, we just need to be more st=\r\nrict about selection, so amp up selection pressure by blocking more of the =\r\npopulation from reproducing.  But you have no way to know a priori what tha=\r\nt threshold should be, so you are risking breaking evolution in other ways =\r\n(such as becoming too convergent) by wiping out diversity.  In fact, early =\r\nin evolution, when most structure is nonfunctional or less functional, that=\r\n could short circuit the  whole process.  \n&gt; \n\nAs I have said repeatedly, I=\r\n agree there are all sorts of nasty consequences and tricky issues when pic=\r\nking fitness functions: I just think those issues also exist with encodings=\r\n (and that fitness penalties are at least ever-influencing instead of ephem=\r\neral, as  initial encoding biases are). \n\n&gt; But I want to emphasize that my=\r\n point here has nothing to do with trying to figure out the right &quot;trick&quot; t=\r\no get fitness to actually align properly with what we want to see, or with =\r\nnatural evolution of modularity.  If you notice, when you begin to talk abo=\r\nut using probabilistic Pareto fronts or something like that, you are just p=\r\nlaying again the same &quot;let&#39;s tweak things around hoping to get it right&quot; ga=\r\nme.  And my point here is that that game is ultimately a game of futility. =\r\n Sure, in this very simply task (relative to finding a natural brain), virt=\r\nually anything will work even if it is radically out of whack with nature, =\r\nso you can convince yourself that this problem is possible to reconcile.  Y=\r\nou can convince yourself that with enough tweaking you&#39;ll just write down t=\r\nhe magic fitness/MOEA recipe that equals finding what you want.  But the se=\r\narch space is so incredibly complex that such a dream is virtually impossib=\r\nle.  Because if you think about it, as you make one tweak after another, as=\r\n you fix one unintended consequence with yet another trick, what you are ul=\r\ntimately doing is describing the path through the search space itself.  In =\r\nother words, the logical extension of such a process is simply to identify =\r\nall the stepping stones from all possible random starting points to the obj=\r\nective and give higher fitness for each step in the chain, a task akin to a=\r\npplied omnipotence.  You might as well just build the solution by hand in t=\r\nhat case, because you would know all the stepping stones to the solution an=\r\nyway.  So while these fitness tricks may work for now, while we play in mod=\r\nest playgrounds, there are big warning signs looming in the future.\n&gt; \n\nThi=\r\ns all sounds like a justification for novelty search vs. target-based searc=\r\nh, not an initial encoding bias vs. a bias via the fitness function. Everyt=\r\nhing you say seems to me to apply to biases in the encoding space too: you =\r\npick one bias to solve one problem, but that creates an unintended conseque=\r\nnce, so you pick another (and maybe a temporal order, so that the first bia=\r\ns solves your first problem and then the second kicks in), etc. You&#39;re play=\r\ning the same game, but just using different tools. \n\n&gt; We are in agreement =\r\nthat encodings matter.  Of course, that is part of why I&#39;m saying they&#39;re i=\r\nmportant.  But what I&#39;m really saying is that encodings are far better suit=\r\ned than fitness for the long haul, i.e. for doing something interesting ove=\r\nr millions of generations, largely *because* a good encoding can canalize. =\r\n The trick behind radically successful long-term evolution, in my view, is =\r\nto keep your options open.  You don&#39;t want to say X is clearly better than =\r\nY.  What you want to say is, if X and Y are fundamentally different, I want=\r\n to check both X and Y and see where each of them lead and follow both bran=\r\nches if both are interesting.  But furthermore, if some property of X prove=\r\ns helpful in leading it to all kinds of cool stuff (or the same for Y), the=\r\nn let&#39;s start preserving (i.e. canalizing) that property THEN, when we obse=\r\nrve its potential, rather than a priori from day one when we would have to =\r\nbe an omnipotent being to anticipate everything that might be useful.  And =\r\nonly encoding offers that possibility.  Fitness is all about making choices=\r\n about priorities long before you have any idea what the options are.  Enco=\r\nding with canalization is about giving evolution the choice to find the lev=\r\nel that&#39;s right for it.  There is nothing analogous to canalization in fitn=\r\ness.\n&gt; \n\nFitness causes canalization, so it determines what type of canaliz=\r\nation occurs. I think your argument does not fully embrace the important di=\r\nfference between short-term payoffs and long-term payoffs. If there is a sh=\r\nort-term fitness penalty by default for a property (e.g. modularity), but w=\r\ne know that modularity is beneficial in the long run, you simply will not g=\r\net canalization for modularity unless you change the default fitness penalt=\r\ny to a reward: in fact, you&#39;ll get the exact opposite (evolution will gain =\r\na bias against producing modular structures). Evolution does not have fores=\r\night. In this situation, how do you envision modularity to become canalized=\r\n? The easiest way to get such canalization is to change the fitness equatio=\r\nn so that properties that generate long-term evolvability are also rewarded=\r\n in the short-term (not just the initial generations, but in the short-term=\r\n throughout evolution). Note: I have some ideas for how evolution could can=\r\nalize things that pay off in the long-term when they don&#39;t in the short-ter=\r\nm, but they are just hypotheses at this point and remain unproven, and woul=\r\nd only occur in rare circumstances.\n\n&gt; Canalization is an intriguing issue =\r\nthat is not fully understood, but it does happen, clearly in nature, and ev=\r\nen in CPPNs.  For example, one cool experiment I tried informally on Picbre=\r\neder was to keep regenerating new populations from the same starting image =\r\nover and over again from both (1) a highly-evolved image and (2) a low-gene=\r\nration image.  Not surprisingly, the offspring of the highly-evolved image =\r\nwere significantly more consistent (based on my subjective perception) than=\r\n of the less-evolved one.  That&#39;s canalization in action, even in Picbreede=\r\nr.  By the way, applying an objective fitness function will undermine the p=\r\notential for canalization (with CPPNs or anything else) because of the tend=\r\nency of objectives to wreck the representation.  So fitness here has a huge=\r\n disadvantage as a tool for manipulation:  Not only does it offer no mechan=\r\nism remotely comparable to canalization, but it actually thwarts canalizati=\r\non in the encoding even if the encoding can do it.  It&#39;s like you keep whip=\r\nping evolution for losing modularity and it keeps paying the price without =\r\nevery really getting the idea fundamentally (i.e. through the encoding).\n&gt; =\r\n\n\nThere is always a fitness function, even in picbreeder and novelty search=\r\n. A fitness function does not have to be a static target. I love all of you=\r\nr work on novelty search and its implications for how to revolutionize sear=\r\nch and evolutionary algorithms, but there is no reason you can&#39;t hybridize =\r\na fitness penalty with those ideas (e.g. you could reward novelty but also =\r\nhave a connection cost). \n\n&gt; So this is why we want something like LEO wher=\r\ne modularity *can* evolve away to different degrees:  We want to make no a =\r\npriori assumptions about what must be correct in all generations, and inste=\r\nad allow evolution to try out everything.  And those things that lead to mo=\r\nre potential over time will become canalized, you can be confident, and the=\r\nrein evolution works its magic.  \n&gt; \n\nWith a constant fitness penalty by de=\r\nfault for modularity, the LEO bias towards short connections will disappear=\r\n over time. Just simulate the experiment in your head: do you really think =\r\nthat if there is a constant, default, short-term fitness reward for entangl=\r\nement/full-connectivity and you evolve networks for a billion years, HyperN=\r\nEAT will hang on to that bias for short encodings? It may for early generat=\r\nions, but very quickly it will go away. \n\n&gt; So while you are saying regardi=\r\nng the human head size that DNA perhaps *can* encode brains with high conne=\r\nctivity but that fitness is preventing it, I would say that DNA *in general=\r\n* perhaps can do that, but by now, long into the human lineage, these pseud=\r\no-modular structures are so deeply canalized that breaking out of that cana=\r\nl for the encoding would require herculean effort.  But that&#39;s beauty of en=\r\ncoding.\n\nAgreed. But it learned that canalization not because it served a l=\r\nong-term evolvability benefit, but because of the short-term fitness cost o=\r\nf having more connections (e.g. the cost of a larger head). I think this is=\r\n an example of a fitness penalty causing the canalization. \n\n&gt; \n&gt; \n&gt; That&#39;s=\r\n why I don&#39;t like the word bias as much when it comes to encoding.  I&#39;d thi=\r\nnk of it more as an option.  Evolution can try everything - preserve it in =\r\nsome lineages, to a less degree in others, and not at all in others still. =\r\n The ability to commit to subtlety is the magic here.  That&#39;s the smart str=\r\nategy - keep your options open but also have the chance to commit to an opt=\r\nion when it&#39;s working for you.  A single blunt bias imposed for a billion y=\r\nears (which is about closing off options) does not sound like a smart strat=\r\negy in a search space more astronomical than imagination itself.\n&gt; \n\nOption=\r\ns exist with fitness penalties too: you can pay the penalty in order to get=\r\n a higher ultimate fitness. In the face of a constant short-term penalty, a=\r\nnd without a counter-balancing fitness reward, evolution will quickly shut =\r\ndown options via canalization: so it will quickly learn for example to not =\r\nproduce modularity.  \n\n&gt; I think your view of evolution here is too linear =\r\n(as opposed to branching), which is why you tend to worry about things like=\r\n what is good in the short term or long term.  But the idea that you can im=\r\npose these blunt constraints on evolution for eternity fits with a linear p=\r\nerspective, so it makes sense if that&#39;s how you view it, as a kind of step-=\r\nby-step succession along a single chain.  But I think evolution in nature i=\r\ns not walking this single tightrope towards some kind of near-optimal ideal=\r\n, where all our effort needs to focus on not falling off the tightrope.   T=\r\nhat is a very objective view, and I think the evidence is pointing more and=\r\n more towards why that kind of perspective has been an impediment for us.  =\r\nBut I agree the conversation has been great and hope I made my points respe=\r\nctfully.   I realize we&#39;re wading into controversy and that reasonable mind=\r\ns can disagree here.\n&gt; \n\nYou assume that evolution will branch out and expl=\r\nore all these options even in the face of fitness penalties for that explor=\r\nation. But that is not how evolution works (it may be how novelty search wo=\r\nrks, of course, which is why you have had some interesting results showing =\r\nthat evolution can take a more long-term view with respect to mutation rate=\r\ns). Evolution will tend to not explore paths that have lower fitness than t=\r\nhe rest of the population, so you won&#39;t get the branching exploration you d=\r\nesire if there are default penalties for exploring certain areas.  \n\nMaybe =\r\nthis is another way to think about it: you really dislike fitness penalties=\r\n, but our work (and those before us) shows that there are all sorts of defa=\r\nult fitness penalties, such as the default short-term fitness penalty again=\r\nst modularity. So, you already have a fitness penalty built in, and thus al=\r\nl of the problems you describe crop up: all our paper shows is that we shou=\r\nld change the default fitness penalty to one more favorable to a property w=\r\ne care about for long-term evolvability, and voila=85.things work better. W=\r\nhat do you think of that framing of the issue? \n\nI totally agree with you t=\r\nhat we may be at a point where we understand each other&#39;s positions clearly=\r\n, and still respectfully disagree. :-)\n\n\nBest regards,\nJeff Clune\n\nAssistan=\r\nt Professor\nComputer Science\nUniversity of Wyoming\njeffclune@...\njeffc=\r\nlune.com\n\n\n\n\r\n--Apple-Mail=_360DE789-E71E-4509-A97F-583F302EDB04\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/html;\n\tcharset=windows-1252\r\n\r\n&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=3D&quot;Content-Type&quot; content=3D&quot;text/html charset=\r\n=3Dwindows-1252&quot;&gt;&lt;/head&gt;&lt;body style=3D&quot;word-wrap: break-word; -webkit-nbsp-=\r\nmode: space; -webkit-line-break: after-white-space; font-family: Times; fon=\r\nt-size: 14px; color: rgb(0, 0, 0); ; font-family: &#39;Times&#39;; font-size: 14px;=\r\n color: rgb( 0,  0,  0); &quot;&gt;&lt;span style=3D&quot;font-family: &#39;Times&#39;; font-size: =\r\n14px; color: rgb( 0,  0,  0)&quot;&gt;&lt;span style=3D&quot;font-family: &#39;Times&#39;; font-siz=\r\ne: 14px; color: rgb( 0,  0,  0)&quot;&gt;&lt;span style=3D&quot;font-family: &#39;Times&#39;; font-=\r\nsize: 14px; color: rgb( 0,  0,  0)&quot;&gt;Hello Ken,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Please se=\r\ne below. Note: I don&#39;t respond to everything you say if my reply would be s=\r\nomething I&#39;ve already said (in this response or earlier).&nbsp;&lt;br&gt;&lt;div app=\r\nle-content-edited=3D&quot;true&quot;&gt;\n&lt;span style=3D&quot;font-family: &#39;Times&#39;; font-size:=\r\n 14px; color: rgb( 0,  0,  0)&quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-fami=\r\nly: Times; font-style: normal; font-variant: normal; font-weight: normal; l=\r\netter-spacing: normal; line-height: normal; orphans: 2; text-align: -webkit=\r\n-auto; text-indent: 0px; text-transform: none; white-space: normal; widows:=\r\n 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-=\r\nwidth: 0px; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-b=\r\nreak: after-white-space; &quot;&gt;&lt;span style=3D&quot;font-family: Times; color: rgb(0,=\r\n 0, 0); &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-style=\r\n: normal; font-variant: normal; font-weight: normal; letter-spacing: normal=\r\n; line-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0=\r\npx; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px=\r\n; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; word-wrap=\r\n: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-spa=\r\nce; &quot;&gt;&lt;span style=3D&quot;font-family: Times; color: rgb(0, 0, 0); &quot;&gt;&lt;div style=\r\n=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-style: normal; font-varia=\r\nnt: normal; font-weight: normal; letter-spacing: normal; line-height: norma=\r\nl; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: =\r\nnone; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-=\r\nadjust: auto; -webkit-text-stroke-width: 0px; word-wrap: break-word; -webki=\r\nt-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span style=3D=\r\n&quot;font-family: Times; color: rgb(0, 0, 0); &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, =\r\n0); font-family: Times; font-style: normal; font-variant: normal; font-weig=\r\nht: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-a=\r\nlign: -webkit-auto; text-indent: 0px; text-transform: none; white-space: no=\r\nrmal; widows: 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit=\r\n-text-stroke-width: 0px; word-wrap: break-word; -webkit-nbsp-mode: space; -=\r\nwebkit-line-break: after-white-space; &quot;&gt;&lt;span style=3D&quot;font-family: Times; =\r\ncolor: rgb(0, 0, 0); &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Time=\r\ns; font-style: normal; font-variant: normal; font-weight: normal; letter-sp=\r\nacing: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; t=\r\next-indent: 0px; text-transform: none; white-space: normal; widows: 2; word=\r\n-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0=\r\npx; word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: af=\r\nter-white-space; &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Times; f=\r\nont-style: normal; font-variant: normal; font-weight: normal; letter-spacin=\r\ng: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-=\r\nindent: 0px; text-transform: none; white-space: normal; widows: 2; word-spa=\r\ncing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; =\r\nword-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-=\r\nwhite-space; &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-=\r\nstyle: normal; font-variant: normal; font-weight: normal; letter-spacing: n=\r\normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-inde=\r\nnt: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing=\r\n: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; word=\r\n-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-whit=\r\ne-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;border-collapse: separ=\r\nate; color: rgb(0, 0, 0); font-family: Times; font-style: normal; font-vari=\r\nant: normal; font-weight: normal; letter-spacing: normal; line-height: norm=\r\nal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform:=\r\n none; white-space: normal; widows: 2; word-spacing: 0px; border-spacing: 0=\r\npx; -webkit-text-decorations-in-effect: none; -webkit-text-size-adjust: aut=\r\no; -webkit-text-stroke-width: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -=\r\nwebkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span cla=\r\nss=3D&quot;Apple-style-span&quot; style=3D&quot;border-collapse: separate; color: rgb(0, 0=\r\n, 0); font-family: Times; font-style: normal; font-variant: normal; font-we=\r\night: normal; letter-spacing: normal; line-height: normal; orphans: 2; text=\r\n-align: -webkit-auto; text-indent: 0px; text-transform: none; white-space: =\r\nnormal; widows: 2; word-spacing: 0px; border-spacing: 0px; -webkit-text-dec=\r\norations-in-effect: none; -webkit-text-size-adjust: auto; -webkit-text-stro=\r\nke-width: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: sp=\r\nace; -webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-sp=\r\nan&quot; style=3D&quot;border-collapse: separate; color: rgb(0, 0, 0); font-variant: =\r\nnormal; letter-spacing: normal; line-height: normal; orphans: 2; text-align=\r\n: -webkit-auto; text-indent: 0px; text-transform: none; white-space: normal=\r\n; widows: 2; word-spacing: 0px; border-spacing: 0px; -webkit-text-decoratio=\r\nns-in-effect: none; -webkit-text-size-adjust: auto; -webkit-text-stroke-wid=\r\nth: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -=\r\nwebkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; st=\r\nyle=3D&quot;border-collapse: separate; color: rgb(0, 0, 0); font-variant: normal=\r\n; letter-spacing: normal; line-height: normal; orphans: 2; text-align: -web=\r\nkit-auto; text-indent: 0px; text-transform: none; white-space: normal; wido=\r\nws: 2; word-spacing: 0px; border-spacing: 0px; -webkit-text-decorations-in-=\r\neffect: none; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0p=\r\nx; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -webkit=\r\n-line-break: after-white-space; &quot;&gt;&lt;br class=3D&quot;Apple-interchange-newline&quot;&gt;&lt;=\r\n/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span=\r\n&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;blockquote=\r\n type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position=\r\n: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relativ=\r\ne;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;block=\r\nquote&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 25=\r\n5, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;Nature doesn&#39;t have anything analogo=\r\nus either, which means there is at \nleast some evidence that the &quot;fitness b=\r\nias&quot; analogy with nature is not \nlining up perfectly. You might point to th=\r\ne continuing existence of \nsingle-celled organisms as something similar to =\r\nthe perpetual \ndead-weight in this formulation, but they aren&#39;t really anal=\r\nogous \nbecause single-celled organisms are functional - they retain the abi=\r\nlity\n to make copies of themselves and continue to evolve in their own righ=\r\nt -\n while the low-connectivity deadweight maintains no capability \nwhatsoe=\r\nver. On the other hand, suspiciously, as in nature, nothing \nsimilar to suc=\r\nh a deadweight niche is perpetuated by a biased encoding.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div=\r\n&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;That&#39;s also true, but \nthat fault does=\r\n not lie with the fitness cost concept, it lies with the \nfact that multi-o=\r\nbjective algorithms, which are the cause of the dead \nweight, do not perfec=\r\ntly analogize to nature. They&#39;re just better than a\n weighted sum for other=\r\n reasons, but the fitness cost concept could \neasily be implemented in a we=\r\nighted sum fitness function and not have \nthis dead weight issue. &nbsp;&lt;/d=\r\niv&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 2=\r\n55, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-msg&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nDoesn&#39;t it seem a little strange th=\r\nat the price we have to pay to obtain\n modular structure is to maintain a p=\r\nerpetual dead pool of genetic junk?\n Note that it doesn&#39;t suggest that such=\r\n a system won&#39;t work in some \ncases, but it&#39;s inelegant enough to raise que=\r\nstions about the best \nrealization of the concept..&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/di=\r\nv&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All\n I think that calls into quest=\r\nion is the optimality of multi-objective \nalgorithms when you don&#39;t want th=\r\ne extreme of one objective. But that \nproblem almost always occurs in multi=\r\n-objective algorithms, so your \nreally indicting the whole field of MOEA in=\r\nstead of our approach of \nusing a fitness penalty instead of a biased encod=\r\ning, no?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;No I don&#39;t think I&#39;m indicting MO=\r\nEAs in general.&nbsp; The problem here is not some inherent problem with MO=\r\nEAs, but that MOEAs were not designed for the purpose for which you have bo=\r\nrrowed them.&nbsp;&nbsp; MOEAs are designed to return a Pareto front given =\r\na number of objective trade-offs.&nbsp; They are doing that perfectly well =\r\nin your experiment.&nbsp; It&#39;s just that your interest is not perfectly ali=\r\ngned with that design:&nbsp; Your interest is in the &quot;best tradeoff&quot; (which=\r\n is inherently slippery to formalize and not formalized by a traditional&nb=\r\nsp; MOEA), while some trade-offs that MOEAs are by design made to preserve =\r\nand elevate (such as total dominance on low connectivity) are of almost no =\r\ninterest in this domain, as you&#39;ve agreed.&nbsp; So my general critique of =\r\nmanipulating the fitness function has nothing to do with MOEAs specifically=\r\n.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I still t=\r\nhink you are indicting all (or at least most) of MOEAs. In many application=\r\ns (e.g. fitness and diversity, or solving task A and task B), we&#39;re rarely =\r\ninterested in the very extreme solutions that totally dominate on only one =\r\nof the objectives. If we were interested in those organisms, we&#39;d just be r=\r\newarding performance on that task and not use MOEAs at all. I feel it is th=\r\ne same story with a connection cost objective.&nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote t=\r\nype=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: =\r\nstatic; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;=\r\n&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;Rather, =\r\nwhat we are observing is simply the struggle to find some kind of expressio=\r\nn of fitness that aligns with what you actually want to see (and thereby in=\r\ncentivizes following the right path through the search space).&nbsp; And th=\r\ne fact that you settled on MOEAs as the best option, and that they do not a=\r\nlign all that well, just illustrates how nasty this little problem of tweak=\r\ning fitness really is.&nbsp; &lt;br&gt;&lt;br&gt;You noted that MOEAs are &quot;just better =\r\nthan a\n weighted sum for other reasons,&quot; but that&#39;s exactly the problem.&nb=\r\nsp; Those &quot;other reasons&quot; are indeed unrelated to the problem you are tryin=\r\ng to solve here.&nbsp; That is, MOEAs are a blunt kludge in this particular=\r\n context.&nbsp; But although you defend fitness in general with the respons=\r\ne that &quot;the fitness cost concept could \neasily be implemented in a weighted=\r\n sum fitness function and not have \nthis dead weight issue,&quot; the problem th=\r\nere is that you once again end up with similarly unnatural and incongruous =\r\nimplications:&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;blockquote type=\r\n=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: sta=\r\ntic; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;=\r\ndiv id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;If you make=\r\n fitness a weighted sum and one component of that weighted sum is &quot;low conn=\r\nectivity,&quot; then there will *still* be a special eternally protected pocket =\r\nfor non-functional low-connectivity structure.&nbsp; The reason is that if =\r\nthere is any progress on actually solving the problem (aside from connectiv=\r\nity), then those networks that are moving towards solving it will be more c=\r\nonnected than the lowest possible connectivity.&nbsp; Very often, because o=\r\nf mutation, some of these more connected networks will break, leading to an=\r\n inevitable (and unavoidable) subpopulation&nbsp; of higher-connectivity ne=\r\ntworks that are broken and nonfunctional.&nbsp; Because of this inevitable =\r\nsubset of failures in every generation, a great strategy for some of the po=\r\npulation is to stay as minimally connected as possible while ignoring funct=\r\nionality (just as in the MOEA) because they can be just barely&nbsp; &quot;good =\r\nenough&quot; to keep perpetuating merely by their connectivity fitness bonus ver=\r\nsus those who are more connected and also nonfunctional.&lt;br&gt;&lt;br&gt;Now you may=\r\n then reason that there is some more complicated way to counteract this pro=\r\nblem.&nbsp; For example, you may say, well, we just need to be more strict =\r\nabout selection, so amp up selection pressure by blocking more of the popul=\r\nation from reproducing.&nbsp; But you have no way to know a priori what tha=\r\nt threshold should be, so you are risking breaking evolution in other ways =\r\n(such as becoming too convergent) by wiping out diversity.&nbsp; In fact, e=\r\narly in evolution, when most structure is nonfunctional or less functional,=\r\n that could short circuit the&nbsp; whole process.&nbsp; &lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/di=\r\nv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As I have said repeatedly, I=\r\n agree there are all sorts of nasty consequences and tricky issues when pic=\r\nking fitness functions: I just think those issues also exist with encodings=\r\n (and that fitness penalties are at least ever-influencing instead of ephem=\r\neral, as &nbsp;initial encoding biases are).&nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote typ=\r\ne=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: st=\r\natic; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;=\r\n&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;But I want=\r\n to emphasize that my point here has nothing to do with trying to figure ou=\r\nt the right &quot;trick&quot; to get fitness to actually align properly with what we =\r\nwant to see, or with natural evolution of modularity.&nbsp; If you notice, =\r\nwhen you begin to talk about using probabilistic Pareto fronts or something=\r\n like that, you are just playing again the same &quot;let&#39;s tweak things around =\r\nhoping to get it right&quot; game.&nbsp; And my point here is that that game is =\r\nultimately a game of futility.&nbsp; Sure, in this very simply task (relati=\r\nve to finding a natural brain), virtually anything will work even if it is =\r\nradically out of whack with nature, so you can convince yourself that this =\r\nproblem is possible to reconcile.&nbsp; You can convince yourself that with=\r\n enough tweaking you&#39;ll just write down the magic fitness/MOEA recipe that =\r\nequals finding what you want.&nbsp; But the search space is so incredibly c=\r\nomplex that such a dream is virtually impossible.&nbsp; Because if you thin=\r\nk about it, as you make one tweak after another, as you fix one unintended =\r\nconsequence with yet another trick, what you are ultimately doing is descri=\r\nbing the path through the search space itself.&nbsp; In other words, the lo=\r\ngical extension of such a process is simply to identify all the stepping st=\r\nones from all possible random starting points to the objective and give hig=\r\nher fitness for each step in the chain, a task akin to applied omnipotence.=\r\n&nbsp; You might as well just build the solution by hand in that case, beca=\r\nuse you would know all the stepping stones to the solution anyway.&nbsp; So=\r\n while these fitness tricks may work for now, while we play in modest playg=\r\nrounds, there are big warning signs looming in the future.&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/di=\r\nv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This all sounds =\r\nlike a justification for novelty search vs. target-based search, not an ini=\r\ntial encoding bias vs. a bias via the fitness function. Everything you say =\r\nseems to me to apply to biases in the encoding space too: you pick one bias=\r\n to solve one problem, but that creates an unintended consequence, so you p=\r\nick another (and maybe a temporal order, so that the first bias solves your=\r\n first problem and then the second kicks in), etc. You&#39;re playing the same =\r\ngame, but just using different tools.&nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;ci=\r\nte&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: static; z=\r\n-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;We are in agreeme=\r\nnt that encodings matter.&nbsp; Of course, that is part of why I&#39;m saying t=\r\nhey&#39;re important.&nbsp; But what I&#39;m really saying is that encodings are fa=\r\nr better suited than fitness for the long haul, i.e. for doing something in=\r\nteresting over millions of generations, largely *because* a good encoding c=\r\nan canalize.&nbsp; The trick behind radically successful long-term evolutio=\r\nn, in my view, is to keep your options open.&nbsp; You don&#39;t want to say X =\r\nis clearly better than Y.&nbsp; What you want to say is, if X and Y are fun=\r\ndamentally different, I want to check both X and Y and see where each of th=\r\nem lead and follow both branches if both are interesting.&nbsp; But further=\r\nmore, if some property of X proves helpful in leading it to all kinds of co=\r\nol stuff (or the same for Y), then let&#39;s start preserving (i.e. canalizing)=\r\n that property THEN, when we observe its potential, rather than a priori fr=\r\nom day one when we would have to be an omnipotent being to anticipate every=\r\nthing that might be useful.&nbsp; And only encoding offers that possibility=\r\n.&nbsp; Fitness is all about making choices about priorities long before yo=\r\nu have any idea what the options are.&nbsp; Encoding with canalization is a=\r\nbout giving evolution the choice to find the level that&#39;s right for it.&nbs=\r\np; There is nothing analogous to canalization in fitness.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/di=\r\nv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Fitness causes canalization,=\r\n so it determines what type of canalization occurs. I think your argument d=\r\noes not fully embrace the important difference between short-term payoffs a=\r\nnd long-term payoffs. If there is a short-term fitness penalty by default f=\r\nor a property (e.g. modularity), but we know that modularity is beneficial =\r\nin the long run, you simply will not get canalization for modularity unless=\r\n you change the default fitness penalty to a reward: in fact, you&#39;ll get th=\r\ne exact opposite (evolution will gain a bias &lt;i&gt;against&lt;/i&gt; producing modul=\r\nar structures). Evolution does not have foresight. In this situation, how d=\r\no you envision modularity to become canalized? The easiest way to get such =\r\ncanalization is to change the fitness equation so that properties that gene=\r\nrate long-term evolvability are also rewarded in the short-term (not just t=\r\nhe initial generations, but in the short-term throughout evolution). Note: =\r\nI have some ideas for how evolution could canalize things that pay off in t=\r\nhe long-term when they don&#39;t in the short-term, but they are just hypothese=\r\ns at this point and remain unproven, and would only occur in rare circumsta=\r\nnces.&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rg=\r\nb(255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot;=\r\n style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;d=\r\niv id=3D&quot;ygrp-text&quot;&gt;Canalization is an intriguing issue that is not fully u=\r\nnderstood, but it does happen, clearly in nature, and even in CPPNs.&nbsp; =\r\nFor example, one cool experiment I tried informally on Picbreeder was to ke=\r\nep regenerating new populations from the same starting image over and over =\r\nagain from both (1) a highly-evolved image and (2) a low-generation image.&=\r\nnbsp; Not surprisingly, the offspring of the highly-evolved image were sign=\r\nificantly more consistent (based on my subjective perception) than of the l=\r\ness-evolved one.&nbsp; That&#39;s canalization in action, even in Picbreeder.&n=\r\nbsp; By the way, applying an objective fitness function will undermine the =\r\npotential for canalization (with CPPNs or anything else) because of the ten=\r\ndency of objectives to wreck the representation.&nbsp; So fitness here has =\r\na huge disadvantage as a tool for manipulation:&nbsp; Not only does it offe=\r\nr no mechanism remotely comparable to canalization, but it actually thwarts=\r\n canalization in the encoding even if the encoding can do it.&nbsp; It&#39;s li=\r\nke you keep whipping evolution for losing modularity and it keeps paying th=\r\ne price without every really getting the idea fundamentally (i.e. through t=\r\nhe encoding).&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;d=\r\niv&gt;There is always a fitness function, even in picbreeder and novelty searc=\r\nh. A fitness function does not have to be a static target. I love all of yo=\r\nur work on novelty search and its implications for how to revolutionize sea=\r\nrch and evolutionary algorithms, but there is no reason you can&#39;t hybridize=\r\n a fitness penalty with those ideas (e.g. you could reward novelty but also=\r\n have a connection cost).&nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div sty=\r\nle=3D&quot;background-color: rgb(255, 255, 255); position: static; z-index: auto=\r\n; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg=\r\n&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;So this is why we want someth=\r\ning like LEO where modularity *can* evolve away to different degrees:&nbsp;=\r\n We want to make no a priori assumptions about what must be correct in all =\r\ngenerations, and instead allow evolution to try out everything.&nbsp; And t=\r\nhose things that lead to more potential over time will become canalized, yo=\r\nu can be confident, and therein evolution works its magic.&nbsp; &lt;br&gt;&lt;br&gt;&lt;/=\r\ndiv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;With a constant fitn=\r\ness penalty by default for modularity, the LEO bias towards short connectio=\r\nns will disappear over time. Just simulate the experiment in your head: do =\r\nyou really think that if there is a constant, default, short-term fitness r=\r\neward for entanglement/full-connectivity and you evolve networks for a bill=\r\nion years, HyperNEAT will hang on to that bias for short encodings? It may =\r\nfor early generations, but very quickly it will go away.&nbsp;&lt;/div&gt;&lt;br&gt;&lt;bl=\r\nockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); =\r\nposition: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position=\r\n:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text=\r\n&quot;&gt;So while you are saying regarding the human head size that DNA perhaps *c=\r\nan* encode brains with high connectivity but that fitness is preventing it,=\r\n I would say that DNA *in general* perhaps can do that, but by now, long in=\r\nto the human lineage, these pseudo-modular structures are so deeply canaliz=\r\ned that breaking out of that canal for the encoding would require herculean=\r\n effort.&nbsp; But that&#39;s beauty of encoding.&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/=\r\nblockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;Agreed. But it learned that canalization not beca=\r\nuse it served a long-term evolvability benefit, but because of the short-te=\r\nrm fitness cost of having more connections (e.g. the cost of a larger head)=\r\n. I think this is an example of a fitness penalty causing the canalization.=\r\n&nbsp;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-col=\r\nor: rgb(255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-=\r\nmlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: =\r\n1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;=\r\nThat&#39;s why I don&#39;t like the word bias as much when it comes to encoding.&nb=\r\nsp; I&#39;d think of it more as an option.&nbsp; Evolution can try everything -=\r\n preserve it in some lineages, to a less degree in others, and not at all i=\r\nn others still.&nbsp; The ability to commit to subtlety is the magic here.&=\r\nnbsp; That&#39;s the smart strategy - keep your options open but also have the =\r\nchance to commit to an option when it&#39;s working for you.&nbsp; A single blu=\r\nnt bias imposed for a billion years (which is about closing off options) do=\r\nes not sound like a smart strategy in a search space more astronomical than=\r\n imagination itself.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div=\r\n&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Options exist with fitness penalties too: you can pay the p=\r\nenalty in order to get a higher ultimate fitness. In the face of a constant=\r\n short-term penalty, and without a counter-balancing fitness reward, evolut=\r\nion will quickly shut down options via canalization: so it will quickly lea=\r\nrn for example to not produce modularity. &nbsp;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;block=\r\nquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); pos=\r\nition: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:re=\r\nlative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;I=\r\n think your view of evolution here is too linear (as opposed to branching),=\r\n which is why you tend to worry about things like what is good in the short=\r\n term or long term.&nbsp; But the idea that you can impose these blunt cons=\r\ntraints on evolution for eternity fits with a linear perspective, so it mak=\r\nes sense if that&#39;s how you view it, as a kind of step-by-step succession al=\r\nong a single chain.&nbsp; But I think evolution in nature is not walking th=\r\nis single tightrope towards some kind of near-optimal ideal, where all our =\r\neffort needs to focus on not falling off the tightrope. &nbsp; That is a ve=\r\nry objective view, and I think the evidence is pointing more and more towar=\r\nds why that kind of perspective has been an impediment for us.&nbsp; But I =\r\nagree the conversation has been great and hope I made my points respectfull=\r\ny.&nbsp;&nbsp; I realize we&#39;re wading into controversy and that reasonable =\r\nminds can disagree here.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;=\r\nbr&gt;&lt;/div&gt;&lt;div&gt;You assume that evolution will branch out and explore all the=\r\nse options even in the face of fitness penalties for that exploration. But =\r\nthat is not how evolution works (it may be how novelty search works, of cou=\r\nrse, which is why you have had some interesting results showing that evolut=\r\nion can take a more long-term view with respect to mutation rates). Evoluti=\r\non will tend to not explore paths that have lower fitness than the rest of =\r\nthe population, so you won&#39;t get the branching exploration you desire if th=\r\nere are default penalties for exploring certain areas. &nbsp;&lt;/div&gt;&lt;div&gt;&lt;br=\r\n&gt;&lt;/div&gt;&lt;div&gt;Maybe this is another way to think about it: you really dislike=\r\n fitness penalties, but our work (and those before us) shows that there are=\r\n all sorts of default fitness penalties, such as the default short-term fit=\r\nness penalty against modularity. So, you already have a fitness penalty bui=\r\nlt in, and thus all of the problems you describe crop up: all our paper sho=\r\nws is that we should change the default fitness penalty to one more favorab=\r\nle to a property we care about for long-term evolvability, and voila=85.thi=\r\nngs work better. What do you think of that framing of the issue?&nbsp;&lt;/div=\r\n&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I totally agree with you that we may be at a point whe=\r\nre we understand each other&#39;s positions clearly, and still respectfully dis=\r\nagree. :-)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div apple-content-edite=\r\nd=3D&quot;true&quot; style=3D&quot;font-size: medium; &quot;&gt;&lt;span style=3D&quot;font-size: 14px; &quot;&gt;=\r\n&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line=\r\n-break: after-white-space; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-n=\r\nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div style=3D&quot;wor=\r\nd-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-whi=\r\nte-space; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; =\r\n-webkit-line-break: after-white-space; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-wor=\r\nd; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div =\r\nstyle=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-brea=\r\nk: after-white-space; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-m=\r\node: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-s=\r\ntyle-span&quot; style=3D&quot;border-collapse: separate; border-spacing: 0px; &quot;&gt;&lt;div =\r\nstyle=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-brea=\r\nk: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;border-co=\r\nllapse: separate; border-spacing: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-wor=\r\nd; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span=\r\n class=3D&quot;Apple-style-span&quot; style=3D&quot;border-collapse: separate; border-spac=\r\ning: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; =\r\n-webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; s=\r\ntyle=3D&quot;border-collapse: separate; border-spacing: 0px; &quot;&gt;&lt;div style=3D&quot;wor=\r\nd-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-whi=\r\nte-space; &quot;&gt;Best regards,&lt;br&gt;&lt;font class=3D&quot;Apple-style-span&quot; color=3D&quot;#0a5=\r\nd19&quot;&gt;&lt;b&gt;Jeff Clune&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;br&gt;Assistant Professor&lt;br&gt;Computer Scienc=\r\ne&lt;/div&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -webk=\r\nit-line-break: after-white-space; &quot;&gt;University of Wyoming&lt;br&gt;&lt;a href=3D&quot;mai=\r\nlto:jeffclune@...&quot;&gt;jeffclune@...&lt;/a&gt;&lt;br&gt;jeffclune.com&lt;/div&gt;&lt;div&gt;&lt;=\r\nbr&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/=\r\ndiv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/s=\r\npan&gt;\n&lt;/span&gt;\n&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;\n\r\n--Apple-Mail=_360DE789-E71E-4509-A97F-583F302EDB04--\r\n\n"}}