{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"E2OPk64nxedHysyiAlGyWA2Cm-EaqIDtaj2Bs45HyKc3PS5mLzVJWMCBrc07bn--J4nPCphqCObEcPTkL5BL2cauYxOjiECw_dd8Pl4dAeFJx9XzU34","spamInfo":{"isSpam":false,"reason":"6"},"subject":"RE : [neat] Re: HyperNEAT: Creating Neural Networks with CPPNs","postDate":"1174999208","msgId":3042,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV1YjNiOCtvZjRpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDY5MjgzOS43MzU3MC5xbUB3ZWI1NzAxNS5tYWlsLnJlMy55YWhvby5jb20+"},"prevInTopic":3041,"nextInTopic":3043,"prevInTime":3041,"nextInTime":3043,"topicId":3028,"numMessagesInTopic":34,"msgSnippet":"Hi, thanks for the quick response, But I know that the CPPN is used like a genome for the big network, and the CPPNs evolve with the NEAT method. I was just","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 35346 invoked from network); 27 Mar 2007 12:41:10 -0000\r\nReceived: from unknown (66.218.66.68)\n  by m46.grp.scd.yahoo.com with QMQP; 27 Mar 2007 12:41:10 -0000\r\nReceived: from unknown (HELO n9b.bullet.sp1.yahoo.com) (69.147.64.101)\n  by mta11.grp.scd.yahoo.com with SMTP; 27 Mar 2007 12:41:10 -0000\r\nReceived: from [216.252.122.218] by n9.bullet.sp1.yahoo.com with NNFMP; 27 Mar 2007 12:40:10 -0000\r\nReceived: from [66.218.69.1] by t3.bullet.sp1.yahoo.com with NNFMP; 27 Mar 2007 12:40:10 -0000\r\nReceived: from [66.218.66.86] by t1.bullet.scd.yahoo.com with NNFMP; 27 Mar 2007 12:40:10 -0000\r\nDate: Tue, 27 Mar 2007 12:40:08 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;eub3b8+of4i@...&gt;\r\nIn-Reply-To: &lt;692839.73570.qm@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: RE : [neat] Re: HyperNEAT: Creating Neural Networks with CPPNs\r\nX-Yahoo-Group-Post: member; u=283334584; y=hziNdZKxiMgpqe9fK9aGKkgF8cbATshW-kQY7efvI7lQqOrDvwgc0Xf1lQ\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi, thanks for the quick response, \nBut I know that the CPPN is used like a=\r\n &quot;genome&quot; for the big network, \nand the CPPNs evolve with the NEAT method. =\r\nI was just wondering why \nso big phenotypes at first? Does it really matter=\r\n? I know that the \nfitness function tells me which genome is better, but co=\r\nnsider some \nsimple task.. like the &quot;go to the food&quot; one.. \nCan this method=\r\n be applied succesfuly where direct encodings like the \noriginal NEAT perfo=\r\nrm best? \nCan HyperNEAT be extended so it can alter the substrate (like add=\r\ning \nmore neurons), just like the original NEAT alters the search space by =\r\n\nadding more nodes and connections?\n\nPeter.\n\n--- In neat@yahoogroups.com, A=\r\nlexandre Devert &lt;marmakoide@...&gt; wrote:\n&gt;\n&gt; Hi\n&gt;  Here the phenotype is the=\r\n million connections neural\n&gt; network, but the genotype is a much more simp=\r\nle,\n&gt; initialy minimal CPNN. Additive mutations acts on the\n&gt; CPNN. So ther=\r\ne is any violations of the NEAT\n&gt; philosophy : minimal genotype with well c=\r\nonceived\n&gt; mutations. Of course, small modifications of the CPNN\n&gt; lead to =\r\nhuge modifications in the target phenotype, as\n&gt; in all compact neural netw=\r\norks encodings like cellular\n&gt; encoding. The HyperNEAT seems to be a new st=\r\nep in this\n&gt; familly of encodings :D\n&gt; \n&gt; The hidden nodes of the genotype =\r\n(the CPNN) are added\n&gt; by NEAT as usual. The hidden nodes of the phenotype\n=\r\n&gt; (the jumbo sized neural network) are never added, it&#39;s\n&gt; up to the substr=\r\nate conception to provide enought\n&gt; neurons. The HyperNEAT allows to put th=\r\nousands of\n&gt; neurons, so we can be generous with the substrate.\n&gt; \n&gt; --- pe=\r\ntar_chervenski &lt;petar_chervenski@...&gt; a\n&gt; =E9crit :\n&gt; \n&gt; &gt; Hi, \n&gt; &gt; a have =\r\na quiestion about this.. The evolution in\n&gt; &gt; this indirect method \n&gt; &gt; evo=\r\nlves the geometry of the connections, right? But\n&gt; &gt; even in the first \n&gt; &gt;=\r\n population there may be phenotypes with millions of\n&gt; &gt; connections. Does =\r\n\n&gt; &gt; this violate the third principle of NEAT, that\n&gt; &gt; initial genomes mus=\r\nt \n&gt; &gt; be as small as possible? \n&gt; &gt; What about hidden nodes? In this appro=\r\nach, a set of\n&gt; &gt; nodes has to be \n&gt; &gt; chosen and the evolution then evolve=\r\ns only the\n&gt; &gt; connections between \n&gt; &gt; them. There are no additive mutatio=\r\nns for nodes and\n&gt; &gt; stuff. \n&gt; &gt; I know that the inner workings of this sys=\r\ntem is\n&gt; &gt; NEAT, starting \n&gt; &gt; minimally and so on, but when we look at the=\r\n actual\n&gt; &gt; phenotypes, when \n&gt; &gt; we see how they evolve, it doesn&#39;t look l=\r\nike NEAT\n&gt; &gt; starting from a \n&gt; &gt; minimal point and slowly adding structure=\r\n.. A single\n&gt; &gt; small mutation \n&gt; &gt; in the CPPN genome changes the entire s=\r\ntructure of\n&gt; &gt; the phenotype. Is \n&gt; &gt; this right?\n&gt; &gt; Or the comlexificati=\r\non here is about moving to\n&gt; &gt; higher resolutions of \n&gt; &gt; the networks? \n&gt; =\r\n&gt; \n&gt; &gt; Peter\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot;\n&gt; &gt; &lt;k=\r\nstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi everyone, as some of you know, we have been=\r\n\n&gt; &gt; working for a while \n&gt; &gt; &gt; now on turning the patterns output by CPPNs=\r\n into\n&gt; &gt; neural networks.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; I am excited to report that we ha=\r\nve found a \n&gt; &gt; &gt; straightforward and principled approach to\n&gt; &gt; interpreti=\r\nng CPPN output \n&gt; &gt; &gt; as a connectivity pattern rather than a spatial\n&gt; &gt; p=\r\nattern.    We are \n&gt; &gt; &gt; calling this method HyperNEAT, which stands for\n&gt; =\r\n&gt; Hypercube-based \n&gt; &gt; &gt; NEAT.  With HyperNEAT, we have been able to\n&gt; &gt; pr=\r\noduce working neural \n&gt; &gt; &gt; networks with millions of connections.\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; Because we have just recently had two publications\n&gt; &gt; on this method =\r\n\n&gt; &gt; &gt; accepted at GECCO-2007, we can finally disclose\n&gt; &gt; our work and sha=\r\nre \n&gt; &gt; &gt; it with others.  The publications are available on\n&gt; &gt; \n&gt; &gt; &gt; the=\r\n &quot;Publications&quot; page at http://eplex.cs.ucf.edu\n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; They are =\r\nalso available through my homepage \n&gt; &gt; &gt; http://www.cs.ucf.edu/~kstanley/#=\r\npublications\n&gt; &gt; (under Publications, \n&gt; &gt; &gt; Conference and Symposium Paper=\r\ns), or directly at\n&gt; &gt; the following \n&gt; &gt; &gt; address, which I am sure yahoo =\r\nis going to mangle:\n&gt; &gt; &gt; \n&gt; &gt; &gt; http://eplex.cs.ucf.edu/index.php?\n&gt; &gt; &gt; o=\r\nption=3Dcom_content&task=3Dview&id=3D14&Itemid=3D28\n&gt; &gt; &gt; \n&gt; &gt; &gt; The two pa=\r\npers, which present separate experiments\n&gt; &gt; are:\n&gt; &gt; &gt; \n&gt; &gt; &gt; &quot;Generating =\r\nLarge-Scale Neural Networks Through\n&gt; &gt; Discovering \n&gt; &gt; &gt; Geometric Regula=\r\nrities&quot; by Jason J. Gauci and\n&gt; &gt; Kenneth O. Stanley\n&gt; &gt; &gt; \n&gt; &gt; &gt; and \n&gt; &gt; =\r\n&gt; \n&gt; &gt; &gt; &quot;A Novel Generative Encoding for Exploiting Neural\n&gt; &gt; Network Sen=\r\nsor \n&gt; &gt; &gt; and Output Geometry&quot; by David B. D&#39;Ambrosio and\n&gt; &gt; Kenneth O. S=\r\ntanley\n&gt; &gt; &gt; \n&gt; &gt; &gt; David D&#39;Ambriosio and Jason Gauci are both Ph.D.\n&gt; &gt; st=\r\nudents in the \n&gt; &gt; &gt; EPlex lab who did an enormous amount of work to\n&gt; &gt; ma=\r\nke this possible.\n&gt; &gt; &gt; \n&gt; &gt; &gt; HyperNEAT is based on a surprisingly simple\n=\r\n&gt; &gt; principle: Connectivity \n&gt; &gt; &gt; patterns are actually no different from =\r\nspatial\n&gt; &gt; patterns in a \n&gt; &gt; higher-\n&gt; &gt; &gt; dimensional space.  In other w=\r\nords, a\n&gt; &gt; 2-dimensional connectivity \n&gt; &gt; &gt; pattern is the same thing as =\r\na 4-dimensional\n&gt; &gt; spatial pattern.  (The \n&gt; &gt; &gt; technical term is that th=\r\ney are &quot;isomorphic.&quot;) \n&gt; &gt; Therefore, if we \n&gt; &gt; &gt; simply produce spatial p=\r\natterns within a 4D\n&gt; &gt; hypercube instead of a \n&gt; &gt; &gt; 2D plane, they can be=\r\n mapped directly to\n&gt; &gt; connectivity patterns with \n&gt; &gt; &gt; all the nice prop=\r\nerties that we have seen from\n&gt; &gt; CPPNs.  Thus, they \n&gt; &gt; &gt; require no spec=\r\nial &quot;image recognition&quot; type\n&gt; &gt; tricks.  The mapping is \n&gt; &gt; &gt; perfectly i=\r\nsomorphic.  We are calling these 4D\n&gt; &gt; CPPNs &quot;connective \n&gt; &gt; &gt; CPPNs&quot; sin=\r\nce they are interpreted as connectivity\n&gt; &gt; patterns.\n&gt; &gt; &gt; \n&gt; &gt; &gt; This ins=\r\night yields a handful of unprecedented\n&gt; &gt; capabilities.  For \n&gt; &gt; &gt; exampl=\r\ne, with connective CPPNs, you can recreate\n&gt; &gt; the same solution \n&gt; &gt; &gt; net=\r\nwork at a different resolution without further\n&gt; &gt; evolution!  You \n&gt; &gt; &gt; c=\r\nan also place inputs and outputs in meaningful\n&gt; &gt; geometric \n&gt; &gt; &gt; configu=\r\nrations that HyperNEAT can exploit for\n&gt; &gt; symmetries and \n&gt; &gt; &gt; regulariti=\r\nes.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; In any case, I am excited about this new advance\n&gt; &gt; and=\r\n these papers \n&gt; &gt; &gt; are a first step in exploring the new approach.\n&gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; ken\n&gt; &gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; \n&gt; \n&gt; _______________________________\n&gt; M=\r\narmakoide aka Alexandre Devert \n&gt; _______________________________\n&gt; \n&gt; \n&gt; \t=\r\n\n&gt; \n&gt; \t\n&gt; \t\t\n&gt; \n___________________________________________________________=\r\n___________\n_____ \n&gt; D=E9couvrez une nouvelle fa=E7on d&#39;obtenir des r=E9pon=\r\nses =E0 toutes vos \nquestions ! \n&gt; Profitez des connaissances, des opinions=\r\n et des exp=E9riences des \ninternautes sur Yahoo! Questions/R=E9ponses \n&gt; h=\r\nttp://fr.answers.yahoo.com\n&gt;\n\n\n\n"}}