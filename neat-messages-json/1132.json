{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"dIX50VJPEmuwBwZ7HC2NQK5jbpvyoR-fMD-6sHcntzuX2Ty974XVGvGcKxuVoj8jo2EIzWYu64xr_ShVB4pPthiF2kgt9z5HxoaZtg0iNhIy","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Size of search-space (was: Bloat)","postDate":"1088014859","msgId":1132,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNiY2htYitpazhmQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGdpbGxhbS0wdk1lMEFSSG5nVU1qK3BjMG4vY01ZK2VSdk1FbGo3QG1haWxibG9ja3MuY29tPg=="},"prevInTopic":1126,"nextInTopic":1137,"prevInTime":1131,"nextInTime":1133,"topicId":904,"numMessagesInTopic":68,"msgSnippet":"Mike, That s a good question.  What would you try to evolve on a supercomputer?  I guess you could roughly assume you could get say 100,000 generations in a","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 51779 invoked from network); 23 Jun 2004 18:22:19 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m17.grp.scd.yahoo.com with QMQP; 23 Jun 2004 18:22:18 -0000\r\nReceived: from unknown (HELO n25.grp.scd.yahoo.com) (66.218.66.81)\n  by mta1.grp.scd.yahoo.com with SMTP; 23 Jun 2004 18:22:18 -0000\r\nReceived: from [66.218.67.140] by n25.grp.scd.yahoo.com with NNFMP; 23 Jun 2004 18:20:59 -0000\r\nDate: Wed, 23 Jun 2004 18:20:59 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;cbchmb+ik8f@...&gt;\r\nIn-Reply-To: &lt;gillam-0vMe0ARHngUMj+pc0n/cMY+eRvMElj7@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 9830\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.81\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Size of search-space (was: Bloat)\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nMike,\n\nThat&#39;s a good question.  What would you try to evolve on a \nsupercomputer?  I guess you could roughly assume you could get say \n100,000 generations in a week or two instead of 1,000.  That would \nmean potentially vastly more complexity and optimization time.  It&#39;s \ntricky, though, because there is a likelihood of stagnation in a \nvery complicated domain over 100,000 generations or more.  The \nproblem is that it&#39;s hard to think of a fitness function with a \ncontinuous gradient that could last that long.  It&#39;s more likely \nthat the fitness function would be good for certain parts of the \nsolution, but in other parts, improvement would require a \nsubstantial jump in insight, without any help from the fitness \nfunction (i.e the fitness function would not improve while the new \nstep was being built).  Thus, I&#39;m not sure if you could just \nimmediately throw some massive domain like robot soccer or Go at a \nsupercomputer raw and expect it to make full use of the available \npower.  On the other hand, it&#39;s tempting to try since even things \nthat stagnate for 500 generations may end up escaping after several \nthousand, given such a long time to improve.\n\nken\n\n--- In neat@yahoogroups.com, &quot;Michael Gillam&quot; &lt;gillam@m...&gt; wrote:\n&gt; Hi Ken,\n&gt; \n&gt; To clarify, I meant, had anyone done any papers estimating what \nsort of\n&gt; problems in other domains could be tackled on supercomputers using \nNEAT?\n&gt; \n&gt; Running NEAT on one of these might be nice...\n&gt; http://www.top500.org/list/2004/06/\n&gt; \n&gt; -Mike\n&gt; \n&gt; \n&gt; ----- Original Message ----- \n&gt; From: &quot;Kenneth Stanley&quot; &lt;kstanley@c...&gt;\n&gt; To: &lt;neat@yahoogroups.com&gt;\n&gt; Sent: Tuesday, June 22, 2004 11:41 AM\n&gt; Subject: [neat] Re: Size of search-space (was: Bloat)\n&gt; \n&gt; \n&gt; &gt; Mike, I know of no efforts to try NEAT on a supercomputer.  It \nwould\n&gt; &gt; definitely be interesting.  The same goes for trying NEAT with \nany\n&gt; &gt; massively parallel system.  Ultimately it just means more\n&gt; &gt; generations in less time, but it might make a difference in \norders\n&gt; &gt; of magnitude, which could substantially change the natureo of \nwhat\n&gt; &gt; evolves.\n&gt; &gt;\n&gt; &gt; I&#39;m not sure to what your second question about solving &quot;what \nsort\n&gt; &gt; of problems have been proposed&quot; is referring?  Do you mean \nregarding\n&gt; &gt; implementing NEAT on a supercomputeror some other kinds of \nproblems?\n&gt; &gt;\n&gt; &gt; ken\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com, &quot;Michael Gillam&quot; &lt;gillam@m...&gt; \nwrote:\n&gt; &gt; &gt; Kenneth,\n&gt; &gt; &gt;\n&gt; &gt; &gt;     What sort of efforts are being pushed to try NEAT \napproaches on\n&gt; &gt; &gt; supercomputers?  And to solving what sort of problems have been\n&gt; &gt; proposed?\n&gt; &gt; &gt;\n&gt; &gt; &gt; Thanks!\n&gt; &gt; &gt;\n&gt; &gt; &gt; -Mike\n&gt; &gt; &gt;\n&gt; &gt; &gt; ----- Original Message ----- \n&gt; &gt; &gt; From: &quot;Kenneth Stanley&quot; &lt;kstanley@c...&gt;\n&gt; &gt; &gt; To: &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; Sent: Tuesday, June 15, 2004 3:48 PM\n&gt; &gt; &gt; Subject: [neat] Re: Size of search-space (was: Bloat)\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Ian,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I am in complete agreement with the spirit of your point \nabout\n&gt; &gt; modular\n&gt; &gt; &gt; &gt; structures potentially reducing the effective space of \nsearch.\n&gt; &gt; I&#39;d\n&gt; &gt; &gt; &gt; like to formalize it a little bit further here...\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; What we have to do is distinguish between the spaces of the\n&gt; &gt; genotype\n&gt; &gt; &gt; &gt; and the phenotype, since they can be quite different in\n&gt; &gt; dimensionality\n&gt; &gt; &gt; &gt; depending on the mapping between them.  Then, as long as we \nare\n&gt; &gt; clear\n&gt; &gt; &gt; &gt; about which space we are talking about, there will be no\n&gt; &gt; ambiguity\n&gt; &gt; &gt; &gt; about the meaning of a dimension.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; In general, all of my arguments about the need to evolve \nvariable\n&gt; &gt; &gt; &gt; length genomes are about *genotypic* space.  Of course, with\n&gt; &gt; NEAT in\n&gt; &gt; &gt; &gt; its current form, this is a trivial statement, since the\n&gt; &gt; dimensions of\n&gt; &gt; &gt; &gt; genotype and phenotype are the same.  However, in a future \nNEAT\n&gt; &gt; &gt; &gt; wherein the genotype goes through an indirect mapping to\n&gt; &gt; phenotype,\n&gt; &gt; &gt; &gt; the dimensions of the genotype may be much fewer than the\n&gt; &gt; phenotype.\n&gt; &gt; &gt; &gt; Neverthelsss, all the arguments still apply: we still wish to\n&gt; &gt; minimize\n&gt; &gt; &gt; &gt; the number of dimensions in the genome.  It&#39;s just that now \nthey\n&gt; &gt; are\n&gt; &gt; &gt; &gt; going to be mapped to somethin different in the phenotype.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; What this analysis suggests, and what I ultimately believe is\n&gt; &gt; &gt; &gt; happening in this field, is that there are two parallel yet\n&gt; &gt; &gt; &gt; complementary directions of research that should ultimately\n&gt; &gt; converge:\n&gt; &gt; &gt; &gt; 1) The idea of complexification through starting minimally \nand\n&gt; &gt; &gt; &gt; protection of innovation inside NEAT is a generic \nmethodology for\n&gt; &gt; &gt; &gt; evolving in any genotypic space, and 2) an (extremely) clever\n&gt; &gt; indirect\n&gt; &gt; &gt; &gt; mapping would allow very compact representations.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; 1 with 2 means efficient search plus efficient \nrepresentation.\n&gt; &gt; Thus\n&gt; &gt; &gt; &gt; they go together very neatly.  You may think for a moment \nthat 2\n&gt; &gt; &gt; &gt; precludes 1, since perhaps if the mapping is sufficiently\n&gt; &gt; powerful the\n&gt; &gt; &gt; &gt; number of dimensions necessary in the genome will be so low \nthat\n&gt; &gt; 1\n&gt; &gt; &gt; &gt; will become irrelevant.  However, that is not likely to be \nthe\n&gt; &gt; case.\n&gt; &gt; &gt; &gt; Even in indirect mappings we are likely to need many \nhundreds or\n&gt; &gt; &gt; &gt; thousands of genes, even though those genes may be reused.  \nNote\n&gt; &gt; human\n&gt; &gt; &gt; &gt; DNA, with 30,000 genes.  These 30,000 genes are reused in \nsuch\n&gt; &gt; amazing\n&gt; &gt; &gt; &gt; proportions that they somehow map to 100 trillion \nconnections in\n&gt; &gt; the\n&gt; &gt; &gt; &gt; human brain.  Yet even with this brilliant reduction, 30,000 \nis\n&gt; &gt; still\n&gt; &gt; &gt; &gt; a lot of dimensions, and still is unlikely to be optimized\n&gt; &gt; through\n&gt; &gt; &gt; &gt; direct search in the genotype space of 30,000 dimensions.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Therefore, I believe the field should head towards NEAT-style\n&gt; &gt; &gt; &gt; evolution of indiretly encoded genomes.  I don&#39;t know if you \nsaw\n&gt; &gt; when\n&gt; &gt; &gt; &gt; I mentioned our paper, &quot;A Taxonomy for Artificial \nEmbryogeny,&quot;\n&gt; &gt; but it\n&gt; &gt; &gt; &gt; is a large review of this area that you may be interested in:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; http://nn.cs.utexas.edu/keyword?stanley:alife03\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I agree that modularity is a big deal in evolution, and it \nshould\n&gt; &gt; &gt; &gt; definitely be at the forefront of future researh.  However,\n&gt; &gt; sometimes\n&gt; &gt; &gt; &gt; the way we think about modularity may be misleading since we \nare\n&gt; &gt; &gt; &gt; tempted to think as engineers whereas evolution is not like \nan\n&gt; &gt; &gt; &gt; engineer.  We have a short paper on this topic as well:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; http://nn.cs.utexas.edu/keyword?stanley:gecco04ws\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, Ian Badcoe &lt;ian_badcoe@y...&gt; \nwrote:\n&gt; &gt; &gt; &gt; &gt; Hi,\n&gt; &gt; &gt; &gt; &gt; (I&#39;ve been on holiday so I&#39;m a bit out of daye, this is \nfrom\n&gt; &gt; &gt; &gt; Kenneth&#39;s\n&gt; &gt; &gt; &gt; &gt; long discussion of about a week ago)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Great analysis!  Just one small additional thought:  what \ndo we\n&gt; &gt; &gt; &gt; mean by\n&gt; &gt; &gt; &gt; &gt; &quot;dimensions&quot; in the search space?\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Example, suppose we&#39;re doing some vision processing and by\n&gt; &gt; whatever\n&gt; &gt; &gt; &gt; means\n&gt; &gt; &gt; &gt; &gt; we arrive at a good solution.  Then we analyze the solution\n&gt; &gt; and we\n&gt; &gt; &gt; &gt; discover\n&gt; &gt; &gt; &gt; &gt; that, although it contains 1000 neurones, they are \nactually 10\n&gt; &gt; &gt; &gt; copies(*) of\n&gt; &gt; &gt; &gt; &gt; the same 90-neurone structure (say an edge-detector) and a\n&gt; &gt; control\n&gt; &gt; &gt; &gt; network\n&gt; &gt; &gt; &gt; &gt; linking them together(**).  That&#39;s not really anything \nlike as\n&gt; &gt; &gt; &gt; large a\n&gt; &gt; &gt; &gt; &gt; solution-space as it looked before the analysis, for two\n&gt; &gt; reasons:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; (* or 10 &quot;iso-neural&quot; networks, e.g. not copies but\n&gt; &gt; functionally\n&gt; &gt; &gt; &gt; &gt; equivalent....)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; (** current systems are unlikely to produce this, see \nbelow)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 1) The 10 copies of the edge detector are 10 copies of the\n&gt; &gt; same set\n&gt; &gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; dimensions, and thus a sub-space with 10-fold less \ndimensions\n&gt; &gt; than\n&gt; &gt; &gt; &gt; it\n&gt; &gt; &gt; &gt; &gt; originally appeared\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 2) The edge-detector and the control network are (arguably)\n&gt; &gt; not in\n&gt; &gt; &gt; &gt; the same\n&gt; &gt; &gt; &gt; &gt; search-space -- they are &quot;orthogonal&quot;.  e.g. the \nmodularity of\n&gt; &gt; the\n&gt; &gt; &gt; &gt; problem\n&gt; &gt; &gt; &gt; &gt; only requires them to respect the same &quot;interface&quot;\n&gt; &gt; connections, if\n&gt; &gt; &gt; &gt; does not\n&gt; &gt; &gt; &gt; &gt; required the edge-detector internal works to be finely \ntuned to\n&gt; &gt; &gt; &gt; match the\n&gt; &gt; &gt; &gt; &gt; control network.  Or, to put it another way, any functional\n&gt; &gt; edge\n&gt; &gt; &gt; &gt; detector\n&gt; &gt; &gt; &gt; &gt; would work with any functional control network.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Stronger examples of modularity producing orthogonality can\n&gt; &gt; easily\n&gt; &gt; &gt; &gt; be\n&gt; &gt; &gt; &gt; &gt; dreamed up.  Consider the case of N sub-nets, each evolved \nto\n&gt; &gt; &gt; &gt; recognize a\n&gt; &gt; &gt; &gt; &gt; different input class, and a control net which just checks \nfor\n&gt; &gt; &gt; &gt; which\n&gt; &gt; &gt; &gt; &gt; sub-net is reporting the highest confidence.  There is no\n&gt; &gt; &gt; &gt; dependency(***)\n&gt; &gt; &gt; &gt; &gt; between the sub-nets.  (Their internal dependencies are (i)\n&gt; &gt; report\n&gt; &gt; &gt; &gt; their\n&gt; &gt; &gt; &gt; &gt; confidence on a connection to the control net, (ii) the \ninput\n&gt; &gt; data\n&gt; &gt; &gt; &gt; format.)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; (*** dependency is the opposite of orthogonality)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; However, one cannot expect a homogeneous evolution \nprocedure to\n&gt; &gt; &gt; &gt; just\n&gt; &gt; &gt; &gt; &gt; happen to produce orthogonal modules.  You need a modular\n&gt; &gt; evolution\n&gt; &gt; &gt; &gt; system:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; (slowest) mutate modularity\n&gt; &gt; &gt; &gt; &gt; (medium) try topologies within each module\n&gt; &gt; &gt; &gt; &gt; (fastest) play with the weights in each module\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; - as people have begun to tinker with.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Ian Badcoe\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Living@Home - Open Source Evolving Organisms -\n&gt; &gt; &gt; &gt; &gt; http://livingathome.sourceforge.net/\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Yahoo! Groups Links\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n\n\n"}}