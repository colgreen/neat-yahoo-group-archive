{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"KZjFJxd9rvmQXIac8K7bt4l5aKDeQazWQkggGM-BcOmOGg_n8SW7DZsGrRDwII95593syOrN0yad1Eq5XujkcjpnwpC0oLeq-ocAGsVWFEm7","spamInfo":{"isSpam":false,"reason":"2"},"subject":"Re: Parameter settings for comparing HyperNEAT to P-NEAT","postDate":"1228639980","msgId":4499,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdoZzJ0YyszMHFoQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDhkOGZmZTM0MDgxMjA2MjIzNmc0OWQ4MDYxYnkyZjQyNzk0MzUwZjA4N2E4QG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4498,"nextInTopic":4514,"prevInTime":4498,"nextInTime":4500,"topicId":4496,"numMessagesInTopic":6,"msgSnippet":"Jeff, a few other thoughts on the issue... Note that I believe the only time P-NEAT comes up is in the boxes domain.  None of David s experiments involve","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 10149 invoked from network); 7 Dec 2008 08:53:03 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m57.grp.scd.yahoo.com with QMQP; 7 Dec 2008 08:53:03 -0000\r\nX-Received: from unknown (HELO n18c.bullet.sp1.yahoo.com) (69.147.64.129)\n  by mta18.grp.scd.yahoo.com with SMTP; 7 Dec 2008 08:53:03 -0000\r\nX-Received: from [69.147.65.151] by n18.bullet.sp1.yahoo.com with NNFMP; 07 Dec 2008 08:53:03 -0000\r\nX-Received: from [66.218.66.77] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 07 Dec 2008 08:53:02 -0000\r\nDate: Sun, 07 Dec 2008 08:53:00 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ghg2tc+30qh@...&gt;\r\nIn-Reply-To: &lt;8d8ffe340812062236g49d8061by2f42794350f087a8@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:2:2:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Parameter settings for comparing HyperNEAT to P-NEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=vSr4TxkIecRaGr3gA-Yh7gqTdc9yat0-7_A3MfiCIxbU_5pguDDi\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, a few other thoughts on the issue...\n\nNote that I believe the only ti=\r\nme P-NEAT comes up is in the boxes\ndomain.  None of David&#39;s experiments inv=\r\nolve P-NEAT.  I think Jason\ndid some cursory checking of other settings for=\r\n P-NEAT, but nothing\nsystematic.  Jason can correct me if I am wrong.\n\nI un=\r\nderstand that like Jason and myself, you don&#39;t think it would\nreally make a=\r\n big difference no matter what we do with P-NEAT, but\njust for the record, =\r\nI think the reasoning you give for the\ndifferences with P-NEAT is not entir=\r\nely accurate.  In particular, you\nsuggest that small mutations in HyperNEAT=\r\n may lead to big changes on\nthe substrate, while the same is not true for P=\r\n-NEAT.  I disagree with\nthat perspective because ultimately what is importa=\r\nnt is not the\nsubstrate, but the behavior produced by the substrate.  The s=\r\nubstrate\nis just a level of indirection in the mapping between genotype and=\r\n\nbehavior.  In that view, a small mutation in P-NEAT is just as likely\nto p=\r\nroduce a large change in *behavior* as it is in HyperNEAT. \nConsider that b=\r\nehavior is an indirect holistic product of genotype as\nwell.  That is, a si=\r\nngle gene mutating in P-NEAT can change how an\nindividual behaves in every =\r\npossible situation it may encounter. \nHence it is equally holistic as Hyper=\r\nNEAT.\n\nIn fact, one could argue that the situation is actually opposite of\n=\r\nwhat you say:  Because a single mutation in HyperNEAT produces a\nsystematic=\r\n concerted change in the substrate, it is less likely to\nproduce a haphazar=\r\nd change in behavior than a single mutation in\nP-NEAT.  That is a difficult=\r\n argument to make concrete, but it&#39;s not\nunreasonable.  Just because a lot =\r\nof connection weights change does\nnot mean that the change is &quot;big.&quot;  If th=\r\ney all change in a concerted\nmanner, it can be quite subtle, or no change a=\r\nt all.  And in fact,\nconcerted change is exactly what indirect encoding is =\r\nabout.\n\nNote that I am referring to P-NEAT in general.  In the boxes domain=\r\n,\nit is perhaps more as you say since individual connections in that\ndomain=\r\n do indeed have small effects.\n\nIn any case, the larger concern is still va=\r\nlid.  There may indeed be\ndifferent optimal parameter settings for P-NEAT a=\r\nnd HyperNEAT, and\nthat is something people can look at.  But if there are, =\r\nin my view it\nis probably for different reasons than the ones you cite (as =\r\nI explain\nabove).  Still, barring finding the optimal P-NEAT parameters (wh=\r\nich I\ndon&#39;t know), I think the most fair thing is indeed to give them the\ns=\r\name parameters because they are both ultimately variants of NEAT\nevolving a=\r\n solution to the same problem.  Still, I do see that one\nmight be intereste=\r\nd in optimizing P-NEAT further to see how good it\ncan really be.  However, =\r\nas you say and Jason supports, it won&#39;t be\neasy to get P-NEAT to optimize a=\r\n 14,000-dimensional space, whatever\nparameters you give it.\n\nken\n\n--- In ne=\r\nat@yahoogroups.com, &quot;Jason G&quot; &lt;jgmath2000@...&gt; wrote:\n&gt;\n&gt; Hey Jeff,\n&gt; \n&gt; I =\r\nunderstand the concern with the mutation probability.  I believe the\n&gt; reas=\r\non that NEAT cannot solve the boxes problem in training is a credit\n&gt; assig=\r\nnment problem. Because the number of connections is so high, it is\n&gt; diffic=\r\nult for a direct encoding to learn which connections were\nresponsible\n&gt; for=\r\n an increase/decrease in fitness.\n&gt; \n&gt; It might be possible to improve the =\r\ncredit assignment by lowering the\n&gt; mutation rate.  The problem is that if =\r\nthe mutation rate was lowered\nto the\n&gt; point where credit assignment could =\r\nbe manageable by NEAT, I believe\nthat\n&gt; this would require orders of magnit=\r\nude more generations to converge.\nEven if\n&gt; NEAT converged to a solution, t=\r\nhis does not negate the fact that a\nlot of\n&gt; the connections are never used=\r\n in training, and these connections\nwill have\n&gt; effectively random values, =\r\nresulting in poor validation performance.\n&gt; \n&gt; Consider this: if NEAT was a=\r\nble to learn the correct value for a\nsingle link\n&gt; every generation, and th=\r\nis correct value was preserved through the\nwhole run\n&gt; (i.e. it was not acc=\r\nidentally mutated), it would still take about 5000\n&gt; generations to complet=\r\nely solve the training phase of the boxes\nproblem.  At\n&gt; roughly an hour pe=\r\nr generation, that&#39;s about 7 months per run.\n&gt; \n&gt; Any sweep of the mutation=\r\n rate parameter would require many\ngenerations in\n&gt; each run. I believe tha=\r\nt, given a very low mutation rate, NEAT might\nbe able\n&gt; to solve the boxes =\r\nproblem; however, it would take tens of thousands of\n&gt; generations at least=\r\n, and there&#39;s still the generalization issue. \nGiven the\n&gt; amount of resour=\r\nces necessary to find the magic numbers, I didn&#39;t\nsee the\n&gt; utility in tryi=\r\nng to pursue it.\n&gt; \n&gt; I think what might be more interesting would be to tr=\r\ny different\nparameters\n&gt; for HyperNEAT.  As we fix bugs and develop maturit=\r\ny in the codebase, it\n&gt; would be important to note how the parameters shoul=\r\nd be changed for the\n&gt; older experiments (e.g. the mutation rate is lower n=\r\now because we\nfixed a\n&gt; bug in mutation).\n&gt; \n&gt; --- In neat@yahoogroups.com,=\r\n Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi all-\n&gt; &gt;\n&gt; &gt; A quick question for K=\r\nen, Jason and Dave.\n&gt; &gt;\n&gt; &gt; I notice that most of the parameter settings (e=\r\n.g.\n&gt; &gt; MutateLinkWeightsProbability) were the same when you guys compared\n=\r\n&gt; HyperNEAT\n&gt; &gt; to P-NEAT.\n&gt; &gt;\n&gt; &gt; Someone in my lab raised the issue yeste=\r\nrday that each\nconfiguration may\n&gt; &gt; have entirely different optimal settin=\r\ngs, making a comparison with the\n&gt; same\n&gt; &gt; settings potentially unfair. Ou=\r\nt of curiosity, did you do any\nparameter\n&gt; &gt; sweeps to see if P-NEAT&#39;s perf=\r\normance did much better, and better\n&gt; approached\n&gt; &gt; HyperNEAT&#39;s, with diff=\r\nerent parameter settings?\n&gt; &gt;\n&gt; &gt; For example, since mutations to HyperNEAT=\r\n have such larger effects\non the\n&gt; &gt; final substrate, it could be argued th=\r\nat P-NEAT needs a much higher\n&gt; mutation\n&gt; &gt; rate to compete.\n&gt; &gt;\n&gt; &gt; Note:=\r\n I don&#39;t think P-NEAT will beat HyperNEAT no matter what the\n&gt; settings,\n&gt; =\r\n&gt; but I do think the question is fair and I would not be surprised\nif the\n&gt;=\r\n &gt; settings that worked great for HyperNEAT are not the ones that\nwork grea=\r\nt\n&gt; &gt; for P-NEAT (and vice versa). In short, I am confident that the\nqualit=\r\native\n&gt; &gt; results of your paper are still all valid (and represent\nbreakthr=\r\noughs for\n&gt; &gt; the field), but am interested to know whether the quantitativ=\r\ne\ndifference\n&gt; &gt; between the encodings might be much less with different se=\r\nttings.\n&gt; &gt;\n&gt; &gt; PS. As a side note, there are a ton of settings and sweepin=\r\ng them\nall is\n&gt; &gt; nearly impossible, especially when considering interactio=\r\nns. What does\n&gt; &gt; everyone in the group consider to be the important ones t=\r\no sweep?\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Cheers,\n&gt; &gt; Jeff Clune\n&gt; &gt;\n&gt; &gt; Digital Evoluti=\r\non Lab, Michigan State University\n&gt; &gt;\n&gt; &gt; jclune@\n&gt; &gt;\n&gt; \n&gt; \n&gt; On Thu, Dec 4=\r\n, 2008 at 11:49 AM, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt; \n&gt; &gt;   Hi all-\n&gt; &gt;\n&gt; &gt;=\r\n A quick question for Ken, Jason and Dave.\n&gt; &gt;\n&gt; &gt; I notice that most of th=\r\ne parameter settings (e.g.\n&gt; &gt; MutateLinkWeightsProbability) were the same =\r\nwhen you guys compared\n&gt; &gt; HyperNEAT\n&gt; &gt; to P-NEAT.\n&gt; &gt;\n&gt; &gt; Someone in my l=\r\nab raised the issue yesterday that each\nconfiguration may\n&gt; &gt; have entirely=\r\n different optimal settings, making a comparison with\nthe same\n&gt; &gt; settings=\r\n potentially unfair. Out of curiosity, did you do any\nparameter\n&gt; &gt; sweeps =\r\nto see if P-NEAT&#39;s performance did much better, and better\n&gt; &gt; approached\n&gt;=\r\n &gt; HyperNEAT&#39;s, with different parameter settings?\n&gt; &gt;\n&gt; &gt; For example, sin=\r\nce mutations to HyperNEAT have such larger effects\non the\n&gt; &gt; final substra=\r\nte, it could be argued that P-NEAT needs a much higher\n&gt; &gt; mutation\n&gt; &gt; rat=\r\ne to compete.\n&gt; &gt;\n&gt; &gt; Note: I don&#39;t think P-NEAT will beat HyperNEAT no mat=\r\nter what the\nsettings,\n&gt; &gt; but I do think the question is fair and I would =\r\nnot be surprised\nif the\n&gt; &gt; settings that worked great for HyperNEAT are no=\r\nt the ones that\nwork great\n&gt; &gt; for P-NEAT (and vice versa). In short, I am =\r\nconfident that the\nqualitative\n&gt; &gt; results of your paper are still all vali=\r\nd (and represent\nbreakthroughs for\n&gt; &gt; the field), but am interested to kno=\r\nw whether the quantitative\ndifference\n&gt; &gt; between the encodings might be mu=\r\nch less with different settings.\n&gt; &gt;\n&gt; &gt; PS. As a side note, there are a to=\r\nn of settings and sweeping them\nall is\n&gt; &gt; nearly impossible, especially wh=\r\nen considering interactions. What does\n&gt; &gt; everyone in the group consider t=\r\no be the important ones to sweep?\n&gt; &gt;\n&gt; &gt; Cheers,\n&gt; &gt; Jeff Clune\n&gt; &gt;\n&gt; &gt; Di=\r\ngital Evolution Lab, Michigan State University\n&gt; &gt;\n&gt; &gt; jclune@... &lt;jclune%4=\r\n0msu.edu&gt;\n&gt; &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt;\n\n\n\n"}}