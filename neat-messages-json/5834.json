{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"IjrFDyCYT0X54TcHBu5B7taMCi7xOswoOCrBL1E0blCXmez_xjjuoJnZpT1T7MAtu_sJRCgV4kw_aW5Guh-05YaWbiK8","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: Models of brains, what should we borrow from biology?","postDate":"1343201659","msgId":5834,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGp1bzdocis3NWtjQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDc0NEJBN0EyLUE2MzAtNEREMC1CRDdDLTcxRDkyMzI0QjhFQkBjb3JuZWxsLmVkdT4="},"prevInTopic":5833,"nextInTopic":5835,"prevInTime":5833,"nextInTime":5835,"topicId":5801,"numMessagesInTopic":16,"msgSnippet":"Hi Jeff and Oliver, nice discussion and definitely relevant to the group.  Jeff mentioned my strong opinions about algorithm comparisons, so I thought it","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 10142 invoked from network); 25 Jul 2012 07:34:19 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m9.grp.sp2.yahoo.com with QMQP; 25 Jul 2012 07:34:19 -0000\r\nX-Received: from unknown (HELO ng13-vm5.bullet.mail.gq1.yahoo.com) (98.136.219.161)\n  by mta1.grp.sp2.yahoo.com with SMTP; 25 Jul 2012 07:34:19 -0000\r\nX-Received: from [98.137.0.82] by ng13.bullet.mail.gq1.yahoo.com with NNFMP; 25 Jul 2012 07:34:19 -0000\r\nX-Received: from [98.137.34.73] by tg2.bullet.mail.gq1.yahoo.com with NNFMP; 25 Jul 2012 07:34:19 -0000\r\nDate: Wed, 25 Jul 2012 07:34:19 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;juo7hr+75kc@...&gt;\r\nIn-Reply-To: &lt;744BA7A2-A630-4DD0-BD7C-71D92324B8EB@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Models of brains, what should we borrow from biology?\r\nX-Yahoo-Group-Post: member; u=54567749; y=xr7qIBlamEoWYMEq9BwapI9ooo1yLiZh_qjBTKr73nnH1n8d-6dj\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Jeff and Oliver, nice discussion and definitely relevant to the group.=\r\n  Jeff mentioned my &quot;strong opinions&quot; about algorithm comparisons, so I tho=\r\nught it can&#39;t hurt to follow up on what Jeff said:\n\n&quot;Ken Stanley has strong=\r\n opinions on why comparing different\nalgorithms on one or a few tasks tells=\r\n us very little, which he may \nwant to chime in with. I generally agree wit=\r\nh him that it is not \nterribly informative, although I tend to think it is =\r\nstill somewhat \ntvaluable, while he thinks it is mostly worthless! (Sorry i=\r\nf I am \ntincorrectly paraphrasing you Ken). Ken is right that different \nal=\r\ngorithms perform very differently on different problems, so a few tests pro=\r\nvides too small a sample size to learn much. Moreover, every researcher ina=\r\ndvertently knows their own algorithm much better than what they are compari=\r\nng against, so they keep tuning their algorithm to the benchmarks being use=\r\nd until they win, reducing the value of the comparison. There&#39;s no great al=\r\nternative, in my opinion, so I still do it...but  I increasingly agree with=\r\n Ken that our time as scientists can better be spent on other chores (such =\r\nas showing the new, interesting, properties of our new algorithms...an exam=\r\nple being HyperNEAT genomes scaling up to very large networks without subst=\r\nantial performance drops).&quot;\n\nI agree with these concerns but as Jeff hints =\r\nI&#39;d go farther with it.  The problem here is more fundamental than simply t=\r\nhat it&#39;s hard to tell which algorithm is &quot;better&quot; from a few comparisons.  =\r\nThe problem is that it&#39;s not even clear what &quot;better&quot; means no matter how m=\r\nany comparisons there are.  Quantitative comparisons imply that &quot;better&quot; me=\r\nans that an algorithms scores better on average on some performance metric.=\r\n  But for those who are pursuing revolutionary advances in AI, I&#39;m skeptica=\r\nl that it really matters which algorithm scores better even across many ben=\r\nchmarks.\n\nThe reason is that to me &quot;better&quot; should mean &quot;leads to the most =\r\nnew algorithms in the future.&quot;  In other words, it has little or nothing to=\r\n do with performance.  &quot;Better&quot; means creating a foundation for new ideas a=\r\nnd a new research direction.  We know it when we see it.  We&#39;re talking abo=\r\nut primitive AI algorithms here that are about 3 inches into a 10-million-k=\r\nilometer marathon to the pinnacle of AI.  If you&#39;re looking at two differen=\r\nt algorithms then in effect you&#39;re comparing two different points in the va=\r\nst space of all possible algorithms.  Given that there are probably light y=\r\nears of advances to go in the direction of either one of them, why would yo=\r\nu cut the path of either one of them off regardless of the &quot;results&quot; if bot=\r\nh of them are interesting ideas?\n\nIf you were running an evolutionary algor=\r\nithm with diversity maintenance of some kind, then how one arbitrary point =\r\nin the search space compares to another would hardly matter.  So why do we =\r\ncare about apple-and-oranges comparisons in AI?  \n\nI think it has become a =\r\nconvenient way to avoid the sobering reality that most algorithms don&#39;t hav=\r\ne any exciting ideas behind them.  So the only thing you can do is look at =\r\na pointless comparison.  For those algorithms that do have interesting idea=\r\ns behind them, I don&#39;t even need a comparison to know they&#39;re interesting, =\r\nand even if they perform worse than something else, the last thing I want t=\r\no do is throw out an interesting idea.   Who knows where it might lead?\n\nSo=\r\n yes comparisons are very overrated.  One type of comparison I do think can=\r\n be useful once in a while is to compare an algorithm with a variant of its=\r\nelf (which includes ablations).  That can give a sense of what a new ingred=\r\nient adds.  But even then, if the idea isn&#39;t inspirational, the performance=\r\n gain won&#39;t matter much in the long run.  Because in the long run we aren&#39;t=\r\n interested in performance gains but rather in stepping stones to new front=\r\niers. These things (i.e. performance and where an idea leads) are not corre=\r\nlated in any complex search space and therefore we should should not be run=\r\nning the whole field of AI research like a naive giant hill-climbing algori=\r\nthm.  The irony here is that the world&#39;s greatest experts in search are doi=\r\nng exactly that at the meta-level (i.e. at the level of how the community s=\r\nearches for new algorithms) by focusing so intently on comparative performa=\r\nnce results.\n\nThe one other kind of performance result I think is useful is=\r\n when an algorithm does something completely unprecedented.  Of course, in =\r\nthat case, you don&#39;t need a comparison because there&#39;s nothing to compare w=\r\nith.  Though that won&#39;t stop traditionalists from clamoring for a compariso=\r\nn anyway.\n\nken\n\n\n"}}