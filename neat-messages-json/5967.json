{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":344770077,"authorName":"Colin Green","from":"Colin Green &lt;colin.green1@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"5zaQJ2ppuJyj72JcISvc-qEQQTt-sRSfvFXJCVqy9YbwD3UvRYS-kuncf3Oa_UuGG0KDUVJ2fsDgMXIByPsPUWvzjMe5zwYf2mLx","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Precision / granularity for weight values","postDate":"1358608833","msgId":5967,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBRTBNK1ljRFN4NFdYUzB0NjE9NkFvZ0FVaVlNd3QtMnBCQkdfOFlXUmg5PVJod0dRd0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PGtkYXJvNit2aTBtQGVHcm91cHMuY29tPg==","referencesHeader":"PGtkYXJvNit2aTBtQGVHcm91cHMuY29tPg=="},"prevInTopic":5958,"nextInTopic":0,"prevInTime":5966,"nextInTime":5968,"topicId":5945,"numMessagesInTopic":3,"msgSnippet":"The only benefit I can think of is the reduced RAM requirement for network state - if you code it right. Double precision floats are 8 bytes, single precision","rawEmail":"Return-Path: &lt;colin.green1@...&gt;\r\nX-Sender: colin.green1@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 30672 invoked from network); 19 Jan 2013 15:21:14 -0000\r\nX-Received: from unknown (10.193.84.135)\n  by m1.grp.bf1.yahoo.com with QMQP; 19 Jan 2013 15:21:14 -0000\r\nX-Received: from unknown (HELO mail-vb0-f47.google.com) (209.85.212.47)\n  by mta1.grp.bf1.yahoo.com with SMTP; 19 Jan 2013 15:21:14 -0000\r\nX-Received: by mail-vb0-f47.google.com with SMTP id e21so4523508vbm.34\n        for &lt;neat@yahoogroups.com&gt;; Sat, 19 Jan 2013 07:21:13 -0800 (PST)\r\nX-Received: by 10.220.231.196 with SMTP id jr4mr11705413vcb.16.1358608873912;\n Sat, 19 Jan 2013 07:21:13 -0800 (PST)\r\nMIME-Version: 1.0\r\nX-Received: by 10.58.210.69 with HTTP; Sat, 19 Jan 2013 07:20:33 -0800 (PST)\r\nIn-Reply-To: &lt;kdaro6+vi0m@...&gt;\r\nReferences: &lt;kdaro6+vi0m@...&gt;\r\nDate: Sat, 19 Jan 2013 15:20:33 +0000\r\nMessage-ID: &lt;CAE0M+YcDSx4WXS0t61=6AogAUiYMwt-2pBBG_8YWRh9=RhwGQw@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Colin Green &lt;colin.green1@...&gt;\r\nSubject: Re: [neat] Re: Precision / granularity for weight values\r\nX-Yahoo-Group-Post: member; u=344770077; y=COBLhagaDywMxtPomuEsNZ94exUvzDlV-Py2hDpThbn3NiyHBU1V\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nThe only benefit I can think of is the reduced RAM requirement for\nnetwork state - if you code it right. Double precision floats are 8\nbytes, single precision is 4 bytes, so there&#39;s perhaps an argument for\nsqueezing connection weights into 2 bytes to half the total RAM again,\nespecially if you&#39;re dealing with very large networks and wanting to\nrun them in a GPU (as one example).\n\nFunctionally I can&#39;t think of a benefit.\n\nColin.\n\nOn 18 January 2013 06:57, Ken &lt;kstanley@...&gt; wrote:\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; I&#39;m not sure about the motivation for doing that either. Could you point\n&gt; out where Soltoggio says he does that? (Then I could ask him.)\n&gt;\n\n&gt; --- In neat@yahoogroups.com, Oliver Coleman wrote:\n&gt; &gt;\n&gt; &gt; Hi all,\n&gt; &gt;\n&gt; &gt; I&#39;ve noticed a few authors (some using NEAT and others not, eg\n&gt; &gt; Soltoggio)\n&gt; &gt; use a precision or granularity parameter for weight values, ie each\n&gt; &gt; weight\n&gt; &gt; may only adopt a value from a (fairly large) discrete set of values\n&gt; &gt; determined by the granularity/precision parameter.\n\n"}}