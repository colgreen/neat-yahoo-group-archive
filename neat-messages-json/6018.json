{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"9kUgE1R0WK7p8aPf59Y3xf5dKdsgOyUFaQaMbTGrsN24sBU21bQ6mt8ACHRATOpEsr9CGEcfE-Ub4FrMkJunw0VAiCti","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: New paper on why modules evolve, and how to evolve modular artif","postDate":"1362731263","msgId":6018,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtoYzdkdiszZnBsQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtoNHBkaitjbzM2QGVHcm91cHMuY29tPg=="},"prevInTopic":6017,"nextInTopic":6019,"prevInTime":6017,"nextInTime":6019,"topicId":6011,"numMessagesInTopic":10,"msgSnippet":"Hi Martin, I appreciate your summary of the discussion and agree with a lot of your points.  You re right that my point isn t only simply to use an encoding to","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 63726 invoked from network); 8 Mar 2013 08:27:45 -0000\r\nX-Received: from unknown (10.193.84.151)\n  by m7.grp.bf1.yahoo.com with QMQP; 8 Mar 2013 08:27:45 -0000\r\nX-Received: from unknown (HELO ng14-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.118)\n  by mta5.grp.bf1.yahoo.com with SMTP; 8 Mar 2013 08:27:45 -0000\r\nX-Received: from [98.139.164.126] by ng14.bullet.mail.bf1.yahoo.com with NNFMP; 08 Mar 2013 08:27:45 -0000\r\nX-Received: from [10.193.94.46] by tg7.bullet.mail.bf1.yahoo.com with NNFMP; 08 Mar 2013 08:27:45 -0000\r\nDate: Fri, 08 Mar 2013 08:27:43 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;khc7dv+3fpl@...&gt;\r\nIn-Reply-To: &lt;kh4pdj+co36@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New paper on why modules evolve, and how to evolve modular artif\r\nX-Yahoo-Group-Post: member; u=54567749; y=QNXT_aBBZNQx6RlA--SyrhDcli8UNHY9AAk6xFfNUB2GkB8SUScW\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Martin, I appreciate your summary of the discussion and agree with a l=\r\not of your points.  You&#39;re right that my point isn&#39;t only simply to use an =\r\nencoding to impose a bias, which is why my explanation turned out so long.\n=\r\n\nRegarding which encodings are canalizeable, I think the jury is still out =\r\non that question.  Canalization remains a somewhat mysterious subject and I=\r\n don&#39;t think it&#39;s clear whether CPPNs can canalize as well as DNA or not be=\r\ncause we have not seen CPPNs yet with as many nodes as there are genes in t=\r\nhe DNA of many animals (on the order of tens of thousands).  Once you get u=\r\np to that level (e.g. a 30,000-node CPPN), the amount of redundancy and int=\r\nerdependence among all the parts might lead to a similar level of canalizat=\r\nion.  As I noted before, even on Picbreeder some canalization is already ev=\r\nident in the more complex images.\n\nBut I think we have a bigger problem in =\r\nthe field than canalization.  The real problem we face, and the source of t=\r\nension in this particular discussion (as well as many others), is that evol=\r\nution seems to be most powerful when it is open-ended, but we as researcher=\r\ns in EC want to control evolution for our own purposes, which in effects cl=\r\noses it.  Resolving this delicate contradiction is a fundamental problem in=\r\n EC right now.  Somehow we need to &quot;open&quot; evolution enough for it to flouri=\r\nsh while still imposing some level of control - a very uneasy balancing act=\r\n with no easy answers.  \n\n\nBest,\n\nken\n\n--- In neat@yahoogroups.com, &quot;martin=\r\n_pyka&quot; &lt;martin.pyka@...&gt; wrote:\n&gt;\n&gt; Thank you for this long answer which ha=\r\ns a lot of inspiring ideas that I would like to pick up. But let me first p=\r\noint out the different topics that have been discussed before because I am =\r\nafraid that the arguments you brought forward could be assigned to the wron=\r\ng topics ;)\n&gt; \n&gt; I think there are several questions (or topics of interest=\r\n) that are discussed here. \n&gt; \n&gt; Related to Jeffs Paper:\n&gt; a) Does connecti=\r\non cost represent a natural bias necessary for the emergence of modules?\n&gt; =\r\n\n&gt; I think this question is hard to answer and remains controversial ;) Pri=\r\nor beliefs can lead us to experiments that can support or refuse this theor=\r\ny.\n&gt; \n&gt; b) When someone wants to show that connection costs leads to modula=\r\nrity, does it matter whether a bias is implemented in the fitness function =\r\nor in the encoding *given the currently known techniques in both domains*?\n=\r\n&gt; \n&gt; My impression is, that Jeff and Stef mostly address this question and =\r\nunderstand Ken&#39;s arguments as a response to this question, while Ken argues=\r\n and understands Jeffs and Stefs arguments as a response to the question:\n&gt;=\r\n \n&gt; c) How does a biological plausible mechanism for any bias look like? \n&gt;=\r\n \n&gt; I think Ken&#39;s long answer here is a strong statement for encodings that=\r\n are able to canalize (and abandon) certain design principles and I mostly =\r\nagree with Ken&#39;s opinion related to question c. However, I don&#39;t think that=\r\n an artificial encoding with such good canalizing properties already exist.=\r\n So you are more arguing for spending more time in developing such an encod=\r\ning instead of investigating the influence of a bias on network function / =\r\narchitecture with available means. Because, when we have such an encoding, =\r\nit might help to understand how strong a certain bias (like connection cost=\r\n) in parts of the evolutionary process actually is and to which extent we c=\r\nan find modularity in the network. \n&gt; \n&gt; So, as far as I got it, Ken does n=\r\not say: =84use the encoding instead of the fitness function to bias the sea=\r\nrch towards modularity&quot; (as previous postings suggested it) but rather: =84=\r\nAn encoding with certain properties (e.g. canalization) would allow us to r=\r\neassess the value of concepts like =84connection cost&quot; and =84modularity&quot; &quot;=\r\n !?\n&gt; \n&gt; \n&gt; And in direct response to Ken&#39;s posting some random thoughts: \n=\r\n&gt; \n&gt; I also think that open-ended evolution is driven by a canalizable enco=\r\nding, and I think one can come up with many detailed properties that the en=\r\ncoding has to fullfill in order to be regarded as canalizable. The challeng=\r\ne is now: how to develop such an encoding given the fact that all these pro=\r\nperties are emergent properties of the encoding and therefore don&#39;t lead in=\r\n a deductive manner to the particular form of the encoding? I think, we fac=\r\ne here similar problems than in the lower abstraction levels. \n&gt; \n&gt; My firs=\r\nt idea was:  let&#39;s apply evolutionary algorithms on encodings to find the b=\r\nest encoding (something similar exist already for L-Systems), but how would=\r\n such a meta-language look like? \n&gt; \n&gt; I think that the idea of CPPNs repre=\r\nsents already a good starting point for canalizable encodings but its imple=\r\nmentation in HyperNEAT seems to me not to be consequent enough and looses a=\r\n lot of robustness as for example self-organizing mechanisms (like structur=\r\nal plasticity) are not implemented.  Of course, it is always easier to prov=\r\nide critique than to suggest a better solution ;-). I wished I would have m=\r\nore time to work on these things on my own. \n&gt; \n&gt; Best,\n&gt; Martin\n&gt;\n\n\n\n"}}