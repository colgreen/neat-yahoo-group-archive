{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"KVh0oiRxnldiZKqm45jvc-bDluhsIsRak_XYcwfv7QTNDinlPS46M4qYfRNevW-w7fO3XhUhoBq81ObpU2r3-jwbCQ_8DfkDpQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Bloat defeated! (Maybe...)","postDate":"1142981561","msgId":2578,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0MjA4M0I5LjQwMTA4MDRAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":2562,"nextInTopic":2595,"prevInTime":2577,"nextInTime":2579,"topicId":2532,"numMessagesInTopic":24,"msgSnippet":"Hi All, I wanted to just pick up this thread again because I think we were broaching on some fairly fundamental stuff, specifically Kens query about what the","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 74399 invoked from network); 21 Mar 2006 22:52:41 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m33.grp.scd.yahoo.com with QMQP; 21 Mar 2006 22:52:41 -0000\r\nReceived: from unknown (HELO blaster.systems.pipex.net) (62.241.163.7)\n  by mta4.grp.scd.yahoo.com with SMTP; 21 Mar 2006 22:52:41 -0000\r\nReceived: from [10.0.0.11] (81-86-161-87.dsl.pipex.com [81.86.161.87])\n\tby blaster.systems.pipex.net (Postfix) with ESMTP id 942DFE000377\n\tfor &lt;neat@yahoogroups.com&gt;; Tue, 21 Mar 2006 22:52:39 +0000 (GMT)\r\nMessage-ID: &lt;442083B9.4010804@...&gt;\r\nDate: Tue, 21 Mar 2006 22:52:41 +0000\r\nUser-Agent: Mozilla Thunderbird 1.0.7 (Windows/20050923)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Re: Bloat defeated! (Maybe...)\r\nX-Yahoo-Group-Post: member; u=127853030; y=vuCZrSn5Granh8VwMHqsjqEKcKUFkHW0ikR7nRkVYaPopJ4P22zY\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nHi All,\n\nI wanted to just pick up this thread again because I think we were \nbroaching on some fairly fundamental stuff, specifically Kens query \nabout what the optimum distribution of genomes might be in a search. \nAlso I&#39;m aware that some emails were left hanging with no response, so \nhopefully this will address some questions (though not necessarily \nanswer them!), albeit perhaps not in the way you might have been \nexpecting. Let me try and explain my train of thinking by going back to \nbasics.\n\nThe traditional evolutionary search uses a population of genomes, each \nof which represents a point in the search space. Thus the search &#39;front&#39; \ncontains multiple points at any point in time (generation), but how did \nwe arrive at this type of scheme and why is it so popular? Why not just \nhave one single search point and walk it around the search space - after \nall most of us haven&#39;t progressed to distributed/parallel multi-CPU \nprojects yet so why not just search one point at a time?\n\nA few immediate/obvious answers come to mind:\n1) We would get stuck in a local maxima.\n2) Recombination wouldn&#39;t be possible. Recombination basically being a \nmethod of generating new promising search points that are some way \ndistant from the current search front  - more promising than any \nsimilarly distant /random/ point we could come up with (probably).\n3) A population allows us to sample several points at a time around a \npromising area.\n\nOf course, without something like speciation the population will tend to \nbe dominated by offspring from a champ and the search front will \nprobably get stuck in a local maxima. This is where speciation comes in, \nensuring that the population doesn&#39;t cluster around one point. But I \nwonder now if we haven&#39;t just replaced one problem with another similar \nproblem, which is that our search front will now be a bunch of clusters \naround a maxima that never move on, instead of just one cluster.\n\nSpecies culling was meant to tackle this, but I question the \neffectiveness of this approach, e.g. it&#39;s very likely that species \nthemselves may cluster around a broad enough maxima, and so culling a \nspecies will just lead to existing species redistributing themselves \nover the newly vacated search area and a new species popping up around \nthe same cluster of species (since it spawned of one of them). There may \nbe cases where species are able to break away from clusters and walk the \nsearch space effectively, but I suspect that this clustering phenomenon \nremains a problem in the general case.\n\nEnter stage right the idea of the tabu search. [I&#39;m not sure if this is \nstrictly the correct term, but I&#39;ll use it for now for want of a better \nterm]. The tabu search introduces the idea of a memory of where in the \nsearch space we have already visited, so that we may avoid these areas \nand progress the search forward. This means that the natural clustering \nof the search front will still occur, but will be moved on as the tabu \nmechanism is applied. Previously I suggested ring fencing areas that had \npreviously been searched, although perhaps a better idea is to use a \nsort of density map of areas that have been searched. The areas of high \ndensity have a weighting assigned to them to limit further searching in \nthose areas, so if surrounding areas begin to match that weighting then \nthe old searched areas may actually be revisted - becasue their relative \nweight/density is now lower than the surrounding areas.\n\nThere is the problem of how you build and maintain such a density map, \nbut I choose to put that aside for the moment and concentrate of the \nconcept rather than get bogged down in implementation. Let&#39;s assume we \ncould maintain a search density map without too much CPU and memory \noverhead, well then couldn&#39;t we just discard the population based models \nand speciation and revert to a simple single point search front? The \npoint would naturally move away from well searched areas as it navigates \naway from high denisty areas on the map. In fact are population based \nsearches and techniques such as speciation just ways of approximating \njust such a search without the overhead of maintaining a map? - which I \nadmit may be impractical to implement.\n\nThis does leave the loose end of recombination - how would we jump to \nnew promising search points if we just had one point to start from? Our \nsingle point search wouldn&#39;t work very well if it only ever moved to \nadjacent areas in the search space, it would take an age to move to \nsomewhere in a completely different part of the space. Whereas a \npopulation based search (potentially) samples multiple points \ndistributed throughout the search space (when it isn&#39;t clustering \nanyhow). Well we could define some mechanism for &#39;jumping&#39; the single \npoint around the search space, well away from previously searched areas. \nIan is doing something like this I think - e.g. by creating fairly \nextreme mutants - although I could be remembering wrong there. OR we \ncould recomine previous disparate points in the historical search path, \nOR perhaps there is a case for a hybrid approach of a population based \nsearch combined with a density map - thus maintaining something \nanalagous to a gene pool, with it&#39;s associated diversity of solutions.\n\nThe practicalities of a denisty map are potentially a problem because \nyou have such a large area to map, but we could use a sort of limited \ndensity map where the old areas in the map get removed to keep the map \nfrom growing out of control - which is sort of how traditional tabu \nsearch works I think. That is, if you avoid all of the recentrly \nsearched areas then you can forget about avoiding the old search areas, \nbecause you are now so far away you are unlikely to find your way back.\n\nColin\n\n"}}