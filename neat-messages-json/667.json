{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"QKpVF33L86kUUAntNAcHa0OqrFPGhRGM2vATSm8FKBVUpLtYzNSPjH5svvx1V9bt95P1T6KjEZZAlYZvPGcS9gqYHbQqlFRjOzqDFnFlD5-7","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: autonomous virtual humans project","postDate":"1082488062","msgId":667,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGM2M3NkdStvNGM4QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDQwNDIwMDQxMTU3Ljg0NzUwLnFtYWlsQHdlYjQwNTA5Lm1haWwueWFob28uY29tPg=="},"prevInTopic":665,"nextInTopic":668,"prevInTime":666,"nextInTime":668,"topicId":657,"numMessagesInTopic":32,"msgSnippet":"I think another useful sense would be to tell the net when a foot touches the ground, and perhaps with what force/weight.  That way the NN can try to","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 17673 invoked from network); 20 Apr 2004 19:09:44 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m2.grp.scd.yahoo.com with QMQP; 20 Apr 2004 19:09:44 -0000\r\nReceived: from unknown (HELO n38.grp.scd.yahoo.com) (66.218.66.106)\n  by mta1.grp.scd.yahoo.com with SMTP; 20 Apr 2004 19:09:44 -0000\r\nReceived: from [66.218.66.119] by n38.grp.scd.yahoo.com with NNFMP; 20 Apr 2004 19:07:45 -0000\r\nDate: Tue, 20 Apr 2004 19:07:42 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;c63sdu+o4c8@...&gt;\r\nIn-Reply-To: &lt;20040420041157.84750.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Length: 2124\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.106\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: autonomous virtual humans project\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nI think another useful sense would be to tell the net when a foot\ntouches t=\r\nhe ground, and perhaps with what force/weight.  That way the\nNN can try to =\r\ndistribute its weight evenly, and react when a foot goes\nin the air.\n\nken\n\n=\r\n--- In neat@yahoogroups.com, Tyler Streeter &lt;tylerstreeter@y...&gt;\nwrote:\n&gt; \n=\r\n&gt; &gt; * joint angles\n&gt; &gt; * forces on body parts\n&gt; &gt;\n&gt; &gt; Those are the things =\r\nthat an actual human being is\n&gt; &gt; able to sense directly.\n&gt; \n&gt; I&#39;ve been th=\r\ninking about this idea quite a bit- things\n&gt; we can sense directly and &quot;sen=\r\nses&quot; we deduce from our\n&gt; more direct senses.  Can we directly sense joint\n=\r\n&gt; angles?  I&#39;m guessing not.  I think we probably deduce\n&gt; that from our mo=\r\nre direct &quot;force&quot; senses (i.e. sense\n&gt; of touch).  ...Not that that matters=\r\n for this project.\n&gt;  Of course, using simulated senses we (&quot;real&quot;) humans\n=\r\n&gt; don&#39;t have can help a simulated human.  However, I\n&gt; like the idea of mak=\r\ning simulated humans mimic real\n&gt; humans as closely as possible since real =\r\nhumans seem\n&gt; to work pretty well.\n&gt; \n&gt; I think there&#39;s a term for the sens=\r\ne of &quot;knowing your\n&gt; limbs&#39; positions, orientations, etc.&quot; is the\n&gt; &quot;propri=\r\noceptive system.&quot;  So maybe an artificial\n&gt; neural network could build this=\r\n sort of mental model\n&gt; given some primitive input.\n&gt; \n&gt; Another sense coul=\r\nd be the vestibular system (the\n&gt; circular tubes in our ears that help us s=\r\nense angular\n&gt; velocities).  That would be pretty simple to implement\n&gt; and=\r\n seems like it would help.\n&gt; \n&gt; Another big thing on my to-do list is a sen=\r\nse of\n&gt; sight.  The two main options I&#39;ve thought of are\n&gt; these:\n&gt; \n&gt; 1.  =\r\nRay-casting.  Shoot a grid of rays out from the\n&gt; face that each return the=\r\n distance of the nearest\n&gt; intersection (i.e. distance sensors).  More rays=\r\n could\n&gt; be added throughout evolution.  I&#39;ve heard that such\n&gt; intersectio=\r\nn testing in large quantities is pretty\n&gt; expensive if the environment is c=\r\nomplex.\n&gt; \n&gt; 2.  Use some sort of image processing/computer vision.\n&gt; \n&gt; Ty=\r\nler\n&gt; \n&gt; \n&gt; \t\n&gt; \t\t\n&gt; __________________________________\n&gt; Do you Yahoo!?\n&gt; =\r\nYahoo! Photos: High-quality 4x6 digital prints for 25=A2\n&gt; http://photos.ya=\r\nhoo.com/ph/print_splash\n\n\n"}}