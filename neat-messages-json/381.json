{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":115403844,"authorName":"John Arrowwood","from":"&quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"osfpj-py-tIv4kfz9mX87IZsRPErNWvXBi8HS1gQMbim6KeBsbcZPvV_5ZLOwI8tsd4wOma3njzAI4E66PGLSZ72LWWtEVFK7WXG4B4l","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [neat] Image Enlargement Project","postDate":"1076955886","msgId":381,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBWTItRjcxZVFMYTVETGtkNEgwMDAxNDYxYkBob3RtYWlsLmNvbT4="},"prevInTopic":380,"nextInTopic":382,"prevInTime":380,"nextInTime":382,"topicId":371,"numMessagesInTopic":22,"msgSnippet":"... Actually, I m using favorites first.  That is, if I only have enough disk space for 100 photos, I m going to use the ones I plan to enlarge first.  If ","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 41705 invoked from network); 16 Feb 2004 18:24:46 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m8.grp.scd.yahoo.com with QMQP; 16 Feb 2004 18:24:46 -0000\r\nReceived: from unknown (HELO hotmail.com) (65.54.247.71)\n  by mta3.grp.scd.yahoo.com with SMTP; 16 Feb 2004 18:24:46 -0000\r\nReceived: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\n\t Mon, 16 Feb 2004 10:24:46 -0800\r\nReceived: from 64.122.44.102 by by2fd.bay2.hotmail.msn.com with HTTP;\n\tMon, 16 Feb 2004 18:24:46 GMT\r\nX-Originating-Email: [jarrowwx@...]\r\nX-Sender: jarrowwx@...\r\nTo: neat@yahoogroups.com\r\nBcc: \r\nDate: Mon, 16 Feb 2004 10:24:46 -0800\r\nMime-Version: 1.0\r\nContent-Type: text/plain; format=flowed\r\nMessage-ID: &lt;BAY2-F71eQLa5DLkd4H0001461b@...&gt;\r\nX-OriginalArrivalTime: 16 Feb 2004 18:24:46.0474 (UTC) FILETIME=[27C3BEA0:01C3F4BA]\r\nX-eGroups-Remote-IP: 65.54.247.71\r\nFrom: &quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;\r\nReply-To: john@...\r\nSubject: RE: [neat] Image Enlargement Project\r\nX-Yahoo-Group-Post: member; u=115403844\r\nX-Yahoo-Profile: jarrowwx\r\n\r\n&gt;From: Derek James &lt;blue5432@...&gt;\n\n&gt;What was your approach in gathering a sample of test\n&gt;photos?  Were you trying to cover as broad a spectrum\n&gt;of types of images as possible, or narrowly defining\n&gt;the sample to similar images, under similar lighting\n&gt;conditions?\n\nActually, I&#39;m using &#39;favorites first.&#39;  That is, if I only have enough disk \nspace for 100 photos, I&#39;m going to use the ones I plan to enlarge first.  If \nthere are enough &#39;duplicate&#39; samples that I get all 3000 photos, great.\n\nI&#39;m not worried about similar images or similar lighting.  When you look at \na photo at the pixel level, such things don&#39;t play as big of a role.  There \nare smooth gradients and there are edges.  And I&#39;m going to use a scaled \nencoding, as mentioned in the paper &quot;Neural Network Image Scaling Using \nSpatial Errors&quot; (I can provide a link to the actual paper if you like).  To \nquote the paper:  &quot;This has the effect of stretching the windows so that the \nunderlying image structure is supplied and predicted by the network.  For \nexample, an edge is treated as an edge no matter what the contrast between \nthe sides is, nor the overall gray-level at which it occurs.&quot;\n\nFortunately, I don&#39;t have to worry about whether or not it will work.  These \nguys have already proven that a neural network can give really good results. \n  I just want to use NEAT to see if I can get an optimal network \nconfiguration.  Saves me the trouble of having to manually experiment with \ntopologies.\n\n&gt;I would think that the more diversity you have in the\n&gt;training set, the more difficult it might be to\n&gt;train/evolve networks for image enlargement.\n\nThat&#39;s the beauty of my initial segregation of training samples.  If as you \nsay I can&#39;t come up with a single network that does an adequate job, then I \ntrain a separate network for each of the categories of inputs.  For example, \none network that works on mostly flat areas, one for diagonal ridges, and \none for horizontal or vertical edges.  But according to the literature, a \nsingle network is adequate.  To quote the above paper: &quot;In practice we have \nfound that only a small number of hidden nodes are required to provide \nsatisfactory results.  In particular, we have found that reasonable results \ncan be obtained with between 10 and 30 hidden nodes.&quot;\n\nOn the other hand, they did not configure the hidden nodes in the usual way. \n  So, that makes me wonder what kinds of configurations NEAT might come up \nwith.\n\n&gt;I would think that networks trained/evolved to\n&gt;specialize in enlarging particular types of images\n&gt;(e.g., human faces) might be more efficient than a\n&gt;generalist enlarger for any and all types of images.\n\nYes and no.  If you break the picture into its component pieces and look at \nthem, there is no obvious relationship between the parts and the whole.  If \nyou look at an 8x8 piece of a picture, chances are it will be hard to know \nwhat you are looking at.  Nevertheless, there is enough information present \nto judge whether that dark spot on the right makes it into the center square \nor not.  If the dark region represents a curve, it should be possible to \ncalculate the shape of that curve and then use that information to fill in \nthe missing pixels.\n\nOn the other hand, if the statistical distribution of training samples \nfavors a particular category, then the network will be better at handling \nthat category than any other.  That is why I have chosen to break up the \ntraining data into clusters of similar samples.  Then I only present one \nexample per cluster during training/evolving.  It may end up requiring more \nhidden nodes to model the data, but it will not get skewed by trends in the \ntraining data.\n\n&gt;What approach are you taking?\n\nI may actually try both and see how it goes.   One general network, and one \nper category.\n\n&gt; &gt; Input node &#39;a&#39; is connected with weight 1 to all\n&gt; &gt; output nodes &#39;a&#39;.  Same for\n&gt; &gt; b, c, and d.  This corresponds exactly to a &#39;nearest\n&gt; &gt; neighbor&#39; or &#39;pixel\n&gt; &gt; enlargement&#39; algorithm.  The remaining input nodes\n&gt; &gt; are unconnected in the\n&gt; &gt; hopes that NEAT will decide for itself which nodes\n&gt; &gt; it needs and which it\n&gt; &gt; does not.\n&gt;\n&gt;That&#39;s an interesting approach.  It would be\n&gt;interesting to allow inputs to evolve at any distance\n&gt;across the entire image input, rather than a confined\n&gt;grid.\n\nPerhaps, but that increases my overhead by orders of magnitude.  I&#39;d rather \ntrust that the work that others have done is valid:  &quot;The input pattern \nconsists of a window around the pixel of interest drawn from the \nlow-resolution image.  The window size should increase as the scaling factor \nincreases - we have generally found that a window size of 5x5 is suitable fo \nfactor 2x upscaling, and 7x7 for factor 4x upscaling.&quot;  So I am going to \nstart out with similar input window size and try to replicate their success. \n  If it works, then I&#39;ll try letting it evolve with a larger input space and \nsee what it comes up with.\n\n&gt;There may be features in the lower right corner\n&gt;that provide important information on how to enlarge\n&gt;an area in the upper left corner.\n\nOnly to a human.  A human can make inferences based on the known structure \nof an object.  &quot;That&#39;s a pencil, therefore, I know that...&quot;  Such things are \nbeyond the scope of an image enlargement algorithm, and would be overkill \nanyway.  The information needed to make a good enlargement is already \ncontained in the bits that are present.\n\n&gt;While thinking about the domain you&#39;re interested in,\n&gt;I&#39;m also thinking about Go, and other game domains\n&gt;that Philip, I, and others on the list are\n&gt;particularly interested in.  We&#39;re interested in\n&gt;experimenting with a similar approach...a mobile\n&gt;viewing window which only looks at a portion of the\n&gt;board at a time.  We thought it would be interesting\n&gt;to allow the size and shape of the input window to\n&gt;evolve as well.\n\nI&#39;ll bet that the size of the window you give it determines the nature of \nthe solution, but that solutions exist for different sizes.\n\n&gt;And in Go, oftentimes there are features on one side\n&gt;of the board that affect decisions on the other side\n&gt;(e.g. ladders are sequences of moves along a path that\n&gt;can either result in life or death for a chain of\n&gt;stones depending on whether a friendly stone may lie\n&gt;in the projected path of the ladder).\n\nYes.  But I don&#39;t think that poses as big of a problem for image \nenlargement.  The task for enlargement is to extrapolate features.  Identify \nthe boundary of a curve, and put in the necessary pixels to make that curve \nfollow the path that we identified.\n\n&gt;It may be that an optimal &quot;window&quot; is actually a\n&gt;non-adjacent collection of inputs from various areas\n&gt;of the board.\n&gt;\n&gt;I&#39;m wondering if this may be the case in domains like\n&gt;image recognition and image enlargement.\n\nWe&#39;ll find out! :)\n\n&gt; &gt; Okay, I have now read all of the archives for the\n&gt; &gt; lits, so I&#39;m up to speed\n&gt; &gt; on the &#39;roving eye&#39; concept...  Yes, it is very\n&gt; &gt; similar, except it has no\n&gt; &gt; control over the roving.  It is applied successively\n&gt; &gt; to every 8x8 chunk of\n&gt; &gt; the image.\n&gt;\n&gt;I wonder how it might perform if it were given control\n&gt;over its movement.\n\nI&#39;m not sure how I would implement such a thing.  I&#39;ll have to chew on it a \nwhile.\n\n&gt;If the window could rescan\n&gt;particular regions and perhaps average its later\n&gt;output values with its initial ones.  For example, if\n&gt;the roving eye scans all the way to the lower right,\n&gt;then decides to adjust some of the output values back\n&gt;in the upper left, it can move back up and output new\n&gt;values, which could either replace, or be averaged\n&gt;with the old ones.\n&gt;\n&gt;Granted, this would be a hell of a lot more processing\n&gt;though.\n&gt;\n&gt; &gt; The original image is 1984x1488 pixels.  The\n&gt; &gt; enlarged image will be\n&gt; &gt; 7936x5952.\n&gt;\n&gt;Wow...those are big pics.  Might it be better to work\n&gt;with smaller ones first?\n\nI&#39;m taking the 3000 images and breaking them into 8x8 chunks.  Overlapping \nchunks, I might add.  Not just at the base resolution, but at 1/2, 1/3, 1/4, \n1/5, 1/6, 1/7, and 1/8th the original size.  That is, I will take a 32x32 \nchunk, reduce it to 8x8, and use that as the input, and the center 8x8 of \nthe 32x32 as the output.  And then I will take a 64x64 chunk, shrink it to \n32x32, and repeat.  And so on and so forth.  This produces a whole bunch of \n8x8 inputs that are completely disassociated from their original pictures.  \nThey simply represent a &#39;shape&#39; and what that shape should look like after \nit has been enlarged.  I want to start with so many training samples because \nI want to be sure that every posible &#39;shape&#39; is represented in the training \ndata.  I won&#39;t be using every one of those samples, only a fixed and \nbalanced number per &#39;category&#39; of shape.  But the point is, the size of the \nimage isn&#39;t important.  What&#39;s important is the balanced and representative \ntraining data.  The data must adequately describe the problem.  If I start \nwith less data, I don&#39;t describe the problem as well.  The end result is \nthat a sub-optimal solution will probably be found.\n\n&gt; &gt;  But I felt that having\n&gt; &gt; overlap would allow me to have a &#39;degree of\n&gt; &gt; confidence&#39; in particular\n&gt; &gt; pixels.\n&gt;\n&gt;This overlapping approach sounds like a good idea.\n&gt;\n&gt; &gt; My biggest problem at this point is time and disk\n&gt; &gt; space. :)  For now...\n&gt;\n&gt;Well good luck with it, and keep us posted.  Did you\n&gt;say which implementation of NEAT you plan on using?\n\nProbably the Linux/C++ version.  I&#39;ll have to teach myself C++ in the \nprocess, but such is life.\n\nI&#39;d use the Java version, but I want as much raw speed as I can get.  To \ngive you an idea, this weekend I wrote the code that identifies and &#39;hashes&#39; \nor categorizes each of the possible training samples from a single picture.  \nI took lots of care to try to optimize the heck out of it.  The initial \nversion took 12 minutes just for the initial calculations.  I analyzed and \nfound redundant calculations and got it down to just over 3 minutes on my \n500 MHz processor.  I even experimented to see what effect processing order \nmade, so I could factor in L2 cache hits vs. misses.   And that&#39;s without \nactually saving the results of any of those calculations.  That&#39;s just the \nsetup time for one photo.  That means almost a week just for that \npreparatory calculations, and doesn&#39;t include the time required to save that \ndata out to disk.  I&#39;m looking at 2-3 weeks minimum just to build my \ntraining data once I get the code written and perfected.  I&#39;m hoping to get \nthat part started in the next few days.  Then let it run until the disk is \nfull.  THEN I can start building the experiment for NEAT.  I&#39;ll keep \neveryone posted on my progress.\n\n-- John\n\n_________________________________________________________________\nPlan your next US getaway to one of the super destinations here. \nhttp://special.msn.com/local/hotdestinations.armx\n\n\n"}}