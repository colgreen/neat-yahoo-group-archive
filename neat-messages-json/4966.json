{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":162209378,"authorName":"rvonwahlde","from":"&quot;rvonwahlde&quot; &lt;rvonwahlde@...&gt;","profile":"rvonwahlde","replyTo":"LIST","senderId":"NpwYiwMpY7x8V_8B7XxdJwTiqgo_TKS5umPk6C--uZpTLkJjauQQQQNLyRorn4mZAfS7hcYnHfRhQUbNd7EpEIYC6_Nurt1dWhg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Best practices for teaching a network","postDate":"1259674254","msgId":4966,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhmMzVxZisxdm1uQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhmMWNqNitqYjcwQGVHcm91cHMuY29tPg=="},"prevInTopic":4964,"nextInTopic":0,"prevInTime":4965,"nextInTime":4967,"topicId":4928,"numMessagesInTopic":6,"msgSnippet":"Let me clarify.  Matt Buckland s code DOES reevaluate genomes that have already been evaluated.  For my application, I prevented this to save simulation time. ","rawEmail":"Return-Path: &lt;rvonwahlde@...&gt;\r\nX-Sender: rvonwahlde@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 79617 invoked from network); 1 Dec 2009 13:30:59 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m4.grp.sp2.yahoo.com with QMQP; 1 Dec 2009 13:30:59 -0000\r\nX-Received: from unknown (HELO n45b.bullet.mail.sp1.yahoo.com) (66.163.168.159)\n  by mta2.grp.re1.yahoo.com with SMTP; 1 Dec 2009 13:30:59 -0000\r\nX-Received: from [69.147.65.151] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 01 Dec 2009 13:30:56 -0000\r\nX-Received: from [98.137.34.184] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 01 Dec 2009 13:30:56 -0000\r\nDate: Tue, 01 Dec 2009 13:30:54 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hf35qf+1vmn@...&gt;\r\nIn-Reply-To: &lt;hf1cj6+jb70@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;rvonwahlde&quot; &lt;rvonwahlde@...&gt;\r\nSubject: Re: Best practices for teaching a network\r\nX-Yahoo-Group-Post: member; u=162209378; y=kPc9gE0Z6ygfFhAUAoqxwyO06mKbG1VDyH49-eSHYeIDV3f0iQ\r\nX-Yahoo-Profile: rvonwahlde\r\n\r\nLet me clarify.  Matt Buckland&#39;s code DOES reevaluate genomes that have alr=\r\neady been evaluated.  For my application, I prevented this to save simulati=\r\non time.\n\nRaymond\n\n--- In neat@yahoogroups.com, &quot;ddambroeplex&quot; &lt;ddambro84@.=\r\n..&gt; wrote:\n&gt;\n&gt; Part of the problem you are experiencing is that SharpNEAT a=\r\nnd HyperSharpNEAT (and apparently Matt Buckland&#39;s code, based on a recent p=\r\nost) don&#39;t reevaluate genomes that have already been evaluated.  This metho=\r\nd works great with deterministic, static fitness functions, but if you chan=\r\nge the fitness during evolution as you are doing, you will have to change t=\r\nhe code slightly.\n&gt; \n&gt; If you&#39;re using the SingleFilePopulationEvaluator, s=\r\nimply comment out lines 44 and 45 (if(g.EvaluationCount!=3D0) continue;).  =\r\nIf you&#39;re using the multi-threaded one the relevant code should already be =\r\ncommented out, but you can check on line 113 of MultiThreadedPopulationEval=\r\nuator.  \n&gt; \n&gt; The best fitness in the EvolutionAlgorithm class is calculate=\r\nd based on the fitnesses of the current population, so as long as you are r=\r\neevaluating everything you shouldn&#39;t have to worry about resetting that.  H=\r\nowever If you are using my CommandLineEvolution code, you will have to rese=\r\nt the maxFitness variable, otherwise it won&#39;t output new genome XML until y=\r\nou beat the old maxFitness value.\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Daniel=\r\n&quot; &lt;daniel_kuppitz@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Right now I train my network on a single=\r\n set of input data. After reaching a predefined fitness value I switch over=\r\n to the next set of input data. When the fitness is too low the training be=\r\ngins for this data and continues until the predefined fitness value is reac=\r\nhed and so on.\n&gt; &gt; After a few iterations the network produces perfect outp=\r\nuts on some sets of data. Consequently the best fitness value is extremly h=\r\nigh. When I now switch to a new set of data it&#39;s nearly impossible to reach=\r\n this fitness and so the best genome will never change again, even if it pe=\r\nrforms really bad on different inputs.\n&gt; &gt; My idea was that I could reset t=\r\nhe best fitness each time when I change the input data. The data is changed=\r\n within the EvaluateNetwork method; is there also a way to reset the best f=\r\nitness from within this method? Or should I better change the whole workflo=\r\nw?\n&gt; &gt; \n&gt; &gt; Cheers,\n&gt; &gt; Daniel\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Danie=\r\nl&quot; &lt;daniel_kuppitz@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hello everyone,\n&gt; &gt; &gt; \n&gt; &gt; &gt; I have=\r\n a general question regarding the learning process.\n&gt; &gt; &gt; \n&gt; &gt; &gt; After play=\r\ning around with NERO the last days, I&#39;ve learned a lot about how networks l=\r\nearn, but I still found no answer to this elementary question: In which seq=\r\nuence should I train a network that has to solve more than one task. NERO i=\r\nsn&#39;t build with HyperNEAT, but I think my questions target HyperNEAT as wel=\r\nl as NEAT.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Consider 9 stages:\n&gt; &gt; &gt; \n&gt; &gt; &gt; Network is ...\n&gt; &gt; =\r\n&gt; \n&gt; &gt; &gt;   1: quite good in task #1\n&gt; &gt; &gt;   2: really good in task #1\n&gt; &gt; &gt;=\r\n   3: perfect in task #1\n&gt; &gt; &gt;   4: quite good in task #2\n&gt; &gt; &gt;   5: really=\r\n good in task #2\n&gt; &gt; &gt;   6: perfect in task #2\n&gt; &gt; &gt;   7: quite good in tas=\r\nk #1 and #2\n&gt; &gt; &gt;   8: really good in task #1 and #2\n&gt; &gt; &gt;   9: perfect in =\r\ntask #1 and #2\n&gt; &gt; &gt; \n&gt; &gt; &gt; Obviously I&#39;ll begin with stage 1, but what&#39;s n=\r\next? Should I continue to train my network in this task (continue with stag=\r\ne 2) or should I switch to the next task (stage 4/7) and come back to stage=\r\n 2 later.\n&gt; &gt; &gt; The next question is: How should I calculate the fitness wh=\r\nen the network is trained in task #2.  Should solutions for task #2 be rewa=\r\nrded higher than those for task #1 (stage 4) or should solutions for task #=\r\n1 still get the same reward as in stage 1 (stage 7)?\n&gt; &gt; &gt; \n&gt; &gt; &gt; Maybe the=\r\nre&#39;s no general answer to my questions, but what&#39;s the best practice? What =\r\nmakes sense, what does not?\n&gt; &gt; &gt; \n&gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; Daniel\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n=\r\n\n\n"}}