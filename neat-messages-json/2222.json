{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"2CWTSpBnmknzrmlJpeo2WEl1KzEyeEEMVsoZq-wyb3U_VKjFcl0lVvVTHtiYSC5Dcp9cc9RwiCGsA-J-6dmEN0xPNZt4gNErRC2DodKImM6c","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Introduction---recurrency question","postDate":"1125459712","msgId":2222,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRmMzh1MCtkNGhvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGRlcTg2aithcnBxQGVHcm91cHMuY29tPg=="},"prevInTopic":2221,"nextInTopic":2223,"prevInTime":2221,"nextInTime":2223,"topicId":2209,"numMessagesInTopic":42,"msgSnippet":"This all has to do with the granularity of time.  Usually in a virtual environment, there is such a high granularity of timesteps (i.e. at least a few per","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 54046 invoked from network); 31 Aug 2005 03:41:55 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m32.grp.scd.yahoo.com with QMQP; 31 Aug 2005 03:41:55 -0000\r\nReceived: from unknown (HELO n23.bulk.scd.yahoo.com) (66.94.237.52)\n  by mta2.grp.scd.yahoo.com with SMTP; 31 Aug 2005 03:41:54 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.69.4] by n23.bulk.scd.yahoo.com with NNFMP; 31 Aug 2005 03:41:53 -0000\r\nReceived: from [66.218.66.80] by mailer4.bulk.scd.yahoo.com with NNFMP; 31 Aug 2005 03:41:53 -0000\r\nDate: Wed, 31 Aug 2005 03:41:52 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;df38u0+d4ho@...&gt;\r\nIn-Reply-To: &lt;deq86j+arpq@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Length: 11834\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Introduction---recurrency question\r\nX-Yahoo-Group-Post: member; u=54567749; y=QOOvumtNYVnnxGgnA8w4FdwMA30Xzw79aiFyAt8ZDUb1RaNH3YR7\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nThis all has to do with the granularity of time.  Usually in a \nvirtual env=\r\nironment, there is such a high granularity of timesteps \n(i.e. at least a f=\r\new per second) that each move or change of state \nis tiny.  \n\nIn other word=\r\ns, the output saying &quot;move forward&quot; results in only the \ntiniest micro-move=\r\nment over the course of one timestep, so by the \ntime the activation has pr=\r\nopagated from the inputs through the \nhidden nodes, the state of the world =\r\nis hardly different.\n\nThis makes intuitive sense when compared to the real =\r\nworld.  Clearly \nthe signals coming into your eyes are *newer* than those t=\r\nhat came \ninto you eyes earlier when you first began to raise your hand to =\r\n\nblock a ball flying into your face.  But that doesn&#39;t present any \nparticu=\r\nlar problem because the activation traverses the entire \nnetwork so fast (i=\r\n.e. there are so many timesteps that pass) that it \nis as if everything hap=\r\npened in the same instant.\n\nIn other words, if you make time ticks so gappy=\r\n that huge changes \noccur between them, then of course you will have seriou=\r\ns problems \nusing input that has had to propagate through the network.  But=\r\n if \ntime ticks quickly, one timestep and the next are hardly different.\n\nA=\r\nlso you can increase the rate of &quot;thought&quot; relative to the rate of \ntime by=\r\n activating twice or more per timestep if you really feel \nit&#39;s necessary, =\r\nthough that is a major increase in CPU time so you \nneed to think about it =\r\ncarefully whether that is necessary.  I have \nnever done it.\n\nBy the way, J=\r\nohn&#39;s point about precomputing an activation order and \nthen propagating it=\r\n all the way through the network in each tick \nactually could work better t=\r\nhan the &quot;standard&quot; way of activating a \nnetwork, which I am describing.  No=\r\nte that the standard way also \ncreates a kind of &quot;memory&quot; potential in that=\r\n if you chain nodes \nalong you can delay activation and thereby react to in=\r\nformation from \nthe past *without* recurrent connections.  With John&#39;s meth=\r\nod, that \nwouldn&#39;t happen.  But aside from that, I am still pondering wheth=\r\ner \nthere is any reason not to do it John&#39;s way.\n\nActually, I originally ha=\r\nd NEAT written to work John&#39;s way but Risto \n(my advisor) told me that no o=\r\nne activates a network like that; he \nsaid, &quot;why would you do it that way?&quot;=\r\n  At the time I just thought \nI&#39;d made a mistake so I switched to the &quot;stan=\r\ndard&quot; method, but now \nas I think about it again, it&#39;s worth a second look.=\r\n\n\nken\n\n--- In neat@yahoogroups.com, &quot;maitrikaruna&quot; &lt;kevin@t...&gt; wrote:\n&gt; Hi=\r\n Ken,\n&gt; \n&gt; Your explanation was very helpful..I thought I &quot;had&quot; it, but I \n=\r\n&gt; discovered more subtlety to this than I originally thought.  this \nis \n&gt; =\r\nbest given in a scenario network where:\n&gt; \n&gt; NODE1 is input node\n&gt; NODE2 is=\r\n input node\n&gt; NODE3 is hidden node\n&gt; NODE4 is output node\n&gt; \n&gt; NODE4 tells =\r\nan agent to move either up or down.  Any movement of \n&gt; this agent will nec=\r\nessarily require a review of its sensory input \n&gt; coming in from node1 and =\r\nnode2(or does it?).\n&gt; \n&gt; Links are as follows(all neuron thresholds are 1.0=\r\n):\n&gt; \n&gt; NODE1--&gt;NODE3 weight 1.0\n&gt; NODE2--&gt;NODE4 weight 1.0\n&gt; NODE3--&gt;NODE4=\r\n weight 1.0\n&gt; NODE4--&gt;NODE3 weight -.3 //this is the recurrent connection\n&gt;=\r\n \n&gt; So suppose we have binary inputs from the &quot;world&quot; with values of 1 \n&gt; f=\r\nor both NODE1 and NODE2.  As this propogates, the input totals \nfor \n&gt; the =\r\nneurons should be:\n&gt; \n&gt; NODE3=3D1.0 enough to fire, but as i understand it,=\r\n we do not yet \n&gt; actually fire it by adding its links weight to NODE4\n&gt; \n&gt;=\r\n NODE4=3D1.0 enough to fire, but as i understand it, we do not yet \n&gt; actua=\r\nlly fire it by adding its links weight to NODE3\n&gt; \n&gt; So this leads to my fi=\r\nrst question...since at this first timestep \n&gt; NODE4 can fire, and it *is* =\r\nan output node, do we fire it in the \n&gt; sense that it tells the agent to ma=\r\nke a move?  But my dilemma is \n&gt; that if the answer to that is &quot;yes&quot;, then =\r\nthis changes the state \nof \n&gt; the world and we need on the next timestep to=\r\n re-propogate from \nthe \n&gt; inputs.  If this is so, then how will a signal e=\r\nver get from the \n&gt; hidden layer in this network to the output layer since =\r\n&quot;a signal \n&gt; never travels from input--&gt;hidden--&gt;output in one step.&quot;?  It =\r\ndoes \n&gt; not seem logical to make an agent move and not reconsider the \n&gt; cu=\r\nrrent sensor input.\n&gt; \n&gt; I have a fwe more questions, but i&#39;ll leave them f=\r\nor later...sorry \n&gt; if this is elementary stuff.\n&gt; \n&gt; --Kevin\n&gt; \n&gt; \n&gt; \n&gt; \n&gt;=\r\n \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@c...&gt; \nwrot=\r\ne:\n&gt; &gt; Kevin,\n&gt; &gt; \n&gt; &gt; Let me add to Charles comments a bit...although Char=\r\nles does a \n&gt; good \n&gt; &gt; job giving some background, I believe there are som=\r\ne things \n&gt; Charles \n&gt; &gt; didn&#39;t mention you should be aware of.\n&gt; &gt; \n&gt; &gt; Fi=\r\nrst, see the question, &quot;How are networks with arbitrary \n&gt; topologies \n&gt; &gt; =\r\nactivated?&quot; in the NEAT FAQ located at:\n&gt; &gt; \n&gt; &gt; http://www.cs.utexas.edu/u=\r\nsers/kstanley/neat.html\n&gt; &gt; \n&gt; &gt; That question gives some background on you=\r\nr own question.\n&gt; &gt; \n&gt; &gt; The short answer is that every node is activated o=\r\nn every \ntimestep \n&gt; &gt; from ALL incoming connections.  Any node that has no=\r\nt yet \nreceived \n&gt; &gt; input it assumed to be outputting a zero.  In other wo=\r\nrds, time \n&gt; &gt; delay does not enter into it at all (I have never actually u=\r\nsed \n&gt; the \n&gt; &gt; time-delay code).  Also, activation does not travel all the=\r\n way \n&gt; from \n&gt; &gt; inputs to outputs in a single timestep unless there is a =\r\ndirect \n&gt; &gt; connection from inputs to outputs.  But activation traveling \no=\r\nver \n&gt; &gt; intervening nodes will take extra time to get there.\n&gt; &gt; \n&gt; &gt; So w=\r\nhat happens is that a node that connects to itself receives \n&gt; the \n&gt; &gt; act=\r\nivation that itself output on the *previous* timestep.  \n&gt; Networks \n&gt; &gt; ar=\r\ne activated over a series of timesteps.\n&gt; &gt; \n&gt; &gt; It is important to note th=\r\nat you should *not* be relaxing a \n&gt; network \n&gt; &gt; during a control task lik=\r\ne food gathering.  Charles mentions \n&gt; &gt; relaxation but that is only approp=\r\nriate for classification tasks \n&gt; &gt; where the network is trying to decide o=\r\nn a final answer.  See \nthe \n&gt; &gt; question, &quot;How do I ensure that a network =\r\nstabilizes before \ntaking \n&gt; &gt; its output(s) for a classification problem?&quot;=\r\n in the NEAT FAQ for \n&gt; &gt; more info on this.\n&gt; &gt; \n&gt; &gt; In a continual contro=\r\nl task like food gathering (or most tasks \n&gt; NEAT \n&gt; &gt; is used for) there i=\r\ns always new input coming in and new output \n&gt; &gt; coming out, so the network=\r\n will never relax, since there is \n&gt; &gt; no &quot;final&quot; answer.  The only questio=\r\nn that comes up is how many \n&gt; &gt; times (steps) to activate the network per =\r\nworld tick.  Almost \nany \n&gt; &gt; experiment I&#39;ve heard of activates once per t=\r\nick, but it is \n&gt; possible \n&gt; &gt; to imagine activating &gt;1 time per tick, whi=\r\nch is equivalent to \n&gt; &gt; speeding up the rate of thought.   However, note t=\r\nhat more \n&gt; &gt; activations also means more CPU time per world tick.\n&gt; &gt; \n&gt; &gt;=\r\n I hope this help; feel free to ask any other questions.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; \n=\r\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, Charles Tarun &lt;ctarun@g...&gt;=\r\n wrote:\n&gt; &gt; &gt; Hello Maitrikaruna,\n&gt; &gt; &gt; I would like to offer any help I ca=\r\nn, and I&#39;m sure others will \n&gt; &gt; also help,\n&gt; &gt; &gt; \n&gt; &gt; &gt; I also don&#39;t have =\r\nany training on NN either, but I&#39;ve been \nread \n&gt; a \n&gt; &gt; lot about \n&gt; &gt; &gt; t=\r\nhem. Each implementation of NEAT handles the firing of the \nnode \n&gt; &gt; in th=\r\neir \n&gt; &gt; &gt; own way, as NEAT doesn&#39;t define it exactly. My method of \nchoice=\r\n \n&gt; is \n&gt; &gt; one of \n&gt; &gt; &gt; the SharpNEAT ones, &quot;FastConcurrentNetwork&quot;. This=\r\n network \n&gt; &gt; simulates each \n&gt; &gt; &gt; neuron activating concurrently.\n&gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; 1) Assign the values to all input nodes\n&gt; &gt; &gt; 2) Activate the network=\r\n \n&gt; &gt; &gt; 3) Relax the network\n&gt; &gt; &gt; 4) Read the outputs\n&gt; &gt; &gt; \n&gt; &gt; &gt; Activat=\r\ne network is pass a parameter of how many times to run \n&gt; for, \n&gt; &gt; this is=\r\n \n&gt; &gt; &gt; basically how many steps to run for. Each step uses the signal \n&gt; &gt;=\r\n strength from \n&gt; &gt; &gt; the previous.\n&gt; &gt; &gt; \n&gt; &gt; &gt; The Relax network function=\r\n is very much like the Activate \n&gt; &gt; function, but also \n&gt; &gt; &gt; take in a ma=\r\nxAllowedSignalDelta. It runs until the signal \nchange \n&gt; &gt; for each \n&gt; &gt; &gt; =\r\nnode is &lt;maxAllowedSignalDelta or the maxSteps count is \nreached. \n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; |-------\n&gt; &gt; &gt; v |\n&gt; &gt; &gt; NODE1--&gt;NODE2--&gt;NODE3\n&gt; &gt; &gt; \n&gt; &gt; &gt; They way I=\r\n see this working with your diagram is(assuming the \n&gt; &gt; links had \n&gt; &gt; &gt; e=\r\nnough weight to cause the next to fire):\n&gt; &gt; &gt; \n&gt; &gt; &gt; Step 1:\n&gt; &gt; &gt; Node1(i=\r\nnput) is firing.\n&gt; &gt; &gt; node2 get enough signal to fire at this time stamp\n&gt;=\r\n &gt; &gt; node3 only getting signal from the previous step when node2 \n&gt; wasn&#39;t =\r\n\n&gt; &gt; firing \n&gt; &gt; &gt; does not have enough signal to fire.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Step2:=\r\n\n&gt; &gt; &gt; Node1(input) is firing.\n&gt; &gt; &gt; node2 gets enough signal to fire from =\r\nnode1&#39;s last step, but \nis \n&gt; &gt; not getting \n&gt; &gt; &gt; signal from node3.\n&gt; &gt; &gt;=\r\n node3 gets enough signal to fire from node2&#39;s last step and \nfires\n&gt; &gt; &gt; \n=\r\n&gt; &gt; &gt; step3:\n&gt; &gt; &gt; Node1(input) is firing(As always, input nodes don&#39;t chan=\r\nge)\n&gt; &gt; &gt; node2 is getting signal from node1 and node3 now\n&gt; &gt; &gt; node3 is g=\r\netting signal from node2 last time step, the \nrecurrent \n&gt; &gt; connection \n&gt; =\r\n&gt; &gt; hasn&#39;t effected the signal from 2 to 3 yet.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Under such a s=\r\nystem it is possible to get oscillation in the \n&gt; &gt; signals, that&#39;s \n&gt; &gt; &gt; =\r\nwhy there is a maxSteps on the relax function. The creator of \n&gt; &gt; SharpNEA=\r\nT is \n&gt; &gt; &gt; part of this list as well(Colin D. Green). I hope this will be =\r\n\n&gt; &gt; helpful.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Chuck Tarun\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; On=\r\n 8/24/05, maitrikaruna &lt;kevin@t...&gt; wrote:\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Hello all,\n&gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; I stumbled on NEAT just a short week ago and have found it \nve=\r\nry\n&gt; &gt; &gt; &gt; interesting. I spent the last few days implementing NEAT in\n&gt; &gt; =\r\n&gt; &gt; PowerBASIC and I&#39;m nearly done. I am doing a rather simple\n&gt; &gt; &gt; &gt; simu=\r\nlation.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I basically set up a &quot;room&quot; and drop an agent in t=\r\nhe middle.\n&gt; &gt; &gt; &gt; The\n&gt; &gt; &gt; &gt; agent needs to eat=85so I place a large circ=\r\nle representing\n&gt; &gt; food in\n&gt; &gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; room. The agent has so many=\r\n steps to find the food or it\n&gt; &gt; &gt; &gt; disappears. The food is then moved to=\r\n a new location and the \n&gt; &gt; agent\n&gt; &gt; &gt; &gt; can try again. The agent is test=\r\ned against four different \nfood\n&gt; &gt; &gt; &gt; locations. The agent has 8 sensors =\r\nthat allow it to &quot;see&quot; in\n&gt; &gt; &gt; &gt; those 8\n&gt; &gt; &gt; &gt; directions.\n&gt; &gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; &gt; Right now with only 50 parents and 10 generations it is able \n&gt; to \n&gt; &gt;=\r\n find\n&gt; &gt; &gt; &gt; all the 4 different food bins after about9 or 10 \ngens...whic=\r\nh \n&gt; is\n&gt; &gt; &gt; &gt; pretty good.. Especially since I discovered that I have a \n=\r\n&gt; neuron\n&gt; &gt; &gt; &gt; firing issue in my code..\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Anyway..I am co=\r\nmpletely new to NN&#39;s...i have no training on \n&gt; them \n&gt; &gt; at\n&gt; &gt; &gt; &gt; all, a=\r\nlthough I do know GA&#39;s fairly well (I am CEO of \n&gt; &gt; bioinformatics\n&gt; &gt; &gt; &gt;=\r\n firm that uses GA&#39;s to analyze genetics data).\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I have a q=\r\nuestion I hope you can help with. the way I setup \nthe\n&gt; &gt; &gt; &gt; networks all=\r\nows for recurrent connections to occur. So \nsuppose \n&gt; &gt; you\n&gt; &gt; &gt; &gt; have a=\r\n simple netowrk where input node 1 connects to hidden \n&gt; node \n&gt; &gt; 2,\n&gt; &gt; &gt;=\r\n &gt; which connects to hidden node 3, which connects to back to \n&gt; node \n&gt; &gt; =\r\n2.\n&gt; &gt; &gt; &gt; How is firing to proceed in such a scenario? Node 2 can&#39;t \nfire\n=\r\n&gt; &gt; &gt; &gt; until it has all its inputs, yet one of its outputs(the one \nto \n&gt; =\r\n&gt; node\n&gt; &gt; &gt; &gt; 3) affects what its input will be. Thanks for your help...\n&gt;=\r\n &gt; &gt; &gt; |-------\n&gt; &gt; &gt; &gt; v |\n&gt; &gt; &gt; &gt; NODE1--&gt;NODE2--&gt;NODE3\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\nAnd what if a node links back to itself? Then how is the \nfiring\n&gt; &gt; &gt; &gt; se=\r\nquence to work? I saw a time delay in teh C code and I am\n&gt; &gt; &gt; &gt; guessing =\r\nthis is involved, but I&#39;m not quite sure how...\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; When I get=\r\n this working, I would like to tackle the tic-tac-\ntoe\n&gt; &gt; &gt; &gt; problem you =\r\nguys are working on.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; i really appreciate all your posts...=\r\nvery enlightening...\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Best,\n&gt; &gt; &gt; &gt; Kevin Cramer\n&gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Yahoo! Groups Links\n&gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;\n\n\n\n"}}