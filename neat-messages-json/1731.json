{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"Dxs2zEr2k0B2N6zvV_6QuLX1nOOiNyRLC2IKA0ZnCu7WpGH6QLr_q8ibBlROmf8qMHMNZNMF91Ce_GEltlXPfgz3MSpqTI4B93NMVCYlAf1P","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: GECCO 2005","postDate":"1100730055","msgId":1731,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNuZ2lzOCtzc2E5QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDE5YjEwZDUxMDQxMTE2MDcwNjM0NTE1ZTZmQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":1726,"nextInTopic":1734,"prevInTime":1730,"nextInTime":1732,"topicId":1720,"numMessagesInTopic":9,"msgSnippet":"Man, I just gotta say, this is a really cool demo.  I think what s so compelling about it is that you are watching the eye thinking. Hopefully if you get a","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 84692 invoked from network); 17 Nov 2004 22:21:10 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m14.grp.scd.yahoo.com with QMQP; 17 Nov 2004 22:21:10 -0000\r\nReceived: from unknown (HELO n17a.bulk.scd.yahoo.com) (66.94.237.46)\n  by mta2.grp.scd.yahoo.com with SMTP; 17 Nov 2004 22:21:09 -0000\r\nReceived: from [66.218.69.2] by n17.bulk.scd.yahoo.com with NNFMP; 17 Nov 2004 22:20:57 -0000\r\nReceived: from [66.218.67.153] by mailer2.bulk.scd.yahoo.com with NNFMP; 17 Nov 2004 22:20:56 -0000\r\nDate: Wed, 17 Nov 2004 22:20:55 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;cngis8+ssa9@...&gt;\r\nIn-Reply-To: &lt;19b10d51041116070634515e6f@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2999\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.94.237.46\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: GECCO 2005\r\nX-Yahoo-Group-Post: member; u=54567749\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\nMan, I just gotta say, this is a really cool demo.  I think what&#39;s \nso compelling about it is that you are watching the eye &quot;thinking.&quot;\nHopefully if you get a paper accepted you&#39;ll get a chance to show \nthis demo.  I think it would get a really good reaction.\n\nken\n\n--- In neat@yahoogroups.com, Derek James &lt;djames@g...&gt; wrote:\n&gt; On Tue, 16 Nov 2004 02:18:47 -0000, Kenneth Stanley\n&gt; &lt;kstanley@c...&gt; wrote:\n&gt; &gt;\n&gt; &gt; What are the eye&#39;s motions like when looking over fingerprints?  \nIt\n&gt; &gt; would be really interesting to see movies of the the eye \nexamining a\n&gt; &gt; fingerprint.\n&gt; \n&gt; Well, there you go.  I&#39;ve uploaded another Flash movie,\n&gt; &quot;left_loop2.swf&quot; into the files section of the group:\n&gt; \n&gt; http://f6.grp.yahoofs.com/v1/4AeaQcXY5lgs-UB2o8GRVhmNYECb-\nSIVrixEfUUQ7ZnnUfHOWucQ1WZHRBRPJTxW6aEQJLDF0w2xu1KtIUF1Ig/left_loop2.\nswf\n&gt; \n&gt; This particular network is evolved to recognize the left loop \nclass of\n&gt; fingerprints.  Here are some samples of the different classes:\n&gt; \n&gt; http://www.nist.gov/srd/fing_img.htm\n&gt; \n&gt; For now we&#39;re just focusing on the four-class problem, lumping\n&gt; together arch and tented arch (which together only make up about 5-\n6%\n&gt; of fingerprints in the natural population anyway).\n&gt; \n&gt; So if you watch the movie, you&#39;ll see that the eye always seems to\n&gt; zoom in on the core of the print, then oscillate in that core \narea. \n&gt; For left loops, though, it zooms into the core, then always drifts\n&gt; away to the left.  It&#39;s interesting to note that it pretty easily\n&gt; distinguishes between right loops and arches, while the class that\n&gt; seems difficult to distinguish between the most is whorl.\n&gt; \n&gt; I didn&#39;t include the affinity representation in the uploaded movie,\n&gt; but with whorls, the eye begins to drift the left, spitting out \nhigh\n&gt; affinities, but then apparently notices that the ridge lines don&#39;t\n&gt; continue to slant the same way they do in a left loop pattern, so \nthe\n&gt; eye returns to the core of the whorl and oscillates.\n&gt; \n&gt; Now, I actually thought that loops would be more likely to be \nconfused\n&gt; with arches, but apparently the eye doesn&#39;t have much problem \nmaking\n&gt; that distinction.\n&gt; \n&gt; One of the things I&#39;m really pleased about is that the neural \nnetwork\n&gt; doesn&#39;t seem to have a problem handling images where the contrast\n&gt; levels are quite different.  We did a few brief experiments with\n&gt; fingerprint images that we had done some preprocessing on, to try \nto\n&gt; filter out some of the noise and heighten the contrast of the ridge\n&gt; lines to the background, but that doesn&#39;t seem to really affect the\n&gt; evolving fitness much.  So it&#39;s nice that the system seems to be \nable\n&gt; to handle raw images.  Most other systems do a lot of\n&gt; computationally-expensive pre-processing of the images.  In fact, \none\n&gt; of the most successful research projects we read about take up to \n10\n&gt; seconds per print for classification.  I don&#39;t know what kind of\n&gt; accuracy rate we&#39;ll end up with, but we&#39;ll definitely be able to \nbeat\n&gt; that by a long way.\n&gt; \n&gt; Derek\n\n\n\n\n"}}