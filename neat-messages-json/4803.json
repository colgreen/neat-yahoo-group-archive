{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"0g8pkhReEo3SYPCxSuHOEUOG9ErSAW2iSDTwEzs195mJP28rM9iyohlsbfXfQwZemj8ZOqQ75_uiswhjJw2ZobDc1_2re8AV5A1dEmmesG0o","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HybrID: A Hybridization of Indirect and Direct Encodings for Evolutionary Computation","postDate":"1249425673","msgId":4803,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGg1YWRlOSszMGJrQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM2OTlFNDU3LjJCQjAzJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4800,"nextInTopic":4819,"prevInTime":4802,"nextInTime":4804,"topicId":4772,"numMessagesInTopic":19,"msgSnippet":"Jeff, I m going to give you a split-brained response.   First, I ll point out one more reason to be cautious about drawing conclusions about representation in","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 29230 invoked from network); 4 Aug 2009 22:41:41 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m8.grp.re1.yahoo.com with QMQP; 4 Aug 2009 22:41:41 -0000\r\nX-Received: from unknown (HELO n4-vm6.bullet.mail.sp2.yahoo.com) (67.195.135.100)\n  by mta3.grp.re1.yahoo.com with SMTP; 4 Aug 2009 22:41:41 -0000\r\nX-Received: from [67.195.134.239] by n4.bullet.mail.sp2.yahoo.com with NNFMP; 04 Aug 2009 22:41:16 -0000\r\nX-Received: from [69.147.65.171] by t4.bullet.mail.sp2.yahoo.com with NNFMP; 04 Aug 2009 22:41:16 -0000\r\nX-Received: from [98.137.34.184] by t13.bullet.mail.sp1.yahoo.com with NNFMP; 04 Aug 2009 22:41:16 -0000\r\nDate: Tue, 04 Aug 2009 22:41:13 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;h5ade9+30bk@...&gt;\r\nIn-Reply-To: &lt;C699E457.2BB03%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: HybrID: A Hybridization of Indirect and Direct Encodings for Evolutionary Computation\r\nX-Yahoo-Group-Post: member; u=54567749; y=Alt-JXVpBzfTgjMArZjJRCJPgPNewWDmcI_mtwxGRvh41czTlVig\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff, I&#39;m going to give you a split-brained response.   First, I&#39;ll point o=\r\nut one more reason to be cautious about drawing conclusions about represent=\r\nation in HyperNEAT from your results and then I&#39;ll go ahead and draw conclu=\r\nsions from it anyway :)\n\nI just want to point out first that the lesson of =\r\nnovelty search applies very much to results on irregularity:  Just because =\r\na particular method or representation fails to evolve a particular pattern =\r\nwhen that pattern is a target does not mean that the method or representati=\r\non cannot represent such a pattern.  For example, in my experiment with Joe=\r\nl Lehman, NEAT could almost never solve the hard maze problem, so you might=\r\n then conclude that NEAT needs to be improved to solve such problems or rep=\r\nresent their solutions.  But when we run novelty search with NEAT, it solve=\r\ns it almost every time, showing that the problem is not with NEAT after all=\r\n, but rather with how the objective is formalized.\n\nIt is completely possib=\r\nle that the same is true with the quadruped experiment .  That is, in the c=\r\nanned situation of your objective scenario, HyperNEAT becomes deceived and =\r\nends up coming short of the optimal irregularities.  However, we cannot con=\r\nclude from this result that HyperNEAT has any real problem with representin=\r\ng such irregularities.  After all, there are numerous pictures on Picbreede=\r\nr that NEAT with CPPNs would be terrible at evolving if they were made the =\r\nobjective, yet we know that they in fact are from CPPNs!  So we have to be =\r\ncareful about concluding too much about the representation.  \n\nFurthermore,=\r\n much of the fine-grained refinement that does ultimately lead to highly op=\r\ntimized articulated control in nature is probably due to adaptive mechanism=\r\ns, which suggests more that adaptation is important than that some special =\r\nmechanism for encoding exceptions is necessary.\n\nNevertheless, I still spen=\r\nt time thinking about what it all means assuming that there is a need for b=\r\netter expression of exceptions.  It&#39;s definitely still worth considering.  =\r\nAnd I started thinking that the issue may be less about irregularity than a=\r\nbout *independence*.  That is, your direct encoding is entirely independent=\r\n of your indirect encoding.  Is it the fact that the direct encoding is irr=\r\negular, or is it the fact that it is independent that matters?\n\nHere is an =\r\ninteresting experiment:  What if you ran the usual evolution with the quadr=\r\nuped with a CPPN, and then, when you would have switched to direct encoding=\r\n, instead you start evolving a *second* CPPN (for each individual) whose ou=\r\ntput is simply added to the first.  The second CPPN would then be completel=\r\ny independent of the motifs and symmetries in the first.  That way, when it=\r\ns output is added to the first, it will appear irregular (because it does n=\r\not follows its conventions), even though the CPPN itself is still biased to=\r\nwards its own independent irregularities.  \n\nIn fact, if you add one arbitr=\r\nary symmetric pattern to another one that is oriented differently, the resu=\r\nlt can look entirely irregular, even though it is composed to two regular s=\r\nub-patterns.\n\nPerhaps, under this hypothesis, CPPNs could be improved simpl=\r\ny by allowing them to develop parallel independent patterns simultaneously =\r\nmore easily.\n\nIt&#39;s mainly interesting to consider because it does not intro=\r\nduce the unpalatable chaos of direct encoding back into the mix, yet perhap=\r\ns captures some of the spirit of what you feel is missing.   In this way, &quot;=\r\nirregularities&quot; can still be described as holistic patterns, so that they c=\r\nan scale into very high dimensions.\n\nIt&#39;s just something to think about; I&#39;=\r\nm not sure about it, and there are clearly a broad range of options (e.g. r=\r\nadial basis functions) for changing representation.\n\nken\n\n\n--- In neat@yaho=\r\nogroups.com, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; &gt; But is the quadruped real=\r\nly representative of &quot;real-world&quot; problems that\n&gt; &gt; nature solved?  I don&#39;t=\r\n think the quadruped solution is anything like nature&#39;s\n&gt; &gt; solutions to qu=\r\nadruped walking.  The HybrID quadruped was allowed to *further*\n&gt; &gt; evolve =\r\nto adjust to joint faults, whereas real-life quadrupeds would simply\n&gt; &gt; ad=\r\napt during their lifetime, which is a major difference.  In fact, walking\n&gt;=\r\n &gt; solutions in the real world are adaptive and malleable, not canned circu=\r\nits\n&gt; &gt; that only produce a single gait.  If a dog hurts its knee, it chang=\r\nes how it\n&gt; &gt; walks.  The HyrbrID quadruped can&#39;t do that.  Even an insect =\r\nthat loses a leg\n&gt; &gt; can adjust and keep walking.\n&gt; \n&gt; You are correct that=\r\n I overreached. I was trying to distance this problem\n&gt; from traditional EC=\r\n toy problems only. Clearly there is a ton more to\n&gt; natural gaits (includi=\r\nng intralife learning) than what we have shown.\n&gt; \n&gt; &gt; Thus my guess is tha=\r\nt the underlying encoding in nature is regular after all,\n&gt; &gt; and the irreg=\r\nularity that may ultimately arise within the brain is because of\n&gt; &gt; change=\r\ns that are guided by adaptive rules.  But what the DNA codes for are\n&gt; &gt; th=\r\nose *rules*, not the changes that the rules produce.  Thus the rules\n&gt; &gt; th=\r\nemselves can certainly be distributed in a regular pattern.  If an irregula=\r\nr\n&gt; &gt; fault then arises, the rules for how that local area should change wi=\r\nll cause\n&gt; &gt; changes for that area.  In fact, the rules must be distributed=\r\n in a mostly\n&gt; &gt; regular manner:  How could it be that you should somehow a=\r\ndapt differently to\n&gt; &gt; a right knee fault than to a left one?  The underly=\r\ning concept of adaptation\n&gt; &gt; is symmetric.\n&gt; \n&gt; You make very interesting =\r\npoints. At this point it is speculation, but it\n&gt; seems we disagree in our =\r\nguesses as to the amount of hard-wired irregularity\n&gt; there is in natural s=\r\nystems. For example, Hyenas have longer back legs than\n&gt; front legs: my gue=\r\nss is that there are some hard-wired differences in the\n&gt; neural controller=\r\ns between the back and front legs. I am sure learning plays\n&gt; a huge role a=\r\ns well, but I wouldn&#39;t be surprised if (a la the Baldwin\n&gt; effect), some of=\r\n the knowledge began to be encoded genetically. I guess only\n&gt; very advance=\r\nd empirical studies will reveal which of us is right. Another\n&gt; issue, of c=\r\nourse, is that we still do not have a good handle on how much\n&gt; variation o=\r\nn a theme HyperNEAT can produce. We know the extremes: it can\n&gt; produce som=\r\ne variation, on the one hand, and it has a hard time making\n&gt; exceptions fo=\r\nr only one link in 100 on the other, but I still do not have a\n&gt; good feel =\r\nfor whether it could make exceptions in the case of the Hyena, for\n&gt; exampl=\r\ne, where it simply has to make two legs do something slightly\n&gt; different. =\r\nIn our HybrID imperfect joint experiments, throughout the entire\n&gt; run one =\r\nof the joints (or a few) had a slight bit of error, and HyperNEAT\n&gt; did not=\r\n do as well as HybrID. So to me that is some evidence that HyperNEAT\n&gt; curr=\r\nently would have a harder time with my Hyena example than HybrID, and it\n&gt; =\r\nseems to me that we want an encoding that can deal with the Hyena example.\n=\r\n&gt;  \n&gt; I would also like to point out that HybrID statistically significantl=\r\ny\n&gt; outperformed HyperNEAT on the simulated quadruped problem even when the=\r\n\n&gt; quadruped did not have any imperfect joints. I think this shows that, in=\r\n\n&gt; general, rigid regularity is not ideal, and the ability to make exceptio=\r\nns\n&gt; will be helpful in many cases, even on very regular problems. Then aga=\r\nin, it\n&gt; could be that HybrID is overfitting, and thus would perform less w=\r\nell on\n&gt; more generalized tasks than HyperNEAT, or HyperNEAT+Learning. I th=\r\nink it is\n&gt; an interesting area of research.\n&gt; \n&gt; &gt; So I still do not see e=\r\nvidence that CPPNs, nor nature for that matter, should\n&gt; &gt; be expected to e=\r\nncode for ad hoc irregularities such as a creature that is\n&gt; &gt; born with a =\r\nsingle gait attuned to an asymmetric body with a bad knee.  That\n&gt; &gt; is, cr=\r\neatures derive their gaits from their bodies, not vice-versa.  They\n&gt; &gt; sen=\r\nse their limbs once they are alive and adapt the way they move to the limbs=\r\n\n&gt; &gt; with which they find themselves.  Hopefully those limbs are intact, bu=\r\nt if\n&gt; &gt; not, or if they become disabled, they adapt.\n&gt; \n&gt; I do agree that =\r\nit would be great if our evolved organisms were able to do\n&gt; all of these t=\r\nhings. But those are alternate ways to produce necessary\n&gt; irregularities. =\r\nMy instincts tell me that we will want such variation on\n&gt; themes throughou=\r\nt the body (e.g. each rib is slightly different, as are\n&gt; fingers) and brai=\r\nn. This gets back to the issue of how well HyperNEAT can\n&gt; make variations =\r\non themes. Can it do ribs? Fingers? You see the picbreeder\n&gt; pics and concl=\r\nude that it can. I see the results from my attempts to have it\n&gt; make excep=\r\ntions and wonder if it is good enough on that front, and whether\n&gt; we shoul=\r\nd try to make it better.\n&gt; \n&gt; &gt; It certainly could be possible that some ne=\r\nw set of activation functions or\n&gt; &gt; augmentations of CPPNs could be better=\r\n at producing the kinds of regularities\n&gt; &gt; and exceptions that are most ef=\r\nfective for building brains.  But I do think\n&gt; &gt; that it is incorrect to fr=\r\name this issue as a problem with capturing\n&gt; &gt; exceptions.  I mean, I guess=\r\n I don&#39;t accept the premise of the question of\n&gt; &gt; whether it is a zero-sum=\r\n game.  That question assumes that somehow we need\n&gt; &gt; more exceptions, but=\r\n I do not see evidence for that.  I can think of\n&gt; &gt; innumerable possible &quot;=\r\nexceptions&quot; for animal body plans, but nature would be\n&gt; &gt; able to evolve v=\r\nirtually none of them, even with proper selection pressure.\n&gt; &gt; How about f=\r\ningers coming out of one ear, or a tongue on the bottom of one\n&gt; &gt; foot?  O=\r\nr maybe one half side of the body entirely covered in hair but the\n&gt; &gt; othe=\r\nr bald?  Or maybe we could breed babies to be born with a nice smiley-face\n=\r\n&gt; &gt; tattoo on one cheek?\n&gt; &gt; \n&gt; &gt; These are ridiculous, but I do not see an=\r\ny clear a priori distinction that you\n&gt; &gt; have articulated between what is =\r\nridiculous and what isn&#39;t.  You seem to have\n&gt; &gt; the intuition that what Hy=\r\nbrID produces is exactly in the class of &quot;not\n&gt; &gt; ridiculous&quot; exceptions, b=\r\nut in my view just because something worked does not\n&gt; &gt; mean it has any re=\r\nlation to nature at all.  Still, ok, it doesn&#39;t have to be\n&gt; &gt; like nature,=\r\n but the question is whether it somehow sets up a new ideal vision\n&gt; &gt; for =\r\nindirect encodings.  And I don&#39;t see that because I think the quadruped\n&gt; &gt;=\r\n born with the broken joint is no less arbitrary than a baby with a smiley-=\r\nface\n&gt; &gt; tattoo.  \n&gt; \n&gt; The examples you raise are about as extreme as I ca=\r\nn imagine. But I don&#39;t\n&gt; think the exceptions I was testing for in my HybrI=\r\nD paper are in any way as\n&gt; ridiculous. \n&gt; \n&gt; HybrID outperformed HyperNEAT=\r\n even without imperfect joints. Thus, in the\n&gt; most regular version of a no=\r\nn-toy problem, there were exceptions/variations\n&gt; that helped. I think it i=\r\ns much more analogous to think of these as the\n&gt; kinds of variations on a t=\r\nheme that produce slightly different fingers, or\n&gt; back legs longer than fr=\r\nont legs, than to think of these exceptions as\n&gt; similar to a finger sticki=\r\nng out of an ear. I was not comparing HyperNEAT to\n&gt; HybrID on a rigged pro=\r\nblem where it was beneficial to make ridiculous\n&gt; exceptions. I tested it, =\r\nin fact, on a problem that many have faulted for\n&gt; being too regular! Even =\r\nthen, exceptions (i.e., variations on a theme)\n&gt; helped out. I then went on=\r\n to show that exceptions that I think are pretty\n&gt; reasonable (minor noise =\r\nin joints of the body) are even more challenging for\n&gt; HyperNEAT, possibly =\r\nbecause it is too biased toward regularity.\n&gt;  \n&gt; &gt; So you might wonder wha=\r\nt irregularities I would think are not arbitrary.  The\n&gt; &gt; things that are =\r\nnot arbitrary are those irregular motifs that I intuitively\n&gt; &gt; observe in =\r\nnature such as imperfect symmetry (e.g. the heart on one side or\n&gt; &gt; right-=\r\nhandedness) and repetition with variation (e.g. receptive field patterns\n&gt; =\r\n&gt; in the brain or fingers on the hand).\n&gt; \n&gt; We agree that producing such i=\r\nrregularities is a good thing. I guess we\n&gt; disagree on whether my results =\r\nto date are evidence of ridiculous\n&gt; exceptions, or desirable variation. Mo=\r\nre tests on different problems with\n&gt; such desired variations (e.g. a robot=\r\n with back legs longer than the front)\n&gt; will help us refine our picture.\n&gt;=\r\n \n&gt; &gt; It&#39;s hard for me to think of major exceptions.  Maybe the lobster&#39;s c=\r\nlaw?  But\n&gt; &gt; of course in all the immensity of nature there will be here a=\r\nnd there a\n&gt; &gt; bizarre occurrence, but those do not make a rule.  (And anyw=\r\nay, to my\n&gt; &gt; intuition the lobster&#39;s claw is more a kind of imperfect symm=\r\netry than an\n&gt; &gt; arbitrary exception.)\n&gt; &gt; \n&gt; &gt; Admittedly, a lot of what I=\r\n&#39;m going on here is intuition rather than logic.\n&gt; \n&gt; Me too. I hope you do=\r\nn&#39;t mind that I am out in the world raising these\n&gt; issues. You know more t=\r\nhan anyone that I think HyperNEAT is fantastic, and\n&gt; represents a huge lea=\r\np forward in terms of evolving bodies and brains as\n&gt; complex as those in n=\r\nature. As I said, I personally believe we can solve the\n&gt; issues I raise wi=\r\nthin the HyperNEAT framework.\n&gt; \n&gt; &gt;&gt; In fact, isn&#39;t HybrID an example of t=\r\nhis? Mutation-selection balance aside,\n&gt; &gt;&gt; FT-NEAT should only make a chan=\r\nge to a pattern HyperNEAT produced if the\n&gt; &gt;&gt; change helps fitness. I real=\r\nize HybrID is not the long-term solution (partly\n&gt; &gt;&gt; because of the scalin=\r\ng issues you mentioned), but isn&#39;t it at least an\n&gt; &gt;&gt; example of how an al=\r\ngorithm can make advances on the exception-making front\n&gt; &gt;&gt; without losing=\r\n much, if anything, on the producing-regularity front?\n&gt; &gt;&gt; \n&gt; &gt; \n&gt; &gt; That&#39;=\r\ns a really good question/argument, and it is worth thinking about.  But\n&gt; &gt;=\r\n ultimately I would not draw that conclusion from HybrID.  Rather, I would =\r\nsay\n&gt; &gt; that it simply works in practice on lower-dimensional structures, a=\r\nnd I would\n&gt; &gt; not draw any more general lesson from it on the potential fo=\r\nr representing\n&gt; &gt; more exceptions.  My guess is that if such a power were =\r\navailable at much\n&gt; &gt; higher dimensionalities, it would add a kind of noise=\r\n on top of whatever\n&gt; &gt; regularity might be discovered, thereby handicappin=\r\ng the ability to discover\n&gt; &gt; regularity.  That is, my guess is that the ab=\r\nility to make completely\n&gt; &gt; arbitrary regular exceptions probably would no=\r\nt scale well.  Since scaling to\n&gt; &gt; massive sizes is part of what interests=\r\n me, I would need more evidence to\n&gt; &gt; convince me that there is a need for=\r\n such exception-making at large scales.\n&gt; &gt; \n&gt; &gt; Let me conclude by emphasi=\r\nzing that I am *not* suggesting that CPPNs in their\n&gt; &gt; present form are th=\r\ne best encoding we will ever get.  There may indeed be\n&gt; &gt; better ones (and=\r\n it&#39;s worth investigating), but what I think would make them\n&gt; &gt; better is =\r\nnot trying to get &quot;more exceptions&quot; but rather trying to figure out\n&gt; &gt; wha=\r\nt kinds of exceptions there should be and what kinds of regularities there\n=\r\n&gt; &gt; should be and where they would all fit into the big picture.  That is, =\r\nto me\n&gt; &gt; it is more a question of kind than a question of degree.  And unf=\r\nortunately,\n&gt; &gt; arguments about kind are much more specific and hair-splitt=\r\ning than general\n&gt; &gt; arguments about degree.\n&gt; \n&gt; I agree with this sentime=\r\nnt fully. That is why I think it is interesting to\n&gt; conduct experiments li=\r\nke those in the HybrID paper, where we are learning\n&gt; about what kinds of i=\r\nrregularities HyperNEAT is capable of. As you have said\n&gt; to me in the past=\r\n, one of the interesting things about the HybrID work is\n&gt; that it shows th=\r\nat there is some low hanging fruit left on the tree that\n&gt; HyperNEAT is not=\r\n grabbing. It is an open and interesting question if that is\n&gt; fruit that w=\r\ne want our encodings to eat! Currently you and I have different\n&gt; guesses a=\r\ns to the answer to that question, but at least we think that it is\n&gt; worthw=\r\nhile to continue to think about these issues and research them.\n&gt; \n&gt; Thanks=\r\n again for the interesting discourse.\n&gt; \n&gt; \n&gt; -Jeff\n&gt; \n&gt; \n&gt; &gt; \n&gt; &gt; ken \n&gt; &gt;=\r\n \n&gt; &gt; \n&gt; &gt;&gt; Thanks again for your interesting comments.\n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; Ch=\r\neers,\n&gt; &gt;&gt; Jeff Clune\n&gt; &gt;&gt; \n&gt; &gt;&gt; Digital Evolution Lab, Michigan State Univ=\r\nersity\n&gt; &gt;&gt; \n&gt; &gt;&gt; jclune@\n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt;&gt;&gt; From: Kenneth Stanl=\r\ney &lt;kstanley@&gt;\n&gt; &gt;&gt;&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com=\r\n&gt;\n&gt; &gt;&gt;&gt; Date: Sun, 26 Jul 2009 23:29:15 -0000\n&gt; &gt;&gt;&gt; To: &quot;neat@yahoogroups.c=\r\nom&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt;&gt;&gt; Subject: [neat] Re: HybrID: A Hybridizatio=\r\nn of Indirect and Direct Encodings\n&gt; &gt;&gt;&gt; for Evolutionary Computation\n&gt; &gt;&gt;&gt;=\r\n \n&gt; &gt;&gt;&gt; Jeff knows some of my thoughts on the issue of regularity vs. irreg=\r\nularity\n&gt; &gt;&gt;&gt; in\n&gt; &gt;&gt;&gt; neuroevolution and also that I recognize the nice re=\r\nsults with HybrID, so\n&gt; &gt;&gt;&gt; this\n&gt; &gt;&gt;&gt; post is just my attempt to put out s=\r\nome thoughts on this important issue,\n&gt; &gt;&gt;&gt; rather than a challenge to the =\r\nHybrID concept.  Basically, HybrID creates a\n&gt; &gt;&gt;&gt; good opportunity to disc=\r\nuss these issues.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; Taking a long term view, what I would like t=\r\no question is the idea that\n&gt; &gt;&gt;&gt; there\n&gt; &gt;&gt;&gt; is a problem with a method th=\r\nat has &quot;trouble&quot; discovering arbitrary\n&gt; &gt;&gt;&gt; irregularities.  It important =\r\nto note that HyperNEAT has no trouble\n&gt; &gt;&gt;&gt; representing &quot;irregularity&quot; in =\r\nthe general sense.  In my 2007 paper on CPPNs\n&gt; &gt;&gt;&gt; (http://eplex.cs.ucf.ed=\r\nu/hyperNEATpage/HyperNEAT.html), I included explicit\n&gt; &gt;&gt;&gt; examples of irre=\r\ngularities and how easy they are to represent.  For example,\n&gt; &gt;&gt;&gt; see the =\r\n&quot;Warped Symmetry&quot; panel in figure 9 on page 24.  So I think the\n&gt; &gt;&gt;&gt; issue=\r\n\n&gt; &gt;&gt;&gt; is definitively *not* that HyperNEAT (or more specifically, CPPNs wi=\r\nth a\n&gt; &gt;&gt;&gt; certain set of activation functions) has trouble representing or=\r\n discovering\n&gt; &gt;&gt;&gt; irregularity, but that it has trouble discovering *parti=\r\ncular*\n&gt; &gt;&gt;&gt; irregularities.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; Yet such trouble may actually be =\r\na good thing.  If it were too easy to\n&gt; &gt;&gt;&gt; represent any arbitrary irregul=\r\narity, then you would have an encoding that\n&gt; &gt;&gt;&gt; is\n&gt; &gt;&gt;&gt; poor at discover=\r\ning regularities.  So this argument could go in circles.\n&gt; &gt;&gt;&gt; But\n&gt; &gt;&gt;&gt; it=\r\n&#39;s important to recognize that we are looking at a trade-off.  Nature\n&gt; &gt;&gt;&gt;=\r\n faces\n&gt; &gt;&gt;&gt; the same trade-off.  It is difficult to say for sure whether D=\r\nNA is biased\n&gt; &gt;&gt;&gt; towards regularity or irregularity, but I would guess lo=\r\noking at biological\n&gt; &gt;&gt;&gt; organisms that regularity reigns, and that irregu=\r\nlarities are of certain\n&gt; &gt;&gt;&gt; *types*, that is, you would be hard pressed t=\r\no &quot;breed&quot; a human with a hand\n&gt; &gt;&gt;&gt; protruding from his or her right knee, =\r\nno matter how many generations were\n&gt; &gt;&gt;&gt; available.  Yet we see things lik=\r\ne the heart on one side, right-handedness,\n&gt; &gt;&gt;&gt; etc.  But those do not mea=\r\nn that the encoding can simply bend to the\n&gt; &gt;&gt;&gt; arbitrary\n&gt; &gt;&gt;&gt; whims of a=\r\n random target.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; So I think what you need if you want to evolve=\r\n a really interesting artifact\n&gt; &gt;&gt;&gt; is not an encoding that is entirely fl=\r\nexible with respect to irregularity.\n&gt; &gt;&gt;&gt; If\n&gt; &gt;&gt;&gt; a particular encoding w=\r\nould often fail to meet ad hoc irregular targets,\n&gt; &gt;&gt;&gt; that\n&gt; &gt;&gt;&gt; is proba=\r\nbly a sign of its long term potential, rather something we&#39;d want to\n&gt; &gt;&gt;&gt; =\r\nfix.  If we did &quot;fix&quot; it, we&#39;d be heading back towards the chaos and entrop=\r\ny\n&gt; &gt;&gt;&gt; of direct encoding.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; Therefore, we should be careful ab=\r\nout whether we consider difficulty\n&gt; &gt;&gt;&gt; achieving\n&gt; &gt;&gt;&gt; specific irregular=\r\nities a problem to solve or an asset in the long run.\n&gt; &gt;&gt;&gt; Certainly there=\r\n should an ability to create &quot;repetition with variation,&quot; but\n&gt; &gt;&gt;&gt; CPPNs (=\r\nas well as nature) exhibit that consistently.  So it&#39;s important to\n&gt; &gt;&gt;&gt; b=\r\ne\n&gt; &gt;&gt;&gt; careful what we consider to be a pathology versus an asset.\n&gt; &gt;&gt;&gt; \n=\r\n&gt; &gt;&gt;&gt; That said, HybrID is a good practical idea.  It is clear that in some=\r\n\n&gt; &gt;&gt;&gt; problems\n&gt; &gt;&gt;&gt; it is just what is needed to perfect solutions with p=\r\narticular irregular\n&gt; &gt;&gt;&gt; needs.  Of course, when the networks become reall=\r\ny big, e.g. with millions\n&gt; &gt;&gt;&gt; of\n&gt; &gt;&gt;&gt; connections, HybrID might begin to=\r\n lose some of its ability to cope with the\n&gt; &gt;&gt;&gt; very high dimensionality, =\r\neven if it is just tweaking on top of preexisting\n&gt; &gt;&gt;&gt; regularities encode=\r\nd by the CPPN.  Nevertheless, at lower dimensionalities,\n&gt; &gt;&gt;&gt; as\n&gt; &gt;&gt;&gt; Jef=\r\nf&#39;s paper shows, it can really help.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; In any case, my main poin=\r\nt is that the issue of what we actually *want* in\n&gt; &gt;&gt;&gt; an\n&gt; &gt;&gt;&gt; encoding w=\r\nith respect to regularity and irregularity is quite subtle and\n&gt; &gt;&gt;&gt; deserv=\r\nes considered contemplation.  The CPPN with the usual set of\n&gt; &gt;&gt;&gt; activati=\r\non\n&gt; &gt;&gt;&gt; functions may not ultimately be the very best representation to bi=\r\nas towards\n&gt; &gt;&gt;&gt; what we want, but if there is something better, it would n=\r\not be better by\n&gt; &gt;&gt;&gt; virtue of simply being able to capture irregularities=\r\n more easily.  Rather,\n&gt; &gt;&gt;&gt; any advantage would be gained through a much m=\r\nore subtle argument, which\n&gt; &gt;&gt;&gt; likely refers to both regularities and irr=\r\negularities of certain types, and\n&gt; &gt;&gt;&gt; why they are appropriate for the ki=\r\nnds of neural structures we hope to\n&gt; &gt;&gt;&gt; evolve.\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt; ken\n&gt; &gt;&gt;&gt; \n&gt;=\r\n &gt;&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;=\r\n&gt; Hello all-\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Recently I have shown that HyperNEAT has troubl=\r\ne making exceptions to the\n&gt; &gt;&gt;&gt;&gt; rules it discovers (Clune et al. PPSN 200=\r\n8). I would like to introduce a\n&gt; &gt;&gt;&gt;&gt; new\n&gt; &gt;&gt;&gt;&gt; paper that will be at ECA=\r\nL 2009 which shows one way to remedy this problem:\n&gt; &gt;&gt;&gt;&gt; combining a gener=\r\native encoding (HyperNEAT in this case) with a direct\n&gt; &gt;&gt;&gt;&gt; encoding (FT-N=\r\nEAT in this case).\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; The resulting algorithm, which we call Hy=\r\nbrID (Hybridization of Indirect\n&gt; &gt;&gt;&gt;&gt; and\n&gt; &gt;&gt;&gt;&gt; Direct Encodings), combin=\r\nes the best of both encodings, and outperformed\n&gt; &gt;&gt;&gt;&gt; HyperNEAT on all of =\r\nthe problems we tested it on, sometimes by as much as\n&gt; &gt;&gt;&gt;&gt; 40%. \n&gt; &gt;&gt;&gt;&gt; \n=\r\n&gt; &gt;&gt;&gt;&gt; I&#39;d be really interested to hear what the people on this list think =\r\nof the\n&gt; &gt;&gt;&gt;&gt; work. For example, I&#39;ll bet there are interesting ways to rem=\r\nedy the\n&gt; &gt;&gt;&gt;&gt; problem\n&gt; &gt;&gt;&gt;&gt; of making exceptions within HyperNEAT, and it=\r\n would be interesting for us\n&gt; &gt;&gt;&gt;&gt; as\n&gt; &gt;&gt;&gt;&gt; a community to explore them. =\r\nBut in the interim, if any of you are\n&gt; &gt;&gt;&gt;&gt; deploying\n&gt; &gt;&gt;&gt;&gt; HyperNEAT on =\r\nsome task and want a possible performance boost, HybrID is\n&gt; &gt;&gt;&gt;&gt; easy\n&gt; &gt;&gt;=\r\n&gt;&gt; to implement and may lead to a significant improvement.\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; H=\r\nere is a link to the paper:\n&gt; &gt;&gt;&gt;&gt; \n&gt; https://www.msu.edu/~jclune/webfiles/=\r\npublications/Clune-HybrID-ECAL-2009.pd&gt;&gt;&gt;&gt;\n&gt; f\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Here is the a=\r\nbstract from the paper:\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Evolutionary algorithms typically us=\r\ne direct encodings, where each element\n&gt; &gt;&gt;&gt;&gt; of the phenotype is specified=\r\n independently in the genotype. Because direct\n&gt; &gt;&gt;&gt;&gt; encodings have diffic=\r\nulty evolving modular and symmetric phenotypes, some\n&gt; &gt;&gt;&gt;&gt; researchers use=\r\n indirect encodings, wherein one genomic element can\n&gt; &gt;&gt;&gt;&gt; influence multi=\r\nple parts of a phenotype. We have previously shown that\n&gt; &gt;&gt;&gt;&gt; HyperNEAT, a=\r\nn indirect encoding, outperforms FT-NEAT, a direct-encoding\n&gt; &gt;&gt;&gt;&gt; control,=\r\n on many problems, especially as the regularity of the problem\n&gt; &gt;&gt;&gt;&gt; incre=\r\nases. However, HyperNEAT is no panacea; it had difficulty accounting\n&gt; &gt;&gt;&gt;&gt;=\r\n for irregularities in problems. In this paper, we propose a new algorithm,=\r\n\n&gt; &gt;&gt;&gt;&gt; a\n&gt; &gt;&gt;&gt;&gt; Hybridized Indirect and Direct encoding (HybrID), which di=\r\nscovers the\n&gt; &gt;&gt;&gt;&gt; regularity of a problem with an indirect encoding and ac=\r\ncounts for\n&gt; &gt;&gt;&gt;&gt; irregularities via a direct encoding. In three different =\r\nproblem domains,\n&gt; &gt;&gt;&gt;&gt; HybrID outperforms HyperNEAT in most situations, wi=\r\nth performance\n&gt; &gt;&gt;&gt;&gt; improvements as large as 40%. Our work suggests that =\r\nhybridizing indirect\n&gt; &gt;&gt;&gt;&gt; and direct encodings can be an effective way to=\r\n improve the performance of\n&gt; &gt;&gt;&gt;&gt; evolutionary algorithms.\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; =\r\n\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Cheers,\n&gt; &gt;&gt;&gt;&gt; Jeff Clune\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; Digital Ev=\r\nolution Lab, Michigan State University\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;&gt; jclune@\n&gt; &gt;&gt;&gt;&gt; \n&gt; &gt;&gt;&gt;=\r\n \n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt; \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}