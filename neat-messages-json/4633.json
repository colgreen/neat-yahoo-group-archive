{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"tW8uX3Vft3c1GmHYFlmcTcp4CL9G9u55HO9YgBf_uSJP9aKYGSC27OJF0t5hxtMO6dnZIdB78hnSa6o2grmaN_Kg","spamInfo":{"isSpam":false,"reason":"4"},"subject":"Re: [neat] Re: New paper investigating HyperNEAT&#39;s sensitivity to different geometric representations of a problem","postDate":"1240188529","msgId":4633,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM2MTEzRUIxLjJBMzdEJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGdzZDdxYisxMDJ0ckBlR3JvdXBzLmNvbT4="},"prevInTopic":4631,"nextInTopic":4635,"prevInTime":4632,"nextInTime":4634,"topicId":4627,"numMessagesInTopic":14,"msgSnippet":"Hello Ken and Peter- Please see my responses interspersed below. ... The position I took when discussing this with Ken was that the geometry of a problem","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 17139 invoked from network); 20 Apr 2009 00:50:05 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m1.grp.re1.yahoo.com with QMQP; 20 Apr 2009 00:50:05 -0000\r\nX-Received: from unknown (HELO yx-out-2324.google.com) (74.125.44.30)\n  by mta3.grp.re1.yahoo.com with SMTP; 20 Apr 2009 00:50:03 -0000\r\nX-Received: by yx-out-2324.google.com with SMTP id 31so524986yxl.13\n        for &lt;neat@yahoogroups.com&gt;; Sun, 19 Apr 2009 17:48:56 -0700 (PDT)\r\nX-Received: by 10.90.90.4 with SMTP id n4mr86505agb.70.1240188536095;\n        Sun, 19 Apr 2009 17:48:56 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?10.0.1.200? (c-76-20-191-220.hsd1.mi.comcast.net [76.20.191.220])\n        by mx.google.com with ESMTPS id 25sm9306140aga.45.2009.04.19.17.48.52\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Sun, 19 Apr 2009 17:48:54 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.13.0.080930\r\nDate: Sun, 19 Apr 2009 20:48:49 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C6113EB1.2A37D%jclune@...&gt;\r\nThread-Topic: [neat] Re: New paper investigating HyperNEAT&#39;s sensitivity to\n different geometric representations of a problem\r\nThread-Index: AcnBUcR/Vz9UoMItaEKYGizX0iDOrg==\r\nIn-Reply-To: &lt;gsd7qb+102tr@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-transfer-encoding: 7bit\r\nX-eGroups-Msg-Info: 2:4:8:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: New paper investigating HyperNEAT&#39;s sensitivity to\n different geometric representations of a problem\r\nX-Yahoo-Group-Post: member; u=211599040; y=TM7kwCW6Y-S7xB-0--s6ycL54UHNROIzIgTt9gO8zQMdKFZ2BlEc\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nHello Ken and Peter-\n\nPlease see my responses interspersed below.\n\n&gt; Peter, Jeff and I have had a lot of in-depth conversations about whether or\n&gt; not the good performance of randomized geometry has anything to do with its\n&gt; geometry at all or whether it&#39;s just the indirect encoding.\n&gt; \n&gt; As I&#39;ve said to Jeff, I believe that anything HyperNEAT does has something to\n&gt; do with geometry so the connection is inescapable.  While it is an indirect\n&gt; encoding, the encoding itself is a function of geometry, so it cannot be\n&gt; considered independently of that geometry.\n&gt; \n&gt; My hypothesis, which I&#39;ve discussed with Jeff, is that in some domains almost\n&gt; *any* random layout has some kind of exploitable geometric relationship.  It\n&gt; may not be the most convenient one, but it is still better than nothing.\n\nThe position I took when discussing this with Ken was that &#39;the geometry of\na problem&#39; refers to meaningful geometric relationships *in the problem\nitself* (e.g,. the concept of a straight line in Tic Tac Toe, whether on the\ndiagonals, columns, or rows). If that geometry is entirely scrambled when\ncreating the geometric representation that HyperNEAT uses, then it cannot\nmeaningfully be said that HyperNEAT exploits the geometry of the problem.\n\nKen&#39;s response, which he described well, is that HyperNEAT is always\nexploiting geometry. I can see his point of view. Maybe one way to think\nabout it is that HyperNEAT is always exploiting the geometry of *the problem\nit is presented with,* which may or may not relate to the geometry of the\nactual problem. \n\nMy point was that if HyperNEAT does better than other neuroevolutionary\nalgorithms on a problem, and the true geometry of the problem is scrambled,\nthen why is the problem easier for HyperNEAT? There are two things which\nmake HyperNEAT different: its generative nature and its ability to exploit\ngeometry. If the geometry is truly gone because of the scrambling, then it\nseems that what is left to explain HyperNEAT&#39;s success is its generative\nproperties. However, Ken has convinced me that it is not that simple to\ndisentangle these two issues. HyperNEAT may be exploiting new geometric\ncorrelations that occur by chance (but is that exploiting the geometry of\nthe real problem?). Alternately, HyperNEAT may be transforming the geometry\nof the scrambled problem back into the geometry of the real problem (but\ncan&#39;t other neural net algorithms perform similar transformations?). I don&#39;t\nraise these issues because I have clear answers to them. I raise them to\nshow that it&#39;s a complicated subject.  In the end, Ken and I decided that it\nis difficult to experimentally isolate the contributions from the two major\nHyperNEAT features (exploiting geometry vs. its generative encoding\nproperties).\n\n&gt; The question for me is whether HyperNEAT can succeed with random geometries in\n&gt; general, or just in particular domains.  It clearly can do it in the quadruped\n&gt; domain, but I wonder about others.  Perhaps the quadruped has properties that\n&gt; make the geometry more forgiving than in most domains.\n&gt; \n&gt; However, you (Peter) note that you also saw the same thing in your own\n&gt; experiments.  So maybe it&#39;s a somewhat widespread phenomenon.\n\nI also think this is interesting, and look forward to seeing how results\nfrom other domains.\n \n&gt; I think that what is important is not so much that you can randomize geometry,\n&gt; because there isn&#39;t really much reason you&#39;d want it to be completely random,\n&gt; but that it shows that you don&#39;t need to get it perfect to still do well.\n&gt; That is definitely good news.\n\nI agree. That HyperNEAT can perform well even with a really poor geometric\nrepresentation also speaks to the issues that others have raised on this\nforum, namely, that some problems don&#39;t seem to have any obvious geometry to\nthem. If that&#39;s true, than it should be similar to asking HyperNEAT to solve\na problem with geometry but scrambling the geometry. Since HyperNEAT seems\n(so far) to deal with that just fine, it leads me to believe that it will\nalso do well on problems that do not have any obviously meaningful geometry.\n\nJeff\n\n\n\n&gt; --- In neat@yahoogroups.com, &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt; wrote:\n&gt;&gt; \n&gt;&gt; Hi!\n&gt;&gt; \n&gt;&gt; Thanks for posting this paper, great work!\n&gt;&gt; By the way I also noticed that HyperNEAT performs well even in cases of a\n&gt;&gt; substrate that is messed up. My first release of the NEVH experiment had a\n&gt;&gt; bug, it was not symmetrical and basically it could be considered randomized.\n&gt;&gt; Yet it was still able to evolve good behaviors, though. I wonder, is this\n&gt;&gt; linked to the geometry at all? Perhaps only the fact that this indirect\n&gt;&gt; encoding searches trough less dimensions, makes it more effective?\n&gt;&gt; \n&gt;&gt; Peter\n&gt;&gt; \n&gt;&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt;&gt;&gt; \n&gt;&gt;&gt; Just for the record, I highly recommend this paper.  It&#39;s the most extensive\n&gt;&gt;&gt; study published on the effect of varying geometry on HyperNEAT performance.\n&gt;&gt;&gt; Some of its results are quite interesting.\n&gt;&gt;&gt; \n&gt;&gt;&gt; For example, it suggests that HyperNEAT is still significantly better than a\n&gt;&gt;&gt; direct encoding encoding even if its geometry is randomized! (Although it is\n&gt;&gt;&gt; still worse than an engineered geometry.)  Jeff and I have discussed how to\n&gt;&gt;&gt; interpret this result and my own opinion is that most randomized geometries\n&gt;&gt;&gt; nevertheless still have some useful geometry, and something is better than\n&gt;&gt;&gt; nothing.  So it suggests that you don&#39;t have to necessarily hit on the\n&gt;&gt;&gt; &quot;perfect&quot; substrate geometry to get traction out of HyperNEAT.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Yet I think a big question that emerges from this result is whether it is\n&gt;&gt;&gt; somehow tied specifically to the quadruped domain.  It is possible that it\n&gt;&gt;&gt; has something to with the fact that a quadruped can get along pretty well if\n&gt;&gt;&gt; all its legs move in tandem, so you have the opportunity to represent that\n&gt;&gt;&gt; repetition regardless of how the legs are organized geometrically.  It is\n&gt;&gt;&gt; possible that other types of systems are less geometrically forgiving,\n&gt;&gt;&gt; though that remains to be seen.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Of course, in practice, if the right geometry is even partially clear, the\n&gt;&gt;&gt; resultant informed substrate configuration is probably going to be better\n&gt;&gt;&gt; than a random geometry.  The &quot;engineered&quot; geometries (meaning they are\n&gt;&gt;&gt; designed by a human to make sense) still outperform the random ones in the\n&gt;&gt;&gt; paper, even as the random ones outperform the direct encoding.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Anyway, in my view, the most important implication is that geometry matters.\n&gt;&gt;&gt; If you can construct a sensible geometry, HyperNEAT will indeed take\n&gt;&gt;&gt; advantage of it to learn the task.  And even if it&#39;s not perfect, it&#39;s\n&gt;&gt;&gt; better than having no geometric knowledge at all.\n&gt;&gt;&gt; \n&gt;&gt;&gt; ken\n&gt;&gt;&gt; \n&gt;&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Hello all-\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Below is a link to a new HyperNEAT paper that I will present at GECCO 2009\n&gt;&gt;&gt;&gt; this summer. It studies how sensitive HyperNEAT is to different geometric\n&gt;&gt;&gt;&gt; representations of the same problem.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; I am especially excited about this paper because it was nominated for the\n&gt;&gt;&gt;&gt; Best Paper Award in the Generative and Developmental Systems track. If you\n&gt;&gt;&gt;&gt; are going to GECCO this year, and enjoyed the paper, please keep it in mind\n&gt;&gt;&gt;&gt; when casting your ballot.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; The paper can be viewed here:\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \nhttps://www.msu.edu/~jclune/webfiles/publications/Clune-HyperNEATSensitivit&gt;&gt;&gt;&gt;\ny\n&gt;&gt;&gt;&gt; ToGeometry.pdf\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Abstract:\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; HyperNEAT, a generative encoding for evolving artificial neural networks\n&gt;&gt;&gt;&gt; (ANNs), has the unique and powerful ability to exploit the geometry of a\n&gt;&gt;&gt;&gt; problem (e.g., symmetries) by encoding ANNs as a function of a problem&#39;s\n&gt;&gt;&gt;&gt; geometry. This paper provides the first extensive analysis of the\n&gt;&gt;&gt;&gt; sensitivity of HyperNEAT to different geometric representations of a\n&gt;&gt;&gt;&gt; problem. Understanding how geometric representations affect the quality of\n&gt;&gt;&gt;&gt; evolved solutions should improve future designs of such representations.\n&gt;&gt;&gt;&gt; HyperNEAT has been shown to produce coordinated gaits for a simulated\n&gt;&gt;&gt;&gt; quadruped robot with a specific two-dimensional geometric representation.\n&gt;&gt;&gt;&gt; Here, the same problem domain is tested, but with different geometric\n&gt;&gt;&gt;&gt; representations of the problem. Overall, experiments show that the quality\n&gt;&gt;&gt;&gt; and kind of solutions produced by HyperNEAT can be substantially affected\n&gt;&gt;&gt;&gt; by\n&gt;&gt;&gt;&gt; the geometric representation. HyperNEAT outperforms a direct encoding\n&gt;&gt;&gt;&gt; control even with randomized geometric representations, but performs even\n&gt;&gt;&gt;&gt; better when a human engineer designs a representation that reflects the\n&gt;&gt;&gt;&gt; actual geometry of the robot. Unfortunately, even choices in geometric\n&gt;&gt;&gt;&gt; layout that seem to be inconsequential a priori can significantly affect\n&gt;&gt;&gt;&gt; fitness. Additionally, a geometric representation can bias the type of\n&gt;&gt;&gt;&gt; solutions generated (e.g., make left-right symmetry more common than\n&gt;&gt;&gt;&gt; front-back symmetry). The results suggest that HyperNEAT practitioners can\n&gt;&gt;&gt;&gt; obtain good results even if they do not know how to geometrically represent\n&gt;&gt;&gt;&gt; a problem, and that further improvements are possible with a well-chosen\n&gt;&gt;&gt;&gt; geometric representation.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; As always, I look forward to any questions or comments you may have.\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; Digital Evolution Lab, Michigan State University\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt;&gt; jclune@\n&gt;&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt; \n&gt; \n&gt; \n\n\n\n"}}