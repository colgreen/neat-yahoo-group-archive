{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":253727962,"authorName":"Nikolai","from":"&quot;Nikolai&quot; &lt;ker_31_toluca@...&gt;","profile":"ker_31_toluca","replyTo":"LIST","senderId":"u9T8phiqE3-rl07hrRe1W2_bTY1aGstvg9fnA7MKxa8m2x9Md-myX84jVclY5o2RMBDh-Sty1wkakblO5Y6J74dGmYfMy41ieJNivRc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: hyperneat questions","postDate":"1250106857","msgId":4824,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGg1djZsOStlOWoxQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGg1dWxlOStrZ3U3QGVHcm91cHMuY29tPg=="},"prevInTopic":4822,"nextInTopic":4825,"prevInTime":4823,"nextInTime":4825,"topicId":4808,"numMessagesInTopic":10,"msgSnippet":"... neither i am an expert in GPU programming. I use CUDA and it maps it pretty well, you even don t have to know what a texture is. Just knowing the basic","rawEmail":"Return-Path: &lt;ker_31_toluca@...&gt;\r\nX-Sender: ker_31_toluca@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 99064 invoked from network); 12 Aug 2009 19:54:45 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m3.grp.sp2.yahoo.com with QMQP; 12 Aug 2009 19:54:45 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta3.grp.re1.yahoo.com with SMTP; 12 Aug 2009 19:54:45 -0000\r\nX-Received: from [69.147.65.173] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 12 Aug 2009 19:54:18 -0000\r\nX-Received: from [98.137.34.33] by t15.bullet.mail.sp1.yahoo.com with NNFMP; 12 Aug 2009 19:54:18 -0000\r\nDate: Wed, 12 Aug 2009 19:54:17 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;h5v6l9+e9j1@...&gt;\r\nIn-Reply-To: &lt;h5ule9+kgu7@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Nikolai&quot; &lt;ker_31_toluca@...&gt;\r\nSubject: Re: hyperneat questions\r\nX-Yahoo-Group-Post: member; u=253727962; y=G9tFIipy_4BYng9Dk2VuN6VJejNYjq9P-6gw7NKvfARXM2_1DYBWNg\r\nX-Yahoo-Profile: ker_31_toluca\r\n\r\n--- In neat@yahoogroups.com, &quot;Jason Gauci&quot; &lt;jgmath2000@...&gt; wrote:\n&gt;\n&gt; Hey =\r\nNikolai,\n&gt; \n&gt; I think the key to implementing HyperNEAT on the GPU would be=\r\n to take advantage of the fact that substrates are so regular.  A sheet of =\r\nconnections between two layers on a substrate of size (a,b) and (x,y) can b=\r\ne represented as a 4d texture of size (a,b,x,y) where the pixel values on t=\r\nhe texture hold the link weights.  The activation levels of the substrate c=\r\nan be represented by textures of size (a,b) and (x,y).  Then maybe the GPU =\r\ncan optimize multiplying the activation level texture by the weight texture=\r\n and summing that and executing the sigmoid, then stuffing that into the ne=\r\nxt layer.\n&gt; \n&gt; Do you know if something like this is possible on the GPU?  =\r\nI don&#39;t have any GPU programming experience.\n&gt; \n\nneither i am an expert in =\r\nGPU programming. I use CUDA and it maps it pretty well, you even don&#39;t have=\r\n to know what a texture is. Just knowing the basic architecture of the card=\r\n is enough. I have ran some activation tests, and a simple kernel to activa=\r\nte 13,107,200 nodes with 7 incoming links each takes 20 milliseconds (with =\r\nsigmoid exp-based function, step function would do much faster). This is on=\r\n one GPU , but you can have 4 , and even 7 in a motherboard. All connected =\r\nwith a PCI bus transfering at 2.5Gbytes per sec, against traditional single=\r\n core cluster on obsolete GigaBit ethernet which is only 100MB per sec. Wit=\r\nh 4 NVIDIA GTX295 cards you can have a supercomputer with 1920 cores for ab=\r\nout 4,000-5,000USD. But the key for fast implementation is, of course, know=\r\ning your hardware, so , for example to count bits in an integer you don&#39;t u=\r\nse ANDs and ORs, but special assembly language instructions like POPCNT, MM=\r\nX instructions with non-polluting cache loads like _mm_stream_si128() which=\r\n can speed up your software hundreds of times. I think the only reason we d=\r\non&#39;t have an artificial brain yet is because we don&#39;t have enough cores to =\r\ndo the math, but for the methods invented, we already surpassed all the pos=\r\nsible algorithms we would need. So, it is all about computing power now.\n\n\n=\r\n\n\n\n\n\n"}}