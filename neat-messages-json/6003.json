{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":464818732,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"bDnM0USPM3DGB-gFOTbJD7Y-RiGwppBp_aIdV0N7-Uvov2YZX60fhCjl_YLd6K4Z7TSOwHjsCN-F5XKDB8pzhnj_mfo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New paper on why modules evolve, and how to evolve modular artificial neural networks","postDate":"1361299148","msgId":6003,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDc3NDVBMTQwLTQ1QzctNDFDQS04ODE3LTY2RjVDNUJDNkZFNkB1d3lvLmVkdT4=","inReplyToHeader":"PGtmcGoyNSs0ZWhmQGVHcm91cHMuY29tPg==","referencesHeader":"PGtmcGoyNSs0ZWhmQGVHcm91cHMuY29tPg=="},"prevInTopic":6002,"nextInTopic":6004,"prevInTime":6002,"nextInTime":6004,"topicId":5976,"numMessagesInTopic":30,"msgSnippet":"Hello Ken, Please see my inlined comments. ... That s true. Of course, you could choose to have a cutoff to minimize this problem. For example, you could not","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 40986 invoked from network); 19 Feb 2013 18:39:05 -0000\r\nX-Received: from unknown (10.193.84.163)\n  by m10.grp.bf1.yahoo.com with QMQP; 19 Feb 2013 18:39:05 -0000\r\nX-Received: from unknown (HELO mail-da0-f49.google.com) (209.85.210.49)\n  by mta3.grp.bf1.yahoo.com with SMTP; 19 Feb 2013 18:39:04 -0000\r\nX-Received: by mail-da0-f49.google.com with SMTP id t11so3089521daj.8\n        for &lt;neat@yahoogroups.com&gt;; Tue, 19 Feb 2013 10:39:04 -0800 (PST)\r\nX-Received: by 10.68.252.2 with SMTP id zo2mr42607332pbc.97.1361299144012;\n        Tue, 19 Feb 2013 10:39:04 -0800 (PST)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from [10.0.1.3] (host-69-146-94-113.lar-wy.client.bresnan.net. [69.146.94.113])\n        by mx.google.com with ESMTPS id zm1sm18791498pbc.26.2013.02.19.10.39.00\n        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);\n        Tue, 19 Feb 2013 10:39:02 -0800 (PST)\r\nContent-Type: multipart/alternative; boundary=&quot;Apple-Mail=_8AD7DEF2-52C7-4E8E-8941-CCC7094388DF&quot;\r\nMessage-Id: &lt;7745A140-45C7-41CA-8817-66F5C5BC6FE6@...&gt;\r\nMime-Version: 1.0 (Mac OS X Mail 6.2 &#92;(1499&#92;))\r\nDate: Tue, 19 Feb 2013 11:39:08 -0700\r\nReferences: &lt;kfpj25+4ehf@...&gt;\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;kfpj25+4ehf@...&gt;\r\nX-Mailer: Apple Mail (2.1499)\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nX-eGroups-From: Jeff Clune &lt;jeffclune@...&gt;\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] New paper on why modules evolve, and how to evolve modular artificial neural networks\r\nX-Yahoo-Group-Post: member; u=464818732; y=js792KuOEhTxBVuWYZmoTgsAkUAXnmE2YB6E7nmeeu_keHKW8PyF\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\n\r\n--Apple-Mail=_8AD7DEF2-52C7-4E8E-8941-CCC7094388DF\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/plain;\n\tcharset=windows-1252\r\n\r\nHello Ken,\n\nPlease see my inlined comments. \n\n&gt; \n&gt; Hi Jeff, I wanted to fol=\r\nlow up on the &quot;dead weight&quot; concept I brought up, because I feel I may not =\r\nhave made it entirely clear what that is. In a multiobjective formulation, =\r\nif one of the objectives is low connectivity, then you can dominate on that=\r\n objective by having extremely low connectivity and no other saving grace w=\r\nhatsoever. In other words we are talking about completely nonfunctional and=\r\n essentially inert garbage that does well on that one objective by effectiv=\r\nely being brain dead. In effect, you have created a special &quot;niche&quot; for bra=\r\nin-dead networks with radically low connectivity.\n&gt; \n&gt; \nThat&#39;s true. Of cou=\r\nrse, you could choose to have a cutoff to minimize this problem. For exampl=\r\ne, you could not give credit to any orgs that do not have a path from input=\r\ns to outputs, or that have a total connectivity below X, or some other solu=\r\ntion (including a cutoff that changes over time). \n\n&gt; Perhaps early on this=\r\n niche is a fruitful point of departure for better places, but the problem =\r\nis that this niche will never go away. You will always have this protective=\r\n pocket for brain-dead low-connectivity networks for as long as evolution r=\r\nuns. In fact it&#39;s a very attractive niche because it&#39;s so easy - you don&#39;t =\r\nhave to worry about performance and simply need to keep your structure down=\r\n. So these types of inert blobs will be around forever.\n&gt; \n&gt; You suggest th=\r\nat my concern about this &quot;unfit&quot; niche is not consistent with my support of=\r\n novelty search, but novelty search is not really analogous. Novelty search=\r\n is about constantly searching for *new* departure points. Your dead-weight=\r\n niche is about keeping around the same bottom-level junk forever. Novelty =\r\nsearch would quickly tire of such a black hole and abandon it (it doesn&#39;t s=\r\ntay novel). But multiobjective search will embrace it for eternity.\n&gt; \n&gt; \nT=\r\nhat&#39;s true, but on many complex/multi-dimensional tasks there are often inf=\r\ninitely many ways to be uninteresting, yet novel. For example, in your unen=\r\nclosed map in the NS journal paper, only a few runs solve the problem (the =\r\nsame as random search), likely because of the permanent dead-weight of an i=\r\nnfinite number of places to end up that are far away from the target. \n\n&gt; N=\r\nature doesn&#39;t have anything analogous either, which means there is at least=\r\n some evidence that the &quot;fitness bias&quot; analogy with nature is not lining up=\r\n perfectly. You might point to the continuing existence of single-celled or=\r\nganisms as something similar to the perpetual dead-weight in this formulati=\r\non, but they aren&#39;t really analogous because single-celled organisms are fu=\r\nnctional - they retain the ability to make copies of themselves and continu=\r\ne to evolve in their own right - while the low-connectivity deadweight main=\r\ntains no capability whatsoever. On the other hand, suspiciously, as in natu=\r\nre, nothing similar to such a deadweight niche is perpetuated by a biased e=\r\nncoding.\n&gt; \n&gt; \nThat&#39;s also true, but that fault does not lie with the fitne=\r\nss cost concept, it lies with the fact that multi-objective algorithms, whi=\r\nch are the cause of the dead weight, do not perfectly analogize to nature. =\r\nThey&#39;re just better than a weighted sum for other reasons, but the fitness =\r\ncost concept could easily be implemented in a weighted sum fitness function=\r\n and not have this dead weight issue.  \n\n&gt; Doesn&#39;t it seem a little strange=\r\n that the price we have to pay to obtain modular structure is to maintain a=\r\n perpetual dead pool of genetic junk? Note that it doesn&#39;t suggest that suc=\r\nh a system won&#39;t work in some cases, but it&#39;s inelegant enough to raise que=\r\nstions about the best realization of the concept..\n&gt; \n\nAll I think that cal=\r\nls into question is the optimality of multi-objective algorithms when you d=\r\non&#39;t want the extreme of one objective. But that problem almost always occu=\r\nrs in multi-objective algorithms, so your really indicting the whole field =\r\nof MOEA instead of our approach of using a fitness penalty instead of a bia=\r\nsed encoding, no?\n\n&gt; \n&gt; Also on the analogy with nature, while your argumen=\r\nt for fitness pressure in nature based on the size of the head is logically=\r\n possible (and the kind of argument that is probably attractive to a lot of=\r\n people), it&#39;s only speculative. In fact what little evidence there is on s=\r\nuch a speculative issue (i.e. whether a baby&#39;s head might fit through a mot=\r\nher&#39;s pelvis in some alternate evolutionary path) doesn&#39;t support the idea =\r\nthat size is the main issue here. After all, whale brains are far bigger th=\r\nan human brains and I&#39;m sure they are also dominated by local connectivity.=\r\n\n&gt; \nYes, but they float in water! You couldn&#39;t have a creature with that bi=\r\ng of a brain on land (I speculate, not being an expert in these things). In=\r\nteresting side note: I believe whale brains are pretty tiny as a fraction o=\r\nf body size compared to primates, and (for some reason I don&#39;t get) we thin=\r\nk that relative brain size matters more for intelligence than absolute brai=\r\nn size.  \n\n&gt; Conversely, human brains, or brains of any size for that matte=\r\nr, could have been exactly the same size but dominated by long-range connec=\r\ntions rather than short range ones. In fact, in such a situation connectivi=\r\nty would actually be lower overall because long-range connections take up m=\r\nore space. But the mother&#39;s anatomy poses no obstacle to such a scenario. T=\r\nhe fact that we don&#39;t see such a connectivity in any species is therefore p=\r\nlausibly a result of the fact that the encoding simply can&#39;t describe it ea=\r\nsily.\n&gt; \n&gt; \nSuch a brain could exist, but because of the extra space taken =\r\nup by the connections, there would have to be either fewer neurons, fewer c=\r\nonnections (as you point out), or both. That certainly sounds like a cost t=\r\no me! Moreover, longer connections are less reliable, cost more to build an=\r\nd maintain, and they are energetically more expensive due to signal drop al=\r\nong the length of the wire. So there are a whole host of costs associated w=\r\nith such a strategy, making me think it much, much more likely that these c=\r\nosts are the reason we don&#39;t see this type of brain, instead of it being di=\r\nfficult to encode. Evolution has produced amazing things, and it already pr=\r\noduces many long-range connections in the brain, so I do not think the diff=\r\niculty of encoding such a brain is what prevented it from existing. \n\n&gt; \n&gt; =\r\nI feel that you may not see what I&#39;m saying about encoding here, because yo=\r\nu speak about encoding as if it has similar effects to fitness pressure, bu=\r\nt I think it&#39;s not the same. You say: \n&gt; \n&gt; &quot;The reasons biases work is bec=\r\nause they do bias search towards some areas and away from others: so I thin=\r\nk both encoding biases and fitness penalties have similar effects in this r=\r\negard.&quot;\n&gt; \n&gt; But I don&#39;t think that&#39;s true for encoding. The difference wit=\r\nh encoding is that it is not pushing the search towards any particular area=\r\n within the space it induces. Absent any kind of fitness function or select=\r\nive pressure, encoding says nothing about which areas are accessible. Rathe=\r\nr it simply says which types of phenotypes are overrepresented or underrepr=\r\nesented throughout the whole space of genotypes. In other words, even if an=\r\n encoding is &quot;biased&quot; towards low connectivity, if you happen to get into a=\r\nn area of the space with high connectivity, the encoding does not have to p=\r\nush you out of that area (it could be a dense subspace full of high-connect=\r\nivity structures). But fitness bias would have to push you out because all =\r\nit does it push you out. It can&#39;t bend or change depending on where you go.=\r\n Encoding can change with the times and has the wonderful additional potent=\r\nial for canalization, a bonus entirely absent from fitness pressure.\n&gt; \n&gt; \n=\r\nFirst of all, an encoding can actually prevent you from accessing a space. =\r\nIf I encode the length of all table legs in one number, than I have elimina=\r\nted the possibility of a table having legs of different lengths. L-systems =\r\ntend to produce such overly rigid biases (unless they are parameterized and=\r\n/or made context-dependent). But more relevant to our discussion are biases=\r\n that are strong likelihoods, but not strict edicts. Even these, though, in=\r\n practice do mean that entire areas of the search space go unexplored. In o=\r\nur TEC paper, for example, the HyperNEAT generative encoding far outperform=\r\ned the direct encoding, even though the fitness function was the exact same=\r\n. Why? Because the direct encoding was biased towards an entirely different=\r\n area of the search space. We know that there was a selection pressure for =\r\ncertain types of ANNs (namely, the ones HyperNEAT produced), and we know th=\r\nat the direct encoding can express those phenotypes (they actually do in Hy=\r\nbrID), but evolution with the direct encoding did not do so because biases =\r\nhave a huge effect on the subset of the search space you visit. In fact, it=\r\n is precisely because encodings have biases of large effect that we all car=\r\ne about generative encodings, no? All of these arguments are also supported=\r\n by Hornby&#39;s comparison of L-systems to a direct encoding, including his ma=\r\nps of the types of phenotypes produced (there are huge differences between =\r\nthe two encodings). I&#39;d argue that any comparison of direct and indirect en=\r\ncodings shows that these biases are not subtle, but grossly change the type=\r\ns of phenotypes explored, and for all practical purposes eliminate large sw=\r\nathes of the search space. For these reasons I think you&#39;ll get huge uninte=\r\nnded consequences by playing around with encodings, and those consequences =\r\nwill not be overridden by the fitness function, because we&#39;ve seen it happe=\r\nn time and time again. Note that I agree that you also have unintended cons=\r\nequences when playing with fitness functions. \n\nNB: I agree with you about =\r\ncanalization, which is one of many reasons I like generative encodings. :-)=\r\n\n\n&gt; The right level of modularity is likely on a delicate continuum - not e=\r\nntirely one way or another, and probably varies by species. You believe evo=\r\nlution can pay a kind of tax for going against the pressure towards low con=\r\nnectivity: &quot;if a certain phenotype pays for its wiring by increasing fitnes=\r\ns, it can add high-connectivity areas anywhere that they are useful.&quot; But i=\r\nn a delicate balancing act where the best option is likely some middle grou=\r\nnd, that sounds too much like gambling and it&#39;s vulnerable to deception in =\r\ncases where there is no immediate fitness benefit (whereas encoding is orth=\r\nogonal to fitness). With encoding you don&#39;t have the play that game. Encodi=\r\nng can create its own tendency towards some middle ground and canalize that=\r\n tendency over time.\n&gt; \nIf there is no fitness gradient toward such a bias =\r\ntoward intermediate connectivity, why would it evolve? Evolution can only t=\r\nhink short term. I&#39;ll give you that an encoding bias might override the fit=\r\nness gradient by making it impossible to follow, but I don&#39;t buy that evolu=\r\ntion can magically figure out biases that are helpful in the long-term if t=\r\nhe short-term fitness gradients all point in another direction. Or, at leas=\r\nt, that&#39;s something we hope that evolution might do, but it&#39;s a controversi=\r\nal, unproven, and theoretically tricky issue that I certain don&#39;t think we =\r\ncan bank on happening until we understand it a lot more. \n\n&gt; While you worr=\r\ny that modularity might &quot;evolve away,&quot; the idea that it cannot evolve away =\r\nto varying degrees sounds worse to me. Natural evolution is generally good =\r\nabout not keeping all its eggs in one basket - a trait may evolve away in s=\r\nome branches but not in others. But for you to make an all-out attempt to b=\r\nar such a deviation from square one is making a lot of strong assumptions a=\r\nbout what we want to see 1 billion years in the future.\n&gt; \n&gt; \nI&#39;d argue tha=\r\nt your bias in the first replicator without any sustained fitness pressure =\r\nwould have zero effect on creatures a billion years later, especially in th=\r\ne case where there is an active fitness gradient by default away from modul=\r\narity (which we know there is, since modularity never evolves without a bia=\r\ns or fitness pressure). Evolution would not keep any eggs in a basket with =\r\nan active fitness penalty, at least not for a billion years. My 1-billion-y=\r\nears-later influence may thus be imperfect, but it at least exists!\n\n&gt; So I=\r\n&#39;m still a fan of manipulating encoding over manipulating fitness. But I wo=\r\nuld not entirely despair on fitness because there will still be cases where=\r\n there is no clear option for manipulating the encoding. But such scenarios=\r\n are not ones we should be hoping for.\n&gt; \n&gt; \nI do think you make some great=\r\n arguments for encodings, but I cannot envision a case in which an initial =\r\nbias only makes a huge difference in the long-term. That&#39;s true even if the=\r\n bias is neutral with respect to fitness (because it would drift away), but=\r\n seems a certainty to me if it relates to a bias that has an active fitness=\r\n penalty. The whole point of canalization is that it figures out what produ=\r\nces fit offspring and generates that type of organism: if modular creatures=\r\n are less fit in the short term, evolution will canalize away from modulari=\r\nty, not toward it. That said, as I mentioned at the beginning of this conve=\r\nrsation, I do think that a sustained encoding bias of some sort is an inter=\r\nesting approach that could work, although it may be that all we have to do =\r\nis provide a fitness cost and then the encoding will canalize in a way that=\r\n produces such a sustained bias. :-)\n\nAs always, an interesting conversatio=\r\nn!\nBest,\nJeff\n\n\n&gt; Best,\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com, Jeff Clu=\r\nne wrote:\n&gt; &gt;\n&gt; &gt; Hello all,\n&gt; &gt; \n&gt; &gt; As Ken mentioned, we&#39;ve discussed the=\r\nse issues in private. I&#39;m going to include some of my comments from one of =\r\nthose email threads with slight modification, as I believe they summarize t=\r\nhe views of Jean-Baptiste and I on the issues Ken raises. I&#39;ll then respond=\r\n to a few individual comments by Ken afterwards. \n&gt; &gt; \n&gt; &gt; ---------------\n=\r\n&gt; &gt; Ken,\n&gt; &gt; \n&gt; &gt; It&#39;s great to hear your feedback on our paper. Thanks for=\r\n sending it.\n&gt; &gt; \n&gt; &gt; First off, thanks for the kind words. We&#39;re very glad=\r\n you liked the paper and think it is important. \n&gt; &gt; \n&gt; &gt; Regarding a selec=\r\ntion pressure vs. an encoding bias. We&#39;re not convinced that an initial enc=\r\noding bias is a good way to encourage properties that one wants in phenotyp=\r\nes throughout evolution, such as modularity. If there is any deceptiveness =\r\n(or even neutrality) regarding modularity at any point during the run then =\r\nthe bias will disappear, and then for the rest of evolutionary time nothing=\r\n will encourage modularity. We are more convinced of the power of mutationa=\r\nl bias in the encoding (i.e. a constant encoding bias instead of just an in=\r\nitial encoding bias), and we think it would be interesting to investigate a=\r\nrea. However, if the encoding bias is under selection, then you have the sa=\r\nme issue where it might evolve away. Selective pressures are interesting be=\r\ncause they are constant, so you&#39;re more likely to get what you want. That r=\r\naises the point you mention about our pressure being too strong, such that =\r\nevolution could not deviate when it would be beneficial not to have modular=\r\nity. That might be a problem if the pressure is too strong, but it seems li=\r\nkely that in many cases the benefits in terms of performance for being non-=\r\nmodular will outweigh the cost. In other words, evolution can decide to pay=\r\n the cost of non-modularity when it is useful (e.g. in your example of a hu=\r\nb of connections between modules).\n&gt; &gt; \n&gt; &gt; Regarding playing with an encod=\r\ning being safer than playing with selection pressures. Our view is that bot=\r\nh are very complicated and can have unintended consequences, so playing wit=\r\nh one is just as bad as the other. I think our field is more familiar with =\r\nunintended consequences of selective pressures just because we historically=\r\n tend to play with them more (and make simple encodings), but it is also ve=\r\nry hard to intuit the consequences of choices regarding biases in complex e=\r\nncodings. In your case the consequences are relatively intuitive, precisely=\r\n because they are so minimally interventionist...but that is also why I thi=\r\nnk they are not strong enough to cause modularity except in cases (like ret=\r\nina) where all you have to do is initially place evolution in the right att=\r\nractor basin.\n&gt; &gt; \n&gt; &gt; Regarding the resource hog waste of having a cost ob=\r\njective. I have to have a little fun here and point out the irony of the co=\r\n-champion of novelty search worrying about the resources consumed by non-hi=\r\ngh-performing individuals! Hehe. As you&#39;ve persuaded me, I&#39;m more intereste=\r\nd in an algorithm that is interesting or that works than spending a little =\r\ncomputation inefficiently.\n&gt; &gt; \n&gt; &gt; I&#39;d also like to point out an innovatio=\r\nn we came up with to mitigate the problem of preventing evolution from expl=\r\noring solutions that are contrary to one of the objectives. We recognized t=\r\nhat the cost objective is ultimately less important than the performance ob=\r\njective. We wanted evolution to periodically ignore the cost objective to e=\r\nxplore stepping stones that had higher connectivity. To do that, we invente=\r\nd a technique that involves &quot;probabilistic pareto dominance&quot;, wherein secon=\r\ndary objectives (in this case cost) are factored into pareto dominance only=\r\n a small percentage of the time. That won&#39;t solve the problem you mention i=\r\nf you have to take a long, many-multi-generational walk through high-connec=\r\ntivity areas of the search space, but it does allow quick forays into that =\r\nterrain without any fitness penalty. This technique could be used for any c=\r\nost (or other) objective, so it is not specific to connectivity costs. \n&gt; &gt;=\r\n \n&gt; &gt; See below for a few specific responses to your comments. I should not=\r\ne that below this the thoughts are my own and Jean-Baptiste should not be b=\r\nlamed for any of them! (Feel free to blame him for things above this line=\r\n=85we went over that text together a while back). ;-)\n&gt; &gt; \n&gt; &gt; &gt; More gener=\r\nally the issue is the usual problem of deception, which is compounded by an=\r\nything you do with fitness. For example, in a complex search space, there i=\r\ns a reasonable chance that the stepping stone to a good low-connectivity so=\r\nlution is something with higher connectivity. By manipulating fitness, you =\r\nare cutting out all chances of encountering such a deceptive stepping stone=\r\n. But even if you don&#39;t believe that could be true, the single-mindedness o=\r\nf always favoring low-connectivity could deceive you from many parts of the=\r\n search space that might be stepping stones to something worthwhile, relati=\r\nng to connection density or not.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; True. But the same exact=\r\n thing can be said for biases in the encoding: they prevent you from search=\r\ning large areas of the search space. You may reply that it is only a bias, =\r\nnot a strict ban, but of course we know that in large search spaces biases =\r\nhugely affect the landscape such that certain areas will practically never =\r\nbe visited. \n&gt; &gt; \n&gt; &gt; &gt; On the other hand, manipulating the encoding is dif=\r\nferent because in effect it actually reorganizes the structure of the searc=\r\nh space itself, which seems to me a more principled thing to do (if you can=\r\n figure out a way to do it). Because the thing is, in that case, you do not=\r\n need to worry about a permanent dead weight taking up some proportion of y=\r\nour population forever. Instead, while the encoding may *tend* to produce e=\r\n.g. low-connectivity solutions, it can still escape that tendency without a=\r\nny penalty to fitness.\n&gt; &gt; &gt; \n&gt; &gt; My instincts tell me that we create dead =\r\nweight with encoding biases too. For example, an overly regular generative =\r\nencoding (e.g. context free L-systems) is great if good solutions are perfe=\r\nctly regular, but if what is required is a mix of regularity and irregulari=\r\nty, then you spend your entire time producing only highly regular phenotype=\r\ns that never wander into the appropriately irregular areas of the search sp=\r\nace. Our IEEE TEC paper, for example, shows that HyperNEAT can spend thousa=\r\nnds of generations spinning its wheels never generating solutions that Hybr=\r\nID could easily generate, demonstrating a &quot;overly regular&quot; dead weight asso=\r\nciated with the biases of even the best known* generative encoding! Both fi=\r\ntness penalties and biases can cause you to focus your search in unproducti=\r\nve areas=85which is ultimately what dead weight is. \n&gt; &gt; \n&gt; &gt; * in our opin=\r\nion! :0)\n&gt; &gt; \n&gt; &gt; &gt; Furthermore, in reality the best situation regarding mo=\r\ndularity and connectivity is probably rather subtle, with most of the brain=\r\n respecting the principle of low connectivity, but with a number of critica=\r\nl exceptions in key areas, such as major inter-module hubs. A sophisticated=\r\n encoding can allow its bias to bend to make such nuanced exceptions (e.g. =\r\nbased on locations within a geometry), whereas a fitness penalty is a heavy=\r\n hand and blunt instrument that cannot but help always to demand global and=\r\n holistic subservience to dogmatic universals (unless you are willing to ta=\r\nke a hit in fitness).\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; I think the last clause you offer i=\r\ns the key exception though. As I mentioned above, if a certain phenotype pa=\r\nys for its wiring by increasing fitness, it can add high-connectivity areas=\r\n anywhere that they are useful (without even needing to carve out that area=\r\n in geometric space, which is often a difficult task for CPPNs). Instead of=\r\n being a blunt instrument, a fitness penalty can be quite subtle, because i=\r\nt can allow connection-by-connection exceptions if they produce fitness imp=\r\nrovements, and do so without any search overhead. \n&gt; &gt; \n&gt; &gt; &gt; An interestin=\r\ng question in nature (where our brains evolved modular structure) is whethe=\r\nr its tendency towards low connectivity is a result of an aspect of fitness=\r\n in the wild, or an aspect of encoding bias. I think there is a lot of room=\r\n in this question for arguing either way, but my hunch is that the bias is =\r\nmostly in the encoding. My logic is that I think the reason that the connec=\r\ntivity of the brain is so much lower than what it could be (e.g. it is a ti=\r\nny fraction of everything-to-everything connectivity) is an artifact of phy=\r\nsics rather than an artifact of fitness. It is simply physically impossible=\r\n for a giant 100-billion-to-100-billion connectivity to fit in a head anyth=\r\ning close to our size. And physical impossibility is in some sense a proper=\r\nty of encoding. That is, mutations that could step from a low-connectivity =\r\nbrain to a high one are few and far between simply because of physical cons=\r\ntraint. So high-connectivity structures are simply a very small part of the=\r\n search space of brains in the physical universe. However, at the same time=\r\n, you can still get long-range connections from time to time because there =\r\nis no universal penalty for doing so, just a lower a priori probability of =\r\nsuch mutations occurring.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; Here I completely disagree with=\r\n you. I see the force preventing the volume of neural connections from gett=\r\ning too large as a direct fitness cost, not an encoding bias. If mutations =\r\nincrease the size of the head, the baby and the mother are more likely to d=\r\nie in childbirth. Anthropologists have long known that evolution&#39;s desire t=\r\no have larger and larger brains is the main reason why humans have such rid=\r\niculously high maternal and infant mortality &quot;in the wild&quot; (pre modern heal=\r\nth care, and even post). Our encoding keeps producing such mutants, and it&#39;=\r\ns death (via the physical constraints of the pelvis) that keep them from be=\r\ning kept around. The historical accident of birthing through the pelvis asi=\r\nde, there would still be fitness consequences for more vastly neural connec=\r\ntions (e.g. neurons are metabolically expensive, neural connections require=\r\n energy to build and maintain, and housing such large brains would create a=\r\n large, clunky bobble head of a being that would be ungainly). It is possib=\r\nle that low connectivity is an encoding bias, but were that true I think it=\r\n would look like some sort of growth rule that only grew a few connections =\r\nper neuron (e.g. 10k). Evolution could have learned such a rule, and canali=\r\nzed that rule in a way that makes it unlikely to have mutations that produc=\r\ne orders of magnitude more neurons, but my guess is that if it has done so,=\r\n it was because of the fitness costs associated with large numbers of neuro=\r\nns, not because of evolvability (or due to some historical accident). I do =\r\nthink it is interesting to study whether such biases exist in the encoding =\r\nof neural growth rules, but even if they do exist I don&#39;t think that shows =\r\nthat a fitness cost was not the ultimate cause. Note: I recognize that you =\r\nadmit that this could be argued &quot;either way&quot;=85are these the sorts of argum=\r\nents you envisioned as being the other way?\n&gt; &gt; \n&gt; &gt; &gt; In summary, the key =\r\ndifference between the alternatives is that with fitness you are saying &quot;st=\r\nay out of this part of the search space&quot; whereas with encoding you are sayi=\r\nng &quot;this part of the search space is much smaller and hence less likely to =\r\nencounter.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; I don&#39;t precisely understand your latter clau=\r\nse, but I think I understand the spirit of it. I disagree, though. The reas=\r\nons biases work is because they do bias search towards some areas and away =\r\nfrom others: so I think both encoding biases and fitness penalties have sim=\r\nilar effects in this regard. \n&gt; &gt; \n&gt; &gt; &gt; So, my speculation is that if you =\r\nwant to bias the search in highly complex domains, the best way is through =\r\nthe encoding. Fitness is a nasty quagmire that is deceptively tempting to m=\r\nanipulate, but never plays by the rules you wish it would. Of course, these=\r\n are merely my own unproven intuitions and their veracity remains to be dem=\r\nonstrated. But at least it&#39;s something to think about.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; \n&gt;=\r\n &gt; Thanks again for your feedback. As always, I appreciate your input and e=\r\nnjoy discussing these fascinating subjects. \n&gt; &gt; \n&gt; &gt; I want to end by clar=\r\nifying that I agree that there are positives and negatives to both approach=\r\nes. I do not see it as such an obvious choice between the two as you do. As=\r\n I mentioned up top: I definitely don&#39;t think initial encoding biases that =\r\nselection can get rid of will get us very far. For simple problems they wil=\r\nl work, but for any challenging problem the initial bias will have long dis=\r\nappeared by the time it will matter. What we need is some constant force en=\r\ncouraging search to take promising paths. A fitness cost is one way to do t=\r\nhat, but a *constant* (or, at least, *periodic*) encoding bias could do tha=\r\nt just as well, and perhaps better. \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Best regards,\n&gt; &gt; Jeff C=\r\nlune\n&gt; &gt; \n&gt; &gt; Assistant Professor\n&gt; &gt; Computer Science\n&gt; &gt; University of Wy=\r\noming\n&gt; &gt; jeffclune@...\n&gt; &gt; jeffclune.com\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; &gt; Best,\n&gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; ken\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, Alexandre Devert wrote:\n&gt; &gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; &gt; Hi,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =C2 Simple, clean experiment, with sharp =\r\nresults, congrats on that, definitely\n&gt; &gt; &gt; &gt; a step forward ! Of course, i=\r\nt begs for more questions. I would love to hear\n&gt; &gt; &gt; &gt; you on such (fairly=\r\n open) questions\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =C2 =C2 1) Do you think that selection pr=\r\nessure for low connectivity is sufficient in\n&gt; &gt; &gt; &gt; itself to evolve large=\r\n coherent networks, or is it just a piece of the puzzle ?\n&gt; &gt; &gt; &gt; =C2 =C2 2=\r\n) Do you see your work as an indication that any approach biased to low\n&gt; &gt;=\r\n &gt; &gt; connectivity would reproduce the result ? Or does the way you guys enf=\r\norced\n&gt; &gt; &gt; &gt; this bias matters ?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; To me=C2 \n&gt; &gt; &gt; &gt; 1) =3D=\r\n&gt; Part of the puzzle. Should see how well it scales for increasingly\n&gt; &gt; &gt; =\r\n&gt; complex task, when the connection graph gets bigger. A randomized=C2 \n&gt; &gt;=\r\n &gt; &gt; search process=C2 on large graph sounds not so efficient, need somethi=\r\nng to guide it.\n&gt; &gt; &gt; &gt; I advocate construction process that have a feedbac=\r\nk from what the neuron=C2 \n&gt; &gt; &gt; &gt; network is computing. Don&#39;t know how to =\r\ndo it without creepling computational\n&gt; &gt; &gt; &gt; cost tho...\n&gt; &gt; &gt; &gt; 2) =3D&gt; I=\r\n guess that the bias alone is enough, the way to introduce it might\n&gt; &gt; &gt; &gt;=\r\n not be such a big deal.=C2 \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Again, great work, very helpf=\r\nul contribution :)\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Alex\n&gt; &gt; &gt; &gt; =C2 \n&gt; &gt; &gt; &gt; Dr. Devert Al=\r\nexandre\n&gt; &gt; &gt; &gt; Researcher at the Nature Inspired Computation and Applicati=\r\nons Laboratory (NICAL)\n&gt; &gt; &gt; &gt; Lecturer at School Of Software Engineering o=\r\nf USTC\n&gt; &gt; &gt; &gt; ----------------------------------------------------\n&gt; &gt; &gt; &gt;=\r\n Homepage :=C2 http://www.marmakoide.org\n&gt; &gt; &gt; &gt; --------------------------=\r\n--------------------------\n&gt; &gt; &gt; &gt; 166 Renai Road, Dushu Lake Higher Educat=\r\nion Town\n&gt; &gt; &gt; &gt; Suzhou Industrial Park,\n&gt; &gt; &gt; &gt; Suzhou, Jiangsu, People&#39;s =\r\nRepublic of China\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; _______________________________=\r\n_\n&gt; &gt; &gt; &gt; From: Jeff Clune \n&gt; &gt; &gt; &gt; To: neat users group group \n&gt; &gt; &gt; &gt; Cc:=\r\n Jean-Baptiste Mouret ; Hod Lipson \n&gt; &gt; &gt; &gt; Sent: Thursday, February 7, 201=\r\n3 1:57 AM\n&gt; &gt; &gt; &gt; Subject: [neat] New paper on why modules evolve, and how =\r\nto evolve modular artificial neural networks\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =C2 =\r\n\n&gt; &gt; &gt; &gt; Hello all,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I&#39;m extremely pleased to announce a ne=\r\nw paper on a subject that many--including myself--think is critical to maki=\r\nng significant progress in our field: the evolution of modularity.=C2 \n&gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; Jean-Baptiste Mouret, Hod Lipson and I have a new paper that=\r\n=C2 \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; 1) sheds light on why modularity may evolve in biolog=\r\nical networks (e.g. neural, genetic, metabolic, protein-protein, etc.)\n&gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; 2) provides a simple technique for evolving neural networks th=\r\nat are modular and have increased evolvability, in that they adapt faster t=\r\no new environments. The modules that formed solved subproblems in the domai=\r\nn.=C2 \n&gt; &gt; &gt; &gt; Cite:=C2 Clune J, Mouret J-B, Lipson H (2013) The evolutiona=\r\nry origins of modularity. Proceedings of the Royal Society B. 280: 20122863=\r\n.=C2 http://dx.doi.org/10.1098/rspb.2012.2863=C2 (pdf)\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Abs=\r\ntract: A central biological question is how natural organisms are so evolva=\r\nble (capable of quickly adapting to new environments). A key driver of evol=\r\nvability is the widespread modularity of biological networks=E2=80&quot;their or=\r\nganization as functional, sparsely connected subunits=E2=80&quot;but there is no=\r\n consensus regarding why modularity itself evolved. Although most hypothese=\r\ns assume indirect selection for evolvability, here we demonstrate that the =\r\nubiquitous, direct selection pressure to reduce the cost of connections bet=\r\nween network nodes causes the emergence of modular networks. Computational =\r\nevolution experiments with selection pressures to maximize network performa=\r\nnce and minimize connection costs yield networks that are significantly mor=\r\ne modular and more evolvable than control experiments that only select for =\r\nperformance. These results will catalyse research in numerous disciplines, =\r\nsuch as neuroscience and genetics, and enhance our ability to harness\n&gt; &gt; &gt;=\r\n &gt; evolution for engineering purposes.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Video:=C2 http://ww=\r\nw.youtube.com/watch?feature=3Dplayer_embedded&v=3DSG4_aW8LMng\n&gt; &gt; &gt; &gt; \n&gt; &gt; =\r\n&gt; &gt; There has been some nice coverage of this work in the popular press, in=\r\n case you are interested:\n&gt; &gt; &gt; &gt; National Geographic:=C2 http://phenomena.=\r\nnationalgeographic.com/2013/01/30/the-parts-of-life/MIT&#39;s Technology Review=\r\n:=C2 http://www.technologyreview.com/view/428504/computer-scientists-reprod=\r\nuce-the-evolution-of-evolvability/=C2 Fast Company:=C2 http://www.fastcompa=\r\nny.com/3005313/evolved-brains-robots-creep-closer-animal-learningCornell Ch=\r\nronicle:=C2 http://www.news.cornell.edu/stories/Jan13/modNetwork.htmlScienc=\r\neDaily:=C2 http://www.sciencedaily.com/releases/2013/01/130130082300.htm\n&gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Please let me know what you think and if you have any questi=\r\nons. I hope this work will help our field move forward!\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Best regards,\n&gt; &gt; &gt; &gt; Jeff Clune\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\nAssistant Professor\n&gt; &gt; &gt; &gt; Computer Science\n&gt; &gt; &gt; &gt; University of Wyoming\n=\r\n&gt; &gt; &gt; &gt; jclune@\n&gt; &gt; &gt; &gt; jeffclune.com\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt;\n&gt; &gt;\n&gt; \n&gt; =\r\n\n\n\r\n--Apple-Mail=_8AD7DEF2-52C7-4E8E-8941-CCC7094388DF\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/html;\n\tcharset=windows-1252\r\n\r\n&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=3D&quot;Content-Type&quot; content=3D&quot;text/html charset=\r\n=3Dwindows-1252&quot;&gt;&lt;/head&gt;&lt;body style=3D&quot;word-wrap: break-word; -webkit-nbsp-=\r\nmode: space; -webkit-line-break: after-white-space; ; font-family: &#39;Times&#39;;=\r\n font-size: 14px; color: rgb( 0,  0,  0); &quot;&gt;&lt;span style=3D&quot;font-family: &#39;Ti=\r\nmes&#39;; font-size: 14px; color: rgb( 0,  0,  0)&quot;&gt;Hello Ken,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;di=\r\nv&gt;Please see my inlined comments.&nbsp;&lt;br&gt;&lt;div apple-content-edited=3D&quot;tru=\r\ne&quot;&gt;\n&lt;span style=3D&quot;font-family: &#39;Times&#39;; font-size: 14px; color: rgb( 0,  0=\r\n,  0)&quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-style: n=\r\normal; font-variant: normal; font-weight: normal; letter-spacing: normal; l=\r\nine-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px;=\r\n text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -=\r\nwebkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; word-wrap: b=\r\nreak-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;=\r\n &quot;&gt;&lt;span style=3D&quot;font-family: Times; color: rgb(0, 0, 0); &quot;&gt;&lt;div style=3D&quot;=\r\ncolor: rgb(0, 0, 0); font-family: Times; font-style: normal; font-variant: =\r\nnormal; font-weight: normal; letter-spacing: normal; line-height: normal; o=\r\nrphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: none=\r\n; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-adju=\r\nst: auto; -webkit-text-stroke-width: 0px; word-wrap: break-word; -webkit-nb=\r\nsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span style=3D&quot;fon=\r\nt-family: Times; color: rgb(0, 0, 0); &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); =\r\nfont-family: Times; font-style: normal; font-variant: normal; font-weight: =\r\nnormal; letter-spacing: normal; line-height: normal; orphans: 2; text-align=\r\n: -webkit-auto; text-indent: 0px; text-transform: none; white-space: normal=\r\n; widows: 2; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-tex=\r\nt-stroke-width: 0px; word-wrap: break-word; -webkit-nbsp-mode: space; -webk=\r\nit-line-break: after-white-space; &quot;&gt;&lt;span style=3D&quot;font-family: Times; colo=\r\nr: rgb(0, 0, 0); &quot;&gt;&lt;div style=3D&quot;color: rgb(0, 0, 0); font-family: Times; f=\r\nont-style: normal; font-variant: normal; font-weight: normal; letter-spacin=\r\ng: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-=\r\nindent: 0px; text-transform: none; white-space: normal; widows: 2; word-spa=\r\ncing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; =\r\nword-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-=\r\nwhite-space; &quot;&gt;&lt;span style=3D&quot;font-family: Times; color: rgb(0, 0, 0); &quot;&gt;&lt;d=\r\niv style=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-style: normal; fo=\r\nnt-variant: normal; font-weight: normal; letter-spacing: normal; line-heigh=\r\nt: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-tra=\r\nnsform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-te=\r\nxt-size-adjust: auto; -webkit-text-stroke-width: 0px; word-wrap: break-word=\r\n; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div s=\r\ntyle=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-style: normal; font-v=\r\nariant: normal; font-weight: normal; letter-spacing: normal; line-height: n=\r\normal; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transfo=\r\nrm: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-s=\r\nize-adjust: auto; -webkit-text-stroke-width: 0px; word-wrap: break-word; -w=\r\nebkit-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div style=\r\n=3D&quot;color: rgb(0, 0, 0); font-family: Times; font-style: normal; font-varia=\r\nnt: normal; font-weight: normal; letter-spacing: normal; line-height: norma=\r\nl; orphans: 2; text-align: -webkit-auto; text-indent: 0px; text-transform: =\r\nnone; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-size-=\r\nadjust: auto; -webkit-text-stroke-width: 0px; word-wrap: break-word; -webki=\r\nt-nbsp-mode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D=\r\n&quot;Apple-style-span&quot; style=3D&quot;border-collapse: separate; color: rgb(0, 0, 0);=\r\n font-family: Times; font-style: normal; font-variant: normal; font-weight:=\r\n normal; letter-spacing: normal; line-height: normal; orphans: 2; text-alig=\r\nn: -webkit-auto; text-indent: 0px; text-transform: none; white-space: norma=\r\nl; widows: 2; word-spacing: 0px; border-spacing: 0px; -webkit-text-decorati=\r\nons-in-effect: none; -webkit-text-size-adjust: auto; -webkit-text-stroke-wi=\r\ndth: 0px; &quot;&gt;&lt;div style=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; =\r\n-webkit-line-break: after-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; s=\r\ntyle=3D&quot;border-collapse: separate; color: rgb(0, 0, 0); font-family: Times;=\r\n font-style: normal; font-variant: normal; font-weight: normal; letter-spac=\r\ning: normal; line-height: normal; orphans: 2; text-align: -webkit-auto; tex=\r\nt-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-s=\r\npacing: 0px; border-spacing: 0px; -webkit-text-decorations-in-effect: none;=\r\n -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; &quot;&gt;&lt;div sty=\r\nle=3D&quot;word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: =\r\nafter-white-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;border-colla=\r\npse: separate; color: rgb(0, 0, 0); font-variant: normal; letter-spacing: n=\r\normal; line-height: normal; orphans: 2; text-align: -webkit-auto; text-inde=\r\nnt: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing=\r\n: 0px; border-spacing: 0px; -webkit-text-decorations-in-effect: none; -webk=\r\nit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; &quot;&gt;&lt;div style=3D&quot;=\r\nword-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-=\r\nwhite-space; &quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;border-collapse: s=\r\neparate; color: rgb(0, 0, 0); font-variant: normal; letter-spacing: normal;=\r\n line-height: normal; orphans: 2; text-align: -webkit-auto; text-indent: 0p=\r\nx; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;=\r\n border-spacing: 0px; -webkit-text-decorations-in-effect: none; -webkit-tex=\r\nt-size-adjust: auto; -webkit-text-stroke-width: 0px; &quot;&gt;&lt;div style=3D&quot;word-w=\r\nrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-=\r\nspace; &quot;&gt;&lt;br class=3D&quot;Apple-interchange-newline&quot;&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;=\r\n&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/spa=\r\nn&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=\r\n=3D&quot;background-color: rgb(255, 255, 255); position: static; z-index: auto; =\r\n&quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; =\r\nstyle=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;&lt;br&gt;\nHi Jeff, I wanted to fo=\r\nllow up on the &quot;dead weight&quot; concept I brought up, because I feel I may not=\r\n have made it entirely clear what that is. In a multiobjective formulation,=\r\n if one of the objectives is low connectivity, then you can dominate on tha=\r\nt objective by having extremely low connectivity and no other saving grace =\r\nwhatsoever.  In other words we are talking about completely nonfunctional a=\r\nnd essentially inert garbage that does well on that one objective by effect=\r\nively being brain dead.  In effect, you have created a special &quot;niche&quot; for =\r\nbrain-dead networks with radically low connectivity.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/di=\r\nv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;That&#39;s true. Of course, you could choose to=\r\n have a cutoff to minimize this problem. For example, you could not give cr=\r\nedit to any orgs that do not have a path from inputs to outputs, or that ha=\r\nve a total connectivity below X, or some other solution (including a cutoff=\r\n that changes over time).&nbsp;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cit=\r\ne&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: static; z-=\r\nindex: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nPerhaps early=\r\n on this niche is a fruitful point of departure for better places, but the =\r\nproblem is that this niche will never go away.  You will always have this p=\r\nrotective pocket for brain-dead low-connectivity networks for as long as ev=\r\nolution runs.  In fact it&#39;s a very attractive niche because it&#39;s so easy - =\r\nyou don&#39;t have to worry about performance and simply need to keep your stru=\r\ncture down.  So these types of inert blobs will be around forever.&lt;br&gt;\n&lt;br&gt;=\r\n\nYou suggest that my concern about this &quot;unfit&quot; niche is not consistent wit=\r\nh my support of novelty search, but novelty search is not really analogous.=\r\n  Novelty search is about constantly searching for *new* departure points. =\r\n Your dead-weight niche is about keeping around the same bottom-level junk =\r\nforever.  Novelty search would quickly tire of such a black hole and abando=\r\nn it (it doesn&#39;t stay novel).  But multiobjective search will embrace it fo=\r\nr eternity.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;That&#39;s tr=\r\nue, but on many complex/multi-dimensional tasks there are often infinitely =\r\nmany ways to be uninteresting, yet novel. For example, in your unenclosed m=\r\nap in the NS journal paper, only a few runs solve the problem (the same as =\r\nrandom search), likely because of the permanent dead-weight of an infinite =\r\nnumber of places to end up that are far away from the target.&nbsp;&lt;/div&gt;&lt;d=\r\niv&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(=\r\n255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; s=\r\ntyle=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div=\r\n id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nNature doesn&#39;t have anything analogous either, which =\r\nmeans there is at least some evidence that the &quot;fitness bias&quot; analogy with =\r\nnature is not lining up perfectly.  You might point to the continuing exist=\r\nence of single-celled organisms as something similar to the perpetual dead-=\r\nweight in this formulation, but they aren&#39;t really analogous because single=\r\n-celled organisms are functional - they retain the ability to make copies o=\r\nf themselves and continue to evolve in their own right - while the low-conn=\r\nectivity deadweight maintains no capability whatsoever.  On the other hand,=\r\n suspiciously, as in nature, nothing similar to such a deadweight niche is =\r\nperpetuated by a biased encoding.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blo=\r\nckquote&gt;&lt;div&gt;That&#39;s also true, but that fault does not lie with the fitness=\r\n cost concept, it lies with the fact that multi-objective algorithms, which=\r\n are the cause of the dead weight, do not perfectly analogize to nature. Th=\r\ney&#39;re just better than a weighted sum for other reasons, but the fitness co=\r\nst concept could easily be implemented in a weighted sum fitness function a=\r\nnd not have this dead weight issue. &nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cit=\r\ne&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: static; z-=\r\nindex: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nDoesn&#39;t it se=\r\nem a little strange that the price we have to pay to obtain modular structu=\r\nre is to maintain a perpetual dead pool of genetic junk?  Note that it does=\r\nn&#39;t suggest that such a system won&#39;t work in some cases, but it&#39;s inelegant=\r\n enough to raise questions about the best realization of the concept..&lt;br&gt;&lt;=\r\n/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All I think tha=\r\nt calls into question is the optimality of multi-objective algorithms when =\r\nyou don&#39;t want the extreme of one objective. But that problem almost always=\r\n occurs in multi-objective algorithms, so your really indicting the whole f=\r\nield of MOEA instead of our approach of using a fitness penalty instead of =\r\na biased encoding, no?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div s=\r\ntyle=3D&quot;background-color: rgb(255, 255, 255); position: static; z-index: au=\r\nto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-m=\r\nsg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\n&lt;br&gt;\nAlso on the analog=\r\ny with nature, while your argument for fitness pressure in nature based on =\r\nthe size of the head is logically possible (and the kind of argument that i=\r\ns probably attractive to a lot of people), it&#39;s only speculative.  In fact =\r\nwhat little evidence there is on such a speculative issue (i.e. whether a b=\r\naby&#39;s head might fit through a mother&#39;s pelvis in some alternate evolutiona=\r\nry path)  doesn&#39;t support the idea that size is the main issue here.  After=\r\n all, whale brains are far bigger than human brains and I&#39;m sure they are a=\r\nlso dominated by local connectivity.  &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockqu=\r\note&gt;&lt;div&gt;Yes, but they float in water! You couldn&#39;t have a creature with th=\r\nat big of a brain on land (I speculate, not being an expert in these things=\r\n). Interesting side note: I believe whale brains are pretty tiny as a fract=\r\nion of body size compared to primates, and (for some reason I don&#39;t get) we=\r\n think that relative brain size matters more for intelligence than absolute=\r\n brain size. &nbsp;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div styl=\r\ne=3D&quot;background-color: rgb(255, 255, 255); position: static; z-index: auto;=\r\n &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot;=\r\n style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;Conversely, human brains, o=\r\nr brains of any size for that matter, could have been exactly the same size=\r\n but dominated by long-range connections rather than short range ones.  In =\r\nfact, in such a situation connectivity would actually be lower overall beca=\r\nuse long-range connections take up more space.  But the mother&#39;s anatomy po=\r\nses no obstacle to such a scenario.&nbsp;The fact that we don&#39;t see such a =\r\nconnectivity in any species is therefore plausibly a result of the fact tha=\r\nt the encoding simply can&#39;t describe it easily.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;=\r\n&lt;/blockquote&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(=\r\n255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; s=\r\ntyle=3D&quot;position: relative; &quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1; &quot;&gt;&lt;=\r\ndiv id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;S=\r\nuch a brain could exist, but because of the extra space taken up by the con=\r\nnections, there would have to be either fewer neurons, fewer connections (a=\r\ns you point out), or both. That certainly sounds like a cost to me! Moreove=\r\nr, longer connections are less reliable, cost more to build and maintain, a=\r\nnd they are energetically more expensive due to signal drop along the lengt=\r\nh of the wire. So there are a whole host of costs associated with such a st=\r\nrategy, making me think it much, much more likely that these costs are the =\r\nreason we don&#39;t see this type of brain, instead of it being difficult to en=\r\ncode. Evolution has produced amazing things, and it already produces many l=\r\nong-range connections in the brain, so I do not think the difficulty of enc=\r\noding such a brain is what prevented it from existing.&nbsp;&lt;/div&gt;&lt;br&gt;&lt;bloc=\r\nkquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-color: rgb(255, 255, 255); po=\r\nsition: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:r=\r\nelative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;=\r\n&lt;p&gt;&lt;br&gt;\nI feel that you may not see what I&#39;m saying about encoding here, be=\r\ncause you speak about encoding as if it has similar effects to fitness pres=\r\nsure, but I think it&#39;s not the same.  You say: &lt;br&gt;\n&lt;br&gt;\n&quot;The reasons biase=\r\ns work is because they do bias search towards some areas and away from othe=\r\nrs: so I think both encoding biases and fitness penalties have similar effe=\r\ncts in this regard.&quot;&lt;br&gt;\n&lt;br&gt;\nBut I don&#39;t think that&#39;s true for encoding.  =\r\nThe difference with encoding is that it is not pushing the search towards a=\r\nny particular area within the space it induces.  Absent any kind of fitness=\r\n function or  selective pressure, encoding says nothing about which areas a=\r\nre accessible.  Rather it simply says which types of phenotypes are overrep=\r\nresented or underrepresented throughout the whole space of genotypes.  In o=\r\nther words, even if an encoding is &quot;biased&quot; towards low connectivity, if yo=\r\nu happen to get into an area of the space with high connectivity, the encod=\r\ning does not have to push you out of that area (it could be a dense subspac=\r\ne full of high-connectivity structures).  But fitness bias would have to pu=\r\nsh you out because all it does it push you out.  It can&#39;t bend or change de=\r\npending on where you go.  Encoding can change with the times and has the wo=\r\nnderful additional potential for canalization, a bonus entirely absent from=\r\n fitness pressure.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;Fi=\r\nrst of all, an encoding can actually prevent you from accessing a space. If=\r\n I encode the length of all table legs in one number, than I have eliminate=\r\nd the possibility of a table having legs of different lengths. L-systems te=\r\nnd to produce such overly rigid biases (unless they are parameterized and/o=\r\nr made context-dependent). But more relevant to our discussion are biases t=\r\nhat are strong likelihoods, but not strict edicts. Even these, though, in p=\r\nractice do mean that entire areas of the search space go unexplored. In our=\r\n TEC paper, for example, the HyperNEAT generative encoding far outperformed=\r\n the direct encoding, even though the fitness function was the exact same. =\r\nWhy? Because the direct encoding was biased towards an entirely different a=\r\nrea of the search space. We know that there was a selection pressure for ce=\r\nrtain types of ANNs (namely, the ones HyperNEAT produced), and we know that=\r\n the direct encoding can express those phenotypes (they actually do in Hybr=\r\nID), but evolution with the direct encoding did not do so because biases ha=\r\nve a huge effect on the subset of the search space you visit. In fact, it i=\r\ns precisely because encodings have biases of large effect that we all care =\r\nabout generative encodings, no? All of these arguments are also supported b=\r\ny Hornby&#39;s comparison of L-systems to a direct encoding, including his maps=\r\n of the types of phenotypes produced (there are huge differences between th=\r\ne two encodings). I&#39;d argue that any comparison of direct and indirect enco=\r\ndings shows that these biases are not subtle, but grossly change the types =\r\nof phenotypes explored, and for all practical purposes eliminate large swat=\r\nhes of the search space. For these reasons I think you&#39;ll get huge unintend=\r\ned consequences by playing around with encodings, and those consequences wi=\r\nll not be overridden by the fitness function, because we&#39;ve seen it happen =\r\ntime and time again. Note that I agree that you also have unintended conseq=\r\nuences when playing with fitness functions.&nbsp;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;=\r\nNB: I agree with you about canalization, which is one of many reasons I lik=\r\ne generative encodings. :-)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;=\r\ndiv style=3D&quot;background-color: rgb(255, 255, 255); position: static; z-inde=\r\nx: auto; &quot;&gt;&lt;div id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;y=\r\ngrp-msg&quot; style=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nThe right level of=\r\n modularity is likely on a delicate continuum - not entirely one way or ano=\r\nther, and probably varies by species.  You believe evolution can pay a kind=\r\n of tax for going against the pressure towards low connectivity: &quot;if a cert=\r\nain phenotype pays for its wiring by increasing fitness, it can add high-co=\r\nnnectivity areas anywhere that they are useful.&quot;  But in a delicate balanci=\r\nng act where the best option is likely some middle ground, that sounds too =\r\nmuch like gambling and it&#39;s vulnerable to deception in cases where there is=\r\n no immediate fitness benefit (whereas encoding is orthogonal to fitness). =\r\n With encoding you don&#39;t have the play that game.  Encoding can create its =\r\nown tendency towards some middle ground and canalize that tendency over tim=\r\ne.  &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;If there is no fitness gr=\r\nadient toward such a bias toward intermediate connectivity, why would it ev=\r\nolve? Evolution can only think short term. I&#39;ll give you that an encoding b=\r\nias might override the fitness gradient by making it impossible to follow, =\r\nbut I don&#39;t buy that evolution can magically figure out biases that are hel=\r\npful in the long-term if the short-term fitness gradients all point in anot=\r\nher direction. Or, at least, that&#39;s something we hope that evolution might =\r\ndo, but it&#39;s a controversial, unproven, and theoretically tricky issue that=\r\n I certain don&#39;t think we can bank on happening until we understand it a lo=\r\nt more.&nbsp;&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;background-c=\r\nolor: rgb(255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=3D&quot;ygr=\r\np-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;z-index=\r\n: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;While you worry that modularity might &quot;evolv=\r\ne away,&quot; the idea that it cannot evolve away to varying degrees sounds wors=\r\ne to me.  Natural evolution is generally good about not keeping all its egg=\r\ns in one basket - a trait may evolve away in some branches but not in other=\r\ns.  But for you to make an all-out attempt to bar such a deviation from squ=\r\nare one is making a lot of strong assumptions about what we want to see 1 b=\r\nillion years in the future.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquot=\r\ne&gt;&lt;div&gt;I&#39;d argue that your bias in the first replicator without any sustain=\r\ned fitness pressure would have zero effect on creatures a billion years lat=\r\ner, especially in the case where there is an active fitness gradient by def=\r\nault away from modularity (which we know there is, since modularity never e=\r\nvolves without a bias or fitness pressure). Evolution would not keep any eg=\r\ngs in a basket with an active fitness penalty, at least not for a billion y=\r\nears. My 1-billion-years-later influence may thus be imperfect, but it at l=\r\neast exists!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;ba=\r\nckground-color: rgb(255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div=\r\n id=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=\r\n=3D&quot;z-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nSo I&#39;m still a fan of manipulati=\r\nng encoding over manipulating fitness.  But I would not entirely despair on=\r\n fitness because there will still be cases where there is no clear option f=\r\nor manipulating the encoding.  But such scenarios are not ones we should be=\r\n hoping for.&lt;br&gt;\n&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;I do thi=\r\nnk you make some great arguments for encodings, but I cannot envision a cas=\r\ne in which an initial bias only makes a huge difference in the long-term. T=\r\nhat&#39;s true even if the bias is neutral with respect to fitness (because it =\r\nwould drift away), but seems a certainty to me if it relates to a bias that=\r\n has an active fitness penalty. The whole point of canalization is that it =\r\nfigures out what produces fit offspring and generates that type of organism=\r\n: if modular creatures are less fit in the short term, evolution will canal=\r\nize away from modularity, not toward it. That said, as I mentioned at the b=\r\neginning of this conversation, I do think that a sustained encoding bias of=\r\n some sort is an interesting approach that could work, although it may be t=\r\nhat all we have to do is provide a fitness cost and then the encoding will =\r\ncanalize in a way that produces such a sustained bias. :-)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/=\r\ndiv&gt;&lt;div&gt;As always, an interesting conversation!&lt;/div&gt;&lt;div&gt;Best,&lt;/div&gt;&lt;div&gt;=\r\nJeff&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div style=3D&quot;backgr=\r\nound-color: rgb(255, 255, 255); position: static; z-index: auto; &quot;&gt;&lt;div id=\r\n=3D&quot;ygrp-mlmsg&quot; style=3D&quot;position:relative;&quot;&gt;&lt;div id=3D&quot;ygrp-msg&quot; style=3D&quot;=\r\nz-index: 1;&quot;&gt;&lt;div id=3D&quot;ygrp-text&quot;&gt;&lt;p&gt;\nBest,&lt;br&gt;\n&lt;br&gt;\nken&lt;br&gt;\n&lt;br&gt;\n--- In &lt;=\r\na href=3D&quot;mailto:neat%40yahoogroups.com&quot;&gt;neat@yahoogroups.com&lt;/a&gt;, Jeff Clu=\r\nne  wrote:&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Hello all,&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; As Ken mentioned=\r\n, we&#39;ve discussed these issues in private. I&#39;m going to include some of my =\r\ncomments from one of those email threads with slight modification, as I bel=\r\nieve they summarize the views of Jean-Baptiste and I on the issues Ken rais=\r\nes. I&#39;ll then respond to a few individual comments by Ken afterwards. &lt;br&gt;\n=\r\n&gt; &lt;br&gt;\n&gt; ---------------&lt;br&gt;\n&gt; Ken,&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; It&#39;s great =\r\nto hear your feedback on our paper. Thanks for sending it.&lt;br&gt;\n&gt; &lt;br&gt;\n&g=\r\nt; First off, thanks for the kind words. We&#39;re very glad you liked the pape=\r\nr and think it is important. &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Regarding a selection pres=\r\nsure vs. an encoding bias. We&#39;re not convinced that an initial encoding bia=\r\ns is a good way to encourage properties that one wants in phenotypes throug=\r\nhout evolution, such as modularity. If there is any deceptiveness (or even =\r\nneutrality) regarding modularity at any point during the run then the bias =\r\nwill disappear, and then for the rest of evolutionary time nothing will enc=\r\nourage modularity. We are more convinced of the power of mutational bias in=\r\n the encoding (i.e. a constant encoding bias instead of just an initial enc=\r\noding bias), and we think it would be interesting to investigate area. Howe=\r\nver, if the encoding bias is under selection, then you have the same issue =\r\nwhere it might evolve away. Selective pressures are interesting because the=\r\ny are constant, so you&#39;re more likely to get what you want. That raises the=\r\n point you mention about our pressure being too strong, such that evolution=\r\n could not deviate when it would be beneficial not to have modularity. That=\r\n might be a problem if the pressure is too strong, but it seems likely that=\r\n in many cases the benefits in terms of performance for being non-modular w=\r\nill outweigh the cost. In other words, evolution can decide to pay the cost=\r\n of non-modularity when it is useful (e.g. in your example of a hub of conn=\r\nections between modules).&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Regarding playing with an enco=\r\nding being safer than playing with selection pressures. Our view is that bo=\r\nth are very complicated and can have unintended consequences, so playing wi=\r\nth one is just as bad as the other. I think our field is more familiar with=\r\n unintended consequences of selective pressures just because we historicall=\r\ny tend to play with them more (and make simple encodings), but it is also v=\r\nery hard to intuit the consequences of choices regarding biases in complex =\r\nencodings. In your case the consequences are relatively intuitive, precisel=\r\ny because they are so minimally interventionist...but that is also why I th=\r\nink they are not strong enough to cause modularity except in cases (like re=\r\ntina) where all you have to do is initially place evolution in the right at=\r\ntractor basin.&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Regarding the resource hog waste of havin=\r\ng a cost objective. I have to have a little fun here and point out the iron=\r\ny of the co-champion of novelty search worrying about the resources consume=\r\nd by non-high-performing individuals! Hehe. As you&#39;ve persuaded me, I&#39;m mor=\r\ne interested in an algorithm that is interesting or that works than spendin=\r\ng a little computation inefficiently.&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; I&#39;d also like to p=\r\noint out an innovation we came up with to mitigate the problem of preventin=\r\ng evolution from exploring solutions that are contrary to one of the object=\r\nives. We recognized that the cost objective is ultimately less important th=\r\nan the performance objective. We wanted evolution to periodically ignore th=\r\ne cost objective to explore stepping stones that had higher connectivity. T=\r\no do that, we invented a technique that involves &quot;probabilistic pareto domi=\r\nnance&quot;, wherein secondary objectives (in this case cost) are factored into =\r\npareto dominance only a small percentage of the time. That won&#39;t solve the =\r\nproblem you mention if you have to take a long, many-multi-generational wal=\r\nk through high-connectivity areas of the search space, but it does allow qu=\r\nick forays into that terrain without any fitness penalty. This technique co=\r\nuld be used for any cost (or other) objective, so it is not specific to con=\r\nnectivity costs. &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; See below for a few specific responses=\r\n to your comments. I should note that below this the thoughts are my own an=\r\nd Jean-Baptiste should not be blamed for any of them! (Feel free to blame h=\r\nim for things above this line=85we went over that text together a while bac=\r\nk). ;-)&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &gt; More generally the issue is the usual probl=\r\nem of deception, which is compounded by anything you do with fitness. For e=\r\nxample, in a complex search space, there is a reasonable chance that the st=\r\nepping stone to a good low-connectivity solution is something with higher c=\r\nonnectivity. By manipulating fitness, you are cutting out all chances of en=\r\ncountering such a deceptive stepping stone. But even if you don&#39;t believe t=\r\nhat could be true, the single-mindedness of always favoring low-connectivit=\r\ny could deceive you from many parts of the search space that might be stepp=\r\ning stones to something worthwhile, relating to connection density or not.&lt;=\r\nbr&gt;\n&gt; &gt; &lt;br&gt;\n&gt; &gt; &lt;br&gt;\n&gt; True. But the same exact thing can b=\r\ne said for biases in the encoding: they prevent you from searching large ar=\r\neas of the search space. You may reply that it is only a bias, not a strict=\r\n ban, but of course we know that in large search spaces biases hugely affec=\r\nt the landscape such that certain areas will practically never be visited. =\r\n&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &gt; On the other hand, manipulating the encoding is di=\r\nfferent because in effect it actually reorganizes the structure of the sear=\r\nch space itself, which seems to me a more principled thing to do (if you ca=\r\nn figure out a way to do it). Because the thing is, in that case, you do no=\r\nt need to worry about a permanent dead weight taking up some proportion of =\r\nyour population forever. Instead, while the encoding may *tend* to produce =\r\ne.g. low-connectivity solutions, it can still escape tha\n(Message over 64 KB, truncated)"}}