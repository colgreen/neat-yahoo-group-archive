{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"4oCG_Z4m2e5uFZKXcjkNncLuATtiR9FBfd9D1Kb6koufruESeZ3vEievyI4NpNWul0HCiA0_9Odd9Vzerz5huG_nfY-iGeUvtel03PIp__MkxVH7nAQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1210859054","msgId":4066,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwaGVuZSs2amxmQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGcwZ2thMCsxMHFxbkBlR3JvdXBzLmNvbT4="},"prevInTopic":4065,"nextInTopic":4069,"prevInTime":4065,"nextInTime":4067,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"Hi Ken, thanks for this great post again, it answered many questions and it helped me get more insight in the philosophy behind NS. One question I have, how we","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 19680 invoked from network); 15 May 2008 13:44:15 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m36.grp.scd.yahoo.com with QMQP; 15 May 2008 13:44:15 -0000\r\nX-Received: from unknown (HELO n1.bullet.mail.re1.yahoo.com) (69.147.103.128)\n  by mta15.grp.scd.yahoo.com with SMTP; 15 May 2008 13:44:15 -0000\r\nX-Received: from [68.142.237.87] by n1.bullet.mail.re1.yahoo.com with NNFMP; 15 May 2008 13:44:15 -0000\r\nX-Received: from [209.73.164.86] by t3.bullet.re3.yahoo.com with NNFMP; 15 May 2008 13:44:14 -0000\r\nX-Received: from [66.218.67.201] by t8.bullet.scd.yahoo.com with NNFMP; 15 May 2008 13:44:14 -0000\r\nDate: Thu, 15 May 2008 13:44:14 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g0hene+6jlf@...&gt;\r\nIn-Reply-To: &lt;g0gka0+10qqn@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=283334584; y=ai_TB4rcTcL29PJBecCexy5KCxxDwwjw6dmBR7leeHyd7ijt7NA1E92dxw\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi Ken,\n\nthanks for this great post again, it answered many questions and i=\r\nt \nhelped me get more insight in the philosophy behind NS. \nOne question I =\r\nhave, how we could deal with stagnation even in \nnovelty search, i.e. when =\r\nevery new genome happens to be a known \nbehavior? Is this possible at all? =\r\n\n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrot=\r\ne:\n&gt;\n&gt; Jeff,\n&gt; \n&gt; Thanks for asking these questions.  These are likely the =\r\nkinds of\n&gt; questions we are going to face over time so it&#39;s a good chance t=\r\no \nwork\n&gt; on our response.  I&#39;m going to start with a technical response bu=\r\nt\n&gt; move to philosophical.  It&#39;s a bit of an essay but hopefully worth \nthe=\r\n\n&gt; read.\n&gt; \n&gt; Your first set of questions regards the relationship between =\r\nnovelty\n&gt; search (NS) and exhaustive search of behavioral space.  Do we thi=\r\nnk\n&gt; these are effectively the same thing?\n&gt; \n&gt; I think it&#39;s a tricky subje=\r\nct but in the end I would not equate NS \nto\n&gt; exhaustive search.  While NS =\r\nindeed does attempt to essentially \nvisit\n&gt; every behavior in behavioral sp=\r\nace, the way it does it is not the \nsame\n&gt; as what is usually meant by exha=\r\nustive search.  We usually think of \nan\n&gt; exhaustive search as a purposeful=\r\n enumeration, where if I just try\n&gt; every combination of something, one wil=\r\nl be the answer.  A key \nfeature\n&gt; of this type of search is that it does n=\r\not require or utilize\n&gt; information or feedback of any kind as a guide.  Ra=\r\nther, it simply\n&gt; makes sure it does not visit the same point twice.  (It i=\r\ns similar \nto\n&gt; random search except that random search might indeed visit =\r\nthe same\n&gt; point twice.)\n&gt; \n&gt; One clear difference between such a search an=\r\nd NS is that we cannot\n&gt; purposefully enumerate all possible behaviors beca=\r\nuse our search \nspace\n&gt; is the genotype space, which maps indirectly to the=\r\n behavior space. \n&gt; Therefore, there is actually no way to simply say &quot;list=\r\n all possible\n&gt; behaviors&quot; and try each one in succession.  We must seek th=\r\nem out.\n&gt; \n&gt; Furthermore, in novelty search there is *information* guiding =\r\nthe\n&gt; order of points we visit (the information is the novelty measure). \n&gt;=\r\n The points also have an inherent order (perhaps quite useful) \ninduced\n&gt; b=\r\ny the genetic encoding (hence the promise of combining it with\n&gt; HyperNEAT)=\r\n. In other words, we are not simply enumerating in an\n&gt; arbitrary non-overl=\r\napping order.  Rather, we follow the most \npromising\n&gt; trails that seem to =\r\nbe leading to something new.\n&gt; \n&gt; One significant consequence of this fact =\r\nis that the actual search\n&gt; space (which is the genotype space) will almost=\r\n certainly never need\n&gt; to be exhaustively searched.  So we effectively avo=\r\nided wasting our\n&gt; time examining all kinds of genetic combinations that wo=\r\nuld have\n&gt; produced redundant behaviors.  In its usual meaning, exhaustive =\r\n\nsearch\n&gt; would be just such a search through genotype space.  So certainly=\r\n it\n&gt; is not normal exhaustive search.\n&gt; \n&gt; Yet if you still want to talk a=\r\nbout exhaustively searching behavior\n&gt; space, it is still not a typical exh=\r\naustive search because of the \nfact\n&gt; it proceeds in an order guided by inf=\r\normation- not typical of\n&gt; exhaustive search.  Another corollary is that it=\r\n is impossible to\n&gt; perform a typical exhaustive search of behavior space b=\r\necause we \nhave\n&gt; no method to enumerate it:  It must be explored.\n&gt; \n&gt; Yet=\r\n you might still say, fine, semantically perhaps it is something\n&gt; differen=\r\nt, but still, in spirit are you not essentially doing\n&gt; something equally i=\r\nnefficient, i.e. looking for absolutely \neverything?  \n&gt; \n&gt; And it is true =\r\nthat in effect we are searching for every behavior, \nor\n&gt; at least every be=\r\nhavior that looks distinguishable from each other\n&gt; with respect to the nov=\r\nelty metric and in an order from simplicity \nto\n&gt; high complexity.  Yet the=\r\nrein lies the fundamental insight: While \nsuch\n&gt; a search might sound bad, =\r\nit is a lot better to look at everything \n(in\n&gt; some meaningful order) and =\r\neventually run across what you want\n&gt; (perhaps after a very long time) than=\r\n to look for one specific thing\n&gt; and *never* find it.\n&gt; \n&gt; We are indeed s=\r\nuggesting that this rather tortured choice (between\n&gt; looking for something=\r\n without hope and looking for everything) is\n&gt; sometimes the real choice th=\r\nat we face with the most ambitious\n&gt; problems.  In other words, objective-b=\r\nased fitness is literally \ndoomed\n&gt; when it comes to evolving many incredib=\r\nly complex systems from\n&gt; scratch.  It will simply never happen because at =\r\nhigh levels of\n&gt; complexity, there is going to be massive deception at many=\r\n levels, \nand\n&gt; fitness becomes as bad as random search in such a problem. =\r\n In fact,\n&gt; as our results show, you don&#39;t even have to make the problem al=\r\nl \nthat\n&gt; hard to cause fitness to crumble into something as bad as random\n=\r\n&gt; search.  What do you think will happen if you are trying to evolve a\n&gt; ne=\r\nural network into the mind of a quantum physicist based on how\n&gt; brilliant =\r\nit is at quantum physics?  The answer: Nothing.\n&gt; \n&gt; A more down-to-earth e=\r\nxample is the car that I evolved on \nPicbreeder.\n&gt;  It could never have evo=\r\nlved if evolving a car had been the\n&gt; *objective* because it was preceded b=\r\ny an alien face (evolved by\n&gt; someone else).  It just so happens that the a=\r\nlien face is a stepping\n&gt; stone to a car, but if we had judged the alien fa=\r\nce on it &quot;car-\nness,&quot;\n&gt; it would have failed miserably and been deleted.  H=\r\nence if we were\n&gt; looking for a car we would never have found one.\n&gt; \n&gt; In =\r\nnature, if we had bred flatworms (the earliest chordates) based \non\n&gt; their=\r\n humanity, they too would have never evolved into amphibians,\n&gt; then reptil=\r\nes, then mammals, as they did.  The objective in long-run\n&gt; problems is tot=\r\nally blind to the necessary stepping stones.  Unless \nwe\n&gt; know them a prio=\r\nri, we are lost.\n&gt; \n&gt; Why do you suppose we have never seen a flowering of =\r\ndiversity and\n&gt; complexity such as seen in nature in evolutionary computati=\r\non?  In \n30\n&gt; or 40 years of this field, which is inspired by nature, we ha=\r\nve \nnever\n&gt; seen something that comes even close to even nature&#39;s modest\n&gt; =\r\nachievements.  The problem is that we have been blinded by \nobjectives.\n&gt;  =\r\n  As soon as we set an objective, the stepping stones to it often\n&gt; vanish =\r\ninto thin air.  There is no escape from this very sobering\n&gt; fact.  It will=\r\n have to be accepted, though it will be hard to \naccept.\n&gt; \n&gt; Novelty searc=\r\nh cures this problem, although admittedly in a painful\n&gt; way, because it fo=\r\nrces us to let go of our natural desire to \n*control*\n&gt; what is happening. =\r\n We feel compelled to demand to the search\n&gt; algorithm that it go in a cert=\r\nain direction.  It is difficult to\n&gt; relinquish this feeling of control, ye=\r\nt if we recognize that in the\n&gt; end the setting of such goals is its own wo=\r\nrst enemy, then we can\n&gt; begin to be liberated from this longstanding compu=\r\nlsion.\n&gt; \n&gt; (Note that I am not saying fitness is always useless; obviously=\r\n that\n&gt; is not the case.  I am talking about very ambitious problems, beyon=\r\nd\n&gt; the kind we have been able to solve yet- though even the &quot;hard maze&quot;\n&gt; =\r\nis bordering on such a problem.)\n&gt; \n&gt; You point out that novelty search may=\r\n get &quot;lost&quot; in a kind of \nendless\n&gt; offshoot in behavior space.  And yes, i=\r\nn some situations, it very \nwell\n&gt; may.  Yet I believe it will not do so in=\r\n many interesting domains. \n&gt; For example, if there was indeed a long offsh=\r\noot of the maze, first,\n&gt; since there is a time limit for each robot, it wo=\r\nuld make little\n&gt; difference and would quickly be filled up by novelty sear=\r\nch.  If \nthere\n&gt; are no obstacles in the offshoot, it would be filled espec=\r\nially \nfast.\n&gt;  But at the same time, novelty search is not likely to go of=\r\nf in \nonly\n&gt; one direction anyway.  Because it is a population, it will go =\r\noff in\n&gt; many directions at once.  While some parts may shoot down the\n&gt; di=\r\nversionary offshoot, at the same time others will begin to flow \ndown\n&gt; the=\r\n paths we want.  If it happens to take the wrong paths, it will\n&gt; fill that=\r\n areas first and eventually be pushed back into the areas \nwe\n&gt; care about =\r\n(only if each individual was given infinite time could it\n&gt; be stuck in one=\r\n area forever)\n&gt; \n&gt; In the end, of course there is a chance it will fail to=\r\n go the right\n&gt; way in reasonable time; after all, it has no objective!  In=\r\n fact, in\n&gt; the hard maze experiment, it did once fail to find a solution i=\r\nn 40\n&gt; runs.  Yet look at how much more consistent it is than fitness-based=\r\n\n&gt; search.  So the point is not that this is a guarantee (there will\n&gt; neve=\r\nr be one).  Rather, it is a profoundly different kind of search,\n&gt; which is=\r\n likely to reach places that fitness-based search can never\n&gt; hope to touch=\r\n.  So it opens up a whole new world of possibilities to\n&gt; evolutionary comp=\r\nutation.  That does not mean it solves everything; \nof\n&gt; course it may stil=\r\nl not always give us what we want.  There is no\n&gt; method that will ever alw=\r\nays give you what you want.  Yet objective\n&gt; fitness is often even worse.  =\r\nThat is the sobering moral of the \nstory.\n&gt; \n&gt; So in my view, NS is actuall=\r\ny suited for exactly those &quot;large \nspaces&quot;\n&gt; that you suggest it will have =\r\ntrouble in.  And by large I mean \nLARGE.\n&gt;  Those are the ones where object=\r\nive-based fitness has no hope.  \nThese\n&gt; are spaces like life on earth, whe=\r\nre it would be futile (and silly) \nto\n&gt; start with a single cell and select=\r\n offspring based on relative\n&gt; humanity.  The only reason we got to humans =\r\nin nature is because\n&gt; nobody said we had to get there.  It&#39;s almost parado=\r\nxical, but if \nyou\n&gt; accept it, it is an exciting liberation.  If we let go=\r\n of the\n&gt; compulsion to be in control, we may find something we did not exp=\r\nect\n&gt; that is quite significant.\n&gt; \n&gt; So actually the idea of running fitne=\r\nss-based search and then \nnovelty\n&gt; search is less exciting to us although =\r\nwe raise it as a practical\n&gt; matter.  In some domains, objective fitness is=\r\n simply impotent, and\n&gt; the compulsion to have some shred of guidance to ha=\r\nng onto is a \nfalse\n&gt; comfort.  We will have to let go, and then, strangely=\r\n, we will end \nup\n&gt; where we want to be.  It&#39;s like when your grandparents =\r\ntold you that\n&gt; if you stop worrying so much about making things work out, =\r\nthey will\n&gt; work out on their own.  Did you believe them?  Maybe there is m=\r\nore\n&gt; wisdom in it than there appeared to be.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; --- In neat@=\r\nyahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hello. \n&gt; &gt; \n&gt; &gt; Thank=\r\ns for the thought provoking paper. Here is my main question\n&gt; regarding\n&gt; &gt;=\r\n the work: How would you differentiate the NSA (novelty search \nalgorithm)\n=\r\n&gt; &gt; from exhaustive search in the behavior space?\n&gt; &gt; \n&gt; &gt; If you think the=\r\nre is a relevant difference between the NSA and\n&gt; exhaustive\n&gt; &gt; behavioral=\r\n search, have you tried using the former as a control \nand\n&gt; seeing\n&gt; &gt; how=\r\n they compare?\n&gt; &gt; \n&gt; &gt; If the NSA is effectively exhaustive search in beha=\r\nvior space, it\n&gt; seems to\n&gt; &gt; me that, while it will work well (and better =\r\nthan a GA) in small,\n&gt; deceptive\n&gt; &gt; landscapes, it will not perform very w=\r\nell in large search spaces.\n&gt; Imagine,\n&gt; &gt; for example, the paper&#39;s &quot;medium=\r\n map&quot; but with a huge (near\n&gt; infinite) open\n&gt; &gt; area to the left of the st=\r\narting condition. It could easily get \nlost\n&gt; over\n&gt; &gt; there indefinitely.\n=\r\n&gt; &gt; \n&gt; &gt; You mention that it helps to have the domain constrain the search =\r\n\nspace.\n&gt; &gt; Does this just mean that the (behavioral) search space has to b=\r\ne \nsmall\n&gt; &gt; enough that it can an exhaustive search can deal with it? How =\r\nwill\n&gt; it fare\n&gt; &gt; in the much larger search spaces of real-world problems,=\r\n like \ncheckers?\n&gt; &gt; \n&gt; &gt; Using the NSA as something to bail out objective-=\r\nsearch when it\n&gt; stagnates is\n&gt; &gt; an interesting suggestion. But at that po=\r\nint it should be \ncompared to\n&gt; &gt; fitness sharing. Would it do better than =\r\nfitness sharing? I can \nthink of\n&gt; &gt; reasons it might (because it truly is =\r\nnot tempted by deceptive\n&gt; traps), but\n&gt; &gt; it would useful to see it compar=\r\ned to fitness sharing controls.\n&gt; &gt; \n&gt; &gt; Just my 2 cents. Thanks for puttin=\r\ng this out there.\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Cheers,\n&gt; &gt; Jeff Clune\n&gt; &gt; \n&gt; &gt; Digital Evo=\r\nlution Lab, Michigan State University\n&gt; &gt; \n&gt; &gt; jclune@\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n=\r\n&gt; &gt; &gt; From: Kenneth Stanley &lt;kstanley@&gt;\n&gt; &gt; &gt; Reply-To: &quot;neat@yahoogroups.c=\r\nom&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; Date: Fri, 09 May 2008 02:00:33 -0000\n&gt; &gt; =\r\n&gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; &gt; Subject: [neat] I=\r\nntroducing a New Approach to Search: Novelty\n&gt; Search (New\n&gt; &gt; &gt; Paper)\n&gt; &gt;=\r\n &gt; \n&gt; &gt; &gt; Joel Lehman and I are excited to announce our new publication to\n=\r\n&gt; &gt; &gt; appear in the Eleventh International Conference on Articifial \nLife\n&gt;=\r\n &gt; &gt; (ALIFE XI), called &quot;Exploiting Open-Endedness to Solve Problems\n&gt; &gt; &gt; =\r\nThrough the Search for Novelty.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; The paper is here:\n&gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; http://eplex.cs.ucf.edu/publications.html#lehman.alife08\n&gt; &gt; &gt; \n&gt; &gt; &gt; Di=\r\nrect link: http://eplex.cs.ucf.edu/papers/lehman_alife08.pdf\n&gt; &gt; &gt; \n&gt; &gt; &gt; T=\r\nhis paper is about a new kind of search (which works with \nNEAT) that\n&gt; &gt; &gt;=\r\n abandons the longstanding notion in all of machine learning \nthat the\n&gt; &gt; =\r\n&gt; gradient of search should be measured with respect to the \nultimate\n&gt; &gt; &gt;=\r\n objective.  In other words, it entirely abandons objectives and\n&gt; &gt; &gt; ther=\r\neby also abandons fitness functions as the impetus for \nsearch.\n&gt; &gt; &gt; Yet r=\r\nemarkably, we still show that such an algorithm can perform\n&gt; &gt; &gt; *better* =\r\nthan one that actually tries to achieve the \nobjective!  I\n&gt; &gt; &gt; believe th=\r\nis strange result has fascinating implications for \nmachine\n&gt; &gt; &gt; learning,=\r\n artificial life, and even biology.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Lately on this forum we ha=\r\nve often discussed the nagging \nproblem that\n&gt; &gt; &gt; the fitness function oft=\r\nen does not properly recognize or \nreward the\n&gt; &gt; &gt; stepping stones on the =\r\nway to the solution.  I went as far as\n&gt; &gt; &gt; suggesting that the fitness fu=\r\nnction can become an *obstacle* to\n&gt; &gt; &gt; success (e.g. when we discussed cr=\r\neativity in Picbreeder).\n&gt; &gt; &gt; \n&gt; &gt; &gt; While this discussion was largely phi=\r\nlosophical, Joel Lehman \nand I\n&gt; &gt; &gt; decided to make it concrete and actual=\r\nly introduce an algorithm \nthat\n&gt; &gt; &gt; makes an automated evolutionary proce=\r\nss in *any* domain behave \nlike\n&gt; &gt; &gt; humans in Picbreeder, that is, like o=\r\npen-ended evolution.  This\n&gt; &gt; &gt; approach is called &quot;novelty search.&quot;  The =\r\nalgorithm simply \nsearches\n&gt; &gt; &gt; for behavior that is novel with respect to=\r\n what has come before.\n&gt; &gt; &gt; \n&gt; &gt; &gt; The benefit of this approach is that it=\r\n is immune to deception \nbecause\n&gt; &gt; &gt; it does not even try to achieve the =\r\nobjective.  I know it seems\n&gt; &gt; &gt; strange but, counterintuitively, we show =\r\nthat in fact it is far \nmore\n&gt; &gt; &gt; effective at solving a difficult problem=\r\n in a deceptive \nlandscape than\n&gt; &gt; &gt; fitness-based search.\n&gt; &gt; &gt; \n&gt; &gt; &gt; In=\r\n other words, what we are saying is that to achieve some of \nthe most\n&gt; &gt; &gt;=\r\n ambitious objectives we might have for evolution, we must \nabandon\n&gt; &gt; &gt; t=\r\nrying to explicitly achieve them.  To quote from the end of our\n&gt; &gt; &gt; Discu=\r\nssion section:\n&gt; &gt; &gt; \n&gt; &gt; &gt; &quot;In summary, almost like a riddle, novelty sear=\r\nch suggests\n&gt; &gt; &gt; a surprising new perspective on achievement: To achieve\n&gt;=\r\n &gt; &gt; your highest goals, you must be willing to abandon them.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n I believe this lesson is true in practice and is therefore \nbeyond a\n&gt; &gt; &gt;=\r\n philosophical curiosity.  In fact, we are instinctively \nfamiliar with\n&gt; &gt;=\r\n &gt; it in life in general when people say things like &quot;You are \ntrying too\n&gt;=\r\n &gt; &gt; hard&quot; or when we focus so much on something so far ahead of us \nin lif=\r\ne\n&gt; &gt; &gt; that we forget completely to solve the short term problems that \nst=\r\nand\n&gt; &gt; &gt; in our way.  It is no less true in evolution or search in \ngenera=\r\nl.\n&gt; &gt; &gt; \n&gt; &gt; &gt; For NEAT, novelty search should open up new opportunities f=\r\nor\n&gt; &gt; &gt; discovery that were previously closed off to us.\n&gt; &gt; &gt; \n&gt; &gt; &gt; I lo=\r\nok forward to hearing your thoughts on this work.\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt;\n&gt; =\r\n&gt;\n&gt;\n\n\n\n"}}