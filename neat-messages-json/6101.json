{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"Ix4t2TIdRpjukDgMcO-Iv8ldi-3JIAheFp38TW1RW3ys8EULuuunhVarE8wgBQMp_8Es35NxvA5D8pkLbMuOIQ5sUTDX","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: GECCO Paper on HyperNEAT","postDate":"1369774086","msgId":6101,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtvMzU2NitnOWxvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtudnM0aSszbXJmQGVHcm91cHMuY29tPg=="},"prevInTopic":6097,"nextInTopic":6127,"prevInTime":6100,"nextInTime":6102,"topicId":6085,"numMessagesInTopic":14,"msgSnippet":"Hi Shimon, Let me respond to your three points as best I can at this point.  I appreciate the effort you ve put into articulating your position and hope this","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 58675 invoked by uid 102); 28 May 2013 20:48:09 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m7.grp.bf1.yahoo.com with SMTP; 28 May 2013 20:48:09 -0000\r\nX-Received: (qmail 21564 invoked from network); 28 May 2013 20:48:08 -0000\r\nX-Received: from unknown (HELO ng17-ip10.bullet.mail.bf1.yahoo.com) (98.139.165.156)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 28 May 2013 20:48:08 -0000\r\nX-Received: from [98.139.164.121] by ng17.bullet.mail.bf1.yahoo.com with NNFMP; 28 May 2013 20:48:08 -0000\r\nX-Received: from [10.193.94.109] by tg2.bullet.mail.bf1.yahoo.com with NNFMP; 28 May 2013 20:48:08 -0000\r\nDate: Tue, 28 May 2013 20:48:06 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ko3566+g9lo@...&gt;\r\nIn-Reply-To: &lt;knvs4i+3mrf@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: GECCO Paper on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=zuYMpm7R4Fc4-ndaavVg86yQBoiMnwek0rPavaO1h6SXRo2RUU1E\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Shimon,\n\nLet me respond to your three points as best I can at this poi=\r\nnt.  I appreciate the effort you&#39;ve put into articulating your position and=\r\n hope this discussion remains positive and illuminating.  Please note that =\r\nwe will release a more formal response with supporting data in the near fut=\r\nure, but for the moment I will try to respond informally to the best of my =\r\nability with the understanding that we have collected data to support my ar=\r\ngument.\n\n[For people who want a quick summary:\n\n1) In recent reimplementati=\r\nons by our group with only slightly different parameters and setups it appe=\r\nars regular HyperNEAT actually *can* solve the problems in the paper, sugge=\r\nsting that critical factors in the performance of HyperNEAT are not actuall=\r\ny clarified by the paper.\n2) Shimon and I disagree on what &quot;target-based&quot; m=\r\neans.  In my view the benchmark problems in the paper are just as &quot;target-b=\r\nased&quot; as the pattern-matching task, and I give details on why in this respo=\r\nnse, and on why that distinction is important for the future of indirect en=\r\ncoding.\n3) I argue that it doesn&#39;t really matter if fracture takes six or s=\r\neven nodes to represent because that number is trivial in the grand scheme =\r\nof things, and even Picbreeder genomes have many times more nodes than that=\r\n.\n]\n\n\nThe detailed version:\n\n1)  Regarding the code itself, we have at this=\r\n point run enough experiments in reimplementations of both the triangles an=\r\nd the hard line following domain, and within PEAS-NEAT (sometimes with twea=\r\nks to parameters), to say with some confidence that HyperNEAT actually *doe=\r\ns* solve these problems.  Of course, because these problems are the basis f=\r\nor the main concern raised in the paper, the fact we can get good results w=\r\nith HyperNEAT on them is a significant problem for the main hypothesis.  \n\n=\r\nI do not want to imply the PEAS code is somehow fundamentally flawed or wro=\r\nng, or that you and Thomas did not do your best to make it accurate.  The m=\r\nain issue is just that HyperNEAT apparently can solve these tasks without m=\r\nuch trouble.  \n\nWhile it looks like getting HyperNEAT to solve these tasks =\r\nmay require a slightly different parameterization or setup than the one in =\r\nthe paper, the paper is claiming to be identifying &quot;Critical Factors in the=\r\n Performance of HyperNEAT.&quot;  If the main factors in the performance of thes=\r\ne problems turns out to be minor variations in their parameters, then that =\r\nwould suggest that the &quot;factors&quot; are misidentified in this paper, and that =\r\nin fact HyperNEAT is not ill-equipped to solve these problems.\n\nHowever, I =\r\nalso should disclose that it appears to us at this time that these two doma=\r\nins that were intended to be harder *also* can yield good scores without hi=\r\ndden nodes, which actually means the domains are not that good for explorin=\r\ng the hypothesis advanced in the paper that there is some kind of problem w=\r\nith hidden nodes for HyperNEAT.  At the same time, it also appear from our =\r\npreliminary results in a different version of HyperNEAT that allowing hidde=\r\nn nodes may yield a bit better performance at least the triangles domain, b=\r\nut we are still determining if the difference is significant.  At least it =\r\nappears that a *perfect* solution (which it turns out HyperNEAT found at le=\r\nast once) does require hidden nodes.  Therefore, to be fair, based on these=\r\n domains and our preliminary analysis, the main hypothesis still may or may=\r\n not be true, but these domains do not seem to be the best to provide evide=\r\nnce for it one way or another.  \n\nAs you noted, the third domain, the quadr=\r\nuped, is in another implementation, but given that we have been having good=\r\n results with HyperNEAT in quadruped domains similar to the &quot;hard&quot; one in t=\r\nhe paper (and in fact even harder)\n\n(for example http://eplex.cs.ucf.edu/pa=\r\npers/morse_gecco13.pdf and\nhttp://eplex.cs.ucf.edu/papers/risi_gecco13b.pdf=\r\n)\n\nit is reasonable to speculate that a similar story could turn out true f=\r\nor the hard quadruped as well:  it can probably be made to work with a litt=\r\nle parameter tweaking, and may not even require hidden nodes either.\n\nSo I =\r\nthink this hidden node issue remains an interesting open question, but the =\r\ndomains in this paper do not really seem to address it.  I would not be sur=\r\nprised if there are indeed some domains that HyperNEAT has trouble solving =\r\nas a direct objective if it requires multiple hidden nodes, but that is why=\r\n ultimately a more important issue is probably the target-based one, which =\r\nis the one you addressed next:\n\n2)  We seem to disagree on what is &quot;target-=\r\nbased.&quot;  You say most experiments were &quot;not on such target-based tasks,&quot; bu=\r\nt I consider all the experiments in your paper target-based, including the =\r\nones you call &quot;regular.&quot;  Indeed, that&#39;s been a major problem in our field =\r\nI&#39;ve been trying to highlight: the &quot;regular&quot; way of doing business isn&#39;t go=\r\ning to scale because it is target-based.\n\nRunning a controller-evolution pr=\r\noblem with a strictly objective-driven fitness is analogous to evolving the=\r\n output of a CPPN to produce a particular patten or image.  That&#39;s the deep=\r\ner point of my paper with Woolley, and an important lesson from novelty sea=\r\nrch in general: the field has been running target-based experiments for dec=\r\nades but evolution in nature does not work that way.  &quot;Walking&quot; was never a=\r\nn explicit objective (i.e. target) for nature.  It is the oblique achieveme=\r\nnt of such feats (i.e. despite never being formalized as an objective) that=\r\n makes nature&#39;s accomplishments so interesting.  Picbreeder&#39;s accomplishmen=\r\nts are similarly oblique.  And as we have observed with novelty search, whe=\r\nn you take away that target (such as in the maze, or the biped), sometimes =\r\nthat&#39;s when you get even better results.  \n\nSo in my view all your experime=\r\nnts in this paper are target-based.  Of course, like I said above, they see=\r\nm nevertheless possible to solve by HyperNEAT (even though they are target-=\r\nbased), but more importantly even if they could not be solved as targets, i=\r\nn principle we would have to ask whether they are more appropriately solved=\r\n with a stronger behavioral diversity mechanism.  That is a reasonable hypo=\r\nthesis given results in recent years from our group and others.   \n\nThat ob=\r\nservation is relevant because it would suggest qualifying your hypothesis. =\r\n Instead of saying fracture is &quot;highly problematic for HyperNEAT,&quot; the hypo=\r\nthesis would instead say, &quot;fracture is sometimes problematic for HyperNEAT =\r\nwhen fitness is expressed exclusively in a target-based fashion.&quot;  Of cours=\r\ne, my guess right now is that it is not particularly more problematic for H=\r\nyperNEAT than any other genuine indirect encoding, and to the extent it&#39;s t=\r\nrue, this statement would likely apply for other genuine indirect encodings=\r\n as well.\n\nI say &quot;genuine indirect encoding&quot; because one of the big dangers=\r\n in this kind of analysis is that we inadvertently glorify direct encodings=\r\n.  Often direct encodings will actually be better at hitting arbitrary targ=\r\nets.  That&#39;s an unfortunate fact that is going to unravel a lot of our prog=\r\nress in indirect encoding if we continue returning to it.  A direct encodin=\r\ng is like a Xerox machine, reproducing every pixel in an image independentl=\r\ny.  So of course it will copy arbitrary patterns better than an encoding th=\r\nat has to build up complexity compositionally, i.e. by establishing regular=\r\nities first and then elaborating on them.  The wavelet encoding in your pap=\r\ner is similar to this kind of direct encoding, placing independent blobs at=\r\n arbitrary locations.  \n\nMy belief is that in this field we&#39;re facing a tra=\r\ndeoff that hasn&#39;t been discussed very much, but that is very fundamental an=\r\nd important: \nThe more direct the mapping between genotype and final soluti=\r\non, the more suited direct encodings become to relatively simple target-bas=\r\ned problems (e.g. under 1,000 dimensions), but we pay for that &quot;quality&quot; by=\r\n committing to an encoding that can never generate genuinely high-complexit=\r\ny structures.  \n\nSo as long as we stick to the benchmark playground that we=\r\n&#39;re used to (where most solutions require under 1,000 parts), we are going =\r\nto keep fooling ourselves into revisiting direct-like encodings, which have=\r\n no chance to ever produce anything like the complexity seen in nature.\n\nTh=\r\nus in my view the final target-based validation in the paper is potentially=\r\n misleading in this respect - it appears rational as a choice for validatin=\r\ng the fracture hypothesis, but actually it is a *good* result for the indir=\r\nect encoding: we would not want an indirect encoding to succeed in this typ=\r\ne of scenario.  If it did, it should raise the suspicion that it is a direc=\r\nt encoding in disguise, just a Xerox machine posing as as watchmaker (or wa=\r\ntch-designer to be more accurate).\n\n3) [It&#39;s worth noting that there are a =\r\nlot of fractures of the type with repeating patterns within fractured regio=\r\nns on Picbreeder as well, but I&#39;ll leave that to a different thread so as n=\r\not to distract from the main discussion here.]\n\nI think you might have misu=\r\nnderstood my point about figure 13 (or maybe I didn&#39;t express it clearly en=\r\nough).  I don&#39;t think it&#39;s really important whether the exact number of nod=\r\nes shown in figure 13 is necessary for fracture.  The only point I meant to=\r\n make is that you don&#39;t need a special &quot;mask node&quot; with an inversion operat=\r\nor like in that figure (since Picbreeder doesn&#39;t have such nodes).  But sur=\r\ne, I agree that the exact number of hidden nodes needed for a particular fr=\r\nacture is probably similar to the number (i.e. six or seven) in your figure=\r\n.\n\nBut that isn&#39;t the important point from my perspective.  The important p=\r\noint is that six or seven isn&#39;t very many hidden nodes in the grand scheme =\r\nof things.  The Picbreeder Apple has 83 nodes.  The Car has 50, and the Sku=\r\nll 23.  6 is just a small fraction, and clearly poses no problem in hundred=\r\ns or even thousands of examples of such structures evolved routinely on Pic=\r\nbreeder.  Human DNA has about 30,000 genes; a gene is roughly analogous to =\r\na node in a CPPN (genes connect to each other through a GRN).  6 out of 30,=\r\n000 is a tiny drop in the bucket.  We should be aspiring to evolving genoty=\r\npic structures with at least 50 nodes, and Picbreeder shows that for CPPNs =\r\nsuch a feat is routine and unremarkable.  \n\nThe main point is, there&#39;s noth=\r\ning particularly prohibitive about a substructure requiring a few nodes (an=\r\nd it happens routinely), so the motivation for the hypothesis, i.e. that re=\r\nquiring a few nodes to represent a particular motif is a &quot;problem,&quot; is wort=\r\nh questioning.  \n\nNow granted the question on whether HyperNEAT in a target=\r\n-based scenario can evolve levels of complexity like in Picbreeder or Endle=\r\nssforms is open, but like I said, I see that issue as a red herring because=\r\n we need to be moving away from target-based formulations if we are to see =\r\nthe complexity that is achievable through indirect encoding.  Target-based =\r\nformulations will ultimately only drag us back to more direct encodings tha=\r\nt do well in neat little benchmarks.  That doesn&#39;t mean we can&#39;t use indire=\r\nct encodings to solve problems; it just means that we need to learn to form=\r\nalize our problems in a way that respects the need for phenotypic diversity=\r\n and open-endedness.  \n\nUltimately we may even find that evolution in its m=\r\nost grandiose, i.e. when it finds things like humans, simply must be unchai=\r\nned completely from a specific target behavior.  I don&#39;t know if that&#39;s tru=\r\ne yet, but if it is, I feel no inhibition about pushing it down that road a=\r\nnyway.  That is, even if it isn&#39;t really a &quot;tool,&quot; it is still the greatest=\r\n creative force ever to exist, and unchaining that force is no small feat e=\r\nven if it is not the solution to a benchmark problem.  At the same time I h=\r\nold out hope that specific problems can still be solved by indirect encodin=\r\ngs as well as long as we respect their special need for open-endedness and =\r\ndiversity.  \n\n&quot;An unhappy and unhealthy indirect encoding is one with only =\r\na strict target to which to aspire.&quot;\n\nBest Regards,\n\nken\n\n\n--- In neat@yaho=\r\nogroups.com, &quot;shimonw&quot; &lt;shimon@...&gt; wrote:\n&gt;\n&gt; \n&gt; Dear all,\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; I=\r\n&#39;d like to take the opportunity to respond to some of the\n&gt; criticisms that=\r\n Ken made about our GECCO-13 paper on HyperNeat. \n&gt; I&#39;ve organized the resp=\r\nonse according to what I consider the three\n&gt; main issues of contention.  F=\r\nollowing Ken&#39;s example, I&#39;ve\n&gt; included a short summary at the beginning fo=\r\nr those who lack the time or\n&gt; interest to read the whole response. (FYI, t=\r\nhis response was prepared\n&gt; with the help of Thomas van den Berg, the first=\r\n author of the paper in\n&gt; question).\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Short summary\n&gt; \n&gt; 1. Th=\r\nere&#39;s no evidence of any problem with our code or experiments.\n&gt; \n&gt; 2. Whil=\r\ne it is an important caveat of one section of our paper that it\n&gt; focuses o=\r\nn target-based scenarios, there are good reasons to do the\n&gt; experiment thi=\r\ns way, the results still provide substantial evidence that\n&gt; fracture can b=\r\ne difficult for HyperNEAT, this is supported by additional\n&gt; evidence not f=\r\nrom target-based scenarios, and analogous caveats apply to\n&gt; the counterexa=\r\nmples Ken provides.\n&gt; \n&gt; 3. Ken&#39;s examples of Picbreeder evolving fracture =\r\ndo not contradict\n&gt; our claim about the topology needed to represent fractu=\r\nre but are in\n&gt; fact consistent with it.  If our claim is wrong, anyone can=\r\n easily\n&gt; disprove it by showing a simpler topology than in our Fig. 13 but=\r\n to\n&gt; date no one has done so.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; And here&#39;s the full version:\n&gt;=\r\n \n&gt; \n&gt; \n&gt; \n&gt; Whether our implementation of HyperNEAT is valid:\n&gt; \n&gt; The PEA=\r\nS implementation of NEAT and HyperNEAT is an attempt to create an\n&gt; accessi=\r\nble python environment for experimenting with (generative)\n&gt; evolutionary m=\r\nethods. The code was made public as soon as possible to\n&gt; allow feedback, s=\r\no we&#39;re happy that Ken and others are looking at it\n&gt; and working with it n=\r\now.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; That said, we have several good reasons to believe that a=\r\nll of our\n&gt; results are based on correctly functioning code:\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; =\r\n1. The code was built by closely following the specifications given in\n&gt; pu=\r\nblished papers, and existing implementations were used as references\n&gt; when=\r\never the details were unclear.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; 2. It was validated on multipl=\r\ne benchmarks from existing research,\n&gt; including those we mention in our pa=\r\nper. We have not found=97and no\n&gt; one has shown us=97any evidence that sugg=\r\nests our implementation is\n&gt; invalid or that its results are inconsistent w=\r\nith those of existing\n&gt; implementations.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; 3. Not all of the ex=\r\nperiments in our paper use PEAS. The fact that we\n&gt; get qualitatively simil=\r\nar results on the Walking Gait task using Clune\n&gt; et al.&#39;s implementation i=\r\ns evidence for both our hypothesis and for\n&gt; the correctness of our code.\n&gt;=\r\n \n&gt; \n&gt; \n&gt; \n&gt; Whether our experiments are misleading because they use a targ=\r\net-based\n&gt; scenario:\n&gt; \n&gt; It is indeed an important caveat of the experimen=\r\nts we present in\n&gt; Section 6 of our paper that they use a target-based scen=\r\nario (evolving\n&gt; towards a fixed configuration of weights) with a &quot;tight&quot; f=\r\nitness\n&gt; function, as we explicitly acknowledge in the paper. However:\n&gt; \n&gt;=\r\n \n&gt; \n&gt; \n&gt; 1. There are good reasons to do the experiment this way: because =\r\nthe\n&gt; definition of fracture is inherently generative, only a target-based\n=\r\n&gt; scenario makes it possible to control for the amount of fracture needed\n&gt;=\r\n to solve the task.  In addition, our experiments in the target-based\n&gt; sce=\r\nnario allow us to follow up on the experiments of Clune et al.,\n&gt; shedding =\r\nlight on the reasons for HyperNEAT&#39;s failure, which were\n&gt; not completely a=\r\npparent from the original experiments.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; 2. Even given the cave=\r\nat that it is a target-based scenario, it is\n&gt; surprising and disappointing=\r\n how quickly HyperNEAT fails to find the\n&gt; fracture necessary to solve very=\r\n small, easy target-based tasks, much\n&gt; easier than those considered by Woo=\r\nlley & Stanley.  Therefore, we think\n&gt; these results constitute valid evide=\r\nnce that fracture can be a challenge\n&gt; for HyperNEAT.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; 3. In a=\r\nddition, most of the experiments in our paper were not on such\n&gt; target-bas=\r\ned tasks, and the &#39;difficult&#39; Walking Gait experiment provides\n&gt; additional=\r\n evidence that fracture can be challenging for HyperNEAT, but\n&gt; now in a &quot;r=\r\negular&quot; fitness-based scenario.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; 4. An analogous caveat applie=\r\ns to the Picbreeder counterexamples that\n&gt; Ken mentions: they were generate=\r\nd using the &quot;loose&quot; fitness\n&gt; functions of interactive evolution, where man=\r\ny good solutions are\n&gt; possible and humans naturally provide intermediate g=\r\nradients.  These\n&gt; results are beautiful, fascinating, and important, but t=\r\nhey are no more\n&gt; representative of many &quot;regular&quot; fitness functions, which=\r\n are\n&gt; encountered in a wide range of challenging optimization settings and=\r\n for\n&gt; which good solutions are rare but not unique, than target-based fitn=\r\ness\n&gt; functions are.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Obviously, more research needs to be don=\r\ne to explore different points on\n&gt; the spectrum between tight and loose fit=\r\nness functions, and it&#39;s\n&gt; worthwhile to debate what parts of the spectrum =\r\nwe should care about. \n&gt; But the fact that one set of our experiments looks=\r\n at only one point on\n&gt; that spectrum does not make them misleading any mor=\r\ne than the examples\n&gt; Ken provided are misleading.  It just means that, lik=\r\ne any finite set of\n&gt; experiments, it cannot tell the whole story.\n&gt; \n&gt; \n&gt; =\r\n\n&gt; \n&gt; 5. Regarding the non-Picbreeder counterexamples of HyperNEAT evolving=\r\n\n&gt; fracture: while these examples show that HyperNEAT can evolve fracture\n&gt;=\r\n given &quot;regular&quot; fitness functions, they do not establish that\n&gt; such fract=\r\nure is necessary.  A key distinction between our experiments\n&gt; and those th=\r\nat have previously been used to evaluate HyperNEAT is that\n&gt; we use baselin=\r\nes to establish the level of complexity that is actually\n&gt; needed to solve =\r\nthe task.  The results show that HyperNEAT sometimes\n&gt; evolves complex stru=\r\nctures that look impressive but are largely\n&gt; superfluous.  Thus, an import=\r\nant caveat of these counterexamples is that\n&gt; we don&#39;t know how much of thi=\r\ns fracture, if any, is needed to solve\n&gt; the task.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Whether si=\r\nmpler topologies can represent fracture than what we claim.\n&gt; \n&gt; Ken provid=\r\nes some examples from Picbreeder to show how fracture can be\n&gt; represented =\r\nin a very simply way.  While these examples are very cool,\n&gt; they actually =\r\ndo not contradict our assertions about what topologies are\n&gt; needed to repr=\r\nesent fracture.  Both Ken&#39;s examples and our Figure 13\n&gt; highlight the fact=\r\n that representing fracture requires what we call an\n&gt; &quot;indicator node&quot; for=\r\n outputting a component region in each of\n&gt; the phenotypes.  The only reaso=\r\nn that Figure 13 is a bit more\n&gt; complicated than Ken&#39;s examples is that it=\r\n is solving a harder\n&gt; problem: in addition to partitioning the space into =\r\nregions, it fills\n&gt; each region with a particular repeated pattern.  This r=\r\nequires extra\n&gt; nodes to prepare the inputs to the indicator node.\n&gt; \n&gt; \n&gt; =\r\n\n&gt; \n&gt; Note that Fig 13 is by no means a proof that a topology of this\n&gt; com=\r\nplexity is required to represent fracture: it&#39;s an upper bound,\n&gt; not a low=\r\ner bound.  We know it can be done in this way and we are unable\n&gt; to think =\r\nof a simpler way.  That doesn&#39;t prove that a simpler way\n&gt; doesn&#39;t exist, b=\r\nut, to date, no one has been able to show us a\n&gt; simpler way.  If our claim=\r\n is not correct, everyone is free to prove us\n&gt; wrong by simply providing s=\r\nuch an example.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; In conclusion\n&gt; \n&gt; We wrote this paper becaus=\r\ne we believe strongly in the promise of GDS,\n&gt; even when used with &quot;regular=\r\n&quot; fitness functions. It seems clear\n&gt; that HyperNEAT paired with interactiv=\r\ne evolution is a powerful tool. \n&gt; But our experiments suggest that there a=\r\nre some potentially serious\n&gt; difficulties when it comes to the &quot;regular&quot; f=\r\nitness functions\n&gt; that arise in a large range of important applications.  =\r\nWe don&#39;t\n&gt; think those limitations were sufficiently apparent from previous=\r\n\n&gt; experimental analyses of HyperNEAT and we therefore hope that, in this\n&gt;=\r\n respect, our paper will be a useful contribution.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ----------=\r\n---------------------------------------------------\n&gt; \n&gt; Shimon Whiteson | =\r\nAssistant Professor\n&gt; \n&gt; Intelligent Autonomous Systems Group\n&gt; \n&gt; Informat=\r\nics Institute | University of Amsterdam\n&gt; \n&gt; ------------------------------=\r\n-------------------------------\n&gt; \n&gt; Science Park 904 | 1098 XH Amsterdam\n&gt;=\r\n \n&gt; +31 (0)20.525.8701 | +31 (0)6.3851.0110\n&gt; \n&gt; http://staff.science.uva.n=\r\nl/~whiteson\n&gt; &lt;http://staff.science.uva.nl/~whiteson&gt;\n&gt; \n&gt; \n&gt; \n&gt; ----------=\r\n---------------------------------------------------\n&gt;\n\n\n\n"}}