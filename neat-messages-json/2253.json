{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":60940451,"authorName":"Jeff Haynes","from":"&quot;Jeff Haynes&quot; &lt;jeff@...&gt;","profile":"jefffhaynes","replyTo":"LIST","senderId":"nR3WXovA8PABo47FOueZ5UxSIcKlSZnFLISBK-PH1DtIXFLPRjs85rcnw-lwh4rTg8wI5ZNeVz5nL5kljhcEyDp6N_eM55O3gg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Introduction---recurrency question","postDate":"1125956868","msgId":2253,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDUwOTA1MjExNDIwLk01OTI0OUBkZWFyZG9yZmYuY29tPg==","inReplyToHeader":"PDQzMUM4Q0Q3LjUwNTA0MDFAeWFob28uY29tPg==","referencesHeader":"PGRmaTEzNSs1cXZuQGVHcm91cHMuY29tPiA8NDMxQzhDRDcuNTA1MDQwMUB5YWhvby5jb20+"},"prevInTopic":2252,"nextInTopic":2254,"prevInTime":2252,"nextInTime":2254,"topicId":2209,"numMessagesInTopic":42,"msgSnippet":"On Mon, 05 Sep 2005 13:22:15 -0500, Jim O Flaherty, Jr. wrote ... Yes, and I have done a very poor job of saying as much.  While I think that feed-forward","rawEmail":"Return-Path: &lt;jeff@...&gt;\r\nX-Sender: jeff@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 27209 invoked from network); 5 Sep 2005 21:47:50 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m26.grp.scd.yahoo.com with QMQP; 5 Sep 2005 21:47:50 -0000\r\nReceived: from unknown (HELO eagle.deardorff.com) (64.92.206.84)\n  by mta1.grp.scd.yahoo.com with SMTP; 5 Sep 2005 21:47:50 -0000\r\nReceived: from eagle.deardorff.com (jeffie@localhost [127.0.0.1])\n\tby eagle.deardorff.com (8.13.3/8.13.3) with ESMTP id j85Llml7015230\n\tfor &lt;neat@yahoogroups.com&gt;; Mon, 5 Sep 2005 17:47:48 -0400\r\nTo: neat@yahoogroups.com\r\nDate: Mon, 5 Sep 2005 17:47:48 -0400\r\nMessage-Id: &lt;20050905211420.M59249@...&gt;\r\nIn-Reply-To: &lt;431C8CD7.5050401@...&gt;\r\nReferences: &lt;dfi135+5qvn@...&gt; &lt;431C8CD7.5050401@...&gt;\r\nX-Mailer: Open WebMail 2.51 20050323\r\nX-OriginatingIP: 69.143.110.253 (jeffie)\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=iso-8859-1\r\nX-Spam-Status: No, Not spam. Probably whitelisted.\r\nX-Scanned-By: MIMEDefang 2.51 on 64.92.206.84\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Jeff Haynes&quot; &lt;jeff@...&gt;\r\nSubject: Re: [neat] Re: Introduction---recurrency question\r\nX-Yahoo-Group-Post: member; u=60940451; y=h3R1c_QQGZEi6cLRIWlgCjaJevtqW2uhbOWFVWsLI_Z2BFXkLwE\r\nX-Yahoo-Profile: jefffhaynes\r\n\r\nOn Mon, 05 Sep 2005 13:22:15 -0500, Jim O&#39;Flaherty, Jr. wrote\n\n&gt; \n&gt; With recurrence, things substantially change.  With any degree of \n&gt; recurrence, the network is very unlikely to provide precisely the \n&gt; same output for precisely the same input.  The network is no longer \n&gt; a pure state machine.  Here it is like a ROM with some RAM \n&gt; (recurrent connections are a form of memory), albeit the Random part \n&gt; of Random Access Memory is inaccurate.\n&gt; \n&gt; So, Jeff - Does your definition of a &quot;static neural network&quot; include \n&gt; recurrence?\n&gt; \n\nYes, and I have done a very poor job of saying as much.  While I think that\nfeed-forward networks are elemental in understanding the behavior of neural\nnets in general, I find them relatively uninteresting.  As Jim did a much more\nsuccinct job of explaining, there is a sort of night and day difference\nbetween those and those employing recurrence (as you are no doubt fully\naware).  I remember as a freshmen in college trying to create a flip-flop out\nof a recurrent neural net.  I don&#39;t remember if I was successful or not but\nI&#39;m sure if I wasn&#39;t it was simply a failure on my part.  I think if I were to\ntry it again now, the problem would be relatively trivial.\n\nAt any rate, it&#39;s a great to hear some other views on this!  If there&#39;s\nanything else amiss with the aforementioned idea of creating arbitrary logic\nsystems from RNNs, I would very much like to hear it.  Thank you,\n\njeff\n\nps - after a little googling, I was unable to located a nice source for an\nexample of a flip-flop implemented in a RNN.  However, this page\n(http://www.dna.caltech.edu/courses/cns187/info.html) at caltech seemed to\nsuggest the book &quot;Introduction to the Theory of Neural Computation&quot; by A.\nHertz, A. Krogh, and R. Palmer contains one.  If I come across anything better\nor come up with a model myself, I&#39;ll send it.\n\n&gt; \n&gt; Kenneth Stanley wrote:\n&gt; \n&gt; &gt; I&#39;m not sure I follow this logic.  A computer isn&#39;t just made out of\n&gt; &gt; NAND gates.  It also has flip-flops for storing data.  Therefore, I\n&gt; &gt; don&#39;t think it follows that a feedforward neural network can act as\n&gt; &gt; a programmable computer.\n&gt; &gt;\n&gt; &gt; ken\n&gt; &gt;\n&gt; &gt; --- In neat@yahoogroups.com, &quot;Jeff Haynes&quot; &lt;jeff@d...&gt; wrote:\n&gt; &gt; &gt; Well, I&#39;m sure people are getting weary of hearing us go on about\n&gt; &gt; this\n&gt; &gt; &gt; particular topic so I&#39;ll just say one last thing on it.\n&gt; &gt; &gt;\n&gt; &gt; &gt; - One can recreate any arbitrary circuit with a static neural\n&gt; &gt; network (in case\n&gt; &gt; &gt; there is any doubt about this, try creating a NAND gate).\n&gt; &gt; &gt;\n&gt; &gt; &gt; - Therefore, one can recreate a computer with a neural network.\n&gt; &gt; &gt; - A computer can be programmed to learn.\n&gt; &gt; &gt; - Therefore, a static neural network can learn.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Unless there is some error in that logic, I&#39;m not sure what the\n&gt; &gt; real issue is.\n&gt; &gt; &gt;  If we could refrain from talking about nebulous concepts like\n&gt; &gt; constructive\n&gt; &gt; &gt; signal reinforcement in the brain, that would really make this\n&gt; &gt; easier for me\n&gt; &gt; &gt; too.  Thanks, regards,\n&gt; &gt; &gt;\n&gt; &gt; &gt; jeff\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; SPONSORED LINKS\n&gt; &gt; Computer science distance education \n&gt; &gt;\n&lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+distance+education&w1=Computer+science+distance+education&w2=Computer+science+course&w3=Computer+science+school&w4=Computer+science+and+education&w5=Computer+science+distance+learning&w6=Computer+science&c=6&s=197&.sig=KYPdKysRuHtxvL3yYs0p-A&gt;\n\n&gt; &gt; \tComputer science course \n&gt; &gt;\n&lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+course&w1=Computer+science+distance+education&w2=Computer+science+course&w3=Computer+science+school&w4=Computer+science+and+education&w5=Computer+science+distance+learning&w6=Computer+science&c=6&s=197&.sig=_DCgQaArrnlxKJJMUj8sFw&gt;\n\n&gt; &gt; \tComputer science school \n&gt; &gt;\n&lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+school&w1=Computer+science+distance+education&w2=Computer+science+course&w3=Computer+science+school&w4=Computer+science+and+education&w5=Computer+science+distance+learning&w6=Computer+science&c=6&s=197&.sig=uA3cOaMSAtDgi21ZfTWb8w&gt;\n\n&gt; &gt;\n&gt; &gt; Computer science and education \n&gt; &gt;\n&lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+and+education&w1=Computer+science+distance+education&w2=Computer+science+course&w3=Computer+science+school&w4=Computer+science+and+education&w5=Computer+science+distance+learning&w6=Computer+science&c=6&s=197&.sig=5q8cHbMMHrbdxmhEBkAONw&gt;\n\n&gt; &gt; \tComputer science distance learning \n&gt; &gt;\n&lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+distance+learning&w1=Computer+science+distance+education&w2=Computer+science+course&w3=Computer+science+school&w4=Computer+science+and+education&w5=Computer+science+distance+learning&w6=Computer+science&c=6&s=197&.sig=Seci-ZLfRrxpV8LacuBp1g&gt;\n\n&gt; &gt; \tComputer science \n&gt; &gt;\n&lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science&w1=Computer+science+distance+education&w2=Computer+science+course&w3=Computer+science+school&w4=Computer+science+and+education&w5=Computer+science+distance+learning&w6=Computer+science&c=6&s=197&.sig=QaAXN_pQ85ps2C2dzf4VkQ&gt;\n\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ------------------------------------------------------------------------\n&gt; &gt; YAHOO! GROUPS LINKS\n&gt; &gt;\n&gt; &gt;     *  Visit your group &quot;neat &lt;http://groups.yahoo.com/group/neat&gt;&quot; on\n&gt; &gt;       the web.\n&gt; &gt;        \n&gt; &gt;     *  To unsubscribe from this group, send an email to:\n&gt; &gt;        neat-unsubscribe@yahoogroups.com\n&gt; &gt;       &lt;mailto:neat-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt; &gt;        \n&gt; &gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt; &gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ------------------------------------------------------------------------\n&gt; &gt;\n&gt; \n&gt; ------------------------ Yahoo! Groups Sponsor --------------------~--&gt; \n&gt; Get fast access to your favorite Yahoo! Groups. Make Yahoo! your \n&gt; home page http://us.click.yahoo.com/dpRU5A/wUILAA/yQLSAA/7brrlB/TM\n&gt; --------------------------------------------------------------------~-&gt;\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n-------------------------------------------------------------------------\nwww.greghaynes.com - check out my bro&#39;s stuff and order something! thx.\n\n\n"}}