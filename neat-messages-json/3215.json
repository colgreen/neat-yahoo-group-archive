{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":151231063,"authorName":"Joseph Reisinger","from":"Joseph Reisinger &lt;joeraii@...&gt;","profile":"joeraii","replyTo":"LIST","senderId":"25Y5MBR_Q1l4VE8C-mBbtyHi-1XAWhosuvi1S7Ebfn_BUvd_hReJCgK_rKEMPFRXUX4jwPjkdw3Q584UGb3fssfB6fDOwQQD0z44YvkytQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] A Few Thoughts on HyperNEAT","postDate":"1177887088","msgId":3215,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuNjQuMDcwNDI5MTcxODQ3MC4xODEyNkBjaGllZi13aWdndW0uY3MudXRleGFzLmVkdT4=","inReplyToHeader":"PGYxMzA3OCtsM2I4QGVHcm91cHMuY29tPg==","referencesHeader":"PGYxMzA3OCtsM2I4QGVHcm91cHMuY29tPg=="},"prevInTopic":3214,"nextInTopic":3216,"prevInTime":3214,"nextInTime":3216,"topicId":3214,"numMessagesInTopic":27,"msgSnippet":"... Hi Ken, I d be really careful in how you word this statement. The point you are trying to make, I think, is that for any specific problem you d want to ","rawEmail":"Return-Path: &lt;joeraii@...&gt;\r\nX-Sender: joeraii@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 74345 invoked from network); 29 Apr 2007 22:51:33 -0000\r\nReceived: from unknown (66.218.66.68)\n  by m43.grp.scd.yahoo.com with QMQP; 29 Apr 2007 22:51:33 -0000\r\nReceived: from unknown (HELO smtp.cs.utexas.edu) (128.83.120.210)\n  by mta11.grp.scd.yahoo.com with SMTP; 29 Apr 2007 22:51:33 -0000\r\nReceived: from chief-wiggum.cs.utexas.edu (joeraii@... [128.83.130.114])\n\tby smtp.cs.utexas.edu (8.14.1/8.14.1) with ESMTP id l3TMpSru001121\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)\n\tfor &lt;neat@yahoogroups.com&gt;; Sun, 29 Apr 2007 17:51:28 -0500\r\nReceived: (from joeraii@localhost)\n\tby chief-wiggum.cs.utexas.edu (8.14.1/8.14.1/Submit) id l3TMpSJK018301;\n\tSun, 29 Apr 2007 17:51:28 -0500\r\nDate: Sun, 29 Apr 2007 17:51:28 -0500 (CDT)\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;f13078+l3b8@...&gt;\r\nMessage-ID: &lt;Pine.LNX.4.64.0704291718470.18126@...&gt;\r\nReferences: &lt;f13078+l3b8@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Joseph Reisinger &lt;joeraii@...&gt;\r\nSubject: Re: [neat] A Few Thoughts on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=151231063; y=EqUuJLSjtVeMH4mO-qPuMwVn0dfRUJqUH3DShg9-P8Mr0g\r\nX-Yahoo-Profile: joeraii\r\n\r\n&gt; While it may be viewed as a weakness that the user must decide the\n&gt; node layout, my view is that it is actually quite a bonus, because it\n&gt; means we have an opportuntiy to inject intuitive relationships into\n&gt; the learning process from the get-go.  The most interesting\n&gt; consequence of this ability is that HyperNEAT is not subject to the\n&gt; No Free Lunch theorem when comparing to algorithms that do not allow\n&gt; injecting such a priori knowledge, which justifies the expectation\n&gt; that HyperNEAT actually may be &quot;better&quot; for evolving very-large-scale\n&gt; brains.\n&gt;\n&gt; No Free Lunch is a theorem showing that no single black-box search\n&gt; method can be better than any other when averaged over all possible\n&gt; problems.  However, HyperNEAT escapes this trap because it is no\n&gt; longer a black box algorithm, thanks to the ability to inject a\n&gt; priori relationships at the start.  In many cases this a priori\n&gt; knowledge is very simple to include because it follows directly from\n&gt; the obvious geometry of the task (such as a visual field or game\n&gt; board being Cartesian in an self-evident arrangement).  Yet the\n&gt; significance of such knowledge (as opposed to not having it) is\n&gt; priceless.  So having the capacity to arrange sensors and outputs in\n&gt; the way you want is quite a powerful new capability.\n\nHi Ken,\n\nI&#39;d be really careful in how you word this statement. The point you are \ntrying to make, I think, is that for any specific problem you&#39;d want to \nsolve with HyperNEAT, the experimenter will always inject the \n/appropriate/ prior knowledge for that problem, and thus HyperNEAT will \n/never/ be used in a black-box setting (e.g. in situations where no prior \nknowledge is available). In this case, yes, NFL no longer holds because, \nin a sense, you are not applying the same algorithm to each problem. \nRather, you are peeking at the problem, and then selecting the most \nappropriate settings for HyperNEAT to solve that problem.\n\nSince your argument relies on the use of an &quot;oracle&quot; experimenter to know \nthe correct properties of the problem to use as prior knowledge, I think \nyou are being a little disingenuous. What if the experimenter messes up \nand puts in the wrong prior knowledge? Or, even worse, puts in almost \ncorrect prior knowledge that s/he assumes generalizes from other problems. \nIn this case, without any other limitations placed on the space of \nproblems we may be trying, we are back to NFL land. Based on this I don&#39;t \nthink you are justified in saying HyperNEAT is not a black box algorithm.\n\nFurthermore, I would argue that HyperNEAT&#39;s ability to inject prior \nknowledge is not something special to that algorithm. You can do this in \nNEAT as well, albeit to a less spectacular extent, by manipulating the \ninput coding. The same problem can be made arbitrarily difficult by using \n&quot;dumb&quot; input codings, i.e. input codings that you might use if you didn&#39;t \nhave any prior knowledge of the problem.  Nate has done some interesting \nwork in this area.\n\nIn any case, I do agree with your original point: HyperNEAT probably has a \nbias which makes it better for large scale problems, given the appropriate \nprior knowledge, and NEAT probably has a bias towards simpler problems. I \nwould leave out the appeal to &quot;injecting prior knowledge&quot; and just say: \n&quot;HyperNEAT is expected to perform better on the class of large-scale \nproblems with regular structure.&quot; This statement can be made NFL-proof in \nand of itself, simply by ensuring that that class of problems is not \nclosed-under-permutation, which it probably isn&#39;t: See, for instance, Marc \nToussaint&#39;s work on compressible search landscapes (i.e. problems with \nregular structure) and how the class of such landscapes is not CUP and \nthus NFL does not apply.\n\n\nOk, phew. Let me recap my argument just in case I lost anyone: Ken, I \nthink your intuition here about HyperNEAT is perfectly correct, but your \njustification and statement that HyperNEAT does not fall under the purview \nof NFL is tenuous at best.\n\n\n-- Joe\n\n-- \n\nJoseph Reisinger\nhttp://www.cs.utexas.edu/~joeraii\n\n"}}