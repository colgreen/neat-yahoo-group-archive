{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"cFYHAOQr4k3DvVFsgTvPNfHJd_Zf12McAL_CnDP3vobKYdc9sD5ixhFkqhg7Vi3H9aZzIiMjpCwqbRkVXjzCE5eUNm0cquiRVrDZVpWsoxoL","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: The Next Generation of Neural Networks - Geoff Hinton TechTalk","postDate":"1239574171","msgId":4623,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdydG9xcityMmU5QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDEyODBjZjZhMDkwNDEyMTQ0NHE0OTNjNWY3Mm45NTQyMDFmY2ExYWMyMWZlQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4622,"nextInTopic":4624,"prevInTime":4622,"nextInTime":4624,"topicId":4620,"numMessagesInTopic":8,"msgSnippet":"Thomas, that s an interesting hypothesis that we would have no trouble with arbitrary dot patterns if we had grown up with them.  That hypothesis can t be","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 82423 invoked from network); 12 Apr 2009 22:09:54 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m3.grp.sp2.yahoo.com with QMQP; 12 Apr 2009 22:09:54 -0000\r\nX-Received: from unknown (HELO n13d.bullet.sp1.yahoo.com) (69.147.64.236)\n  by mta2.grp.sp2.yahoo.com with SMTP; 12 Apr 2009 22:09:54 -0000\r\nX-Received: from [69.147.65.148] by n13.bullet.sp1.yahoo.com with NNFMP; 12 Apr 2009 22:09:33 -0000\r\nX-Received: from [98.137.34.184] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 12 Apr 2009 22:09:33 -0000\r\nDate: Sun, 12 Apr 2009 22:09:31 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;grtoqr+r2e9@...&gt;\r\nIn-Reply-To: &lt;1280cf6a0904121444q493c5f72n954201fca1ac21fe@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: The Next Generation of Neural Networks - Geoff Hinton TechTalk\r\nX-Yahoo-Group-Post: member; u=54567749; y=wzqfftCG3MZ05YRgWYsCtBQOy2G08WFOgbh2AZgVDSc_W7P0bGM_\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nThomas, that&#39;s an interesting hypothesis that we would have no trouble with=\r\n arbitrary dot patterns if we had grown up with them.  That hypothesis can&#39;=\r\nt be directly tested since we didn&#39;t grow up that way, but my guess is that=\r\n if characters were just arbitrary disconnected pixel patterns like:\n\n   . =\r\n     .   .. ..     .\n \n   .     .  . .\n   ...           ..  . . .\n         =\r\n  ..      ...\n               .\n     .      .      . .  .\n       . . .   . .=\r\n   \n\n  \nthen life would be much much harder, and perhaps we would never lea=\r\nrn any of them.  Note that no human writing system in the world (including =\r\nbraille http://www.afb.org/braillebug/braille_print.asp) employs arbitrary =\r\nscrambles of dots.  My guess is that there is a reason for that.\n\nAnd we kn=\r\now something about why that is too:  The human visual system is designed as=\r\n a series of ascending topographic maps that preserve adjacency relationshi=\r\nps.  That is, if two photoreceptors (i.e. &quot;pixels&quot;) are adjacent in the eye=\r\n, then the receptive field neurons associated with those locations in the v=\r\nisual cortex are *also* near each other.  Thus the geometry is preserved as=\r\n we move up the processing hierarchy.  That&#39;s why the maps are called &quot;topo=\r\ngraphic.&quot;  This topographic arrangement allows us to exploit geometric rela=\r\ntionships like connectedness as a step in our visual perception.  In fact, =\r\nidentifying contiguous contours is a fundamental step in visual processing.=\r\n  \n\nThese facts are not accidental:  Almost nothing in the natural world is=\r\n an arbitrary scramble of dots.  Thus the visual system would not benefit f=\r\nrom a design that could learn such arbitrary scrambles, since they never co=\r\nme up.  \n\nI am not certain that geometry is inherent in all problems, but I=\r\n would also not assume that it isn&#39;t.  In a time series, time itself can be=\r\n exploited conceptually as a geometric dimension (as it often is when you d=\r\nraw one).  Document classification involves semantics, and semantics are co=\r\nnveniently expressible in terms of &quot;semantic maps.&quot;   For example, &quot;happy&quot; =\r\nis closer to &quot;contented&quot; (geometrically) than it is to &quot;sad.&quot;  In poker, it=\r\n is possible to visualize the state of one&#39;s hand as a configuration in a m=\r\nultidimensional geometric space.   I have had conversations with others in =\r\nthe field in which we tried to think of concepts that are clearly entirely =\r\nnon-geometric, and it&#39;s not as easy as you would think to find something li=\r\nke that.\n\nThe human brain is so topographic, especially in the neocortex (l=\r\naminated, i.e. layered, structures tend to easily preserve topographic rela=\r\ntionships), that it would not surprise me if geometry is the fundamental co=\r\nnceptual building block below almost every concept.  Everything from counti=\r\nng (going up) to who is your boss (also going up) and who is your subordina=\r\nte (going down) has a potential geometric valence.  In fact, anything that =\r\nhas &quot;dimensions&quot; is conceivable as a geometry.  What has no dimensions?\n\nWh=\r\nile I cannot prove that everything requires a geometric perspective, it is =\r\nby no means clear that they do not, or at least that the vast majority of i=\r\nmportant things we learn are heavily dependent on their geometry.  So I&#39;d b=\r\ne a little suspicious of any algorithm that entirely ignores geometry, or i=\r\ns incapable of seeing it.\n\nken\n\n\n\n\n\n--- In neat@yahoogroups.com, Thomas Joh=\r\nnson &lt;thomas.j.johnson@...&gt; wrote:\n&gt;\n&gt; But the only reason they&#39;re now inco=\r\nmprehensible scrambles of dots from a\n&gt; human perspective is because you an=\r\nd I haven&#39;t grown up with the concept of\n&gt; those particular scrambles as re=\r\npresenting particular digits. If we had,\n&gt; then we would probably be as abl=\r\ne to recognize those scrambles as easily as\n&gt; we recognize handwritten numb=\r\ners.\n&gt; \n&gt; Now certainly geometry is important for some (maybe even many) pr=\r\noblems, but\n&gt; it doesn&#39;t lend an advantage to every problem. And for other =\r\nproblems (e.g.,\n&gt; document classification, non-board games like poker, time=\r\n series analysis)\n&gt; it&#39;s not immediately clear how to encode the problem do=\r\nmain in a geometric\n&gt; way, and trying to force the problem domain into a ge=\r\nometric representation\n&gt; may be more work than the return it gives.\n&gt; \n&gt; On=\r\n Sun, Apr 12, 2009 at 4:36 PM, Kenneth Stanley &lt;kstanley@...&gt;wrote:\n&gt; \n&gt; &gt;\n=\r\n&gt; &gt;  As a thought experiment, let&#39;s imagine that we scrambled the order of =\r\nthe\n&gt; &gt; pixel array that represents these characters. For example, we might=\r\n map\n&gt; &gt; pixel (0,0) to (4,2) (arbitrarily). Every other pixel is also mapp=\r\ned to a\n&gt; &gt; unique random location. Then assume that we use this same scram=\r\nbled mapping\n&gt; &gt; on every example, so they are all still consistent. Unreal=\r\nistically,\n&gt; &gt; assuming I understand the model, it will *still* learn the p=\r\natterns just as\n&gt; &gt; effectively as before, irrespective of the fact that th=\r\ney are now completely\n&gt; &gt; incomprehensible scrambles of dots from a human p=\r\nerspective.\n&gt; &gt;\n&gt;\n\n\n\n"}}