{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":200957992,"authorName":"Jason Gauci","from":"&quot;Jason Gauci&quot; &lt;jgmath2000@...&gt;","profile":"jgmath2000","replyTo":"LIST","senderId":"w4r47HpFxCAlryJuMUvVdXZvn-BOj2E5V_XzAhQFW8M7kByUchyVDbpA4gfnIqQoQj3aiG_BM-aiobysGg0_IaC0CGP1l-mi_VW4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"RE : [neat] Re: HyperNEAT Source Code Release","postDate":"1175105270","msgId":3064,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV1ZWF0bStpdTlpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDUzOTMyMy4yNzQ0OC5xbUB3ZWI1NzAwOS5tYWlsLnJlMy55YWhvby5jb20+"},"prevInTopic":3063,"nextInTopic":0,"prevInTime":3063,"nextInTime":3065,"topicId":3057,"numMessagesInTopic":8,"msgSnippet":"... I like the idea of using a pointer swap, but the code you posted looks like it copies the outputs in that for loop at the end.  You could completely","rawEmail":"Return-Path: &lt;jgmath2000@...&gt;\r\nX-Sender: jgmath2000@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 78408 invoked from network); 28 Mar 2007 18:09:40 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m42.grp.scd.yahoo.com with QMQP; 28 Mar 2007 18:09:40 -0000\r\nReceived: from unknown (HELO n17d.bullet.scd.yahoo.com) (66.218.67.56)\n  by mta10.grp.scd.yahoo.com with SMTP; 28 Mar 2007 18:09:40 -0000\r\nReceived: from [66.218.69.6] by n17.bullet.scd.yahoo.com with NNFMP; 28 Mar 2007 18:07:50 -0000\r\nReceived: from [66.218.66.75] by t6.bullet.scd.yahoo.com with NNFMP; 28 Mar 2007 18:07:50 -0000\r\nDate: Wed, 28 Mar 2007 18:07:50 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;eueatm+iu9i@...&gt;\r\nIn-Reply-To: &lt;539323.27448.qm@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Jason Gauci&quot; &lt;jgmath2000@...&gt;\r\nSubject: RE : [neat] Re: HyperNEAT Source Code Release\r\nX-Yahoo-Group-Post: member; u=200957992; y=xbRjU6e4GbMOfLSTu8nuAsmK2uaLNn2tM-sWTjd5CpR55POm3A\r\nX-Yahoo-Profile: jgmath2000\r\n\r\n--- In neat@yahoogroups.com, Alexandre Devert &lt;marmakoide@...&gt; wrote:\n&gt;\n&gt; H=\r\ni\n&gt; \n&gt; I have my tricks too to make fast neural networks :\n&gt; * All the conn=\r\nection weights on a flat array\n&gt; * The neural network graph is flaten in an=\r\n array of\n&gt; indexes. \n&gt; * To switch from previous to current state neurons,=\r\n I\n&gt; use an array of size 2N, where N is the number of\n&gt; neurons. A simple =\r\npointer swap, even faster than a\n&gt; memcpy ;)\n&gt; \n&gt; This way, I have no condi=\r\ntional in my update loop, and\n&gt; I limit the memory cache breaks to the mini=\r\nmum. Here\n&gt; it is my inner loop, to get an idea. \n&gt; \n&gt; --------------------=\r\n----------------------------------\n&gt; void\n&gt; Net::update(State& inState, IO&=\r\n inIO) const {\n&gt;   swap(inState.mPreviousActivity,\n&gt; inState.mCurrentActivi=\r\nty);\n&gt; \n&gt;   const double* lWeight =3D mWeightsTab;\n&gt;   double* lActivity =\r\n=3D inState.mCurrentActivity;\n&gt;   const size_t* lIndex =3D mDriveTab;\n&gt; \n&gt; =\r\n  // For each neuron\n&gt;   for(size_t i =3D mNbNeurons; i !=3D 0; --i) {\n&gt;   =\r\n  double lSum =3D 0.0f;\n&gt; \n&gt;     // Sum of the incoming neurons activations=\r\n\n&gt;     for(size_t j =3D (*lIndex++); j !=3D 0; --j)\n&gt;       lSum +=3D inSta=\r\nte.mPreviousActivity[(*lIndex++)] *\n&gt; (*lWeight++);\n&gt; \n&gt;     // Sum of the =\r\nincoming inputs\n&gt;     for(size_t j =3D (*lIndex++); j !=3D 0; --j)\n&gt;       =\r\nlSum +=3D (*lWeight++) * inIO.mInputs[*lIndex++];\n&gt; \n&gt;     // Activation of=\r\n the current neuron\n&gt;     (*lActivity++) =3D 1.0 / (1.0 + exp(-lSum));\n&gt;   =\r\n}\n&gt; \n&gt;   // Update the outputs\n&gt;   for(size_t i =3D 0; i !=3D mNbOutputs; +=\r\n+i)\n&gt;     inIO.mOutputs[i] =3D\n&gt; inState.mCurrentActivity[(*lIndex++)];\n&gt; }=\r\n\n&gt; ------------------------------------------------------\n&gt; \n\nI like the id=\r\nea of using a pointer swap, but the code you posted \nlooks like it copies t=\r\nhe outputs in that for loop at the end.  You \ncould completely replace that=\r\n last for loop with something to the \neffect of:\n\nmemcpy(inIO.mOutputs,inSt=\r\nate.mCurrentActivity,sizeof(...)*mNbOutputs)\n\nIt&#39;s not exactly this because=\r\n mCurrentActivity doesn&#39;t start at 0, \nbut you get the idea.\n\n\n"}}