{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":206967455,"authorName":"Julian Togelius","from":"Julian Togelius &lt;julian@...&gt;","profile":"jtogel","replyTo":"LIST","senderId":"gKND7oivm3A26zscscLf5qFMHhPqZu9Jcjx_ejvLTeDqxF1B31r8lwjeyYhd9GrcGeXZbvq1ilPv22FoKnJkQxK4bDMPBOGkD2MPPg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Quantitative vs. Qualitative Results","postDate":"1370164817","msgId":6109,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBSFVvS29wUTVoNTRQd0Y0Q0tuVDNWbndRNVVXLTFKdTg3MHotQlNwQkZBa2tGM3BPZ0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PGtvZGZsaCs5OHA5QGVHcm91cHMuY29tPg==","referencesHeader":"PGtrdjdvMCt0b3RnQGVHcm91cHMuY29tPgk8a29kZmxoKzk4cDlAZUdyb3Vwcy5jb20+"},"prevInTopic":6108,"nextInTopic":6111,"prevInTime":6108,"nextInTime":6110,"topicId":6038,"numMessagesInTopic":46,"msgSnippet":"... Mostly, you are right. But sometimes it s valuable even to show that something is possible - an existence proof . E.g., it could be worth a paper to show","rawEmail":"Return-Path: &lt;julian.togelius@...&gt;\r\nX-Sender: julian.togelius@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 70325 invoked by uid 102); 2 Jun 2013 09:20:18 -0000\r\nX-Received: from unknown (HELO mtaq4.grp.bf1.yahoo.com) (10.193.84.143)\n  by m11.grp.bf1.yahoo.com with SMTP; 2 Jun 2013 09:20:18 -0000\r\nX-Received: (qmail 23320 invoked from network); 2 Jun 2013 09:20:18 -0000\r\nX-Received: from unknown (HELO mail-wi0-f180.google.com) (209.85.212.180)\n  by mtaq4.grp.bf1.yahoo.com with SMTP; 2 Jun 2013 09:20:18 -0000\r\nX-Received: by mail-wi0-f180.google.com with SMTP id hn14so1807059wib.1\n        for &lt;neat@yahoogroups.com&gt;; Sun, 02 Jun 2013 02:20:18 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.194.179.102 with SMTP id df6mr15121245wjc.42.1370164817841;\n Sun, 02 Jun 2013 02:20:17 -0700 (PDT)\r\nX-Received: by 10.180.109.112 with HTTP; Sun, 2 Jun 2013 02:20:17 -0700 (PDT)\r\nIn-Reply-To: &lt;kodflh+98p9@...&gt;\r\nReferences: &lt;kkv7o0+totg@...&gt;\n\t&lt;kodflh+98p9@...&gt;\r\nDate: Sun, 2 Jun 2013 11:20:17 +0200\r\nX-Google-Sender-Auth: 7IiFSLwmWpcpbAHiQBOPN6maFIY\r\nMessage-ID: &lt;CAHUoKopQ5h54PwF4CKnT3VnwQ5UW-1Ju870z-BSpBFAkkF3pOg@...&gt;\r\nTo: neat &lt;neat@yahoogroups.com&gt;\r\nContent-Type: multipart/alternative; boundary=089e01493c3440565804de285b8b\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Julian Togelius &lt;julian@...&gt;\r\nSubject: Re: [neat] Re: Quantitative vs. Qualitative Results\r\nX-Yahoo-Group-Post: member; u=206967455\r\nX-Yahoo-Profile: jtogel\r\n\r\n\r\n--089e01493c3440565804de285b8b\r\nContent-Type: text/plain; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nOn 1 June 2013 20:48, rhiever489 &lt;rhiever@...&gt; wrote:\n\n&gt; **\n&gt;\n&gt;\n&gt; Hi =\r\nKen,\n&gt;\n&gt; The discussion going on in this thread is great. Philosophy of sci=\r\nence is\n&gt; a fun topic to discuss. I would like to reiterate JBM&#39;s statement=\r\ns and\n&gt; respond to some of the points brought up in this thread.\n&gt;\n&gt; ### Wh=\r\nat do we have to prove? ###\n&gt;\n&gt; Ken writes,\n&gt;\n&gt; &gt; Nevertheless, JBM says, &quot;=\r\nI think that it is much harder to write a\n&gt; convincing paper without any qu=\r\nantitative test than with the help of\n&gt; measures/comparisons/etc.&quot; Again, m=\r\nany would share this sentiment. But if\n&gt; you think about it, what exactly d=\r\no we need to be &quot;convinced&quot; of? Why do we\n&gt; think science (or AI especially=\r\n) is about convincing someone of something?\n&gt; Why do we need e.g. 30 strang=\r\ners to validate an intuition we already feel\n&gt; deeply that something is int=\r\neresting? The links in the chain of progress\n&gt; are from inspiration, not fr=\r\nom convincing. There are many ideas that are\n&gt; neither right nor wrong anyw=\r\nay, but worth exploring because they will lead\n&gt; us to new revelations. To =\r\nme, capturing the essence of nature is as much\n&gt; about a feeling as it is a=\r\nbout a result. And my experience in practice\n&gt; bears that out.\n&gt;\n&gt; We don&#39;t=\r\n have to convince others of an idea/finding to continue working on\n&gt; that r=\r\nesearch path ourselves (unless we need funding ;-)), but we *must*\n&gt; convin=\r\nce others of that idea/finding if we want that work published. Even\n&gt; mores=\r\no if we want other people to build off of that idea. Convincing others\n&gt; of=\r\n an idea/finding is core to scientific progress. This is why we have peer\n&gt;=\r\n review for journals, blog posts dedicated to discussing research findings,=\r\n\n&gt; regular seminars at universities, and conferences that are dedicated to\n=\r\n&gt; convincing people of the validity and usefulness of our work.\n&gt;\n&gt; This fa=\r\nct is why we need methods to prove the validity and usefulness of\n&gt; our wor=\r\nk, which I&#39;ll discuss below.\n&gt;\n&gt; ### Quantitative vs. qualitative analyses =\r\n###\n&gt;\n&gt; The reason why qualitative results are often insufficient is becaus=\r\ne we\n&gt; are using evolution as a discovery tool. As we all know, by definiti=\r\non,\n&gt; evolution is a random process. This means that the result of a single=\r\n\n&gt; evolutionary run could be purely due to chance, and have nothing to do w=\r\nith\n&gt; the technique(s) presented in the paper.\n&gt;\n&gt; What if we show qualitat=\r\nive results of multiple evolutionary runs? At that\n&gt; point, if the phenomen=\r\non is truly reproducible across replicate\n&gt; evolutionary runs (w/ different=\r\n seeds), then we already have a simple\n&gt; qualitative metric: How many repli=\r\ncates reproduced the phenomenon. Of\n&gt; course, that is a weak qualitative an=\r\nalysis, but if other measures are\n&gt; lacking, it would still be more informa=\r\ntive than saying, &quot;this technique\n&gt; worked once (here&#39;s a video).&quot;\n&gt;\n&gt; Let&#39;=\r\ns ground this idea with a concrete example. Last year at ALife, one of\n&gt; th=\r\ne presenters in the Artificial Life track presented work where (they\n&gt; open=\r\nly admitted) that the phenomenon only occurred 1 out of 100 replicates.\n&gt; I=\r\nOW, the researcher had N=3D1. They went on to talk about how the environmen=\r\nt\n&gt; shaped the observed phenomenon in that single replicate. Would this eve=\r\nr\n&gt; pass in any other field? Would *you* believe that the environment had a=\r\nny\n&gt; effect with N=3D1? Effectively, that is what showing a qualitative res=\r\nult is.\n&gt;\n&gt; In science, it is vital to show that our results are reproducib=\r\nle and\n&gt; measurable. Thus, by that very nature, we must provide a quantitat=\r\nive\n&gt; analysis of our results. However, in my (and many others&#39;) view, I do=\r\n not\n&gt; think that how the results are presented is the core problem. Rather=\r\n, the\n&gt; problem lies in how the experiments are designed and the hypotheses=\r\n\n&gt; addressed (or lack thereof).\n&gt;\n&gt;\nMostly, you are right. But sometimes it=\r\n&#39;s valuable even to show that\nsomething is possible - an &quot;existence proof&quot;.=\r\n E.g., it could be worth a\npaper to show that a particular paper could be r=\r\nepresented by a neural\nnetwork. The paper could then describe the behaviour=\r\n, the structure of the\nnetwork and (for completeness) the evolutionary meth=\r\nod used to create the\nnetwork that displays this behaviour. Additional runs=\r\n to verify that it can\nbe done again might not actually add much to the pap=\r\ner, because that&#39;s not\nwhat the paper is about. (They might also not be att=\r\nempted by the author\nbecause of the time it takes to run the experiment aga=\r\nin, and an impending\ndeadline.)\n\nIn general, I believe that there are many =\r\npossible ways of doing good\nresearch. The big problem with some papers is n=\r\not that they don&#39;t follow\nsome particular research methodology, rather that=\r\n they are not clear about\nwhat they are seeking to show.\n\n\n&gt; ### Hypothesis=\r\n testing ###\n&gt;\n&gt; This is an argument that was huge in the biology community=\r\n some 50 years\n&gt; ago. I refer to, e.g., &quot;Strong Inference&quot; by J Platt (1964=\r\n). What is the\n&gt; best (or, most expedient) way to do science? Platt&#39;s paper=\r\n has some great\n&gt; quotes, and he eloquently touches on some relevant subjec=\r\nts for the very\n&gt; conversation we are having here.\n&gt;\n&gt; First, let&#39;s touch o=\r\nn the culture of method development. Too much research\n&gt; focuses on method =\r\ndevelopment rather than testing a hypothesis that\n&gt; actually advances the f=\r\nield. I&#39;ve read too many papers that say, &quot;we\n&gt; hypothesize that our method=\r\n will work in task A.&quot; That&#39;s technically a\n&gt; testable hypothesis, but what=\r\n does testing that hypothesis really tell us?\n&gt; Has anyone outside of your =\r\nwork group actually wondered about that\n&gt; question? Testing that hypothesis=\r\n just shows that our method works on task\n&gt; A, but like JBM said, the field=\r\n as a whole doesn&#39;t actually learn much from\n&gt; it.\n&gt;\n&gt; Instead of showing t=\r\nhat our method works on task A, we can address broader\n&gt; hypotheses with th=\r\ne method. What is it about our method that allows it to\n&gt; work on task A? F=\r\nor example, what fundamental body plan does a robot need\n&gt; for an evolved A=\r\nNN to control it? [&quot;Morphological change in machines\n&gt; accelerates the evol=\r\nution of robust behavior&quot;, Bongard (2011)] Or, how does\n&gt; using a generativ=\r\ne encoding vs. a direct encoding affect mutation effect\n&gt; size? [&quot;Evolving =\r\nCoordinated Quadruped Gaits with the HyperNEAT Generative\n&gt; Encoding&quot;, Clun=\r\ne et al. (2009)] These papers demonstrated new methods while\n&gt; also answeri=\r\nng questions that are broadly interesting beyond that method.\n&gt; Method deve=\r\nlopment should occur *alongside* the science, but it should not\n&gt; be the fo=\r\ncus of the science itself.\n&gt;\n&gt; What&#39;s worse, this culture of method develop=\r\nment has led to a culture of\n&gt; method comparison, e.g., &quot;our method outperf=\r\norms method X on benchmark A.&quot;\n&gt; In this kind of work, method development r=\r\neally is the focus of the\n&gt; research. As Ken attests, after spending months=\r\n reading this kind of\n&gt; literature, it leaves you knowing little more than =\r\n&quot;method X is better than\n&gt; method Y on tasks A, B, and C.&quot; This kind of wor=\r\nk has no lasting effect\n&gt; because the hypotheses it addresses are weak.\n&gt;\n&gt;=\r\n As such, the field would benefit from researchers focusing more on what\n&gt; =\r\nbroader hypotheses they want to address with their work, rather than what\n&gt;=\r\n method will produce a phenomenon. What broadly interesting questions can w=\r\ne\n&gt; answer with our method?\n&gt;\n\nAgain, I agree to some extent. But you take =\r\nfor granted that what we are\ndoing here is science. Much of what gets publi=\r\nshed in Gecco, CEC, TEC etc\nis not really science but rather engineering re=\r\nsearch, which can be good or\nbad. I think that comparing methods on some pa=\r\nrticular benchmark can be\nvery valuable, but of course it helps if the benc=\r\nhmark is relevant.\n\nJulian\n\n--- In neat@yahoogroups.com, &quot;Ken&quot; &lt;kstanley@..=\r\n.&gt; wrote:\n&gt;\n&gt;\n&gt;\n&gt; Hi JBM, thanks for getting deeper into this fascinating i=\r\nssue of how we\ncan be confident that a paper has strong results. I hope you=\r\n don&#39;t mind\nthat I changed the subject line to make this thread easier to f=\r\nind in the\nfuture.\n&gt;\n&gt; I think we all broadly agree that there is no single=\r\n formula for a good\npaper and you and Jeff are arguing more about matters o=\r\nf degree. I am very\ninterested in this subject as you know and I think it m=\r\nerits a lot more\nattention than it usually gets, which is one reason I&#39;m gl=\r\nad you got deeper\ninto it. So here I want to add some more weight to the ca=\r\nse for qualitative\npapers. I should warn everyone up front that I took this=\r\n opportunity\nbasically to write an essay, so this is a long post full of my=\r\n thoughts on\nthis issue.\n&gt;\n&gt; I believe most people in our field would agree=\r\n with JBM&#39;s assertion that\nthere is &quot;a strong correlation between weak pape=\r\nrs and papers without\nstrong quantitative results.&quot;\n&gt;\n&gt; I want to question =\r\nthat assumption because I do not believe it is true\neven though it is widel=\r\ny assumed to be true and in fact is perhaps the\nengine behind the entire re=\r\nviewing philosophy in AI. In fact, this issue of\nhow science should progres=\r\ns is ultimately not a scientific issue but a\nphilosophical issue. That is, =\r\nwhen you begin to discuss which kinds of\nresults are most useful for future=\r\n progress, it is a meta-discussion about\nhow science progresses. Paul Feyer=\r\nabend, who was a kind of radical\nphilosopher of science, has a really nice =\r\nquote on this issue that I find\ninspirational:\n&gt;\n&gt; &quot;To those who look at th=\r\ne rich material provided by history, and who are\nnot intent on impoverishin=\r\ng it in order to please their lower instincts,\ntheir craving for intellectu=\r\nal security in the form of clarity, precision,\n&#39;objectivity&#39;, &#39;truth&#39;, it w=\r\nill become clear that there is only one\nprinciple that can be defended unde=\r\nr all circumstances and in all stages of\nhuman development. It is the princ=\r\niple: anything goes.&quot;\n&gt; Against Method: Outline of an Anarchistic Theory of=\r\n Knowledge (1975)\n&gt;\n&gt; My personal experience fits very well with this idea.=\r\n There will be times\nin history where quantification is what we need, and o=\r\nther times when it is\nthe last thing we need. And I believe the worship of =\r\nquantification has\nrecently, at this point in the history of our field, bee=\r\nn mostly an\nobstacle to progress put in place by those &quot;craving for intelle=\r\nctual\nsecurity,&quot; as Feyerabend puts it. But insecurity is not a good founda=\r\ntion\nfor the building of wisdom because exploration requires courage and a\n=\r\nwillingness to confront ambiguity. Quantification at this time in AI is\nlar=\r\ngely an attempt to escape from ambiguity, and thereby becomes a form of\ndec=\r\neption.\n&gt;\n&gt; Consider what I have called the &quot;objective paradox&quot;: often if y=\r\nou measure\nthe ability of a method or encoding in EC to achieve a specific =\r\nobjective,\nyour conclusions about what that method can achieve in general w=\r\nill be\nentirely skewed and misleading. Target-based benchmarks, rather than=\r\n giving\nconfidence, are causing us to miss the forest for the trees. Think =\r\nhow in\nmy paper with Brian Woolley (\nhttp://eplex.cs.ucf.edu/publications/2=\r\n011/woolley-gecco11) we could not\nre-evolve many images on Picbreeder with =\r\nNEAT and CPPNs (which are the very\nmethods behind Picbreeder). So in the qu=\r\nantitative world we would conclude\nthat CPPNs cannot evolve such images. An=\r\nd in fact results of this sort\n(showing method X cannot solve problem A) ar=\r\ne published all the time, and\nalmost entirely misleading.\n&gt;\n&gt; They are also=\r\n the basis of highly deceptive comparisons between method X\nand Y. We like =\r\nto say if method X &quot;performs significantly better&quot; than\nmethod Y on task A =\r\nthen method X is somehow &quot;better.&quot; But the truth is that\noften the ability =\r\nof an encoding to evolve to a specific target is a bad\nsign for its ability=\r\n to ever produce anything interesting. Think about\ndirect encodings: they w=\r\nill always win on low-dimensional target-matching\nproblems but are a dead e=\r\nnd for evolving anything truly complex. We are\nfooling ourselves with quant=\r\nification.\n&gt;\n&gt; Even people who are aware of Woolley&#39;s result and agree with=\r\n our\nconclusions *still* publish this kind of result because our culture is=\r\n so\ndeeply entrenched in this kind of quantification that we simply have no=\r\n\nidea what else to do. If we were willing to truly embrace the absurdity of=\r\n\nthis kind of analysis, someone would have the courage to proclaim that DNA=\r\n\nis incapable of evolving humans (which were of course never set as the\nobj=\r\nective of evolution). After all, if humans were set as objective targets\nfo=\r\nr evolution from the start, there would be no humans.\n&gt;\n&gt; How many of us ha=\r\nve tried to test method X on objective A and found\nmethod X wanting and the=\r\nn published the result? And how many such papers\nwould you consider &quot;strong=\r\n?&quot; Our culture of worshipping quantification has\noften led us astray on the=\r\n real power of evolution and the potential of\ndifferent encodings. If intui=\r\ntion trumped quantification (a heretical\nsuggestion) this fundamental confu=\r\nsion would not have arisen so severely.\n&gt;\n&gt; Now I want to look at this issu=\r\ne from the opposite direction, where my\nown experience has been much more p=\r\nositive: how qualitative observations\noften lead to unexpected leaps of ins=\r\night in a way quantitative results\nrarely have for me. In fact, almost ever=\r\ny idea in which I have been\ninvolved is the result of a qualitative observa=\r\ntion, exactly the kind that\nworshipers of quantification seem to want to pr=\r\nevent us from publishing and\nsharing with each other.\n&gt;\n&gt; For example, befo=\r\nre I thought of NEAT I read dozens of neuroevolution\npapers (this was in th=\r\ne Fall of 1999). There were tons of quantitative\nresults and comparisons, b=\r\nut at the end of four months of reading all this\nliterature, I did not reme=\r\nmber any of the quantitative results. Instead,\nwhat was left with me was a =\r\n&quot;feeling&quot; that something qualitative was\nmissing: Regardless of performance=\r\n, none of these methods had the feel of\nnature when it came to the tendency=\r\n for complexity to increase elegantly\nand indefinitely. And that is where t=\r\nhe inspiration for NEAT began, by\nignoring quantitative results. If I had f=\r\nollowed them, I would simply have\nbuilt upon the &quot;best&quot; neuroevolution meth=\r\nod of the time, which had been my\noriginal plan, having been brought up too=\r\n in the culture of quantification.\nSo then there would be no NEAT.\n&gt;\n&gt; My i=\r\ndea for CPPNs was also from an entirely qualitative observation. It\nactuall=\r\ny came before Picbreeder. The main insight was actually from\nevolving a spa=\r\nceship image in Mattias Fagerlund&#39;s old NEAT-based Genetic\nArt program. The=\r\n experience of evolving the spaceship was so exciting to me\nat the time tha=\r\nt I put up a whole website on it:\nhttp://www.cs.utexas.edu/users/kstanley/r=\r\nocket.html\n&gt;\n&gt; There was not a single quantitative result, but I was convin=\r\nced that I\nhad seen something, qualitatively, that resonated with nature. I=\r\nt was that\nqualitative feeling, that recognition of something deep in the r=\r\nesults,\nthat led to CPPNs. It was a couple years later that the whole theor=\r\ny\nsolidified and I wrote the journal article on CPPNS:\nhttp://eplex.cs.ucf.=\r\nedu/publications/2007/stanley-gpem07\n&gt;\n&gt; One interesting thing about that C=\r\nPPN journal article is that it is\nalmost entirely qualitative. As you can i=\r\nmagine, that posed problems for\nreview, but I was determined not to pollute=\r\n it with meaningless\nquantification. For me, the images speak for themselve=\r\ns.\n&gt;\n&gt; Those observations on CPPNs and their resulting symmetries and\nregul=\r\narities are also what led to David D&#39;Ambrosio, Jason Gauci and myself\ncreat=\r\ning HyperNEAT - again, the inspiration for the idea was not any\nquantitativ=\r\ne demonstration of anything.\n&gt;\n&gt; And finally, as some of you know, novelty =\r\nsearch itself was not inspired\nby a quantitative result. Rather, it comes *=\r\nagain* from evolving pictures -\nin this case it was my experience of evolvi=\r\nng the Picbreeder Car:\npicbreeder.org/search/showgenome.php?sid=3D464\n&gt; Wha=\r\nt shocked me from the experience of evolving the car was that I had\nnot bee=\r\nn trying to evolve a car. I could not stop thinking about that,\nabout how I=\r\n did something really hard (from a qualitative perspective) by\nnot trying t=\r\no do it. I later noticed that almost every interesting image on\nthe site ha=\r\ns the same strange story. I discussed the implications of these\nobservation=\r\ns with Joel Lehman, which led us both to novelty search.\n&gt;\n&gt; Now someone co=\r\nuld argue that these ideas may all turn out &quot;weak&quot; in the\nend. But that wou=\r\nld be a strange philosophy of science; it would suggest\nthat we should neve=\r\nr have explored down these roads in the first place. Of\ncourse we cannot kn=\r\now where any road leads until we take it - and I think\nat least it&#39;s clear =\r\nthese were roads worth exploring though no one can say\nthey lead ultimately=\r\n to the greatest truths. But it&#39;s still worth the\nlessons along the way.\n&gt;\n=\r\n&gt; Someone might also think, okay, your inspirations may have been\nqualitati=\r\nve but your *results* were mainly quantitative, and somehow that&#39;s\nwhat mat=\r\nters (though recall the CPPN paper does not have quantitative\nresults). As =\r\nJBM points out, our novelty search paper did have quantitative\nresults that=\r\n ultimately convinced him something interesting was going on.\nBut I think a=\r\ngain the focus here on &quot;results&quot; misses the forest for the\ntrees. What is m=\r\nore important for the progress of science than the results\nis the *inspirat=\r\nion* that leads to the ideas that produced the results. If\nthe inspiration =\r\nis withheld, if I cannot share with you the analogue of the\nspaceship or th=\r\ne car in the future, then you can never draw from those\ninspirations to fin=\r\nd new roads for us to travel. The kind of science that I\nbelieve JBM and ma=\r\nny others idealize cuts out all the inspiration from the\npublic sphere and =\r\nleaves us only to share its fruits when someone is lucky\nenough in private =\r\nto see something interesting (and try to quantify it\nthen).\n&gt;\n&gt; Nevertheles=\r\ns, JBM says, &quot;I think that it is much harder to write a\nconvincing paper wi=\r\nthout any quantitative test than with the help of\nmeasures/comparisons/etc.=\r\n&quot; Again, many would share this sentiment. But if\nyou think about it, what e=\r\nxactly do we need to be &quot;convinced&quot; of? Why do we\nthink science (or AI espe=\r\ncially) is about convincing someone of something?\nWhy do we need e.g. 30 st=\r\nrangers to validate an intuition we already feel\ndeeply that something is i=\r\nnteresting? The links in the chain of progress\nare from inspiration, not fr=\r\nom convincing. There are many ideas that are\nneither right nor wrong anyway=\r\n, but worth exploring because they will lead\nus to new revelations. To me, =\r\ncapturing the essence of nature is as much\nabout a feeling as it is about a=\r\n result. And my experience in practice\nbears that out.\n&gt;\n&gt; Here is where I =\r\nwant to return to the intellectual insecurity that\nFeyerabend raises. I thi=\r\nnk our quantitative culture all boils down to this\nproblem of insecurity. W=\r\ne do not trust ourselves to have valid intuitions.\nWe dismiss our own abili=\r\nty to think, as with JBM&#39;s tongue-in-cheeck parody,\n&quot;look, cool simulated r=\r\nobots.&quot; But I want to question why we are so\ninsecure in our own qualitativ=\r\ne judgments?\n&gt;\n&gt; For those of us with PhDs, our countries invested somethin=\r\ng like 25 years\ninto our education. Shouldn&#39;t someone who supposedly succee=\r\nded in jumping\nthrough intellectual hoop after hoop after hoop - eventually=\r\n impressing\ntheir peers enough to be hired, even eventually to be tenured o=\r\nr promoted -\nbe able to think for themselves sufficiently to decide whether=\r\n the &quot;cool\nrobots&quot; are worth sharing with other scientists because they mig=\r\nht inspire\nnew ideas? If we are really entirely unqualified after all those=\r\n years of\nsupposedly learning to be a scientist, then what was the use of a=\r\nll that\npublic investment? Was it simply to validate that we are able to ch=\r\neck\np-values that someone else reports in an X vs. Y quantitative compariso=\r\nn?\nThat&#39;s all we&#39;re qualified to do? Why do we deny our intellectual curios=\r\nity\nand ability to think for ourselves?\n&gt;\n&gt; You may think it can&#39;t be done.=\r\n Maybe you think my personal experience\nwith NEAT, CPPNs, HyperNEAT, novelt=\r\ny search, etc. is some kind of fluke\nthat doesn&#39;t really represent science =\r\nand how it works. Maybe you think\nthat kind of qualitative approach may wor=\r\nk for Ken for some reason but it\ncan&#39;t work in general. But why would that =\r\nbe? Isn&#39;t it possible that we are\nall prematurely discrediting our intellec=\r\ntual potential to think for\nourselves? We have created a culture in which t=\r\nhe spaceships and cars of\nscience must be hidden, buried until their discov=\r\nerers figure out (or give\nup figuring out) their deeper implications. I do =\r\nnot support publishing a\npaper simply because of some &quot;cool robots,&quot; but I =\r\ndo support qualified\nscientists deciding for themselves, from their experie=\r\nnce and intuitions,\nwhether those cool robots might be the seed of an impor=\r\ntant chain of ideas.\nAnd I do not want those cool robots hidden from me as =\r\na reader of\nscientific literature if they might be such a seed. When I look=\r\ned at Jeff&#39;s\nrecent video of his cool robots, I could feel those wheels of =\r\nintuition\nturning in my mind. I still don&#39;t know if it leads to anything, b=\r\nut I don&#39;t\nneed any quantification to know that that feeling is more than e=\r\nnough to\njustify publishing that paper, and I&#39;m grateful he and his coautho=\r\nrs did\nnot try to obfuscate it with a veil of needless quantification.\n&gt;\n&gt; =\r\nBest,\n&gt;\n&gt; ken\n\n \n&gt;\n\n\n\n-- \nJulian Togelius\nAssociate Professor\nIT University=\r\n of Copenhagen\nRued Langgaards Vej 7, 2300 Copenhagen, Denmark\nmail: julian=\r\n@..., web: http://julian.togelius.com\nmobile: +46-705-192088, offi=\r\nce: +45-7218-5277\n\r\n--089e01493c3440565804de285b8b\r\nContent-Type: text/html; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail=\r\n_quote&quot;&gt;On 1 June 2013 20:48, rhiever489 &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;m=\r\nailto:rhiever@...&quot; target=3D&quot;_blank&quot;&gt;rhiever@...&lt;/a&gt;&gt;&lt;/span&gt;=\r\n wrote:&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0px 0=\r\n.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex&quot;&gt;\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n=\r\n\n\n\n\n\n\n\n\n&lt;div style&gt;\n&lt;span&gt;=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n    &lt;div&gt;\n      \n   =\r\n   \n      &lt;p&gt;Hi Ken,&lt;br&gt;\n&lt;br&gt;\nThe discussion going on in this thread is gre=\r\nat. Philosophy of science is a fun topic to discuss. I would like to reiter=\r\nate JBM&#39;s statements and respond to some of the points brought up in th=\r\nis thread.&lt;br&gt;\n&lt;br&gt;\n### What do we have to prove? ###&lt;br&gt;\n&lt;br&gt;\nKen writes,&lt;=\r\n/p&gt;&lt;div class=3D&quot;im&quot;&gt;&lt;br&gt;\n&gt; Nevertheless, JBM says, &quot;I think that i=\r\nt is much harder to write a convincing paper without any quantitative test =\r\nthan with the help of measures/comparisons/etc.&quot;  Again, many would sh=\r\nare this sentiment.  But if you think about it, what exactly do we need to =\r\nbe &quot;convinced&quot; of?  Why do we think science (or AI especially) is=\r\n about convincing someone of something?  Why do we need e.g. 30 strangers t=\r\no validate an intuition we already feel deeply that something is interestin=\r\ng?  The links in the chain of progress are from inspiration, not from convi=\r\nncing.  There are many ideas that are neither right nor wrong anyway, but w=\r\north exploring because they will lead us to new revelations.  To me, captur=\r\ning the essence of nature is as much about a feeling as it is about a resul=\r\nt.  And my experience in practice bears that out.&lt;br&gt;\n\n&lt;br&gt;&lt;/div&gt;\nWe don&#3=\r\n9;t have to convince others of an idea/finding to continue working on that =\r\nresearch path ourselves (unless we need funding ;-)), but we *must* convinc=\r\ne others of that idea/finding if we want that work published. Even moreso i=\r\nf we want other people to build off of that idea. Convincing others of an i=\r\ndea/finding is core to scientific progress. This is why we have peer review=\r\n for journals, blog posts dedicated to discussing research findings, regula=\r\nr seminars at universities, and conferences that are dedicated to convincin=\r\ng people of the validity and usefulness of our work.&lt;br&gt;\n\n&lt;br&gt;\nThis fact is=\r\n why we need methods to prove the validity and usefulness of our work, whic=\r\nh I&#39;ll discuss below.&lt;br&gt;\n&lt;br&gt;\n### Quantitative vs. qualitative analyse=\r\ns ###&lt;br&gt;\n&lt;br&gt;\nThe reason why qualitative results are often insufficient is=\r\n because we are using evolution as a discovery tool. As we all know, by def=\r\ninition, evolution is a random process. This means that the result of a sin=\r\ngle evolutionary run could be purely due to chance, and have nothing to do =\r\nwith the technique(s) presented in the paper.&lt;br&gt;\n\n&lt;br&gt;\nWhat if we show qua=\r\nlitative results of multiple evolutionary runs? At that point, if the pheno=\r\nmenon is truly reproducible across replicate evolutionary runs (w/ differen=\r\nt seeds), then we already have a simple qualitative metric: How many replic=\r\nates reproduced the phenomenon. Of course, that is a weak qualitative analy=\r\nsis, but if other measures are lacking, it would still be more informative =\r\nthan saying, &quot;this technique worked once (here&#39;s a video).&quot;&lt;b=\r\nr&gt;\n\n&lt;br&gt;\nLet&#39;s ground this idea with a concrete example. Last year at A=\r\nLife, one of the presenters in the Artificial Life track presented work whe=\r\nre (they openly admitted) that the phenomenon only occurred 1 out of 100 re=\r\nplicates. IOW, the researcher had N=3D1. They went on to talk about how the=\r\n environment shaped the observed phenomenon in that single replicate. Would=\r\n this ever pass in any other field? Would *you* believe that the environmen=\r\nt had any effect with N=3D1? Effectively, that is what showing a qualitativ=\r\ne result is.&lt;br&gt;\n\n&lt;br&gt;\nIn science, it is vital to show that our results are=\r\n reproducible and measurable. Thus, by that very nature, we must provide a =\r\nquantitative analysis of our results. However, in my (and many others&#39;)=\r\n view, I do not think that how the results are presented is the core proble=\r\nm. Rather, the problem lies in how the experiments are designed and the hyp=\r\notheses addressed (or lack thereof).&lt;br&gt;\n\n&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blo=\r\nckquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Mostly, you are right. But sometimes it&#39;s v=\r\naluable even to show that something is possible - an &quot;existence proof&=\r\nquot;. E.g., it could be worth a paper to show that a particular paper coul=\r\nd be represented by a neural network. The paper could then describe the beh=\r\naviour, the structure of the network and (for completeness) the evolutionar=\r\ny method used to create the network that displays this behaviour. Additiona=\r\nl runs to verify that it can be done again might not actually add much to t=\r\nhe paper, because that&#39;s not what the paper is about. (They might also =\r\nnot be attempted by the author because of the time it takes to run the expe=\r\nriment again, and an impending deadline.)&lt;br&gt;\n&lt;br&gt;In general, I believe tha=\r\nt there are many possible ways of doing good research. The big problem with=\r\n some papers is not that they don&#39;t follow some particular research met=\r\nhodology, rather that they are not clear about what they are seeking to sho=\r\nw.&lt;br&gt;\n=A0&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0=\r\npx 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex&quot;&gt;&lt;div styl=\r\ne&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;\n### Hypothesis testing ###&lt;br&gt;\n&lt;br&gt;\nThis is an argument t=\r\nhat was huge in the biology community some 50 years ago. I refer to, e.g., =\r\n&quot;Strong Inference&quot; by J Platt (1964). What is the best (or, most =\r\nexpedient) way to do science? Platt&#39;s paper has some great quotes, and =\r\nhe eloquently touches on some relevant subjects for the very conversation w=\r\ne are having here.&lt;br&gt;\n\n&lt;br&gt;\nFirst, let&#39;s touch on the culture of metho=\r\nd development. Too much research focuses on method development rather than =\r\ntesting a hypothesis that actually advances the field. I&#39;ve read too ma=\r\nny papers that say, &quot;we hypothesize that our method will work in task =\r\nA.&quot; That&#39;s technically a testable hypothesis, but what does testin=\r\ng that hypothesis really tell us? Has anyone outside of your work group act=\r\nually wondered about that question? Testing that hypothesis just shows that=\r\n our method works on task A, but like JBM said, the field as a whole doesn&=\r\n#39;t actually learn much from it.&lt;br&gt;\n\n&lt;br&gt;\nInstead of showing that our me=\r\nthod works on task A, we can address broader hypotheses with the method. Wh=\r\nat is it about our method that allows it to work on task A? For example, wh=\r\nat fundamental body plan does a robot need for an evolved ANN to control it=\r\n? [&quot;Morphological change in machines accelerates the evolution of robu=\r\nst behavior&quot;, Bongard (2011)] Or, how does using a generative encoding=\r\n vs. a direct encoding affect mutation effect size? [&quot;Evolving Coordin=\r\nated Quadruped Gaits with the HyperNEAT Generative Encoding&quot;, Clune et=\r\n al. (2009)] These papers demonstrated new methods while also answering que=\r\nstions that are broadly interesting beyond that method. Method development =\r\nshould occur *alongside* the science, but it should not be the focus of the=\r\n science itself.&lt;br&gt;\n\n&lt;br&gt;\nWhat&#39;s worse, this culture of method develop=\r\nment has led to a culture of method comparison, e.g., &quot;our method outp=\r\nerforms method X on benchmark A.&quot; In this kind of work, method develop=\r\nment really is the focus of the research. As Ken attests, after spending mo=\r\nnths reading this kind of literature, it leaves you knowing little more tha=\r\nn &quot;method X is better than method Y on tasks A, B, and C.&quot; This k=\r\nind of work has no lasting effect because the hypotheses it addresses are w=\r\neak.&lt;br&gt;\n\n&lt;br&gt;\nAs such, the field would benefit from researchers focusing m=\r\nore on what broader hypotheses they want to address with their work, rather=\r\n than what method will produce a phenomenon. What broadly interesting quest=\r\nions can we answer with our method?&lt;br&gt;\n&lt;div&gt;&lt;div class=3D&quot;h5&quot;&gt;&lt;/div&gt;&lt;/div&gt;=\r\n&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;h5&quot;&gt;Again=\r\n, I agree to some extent. But you take for granted that what we are doing h=\r\nere is science. Much of what gets published in Gecco, CEC, TEC etc is not r=\r\neally science but rather engineering research, which can be good or bad. I =\r\nthink that comparing methods on some particular benchmark can be very valua=\r\nble, but of course it helps if the benchmark is relevant.&lt;br&gt;\n&lt;br&gt;Julian&lt;br=\r\n&gt;&lt;br&gt;\n--- In &lt;a href=3D&quot;mailto:neat%40yahoogroups.com&quot; target=3D&quot;_blank&quot;&gt;ne=\r\nat@yahoogroups.com&lt;/a&gt;, &quot;Ken&quot; &lt;kstanley@...&gt; wrote:&lt;br&gt;\n&gt=\r\n;&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Hi JBM, thanks for getting deeper into this =\r\nfascinating issue of how we can be confident that a paper has strong result=\r\ns.  I hope you don&#39;t mind that I changed the subject line to make this =\r\nthread easier to find in the future.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; I think we all bro=\r\nadly agree that there is no single formula for a good paper and you and Jef=\r\nf are arguing more about matters of degree.  I am very interested in this s=\r\nubject as you know and I think it merits a lot more attention than it usual=\r\nly gets, which is one reason I&#39;m glad you got deeper into it.  So here =\r\nI want to add some more weight to the case for qualitative papers.  I shoul=\r\nd warn everyone up front that I took this opportunity basically to write an=\r\n essay, so this is a long post full of my thoughts on this issue.&lt;br&gt;\n\n&gt;=\r\n &lt;br&gt;\n&gt; I believe most people in our field would agree with JBM&#39;s as=\r\nsertion that there is &quot;a strong correlation between weak papers and pa=\r\npers without strong quantitative results.&quot;&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; I want t=\r\no question that assumption because I do not believe it is true even though =\r\nit is widely assumed to be true and in fact is perhaps the engine behind th=\r\ne entire reviewing philosophy in AI.  In fact, this issue of how science sh=\r\nould progress is ultimately not a scientific issue but a philosophical issu=\r\ne.  That is, when you begin to discuss which kinds of results are most usef=\r\nul for future progress, it is a meta-discussion about how science progresse=\r\ns.  Paul Feyerabend, who was a kind of radical philosopher of science, has =\r\na really nice quote on this issue that I find inspirational: &lt;br&gt;\n\n&gt; &lt;br=\r\n&gt;\n&gt; &quot;To those who look at the rich material provided by history, an=\r\nd who are not intent on impoverishing it in order to please their lower ins=\r\ntincts, their craving for intellectual security in the form of clarity, pre=\r\ncision, &#39;objectivity&#39;, &#39;truth&#39;, it will become clear that t=\r\nhere is only one principle that can be defended under all circumstances and=\r\n in all stages of human development. It is the principle: anything goes.&qu=\r\not; &lt;br&gt;\n\n&gt; Against Method: Outline of an Anarchistic Theory of Knowledg=\r\ne (1975)&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; My personal experience fits very well with this=\r\n idea.  There will be times in history where quantification is what we need=\r\n, and other times when it is the last thing we need.  And I believe the wor=\r\nship of quantification has recently, at this point in the history of our fi=\r\neld, been mostly an obstacle to progress put in place by those &quot;cravin=\r\ng for intellectual security,&quot; as Feyerabend puts it.  But insecurity i=\r\ns not a good foundation for the building of wisdom because exploration requ=\r\nires courage and a willingness to confront ambiguity.  Quantification at th=\r\nis time in AI is largely an attempt to escape from ambiguity, and thereby b=\r\necomes a form of deception.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Consider what I have called=\r\n the &quot;objective paradox&quot;: often if you measure the ability of a m=\r\nethod or encoding in EC to achieve a specific objective, your conclusions a=\r\nbout what that method can achieve in general will be entirely skewed and mi=\r\nsleading.  Target-based benchmarks, rather than giving confidence, are caus=\r\ning us to miss the forest for the trees.  Think how in my paper with Brian =\r\nWoolley (&lt;a href=3D&quot;http://eplex.cs.ucf.edu/publications/2011/woolley-gecco=\r\n11&quot; target=3D&quot;_blank&quot;&gt;http://eplex.cs.ucf.edu/publications/2011/woolley-gec=\r\nco11&lt;/a&gt;) we could not re-evolve many images on Picbreeder with NEAT and CP=\r\nPNs (which are the very methods behind Picbreeder).  So in the quantitative=\r\n world we would conclude that CPPNs cannot evolve such images.  And in fact=\r\n results of this sort (showing method X cannot solve problem A) are publish=\r\ned all the time, and almost entirely misleading.  &lt;br&gt;\n\n&gt; \t&lt;br&gt;\n&gt; The=\r\ny are also the basis of highly deceptive comparisons between method X and Y=\r\n.  We like to say if method X &quot;performs significantly better&quot; tha=\r\nn method Y on task A then method X is somehow &quot;better.&quot;  But the =\r\ntruth is that often the ability of an encoding to evolve to a specific targ=\r\net is a bad sign for its ability to ever produce anything interesting.  Thi=\r\nnk about direct encodings:  they will always win on low-dimensional target-=\r\nmatching problems but are a dead end for evolving anything truly complex.  =\r\nWe are fooling ourselves with quantification.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Even peop=\r\nle who are aware of Woolley&#39;s result and agree with our conclusions *st=\r\nill* publish this kind of result because our culture is so deeply entrenche=\r\nd in this kind of quantification that we simply have no idea what else to d=\r\no.  If we were willing to truly embrace the absurdity of this kind of analy=\r\nsis, someone would have the courage to proclaim that DNA is incapable of ev=\r\nolving humans (which were of course never set as the objective of evolution=\r\n).  After all, if humans were set as objective targets for evolution from t=\r\nhe start, there would be no humans.  &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; How many of us ha=\r\nve tried to test method X on objective A and found method X wanting and the=\r\nn published the result?  And how many such papers would you consider &quot;=\r\nstrong?&quot;  Our culture of worshipping quantification has often led us a=\r\nstray on the real power of evolution and the potential of different encodin=\r\ngs.  If intuition trumped quantification (a heretical suggestion) this fund=\r\namental confusion would not have arisen so severely.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; No=\r\nw I want to look at this issue from the opposite direction, where my own ex=\r\nperience has been much more positive: how qualitative observations often le=\r\nad to unexpected leaps of insight in a way quantitative results rarely have=\r\n for me.  In fact, almost every idea in which I have been involved is the r=\r\nesult of a qualitative observation, exactly the kind that worshipers of qua=\r\nntification seem to want to prevent us from publishing and sharing with eac=\r\nh other.  &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; For example, before I thought of NEAT I read=\r\n dozens of neuroevolution papers (this was in the Fall of 1999).  There wer=\r\ne tons of quantitative results and comparisons, but at the end of four mont=\r\nhs of reading all this literature, I did not remember any of the quantitati=\r\nve results.  Instead, what was left with me was a &quot;feeling&quot; that =\r\nsomething qualitative was missing:  Regardless of performance, none of thes=\r\ne methods had the feel of nature when it came to the tendency for complexit=\r\ny to increase elegantly and indefinitely.  And that is where the inspiratio=\r\nn for NEAT began, by ignoring quantitative results.  If I had followed them=\r\n, I would simply have built upon the &quot;best&quot; neuroevolution method=\r\n of the time, which had been my original plan, having been brought up too i=\r\nn the culture of quantification.  So then there would be no NEAT.&lt;br&gt;\n\n&gt;=\r\n &lt;br&gt;\n&gt; My idea for CPPNs was also from an entirely qualitative observat=\r\nion.  It actually came before Picbreeder.  The main insight was actually fr=\r\nom evolving a spaceship image in Mattias Fagerlund&#39;s old NEAT-based Gen=\r\netic Art program.  The experience of evolving the spaceship was so exciting=\r\n to me at the time that I put up a whole website on it: &lt;a href=3D&quot;http://w=\r\nww.cs.utexas.edu/users/kstanley/rocket.html&quot; target=3D&quot;_blank&quot;&gt;http://www.c=\r\ns.utexas.edu/users/kstanley/rocket.html&lt;/a&gt;  &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; There was=\r\n not a single quantitative result, but I was convinced that I had seen some=\r\nthing, qualitatively, that resonated with nature.  It was that qualitative =\r\nfeeling, that recognition of something deep in the results, that led to CPP=\r\nNs.  It was a couple years later that the whole theory solidified and I wro=\r\nte the journal article on CPPNS: &lt;a href=3D&quot;http://eplex.cs.ucf.edu/publica=\r\ntions/2007/stanley-gpem07&quot; target=3D&quot;_blank&quot;&gt;http://eplex.cs.ucf.edu/public=\r\nations/2007/stanley-gpem07&lt;/a&gt;&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; One interesting thing ab=\r\nout that CPPN journal article is that it is almost entirely qualitative.  A=\r\ns you can imagine, that posed problems for review, but I was determined not=\r\n to pollute it with meaningless quantification. For me, the images speak fo=\r\nr themselves.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Those observations on CPPNs and their res=\r\nulting symmetries and regularities are also what led to David D&#39;Ambrosi=\r\no, Jason Gauci and myself creating HyperNEAT - again, the inspiration for t=\r\nhe idea was not any quantitative demonstration of anything.  &lt;br&gt;\n\n&gt; &lt;br=\r\n&gt;\n&gt; And finally, as some of you know, novelty search itself was not insp=\r\nired by a quantitative result.  Rather, it comes *again* from evolving pict=\r\nures - in this case it was my experience of evolving the Picbreeder Car: &lt;a=\r\n href=3D&quot;http://picbreeder.org/search/showgenome.php?sid=3D464&quot; target=3D&quot;_=\r\nblank&quot;&gt;picbreeder.org/search/showgenome.php?sid=3D464&lt;/a&gt;&lt;br&gt;\n\n&gt; What sh=\r\nocked me from the experience of evolving the car was that I had not been tr=\r\nying to evolve a car.  I could not stop thinking about that, about how I di=\r\nd something really hard (from a qualitative perspective) by not trying to d=\r\no it.  I later noticed that almost every interesting image on the site has =\r\nthe same strange story.  I discussed the implications of these observations=\r\n with Joel Lehman, which led us both to novelty search.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt;=\r\n Now someone could argue that these ideas may all turn out &quot;weak&quot;=\r\n in the end.  But that would be a strange philosophy of science; it would s=\r\nuggest that we should never have explored down these roads in the first pla=\r\nce.  Of course we cannot know where any road leads until we take it - and I=\r\n think at least it&#39;s clear these were roads worth exploring though no o=\r\nne can say they lead ultimately to the greatest truths.  But it&#39;s still=\r\n worth the lessons along the way.  &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Someone might also =\r\nthink, okay, your inspirations may have been qualitative but your *results*=\r\n were mainly quantitative, and somehow that&#39;s what matters (though reca=\r\nll the CPPN paper does not have quantitative results).  As JBM points out, =\r\nour novelty search paper did have quantitative results that ultimately conv=\r\ninced him something interesting was going on.  But I think again the focus =\r\nhere on &quot;results&quot; misses the forest for the trees.  What is more =\r\nimportant for the progress of science than the results is the *inspiration*=\r\n that leads to the ideas that produced the results.  If the inspiration is =\r\nwithheld, if I cannot share with you the analogue of the spaceship or the c=\r\nar in the future, then you can never draw from those inspirations to find n=\r\new roads for us to travel.  The kind of science that I believe JBM and many=\r\n others idealize cuts out all the inspiration from the public sphere and le=\r\naves us only to share its fruits when someone is lucky enough in private to=\r\n see something interesting (and try to quantify it then).&lt;br&gt;\n\n&gt; &lt;br&gt;\n&g=\r\nt; Nevertheless, JBM says, &quot;I think that it is much harder to write a =\r\nconvincing paper without any quantitative test than with the help of measur=\r\nes/comparisons/etc.&quot;  Again, many would share this sentiment.  But if =\r\nyou think about it, what exactly do we need to be &quot;convinced&quot; of?=\r\n  Why do we think science (or AI especially) is about convincing someone of=\r\n something?  Why do we need e.g. 30 strangers to validate an intuition we a=\r\nlready feel deeply that something is interesting?  The links in the chain o=\r\nf progress are from inspiration, not from convincing.  There are many ideas=\r\n that are neither right nor wrong anyway, but worth exploring because they =\r\nwill lead us to new revelations.  To me, capturing the essence of nature is=\r\n as much about a feeling as it is about a result.  And my experience in pra=\r\nctice bears that out.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Here is where I want to return to=\r\n the intellectual insecurity that Feyerabend raises.  I think our quantitat=\r\nive culture all boils down to this problem of insecurity.  We do not trust =\r\nourselves to have valid intuitions.  We dismiss our own ability to think, a=\r\ns with JBM&#39;s tongue-in-cheeck parody, &quot;look, cool simulated robots=\r\n.&quot;  But I want to question why we are so insecure in our own qualitati=\r\nve judgments?  &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; For those of us with PhDs, our countrie=\r\ns invested something like 25 years into our education.  Shouldn&#39;t someo=\r\nne who supposedly succeeded in jumping through intellectual hoop after hoop=\r\n after hoop - eventually impressing their peers enough to be hired, even ev=\r\nentually to be tenured or promoted - be able to think for themselves suffic=\r\niently to decide whether the &quot;cool robots&quot; are worth sharing with=\r\n other scientists because they might inspire new ideas?  If we are really e=\r\nntirely unqualified after all those years of supposedly learning to be a sc=\r\nientist, then what was the use of all that public investment?  Was it simpl=\r\ny to validate that we are able to check p-values that someone else reports =\r\nin an X vs. Y quantitative comparison?  That&#39;s all we&#39;re qualified =\r\nto do?  Why do we deny our intellectual curiosity and ability to think for =\r\nourselves?  &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; You may think it can&#39;t be done.  Maybe=\r\n you think my personal experience with NEAT, CPPNs, HyperNEAT, novelty sear=\r\nch, etc. is some kind of fluke that doesn&#39;t really represent science an=\r\nd how it works.  Maybe you think that kind of qualitative approach may work=\r\n for Ken for some reason but it can&#39;t work in general.  But why would t=\r\nhat be?  Isn&#39;t it possible that we are all prematurely discrediting our=\r\n intellectual potential to think for ourselves?  We have created a culture =\r\nin which the spaceships and cars of science must be hidden, buried until th=\r\neir discoverers figure out (or give up figuring out) their deeper implicati=\r\nons.  I do not support publishing a paper simply because of some &quot;cool=\r\n robots,&quot; but I do support qualified scientists deciding for themselve=\r\ns, from their experience and intuitions, whether those cool robots might be=\r\n the seed of an important chain of ideas.  And I do not want those cool rob=\r\nots hidden from me as a reader of scientific literature if they might be su=\r\nch a seed.  When I looked at Jeff&#39;s recent video of his cool robots, I =\r\ncould feel those wheels of intuition turning in my mind.  I still don&#39;t=\r\n know if it leads to anything, but I don&#39;t need any quantification to k=\r\nnow that that feeling is more than enough to justify publishing that paper,=\r\n and I&#39;m grateful he and his coauthors did not try to obfuscate it with=\r\n a veil of needless quantification.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Best,&lt;br&gt;\n&gt; &lt;br&gt;=\r\n\n&gt; ken&lt;br&gt;\n&lt;br&gt;\n&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:=\r\n0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex&quot;&gt;=\r\n&lt;div style&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;d=\r\niv style=3D&quot;color:rgb(255,255,255);min-height:0px&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n=\r\n\n\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;br clear=3D&quot;all&quot;&gt;&lt;br&gt;-- &lt;br&gt;Julian Togelius&lt;br&gt;=\r\nAssociate Professor&lt;br&gt;IT University of Copenhagen&lt;br&gt;Rued Langgaards Vej 7=\r\n, 2300 Copenhagen, Denmark&lt;br&gt;mail: &lt;a href=3D&quot;mailto:julian@...&quot; =\r\ntarget=3D&quot;_blank&quot;&gt;julian@...&lt;/a&gt;, web: &lt;a href=3D&quot;http://julian.to=\r\ngelius.com&quot; target=3D&quot;_blank&quot;&gt;http://julian.togelius.com&lt;/a&gt;&lt;br&gt;\nmobile: +4=\r\n6-705-192088, office: +45-7218-5277\n&lt;/div&gt;&lt;/div&gt;\n\r\n--089e01493c3440565804de285b8b--\r\n\n"}}