{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":344770077,"authorName":"Colin Green","from":"Colin Green &lt;colin.green1@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"3bIQNAe-GXHsI0TRkOKNmj10H2vK-F7rAz5iXVO1of0IBEzDQCuSdMBhoyDRNYQwLKg3pNHZzwezEHXdniurGDwIwzbeFdfXIdZ4","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Re: A Review of Activation Functions in SharpNEAT","postDate":"1508961218","msgId":6897,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBRTBNK1ljUkNXVTJfSjFUUlpzR0JWWkdmdHQ4MVJZaE5KaEQza3NTbjR6Y0JUbVZDd0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PG9zb3VkbysxOWdwaWhoQFlhaG9vR3JvdXBzLmNvbT4=","referencesHeader":"PENBRTBNK1llaVFkQlpaY093enAtN3JTMkU3LXYrQk1wNEtqY0V2OVVRbzl0eF91cTI4UUBtYWlsLmdtYWlsLmNvbT4gPG9pYWsxaStvM244OHZAWWFob29Hcm91cHMuY29tPiA8Qzc4QjM5MDAtNjFFRS00NTlGLUJCQjQtNDk1NzRBOUVCNjVBQHV3eW8uZWR1PiA8QkZCM0Q3QjctMDU5OS00QjU4LUI5N0UtQ0NEMERGNDVCN0MyQGdtYWlsLmNvbT4gPG9wbms0dCtwZjB0bTFAWWFob29Hcm91cHMuY29tPiA8RTJFN0MyODYtQzQwNC00QjEyLUE0QjQtM0E1QzY1OEI5QUU3QGdtYWlsLmNvbT4gPG9zb3VkbysxOWdwaWhoQFlhaG9vR3JvdXBzLmNvbT4="},"prevInTopic":6896,"nextInTopic":6900,"prevInTime":6896,"nextInTime":6898,"topicId":6827,"numMessagesInTopic":27,"msgSnippet":"On 25 October 2017 at 03:54, sean_c4s@yahoo.com [neat] ... Hi Sean, Imagine we have a data set of 64 x 64 pixel monochrome images (so e.g. each pixel has a","rawEmail":"Return-Path: &lt;colin.green1@...&gt;\r\nX-Sender: colin.green1@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 49559 invoked by uid 102); 25 Oct 2017 20:25:18 -0000\r\nX-Received: from unknown (HELO mtaq1.grp.bf1.yahoo.com) (10.193.84.32)\n  by m17.grp.bf1.yahoo.com with SMTP; 25 Oct 2017 20:25:18 -0000\r\nX-Received: (qmail 20109 invoked from network); 25 Oct 2017 20:25:18 -0000\r\nX-Received: from unknown (HELO mta1004.groups.mail.bf1.yahoo.com) (98.139.245.163)\n  by mtaq1.grp.bf1.yahoo.com with SMTP; 25 Oct 2017 20:25:18 -0000\r\nX-Original-Return-Path: &lt;colin.green1@...&gt;\r\nX-Received-SPF: pass (domain of gmail.com designates 209.85.218.67 as permitted sender)\r\nX-YMailISG: yqNbCh8WLDuaLeLrNOJOOwSvseJOE3QjCQh8AhuCHy6KqRLv\n RZKah6P8LrYniNkqcoITDaJRyIvpAOJa_rH_cDUeXS9d5Iq7lc66YupS8R7k\n bbVxk2ulIeu6c0H51cgeYdTbsfsQj_DYyYVJhy4VJkmGZ9gxw4zfZfCSEs3A\n vmUvF4KBVCILnFuUm3AV6Py_eM75wwJ1KMhlDOOKoeDBTvqtY.f.rLpsy5wg\n oKl0.hgjpWgBwyXqi7.NocS_vN6tjOIu_H_ujdGERzI8VvwMOe_jUWYhb_0r\n GLxorgUEihvEDHicYbT1lFq.54oGMb2R9b21ZR_0fpb1EZO6o_Vj7yeD8v7Q\n j5GEVo8p29rlAAaRqZdCxV7sCfrFGhF_LpY7b3rgnuoObsu5kzaEgwDTSUZl\n AkAwDRk5Hh1GpnZdsV9VkVhimap1erojIcaCtL1.kc0KgAPsobDdakbiJonb\n XAQZWERGCAyqfFjxqieG4QmZlKGoCwJfqcNNCJ.u55pUT.J.4o.mYeNZn1a7\n Lu0w8IDSUCLBcv5s7tD6upMfIbDgOul_JkfnO46fcKDEkNOPyPBnlbt2k4bc\n fv1mY6fOc62Du_5rVIe.pHjmXcdC.MBGW_FqEWiXnt0yen5OeybLWoBwqwCB\n JI10vDBOB0sJaEEiNlc7MWOEgxfa556rKFf2MjUOjOY7VdpeP0BgFP.Mb.Kh\n wnz8eFe1vHnnnddu_Qc4lIppMU9WisQE79Cb5Pq16KTGigXPB8of_Qq2VfGp\n 4uLIXT49btJb9VXgBscE1MWPDQJtXcz.wz9rkPyCSnVl777L55ve0Zl9yn37\n 04aoo3tsBIp5gPXOnkhW05TG73PtFDufWdRt4ZqnSx9xYEJR2i3N4JihBLZy\n IRt5HxvERl2T9lPuHwG2G91_NBuYFg.rtFT38biWXmbMBuwxe6pASv.aHuyr\n ZOJ8KSqeFun.JBF6Qo9Qx._VQla1tSPOI7g8GXjBXp7uTdANgMxLxoZiGa.E\n dvsDjPzyiS8ppoROwKcQQAxNYJ5OsdUmIn_IIom0cmn6fF135tmGzd5x36Po\n fU98miBfdDuKd38qojC6iPPWIwzNxzf15Ceaf3HA2U3wh9IU9_Qmh7ALgA63\n Qgkxr6iPwXqHZD_MGdbiW48yFa3LyD2XcgsUrkQElCqW6.Gd1Qf4pg9.iBaM\n iou4TMi3_huJ2rlLDO9m4uYLTugHfCmAWjfKujvR6_x0NICQiAQ_7Hr.lpeQ\n kXDRFOUVjMUpVLMhMsr0OPKqIwbzqcqBsovbrjRf8B9VqumEOvWpOG0Xex3A\n 7NZ9ChimA.i8ByVgX3iaUTusECRfzeHlHuz2iGBWDzu1Z69qNZSNLpdeTTU3\n H4rJ0Q--\r\nAuthentication-Results: mta1004.groups.mail.bf1.yahoo.com  from=gmail.com; domainkeys=neutral (no sig);  from=gmail.com; dkim=pass (ok)\r\nX-Received: from 127.0.0.1  (EHLO mail-oi0-f67.google.com) (209.85.218.67)\n  by mta1004.groups.mail.bf1.yahoo.com with SMTPS; Wed, 25 Oct 2017 20:25:18 +0000\r\nX-Received: by mail-oi0-f67.google.com with SMTP id c77so2180626oig.0\n        for &lt;neat@yahoogroups.com&gt;; Wed, 25 Oct 2017 13:25:18 -0700 (PDT)\r\nX-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;\n        d=1e100.net; s=20161025;\n        h=x-gm-message-state:mime-version:in-reply-to:references:from:date\n         :message-id:subject:to;\n        bh=lf9A0hsuLokQymdsAERHCkS9ph/zQRPQ09Bl6vMkMxk=;\n        b=CGtGZVL/b22P6ZXni9/3QBIIrub9SJtddIJLtANb6abM/PQNach0MHj3UPY3KbkLQ7\n         mak3r6NkN3O1B97UCGpbvRKpnscSyCD2j13cbECKP+o267/NBfAq6+EPWbSFfWcxp8g9\n         f1MwL6wlmCoQrPe0+L97KLX8rtfZO7tafktQ0jIOen/k932LqP6DHY749isXM2g3+B/o\n         4Azr62BGj4HPWmwBs5GDl9s3ADsx8ULapC/RWkODy1eXahhqKaLZTcVBuMcah2nbEd+K\n         hozN9FsPGt1usf367DHlHon0sEAP+pT/hGtrJvm9CDn5fseVP6oRGGSx9RF2+aaZyV07\n         t8FA==\r\nX-Gm-Message-State: AMCzsaUnRnXOlQXM4oUGOU79FxaeargbFnxHiO7GKWrCVovQMyVjeh2u\n\taAu9zh1EkmJLNkwu6aEF6n6rVXgGGWQiG5hSNc8=\r\nX-Google-Smtp-Source: ABhQp+RjmnvVVehdW6JnHVmHBJKJPs1CAhgUwXu3uU/VpXHPWYyEpw60B/0vobQQJYifWIxB4FV4MVMTaYue65DuehM=\r\nX-Received: by 10.202.208.85 with SMTP id h82mr1459428oig.247.1508961258908;\n Wed, 25 Oct 2017 12:54:18 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.157.42.78 with HTTP; Wed, 25 Oct 2017 12:53:38 -0700 (PDT)\r\nIn-Reply-To: &lt;osoudo+19gpihh@...&gt;\r\nReferences: &lt;CAE0M+YeiQdBZZcOwzp-7rS2E7-v+BMp4KjcEv9UQo9tx_uq28Q@...&gt;\n &lt;oiak1i+o3n88v@...&gt; &lt;C78B3900-61EE-459F-BBB4-49574A9EB65A@...&gt;\n &lt;BFB3D7B7-0599-4B58-B97E-CCD0DF45B7C2@...&gt; &lt;opnk4t+pf0tm1@...&gt;\n &lt;E2E7C286-C404-4B12-A4B4-3A5C658B9AE7@...&gt; &lt;osoudo+19gpihh@...&gt;\r\nDate: Wed, 25 Oct 2017 20:53:38 +0100\r\nMessage-ID: &lt;CAE0M+YcRCWU2_J1TRZsGBVZGftt81RYhNJhD3ksSn4zcBTmVCw@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=&quot;UTF-8&quot;\r\nSubject: Re: [neat] Re: A Review of Activation Functions in SharpNEAT\r\nX-Yahoo-Group-Post: member; u=344770077; y=_VlFUI0bw-USn9R-vYImHaea7EDCa8Wl1P-g5riqrKxynYoHir4d\r\nX-Yahoo-Profile: alienseedpod\r\nFrom: Colin Green &lt;colin.green1@...&gt;\r\n\r\nOn 25 October 2017 at 03:54, sean_c4s@... [neat]\n&lt;neat@yahoogroups.com&gt; wrote:\n&gt;\n&gt;\n&gt; This paper on single pixel attacks on deep neural networks is another\n&gt; indication of a fractal like dependency on initial conditions.\n&gt; https://arxiv.org/pdf/1710.08864.pdf\n&gt; The deeper the net the more fractal chaos there is.\n\nHi Sean,\n\nImagine we have a data set of 64 x 64 pixel monochrome images (so e.g.\neach pixel has a continuous value in the interval [0,1]). We can thus\nconsider each image to be located in a continuous/smooth 4096\ndimension space (64x64), where changing the value of one pixel moves\nyou in the dimension represented by that pixel.\n\nNow imagine a feature space, and for the sake of argument let&#39;s say\nthe feature space has the same size and shape as the image space, i.e.\n64x64 continuous values. Now imagine a bidirectional mapping function\nthat maps between the two spaces (i.e. a bijective function), this\ncould be a neural net, although in that case mapping in both\ndirections is problematic, but just put that aside that for now.\n\nSo we can pick a random point on the feature space and map it to an\nimage, and vice versa. Note that if the mapping function is the\nidentity function then the vast majority of random samples will be\nrandom noise -  because the vast majority of locations in the image\nspace are random noise.\n\nOK so nothing very interesting so far.\n\nThinking for a moment about unsupervised generative models... an ideal\nlearning rule is one that maximises the probability of generating the\ndata set, i.e. e.g. of random samples from the model generating real\nworld images. So typically we might calc the probability of generating\nthe data set (or actually each image in the data set in turn), then\ncalc the gradient of that probability at each model variable (e.g.\nconnection weight), and then follow the gradient. That is unsupervised\nlearning in a nutshell (or &#39;self supervised&#39; if you prefer). In\nreality calculating that gradient exactly is difficult so we have\nhacky approximations, but that&#39;s an implementation problem, the\nunderlying idea is sound.\n\n\nIn our model the random samples just produce noise, and we want to\ntrain it so that it produces real world images, but we also want the\nmapping to be smooth such that as we move smoothly through the feature\nspace  in any direction the images we map to continue to be real world\nimages, so we sort of have a second goal - that of the &#39;mapping\nfunction smoothness&#39;. In turn this means that the mapping the other\nway is also smooth, and thus there should be no &#39;single pixel attack&#39;.\n\nHow do we increase the probability of generating images in our data\nset *and* ensure the mapping is smooth?\n\nSee:\n\n   Density estimation using Real NVP\n   https://arxiv.org/abs/1605.08803\n\nAlso see this blog post for a different take:\n    http://sifter.org/~simon/journal/20171014.html\n\n\nSo take a training data image and map it to the feature space; this\ngives us a single feature vector that represents a point in the\nfeature space. If we think of the mapping/transform as being like a\nlense, i.e. smoothly distorting the image, then it can expand and\ncontract regions in the image, and thus two adjacent points in the\nimage space might be spaced out in the feature space. So we can think\nabout the nature of that distortion at the point we&#39;re mapping to (in\nthe feature space).\n\nWe can apply a learning rule that takes the point our image is at and\ncauses the mapping to expand at that point. If we just have one\ntraining image then it would eventually fill the feature space, i.e.\nall locations in the feature space would map to our image. But if we\nadd more and more images then they all attempt to expand to fill the\nfeature space, and collide where they meet (in the feature space) like\na so many balloons being inflated in a confined space.\n\nSo mathematically we&#39;re applying the transform from image-&gt;feature,\ncalculating the gradient of that mapping in each of the 4096\ndimensions (the Jacobian matrix). Then we interpret those gradients as\ndescribing how much the transform is expanding/contracting at that\npoint in each direction, so we can think of the Jacobian matrix as\ndescribing a volume where high volume (high gradients) corresponds\nwith an &#39;expanding&#39; transform, i.e. the magnitude of the expansion is\ngiven by calculating the volume of the Jacobian (hence talk of the the\nJacobian determinant in the above links).\n\nWe can then ask what the gradient of that volume is w.r.t to a given\nmodel variable, follow the gradient, and thus train the model to\n&#39;inflate the balloons&#39; (fill the feature space). By doing this we also\nmaximise the probability that random samples in the feature space will\nmap to real images.\n\nThe above paper is concerned with how to make a neural net invertible\nso that they can train the model and run it in generative mode,\nalthough as far as I can tell it should be possible to train the model\nwith a non-invertible transform, but you just can&#39;t directly sample\nfrom it (but I may have that all wrong).\n\nAnyways, the point is that this I believe this is directly relevant to\nyour concerns about the structure of the mappings discovered by &#39;deep\nlearning&#39;, so I thought you might find it interesting.\n\n+ There&#39;s a presentation video of the above paper y&#39;all might find\nbeneficial/interesting, and there&#39;s some cool demos in there of the\ntransforms:\n\n     https://www.periscope.tv/hugo_larochelle/1ypKdAVmbEpGW\n\nColin\n\n"}}