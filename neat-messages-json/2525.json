{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":82117382,"authorName":"Jim O&#39;Flaherty, Jr.","from":"&quot;Jim O&#39;Flaherty, Jr.&quot; &lt;jim_oflaherty_jr@...&gt;","profile":"jim_oflaherty_jr","replyTo":"LIST","senderId":"KI8pe1NZMzE6P_zPJ6bDcg4GNqvzEA_d9lxxgz0MnAKHowJc-SSiFRdakX7Qm3nbdL9ybY4YE_TBTK8QwitNWGqCNUQqZzXrYbD9ePVUhm9jYNZMSDhltUg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Structure sharing","postDate":"1139440606","msgId":2525,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzRUE3QkRFLjEwMjAwMDVAeWFob28uY29tPg==","inReplyToHeader":"PGJhOTE5ZDBlMDYwMjA3MDUzNGpmZjViNjJtYzFjMTY5OGU0Y2I5NmYxNkBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PGJhOTE5ZDBlMDYwMjA2MDMzM24zMWU0N2M5N3E4OGEzNWUxODU3MTI3ZWQzQG1haWwuZ21haWwuY29tPgkgPDIwMDYwMjA2MTUwNjU1LjIxMjkwLnFtYWlsQHdlYjUyODA4Lm1haWwueWFob28uY29tPiA8YmE5MTlkMGUwNjAyMDcwNTM0amZmNWI2Mm1jMWMxNjk4ZTRjYjk2ZjE2QG1haWwuZ21haWwuY29tPg=="},"prevInTopic":2524,"nextInTopic":0,"prevInTime":2524,"nextInTime":2526,"topicId":2515,"numMessagesInTopic":4,"msgSnippet":"Sandor, Thank you for your acknowledgment. ... mean do you know how much time your optimizations can save (at least for some specific experiments)? What would","rawEmail":"Return-Path: &lt;jim_oflaherty_jr@...&gt;\r\nX-Sender: jim_oflaherty_jr@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 84479 invoked from network); 8 Feb 2006 23:17:02 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m26.grp.scd.yahoo.com with QMQP; 8 Feb 2006 23:17:02 -0000\r\nReceived: from unknown (HELO smtp104.mail.sc5.yahoo.com) (66.163.169.223)\n  by mta5.grp.scd.yahoo.com with SMTP; 8 Feb 2006 23:17:02 -0000\r\nReceived: (qmail 10649 invoked from network); 8 Feb 2006 23:16:48 -0000\r\nReceived: from unknown (HELO ?192.168.1.101?) (jim?oflaherty?jr@67.187.121.107 with plain)\n  by smtp104.mail.sc5.yahoo.com with SMTP; 8 Feb 2006 23:16:48 -0000\r\nMessage-ID: &lt;43EA7BDE.1020005@...&gt;\r\nDate: Wed, 08 Feb 2006 17:16:46 -0600\r\nUser-Agent: Mozilla Thunderbird 1.0.2 (Windows/20050317)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;ba919d0e0602060333n31e47c97q88a35e1857127ed3@...&gt;\t &lt;20060206150655.21290.qmail@...&gt; &lt;ba919d0e0602070534jff5b62mc1c1698e4cb96f16@...&gt;\r\nIn-Reply-To: &lt;ba919d0e0602070534jff5b62mc1c1698e4cb96f16@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Jim O&#39;Flaherty, Jr.&quot; &lt;jim_oflaherty_jr@...&gt;\r\nSubject: Re: [neat] Structure sharing\r\nX-Yahoo-Group-Post: member; u=82117382; y=Ty100pEevXjgEaOUqRDAVC6TF3-vtJcr_If_HfmeAw2xzxPWQsLfgkFm-Q\r\nX-Yahoo-Profile: jim_oflaherty_jr\r\n\r\nSandor,\n\nThank you for your acknowledgment.\n\nYou wrote:\n &gt;  Do you have any comparison with a naive version of evaluation? I \nmean do you know how much time your optimizations can save (at least for \nsome specific experiments)?\n\nWhat would I compare it to?  It is the first one I generated.  The only \nother implementation I had for ANNs was a fully connected feedforward \n(no recurrancy) with backprop implementation.  So comparing it to a \nsparsely connected read/only feedforward recurrent ANN is somewhat \ndifficult as it is an apples to oranges comparison.\n\n\nYou wrote:\n &gt; Hmm... I think it would make sense if you use the same network a lot \nof times. Otherwise code generation/compilation will take too much time....\n\nI am not sure I understand you on this.  Honestly, if a phenotype is \ninvolved in activating its network repeatedly, then I don&#39;t think your \npremise holds.  In my experiments, a particular specimen will activate \nits network billions of times per fitness evaluation.  So, the amount of \ntime doing dynamic code generation, compilation and hotspot optimization \nis measured in part of a percent compared to the actual activation \npasses on the network.\n\n\nYou wrote:\n&lt;snippet from and old email of mine&gt;\n &gt; Is it still true?\n\n &gt;My understanding of this: connection weights are fixed during \nactivation -&gt; it is not possible to create a &quot;dynamic connection&quot; where \nthe weight of the connection is not constant (e.g. depends on the output \nof another node).\n &gt; Is that correct?\n\nThis is still true with the current implementation options.  I have been \ninvestigating how to make a dynamic weight value version as well, \nalthough I have not implemented it.  It would not be all that difficult \nto do as it would just mean exposing an API to the internals of \nGraphDecorator and then providing a version in Network that kept itself \nsynced with any changes to its GraphDecorator.  Once implemented, using \nthis approach would exclude being able to use the dynamic code \ngeneration path for optimization (or at least the method I currently \nhave designed) and would also generate multi-threading issues I would \nhave to integrate into the design (immutability rocks for simplifying \nmulti-threading issues).  However, I think it would meet your needs \nwithout having to having to &quot;rebuild&quot; the structure every time you \nwanted to adjust a weight and/or bias value on an existing Network.\n\nTraditionally, the value of a particular weight does not depend on the \nvalue of another node.  The value of an feeding node to a particular \nweight is used to created the activation value for that feeding \nnode/weight combination.  And that combination is a component of all the \nfeeding node/weights supplying values to the receiving node.  So, the \nweights in a traditional ANN remain constant unless some sort of \nexternal process is applied to altering them (like a backprop pass).  \nAre you proposing a different model of weight value modification based \non node activation values?  I will say that seems to be a quite novel \nidea (at least to me).  I am not sure what value it has.\n\n\nYou wrote:\n &gt;Did you (or anyone else) use structure sharing for anything else then \ngenotype/phenotype creation and network evaluation?\n\nNot about which I know.\n\n\nJim\n\n\nSandor Murakozi wrote:\n\n&gt;Hi Jim,\n&gt;  \n&gt;\n&gt;On 2/6/06, *Jim O&#39;Flaherty, Jr.* &lt;jim_oflaherty_jr@... &lt;mailto:jim_oflaherty_jr@...&gt;&gt; wrote:\n&gt;  \n&gt;\n&gt;     Sandor,\n&gt;\n&gt;     I created Semiann, an ANN in Java.  And it does exactly what you\n&gt;     are thinking.  It is FOSS/GPLed.  You can find it here:\n&gt;     http://sourceforge.net/projects/semiann\n&gt;\n&gt;\n&gt; I&#39;ve already known about Semiann, but I thought its killer feature is \n&gt; the optimized network evaluation. I didn&#39;t know that you (can) also do \n&gt; structure sharing.\n&gt; I had a look at the source of it (seems very nice, congratulations), \n&gt; and now I realized that the GraphDecorator class caches Graph \n&gt; instances, which is really &quot;structure sharing&quot;.\n&gt;\n&gt;\n&gt;     BTW, typically the real burn is not in the genotype\n&gt;     manipulation/phenotype creation part of a generation.  The real\n&gt;     burn on the CPU is during the fitness evaluation phase (like 100\n&gt;     to 1). \n&gt;\n&gt;\n&gt; Yeah, I know that.  \n&gt;\n&gt;     So, engaging in optimizations where you are reducing expense in\n&gt;     time around the genotype manipulation/phenotype creation is time\n&gt;     not very effectively spent. \n&gt;\n&gt;\n&gt; Agreed. Actually my main goal is not to reduce this time, but to be \n&gt; able to use structural operations in general with less performance \n&gt; overhead. Genotype/phenotype creation is only one (and really not the \n&gt; most important) special case of this. But I think it would allow some \n&gt; operations that were not used previously because they were too \n&gt; expensive. Currently I just have some rough ideas, but I have a \n&gt; feeling that other aspects of NEAT could benefit from structure sharing.\n&gt;\n&gt;     If you really want to reduce your total time, focus on making sure\n&gt;     you are doing the minimum number of fitness evaluations per\n&gt;     generation as is reasonable for you to maintain progress.\n&gt;\n&gt;\n&gt; My hope is that using structural info I could bias the GA to more \n&gt; promising directions:\n&gt; e.g. It is possible that using structural info I can implement some \n&gt; speciation strategies that classifies individuals to species better \n&gt; (at least in some specific domains).\n&gt; A kind of tabu search (avoiding already &quot;depleted&quot; structures) would \n&gt; also be feasible.\n&gt;\n&gt;\n&gt;     That said, if you read the detail docs within Semiann, you can see\n&gt;     how I created an infrastructure to optimize the generated networks. \n&gt;\n&gt;\n&gt; Do you have any comparison with a naive version of evaluation? I mean \n&gt; do you know how much time your optimizations can save (at least for \n&gt; some specific experiments)?\n&gt;\n&gt;\n&gt;     And you can see that I have designed it so that the next version\n&gt;     includes dynamic code generation/compilation so as to maximize\n&gt;     performance by unrolling loops and reording independent operations\n&gt;     and caching precalculated values optimally to minimize CPU\n&gt;     register/cache flushes.\n&gt;\n&gt;\n&gt; Hmm... I think it would make sense if you use the same network a lot \n&gt; of times. Otherwise code generation/compilation will take too much \n&gt; time....\n&gt;\n&gt;     If you get a chance to review it, please give me feedback if you\n&gt;     have any issues or suggestions.\n&gt;\n&gt;  \n&gt; I did a quick evaluation, but no suggestions yet. However, my first \n&gt; impression is definitely positive. It is quite possible that I&#39;ll use \n&gt; Semiann as one (the default?) plugable implementation for ANN \n&gt; representation/evaluation, but I have to think a bit more about my \n&gt; design :-).\n&gt;\n&gt; However, I have some more questions.\n&gt; In one of your old posts you stated:\n&gt;\n&gt;&gt;SEMIANN&#39;s design presumes the weights are not changed during the network\n&gt;&gt;activations.  To create a copy of the network and change the weights\n&gt;&gt;requires regenerating the configuration instances and resubmitting them to\n&gt;\n&gt;&gt;the dynamic evaluator and/or &quot;code generator&quot;.  That&#39;s the &quot;read only&quot;\n&gt;&gt;tradeoff to ensure maximum flexibility for the JVM when it is doing runtime\n&gt;&gt;optimization.\n&gt;\n&gt; Is it still true?\n&gt;\n&gt; My understanding of this: connection weights are fixed during \n&gt; activation -&gt; it is not possible to create a &quot;dynamic connection&quot; \n&gt; where the weight of the connection is not constant (e.g. depends on \n&gt; the output of another node).\n&gt; Is that correct?\n&gt;\n&gt; Did you (or anyone else) use structure sharing for anything else then \n&gt; genotype/phenotype creation and network evaluation?\n&gt;\n&gt;\n&gt; Cheers,\n&gt; don\n&gt;\n&gt;\n&gt;\n&gt;     ----- Original Message ----\n&gt;     From: Sandor Murakozi &lt;smurakozi@...\n&gt;     &lt;mailto:smurakozi@...&gt;&gt;\n&gt;     To: neat &lt; neat@yahoogroups.com &lt;mailto:neat@yahoogroups.com&gt;&gt;\n&gt;     Sent: Monday, February 06, 2006 5:33:00 AM\n&gt;     Subject: [neat] Structure sharing\n&gt;\n&gt;     Hi,\n&gt;\n&gt;     I was playing with the idea of a kind of structure sharing between\n&gt;     networks and I&#39;d like to hear your opinion about it.\n&gt;     Problem:\n&gt;     algorithms related to the structure of networks are usually quite\n&gt;     expensive ( e.g. determining recurrency, comparing structure,\n&gt;     visiting nodes in a specific order, ...). Therefore most people\n&gt;     try to avoid them whenever possible (using heuristics, or simply\n&gt;     ignoring it).\n&gt;\n&gt;     My idea is to separate the structure of a network (nodes +\n&gt;     connections) from all other info (connection weights, values...).\n&gt;     Networks with the same structure would actually use the same\n&gt;     &quot;structure&quot; object. Of course, it would make creation\n&gt;     /modification of networks a bit more complex, but afterwards it\n&gt;     could save a lot of time, just some ideas:\n&gt;\n&gt;     We would need to perform the expensive operations much less times.\n&gt;     If we have several networks with the same structure we need to\n&gt;     find e.g. recurrent connections only once.\n&gt;\n&gt;     Most likely results of these operations could be stored e.g. we\n&gt;     could cache indices defining an order of nodes for network\n&gt;     evaluation. I know some frameworks already do something similar,\n&gt;     but it could be a more general pattern.\n&gt;\n&gt;     During crossover if parents have the same structure (it would be\n&gt;     trivial to determine) then just get the structure of them and\n&gt;     perform crossover only on other attributes.\n&gt;\n&gt;     When we classify networks to species we could use much more info\n&gt;     about structural similarities. If I got it correctly currently it\n&gt;     is limited, because it takes too much time. With structure sharing\n&gt;     we could reduce this time significantly.\n&gt;\n&gt;     I&#39;m sure there are a lot of other things that could benefit from\n&gt;     this feature.\n&gt;\n&gt;     I know that in most of the cases the evaluation of network fitness\n&gt;     takes much more time then these structural operations, but if\n&gt;     evaluation itself is fast, then we could save significant time\n&gt;     and/or use structural operations more frequently.\n&gt;\n&gt;     What do you think about it?\n&gt;\n&gt;     Cheers,\n&gt;     don\n&gt;\n&gt;\n&gt;     SPONSORED LINKS\n&gt;     Artificial intelligence\n&gt;     &lt;http://groups.yahoo.com/gads?t=ms&k=Artificial+intelligence&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=G26NTwjyv4YbnuVA9Ysw6Q&gt;\n&gt;     \tComputer science\n&gt;     &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=GvSBKTvrijsUeRfRGCsFSw&gt;\n&gt;     \tArtificial intelligence software\n&gt;     &lt;http://groups.yahoo.com/gads?t=ms&k=Artificial+intelligence+software&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=k_lTfHUbcTqtXjvR08aKdQ&gt;\n&gt;\n&gt;     Computer science degree\n&gt;     &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+degree&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=4djsV_ZdD-iiNwtBf00kKw&gt;\n&gt;     \tOnline computer science degree\n&gt;     &lt;http://groups.yahoo.com/gads?t=ms&k=Online+computer+science+degree&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=SaKrh2GdPnahzK6fNjSN6g&gt;\n&gt;\n&gt;\n&gt;\n&gt;     ------------------------------------------------------------------------\n&gt;     YAHOO! GROUPS LINKS\n&gt;\n&gt;         *  Visit your group &quot;neat\n&gt;           &lt;http://groups.yahoo.com/group/neat&gt;&quot; on the web.\n&gt;            \n&gt;         *  To unsubscribe from this group, send an email to:\n&gt;             neat-unsubscribe@yahoogroups.com\n&gt;           &lt;mailto:neat-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;            \n&gt;         *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;           Service &lt;http://docs.yahoo.com/info/terms/&gt; .\n&gt;\n&gt;\n&gt;     ------------------------------------------------------------------------\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; SPONSORED LINKS\n&gt; Artificial intelligence \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Artificial+intelligence&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=G26NTwjyv4YbnuVA9Ysw6Q&gt; \n&gt; \tComputer science \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=GvSBKTvrijsUeRfRGCsFSw&gt; \n&gt; \tArtificial intelligence software \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Artificial+intelligence+software&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=k_lTfHUbcTqtXjvR08aKdQ&gt; \n&gt;\n&gt; Computer science degree \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+science+degree&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=4djsV_ZdD-iiNwtBf00kKw&gt; \n&gt; \tOnline computer science degree \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Online+computer+science+degree&w1=Artificial+intelligence&w2=Computer+science&w3=Artificial+intelligence+software&w4=Computer+science+degree&w5=Online+computer+science+degree&c=5&s=154&.sig=SaKrh2GdPnahzK6fNjSN6g&gt; \n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;neat &lt;http://groups.yahoo.com/group/neat&gt;&quot; on\n&gt;       the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        neat-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:neat-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n"}}