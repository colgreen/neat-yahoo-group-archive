{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":466400914,"authorName":"Madan Dabbeeru","from":"Madan Dabbeeru &lt;iitk.madan@...&gt;","profile":"madan_mohan_d","replyTo":"LIST","senderId":"fTr1v2AVoDn71_c1M4VBreSDSpCnM5Czbun74qfcm8ccl6lyG7iL6l1n5LFY1SPP1ezZ_6iGiodclxgdQRl5Mp3wpi-RSPO8dAwP0w","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Re: Models of brains, what should we borrow from biology?","postDate":"1342698501","msgId":5828,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBTHV1dzNPcnMyUzEwRk9VMFFQRkpia2owNnZfTFFyLWczN1AyUCtkUExiRVVCcC1QQUBtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PEMyRTE3MjVELTNEMUMtNDE1QS05QkNGLUIyOEVDQjAxQzRBRkBjb3JuZWxsLmVkdT4=","referencesHeader":"PENBK2R1aW1QWlp3MEJXbjg2Z3hXM2FoSmNVY18yVVhlUkNULWFxMjlpcHpXOWhrUExZQUBtYWlsLmdtYWlsLmNvbT4JPEMyRTE3MjVELTNEMUMtNDE1QS05QkNGLUIyOEVDQjAxQzRBRkBjb3JuZWxsLmVkdT4="},"prevInTopic":5827,"nextInTopic":5830,"prevInTime":5827,"nextInTime":5829,"topicId":5801,"numMessagesInTopic":16,"msgSnippet":"Hello, I am looking for NEAT in Python. I am not able to find any file in the download like provided. (http://code.google.com/p/neat-python/downloads/list ). ","rawEmail":"Return-Path: &lt;iitk.madan@...&gt;\r\nX-Sender: iitk.madan@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 77612 invoked from network); 19 Jul 2012 11:48:21 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m5.grp.sp2.yahoo.com with QMQP; 19 Jul 2012 11:48:21 -0000\r\nX-Received: from unknown (HELO mail-vb0-f45.google.com) (209.85.212.45)\n  by mta1.grp.sp2.yahoo.com with SMTP; 19 Jul 2012 11:48:21 -0000\r\nX-Received: by mail-vb0-f45.google.com with SMTP id fn1so2605205vbb.18\n        for &lt;neat@yahoogroups.com&gt;; Thu, 19 Jul 2012 04:48:21 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.220.141.203 with SMTP id n11mr725896vcu.74.1342698501186; Thu,\n 19 Jul 2012 04:48:21 -0700 (PDT)\r\nX-Received: by 10.52.159.195 with HTTP; Thu, 19 Jul 2012 04:48:21 -0700 (PDT)\r\nIn-Reply-To: &lt;C2E1725D-3D1C-415A-9BCF-B28ECB01C4AF@...&gt;\r\nReferences: &lt;CA+duimPZZw0BWn86gxW3ahJcUc_2UXeRCT-aq29ipzW9hkPLYA@...&gt;\n\t&lt;C2E1725D-3D1C-415A-9BCF-B28ECB01C4AF@...&gt;\r\nDate: Thu, 19 Jul 2012 17:18:21 +0530\r\nMessage-ID: &lt;CALuuw3Ors2S10FOU0QPFJbkj06v_LQr-g37P2P+dPLbEUBp-PA@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=f46d042f93c634235104c52d5b52\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Madan Dabbeeru &lt;iitk.madan@...&gt;\r\nSubject: Re: [neat] Re: Models of brains, what should we borrow from biology?\r\nX-Yahoo-Group-Post: member; u=466400914; y=G_kYHFYsdRL-3p6XUk4-Z4bUrXangf7fDrUjuNPrfT9DdQ52ARuFug\r\nX-Yahoo-Profile: madan_mohan_d\r\n\r\n\r\n--f46d042f93c634235104c52d5b52\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nHello,\n\nI am looking for NEAT in Python. I am not able to find any file in the\ndownload like provided. (http://code.google.com/p/neat-python/downloads/list\n).\n\nPlease share me if anybody has this package.\n\nThanks & Regards,\nMadan\n\nOn Wed, Jul 11, 2012 at 11:42 AM, Jeff Clune &lt;jeffclune@...&gt; wrote:\n\n&gt; Hello Oliver,\n&gt;\n&gt; I&#39;m much delayed in reading all of this as I have been insanely busy\n&gt; lately, but I have a few thoughts that might help you out:\n&gt;\n&gt; 1) Be careful with meta-evolution (evolving the parameters of evolutionary\n&gt; algorithms). It sounds good in theory, but can be tricky in practice\n&gt; because evolution is short-sighted and conservative, preferring\n&gt; exploitation over exploration, which can be very harmful vis a vis\n&gt; long-term adaptation. Check out my PLoS Computational Biology paper for a\n&gt; smoking gun on this front (the evolution of mutation rates). You may face\n&gt; the exact same problem if you go down this road. [Note, however, that using\n&gt; a divergent search algorithm like novelty search may allow you to take\n&gt; better advantage of meta-evolution: see Joel and Ken&#39;s 2012 alife review\n&gt; article on that subject.]\n&gt;\n&gt; 2) Another reason people do not throw all of the biology into the soup to\n&gt; see what happens is because scientifically you end up in an impenetrable\n&gt; quagmire where you can&#39;t figure out what is going on and you end up not\n&gt; learning much/anything. The scientific method demands keeping all else\n&gt; equal, and if you have a lot of variables you don&#39;t perfectly understand,\n&gt; it takes years to figure out what is going on if you are lucky! Even if you\n&gt; keep all else equal, if you are doing so against a backdrop that involves a\n&gt; lot of complexity you don&#39;t understand, any difference you see may be due\n&gt; to an interaction effect with one of the features in your backdrop...and\n&gt; that may invalidate generalizing your result to other backdrops of\n&gt; interest. In my limited experience, I have found that most new scientists\n&gt; want to throw a million things into their model--especially biologically\n&gt; motivated phenomena--to see what happens, and as they grow older/more\n&gt; jaded/wiser/more experienced/gun shy/etc. they increasingly keep things as\n&gt; simple as possible. In fact, a pretty good heuristic for good\n&gt; hypothesis-testing science is to keep things absolutely as simple as\n&gt; possible while allowing the question to be asked. However, that may not be\n&gt; a good heuristic for more exploratory science where you just set out and\n&gt; see what you discover.\n&gt;\n&gt; 3) You should check out Julian Miller&#39;s papers on evolving a checkers\n&gt; player (with his student M. Khan, I believe). Or, better, email/Skype him\n&gt; (he&#39;s an extremely nice guy and I&#39;m sure he would be happy to talk to you).\n&gt; He decided in the last few years that he is running out of time as a\n&gt; scientist and has tenure and he has spent years keeping things as simple as\n&gt; possible, and he now just wants to do what he originally wanted to do when\n&gt; he started: throw as much biology in the soup as possible and see if a\n&gt; golem crawls out. He has incorporated a ton of biologically inspired\n&gt; low-level mechanisms in evolving neural networks. From what I recall,\n&gt; however, it did become very difficult to figure out which ingredients were\n&gt; essential and exactly what was going on because of all the involved\n&gt; complexity. He may have updated results since I last checked in, however.\n&gt; So, you may benefit the actual work that he has done on this front and,\n&gt; more generally, from his opinions on the general scientific approach you\n&gt; are proposing.\n&gt;\n&gt; I hope that helps. Best of luck, and I look forward to hearing what you\n&gt; learn!\n&gt;\n&gt; Best regards,\n&gt; Jeff Clune\n&gt;\n&gt; Postdoctoral Fellow\n&gt; Cornell University\n&gt; jeffclune@...\n&gt; jeffclune.com\n&gt;\n&gt; On May 11, 2012, at 6:34 AM, Oliver Coleman wrote:\n&gt;\n&gt; &gt; Hi Ken,\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Yes, I&#39;m pretty sure that not all of the phenomena I listed are\n&gt; important; and that a good starting point in general is to assume that they\n&gt; are not. I also agree with your argument that a lot of the low-level\n&gt; phenomena we see may be a result of implementation with particular physical\n&gt; systems (and I would add perhaps as a result of evolutionary happenstance).\n&gt; The CPPN is a particularly compelling example of significant abstraction of\n&gt; developmental processes, producing many of the same features of the end\n&gt; result of developmental processes. One thing it does abstract away, in the\n&gt; context of plastic networks, is the effect of external input on the\n&gt; developmental process (which may or may not be an issue depending on\n&gt; details of implementation, problem domain, etc...).\n&gt; &gt;\n&gt; &gt; Perhaps we could also assume that, rather than some specific set of\n&gt; functions being the only workable set, what matters is having a workable\n&gt; combination of functions, and that there are many possible combinations\n&gt; that would work equally well. In this framework we could assume that\n&gt; biological neural networks represent at least a reasonably good combination\n&gt; of low-level functions, and so we could use this combination as a guide\n&gt; (but of course this doesn&#39;t answer what functions in this combination are\n&gt; actually important, or what things can be abstracted away). Also, some\n&gt; combinations may be workable, but are far harder to evolve solutions with,\n&gt; or require much larger networks, etc (eg evolving networks incorporating\n&gt; neuromodulation of synaptic plasticity can be much easier for some tasks\n&gt; than for those without this type of neuromodulation).\n&gt; &gt;\n&gt; &gt; I&#39;m intending to run some experiments to explore these questions (which\n&gt; phenomena are important, acceptable level of abstraction, etc), but of\n&gt; course to try and thoroughly explore all of these functions in many\n&gt; combinations would be a massive undertaking, and is not my main interest,\n&gt; so at some point I will have to pick a model and run with it after only a\n&gt; few, hopefully well chosen, experiments... Perhaps one approach is to\n&gt; create flexible parameterised versions of these functions, and let\n&gt; evolution determine what combination is right (like your approach described\n&gt; in &quot;Evolving adaptive neural networks with and without adaptive synapses&quot;,\n&gt; but perhaps more flexible and applied to more functions).\n&gt; &gt;\n&gt; &gt; Do you mind if I post/quote some/all of this discussion in the comments\n&gt; of my blog post?\n&gt; &gt;\n&gt; &gt; Cheers,\n&gt; &gt; Oliver\n&gt; &gt;\n&gt; &gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt;\n\r\n--f46d042f93c634235104c52d5b52\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHello,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am looking for NEAT in Python. I am not able to=\r\n find any file in the download like provided. (&lt;a href=3D&quot;http://code.googl=\r\ne.com/p/neat-python/downloads/list&quot;&gt;http://code.google.com/p/neat-python/do=\r\nwnloads/list&lt;/a&gt;).&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Please share me if anybody has=\r\n this package.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks &amp; Regards,&lt;/div&gt;&lt;div&gt;Mad=\r\nan&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On Wed, Jul 11, 2012 at 11:42 AM, Jeff=\r\n Clune &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:jeffclune@...&quot; targe=\r\nt=3D&quot;_blank&quot;&gt;jeffclune@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;\n&lt;blockquote cl=\r\nass=3D&quot;gmail_quote&quot; style=3D&quot;margin:0 0 0 .8ex;border-left:1px #ccc solid;p=\r\nadding-left:1ex&quot;&gt;Hello Oliver,&lt;br&gt;\n&lt;br&gt;\nI&#39;m much delayed in reading all=\r\n of this as I have been insanely busy lately, but I have a few thoughts tha=\r\nt might help you out:&lt;br&gt;\n&lt;br&gt;\n1) Be careful with meta-evolution (evolving =\r\nthe parameters of evolutionary algorithms). It sounds good in theory, but c=\r\nan be tricky in practice because evolution is short-sighted and conservativ=\r\ne, preferring exploitation over exploration, which can be very harmful vis =\r\na vis long-term adaptation. Check out my PLoS Computational Biology paper f=\r\nor a smoking gun on this front (the evolution of mutation rates). You may f=\r\nace the exact same problem if you go down this road. [Note, however, that u=\r\nsing a divergent search algorithm like novelty search may allow you to take=\r\n better advantage of meta-evolution: see Joel and Ken&#39;s 2012 alife revi=\r\new article on that subject.]&lt;br&gt;\n\n&lt;br&gt;\n2) Another reason people do not thro=\r\nw all of the biology into the soup to see what happens is because scientifi=\r\ncally you end up in an impenetrable quagmire where you can&#39;t figure out=\r\n what is going on and you end up not learning much/anything. The scientific=\r\n method demands keeping all else equal, and if you have a lot of variables =\r\nyou don&#39;t perfectly understand, it takes years to figure out what is go=\r\ning on if you are lucky! Even if you keep all else equal, if you are doing =\r\nso against a backdrop that involves a lot of complexity you don&#39;t under=\r\nstand, any difference you see may be due to an interaction effect with one =\r\nof the features in your backdrop...and that may invalidate generalizing you=\r\nr result to other backdrops of interest. In my limited experience, I have f=\r\nound that most new scientists want to throw a million things into their mod=\r\nel--especially biologically motivated phenomena--to see what happens, and a=\r\ns they grow older/more jaded/wiser/more experienced/gun shy/etc. they incre=\r\nasingly keep things as simple as possible. In fact, a pretty good heuristic=\r\n for good hypothesis-testing science is to keep things absolutely as simple=\r\n as possible while allowing the question to be asked. However, that may not=\r\n be a good heuristic for more exploratory science where you just set out an=\r\nd see what you discover.&lt;br&gt;\n\n&lt;br&gt;\n3) You should check out Julian Miller&#3=\r\n9;s papers on evolving a checkers player (with his student M. Khan, I belie=\r\nve). Or, better, email/Skype him (he&#39;s an extremely nice guy and I&#39;=\r\nm sure he would be happy to talk to you). He decided in the last few years =\r\nthat he is running out of time as a scientist and has tenure and he has spe=\r\nnt years keeping things as simple as possible, and he now just wants to do =\r\nwhat he originally wanted to do when he started: throw as much biology in t=\r\nhe soup as possible and see if a golem crawls out. He has incorporated a to=\r\nn of biologically inspired low-level mechanisms in evolving neural networks=\r\n. From what I recall, however, it did become very difficult to figure out w=\r\nhich ingredients were essential and exactly what was going on because of al=\r\nl the involved complexity. He may have updated results since I last checked=\r\n in, however. So, you may benefit the actual work that he has done on this =\r\nfront and, more generally, from his opinions on the general scientific appr=\r\noach you are proposing.&lt;br&gt;\n\n&lt;br&gt;\nI hope that helps. Best of luck, and I lo=\r\nok forward to hearing what you learn!&lt;br&gt;\n&lt;br&gt;\nBest regards,&lt;br&gt;\nJeff Clune=\r\n&lt;br&gt;\n&lt;br&gt;\nPostdoctoral Fellow&lt;br&gt;\nCornell University&lt;br&gt;\n&lt;a href=3D&quot;mailto:=\r\njeffclune@...&quot;&gt;jeffclune@...&lt;/a&gt;&lt;br&gt;\n&lt;a href=3D&quot;http://jeff=\r\nclune.com&quot; target=3D&quot;_blank&quot;&gt;jeffclune.com&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\nOn May 11, 2012, at=\r\n 6:34 AM, Oliver Coleman wrote:&lt;br&gt;\n&lt;br&gt;\n&gt; Hi Ken,&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;=\r\n\n&gt; Yes, I&#39;m pretty sure that not all of the phenomena I listed are i=\r\nmportant; and that a good starting point in general is to assume that they =\r\nare not. I also agree with your argument that a lot of the low-level phenom=\r\nena we see may be a result of implementation with particular physical syste=\r\nms (and I would add perhaps as a result of evolutionary happenstance). The =\r\nCPPN is a particularly compelling example of significant abstraction of dev=\r\nelopmental processes, producing many of the same features of the end result=\r\n of developmental processes. One thing it does abstract away, in the contex=\r\nt of plastic networks, is the effect of external input on the developmental=\r\n process (which may or may not be an issue depending on details of implemen=\r\ntation, problem domain, etc...).&lt;br&gt;\n\n&gt;&lt;br&gt;\n&gt; Perhaps we could also a=\r\nssume that, rather than some specific set of functions being the only worka=\r\nble set, what matters is having a workable combination of functions, and th=\r\nat there are many possible combinations that would work equally well. In th=\r\nis framework we could assume that biological neural networks represent at l=\r\neast a reasonably good combination of low-level functions, and so we could =\r\nuse this combination as a guide (but of course this doesn&#39;t answer what=\r\n functions in this combination are actually important, or what things can b=\r\ne abstracted away). Also, some combinations may be workable, but are far ha=\r\nrder to evolve solutions with, or require much larger networks, etc (eg evo=\r\nlving networks incorporating neuromodulation of synaptic plasticity can be =\r\nmuch easier for some tasks than for those without this type of neuromodulat=\r\nion).&lt;br&gt;\n\n&gt;&lt;br&gt;\n&gt; I&#39;m intending to run some experiments to explo=\r\nre these questions (which phenomena are important, acceptable level of abst=\r\nraction, etc), but of course to try and thoroughly explore all of these fun=\r\nctions in many combinations would be a massive undertaking, and is not my m=\r\nain interest, so at some point I will have to pick a model and run with it =\r\nafter only a few, hopefully well chosen, experiments... Perhaps one approac=\r\nh is to create flexible parameterised versions of these functions, and let =\r\nevolution determine what combination is right (like your approach described=\r\n in &quot;Evolving adaptive neural networks with and without adaptive synap=\r\nses&quot;, but perhaps more flexible and applied to more functions).&lt;br&gt;\n\n&=\r\ngt;&lt;br&gt;\n&gt; Do you mind if I post/quote some/all of this discussion in the=\r\n comments of my blog post?&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Cheers,&lt;br&gt;\n&gt; Oliver&lt;br&gt;\n&g=\r\nt;&lt;br&gt;\n&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\n------------------------------------&lt;br&gt;\n&lt;br=\r\n&gt;\nYahoo! Groups Links&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; To visit your group on the web, go=\r\n to:&lt;br&gt;\n=A0 =A0 &lt;a href=3D&quot;http://groups.yahoo.com/group/neat/&quot; target=3D&quot;=\r\n_blank&quot;&gt;http://groups.yahoo.com/group/neat/&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; Your ema=\r\nil settings:&lt;br&gt;\n=A0 =A0 Individual Email | Traditional&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; =\r\nTo change settings online go to:&lt;br&gt;\n=A0 =A0 &lt;a href=3D&quot;http://groups.yahoo=\r\n.com/group/neat/join&quot; target=3D&quot;_blank&quot;&gt;http://groups.yahoo.com/group/neat/=\r\njoin&lt;/a&gt;&lt;br&gt;\n=A0 =A0 (Yahoo! ID required)&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; To change sett=\r\nings via email:&lt;br&gt;\n=A0 =A0 &lt;a href=3D&quot;mailto:neat-digest@yahoogroups.com&quot;&gt;=\r\nneat-digest@yahoogroups.com&lt;/a&gt;&lt;br&gt;\n=A0 =A0 &lt;a href=3D&quot;mailto:neat-fullfeat=\r\nured@yahoogroups.com&quot;&gt;neat-fullfeatured@yahoogroups.com&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;*&=\r\ngt; To unsubscribe from this group, send an email to:&lt;br&gt;\n=A0 =A0 &lt;a href=\r\n=3D&quot;mailto:neat-unsubscribe@yahoogroups.com&quot;&gt;neat-unsubscribe@yahoogroups.c=\r\nom&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; Your use of Yahoo! Groups is subject to:&lt;br&gt;\n=A0 =\r\n=A0 &lt;a href=3D&quot;http://docs.yahoo.com/info/terms/&quot; target=3D&quot;_blank&quot;&gt;http://=\r\ndocs.yahoo.com/info/terms/&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;\n\r\n--f46d042f93c634235104c52d5b52--\r\n\n"}}