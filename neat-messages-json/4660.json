{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"jeffreyclune","from":"&quot;jeffreyclune&quot; &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"5aJW2i5mJXPlTbuBk6idDKm8w7fegUkMstXci9gRyP0e2Vn4DVQbPPXK5VSOo8wxmRPIEsJaotQUwJUg7D5RIQmUmQgpPw","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: New Paper on Novelty Search and Adaptive Neural Networks","postDate":"1242071076","msgId":4660,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGd1OXY3NCszdWF0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGd0ZDNuZis3MTFmQGVHcm91cHMuY29tPg=="},"prevInTopic":4653,"nextInTopic":4663,"prevInTime":4659,"nextInTime":4661,"topicId":4619,"numMessagesInTopic":8,"msgSnippet":"Hello Ken- I agree with you that, from what I have read and personally experienced, evolution likes to evolve static, rather than adaptive, heuristics. It","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 51160 invoked from network); 11 May 2009 19:44:37 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m2.grp.sp2.yahoo.com with QMQP; 11 May 2009 19:44:37 -0000\r\nX-Received: from unknown (HELO n42b.bullet.mail.sp1.yahoo.com) (66.163.168.156)\n  by mta3.grp.sp2.yahoo.com with SMTP; 11 May 2009 19:44:37 -0000\r\nX-Received: from [69.147.65.151] by n42.bullet.mail.sp1.yahoo.com with NNFMP; 11 May 2009 19:44:37 -0000\r\nX-Received: from [98.137.34.36] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 11 May 2009 19:44:37 -0000\r\nDate: Mon, 11 May 2009 19:44:36 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gu9v74+3uat@...&gt;\r\nIn-Reply-To: &lt;gtd3nf+711f@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;jeffreyclune&quot; &lt;jclune@...&gt;\r\nSubject: Re: New Paper on Novelty Search and Adaptive Neural Networks\r\nX-Yahoo-Group-Post: member; u=211599040; y=umK5-Z4ULOo0rhkkdG-xHYUcFzmLzyA5zxfP2tzDDHmywgRxbl4M\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nHello Ken-\n\nI agree with you that, from what I have read and personally exp=\r\nerienced, evolution likes to evolve static, rather than adaptive, heuristic=\r\ns. It seems like your argument is one of induction: evolution tends to evol=\r\nve static heuristics, so there must be a valley, cause otherwise it would e=\r\nvolve adaptive heuristics. That sounds right to me, but it would be very co=\r\nol for us as a community to figure out exactly why there is a valley betwee=\r\nn static heuristics and adaptive ones...and why evolution tends to gravitat=\r\ne toward the static instead of the adaptive peaks. That&#39;s not an easy chall=\r\nenge, but it is probably a worthwhile one. It&#39;s almost like the science is =\r\ncurrently at the point of having an observation of a phenomenon without an =\r\nunderstanding as to why the phenomena occurs. It&#39;ll be hard to solve the pr=\r\noblem unless we understand it. \n\nIf any of you out there have any ideas, it=\r\n would be cool to hear hypotheses. \n\nPS. Apologies for the delayed response=\r\n (to this, and to your other email about the novelty search paper). I am tr=\r\naveling at the moment and can only get on for brief spurts. I look forward =\r\nto properly responding at or after the CEC. \n\n-jeff \n--- In neat@yahoogroup=\r\ns.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Jeff, I see where you&#39;re=\r\n coming from.  First, I am not necessarily saying there is only one valley =\r\nbetween these strategies.  There could be many valleys, or there could be a=\r\n long neutral plateau.\n&gt; \n&gt; But still the question is the same- why should =\r\nthere be one or more valleys or a plateau?\n&gt; \n&gt; A general way to look at th=\r\nis question is just the see that the word &quot;harder&quot; generally means there is=\r\n at least one valley or plateau when you are talking about a search problem=\r\n.  After all, what else would make the problem &quot;hard?&quot;  If here is just a s=\r\ntraight shot up a hill then the problem is easy.  \n&gt; \n&gt; The other aspect of=\r\n hardness is dimensionality.  But both novelty-based and objective-based NE=\r\nAT approach high-dimensionality the same way, i.e. through complexification=\r\n, so that is controlled in the experiment.\n&gt; \n&gt; So if adaptive problems get=\r\n stuck, it is likely because of a valley or plateau.  The plateau idea make=\r\ns sense especially in the context of this type of problem because the fitne=\r\nss function does not recognize differences in behavior that actually matter=\r\n although they appear equally useless.  Such fitness equivalence between ve=\r\nry different behaviors is shown in the paper in one example in figure 5.\n&gt; =\r\n\n&gt; More specifically to adaptation, and this is probably more what you are =\r\nlooking for, you really have to get into the experience of evolving adaptiv=\r\ne neural networks to realize how terribly deceiving they are.  I think most=\r\n people who have worked in this area (and there aren&#39;t that many) would agr=\r\nee from experience that it is an incredibly frustrating area of research be=\r\ncause of evolution&#39;s tendency to find non-adaptive solutions (I realize you=\r\nr ECAL paper is related to this experience as well).  In fact, my guess is =\r\nthat this reason explains why so few people are in this area (i.e. evolving=\r\n adaptive ANNs).  Otherwise, the area is fascinating.  But when you start t=\r\nrying to evolve adaptive networks, you face the endless frustration of tryi=\r\nng to force it to actually use the adaptive capabilities.  It becomes intui=\r\ntively apparent that whatever path there is towards adaptive behavior must =\r\ncross some behaviors that appear entirely useless to the ultimate goal.  Ho=\r\nwever, this kind of argument will probably not appear in a paper because it=\r\n is anecdotal.  But I still believe it, and others who research adaptive AN=\r\nNs have said similar things.\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; \n&gt; --- In neat@...=\r\nm, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hello Ken-\n&gt; &gt; \n&gt; &gt; Thanks for the t=\r\nhought-provoking response. I&#39;d like to think about your\n&gt; &gt; answers a bit b=\r\nefore responding.\n&gt; &gt; \n&gt; &gt; However, if you have a second, I would be intere=\r\nsted to hear your thoughts\n&gt; &gt; on what I originally intended to be my main =\r\nquestion, which is this:\n&gt; &gt; \n&gt; &gt; &gt;&gt; The paper seems to further suggest tha=\r\nt the reason many of these problems\n&gt; &gt; &gt;&gt; are deceptive is because (a) it =\r\nis easier to learn a fixed-heuristic, and\n&gt; &gt; &gt;&gt; then (b) there is a fitnes=\r\ns valley between that fixed-heuristic and the\n&gt; &gt; &gt;&gt; adaptive strategy.\n&gt; &gt;=\r\n &gt;&gt; \n&gt; &gt; &gt;&gt; I agree with (a) (in most cases), but why assume (b)?\n&gt; &gt; \n&gt; &gt; =\r\nMuch of analysis in the paper hinges on the fact that there is actually a\n&gt;=\r\n &gt; fitness valley between a fixed-heuristic and learning. But do we know th=\r\nat\n&gt; &gt; is the case for your experiment? Is it usually the case? Why?\n&gt; &gt; \n&gt;=\r\n &gt; For me, questions on this front are really intriguing and, before your\n&gt;=\r\n &gt; paper, I had not spent much time thinking about them. An understanding o=\r\nf\n&gt; &gt; them might really help our field better evolve adaptive agents.\n&gt; &gt; \n=\r\n&gt; &gt; \n&gt; &gt; Cheers,\n&gt; &gt; Jeff\n&gt; &gt;\n&gt;\n\n\n\n"}}