{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234577593,"authorName":"Oliver Coleman","from":"Oliver Coleman &lt;oliver.coleman@...&gt;","profile":"olivercoleman04","replyTo":"LIST","senderId":"Zu9EJ3ELkLDS9WMDcNJwGRKbR77KtMO7IE-nzg59MDdp6BegslT0lXDqMwgeo13j_7oP5ILZS02-h-1NwnxaT9BosfzTQK6yG_utCZuoNsk","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New paper: Automated Generation of Environments to Test the General Learning Capabilities of AI Agents","postDate":"1398890874","msgId":6288,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBK2R1aW1QQ29VRnkxVzVXRWQrRnJpZ1haWlJ1ckZROVJHeE81LUt4QURaR2dVcExCQUBtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PENBSm42PWRyRU5yMnNoWURmYktaaTNYRWJDeDY0MHBRSDExZmFKdFhoQ1p5dnFKR3dMd0BtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PENBK2R1aW1PMjRzYWtPWFNNVnVxYkVleDgremlCbVFIdmVjb1kza3dBZCt6QUI1Wmt3UUBtYWlsLmdtYWlsLmNvbT4JPENBTnRYaG12dUpHMkxkWXpSRGVXRldpU01HNW1iK3pmQkxWZ0VhQm10dHkyV0ZQaXhFd0BtYWlsLmdtYWlsLmNvbT4JPENBK2R1aW1ONCtZVTMtelN4ZnV1ek9OLVAtcnI4NVBTcHMrMDFDMW5Wa2twSkxjUmR0d0BtYWlsLmdtYWlsLmNvbT4JPENBTnRYaG10eG9oTzRSZmhVYzBCUzRhMmZXMTlKY2pEYmUtOHEwdzlNSDFXalhjbzh6UUBtYWlsLmdtYWlsLmNvbT4JPEY1MkE3MUQ3LURGMzUtNEEzMC1BM0ZDLTk3RjY0NjIwMzg0N0BnbWFpbC5jb20+CTxDQUpuNj1kckVOcjJzaFlEZmJLWmkzWEViQ3g2NDBwUUgxMWZhSnRYaENaeXZxSkd3THdAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":6286,"nextInTopic":6289,"prevInTime":6287,"nextInTime":6289,"topicId":6279,"numMessagesInTopic":11,"msgSnippet":"Hi Vassilis, Yes, we set limits for A-D to [-1,1] and N to [-10,10]. These values were arrived at after some preliminary experiments in parameter tuning. For","rawEmail":"Return-Path: &lt;oliver.coleman@...&gt;\r\nX-Sender: oliver.coleman@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 612 invoked by uid 102); 30 Apr 2014 20:47:55 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m5.grp.bf1.yahoo.com with SMTP; 30 Apr 2014 20:47:55 -0000\r\nX-Received: (qmail 16073 invoked from network); 30 Apr 2014 20:47:55 -0000\r\nX-Received: from unknown (HELO mail-wg0-f50.google.com) (74.125.82.50)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 30 Apr 2014 20:47:55 -0000\r\nX-Received: by mail-wg0-f50.google.com with SMTP id k14so2313707wgh.9\n        for &lt;neat@yahoogroups.com&gt;; Wed, 30 Apr 2014 13:47:54 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.181.12.13 with SMTP id em13mr5508963wid.16.1398890874390;\n Wed, 30 Apr 2014 13:47:54 -0700 (PDT)\r\nX-Received: by 10.194.237.72 with HTTP; Wed, 30 Apr 2014 13:47:54 -0700 (PDT)\r\nIn-Reply-To: &lt;CAJn6=drENr2shYDfbKZi3XEbCx640pQH11faJtXhCZyvqJGwLw@...&gt;\r\nReferences: &lt;CA+duimO24sakOXSMVuqbEex8+ziBmQHvecoY3kwAd+zAB5ZkwQ@...&gt;\n\t&lt;CANtXhmvuJG2LdYzRDeWFWiSMG5mb+zfBLVgEaBmtty2WFPixEw@...&gt;\n\t&lt;CA+duimN4+YU3-zSxfuuzON-P-rr85PSps+01C1nVkkpJLcRdtw@...&gt;\n\t&lt;CANtXhmtxohO4RfhUc0BS4a2fW19JcjDbe-8q0w9MH1WjXco8zQ@...&gt;\n\t&lt;F52A71D7-DF35-4A30-A3FC-97F646203847@...&gt;\n\t&lt;CAJn6=drENr2shYDfbKZi3XEbCx640pQH11faJtXhCZyvqJGwLw@...&gt;\r\nDate: Thu, 1 May 2014 06:47:54 +1000\r\nMessage-ID: &lt;CA+duimPCoUFy1W5WEd+FrigXZZRurFQ9RGxO5-KxADZGgUpLBA@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=f46d043891fba5ccf504f848a9f1\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Oliver Coleman &lt;oliver.coleman@...&gt;\r\nSubject: Re: [neat] New paper: Automated Generation of Environments to Test\n the General Learning Capabilities of AI Agents\r\nX-Yahoo-Group-Post: member; u=234577593; y=WZhMHl2fIio3ib0dC2r694fNg9zoGqFMBcSHZagQtMl3tIOScJ1NQHkIrc64XO2BnPL7qPSsPg\r\nX-Yahoo-Profile: olivercoleman04\r\n\r\n\r\n--f46d043891fba5ccf504f848a9f1\r\nContent-Type: text/plain; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Vassilis,\n\nYes, we set limits for A-D to [-1,1] and N to [-10,10]. These=\r\n values were\narrived at after some preliminary experiments in parameter tun=\r\ning.\n\nFor the CPPN outputs determining the plasticity rule of a connection =\r\nwe use\nlinear outputs and the output with the highest value determines whic=\r\nh rule\nis used. I&#39;m not sure how well a probabilistic approach would work w=\r\nhen\nproducing a phenotype from a genotype, perhaps multiple phenotypes woul=\r\nd\nhave to be evaluated and the fitness aggregated in order to properly\neval=\r\nuate the genotype. But then perhaps speciation methods in GAs achieve\nsomet=\r\nhing similar: assessing multiple phenotypes that are all based on a a\nsimil=\r\nar genotype.\n\nYep, you missed it. ;) From the paper: &quot;Where not specified, =\r\nthe number of\nactions and the length of trials are set to 4 and the number =\r\nof environment\nconfigurations per run is 8.&quot;\n\nCheers,\nOliver\n\nT: 0421 972 9=\r\n53 | E: oliver.coleman@... | W: http://ojcoleman.com\n\n\n\nOn 1 May 2014=\r\n 03:14, Sebastian Risi &lt;sebastian.risi@...&gt; wrote:\n\n&gt;\n&gt;\n&gt; Hi Oliver a=\r\nnd Jeff,\n&gt;\n&gt; Very interesting paper! Good to see that more and more people =\r\nare working\n&gt; on plastic ANNs!\n&gt;\n&gt; I also had one question about the CPPN o=\r\nutputs that determine the type of\n&gt; plasticity. In our original adaptive Hy=\r\nperNEAT paper (Risi&Stanley, 2010)\n&gt; the CPPN directly specifies the values=\r\n for the parameters of Niv&#39;s\n&gt; equation.  Did you also try this approach or=\r\n why did you decide to limit\n&gt; the number of possible rules to four? In you=\r\nr paper you\n&gt; compare it to Ken&#39;s paper on adaptive NEAT and say that &quot;Two =\r\nbenefits of\n&gt; this approach are that it reduces the overall search space...=\r\n&quot;. But I think\n&gt; there is a difference here when we are talking about a dir=\r\nect (NEAT) or an\n&gt; indirect encoding (HyperNEAT).\n&gt;\n&gt; This is the paper on =\r\nAdaptive HyperNEAT I was referring to:\n&gt; Sebastian Risi and Kenneth O. Stan=\r\nley (2010) Indirectly Encoding Neural\n&gt; Plasticity as a Pattern of Local Ru=\r\nles In: Proceedings of the 11th\n&gt; International Conference on Simulation of=\r\n Adaptive Behavior (SAB 2010). New\n&gt; York, NY: Springer.\n&gt; PDF: http://eple=\r\nx.cs.ucf.edu/papers/risi_sab10.pdf\n&gt;\n&gt; Sebastian\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; On Wed, Apr 30, =\r\n2014 at 6:56 PM, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Yes, it=\r\n is clear now. I guess one could also encode the mutation rates in\n&gt;&gt; the g=\r\nenotype, like in Evolution Strategies, and make these parameters\n&gt;&gt; self-ad=\r\naptive.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Self-adaptive mutation rates are a terrible idea! Pleas=\r\ne read this for an\n&gt;&gt; explanation:\n&gt;&gt;\n&gt;&gt; Clune J, Misevic D, Ofria C, Lensk=\r\ni RE, Elena SF, and Sanju=C3=A1n R (2008)\n&gt;&gt; Natural selection fails to opt=\r\nimize mutation rates for long-term\n&gt;&gt; adaptation on rugged fitness landscap=\r\nes. PLoS Computational Biology 4(9):\n&gt;&gt; e1000187.\n&gt;&gt; pdf:\n&gt;&gt; http://jeffclu=\r\nne.com/publications/Clune-EvolvingMutationRates-PLoSCB-2008.pdf\n&gt;&gt;\n&gt;&gt; I hav=\r\ne spent years asking anyone I encounter who advocates self-adaptive\n&gt;&gt; muta=\r\ntion rates for evidence that they work, or even an argument as to why\n&gt;&gt; th=\r\ney could work, and all those conversations have come up empty. Mostly I\n&gt;&gt; =\r\nend up convincing them that self-adaptive mutation rates are a bad idea, or=\r\n\n&gt;&gt; they end up defending something other than self-adaptive mutation rates=\r\n\n&gt;&gt; (e.g. Rechenberg=E2=80=99s 1/5th rule, which is not an example of a sel=\r\nf adaptive\n&gt;&gt; mutation rate: it=E2=80=99s an externally controlled schedule=\r\n).\n&gt;&gt;\n&gt;&gt; For some reason people believe they are a good idea, but without e=\r\nvidence\n&gt;&gt; or intuition. I=E2=80=99m constantly surprised at how persistent=\r\n this errant belief\n&gt;&gt; is. I think it=E2=80=99s because ultimately we want =\r\nto believe that evolution is\n&gt;&gt; good at optimizing everything, and we don=\r\n=E2=80=99t want to have to set parameters,\n&gt;&gt; so we feel like we should jus=\r\nt turn them over to evolution. But we have\n&gt;&gt; lots of evidence of evolution=\r\n being short-sighted (e.g. it doesn=E2=80=99t evolve\n&gt;&gt; modularity when it =\r\nwould help: http://goo.gl/2vzFv).\n&gt;&gt;\n&gt;&gt; Sorry to jump on your side comment =\r\non this issue, but I=E2=80=99m trying to\n&gt;&gt; spread the word in the communit=\r\ny that self-adaptive mutation rates do not\n&gt;&gt; work.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; If I rememb=\r\ner correctly when reading Soltoggio&#39;s paper, he used some\n&gt;&gt; constraints wh=\r\nen evolving the parameters of the plasticity rule and\n&gt;&gt; specifically, A-D =\r\nwere in the range [-1,1] and eta in the range [-100,100].\n&gt;&gt; Did you use an=\r\ny similar constraints?\n&gt;&gt;\n&gt;&gt; Just out of curiosity, what activation functio=\r\nn did you use for these n+1\n&gt;&gt; outputs that correspond to the classes? Did =\r\nyou use a softmax activation\n&gt;&gt; function to interpret the outputs as a prob=\r\nability distribution (and\n&gt;&gt; consequently selected the class probabilistica=\r\nlly) or did you just select\n&gt;&gt; the class based on the highest output among =\r\nthese neurons?\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;  The number of states is independent of the number =\r\nof actions. Different\n&gt;&gt;&gt; actions in state A may all lead to state B but pr=\r\novide different reward\n&gt;&gt;&gt; values.\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt; So, how many states did you us=\r\ne for your simulations? Is it 4 (like in\n&gt;&gt; Figure 1)? I might have missed =\r\nthat when reading the paper, this is why I\n&gt;&gt; asked whether the number of a=\r\nctions correspond to the number of states.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;&gt;  3) On page 3 you s=\r\nay that &quot;the proportion of state transitions that\n&gt;&gt;&gt;&gt; provide a reward val=\r\nue is 0.5&quot;. It is not clear to me, however, what the\n&gt;&gt;&gt;&gt; reward values are=\r\n. Do all transitions that have a reward value have the\n&gt;&gt;&gt;&gt; *same* reward v=\r\nalue (e.g. equal to 1), or does this value vary?\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; For transitio=\r\nns that provide a reward, the reward is selected uniformly\n&gt;&gt;&gt; from the ran=\r\nge [0, 1).\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Also, regarding the &quot;maximum possible reward m=\r\naxRx&quot;, do you mean the\n&gt;&gt;&gt;&gt; &quot;return (sum of rewards) obtained by the optima=\r\nl policy&quot;? If you have the\n&gt;&gt;&gt;&gt; *same* reward value on the transitions (as =\r\nmentioned above) then it is easy\n&gt;&gt;&gt;&gt; to calculate maxRx; if the reward val=\r\nues vary then I guess you have to\n&gt;&gt;&gt;&gt; calculate maxRx using dynamic progra=\r\nmming; the initial state and the trial\n&gt;&gt;&gt;&gt; length matters, especially in t=\r\nhe case where you have 16 actions (states?)\n&gt;&gt;&gt;&gt; and trial length =3D 4.\n&gt;&gt;=\r\n&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; Because the length of trials is relatively small (and the MDPs\n&gt;=\r\n&gt;&gt; deterministic) we calculate the maximum return via a simple brute force\n=\r\n&gt;&gt;&gt; method that tries every possible sequence of actions for the specific t=\r\nrial\n&gt;&gt;&gt; length in question.\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt; Ok, it&#39;s clear now.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;&gt; Yes=\r\n, this is an interesting question in general, and certainly previous\n&gt;&gt;&gt; re=\r\nsults on simple deceptive domains indicate that for delayed-reward MDP\n&gt;&gt;&gt; =\r\nenvironments like you describe (neuro)evolution will likely get stuck if\n&gt;&gt;=\r\n&gt; the search isn&#39;t aided by something like Novelty Search. In our paper we\n=\r\n&gt;&gt;&gt; don&#39;t worry about this issue as we are comparing the performance of the=\r\n\n&gt;&gt;&gt; different neural network models relative to each other and are not\n&gt;&gt;&gt;=\r\n particularly interested in their performance relative to the maximum\n&gt;&gt;&gt; p=\r\nossible (we do scale the results relative to the maximum possible but this\n=\r\n&gt;&gt;&gt; is simply to make aggregation of results easier).\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt; One issue a=\r\nt a time :)\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt; --\n&gt; Dr. Sebastian Risi\n&gt; Assistant Professor=\r\n\n&gt; IT University of Copenhagen, Room 5D08\n&gt; Rued Langgaards Vej 7, 2300 Cop=\r\nenhagen, Denmark\n&gt; email: sebastian.risi@..., web: www.sebastianrisi.=\r\ncom\n&gt; mobile: +45-50250355, office: +45-7218-5127\n&gt;\n&gt;  \n&gt;\n\r\n--f46d043891fba5ccf504f848a9f1\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;Hi Vassilis,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Yes, we set limits for A-D=\r\n to [-1,1] and N to [-10,10]. These values were arrived at after some preli=\r\nminary experiments in parameter tuning.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;For the CP=\r\nPN outputs determining the plasticity rule of a connection we use linear ou=\r\ntputs and the output with the highest value determines which rule is used. =\r\nI&#39;m not sure how well a probabilistic approach would work when producin=\r\ng a phenotype from a genotype, perhaps multiple phenotypes would have to be=\r\n evaluated and the fitness aggregated in order to properly evaluate the gen=\r\notype. But then perhaps speciation methods in GAs achieve something similar=\r\n: assessing multiple phenotypes that are all based on a a similar genotype.=\r\n&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Yep, you missed it. ;) From the paper: &quot;Whe=\r\nre not specified, the number of actions and the length of trials are set to=\r\n 4 and the number of environment configurations per run is 8.&quot;&lt;/div&gt;&lt;d=\r\niv&gt;\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Cheers,=\r\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;Oliver&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;di=\r\nv&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;T: 0421 972 953 |=C2=A0E: &lt;a href=3D=\r\n&quot;mailto:oliver.coleman@...&quot; target=3D&quot;_blank&quot;&gt;oliver.coleman@...=\r\nm&lt;/a&gt;=C2=A0|=C2=A0W:=C2=A0&lt;a href=3D&quot;http://ojcoleman.com&quot; target=3D&quot;_blank=\r\n&quot;&gt;http://ojcoleman.com&lt;/a&gt;&lt;br&gt;\n&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;=\r\n/div&gt;&lt;/div&gt;\n&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On 1 May 2014 03:14, Sebasti=\r\nan Risi &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:sebastian.risi@...&quot; t=\r\narget=3D&quot;_blank&quot;&gt;sebastian.risi@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockqu=\r\note class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0px 0.8ex;border-left-wid=\r\nth:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-l=\r\neft:1ex&quot;&gt;\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n \n&lt;div style&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;=\r\ndiv&gt;\n\n\n    &lt;div&gt;\n      \n      \n      &lt;p&gt;&lt;/p&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;Hi Oliver=\r\n and Jeff,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Very interesting paper! Good to see tha=\r\nt more and more people are working on plastic ANNs!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;I a=\r\nlso had one question about the CPPN outputs that determine the type of plas=\r\nticity. In our original adaptive HyperNEAT paper (Risi&amp;Stanley, 2010) t=\r\nhe CPPN directly specifies the values for the parameters of Niv&#39;s equat=\r\nion. =C2=A0Did you also try this approach or why did you decide to limit th=\r\ne number of possible rules to four? In your paper you&lt;div&gt;\n\ncompare it to K=\r\nen&#39;s paper on adaptive NEAT and say that &quot;Two benefits of this app=\r\nroach are that it reduces the overall search space...&quot;. But I think th=\r\nere is a difference here when we are talking about a direct (NEAT) or an in=\r\ndirect encoding (HyperNEAT).&lt;/div&gt;\n\n&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is t=\r\nhe paper on Adaptive HyperNEAT I was referring to:&lt;/div&gt;&lt;div&gt;&lt;div&gt;Sebastian=\r\n Risi and Kenneth O. Stanley (2010) Indirectly Encoding Neural Plasticity a=\r\ns a Pattern of Local Rules In: Proceedings of the 11th International Confer=\r\nence on Simulation of Adaptive Behavior (SAB 2010). New York, NY: Springer.=\r\n&lt;/div&gt;\n\n&lt;div&gt;PDF: &lt;a href=3D&quot;http://eplex.cs.ucf.edu/papers/risi_sab10.pdf&quot;=\r\n target=3D&quot;_blank&quot;&gt;http://eplex.cs.ucf.edu/papers/risi_sab10.pdf&lt;/a&gt;&lt;/div&gt;&lt;=\r\n/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sebastian&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div=\r\n&gt;&lt;/div&gt;\n&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;div&gt;&lt;div class=3D&quot;h5&quot;&gt;\n&lt;br&gt;&lt;br&gt;&lt;d=\r\niv class=3D&quot;gmail_quote&quot;&gt;On Wed, Apr 30, 2014 at 6:56 PM, Jeff Clune &lt;span =\r\ndir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:jclune@...&quot; target=3D&quot;_blank&quot;&gt;jclun=\r\ne@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; styl=\r\ne=3D&quot;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-s=\r\ntyle:solid&quot;&gt;\n\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n\n\n\n\n\n \n&lt;div&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;di=\r\nv&gt;\n\n\n    &lt;div&gt;\n      \n      \n      &lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;blockquote type=3D=\r\n&quot;cite&quot;&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;&lt;div&gt;&lt;div class=3D&quot;gmail_e=\r\nxtra&quot;&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;&lt;div&gt;Yes, it is clear now. I guess one cou=\r\nld also encode the mutation rates in the genotype, like in Evolution Strate=\r\ngies, and make these parameters self-adaptive. &lt;/div&gt;\n\n&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/=\r\ndiv&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/di=\r\nv&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=3D&quot;font-family:Times-Roman&quot;&gt;Self-adaptive mutation =\r\nrates are a terrible idea! Please read this for an explanation:=C2=A0&lt;/div&gt;=\r\n\n\n&lt;div style=3D&quot;font-family:Times-Roman&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;font-famil=\r\ny:Times-Roman&quot;&gt;Clune J, Misevic D, Ofria C, Lenski RE, Elena SF, and Sanju=\r\n=C3=A1n R (2008)=C2=A0&lt;br&gt;Natural selection fails to optimize mutation rate=\r\ns for long-term adaptation on rugged fitness landscapes. PLoS Computational=\r\n Biology 4(9): e1000187.=C2=A0&lt;/div&gt;\n\n&lt;div style=3D&quot;font-family:Times-Roman=\r\n&quot;&gt;pdf:=C2=A0&lt;a href=3D&quot;http://jeffclune.com/publications/Clune-EvolvingMuta=\r\ntionRates-PLoSCB-2008.pdf&quot; target=3D&quot;_blank&quot;&gt;http://jeffclune.com/publicati=\r\nons/Clune-EvolvingMutationRates-PLoSCB-2008.pdf&lt;/a&gt;&lt;/div&gt;\n\n&lt;div style=3D&quot;fo=\r\nnt-family:Times-Roman&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;font-family:Times-Roman&quot;&gt;I h=\r\nave spent years asking anyone I encounter who advocates self-adaptive mutat=\r\nion rates for evidence that they work, or even an argument as to why they c=\r\nould work, and all those conversations have come up empty. Mostly I end up =\r\nconvincing them that self-adaptive mutation rates are a bad idea, or they e=\r\nnd up defending something other than self-adaptive mutation rates (e.g. Rec=\r\nhenberg=E2=80=99s 1/5th rule, which is not an example of a self adaptive mu=\r\ntation rate: it=E2=80=99s an externally controlled schedule).=C2=A0&lt;/div&gt;\n\n=\r\n&lt;div style=3D&quot;font-family:Times-Roman&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=3D&quot;font-family:=\r\nTimes-Roman&quot;&gt;For some reason people believe they are a good idea, but witho=\r\nut evidence or intuition. I=E2=80=99m constantly surprised at how persisten=\r\nt this errant belief is. I think it=E2=80=99s because ultimately we want to=\r\n believe that evolution is good at optimizing everything, and we don=E2=80=\r\n=99t want to have to set parameters, so we feel like we should just turn th=\r\nem over to evolution. But we have lots of evidence of evolution being short=\r\n-sighted (e.g. it doesn=E2=80=99t evolve modularity when it would help:=C2=\r\n=A0&lt;a href=3D&quot;http://goo.gl/2vzFv&quot; target=3D&quot;_blank&quot;&gt;http://goo.gl/2vzFv&lt;/a=\r\n&gt;).=C2=A0&lt;/div&gt;\n\n&lt;div style=3D&quot;font-family:Times-Roman&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div styl=\r\ne=3D&quot;font-family:Times-Roman&quot;&gt;Sorry to jump on your side comment on this is=\r\nsue, but I=E2=80=99m trying to spread the word in the community that self-a=\r\ndaptive mutation rates do not work.=C2=A0&lt;/div&gt;\n\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;=\r\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div dir=\r\n=3D&quot;ltr&quot;&gt;&lt;div&gt;&lt;div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;&lt;d=\r\niv&gt;If I remember correctly when reading Soltoggio&#39;s paper, he used some=\r\n constraints when evolving the parameters of the plasticity rule and specif=\r\nically, A-D were in the range [-1,1] and eta in the range [-100,100]. Did y=\r\nou use any similar constraints?=C2=A0&lt;/div&gt;\n\n\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Just out =\r\nof curiosity, what activation function did you use for these n+1 outputs th=\r\nat correspond to the classes? Did you use a softmax activation function to =\r\ninterpret the outputs as a probability distribution (and consequently selec=\r\nted the class probabilistically) or did you just select the class based on =\r\nthe highest output among these neurons?=C2=A0&lt;/div&gt;\n\n\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;\n&lt;div&gt;=\r\n&lt;br&gt;&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0px 0.8=\r\nex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-sty=\r\nle:solid&quot;&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;\n&lt;div class=3D&quot;gmail_=\r\nquote&quot;&gt;\n&lt;div&gt;The number of states is independent of the number of actions. =\r\nDifferent actions in state A may all lead to state B but provide different =\r\nreward values.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;\n\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So=\r\n, how many states did you use for your simulations? Is it 4 (like in Figure=\r\n 1)? I might have missed that when reading the paper, this is why I asked w=\r\nhether the number of actions correspond to the number of states.&lt;/div&gt;\n\n\n\n&lt;=\r\ndiv&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;=C2=A0=C2=A0&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; styl=\r\ne=3D&quot;margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(2=\r\n04,204,204);border-left-style:solid&quot;&gt;&lt;div dir=3D&quot;ltr&quot;&gt;\n&lt;div class=3D&quot;gmail_=\r\nextra&quot;&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;\n&lt;div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; s=\r\ntyle=3D&quot;margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rg=\r\nb(204,204,204);border-left-style:solid&quot;&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;3)=\r\n On page 3 you say that &quot;the proportion of state transitions that prov=\r\nide a reward value is 0.5&quot;. It is not clear to me, however, what the r=\r\neward values are. Do all transitions that have a reward value have the *sam=\r\ne* reward value (e.g. equal to 1), or does this value vary?&lt;/div&gt;\n\n\n\n\n\n&lt;/di=\r\nv&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;For transitions that provide a rew=\r\nard, the reward is selected uniformly from the range [0, 1).&lt;/div&gt;&lt;div&gt;&lt;div=\r\n&gt;=C2=A0&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px 0px =\r\n0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-=\r\nstyle:solid&quot;&gt;\n\n\n\n\n\n&lt;div&gt;&lt;div dir=3D&quot;ltr&quot;&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Also, regardi=\r\nng the &quot;maximum possible reward maxRx&quot;, do you mean the &quot;ret=\r\nurn (sum of rewards) obtained by the optimal policy&quot;? If you have the =\r\n*same* reward value on the transitions (as mentioned above) then it is easy=\r\n to calculate=C2=A0maxRx; if the reward=C2=A0values vary then I guess you h=\r\nave to calculate=C2=A0maxRx=C2=A0using dynamic programming; the initial sta=\r\nte and the trial length=C2=A0matters, especially in the case where you have=\r\n 16 actions (states?) and trial length =3D 4.&lt;/div&gt;\n\n\n\n\n\n&lt;/div&gt;&lt;/div&gt;&lt;/bloc=\r\nkquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;Because the length of trials is relatively=\r\n small (and the MDPs deterministic) we calculate the maximum return via a s=\r\nimple brute force method that tries every possible sequence of actions for =\r\nthe specific trial length in question.&lt;/div&gt;\n\n\n\n&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockqu=\r\note&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Ok, it&#39;s clear now.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;=\r\n=C2=A0=C2=A0&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0px 0px=\r\n 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-=\r\nleft-style:solid&quot;&gt;\n\n\n\n&lt;div&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;div=\r\n class=3D&quot;gmail_quote&quot;&gt;&lt;div&gt;Yes, this is an interesting question in general=\r\n, and certainly previous results on simple deceptive domains indicate that =\r\nfor delayed-reward MDP environments like you describe (neuro)evolution will=\r\n likely get stuck if the search isn&#39;t aided by something like Novelty S=\r\nearch. In our paper we don&#39;t worry about this issue as we are comparing=\r\n the performance of the different neural network models relative to each ot=\r\nher and are not particularly interested in their performance relative to th=\r\ne maximum possible (we do scale the results relative to the maximum possibl=\r\ne but this is simply to make aggregation of results easier).&lt;/div&gt;\n\n\n\n&lt;/div=\r\n&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;One issue at a time :)&lt;=\r\n/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;\n\n    &lt;/di=\r\nv&gt;\n     \n\n    \n\n&lt;/div&gt;\n\n\n\n\n\n&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;p&gt;&lt;/p=\r\n&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;div style=3D&quot;color:rgb(255,255,255);min-heig=\r\nht:0px&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;br =\r\nclear=3D&quot;all&quot;&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;-- &lt;br&gt;&lt;div dir=3D&quot;ltr&quot;&gt;Dr. Sebast=\r\nian Risi&lt;br&gt;Assistant Professor=C2=A0&lt;br&gt;IT University of Copenhagen, Room =\r\n5D08&lt;br&gt;Rued Langgaards Vej 7, 2300 Copenhagen, Denmark&lt;br&gt;\nemail: &lt;a href=\r\n=3D&quot;mailto:sebastian.risi@...&quot; target=3D&quot;_blank&quot;&gt;sebastian.risi@gmail=\r\n.com&lt;/a&gt;, web:=C2=A0&lt;a href=3D&quot;http://www.sebastianrisi.com&quot; target=3D&quot;_bla=\r\nnk&quot;&gt;www.sebastianrisi.com&lt;/a&gt;&lt;div&gt;\nmobile: &lt;a href=3D&quot;tel:%2B45-50250355&quot; v=\r\nalue=3D&quot;+4550250355&quot; target=3D&quot;_blank&quot;&gt;+45-50250355&lt;/a&gt;, office: &lt;a href=3D=\r\n&quot;tel:%2B45-7218-5127&quot; value=3D&quot;+4572185127&quot; target=3D&quot;_blank&quot;&gt;+45-7218-5127=\r\n&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;/div&gt;\n&lt;p&gt;&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;div style=\r\n=3D&quot;color:rgb(255,255,255);min-height:0px&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/bl=\r\nockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\n\r\n--f46d043891fba5ccf504f848a9f1--\r\n\n"}}