{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"1lAm5f5nb149DDsMrAT39M1x8PnZh9eYltCUn11NkwlBIcyXFm2gI2SvFRNRoWTqa6eF5cQfhFT3mvf4Fflb0jpYXafcXBQTbA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Performance Sensitivity to float precision","postDate":"1095891079","msgId":1586,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxNTFGODg3LjIwMzAyMDJAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PDUuMS4wLjE0LjAuMjAwNDA5MjEyMTQzMzcuMDIxNGZiZDBAcG9wLm1haWwueWFob28uY28udWs+","referencesHeader":"PDYuMS4yLjAuMC4yMDA0MDkyMTEwNTgxMS4wMjU4YzAwOEBwb3AubWFpbC55YWhvby5jby51az4gPDIwMDQwOTIwMTcwMzA0LjY5MTMyLnFtYWlsQHdlYjYwODA3Lm1haWwueWFob28uY29tPiA8NDE0RjQ1QkYuODAxMDQwM0Bkc2wucGlwZXguY29tPiA8Ni4xLjIuMC4wLjIwMDQwOTIxMTA1ODExLjAyNThjMDA4QHBvcC5tYWlsLnlhaG9vLmNvLnVrPiA8NS4xLjAuMTQuMC4yMDA0MDkyMTIxNDMzNy4wMjE0ZmJkMEBwb3AubWFpbC55YWhvby5jby51az4="},"prevInTopic":1583,"nextInTopic":1588,"prevInTime":1585,"nextInTime":1587,"topicId":1555,"numMessagesInTopic":16,"msgSnippet":"... Ok, slight miscommunication. As it happens the core of SharpNEAT should run on the dotnet compact framework, in fact it s possible the whole project will","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 79521 invoked from network); 22 Sep 2004 22:11:24 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m10.grp.scd.yahoo.com with QMQP; 22 Sep 2004 22:11:24 -0000\r\nReceived: from unknown (HELO shockwave.systems.pipex.net) (62.241.160.9)\n  by mta1.grp.scd.yahoo.com with SMTP; 22 Sep 2004 22:11:24 -0000\r\nReceived: from [10.0.0.10] (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby shockwave.systems.pipex.net (Postfix) with ESMTP id 10DC11C000DA\n\tfor &lt;neat@yahoogroups.com&gt;; Wed, 22 Sep 2004 23:11:20 +0100 (BST)\r\nMessage-ID: &lt;4151F887.2030202@...&gt;\r\nDate: Wed, 22 Sep 2004 23:11:19 +0100\r\nUser-Agent: Mozilla Thunderbird 0.7.1 (Windows/20040626)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;6.1.2.0.0.20040921105811.0258c008@...&gt; &lt;20040920170304.69132.qmail@...&gt; &lt;414F45BF.8010403@...&gt; &lt;6.1.2.0.0.20040921105811.0258c008@...&gt; &lt;5.1.0.14.0.20040921214337.0214fbd0@...&gt;\r\nIn-Reply-To: &lt;5.1.0.14.0.20040921214337.0214fbd0@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.160.9\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Performance Sensitivity to float precision\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nIan Badcoe wrote:\n\n&gt;At 21:25 21/09/2004 +0100, you wrote:\n&gt;  \n&gt;\n&gt;&gt;Maybe in the big power hungry desktop CPU&#39;s. But what about cheap lower\n&gt;&gt;power CPU&#39;s with no built in FPU? Surely they can gain a lot from using\n&gt;&gt;integers directly and not invoking some software routines to do floating\n&gt;&gt;point?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;This is true, but I was talking about your SharpNEAT comment, which I \n&gt;assume is only used on PCs?  There are no currently credible PC CPUs \n&gt;without at least 3 built in floating point units.\n&gt;\n&gt;For embedded systems the game is completely different.\n&gt;  \n&gt;\nOk, slight miscommunication. As it happens the core of SharpNEAT should \nrun on the dotnet compact framework, in fact it&#39;s possible the whole \nproject will run on the compact framework so it could conceivably be run \non embedded systems. I can&#39;t see any point, but it could :)   On the \nother hand it *might* be useful to take an integer based network class \nout of the sharpneat project and use that in an embedded application. To \nbe honest though if you were trying to squeeze out extra performance you \nwouldn&#39;t be running code in the dotnet compact environment - hand \noptimised C/C++ would be more sensible.\n\nSo an integer based network class has only academic/curiosity value \nwithin SharpNEAT, but the technique itself has potential useful \napplications.\n\n\n&gt;&gt;&gt;You can do it by writing a fixed point class to implement the arithmetic,\n&gt;&gt;&gt;and substituting that for &quot;float&quot; in your original code.\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;Yeh but that option is already available by way of existing floating\n&gt;&gt;point arithmetic libraries.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Did you mean to say &quot;existing _fixed_ point arithmetic libraries&quot;?\n&gt;  \n&gt;\nExisting libraries that implement floating point arithmetic in software \nfor FPU-less CPU&#39;s, which is what you were suggesting. As I understand \nit there are highly optimised libraries available, but they are still \ngoing to be slow compared to having an FPU or re-arranging your code to \ndo all the maths using integers.\n\n\n&gt;--\n&gt;\n&gt;[snip on big numbers]\n&gt;\n&gt;That working out is all _much_ easier if you do it in hex...\n&gt;\n&gt;range +/- 0x7FFFFFFF\n&gt;\n&gt;0x400 inputs on a node\n&gt;\n&gt;each node input is 0x80000000 / 0x400 = +/- 0x200000\n&gt;\n&gt;(can overflow if everything maxes out so cut the max nodes to 0x3FF)\n&gt;\n&gt;Node input = node output * weight = +/- 0x200000\n&gt;\n&gt;That splits nicely as 0x400 * 0x800 so call the weights +/- 0x400 and the \n&gt;output values +/- 0x800\n&gt;\n&gt;Personally I would probably take 8-fold less node inputs and bring the \n&gt;weights and outputs both up to +/- 0x1000...\n&gt;  \n&gt;\nOk yep, so lets try and wrap this one up:\n\nweight range: +/-0x1000\nactivation fn input range: +/- 0x7FFFFFFF\nactivation fn output range: +/- 0x1000\n\nThis allows us at *least*  0x80000000 / 0x1000000 = 0x80 (128) incoming \nconnections per node before the possibility of an overflow, which we can \nsimple cap.\n\n&gt;function.  That function will inevitably discard some information so it \n&gt;could shift the value down and then look up the result:\n&gt;\n&gt;out = LookUp[sum &gt;&gt; 16);        // 0x10000 = 65536 entry look up\n&gt;\n&gt;or it could try for some sort of piece-meal approach similar to John&#39;s...\n&gt;\n&gt;  \n&gt;\nIndeed, both techniques have their pros and cons dependent on the \noperating environment. But for completeness here is a modified version \nof Mitchel&#39;s sigmoid approximation function:\n\nif(x&lt;0)\n{\n    int tmp = (x&gt;&gt;19) + 0x1000;\n    return (tmp*tmp)&gt;&gt;13;\n}\nelse\n{\n    int tmp =  (x&gt;&gt;19) - 0x1000;\n    return 0x1000 - ((tmp*tmp)&gt;&gt;13);\n}\n\n\nThis has quite gradual slope BTW.\n\n&gt;that&#39;s looking quite workable, actually...\n&gt;\n&gt;and far less complex than I imagined...\n&gt;  \n&gt;\nYeh, I might have a go at coding this just out of curiosity -  Will the \nloss of precision have a noticable effect on experiments and will the \nnetwork code run any faster on an athlon, which I think has both 3 \ninteger units and 3 floating point. To be fair on the experiments I \nshould steepen that activation function a tab or use the lookup table \napproach.\n\nColin.\n\n"}}