{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"05aRDRj_IGcNODEf6H9PJvXsG34UxpNskdhVPR7RHnoe4hJkxhJI1ZmZLffuWNfh9GZOS9svi1wpkTT363wWyRHSTCcubr4atA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Performance Sensitivity to float precision","postDate":"1095798332","msgId":1579,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxNTA4RTNDLjcwNjAwMDJAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PDYuMS4yLjAuMC4yMDA0MDkyMTEwNTgxMS4wMjU4YzAwOEBwb3AubWFpbC55YWhvby5jby51az4=","referencesHeader":"PDIwMDQwOTIwMTcwMzA0LjY5MTMyLnFtYWlsQHdlYjYwODA3Lm1haWwueWFob28uY29tPiA8NDE0RjQ1QkYuODAxMDQwM0Bkc2wucGlwZXguY29tPiA8Ni4xLjIuMC4wLjIwMDQwOTIxMTA1ODExLjAyNThjMDA4QHBvcC5tYWlsLnlhaG9vLmNvLnVrPg=="},"prevInTopic":1576,"nextInTopic":1580,"prevInTime":1578,"nextInTime":1580,"topicId":1555,"numMessagesInTopic":16,"msgSnippet":"... Maybe in the big power hungry desktop CPU s. But what about cheap lower power CPU s with no built in FPU? Surely they can gain a lot from using integers","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 50424 invoked from network); 21 Sep 2004 20:25:47 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m19.grp.scd.yahoo.com with QMQP; 21 Sep 2004 20:25:47 -0000\r\nReceived: from unknown (HELO pengo.systems.pipex.net) (62.241.160.193)\n  by mta4.grp.scd.yahoo.com with SMTP; 21 Sep 2004 20:25:45 -0000\r\nReceived: from [10.0.0.10] (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby pengo.systems.pipex.net (Postfix) with ESMTP id DEA514C002C6\n\tfor &lt;neat@yahoogroups.com&gt;; Tue, 21 Sep 2004 21:25:33 +0100 (BST)\r\nMessage-ID: &lt;41508E3C.7060002@...&gt;\r\nDate: Tue, 21 Sep 2004 21:25:32 +0100\r\nUser-Agent: Mozilla Thunderbird 0.7.1 (Windows/20040626)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;20040920170304.69132.qmail@...&gt; &lt;414F45BF.8010403@...&gt; &lt;6.1.2.0.0.20040921105811.0258c008@...&gt;\r\nIn-Reply-To: &lt;6.1.2.0.0.20040921105811.0258c008@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.160.193\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Performance Sensitivity to float precision\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nIan Badcoe wrote:\n\n&gt;At 22:03 20/09/2004, you wrote:\n&gt;  \n&gt;\n&gt;&gt;I agree with the consensus here that double precision floats are\n&gt;&gt;probably excessive for most problems. I have switched the neural network\n&gt;&gt;code in SharpNEAT over to floats to improve performance and I have not\n&gt;&gt;noticed a detrimental effect in any of my  experiments to date. In fact\n&gt;&gt;I have considered implementing a neural net class that operates on\n&gt;&gt;integers to get yet more performance. So although I know of no research\n&gt;&gt;as such, my best guess would be that floats are fine.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Switching to fixed-point integer maths isn&#39;t the automatically the huge \n&gt;speed increase it once was.\n&gt;  \n&gt;\nMaybe in the big power hungry desktop CPU&#39;s. But what about cheap lower \npower CPU&#39;s with no built in FPU? Surely they can gain a lot from using \nintegers directly and not invoking some software routines to do floating \npoint?\n\n&gt;e.g. fixed point maths involves a lot of extra shifts and you can&#39;t use the \n&gt;standard maths library routines without having to convert the data and lose \n&gt;you efficiency gain\n&gt;  \n&gt;\nOk but in the neural net code itself we can avoid calling trig functions \nand the like by using alternative activation functions.\n\n\n&gt;You can do it by writing a fixed point class to implement the arithmetic, \n&gt;and substituting that for &quot;float&quot; in your original code.\n&gt;  \n&gt;\nYeh but that option is already available by way of existing floating \npoint arithmetic libraries.\n\n&gt;If you do what to do it, I&#39;ll help out if you like, I&#39;ve done it before \n&gt;(obviously not in C# :)\n&gt;  \n&gt;\nI think it was Steve who was asking originally. I *am* interested in \ntrying it out, but not before a lot of other things :) I agree with you \nthat the benefit with mainstream CPUs is probably not so great, but an \nembedded CPU with no FPU might gain a lot.\n\nWell Ok lets give it a try. The standard model most of are using is a \nnetwork with neurons that have an unlimited input range, and output \nbetween 0.0 and 1.0, and weights usually between -5.0 and 5.0. Let me \ntry and map these figures to integers assuming the use of a signed 32bit \ninteger throughout:\n\n32bit int has range +-2,147,483,647\n\nThe first problem we are going to encounter is that we have a fixed \nrange of values (fixed point) and therefore multiplying a lot of signals \nand weights and then accumulating their total at a neuron could easily \ncause an integer overflow if we&#39;re not careful. The main problem we have \nis that there is no upper limit on the number of  incoming connections a \nneuron can have, so we must arbitrarily pick a maximum number of \nincoming connections that we will expect to see in a network. I choose \n1000 as a basis for this example. If there are more than 1000 and each \nconnection supplies the maximum possible signal then we can simply cap \nthe value.\n\n\nOk so here&#39;s one possible system:\n\nWe allow the full range of an int to be applied to the activation function.\nActivation Fn in:     +- 2,147,483,647 \n\nWe must generate a much smaller range on the output because it will be \nmultiplied by a weight and the total accumulated at the target neuron.\nActivation Fn out:   +- 1,465\n\n\nWeight range: +- 1465\n\n\n\nSo a single incoming connection&#39;s max value will be 1465*1465 = 2,146,225.\nThis allows for up to 1000 signals with the maxmum value, many more with \na lesser value...\n\n1000*2,146,225 = 2,146,225,000\n\n (ok so about 10^6 short of overflow here, so there is still some leeway).\n\n\nAll we need now is a function that describes a sigmoid over the x range \n+-2^16 and y range 0 to 1465. At the very least we can do this with a \nlookup table as described by Emyr recently. Although that might not be \nthe best approach in an embedded system with limited memory and possibly \na slow memory bus.\n\n\nColin\n\n\n\n\n\n\n\n\n\n\n\n"}}