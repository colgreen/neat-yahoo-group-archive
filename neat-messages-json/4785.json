{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"2CvrBrC0PqDUc5_VL29ozkqPGtSMyIihVknAjQlgEhH-24WMRPpxIJGA-rPT-ji_aA5Amy0kOKW2dGxVbBAm-ZTo-nXE4Dr44CuONi3eUwg2","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HybrID: A Hybridization of Indirect and Direct Encodings for Evolutionary Computation","postDate":"1248650955","msgId":4785,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGg0aW9zYitobXJ0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PEM2OEY2NzAxLjJCNzg4JWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":4784,"nextInTopic":4786,"prevInTime":4784,"nextInTime":4786,"topicId":4772,"numMessagesInTopic":19,"msgSnippet":"Jeff knows some of my thoughts on the issue of regularity vs. irregularity in neuroevolution and also that I recognize the nice results with HybrID, so this","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 4927 invoked from network); 26 Jul 2009 23:29:29 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m8.grp.re1.yahoo.com with QMQP; 26 Jul 2009 23:29:29 -0000\r\nX-Received: from unknown (HELO n44d.bullet.mail.sp1.yahoo.com) (66.163.169.158)\n  by mta2.grp.re1.yahoo.com with SMTP; 26 Jul 2009 23:29:29 -0000\r\nX-Received: from [69.147.65.174] by n44.bullet.mail.sp1.yahoo.com with NNFMP; 26 Jul 2009 23:29:16 -0000\r\nX-Received: from [98.137.35.15] by t12.bullet.mail.sp1.yahoo.com with NNFMP; 26 Jul 2009 23:29:16 -0000\r\nDate: Sun, 26 Jul 2009 23:29:15 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;h4iosb+hmrt@...&gt;\r\nIn-Reply-To: &lt;C68F6701.2B788%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: HybrID: A Hybridization of Indirect and Direct Encodings for Evolutionary Computation\r\nX-Yahoo-Group-Post: member; u=54567749; y=pYh1u_GwJwmU_0DGekagFKjiWYRMnPWE3buPack7y7UbRmFUS_-H\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nJeff knows some of my thoughts on the issue of regularity vs. irregularity =\r\nin neuroevolution and also that I recognize the nice results with HybrID, s=\r\no this post is just my attempt to put out some thoughts on this important i=\r\nssue, rather than a challenge to the HybrID concept.  Basically, HybrID cre=\r\nates a good opportunity to discuss these issues.\n\nTaking a long term view, =\r\nwhat I would like to question is the idea that there is a problem with a me=\r\nthod that has &quot;trouble&quot; discovering arbitrary irregularities.  It important=\r\n to note that HyperNEAT has no trouble representing &quot;irregularity&quot; in the g=\r\neneral sense.  In my 2007 paper on CPPNs (http://eplex.cs.ucf.edu/hyperNEAT=\r\npage/HyperNEAT.html), I included explicit examples of irregularities and ho=\r\nw easy they are to represent.  For example, see the &quot;Warped Symmetry&quot; panel=\r\n in figure 9 on page 24.  So I think the issue is definitively *not* that H=\r\nyperNEAT (or more specifically, CPPNs with a certain set of activation func=\r\ntions) has trouble representing or discovering irregularity, but that it ha=\r\ns trouble discovering *particular* irregularities.\n\nYet such trouble may ac=\r\ntually be a good thing.  If it were too easy to represent any arbitrary irr=\r\negularity, then you would have an encoding that is poor at discovering regu=\r\nlarities.  So this argument could go in circles.  But it&#39;s important to rec=\r\nognize that we are looking at a trade-off.  Nature faces the same trade-off=\r\n.  It is difficult to say for sure whether DNA is biased towards regularity=\r\n or irregularity, but I would guess looking at biological organisms that re=\r\ngularity reigns, and that irregularities are of certain *types*, that is, y=\r\nou would be hard pressed to &quot;breed&quot; a human with a hand protruding from his=\r\n or her right knee, no matter how many generations were available.  Yet we =\r\nsee things like the heart on one side, right-handedness, etc.  But those do=\r\n not mean that the encoding can simply bend to the arbitrary whims of a ran=\r\ndom target.  \n\nSo I think what you need if you want to evolve a really inte=\r\nresting artifact is not an encoding that is entirely flexible with respect =\r\nto irregularity.  If a particular encoding would often fail to meet ad hoc =\r\nirregular targets, that is probably a sign of its long term potential, rath=\r\ner something we&#39;d want to fix.  If we did &quot;fix&quot; it, we&#39;d be heading back to=\r\nwards the chaos and entropy of direct encoding.\n\nTherefore, we should be ca=\r\nreful about whether we consider difficulty achieving specific irregularitie=\r\ns a problem to solve or an asset in the long run.  Certainly there should a=\r\nn ability to create &quot;repetition with variation,&quot; but CPPNs (as well as natu=\r\nre) exhibit that consistently.  So it&#39;s important to be careful what we con=\r\nsider to be a pathology versus an asset.\n\nThat said, HybrID is a good pract=\r\nical idea.  It is clear that in some problems it is just what is needed to =\r\nperfect solutions with particular irregular needs.  Of course, when the net=\r\nworks become really big, e.g. with millions of connections, HybrID might be=\r\ngin to lose some of its ability to cope with the very high dimensionality, =\r\neven if it is just tweaking on top of preexisting regularities encoded by t=\r\nhe CPPN.  Nevertheless, at lower dimensionalities, as Jeff&#39;s paper shows, i=\r\nt can really help.\n\nIn any case, my main point is that the issue of what we=\r\n actually *want* in an encoding with respect to regularity and irregularity=\r\n is quite subtle and deserves considered contemplation.  The CPPN with the =\r\nusual set of activation functions may not ultimately be the very best repre=\r\nsentation to bias towards what we want, but if there is something better, i=\r\nt would not be better by virtue of simply being able to capture irregularit=\r\nies more easily.  Rather, any advantage would be gained through a much more=\r\n subtle argument, which likely refers to both regularities and irregulariti=\r\nes of certain types, and why they are appropriate for the kinds of neural s=\r\ntructures we hope to evolve.\n\nken\n\n--- In neat@yahoogroups.com, Jeff Clune =\r\n&lt;jclune@...&gt; wrote:\n&gt;\n&gt; Hello all-\n&gt; \n&gt; Recently I have shown that HyperNEA=\r\nT has trouble making exceptions to the\n&gt; rules it discovers (Clune et al. P=\r\nPSN 2008). I would like to introduce a new\n&gt; paper that will be at ECAL 200=\r\n9 which shows one way to remedy this problem:\n&gt; combining a generative enco=\r\nding (HyperNEAT in this case) with a direct\n&gt; encoding (FT-NEAT in this cas=\r\ne).\n&gt; \n&gt; The resulting algorithm, which we call HybrID (Hybridization of In=\r\ndirect and\n&gt; Direct Encodings), combines the best of both encodings, and ou=\r\ntperformed\n&gt; HyperNEAT on all of the problems we tested it on, sometimes by=\r\n as much as\n&gt; 40%. \n&gt; \n&gt; I&#39;d be really interested to hear what the people o=\r\nn this list think of the\n&gt; work. For example, I&#39;ll bet there are interestin=\r\ng ways to remedy the problem\n&gt; of making exceptions within HyperNEAT, and i=\r\nt would be interesting for us as\n&gt; a community to explore them. But in the =\r\ninterim, if any of you are deploying\n&gt; HyperNEAT on some task and want a po=\r\nssible performance boost, HybrID is easy\n&gt; to implement and may lead to a s=\r\nignificant improvement.\n&gt; \n&gt; Here is a link to the paper:\n&gt; https://www.msu=\r\n.edu/~jclune/webfiles/publications/Clune-HybrID-ECAL-2009.pdf\n&gt; \n&gt; Here is =\r\nthe abstract from the paper:\n&gt; \n&gt; Evolutionary algorithms typically use dir=\r\nect encodings, where each element\n&gt; of the phenotype is specified independe=\r\nntly in the genotype. Because direct\n&gt; encodings have difficulty evolving m=\r\nodular and symmetric phenotypes, some\n&gt; researchers use indirect encodings,=\r\n wherein one genomic element can\n&gt; influence multiple parts of a phenotype.=\r\n We have previously shown that\n&gt; HyperNEAT, an indirect encoding, outperfor=\r\nms FT-NEAT, a direct-encoding\n&gt; control, on many problems, especially as th=\r\ne regularity of the problem\n&gt; increases. However, HyperNEAT is no panacea; =\r\nit had difficulty accounting\n&gt; for irregularities in problems. In this pape=\r\nr, we propose a new algorithm, a\n&gt; Hybridized Indirect and Direct encoding =\r\n(HybrID), which discovers the\n&gt; regularity of a problem with an indirect en=\r\ncoding and accounts for\n&gt; irregularities via a direct encoding. In three di=\r\nfferent problem domains,\n&gt; HybrID outperforms HyperNEAT in most situations,=\r\n with performance\n&gt; improvements as large as 40%. Our work suggests that hy=\r\nbridizing indirect\n&gt; and direct encodings can be an effective way to improv=\r\ne the performance of\n&gt; evolutionary algorithms.\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Cheers,\n&gt; Jef=\r\nf Clune\n&gt; \n&gt; Digital Evolution Lab, Michigan State University\n&gt; \n&gt; jclune@.=\r\n..\n&gt;\n\n\n\n"}}