{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"MkoEn05RKEZDTkkQQBw_aNjK1dJ52ceC3lbH-n_UXo1biei2Vo3VI3ynVNFElfL5CUxAw-8Bb0Bpoz02Uvy-wV_Hq-ostLvlzwAi1Q1Xwiccjixp-qU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1211013675","msgId":4086,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwbTVuYis4cnRpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PFdvcmxkQ2xpZW50LUYyMDA4MDUxNzEwMTQuQUExNDE1MDEyM0BvY3RhZ2F0ZS5jb20+"},"prevInTopic":4085,"nextInTopic":4087,"prevInTime":4085,"nextInTime":4087,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"It is possble to keep only the recent behaviors (not the whole history). I believe this is apropriate since when you reach that point when comparing to the","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 74798 invoked from network); 17 May 2008 08:41:17 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m41.grp.scd.yahoo.com with QMQP; 17 May 2008 08:41:17 -0000\r\nX-Received: from unknown (HELO n53a.bullet.mail.sp1.yahoo.com) (66.163.168.147)\n  by mta18.grp.scd.yahoo.com with SMTP; 17 May 2008 08:41:17 -0000\r\nX-Received: from [216.252.122.216] by n53.bullet.mail.sp1.yahoo.com with NNFMP; 17 May 2008 08:41:17 -0000\r\nX-Received: from [66.218.69.2] by t1.bullet.sp1.yahoo.com with NNFMP; 17 May 2008 08:41:17 -0000\r\nX-Received: from [66.218.66.80] by t2.bullet.scd.yahoo.com with NNFMP; 17 May 2008 08:41:16 -0000\r\nDate: Sat, 17 May 2008 08:41:15 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g0m5nb+8rti@...&gt;\r\nIn-Reply-To: &lt;WorldClient-F200805171014.AA14150123@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=283334584; y=Iqi1Wr7df7ktrlpwvNY7hT3HrgUZgFYAnbL0r3zciUvVrf1WXjT4irU0Bw\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nIt is possble to keep only the recent behaviors (not the whole \nhistory). I=\r\n believe this is apropriate since when you reach that \npoint when comparing=\r\n to the archive becomes very slow, the search \nwould be far away from the i=\r\nnitial behaviors anyway and the \nprobability of going backwards therefore s=\r\nhould be minimal, unless \nthere is simplification (pruning) of the genomes.=\r\n \nOne thing to ask is, is it possible to incorporate a kind of \nobjective f=\r\nunction into the behavior characterization, but not taking \nthat fitness sc=\r\nore into consideration when individuals are selected? \nThe search should th=\r\nen focus on getting different fitnesses every \ntime, no matter high or low.=\r\n \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;Mattias Fagerlund&quot; &lt;mattias@...&gt; wr=\r\note:\n&gt;\n&gt; Hi,\n&gt; \n&gt; &gt; But is this really true?  As I mentioned, we have run n=\r\novelty \nsearch\n&gt; &gt; in these mazes where the behavior is around 400 dimensio=\r\nns, which \ncome\n&gt; &gt; from (x,y) on each timestep.  \n&gt; \n&gt; While this is encou=\r\nraging, I don&#39;t think you&#39;ve actually \ntested &quot;full&quot;\n&gt; dimensions. If it re=\r\nquires 100.000 tests to solve a maze with a \nsize of\n&gt; NxN pixels, a maze o=\r\nf NxNxN voxels should require (sqrt(100.000))\n^3=3D31.6\n&gt; million tests, si=\r\nmply because you now have a vastly larger space to\n&gt; search. Add another di=\r\nmension to that and you&#39;re cozying up to 10 \nbillion\n&gt; tests. \n&gt; \n&gt; The fac=\r\nt that storing every visited x,y over 400 timesteps does&#39;t \nrequire\n&gt; many =\r\nmore tests indicates that the path space for NEAT is fairly \nuniform\n&gt; in t=\r\nhese tests, though it certainly could have exploded, it didn&#39;t.\n&gt; Probably =\r\nfor the reasons you suggest of complexification, try a \nsligthly\n&gt; differen=\r\nt path and you end up somewhere else, filling up the search \nspace\n&gt; of pos=\r\nsible ending positions pretty fast.\n&gt; \n&gt; This wouldn&#39;t and couldn&#39;t happen =\r\nin a volume (for lack of a better \nword)\n&gt; with many more dimensions. \n&gt; \n&gt;=\r\n &gt; Thus the space of possible trajectories is astronomical.  Yet \neven so,\n=\r\n&gt; &gt; with that type of characterization, there was no performance hit \n(in\n&gt;=\r\n &gt; experiments not yet published).  What do you think that implies?  \nDo\n&gt; =\r\n&gt; you really feel that one astronomical space is more expensive than\n&gt; &gt; an=\r\nother?  For example, we might have a 3 dimensional maze with a\n&gt; &gt; similar =\r\nnumber of timesteps, but that would simply increase the\n&gt; &gt; dimensionality =\r\nof behavior from 400 to 1200.  Those are still both\n&gt; &gt; extremely high dime=\r\nnsional characterizations.  If moving from 2\n&gt; &gt; dimensions to 400 doesn&#39;t =\r\nhurt, why would moving from 400 to \n1200?  \n&gt; \n&gt; I do think that the two sp=\r\naces are uncomparable. I&#39;ve tried to \nspeculate\n&gt; on why, but I think that =\r\nyour explanation ultimately is the correct \none,\n&gt; it&#39;s related to complexi=\r\nfication. But adding another true dimension\n&gt; increases the problem search =\r\nspace by a great factor.\n&gt; \n&gt; &gt; However, we are talking about comparing alr=\r\neady-characterized\n&gt; &gt; behaviors, so the &quot;n&quot; in O(n^2) is not the same &quot;N&quot; =\r\nthat is in the\n&gt; &gt; O(N) for number of evaluations.  \n&gt; \n&gt; No, N grows stead=\r\nily and at one point the test of whether the \nsolution is\n&gt; truly novel wil=\r\nl take longer than the actual test itself. granted, \nyou&#39;d\n&gt; be in the rang=\r\ne of hundreds of millions of tests before that \nhappens, but\n&gt; beyond that =\r\npoint, progress will steadily decrease. Actually, it \nsteadily\n&gt; decreases =\r\nfrom the first novelty inovation, but too slowly to be \nnoticable.\n&gt; \n&gt; &gt; C=\r\nomparing two strings is not as expensive as evaluating \n&gt; &gt; an individual. =\r\n \n&gt; \n&gt; Two strings, no, comparing 1 string to N strings will become \nexpens=\r\nive for\n&gt; very large N.\n&gt; \n&gt; O(N^2) looks good for small N. Then, suddenly;=\r\n whammo! Simplest \nmethod,\n&gt; using a bucket hash method with K buckets, you=\r\n reduce the problem \nfrom\n&gt; O(N^2) to O((N/K)^2), which is still O(N^2). So=\r\n for large N, you&#39;re \nstill\n&gt; stuck. That&#39;s for very large searches though.=\r\n\n&gt; \n&gt; with regards,\n&gt; mattias\n&gt;\n\n\n\n"}}