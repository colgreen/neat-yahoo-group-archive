{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":200957992,"authorName":"jgmath2000","from":"&quot;jgmath2000&quot; &lt;jgmath2000@...&gt;","profile":"jgmath2000","replyTo":"LIST","senderId":"WKPk66wloy8a0ww_LbyA5XhJtfiKH8JV8tFJyf4ueqWzNqBzw65M0xqdRCJYAGAILoHs8UtGi6Ch0rfULHZc24e0f19xw7_drgU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: solution for NEAT on CUDA","postDate":"1260643526","msgId":5007,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhnMG9jNiszbG9mQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhmb2xzcytjMmJ1QGVHcm91cHMuY29tPg=="},"prevInTopic":5005,"nextInTopic":0,"prevInTime":5006,"nextInTime":5008,"topicId":4995,"numMessagesInTopic":8,"msgSnippet":"Hey Baihi, I have an implementation of an ANN that works on the GPU using OpenCL.  Here s what I ve noticed with respect to performance: If the number of nodes","rawEmail":"Return-Path: &lt;jgmath2000@...&gt;\r\nX-Sender: jgmath2000@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 40878 invoked from network); 12 Dec 2009 18:45:30 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m1.grp.sp2.yahoo.com with QMQP; 12 Dec 2009 18:45:30 -0000\r\nX-Received: from unknown (HELO n41b.bullet.mail.sp1.yahoo.com) (66.163.168.155)\n  by mta2.grp.sp2.yahoo.com with SMTP; 12 Dec 2009 18:45:30 -0000\r\nX-Received: from [69.147.65.148] by n41.bullet.mail.sp1.yahoo.com with NNFMP; 12 Dec 2009 18:45:26 -0000\r\nX-Received: from [98.137.34.72] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 12 Dec 2009 18:45:26 -0000\r\nDate: Sat, 12 Dec 2009 18:45:26 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hg0oc6+3lof@...&gt;\r\nIn-Reply-To: &lt;hfolss+c2bu@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;jgmath2000&quot; &lt;jgmath2000@...&gt;\r\nSubject: Re: solution for NEAT on CUDA\r\nX-Yahoo-Group-Post: member; u=200957992; y=Qi6yiXRtYtVasa0mTcqRijFFQ3OORP0eTPuY-B1PQuL81Yvb4w\r\nX-Yahoo-Profile: jgmath2000\r\n\r\nHey Baihi,\n\nI have an implementation of an ANN that works on the GPU using =\r\nOpenCL.  Here&#39;s what I&#39;ve noticed with respect to performance:\n\nIf the numb=\r\ner of nodes (neurons) is &lt; 4000, you can store all of the current node valu=\r\nes in local GPU memory.  Updating the ANN on the GPU results in the 10x spe=\r\nedup versus using the CPU ANN update function on the same ANN.\n\nIf the numb=\r\ner of nodes is larger, you cannot cache the current node values in local GP=\r\nU memory and this only results in a 4x speedup from the CPU ANN update func=\r\ntion.\n\nHere&#39;s the hardware I&#39;m using to benchmark:\n\nGPU: XFX NVIDIA GTS 250=\r\n (16-core GPU, using all 16 cores)\nCPU: Intel Core 2 Quad Q6600 2.4Ghz  (on=\r\nly using a single core, but with SSE2 on)\n\nFrom these numbers it looks like=\r\n the GPU isn&#39;t a good way to go if you have access to a cluster or are upda=\r\nting large networks.  It&#39;s possible that with one of the 256-core GPUs (lik=\r\ne NVIDIA tesla), it might provide a speedup, but it&#39;s still not as good as =\r\nrunning on a cluster of CPUs.  The biggest issue here is the fact that most=\r\n of the CPU time in an experiment is spent not updating the ANN, but proces=\r\nsing the domain (e.g. running a physics engine or doing a board game tree s=\r\nearch).  These tasks would either have to be rewritten to use the GPU, or w=\r\nould be better served using a cluster of CPUs.\n\nYou could potentially get a=\r\n nice speedup if you could run the ANN on the GPU in parallel while the dom=\r\nain/environment is running on the CPU simultaneously.  This might be more p=\r\nlausible if you have several evaluations occurring simultaneously.  One thr=\r\nead could be updating an ANN in one evaluation while another thread is runn=\r\ning the environment in a different evaluation at the same time.\n\nIf anyone =\r\nis interested in the code, let me know and I&#39;ll see if I can post it to the=\r\n group.\n\nJason G.\n\n--- In neat@yahoogroups.com, &quot;openmind767&quot; &lt;openmind767@=\r\n...&gt; wrote:\n&gt;\n&gt; Hi, I use NEAT these days. Although I have add parallel for=\r\n \n&gt; EvaluateNetwork and SSE for sigmoid, the performance\n&gt; is still not wel=\r\nl. Maybe performance will never be satisfied.\n&gt; The performance profile sho=\r\nw 90% cpu time is used in \n&gt; Matrix-Vector Multiplication and sigmoid.\n&gt; \n&gt;=\r\n CUDA maybe is the best solution for the performance now. But\n&gt; CUDA progra=\r\nm is not like normal program. I don&#39;t have any \n&gt; experience with CUDA. As =\r\nI think, in most case single network \n&gt; structure is not too big. When Call=\r\ning CUDA do Matrix-Vector \n&gt; Multiplication and sigmoid for one network, CU=\r\nDA memory latency \n&gt; will not be hidden. so it wont gain too much performan=\r\nce for \n&gt; single network. Join all networks of population into one big \n&gt; n=\r\network, and call CUDA to do this big network, CUDA memory latency\n&gt; will be=\r\n hidden well. Maybe this is good solution for NEAT on CUDA.\n&gt; Any suggestio=\r\nn and experience is welcome.\n&gt; \n&gt; Thanks,\n&gt; Baihi\n&gt;\n\n\n\n"}}