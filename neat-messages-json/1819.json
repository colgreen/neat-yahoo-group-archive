{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"g2ye4CTAz1OqfVk7p6oiHb47TuP1GGEJ2CSWSuVeb5ivf6qxZp2EvmBC2Il4bKUhb_TkbVMpl8m6vwpVqS5tHGPKrHAQ1-e6INU","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Symmetry, concepts and data buses in the brain","postDate":"1105718973","msgId":1819,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMi4wLjE0LjAuMjAwNDEyMjExNzIxNTYuMDNiYTYyZThAcG9wLm1haWwueWFob28uY28udWs+","inReplyToHeader":"PGNxN3NmdCtoc29nQGVHcm91cHMuY29tPg==","referencesHeader":"PDQxQzc0NDBCLjUwMTAzMDVAZHNsLnBpcGV4LmNvbT4gPGNxN3NmdCtoc29nQGVHcm91cHMuY29tPg=="},"prevInTopic":1772,"nextInTopic":1820,"prevInTime":1818,"nextInTime":1820,"topicId":1698,"numMessagesInTopic":40,"msgSnippet":"Re: egocentrism etc etc Hi, This is an email that was a long time coming and was far closer to the current topics on the group when I started it but... I have","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 19230 invoked from network); 14 Jan 2005 16:08:50 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m21.grp.scd.yahoo.com with QMQP; 14 Jan 2005 16:08:50 -0000\r\nReceived: from unknown (HELO smtp003.mail.ukl.yahoo.com) (217.12.11.34)\n  by mta6.grp.scd.yahoo.com with SMTP; 14 Jan 2005 16:08:49 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp003.mail.ukl.yahoo.com with SMTP; 14 Jan 2005 16:08:48 -0000\r\nMessage-Id: &lt;6.2.0.14.0.20041221172156.03ba62e8@...&gt;\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.2.0.14\r\nDate: Fri, 14 Jan 2005 16:09:33 +0000\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;cq7sft+hsog@...&gt;\r\nReferences: &lt;41C7440B.5010305@...&gt;\n &lt;cq7sft+hsog@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Remote-IP: 217.12.11.34\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Symmetry, concepts and data buses in the brain\r\nX-Yahoo-Group-Post: member; u=7192225\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nRe: egocentrism etc etc\n\nHi,\n\tThis is an email that was a long time coming and was far closer to the \ncurrent topics on the group when I started it but...\n\n\tI have often wondered how it is that real neural networks (e.g. me) manage \nto exploit the &quot;symmetry&quot; in situations.\n\n\te.g. in the example of the egocentric vs the global-centric eye, the \nreason the former has a easier time of it is that it has some exploitation \nof the symmetries of the situation built into it.  That is the two specific \nsymmetries:\n\n1) that the world retains the same nature as you translate the viewpoint around\n2) that the world retains the same nature as you rotate the view\n\n\t(one could call these &quot;relativities&quot; &#39;cos they are just like the \nassumptions underpinning relativity...)\n\n\tThe egocentric eye does not have full exploitation of them, however, \nbecause for any situation that requires considering the situation at two \npoints (or orientations) it is as badly off as the global viewpoint.  What \nthis means is, if a piece of learning requires the consideration of the \nproperties of more than one &quot;position&quot; -- for example a position#1 where \nthe prey could not see me, and a position#2, where I could eat the prey -- \nthen the eye can move to one of the positions, and get free &quot;relative&quot; \nprocessing, but it has no way of performing any simultaneous calculations \nat a second position, except by evolving its own understanding of the \nsymmetry the hard way.\n\n--\n\n\tAnother good example came up when Mitchel (Timin) was trying to evolve a \nnetwork to play &quot;pairs&quot; (the game where you have to pick two face down \ncards which match by remembering the results of previous goes).  As part of \nthe experimentation, he simplified it way down to 4 cards (2 aces and 2 \ndeuces) and further, he then considered just one case.  Let me quote his \nown words (I hope you don&#39;t mind, Mitchel :):\n\n &gt;There is a 4 card deck, two aces and two deuces.  The\n &gt; ANN goes second.  The first player chooses the first card at random, but\n &gt; the second card is chosen NOT to match the first card.  So the ANN sees\n &gt; two non-matching cards and two face down cards.  Then the cards are\n &gt; turned face down and the ANN picks one card.  Then the ANN picks a\n &gt; second card.  That&#39;s it!  If the cards match, the ANN wins.  Otherwise\n &gt; it loses.\n\nSo he was looking at a very limited subset of the things that could happen \nin play, just to see if he could get the network to do basic remembering \nwhere the cards were.\n\nHowever, when I read his email about the test, I was struck far more by the \nsymmetry of the test case than the basic memory required.  I analyzed the \nsymmetry as follows:\n\n----------------\n\nIf you look at it in a totally naive or &quot;atomic&quot; manner, then there are 96 \ncases:\n\n8 card configurations\n\ntimes 4 first-player first choices\n\ntimes 3 first-player second choices\n\nSo on that basis there&#39;s plenty of cases and it&#39;s easy to believe both the \nneed for a large number of neurones, and also that a net can evolve where \n5% of the cases are in error (this was what Mitchel saw).\n\nHowever.\n\nWhen I solve this problem, I don&#39;t need to consider anything like as many \ncases as 96.  I only need to consider 4 (or even 2) cases.  This is because \nthere is_huge_ symmetry in the problem.\n\nI&#39;m not sure how best to describe the symmetry, but maybe just describing \nhow to exploit it . . . ?\n\n--\n\nAll you need to do is re-map the order of the cards into a consistent pattern.\nThus:\n\nWhichever card player#1 turns first ---&gt; Card#1\nWhichever card player#1 turns second ---&gt; Card#2\nAny other card ---&gt; Card#3\nLast card ---&gt; Card#4\n\nI then always turn over Card#3.  The whole problem is now reduced to the\nfour cases:\n\nADA[D]\nADD[A]\nDAA[D]\nDAD[A]\n\n(the last card is known but never seen)\n\nAnd presumably can be solved by a far smaller net.\n\nThat was all done using only the play order.  If I allow re-mapping based \non card values then the following rules:\n\nWhichever Ace player#1 turns ---&gt; Card#1\nWhichever Deuce player#1 turns ---&gt; Card#2\nAny other card ---&gt; Card#3\nLast card ---&gt; Card#4\n\nReduce it to 2 cases:\n\nADA[D]\nADD[A]\n\n--\n\nSo what am I saying?\n\nI&#39;m not saying that the ANN should in any way be able to do the analysis I \njust did.  I didn&#39;t do that analysis, I just looked at the problem and I \nsaw it wasn&#39;t as hard as 96 cases would suggest, _then_ I did the analysis \nso I could describe why it was\neasier.  Therefore it seems to me that the important point must be that \nsomething in my brain is already primed to exploit symmetry.  When a human \nconsiders a case like this, they don&#39;t have to do any work to figure-out \nthat the game will work\nthe same however the cards are re-ordered.\n\n[[I did have some ideas here on how exploitation of symmetry could be \ncobbled on to a network...]]\n\n---------------\n\n\tAll of which I feel is very relevant, because a system which already has \nsome ability to process symmetry, is facing a far simpler task in learning \nthe rules of the game for the very small number of non-symmetric \nsituations, compared to the naive network which is having to learn the same \nthing over and over.\n\n\tAnd also because it is how my mind works.  e.g. in chess I don&#39;t consider \n&quot;left handed forwards knight moves&quot;, &quot;right handed forwards knight moves&quot; \netc etc.  I just consider &quot;knight moves&quot;.\n\n\tSo to my mind this begs a big question, which is:\n\n\t\tHow does a neural network implement a system such that a general\n\t\tprincipal can be understood before a problem is learned/evolved (*delete as\n\t\tapplicable) and then applied in such a way that it transforms the nature \nof the\n\t\tproblem, making learning and subsequent performance both simpler?\n\n\tWith the obvious corollary that the same principal can be applied equally \nto any number of different problems (where it is relevant).\n\n\tAnd neglecting for the moment the interesting fact that the presence of a \nprincipal in the system seems to go a long way towards automatically \nrecognizing which problems it is relevant to.\n\n\tFor me this raises so many fundamental questions about how RNN&#39;s operate \n(Real Neural Nets, that is).  e.g.\n\n\t- are concepts (such as symmetry) stored at discrete locations and the \nprocessing for a current problem somehow &quot;routed&quot; through those locations\n\n\t- or is a new location created for a new problem and the idea of symmetry \nsomehow copied into that location\n\n\t- or is every activity involving symmetry stored in one multipurpose module\n\n\t- is there some sort of routing system in a brain to decide, moment by \nmoment, which parts talk to one another\n\n\t- or do all symmetry using subroutines connect permanently and the brain \nrelies on not activating them all at once\n\n\t- is there some sort of &quot;bus format&quot; to allow separate modules to \ncommunicate in a language they all understand\n\n\t- or is there a &quot;bus format&quot; for symmetry and different ones for other \nconcepts\n\n\t- and does &quot;learning that a problem is symmetric&quot; involve learning the \nbuss format\n\n\t- or does the brain preprocess every problem just in case symmetry is involved\n\nAll of which seem to me to be closely related to any question of how we \nmight implement modularity.  Obviously the brain might be several orders of \nmagnitude more complex than anything we can do now.  e.g. might be built \nfrom systems which use this sort of thing as a low level component.\n\nBut then the same could be said of the whole field of ANN and yet we get \nsome use from it.  So I guess what I am asking is whether anybody else is \ninterested in the idea that a brain must use some sort of multiplexing or \nrouting to apply different concepts to each other.  If so, how do you think \nit does it?  If not, how do you think it is able to apply unrelated \nconcepts to one another in various combinations?\n\n         Ian B\n\n\nLiving@Home - Open Source Evolving Organisms - \nhttp://livingathome.sourceforge.net/\n\n\n\n\n"}}