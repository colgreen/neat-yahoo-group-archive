{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":274910130,"authorName":"David D&#39;Ambrosio","from":"&quot;David D&#39;Ambrosio&quot; &lt;ddambro84@...&gt;","profile":"ddambroeplex","replyTo":"LIST","senderId":"x_uLUQdEWu1Os-421HlzdbeClHGeictslY34gF6FcDX5295qrmtssXg9Sj0gJtuOjlNd27B3lc9IuUaHDJfW8NUQ--zoUVa_5TXdirVIBTkM","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: New HyperNEAT Paper in the Domain of Checkers","postDate":"1208030135","msgId":3950,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ0cjQzbit1c2txQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGZ0cXNvOSs3amwyQGVHcm91cHMuY29tPg=="},"prevInTopic":3949,"nextInTopic":3951,"prevInTime":3949,"nextInTime":3951,"topicId":3942,"numMessagesInTopic":27,"msgSnippet":"These certainly are impressive results in a very cool domain.  I ve know about them for a while, but just recently got to read exactly how the CPPNs work in","rawEmail":"Return-Path: &lt;ddambro84@...&gt;\r\nX-Sender: ddambro84@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 89356 invoked from network); 12 Apr 2008 19:55:39 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m42.grp.scd.yahoo.com with QMQP; 12 Apr 2008 19:55:39 -0000\r\nX-Received: from unknown (HELO n18a.bullet.scd.yahoo.com) (66.94.237.47)\n  by mta15.grp.scd.yahoo.com with SMTP; 12 Apr 2008 19:55:39 -0000\r\nX-Received: from [209.73.164.86] by n18.bullet.scd.yahoo.com with NNFMP; 12 Apr 2008 19:55:36 -0000\r\nX-Received: from [66.218.67.201] by t8.bullet.scd.yahoo.com with NNFMP; 12 Apr 2008 19:55:36 -0000\r\nDate: Sat, 12 Apr 2008 19:55:35 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;ftr43n+uskq@...&gt;\r\nIn-Reply-To: &lt;ftqso9+7jl2@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;David D&#39;Ambrosio&quot; &lt;ddambro84@...&gt;\r\nSubject: Re: New HyperNEAT Paper in the Domain of Checkers\r\nX-Yahoo-Group-Post: member; u=274910130; y=mP1wk_iGKPfROwSsm7dP_HgAP2zglK2XHTeTl0RdRkf0zHvK\r\nX-Yahoo-Profile: ddambroeplex\r\n\r\nThese certainly are impressive results in a very cool domain.  I&#39;ve\nknow ab=\r\nout them for a while, but just recently got to read exactly how\nthe CPPNs w=\r\nork in this case, and I tend to agree that the CPPN setup\nfor this experime=\r\nnt will be somewhat domain specific.  It does have\nvery clear benefits in t=\r\nerms of querying speed and separating the\noperations of the layers, but I t=\r\nhink it may run into trouble when\nthere are multiple hidden layers.\n\nAdding=\r\n hidden layers using the method described in the previous papers\nrequires o=\r\nnly adding 2 extra input nodes (z1 and z2) for as many\nhidden layers as you=\r\n would like, but this new method requires a new\noutput node for each hidden=\r\n layer.  For example a substrate with 9\nhidden layers would require 4 input=\r\ns and 10 outputs, whereas the\noriginal method would only need 6 inputs and =\r\n1 output.  Scaling by\nadding new hidden layers is also affected by this, bu=\r\nt could be\nresolved with further evolution.\n\nMy guess is that for some expe=\r\nriments there will be some number of\nhidden layers where it is easier to de=\r\nscribe a pattern using z1 and z2\nthan it is to describe with several differ=\r\nent outputs.  But we may not\never reach that number, so maybe this is the b=\r\netter way.  Either way\nthis is a great demonstration that really shows Hype=\r\nrNEAT exploiting\nthe geometry of a problem.\n\nDavid\n\n\n--- In neat@yahoogroup=\r\ns.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Another interesting thin=\r\ng about having a CPPN with two outputs (one\n&gt; for each layer) is that theor=\r\netically you can get two weights out for\n&gt; each single complete activation =\r\nof the CPPN.  We probably did not\n&gt; leverage this capability in this paper =\r\nbecause we only have one\n&gt; output, but if there were many outputs (as there=\r\n are many inputs and\n&gt; hidden nodes) then it might save some computation ti=\r\nme.\n&gt; \n&gt; Anyway, like Jason said, this setup is based on an intuition about=\r\n\n&gt; separability, so I am suspecting that there are pros and cons to both\n&gt; =\r\nalternatives (i.e. using z vs. having 2 outputs) that are\n&gt; domain-specific=\r\n.  This paper does not constitute an exhaustive study\n&gt; of the issue.  Howe=\r\nver, it does show that the multi-output approach,\n&gt; which is perhaps not th=\r\ne one that first comes to mind, can work.\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogr=\r\noups.com, &quot;Jason Gauci&quot; &lt;jgmath2000@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hey Stephen,\n&gt; &gt; \n&gt; &gt; =\r\nGreat questions!  We&#39;ll have to think about some of them for awhile\n&gt; &gt; but=\r\n here&#39;s a few answers:\n&gt; &gt; \n&gt; &gt; The reason why I chose to use a separate ou=\r\ntput for each connection\n&gt; &gt; layer instead of using a 3-dimensional CPPN is=\r\n because I wanted to\n&gt; &gt; separate the network for each layer.  If you use t=\r\nhe 3-D CPPN method,\n&gt; &gt; then the two layers are only distinguished by the v=\r\nalues of &#39;z&#39;. \n&gt; &gt; Because I&#39;m only using two layers, I wanted to make sure=\r\n that each\n&gt; &gt; layer did some unique processing.  If there was only one out=\r\nput, it\n&gt; &gt; would be harder for the connection layers to distinguish themse=\r\nlves as\n&gt; &gt; they would be too dependent.  In the worst case, z1 and z2 inpu=\r\nts are\n&gt; &gt; not used and the two layers are exactly the same. I haven&#39;t done=\r\n any\n&gt; &gt; empirical tests on which method is better so I do not have any\n&gt; &gt;=\r\n evidence to back my claim, but it&#39;s my intuition.\n&gt; &gt; \n&gt; &gt; I haven&#39;t tried=\r\n any computer opponents other than Xcheckers.  I have\n&gt; &gt; had my friends an=\r\nd people in the lab play against the HyperNEAT\n&gt; &gt; opponent and it is defin=\r\nitely better than all of us :-).  I would like\n&gt; &gt; to release a binary vers=\r\nion so people can play the opponents at\n&gt; &gt; different generations and see t=\r\nhe change in performance.\n&gt; &gt; \n&gt; &gt; One active area of interest is to figure=\r\n out how good a HyperNEAT\n&gt; &gt; player is in a global sense.  In Chellapilla =\r\n& Fogel&#39;s paper, they\n&gt; &gt; played human opponents in checkers on MSN Gaming =\r\nZone online and got\n&gt; &gt; an expert rating on that game server.  The problem =\r\nwith this is that\n&gt; &gt; it is very time consuming to play games by hand. It w=\r\nould not be\n&gt; &gt; feasible for me to test several individuals in this way.\n&gt; =\r\n&gt; \n&gt; &gt; I have experimented with coevolution, but I need to solve the\n&gt; &gt; af=\r\norementioned problem before I can say anything about the performance\n&gt; &gt; of=\r\n the evolved individuals.\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, Stephen Wai=\r\nts &lt;steve@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt; On Apr 11, 2008, at 9:38 PM, Kenneth =\r\nStanley wrote:\n&gt; &gt; &gt; &gt; Jason Gauci and I are pleased to share with you new =\r\nresults with\n&gt; &gt; &gt; &gt; HyperNEAT  in our new paper to appear in the Twenty-Th=\r\nird AAAI\n&gt; &gt; &gt; &gt; Conference on Artificial Intelligence (2008), &quot;A Case Stud=\r\ny on the\n&gt; &gt; &gt; &gt; Critical Role of Geometric Regularity in Machine Learning.=\r\n&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Cool, I enjoyed the paper, thanks Jason and Ken.\n&gt; &gt; =\r\n&gt; \n&gt; &gt; &gt; I have a few questions:\n&gt; &gt; &gt; \n&gt; &gt; &gt; * Was the 4in/2out CPPN arbit=\r\nrarily chosen?\n&gt; &gt; &gt; * Why not a 6in/1out (xyz, xyz, out) - which seems mor=\r\ne natural\nto me?\n&gt; &gt; &gt; * Was more than one CPPN configuration tried?  What =\r\nwas the process?\n&gt; &gt; &gt; * Was more than one substrate configuration tried?  =\r\n...\n&gt; &gt; &gt; * What was the full connection pattern through the substrate?  Yo=\r\nu  \n&gt; &gt; &gt; mention the 129 nodes (which makes sense), but what are the 3979 =\r\n \n&gt; &gt; &gt; connections?\n&gt; &gt; &gt; * Did you try against any opponents other than X=\r\ncheckers?\n&gt; &gt; &gt; * Have you experimented with coevolution?\n&gt; &gt; &gt; \n&gt; &gt; &gt; Than=\r\nks again for the great work.\n&gt; &gt; &gt; --\n&gt; &gt; &gt; Stephen Waits\n&gt; &gt; &gt; steve@\n&gt; &gt; =\r\n&gt; http://swaits.com/\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}