{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":411255308,"authorName":"torvhydda","from":"&quot;torvhydda&quot; &lt;torvhydda@...&gt;","profile":"torvhydda","replyTo":"LIST","senderId":"Q2ZaT1LkQqQezgxWP5qP9LRdAfP2dcRTSnsnoR0X0z4R8vqY0ZYtjVmhCZZ3YK6IUZI2vCmjrVG4N-cw6V-G__svnJN4AGJH","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Discrete Neural Networks","postDate":"1260392243","msgId":4998,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhmcDJ2aitjZHBmQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhmb3Zwais1ZWUwQGVHcm91cHMuY29tPg=="},"prevInTopic":4997,"nextInTopic":4999,"prevInTime":4997,"nextInTime":4999,"topicId":4984,"numMessagesInTopic":16,"msgSnippet":"I might have been wrong about how fast it learns compared to the normal eco. I uploaded a new eco-bnn.tar.gz with some fixes, and it seems to me that they are","rawEmail":"Return-Path: &lt;torvhydda@...&gt;\r\nX-Sender: torvhydda@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 30362 invoked from network); 9 Dec 2009 20:57:30 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m1.grp.sp2.yahoo.com with QMQP; 9 Dec 2009 20:57:30 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta2.grp.re1.yahoo.com with SMTP; 9 Dec 2009 20:57:29 -0000\r\nX-Received: from [69.147.65.148] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 09 Dec 2009 20:57:24 -0000\r\nX-Received: from [98.137.35.12] by t11.bullet.mail.sp1.yahoo.com with NNFMP; 09 Dec 2009 20:57:24 -0000\r\nDate: Wed, 09 Dec 2009 20:57:23 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hfp2vj+cdpf@...&gt;\r\nIn-Reply-To: &lt;hfovpj+5ee0@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;torvhydda&quot; &lt;torvhydda@...&gt;\r\nSubject: Re: Discrete Neural Networks\r\nX-Yahoo-Group-Post: member; u=411255308; y=qyyquL_PSQiGX2RNo42ZGkBG6p4Tw_SfcxXRDo2nHp66B1O0\r\nX-Yahoo-Profile: torvhydda\r\n\r\n\n\nI might have been wrong about how fast it learns compared to the normal e=\r\nco. I uploaded a new eco-bnn.tar.gz with some fixes, and it seems to me tha=\r\nt they are quite good learners. Gonna put more statistics inside eco so the=\r\nre is possible to draw better conclusions. Its kind of hard to visually com=\r\npare different versions. :)\n\nI will also add the ability for them to use ot=\r\nher operations than NAND, that might speed up evolution. I find it very int=\r\neresting with this 1-bit neural networks, and I will dive deeper into it fo=\r\nr sure :)\n\n/Magnus\n\n--- In neat@yahoogroups.com, &quot;snapmedown&quot; &lt;snapmedown@.=\r\n..&gt; wrote:\n&gt;\n&gt; So it works?  I would think that the mutation paramaters wou=\r\nld have to be biased (more chance of adding a node than normal NEAT).  Does=\r\n that help?\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;torvhydda&quot; &lt;torvhydda@&gt; wrot=\r\ne:\n&gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; Cool idea!\n&gt; &gt; \n&gt; &gt; I had to try it on my eco project.=\r\n I gave them 1 bit for the bias. 2 bits for the light angle, and 3 bits for=\r\n each distance ray (6 rays total). They got 1 bit for the output thrust, an=\r\nd 1 bit for the output turn angle.\n&gt; &gt; So totally they have 21 inputs & 2 o=\r\nutputs. Each one just 1 bit.\n&gt; &gt; \n&gt; &gt; The summation, in the activation func=\r\ntion neat.c:_genome_activate(), is replaced with NAND. If a node has only o=\r\nne input the node acts like a NOT.\n&gt; &gt; The gene weights has no impact on an=\r\nything in this test.\n&gt; &gt; \n&gt; &gt; for (n =3D 0, res =3D 1; n &lt; nin; n++, op++)\n=\r\n&gt; &gt;  res =3D !(res && (*op-&gt;ptr =3D=3D 1));\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; In eco.c (LINE 30=\r\n - 39) one can experiment with how many bits each input & output has.\n&gt; &gt; \n=\r\n&gt; &gt; I uploaded eco-bnn.tar.gz, to the eco folder. It contains win exe + 3 p=\r\natches for the 0.6 src release.\n&gt; &gt; \n&gt; &gt; They learn how to follow blue ligh=\r\nt, but it takes longer. Train them on an empty map for faster sucess.\n&gt; &gt; \n=\r\n&gt; &gt; /Magnus\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;snapmedown&quot; &lt;snapmedown@=\r\n&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; What are the thoughts on a neural network that has inp=\r\nuts and outputs digitized?  Perhaps 8 bits or even less?  This would reduce=\r\n the search space, but encourage larger structures.\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}