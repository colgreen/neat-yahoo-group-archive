{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"mtoCXkU0k4gpvqFHcYI5d3UQsWPIs7hkAoUnrmWDncnoDoxjeeaGLDqCi0lPuTPUn1XHyYR9vjyeDvVrF9-Ip0dtBpyqFGEA2karfWVG2pcl","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Introducing a New Approach to Search: Novelty Search (New Paper)","postDate":"1211079227","msgId":4087,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcwbzVucittNDY1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PFdvcmxkQ2xpZW50LUYyMDA4MDUxNzEwMTQuQUExNDE1MDEyM0BvY3RhZ2F0ZS5jb20+"},"prevInTopic":4086,"nextInTopic":4088,"prevInTime":4086,"nextInTime":4088,"topicId":4038,"numMessagesInTopic":26,"msgSnippet":"Mattias, ... billion ... require ... space ... word) ... Yet there may be a reason that increasing the dimensions in the physical volume would not cause the","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 94402 invoked from network); 18 May 2008 02:53:50 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m56.grp.scd.yahoo.com with QMQP; 18 May 2008 02:53:50 -0000\r\nX-Received: from unknown (HELO n42b.bullet.mail.sp1.yahoo.com) (66.163.168.156)\n  by mta17.grp.scd.yahoo.com with SMTP; 18 May 2008 02:53:50 -0000\r\nX-Received: from [216.252.122.217] by n42.bullet.mail.sp1.yahoo.com with NNFMP; 18 May 2008 02:53:50 -0000\r\nX-Received: from [66.218.69.6] by t2.bullet.sp1.yahoo.com with NNFMP; 18 May 2008 02:53:50 -0000\r\nX-Received: from [66.218.66.84] by t6.bullet.scd.yahoo.com with NNFMP; 18 May 2008 02:53:50 -0000\r\nDate: Sun, 18 May 2008 02:53:47 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g0o5nr+m465@...&gt;\r\nIn-Reply-To: &lt;WorldClient-F200805171014.AA14150123@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Re: Introducing a New Approach to Search: Novelty Search (New Paper)\r\nX-Yahoo-Group-Post: member; u=54567749; y=YPXdDiXmJc5iTY-13JcbD5SEw5lgltg5VDkUgFHtNQQBnFWJpk9_\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nMattias,\n\n&gt; &gt; But is this really true?  As I mentioned, we have run novelty=\r\n search\n&gt; &gt; in these mazes where the behavior is around 400 dimensions, whi=\r\nch come\n&gt; &gt; from (x,y) on each timestep.  \n&gt; \n&gt; While this is encouraging, =\r\nI don&#39;t think you&#39;ve actually tested &quot;full&quot;\n&gt; dimensions. If it requires 10=\r\n0.000 tests to solve a maze with a size of\n&gt; NxN pixels, a maze of NxNxN vo=\r\nxels should require (sqrt(100.000))^3=3D31.6\n&gt; million tests, simply becaus=\r\ne you now have a vastly larger space to\n&gt; search. Add another dimension to =\r\nthat and you&#39;re cozying up to 10\nbillion\n&gt; tests. \n&gt; \n&gt; The fact that stori=\r\nng every visited x,y over 400 timesteps does&#39;t\nrequire\n&gt; many more tests in=\r\ndicates that the path space for NEAT is fairly uniform\n&gt; in these tests, th=\r\nough it certainly could have exploded, it didn&#39;t.\n&gt; Probably for the reason=\r\ns you suggest of complexification, try a sligthly\n&gt; different path and you =\r\nend up somewhere else, filling up the search\nspace\n&gt; of possible ending pos=\r\nitions pretty fast.\n&gt; \n&gt; This wouldn&#39;t and couldn&#39;t happen in a volume (for=\r\n lack of a better\nword)\n&gt; with many more dimensions. \n&gt; \n\nYet there may be =\r\na reason that increasing the dimensions in the\nphysical volume would not ca=\r\nuse the number of evaluations (i.e. what\nyou are calling tests) to explode =\r\nas in the equation (sqrt(100.000))^3.\n\nThe agents in the maze are controlle=\r\nd by neural networks, which\ncompute their outputs as a function of their in=\r\nputs.  Therefore, the\norder in which various trajectories are encountered i=\r\ns statistically\nrelated to the distribution and number of walls in the maze=\r\n.  And it\nis this *order* of discovery (in other words which trajectory is\n=\r\ndiscovered before which) that really mediates the computational\ncomplexity,=\r\n rather than the theoretical number of possible\ntrajectories or ending loca=\r\ntions that exist.\n\nIn other words, if we were simply to search through leng=\r\nth-100 strings\n like [turn up, forward, turn left, forward, turn right, for=\r\nward,...]\nthen indeed the complexity of the search would be dependent on th=\r\ne\ndimensions in the physical volume.\n\nYet novelty search relies on the fact=\r\n that the behavior of neural\ncontrollers is highly constrained by the confi=\r\nguration of the physical\nworld, not just in the sense that if they hit a wa=\r\nll they cannot move\n(which would be true of the simple-string controllers a=\r\ns well), but\nalso in that their trajectories are computed as a function of =\r\ntheir\nvisual stream, i.e., they are &quot;embodied.&quot;\n\nThus rather than being &quot;li=\r\nsts of directions&quot; like\n(up,left,forward,...) the strategies we are searchi=\r\nng through are in\neffect *heuristics* more like &quot;turn left at any wall&quot; or =\r\n&quot;move in the\ndirection of open space,&quot; or &quot;if you see a wall, run into it.&quot;=\r\n\n \nThe simplest such strategies will be encountered first because of\ncomple=\r\nxification, that is, because the network can only represent\nsimple strategi=\r\nes at first anyway.  Thus if there were.g. one wall in\nthe entire world, wh=\r\nether the world was 2-D or 3-D, the number of\nbehaviors we would see would =\r\nbe limited and almost all wall-relative.\n   We&#39;d see things like bumping in=\r\nto the wall, going along the wall,\nand going around the wall.  There are ce=\r\nrtainly more ways to go around\na wall in 3-D than 2-D, but it is nothing li=\r\nke the total increase in\npossible trajectories in the entire volume.  \n\nThe=\r\nn, as the network becomes more complex, novel behaviors will be the\nones th=\r\nat leverage that added complexity to do something else, such as\nturn after =\r\ngoing around the wall.  But again, there are only so many\nelaborations of t=\r\nhis type.  It&#39;s not like we can suddenly just say\n&quot;...then turn left, turn =\r\nright, go forward, zig-zag, do a\nspin,...etc...&quot;  \n\nGranted, it is true tha=\r\nt recurrent connections mean that\ntheoretically, crazy behaviors are possib=\r\nle even when ignoring\nsensors, but those would take many generations to bui=\r\nld and would not\nbe the first stepping stones encountered.  So they are les=\r\ns likely and\neven when discovered, harder to exploit for novelty  due to th=\r\neir\ninstability and ignorance of the sensors.\n\nSo what we should see is an =\r\norderly ascension through increasingly\ncomplex sensor-mediated strategies, =\r\nas opposed to enumerated\ntrajectories.  And in general, to get through a ma=\r\nze that has some\norderliness requires a strategy that involves some general=\r\nity, which\nmeans that even by the time we ascend to the proper level of\ncom=\r\nplexity for that general strategy, we will have only barely scraped\nthe sur=\r\nface of all possible behaviors.\n\nNow you may say that there are many mazes =\r\nwhere, if we allow them to\nbe large enough, you cannot articulate a general=\r\n (heuristic)\nnavigation strategy because the maze is so crazy.  You simply =\r\nhave to\nin effect (in the genome) enumerate the entire set of directions.  =\r\nYet\nmy feeling is that such mazes are representative of a class of\nproblems=\r\n that are unlikely to be interesting to solve anyway, because\nmost interest=\r\ning problems involve some general principles.  Otherwise,\nthey are merely a=\r\nd hoc concoctions.  \n\nFor example, on most squares on a checkers board, you=\r\n can be jumped if\nsomeone is right next to you and you have nothing to bloc=\r\nk their jump,\nand checkers is an interesting game to solve.  On the other h=\r\nand, a\ngame where the rules are completely different for every square on th=\r\ne\nboard would be extremely difficult to solve (since there are no\ngeneral r=\r\nules of thumb) yet such a game is also crazy and not likely\nto raise a lot =\r\nof interest in any case.\n\nAnyway, I believe this explanation shows why the =\r\nvolume of physical\nspace, or even any measure of the total size of the beha=\r\nvior space, is\nnot necessarily the instrumental factor.  Rather, it is the =\r\nsize of\nthe behavior space that is *encompassed* by the genotype space bein=\r\ng\nsearch at any given time.  And that is much smaller, and includes\ngeneral=\r\n heuristics.\n\nSo my hypothesis, which would be interesting to test, is that=\r\n the\nequation (sqrt(100.000))^3 is a significant overestimation.  The real\n=\r\nissue would be the complexity of the maze itself, whether 2-D or 3-D,\nand w=\r\nhether any general principles can be applied to solving it.\n\n&gt; &gt; Thus the s=\r\npace of possible trajectories is astronomical.  Yet even so,\n&gt; &gt; with that =\r\ntype of characterization, there was no performance hit (in\n&gt; &gt; experiments =\r\nnot yet published).  What do you think that implies?  Do\n&gt; &gt; you really fee=\r\nl that one astronomical space is more expensive than\n&gt; &gt; another?  For exam=\r\nple, we might have a 3 dimensional maze with a\n&gt; &gt; similar number of timest=\r\neps, but that would simply increase the\n&gt; &gt; dimensionality of behavior from=\r\n 400 to 1200.  Those are still both\n&gt; &gt; extremely high dimensional characte=\r\nrizations.  If moving from 2\n&gt; &gt; dimensions to 400 doesn&#39;t hurt, why would =\r\nmoving from 400 to 1200?  \n&gt; \n&gt; I do think that the two spaces are uncompar=\r\nable. I&#39;ve tried to speculate\n&gt; on why, but I think that your explanation u=\r\nltimately is the correct one,\n&gt; it&#39;s related to complexification. But addin=\r\ng another true dimension\n&gt; increases the problem search space by a great fa=\r\nctor.\n&gt; \n&gt; &gt; However, we are talking about comparing already-characterized\n=\r\n&gt; &gt; behaviors, so the &quot;n&quot; in O(n^2) is not the same &quot;N&quot; that is in the\n&gt; &gt; =\r\nO(N) for number of evaluations.  \n&gt; \n&gt; No, N grows steadily and at one poin=\r\nt the test of whether the\nsolution is\n&gt; truly novel will take longer than t=\r\nhe actual test itself. granted, you&#39;d\n&gt; be in the range of hundreds of mill=\r\nions of tests before that\nhappens, but\n&gt; beyond that point, progress will s=\r\nteadily decrease. Actually, it\nsteadily\n&gt; decreases from the first novelty =\r\ninovation, but too slowly to be\nnoticable.\n&gt; \n&gt; &gt; Comparing two strings is =\r\nnot as expensive as evaluating \n&gt; &gt; an individual.  \n&gt; \n&gt; Two strings, no, =\r\ncomparing 1 string to N strings will become\nexpensive for\n&gt; very large N.\n&gt;=\r\n \n&gt; O(N^2) looks good for small N. Then, suddenly; whammo! Simplest method,=\r\n\n&gt; using a bucket hash method with K buckets, you reduce the problem from\n&gt;=\r\n O(N^2) to O((N/K)^2), which is still O(N^2). So for large N, you&#39;re\nstill\n=\r\n&gt; stuck. That&#39;s for very large searches though.\n&gt; \n\nYes I agree that when t=\r\nhe archive gets to a certain size we start\nrunning into problems.  Yet reca=\r\nll that the archive is not a record of\nevery point visited, but rather a re=\r\ncord of every point visited that\nwas sufficiently novel, so it grows slower=\r\n than total # evaluations.\nNevertheless, you are surely correct that at som=\r\ne point is gets too\nbig to be tractable.  \n\nI think that Peter will turn ou=\r\nt correct though that it not be too\nharmful to throw out a lot of the archi=\r\nve.  Yet I think we need to be\ncareful how we do it.  There are always goin=\r\ng to be some &quot;garbage&quot;\nbehaviors that will appear over and over again no ma=\r\ntter how complex\nbehavior is getting, simply because of genetic defect.  We=\r\n don&#39;t want\nto forget those garbage behaviors and have to remember them all=\r\n over\nagain.   However, we can probably throw out archive points that are\na=\r\nlone in space and have not been visited in a long time, because we\nare prob=\r\nably not coming back to them, and even if we did long into the\nfuture, we p=\r\nrobably are coming with a very different genetic approach\nto doing the same=\r\n thing, which effectively means a different stepping\nstone anyway.\n\nIn any =\r\ncase, I agree that the implications of and remedies for the\nexpanding archi=\r\nve will need to be researched\n\nken\n\n\n"}}