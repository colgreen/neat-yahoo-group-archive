{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":102323271,"authorName":"lior_fainshil","from":"&quot;lior_fainshil&quot; &lt;lior_fainshil@...&gt;","profile":"lior_fainshil","replyTo":"LIST","senderId":"qefYcvhlriFff0XeCyKNBIetLiKM970dFxh2vOXlTqJ1tRxNJ5VL820ovnl5mpUKC4x6EVIuuqRA7x8QP-6cU4p47SG1VUb1e0_vdoV1XHk","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Novelty Search for Classification/Regression problems","postDate":"1271853227","msgId":5213,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhxbXJiYitxczRyQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGhxbG8xOSthaDlyQGVHcm91cHMuY29tPg=="},"prevInTopic":5212,"nextInTopic":0,"prevInTime":5212,"nextInTime":5214,"topicId":5211,"numMessagesInTopic":3,"msgSnippet":"... points about overfitting. One thing I m not sure about is the explanation behind the log(n)+log(log(n)) complexity of the Nth neural network? It seems that","rawEmail":"Return-Path: &lt;lior_fainshil@...&gt;\r\nX-Sender: lior_fainshil@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 34818 invoked from network); 21 Apr 2010 12:34:02 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m14.grp.re1.yahoo.com with QMQP; 21 Apr 2010 12:34:02 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta2.grp.re1.yahoo.com with SMTP; 21 Apr 2010 12:34:02 -0000\r\nX-Received: from [69.147.65.171] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 21 Apr 2010 12:33:49 -0000\r\nX-Received: from [98.137.34.35] by t13.bullet.mail.sp1.yahoo.com with NNFMP; 21 Apr 2010 12:33:49 -0000\r\nDate: Wed, 21 Apr 2010 12:33:47 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hqmrbb+qs4r@...&gt;\r\nIn-Reply-To: &lt;hqlo19+ah9r@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;8-0995369644-0701145792=:2&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;lior_fainshil&quot; &lt;lior_fainshil@...&gt;\r\nSubject: Re: Novelty Search for Classification/Regression problems\r\nX-Yahoo-Group-Post: member; u=102323271; y=Bf2SwcJe6xNQ0v1q4xNsIYzuUE9WwHic6GFR-DM_krqIAPfWgdNetQ\r\nX-Yahoo-Profile: lior_fainshil\r\n\r\n\r\n--8-0995369644-0701145792=:2\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n--- In neat@yahoogroups.com, &quot;joel278&quot; &lt;lehman.154@...&gt; wrote:\n&gt;\n&gt;\n&gt;\n&gt; Hi L=\r\nior,\n&gt;\n&gt; Thanks for your interest in novelty search, you make some interest=\r\ning\npoints about overfitting. One thing I&#39;m not sure about is the\nexplanati=\r\non behind the log(n)+log(log(n)) complexity of the Nth neural\nnetwork? It s=\r\neems that in order to regenerate the solution you would\nhave to also take i=\r\nnto account the complexity of the search algorithm\nitself which (if it is N=\r\nEAT+novelty search) is likely a lot larger than\nthis log(n) term?\n\nThe sear=\r\nch algorithm is known in advance and does not depend on the\ninput data. It =\r\nwill always search the hypothesis space in the same\norder. Thus to recreate=\r\n the final hypothesis, we only need to know its\nindex in the search. There =\r\nis no need to save anything else. Thus the\ninformation content of the class=\r\nifier is at most  log(n)+log(log(n)).\nThe limit on overfitting does not dep=\r\nend on the amount of prior\nknowledge, but just on the amount of information=\r\n needed to encode the\nfinal hypothesis. The prior knowledge does affect und=\r\nerfitting - that is\ncan we even classify the training data, but that&#39;s a di=\r\nfferent subject.\n\n&gt; Regardless, it is interesting to consider if novelty se=\r\narch could be a\ngood way of evolving ANNs that solve classification tasks w=\r\nithout\noverfitting.\n&gt;\n&gt; It is true that there is tentative evidence that no=\r\nvelty search may\nevolve more compact solutions than objective-based search =\r\n(shown in the\nrecent GP publication and also in the original Alife conferen=\r\nce paper)\nand may thus be less prone to overfitting. However, I think that\n=\r\nclassification is not an ideal domain for unconstrained novelty search.\nTha=\r\nt is, I am not sure it would always be better than an exhaustive or\nrandom =\r\nsearch in such a scenario. And while exhaustive or random search\nmay be fea=\r\nsible for toy problems, I would be a bit surprised if a\nsignificant breakth=\r\nrough was produced through such means.\n&gt;\n&gt; The main problem with *efficient=\r\nly* applying raw novelty search to a\nclassification problem is that with a =\r\nnaive behavioral characterization\n(e.g. the concatenation of all the classe=\r\ns an ANN outputs over the\ntraining set), there are no domain restrictions a=\r\nnd a vast space of\npossible behaviors. With such a characterization, novelt=\r\ny search would\ncontinually find novel ways of partitioning the training exa=\r\nmples in\ndifferent classes. The problem is, the number of possible partitio=\r\nns\ngrows exponentially in the number of training examples.\n&gt;\n&gt; While someti=\r\nmes learning a new way to partition classification\nexamples may reflect an =\r\nimportant aspect of the distribution of the\ntraining examples, NS may also =\r\nexploit noise or incidental aspects of\nthe training examples to generate ne=\r\nw classifications. For example, if\nthe training data were 10-dimensional, b=\r\nut only one dimension was\nimportant to classification, and the other 9 were=\r\n random, NS might\nexploit the random differences in the unimportant dimensi=\r\nons to generate\na huge amount of novel classifications.\n&gt;\n&gt; The problem is =\r\nthat in NS classification the &quot;behavior&quot; of the ANN is\na direct product of =\r\nits output signals. Contrast such directness with a\nrobot&#39;s behavior in a m=\r\naze: The location at which a robot ends up in a\nmaze is an indirect product=\r\n of its output signals. The robot&#39;s output\nsignals direct its actions, but =\r\nare subject to the virtual world in\nwhich the robot lives (a robot cannot g=\r\no through walls nor travel faster\nthan its motors will allow).\n&gt;\n&gt; Imagine =\r\nif a maze-robot&#39;s outputs simply teleported it into a specific\narea of the =\r\nmaze; this is similar in spirit to a naive search for\nnovelty in a classifi=\r\ncation domain. There is little to learn in a raw NS\nclassification problem =\r\nbecause the &quot;world&quot; in which the classifying ANN\nlives in is so simple and =\r\ncompletely unconstrained.\n\nI agree with this point. The last thing we would=\r\n want from a\nclassification algorithm is a uniform search of the phenotype =\r\nspace. On\nthe other hand, the optimal classification algorithm is a systema=\r\ntic\nsearch of all hypotheses ordered by their complexity under an\nappropria=\r\nte complexity model. It is not completely clear to me where\nnovelty search =\r\nstands between the two. It is possible to encourage\nsimple solutions by inc=\r\norporating into the fitness function a penalty\nfor size. This helped my mul=\r\ntidimensional xor experiment, but not enough\nto make it competitive with or=\r\ndinary performance directed search.\nThe important question is how does nove=\r\nlty search compare with the\ntheoretically optimal, but practically not very=\r\n feasible (for\ncomputational time reasons) systematic search of the genotyp=\r\ne space. \nNovelty search possesses the same minimal overfitting guarantee. =\r\nIt does\nnot inherently possess the same minimal underfitting guarantee and =\r\nit\nmight hold promise for a more reasonable computational performance. If\ni=\r\nt can be shown that novelty search possesses significant classification\nabi=\r\nlity characteristics of the optimal systematic search, but achieves\nit with=\r\n much more realistic computational resources, then it will be a\nvery signif=\r\nicant development. Now the question is whether this is the\ncase.\n\n&gt; Constra=\r\nints or domain restrictions are important because they may\nallow a search f=\r\nor novelty to learn about a domain; for example,\nsearching for novelty in a=\r\n maze incentivizes learning about how to avoid\nwalls. That is, by avoiding =\r\nwalls a robot may end up in a novel location\nin the maze. Although there ar=\r\ne no inherent domain restrictions in a\nclassification problem, such restric=\r\ntions can possibly be introduced\nartificially.\n&gt;\n&gt; Ken Stanley and I have a=\r\n publication on minimal criteria novelty\nsearch (http://eplex.cs.ucf.edu/pu=\r\nblications/2010/lehman.gecco10a.html),\nwhich provides such a way of introdu=\r\ncing artificial domain constraints.\nAn individual in MCNS is considered onl=\r\ny if it meets all user-imposed\nminimal criteria, otherwise it is discarded.=\r\n\n&gt;\n&gt; An intuitive minimal criterion for classification problems might be\nma=\r\nintaining at least x% accuracy (where x could be the accuracy that a\nsimple=\r\n nearest-neighbor classification scheme achieves). This would mean\nthat an =\r\nANN must find novel classification schemes that are partially\nconstrained b=\r\ny the correct labels of the training set. However, I do not\nknow if this is=\r\n a good approach; there may be some domains that are not\namenable to novelt=\r\ny search, just as very deceptive domains provide a bad\nmatch for objective-=\r\nbased search.\n&gt;\n&gt; But, I think that a MCNS approach might be the best way t=\r\no approach\ninteresting classification problems in a novelty-search way.\n\nTh=\r\nis is a possibility. However we risk loosing what we came for. If we\nuse th=\r\ne training set for the search, we must save information on the\ntraining set=\r\n as part of the classifier. If we save a small amount of\ninformation on the=\r\n training set, then the theoretical assurance of\nno-overfitting gets weaker=\r\n. If we save all the training set, the\nassurance will disappear.\n\n&gt; As for =\r\nXOR, I did try novelty search with XOR classification in my\ninitial experim=\r\nents and found that it was able to consistently solve the\nproblem (perhaps =\r\nbecause there are only 4 training examples), although\nit did not provide an=\r\n advantage over objective-based search.\n\nI used a multidimensional version.=\r\n Maybe I should have called it the\nparity problem.\n\n\n\r\n--8-0995369644-0701145792=:2\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n\n&lt;blockquote&gt;--- In neat@yahoogroups.com, &quot;joel278&quot; &lt;lehman.154@...&gt; =\r\nwrote:&lt;br&gt;&gt;&lt;br&gt;&gt; &lt;br&gt;&gt; &lt;br&gt;&gt; Hi Lior,&lt;br&gt;&gt; &lt;br&gt;&gt; Thanks f=\r\nor your interest in novelty search, you make some interesting points about =\r\noverfitting. One thing I&#39;m not sure about is the explanation behind the log=\r\n(n)+log(log(n)) complexity of the Nth neural network? It seems that in orde=\r\nr to regenerate the solution you would have to also take into account the c=\r\nomplexity of the search algorithm itself which (if it is NEAT+novelty searc=\r\nh) is likely a lot larger than this log(n) term?&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;The se=\r\narch algorithm is known in advance and does not depend on the input data. I=\r\nt will always search the hypothesis space in the same order. Thus to recrea=\r\nte the final hypothesis, we only need to know its index in the search. Ther=\r\ne is no need to save anything else. Thus the information content of the cla=\r\nssifier is at most&nbsp; log(n)+log(log(n)). The limit on overfitting does =\r\nnot depend on the amount of prior knowledge, but just on the amount of info=\r\nrmation needed to encode the final hypothesis. The prior knowledge does aff=\r\nect underfitting - that is can we even classify the training data, but that=\r\n&#39;s a different subject.&lt;br&gt;&lt;br&gt;&lt;blockquote&gt;&gt; Regardless, it is interesti=\r\nng to consider if novelty search could be a good way of evolving ANNs that =\r\nsolve classification tasks without overfitting.&lt;br&gt;&gt; &lt;br&gt;&gt; It is true=\r\n that there is tentative evidence that novelty search may evolve more compa=\r\nct solutions than objective-based search (shown in the recent GP publicatio=\r\nn and also in the original Alife conference paper) and may thus be less pro=\r\nne to overfitting. However, I think that classification is not an ideal dom=\r\nain for unconstrained novelty search. That is, I am not sure it would alway=\r\ns be better than an exhaustive or random search in such a scenario. And whi=\r\nle exhaustive or random search may be feasible for toy problems, I would be=\r\n a bit surprised if a significant breakthrough was produced through such me=\r\nans.&lt;br&gt;&gt; &lt;br&gt;&gt; The main problem with *efficiently* applying raw nove=\r\nlty search to a classification problem is that with a naive behavioral char=\r\nacterization (e.g. the concatenation of all the classes an ANN outputs over=\r\n the training set), there are no domain restrictions and a vast space of po=\r\nssible behaviors. With such a characterization, novelty search would contin=\r\nually find novel ways of partitioning the training examples in different cl=\r\nasses. The problem is, the number of possible partitions grows exponentiall=\r\ny in the number of training examples. &nbsp;&lt;br&gt;&gt; &lt;br&gt;&gt; While sometim=\r\nes learning a new way to partition classification examples may reflect an i=\r\nmportant aspect of the distribution of the training examples, NS may also e=\r\nxploit noise or incidental aspects of the training examples to generate new=\r\n classifications. For example, if the training data were 10-dimensional, bu=\r\nt only one dimension was important to classification, and the other 9 were =\r\nrandom, NS might exploit the random differences in the unimportant dimensio=\r\nns to generate a huge amount of novel classifications.&lt;br&gt;&gt; &lt;br&gt;&gt; The=\r\n problem is that in NS classification the &quot;behavior&quot; of the ANN is a direct=\r\n product of its output signals. Contrast such directness with a robot&#39;s beh=\r\navior in a maze: The location at which a robot ends up in a maze is an indi=\r\nrect product of its output signals. The robot&#39;s output signals direct its a=\r\nctions, but are subject to the virtual world in which the robot lives (a ro=\r\nbot cannot go through walls nor travel faster than its motors will allow). =\r\n&lt;br&gt;&gt; &lt;br&gt;&gt; Imagine if a maze-robot&#39;s outputs simply teleported it in=\r\nto a specific area of the maze; this is similar in spirit to a naive search=\r\n for novelty in a classification domain. There is little to learn in a raw =\r\nNS classification problem because the &quot;world&quot; in which the classifying ANN =\r\nlives in is so simple and completely unconstrained.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;I a=\r\ngree with this point. The last thing we would want from a classification al=\r\ngorithm is a uniform search of the phenotype space. On the other hand, the =\r\noptimal classification algorithm is a systematic search of all hypotheses o=\r\nrdered by their complexity under an appropriate complexity model. It is not=\r\n completely clear to me where novelty search stands between the two. It is =\r\npossible to encourage simple solutions by incorporating into the fitness fu=\r\nnction a penalty for size. This helped my multidimensional xor experiment, =\r\nbut not enough to make it competitive with ordinary performance directed se=\r\narch.&lt;br&gt;The important question is how does novelty search compare with the=\r\n theoretically optimal, but practically not very feasible (for computationa=\r\nl time reasons) systematic search of the genotype space.&nbsp; Novelty sear=\r\nch possesses the same minimal overfitting guarantee. It does not inherently=\r\n possess the same minimal underfitting guarantee and it might hold promise =\r\nfor a more reasonable computational performance. If it can be shown that no=\r\nvelty search possesses significant classification ability characteristics o=\r\nf the optimal systematic search, but achieves it with much more realistic c=\r\nomputational resources, then it will be a very significant development. Now=\r\n the question is whether this is the case.&lt;br&gt;&lt;br&gt;&lt;blockquote&gt;&gt; Constrai=\r\nnts or domain restrictions are important because they may allow a search fo=\r\nr novelty to learn about a domain; for example, searching for novelty in a =\r\nmaze incentivizes learning about how to avoid walls. That is, by avoiding w=\r\nalls a robot may end up in a novel location in the maze. Although there are=\r\n no inherent domain restrictions in a classification problem, such restrict=\r\nions can possibly be introduced artificially.&lt;br&gt;&gt; &lt;br&gt;&gt; Ken Stanley =\r\nand I have a publication on minimal criteria novelty search (http://eplex.c=\r\ns.ucf.edu/publications/2010/lehman.gecco10a.html), which provides such a wa=\r\ny of introducing artificial domain constraints. An individual in MCNS is co=\r\nnsidered only if it meets all user-imposed minimal criteria, otherwise it i=\r\ns discarded. &lt;br&gt;&gt; &lt;br&gt;&gt; An intuitive minimal criterion for classific=\r\nation problems might be maintaining at least x% accuracy (where x could be =\r\nthe accuracy that a simple nearest-neighbor classification scheme achieves)=\r\n. This would mean that an ANN must find novel classification schemes that a=\r\nre partially constrained by the correct labels of the training set. However=\r\n, I do not know if this is a good approach; there may be some domains that =\r\nare not amenable to novelty search, just as very deceptive domains provide =\r\na bad match for objective-based search.&lt;br&gt;&gt; &lt;br&gt;&gt; But, I think that =\r\na MCNS approach might be the best way to approach interesting classificatio=\r\nn problems in a novelty-search way.&lt;br&gt;&lt;br&gt;This is a possibility. However w=\r\ne risk loosing what we came for. If we use the training set for the search,=\r\n we must save information on the training set as part of the classifier. If=\r\n we save a small amount of information on the training set, then the theore=\r\ntical assurance of no-overfitting gets weaker. If we save all the training =\r\nset, the assurance will disappear.&lt;br&gt;&nbsp;&lt;br&gt;&gt; As for XOR, I did try =\r\nnovelty search with XOR classification in my initial experiments and found =\r\nthat it was able to consistently solve the problem (perhaps because there a=\r\nre only 4 training examples), although it did not provide an advantage over=\r\n objective-based search.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;I used a multidimensional vers=\r\nion. Maybe I should have called it the parity problem.&lt;br&gt;&lt;br&gt;\n\r\n--8-0995369644-0701145792=:2--\r\n\n"}}