{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Kenneth Stanley","from":"&quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"uPwjbHSZsFpjNiB8g7B6339iguFQGaeyp5RlUKxfA1Jwoz7d6fpjpT99PIP15RQbU5mxFsawBwPK8xh3_08ArMvBHsIzCz6B6SEwTZ2_67Gm","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Question Re: HyperNEAT","postDate":"1178572366","msgId":3258,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYxbzRvZStxaXU0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGYxZDBzYStlbDlsQGVHcm91cHMuY29tPg=="},"prevInTopic":3256,"nextInTopic":3259,"prevInTime":3257,"nextInTime":3259,"topicId":3234,"numMessagesInTopic":13,"msgSnippet":"Andy, It will be interesting to see whether taking a prior evolved network and designating it as the function of a single node in a higher- level network will","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 23624 invoked from network); 7 May 2007 21:12:51 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m35.grp.scd.yahoo.com with QMQP; 7 May 2007 21:12:51 -0000\r\nReceived: from unknown (HELO n20a.bullet.scd.yahoo.com) (66.94.237.49)\n  by mta9.grp.scd.yahoo.com with SMTP; 7 May 2007 21:12:51 -0000\r\nReceived: from [66.218.69.2] by n20.bullet.scd.yahoo.com with NNFMP; 07 May 2007 21:12:47 -0000\r\nReceived: from [66.218.66.77] by t2.bullet.scd.yahoo.com with NNFMP; 07 May 2007 21:12:47 -0000\r\nDate: Mon, 07 May 2007 21:12:46 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f1o4oe+qiu4@...&gt;\r\nIn-Reply-To: &lt;f1d0sa+el9l@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\r\nSubject: Question Re: HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=USiDMTz53Vjbqn99kWRQWM2HLPwdKLe8Vdsomp2Zyu86AxSJkGC0\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nAndy,\n\nIt will be interesting to see whether taking a prior evolved network=\r\n \nand designating it as the function of a single node in a higher-\nlevel ne=\r\ntwork will succeed.  My hunch is that this approach will be \nmore difficult=\r\n to leverage than it may appear because it introduces \na brittle kind of hi=\r\nerarchy that is difficult for evolution to \noptimize.   The problem is that=\r\n while such a new &quot;module&quot; may be \nuseful in some contexts, there are more =\r\ncontexts where it is a round \npeg in a square hole.  Because evolution has =\r\nno a priori method for \nknowing which case is which, it will often place th=\r\ne module in an \nunsuitable location.  \n\nMore generally, the risk can be sum=\r\nmarized as introducing large \ndiscontinuities into the search space.  Inser=\r\nting a node that is \nitself an entire ANN (perhaps even a very large substr=\r\nate) is a \nradical change that will likely lead to a phenotype that is quit=\r\ne \ndifferent from its parent. \n\nThe idea reminds me a bit of Joseph Reising=\r\ner&#39;s Modular NEAT, which \ndid show some promise, but suffered from a simila=\r\nr limitation.  \nJoe&#39;s paper is here:\n\nhttp://nn.cs.utexas.edu/keyword?reisi=\r\nnger:gecco04\n\nIn any case all new ideas involve some risk and if your gut i=\r\nnstinct \ntells you that risk can be overcome, it&#39;s still worth pursuing.\n\nk=\r\nen\n\n--- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@...&gt; wrote:\n&gt;\n&gt; Ken,\n&gt; \n=\r\n&gt;    While your point is well taken, the significance of the \n&gt; infrastruct=\r\nure differences lies not primarily in the diversity of \n&gt; building blocks, =\r\nwith possible overhead associated with its \neffective \n&gt; application in a h=\r\nypercube network, but rather the leveraging of \n&gt; prior &quot;knowledge&quot; to a ne=\r\nw but similar problem through \n&gt; complexification around an static network-=\r\nin-a-node embedded in a \n&gt; NEAT hidden node of a new problem. I believe thi=\r\ns to be the &quot;sine \nquo \n&gt; non&quot; of creating more &quot;brain-like&quot; networks.\n&gt; \n&gt;=\r\n Thanks,\n&gt;    Andy Carl\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanl=\r\ney&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Andy, \n&gt; &gt; \n&gt; &gt; I see, I understand the rati=\r\nonale.  I will be interested to see \nhow \n&gt; &gt; things go with your ideas.  T=\r\nhe main question will be whether \nthe \n&gt; &gt; system crosses the line between =\r\nenough and too much of a good \n&gt; thing. \n&gt; &gt; That is, increasing the divers=\r\nity of computational building \nblocks \n&gt; &gt; can be userful, but beyond some =\r\npoint it starts to make things \n&gt; harder \n&gt; &gt; rather than easier.  Of cours=\r\ne, it&#39;s hard to say exactly where \nthat \n&gt; &gt; line is.  We can only find out=\r\n by trying, so it will be an \n&gt; &gt; interesting experiment.\n&gt; &gt; \n&gt; &gt; ken\n&gt; &gt; =\r\n\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt;=\r\n &gt; Ken,\n&gt; &gt; &gt; \n&gt; &gt; &gt;    Recursive Supervisor NEAT is reformulated as follow=\r\ns:\n&gt; &gt; &gt; \n&gt; &gt; &gt; (a) NEAT moves from namespace to supervisor class;\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; (b) namespace is removed and all classes folded into \npopulation \n&gt; &gt; =\r\nclass;\n&gt; &gt; &gt; \n&gt; &gt; &gt; (c) params and associated code becomes a class, also me=\r\nmber of \n&gt; &gt; &gt; population class;\n&gt; &gt; &gt; \n&gt; &gt; &gt; (d) definition of node expand=\r\ned to include ability to maintain \n&gt; &gt; &gt; multiple unique inputs for hidden =\r\nand output nodes;\n&gt; &gt; &gt; \n&gt; &gt; &gt; (e) definition of node expanded to include a=\r\nbility to maintain \n&gt; &gt; &gt; multiple unique outputs for input and hidden node=\r\ns;\n&gt; &gt; &gt; \n&gt; &gt; &gt; (f) definition of node expanded to include ability to maint=\r\nain \n&gt; &gt; &gt; activation function, network or population;\n&gt; &gt; &gt; \n&gt; &gt; &gt; (g) act=\r\nivation and genome definition modified to address \n&gt; arbitrary \n&gt; &gt; &gt; recur=\r\nsive network definition and topology;\n&gt; &gt; &gt; \n&gt; &gt; &gt;    Given the above, the =\r\ngenome definition of the CPPN, \ncomprised \n&gt; of \n&gt; &gt; &gt; the both the evolved=\r\n substrate and hypercube subnetworks, may \nbe \n&gt; &gt; &gt; embedded as either a s=\r\ntatic substrate network-in-a-node, an \n&gt; &gt; adaptive \n&gt; &gt; &gt; incremental evol=\r\nvable network-in-a-node, static vote-taker \n&gt; &gt; population-\n&gt; &gt; &gt; in-a-node=\r\n, or an adaptive incremental evolvable vote-taker \n&gt; &gt; population-\n&gt; &gt; &gt; in=\r\n-a-node. \n&gt; &gt; &gt; \n&gt; &gt; &gt;    The issue is the required infrastructure to achie=\r\nve \nrecursion \n&gt; &gt; and \n&gt; &gt; &gt; embedability. This combined with the need to =\r\nexpand the \n&gt; functional \n&gt; &gt; &gt; vocabulary of the hypercube network are why=\r\n (d) and (e) above \nare \n&gt; &gt; &gt; important. Adequate means to supervise appli=\r\ncation of a rich \nand \n&gt; &gt; &gt; diverse functional vocabulary, which can also =\r\ninclude prior \n&gt; evolved \n&gt; &gt; &gt; networks and/or populations, whether static=\r\n or adaptive \n&gt; incremental \n&gt; &gt; &gt; evolved, can be developed. There is no r=\r\neason to tie our hands \n&gt; with \n&gt; &gt; &gt; an inordinately small set of monolith=\r\n activation functions \nthat \n&gt; &gt; &gt; conveniently fit within the confines of =\r\none-input/one-output \nper \n&gt; &gt; node.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Thanks,\n&gt; &gt; &gt;    Andy Car=\r\nl\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; \n=\r\nwrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Andy,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I think all these ideas are v=\r\nalid and deserve to be \nexplored.  \n&gt; &gt; &gt; &gt; Automation is a potentially sig=\r\nnificant future direction so \n&gt; &gt; &gt; &gt; heuristics for it are an interesting =\r\ntopic to pursue.  I \nthink \n&gt; &gt; your \n&gt; &gt; &gt; &gt; suggestion about hidden layer=\r\ns is reasonable and could work \nin \n&gt; a \n&gt; &gt; &gt; lot \n&gt; &gt; &gt; &gt; of cases.  \n&gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; Can you expand on your idea about embedding?  How do you \n&gt; e=\r\nnvision \n&gt; &gt; &gt; &gt; taking something already evolved and embedding it into \nan=\r\nother \n&gt; &gt; &gt; &gt; network?  That sounds interesting (again because it can \n&gt; &gt;=\r\n potentially \n&gt; &gt; &gt; &gt; exploit geometric relationships already uncovered), b=\r\nut what \n&gt; are \n&gt; &gt; &gt; you \n&gt; &gt; &gt; &gt; envisioning would be involved?  Would th=\r\ne CPPN also need to \n&gt; &gt; &gt; &gt; be &quot;embedded&quot; in some sense into yet another C=\r\nPPN?  Or would \n&gt; you \n&gt; &gt; &gt; just \n&gt; &gt; &gt; &gt; assume that one substrate a stat=\r\nic structure that is now \npart \n&gt; of \n&gt; &gt; &gt; some \n&gt; &gt; &gt; &gt; larger substrate =\r\nthat is operated on by another CPPN?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\n--- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;=\r\n Ken,\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;    Two issues come to mind. The first is degree =\r\nof \nrequired \n&gt; &gt; user \n&gt; &gt; &gt; &gt; &gt; intervention in the determination of subs=\r\ntrate topology. \nThe \n&gt; &gt; &gt; second \n&gt; &gt; &gt; &gt; &gt; issue is embedability.\n&gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; &gt;    It seems reasonable that the Hypercube network only has \n=\r\n&gt; &gt; &gt; meaning \n&gt; &gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; &gt; the context of the specific substrate =\r\nemployed during the \n&gt; &gt; &gt; &gt; &gt; evolutionary process. The addition of hidden=\r\n nodes to the \n&gt; &gt; &gt; substrate \n&gt; &gt; &gt; &gt; &gt; topology falls outside the scalab=\r\nility of a Hypercube \nnetwork \n&gt; &gt; &gt; &gt; &gt; associated with an increase in res=\r\nolution in the original \n&gt; &gt; &gt; &gt; dimensions \n&gt; &gt; &gt; &gt; &gt; of the substrate inp=\r\nut and output nodes.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;    Taking your position regarding=\r\n attempting to cast the \n&gt; &gt; problem \n&gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; manner=\r\n that facilitates the geometric relationships (I&#39;m \n&gt; using \n&gt; &gt; &gt; the \n&gt; &gt;=\r\n &gt; &gt; &gt; term geometric to represent the larger n-dimensional \ndesign \n&gt; &gt; &gt; =\r\nspace), \n&gt; &gt; &gt; &gt; &gt; it would appear that a reasonable approach would be to l=\r\net \n&gt; the \n&gt; &gt; &gt; &gt; &gt; problem dictate the substrate input and output nodes, =\r\nand \n&gt; then \n&gt; &gt; &gt; &gt; simply \n&gt; &gt; &gt; &gt; &gt; duplicate the substrate input and ou=\r\ntput nodes as \nsubstrate \n&gt; &gt; &gt; hidden \n&gt; &gt; &gt; &gt; &gt; nodes, and let the thresh=\r\nolding of weights in the \nHypercube \n&gt; &gt; &gt; network \n&gt; &gt; &gt; &gt; &gt; separate the =\r\nwheat from the chaff. If there are input-to-\n&gt; input \n&gt; &gt; or \n&gt; &gt; &gt; &gt; &gt; out=\r\nput-to-output proximity relationships, they will emerge \n&gt; &gt; &gt; through \n&gt; &gt;=\r\n &gt; &gt; &gt; evolution of the Hypercube network.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;    I&#39;m just=\r\n trying to somehow automate the process and let \n&gt; the \n&gt; &gt; &gt; user \n&gt; &gt; &gt; &gt;=\r\n &gt; focus on problem definition (i.e. substrate input and \noutput \n&gt; &gt; &gt; &gt; n=\r\nodes). \n&gt; &gt; &gt; &gt; &gt; If this approach is taken, then the genome would need to =\r\n\n&gt; &gt; include \n&gt; &gt; &gt; &gt; both \n&gt; &gt; &gt; &gt; &gt; the substrate and hypercube topology =\r\ndefinitions. \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;    This leads into the second issue of e=\r\nmbedability, or \n&gt; taking \n&gt; &gt; &gt; what \n&gt; &gt; &gt; &gt; &gt; you have evolved and have =\r\nthe ability to embed it into a \n&gt; higher \n&gt; &gt; &gt; &gt; level \n&gt; &gt; &gt; &gt; &gt; network.=\r\n Which is another one of the &quot;multiple reasons&quot; \nwhy I \n&gt; &gt; &gt; &gt; believe \n&gt; =\r\n&gt; &gt; &gt; &gt; the ability to maintain multiple unique inputs and outputs \n&gt; for \n=\r\n&gt; &gt; a \n&gt; &gt; &gt; &gt; node \n&gt; &gt; &gt; &gt; &gt; in a network, substrate or hypercube, is ess=\r\nential to the \n&gt; &gt; &gt; &gt; development \n&gt; &gt; &gt; &gt; &gt; of more &quot;brain-like&quot; networks=\r\n.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt;    Andy Carl\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; \n&gt; &gt; =\r\nwrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Andy,\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Sure, I under=\r\nstand it was just an example.  I went with \nthe \n&gt; &gt; &gt; &gt; example \n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; just for illustration, but let me give a shot at a more \n&gt; &gt; general \n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; answer:\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; I think the most general answer =\r\nis that to the extent \n&gt; inputs \n&gt; &gt; &gt; and \n&gt; &gt; &gt; &gt; &gt; &gt; outputs really are =\r\napples and oranges there is still \n&gt; valuable \n&gt; &gt; &gt; &gt; &gt; &gt; information that=\r\n can be included with respect to how \nthey \n&gt; are \n&gt; &gt; &gt; &gt; &gt; &gt; separately a=\r\nrranged.  It is not only the relationship of \n&gt; &gt; inputs \n&gt; &gt; &gt; &gt; to \n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; outputs, but the relations of inputs to each other (and \n&gt; &gt; outputs=\r\n \n&gt; &gt; &gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; each other) that is potentially valuable.  \n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; On the other hand, I don&#39;t think inputs and outputs are=\r\n \n&gt; &gt; really \n&gt; &gt; &gt; &gt; &gt; often \n&gt; &gt; &gt; &gt; &gt; &gt; going to truly be apples and ora=\r\nnges since both normally \n&gt; will \n&gt; &gt; &gt; be \n&gt; &gt; &gt; &gt; at \n&gt; &gt; &gt; &gt; &gt; &gt; least a=\r\nbout the same world, i.e. what I see in the world \n&gt; vs. \n&gt; &gt; &gt; what \n&gt; &gt; &gt;=\r\n &gt; I \n&gt; &gt; &gt; &gt; &gt; &gt; do in the world; so there is an inherent conceptual \n&gt; &gt; =\r\n&gt; relationship \n&gt; &gt; &gt; &gt; &gt; &gt; between them in most contexts.  While it is pos=\r\nsible to \n&gt; pose \n&gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; problem in a way that removes some of =\r\nthat relationship \n&gt; (such \n&gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; &gt; &gt; your example)=\r\n, it should normally be possible to recast \nthe \n&gt; &gt; &gt; &gt; problem \n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; at least in part to restore it.  That is, there is more \n&gt; than \n&gt; &gt; &gt; o=\r\nne \n&gt; &gt; &gt; &gt; &gt; way \n&gt; &gt; &gt; &gt; &gt; &gt; to pose a problem from a geometric standpoin=\r\nt.  In \ngeneral \n&gt; if \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; inputs and outputs are both a=\r\nbout the same world, then \nsome \n&gt; &gt; &gt; &gt; method \n&gt; &gt; &gt; &gt; &gt; &gt; is probably av=\r\nailable.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; At the same time, even in cases where the=\r\nre is really no \n&gt; &gt; &gt; &gt; &gt; &gt; relationship whatsoever, there is still utilit=\r\ny in \n&gt; arranging \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; inputs and outputs separately in =\r\nways that correspond to \n&gt; &gt; their \n&gt; &gt; &gt; &gt; &gt; &gt; respective geometric contex=\r\nts.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoo=\r\ngroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Ken,\n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt;    The cited example modification of the paper \ng=\r\neometry \n&gt; &gt; &gt; problem \n&gt; &gt; &gt; &gt; &gt; &gt; was \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; only to provide an i=\r\nnstance in which the \ndimensionality \n&gt; of \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; substr=\r\nate inputs and outputs, as applied to the \nHypercube \n&gt; &gt; &gt; &gt; inputs, \n&gt; &gt; =\r\n&gt; &gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; stated in the original attempted general \n&gt; chara=\r\ncterization, \n&gt; &gt; &gt; were \n&gt; &gt; &gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; differing dimensional=\r\nity.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt;    I believe the jist of your other conte=\r\nmporaneous \n&gt; &gt; &gt; &gt; conversations \n&gt; &gt; &gt; &gt; &gt; &gt; is \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; that addit=\r\nional a priori knowledge maybe interjected \nvia \n&gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Hyp=\r\nercube inputs, since:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; (a) this additional info=\r\nrmation is associated with the \n&gt; &gt; &gt; &gt; substrate \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; input/outp=\r\nut node, though not expressly represented in \n&gt; &gt; same, \n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; (b) this additional information is segregated to \neith=\r\ner \n&gt; &gt; &gt; &gt; &gt; the &quot;from&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; or &quot;to&quot; nodes associated with the c=\r\nurrent substrate \nlink \n&gt; &gt; &gt; under \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; consideration.\n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt;    I am only attempting to clarify the seemly more \n&gt; g=\r\neneral \n&gt; &gt; &gt; &gt; &gt; &gt; condition \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; in which the additional &quot;infor=\r\nmation&quot; associated with \na \n&gt; &gt; &gt; &gt; substrate \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; input node is =\r\nof different content and/or \ndimensionality \n&gt; &gt; than \n&gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; additional &quot;information&quot; associated with a substrate \n&gt; output \n&gt; &gt; =\r\n&gt; &gt; node \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; (i.e. apples and oranges, not just oranges and \nora=\r\nnges). \n&gt; &gt; The \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; specifics of the cited modified example is i=\r\nrrelevant \n&gt; &gt; except \n&gt; &gt; &gt; in \n&gt; &gt; &gt; &gt; &gt; &gt; its \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; attempt to =\r\nillustrate this point.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;  =\r\n  Andy Carl\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogr=\r\noups.com, &quot;Kenneth Stanley&quot; \n&gt; &lt;kstanley@&gt; \n&gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Andy,\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; There are still a lo=\r\nt of ways to configure the \n&gt; substrate \n&gt; &gt; &gt; for \n&gt; &gt; &gt; &gt; &gt; &gt; such a \n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; problem, so it&#39;s difficult to give a general \nanswer.  \n&gt; For =\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; example, \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; you might have a single 2D input lay=\r\ner connecting to \na \n&gt; &gt; &gt; single \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; no=\r\nde (yes/no); or you could have a multilayer 3D \ninput \n&gt; &gt; &gt; field \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; (where \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; each 2D layer is a type of object) connecting =\r\nto a \n2D \n&gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; &gt; &gt; field \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (where each pixe=\r\nl answers the question, is there \n&gt; overlap \n&gt; &gt; &gt; &gt; &gt; &gt; here?).  \n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; You might have a hidden layer, and you might not.  \nYou \n&gt; &gt; &gt; migh=\r\nt \n&gt; &gt; &gt; &gt; &gt; &gt; allow \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the hidden layer to express lateral c=\r\nonnections, and \n&gt; you \n&gt; &gt; &gt; &gt; might \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; not.  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n You might have a 3D hidden layer or a 2D hidden \nlayer.  \n&gt; &gt; You \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; might \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; embed everything in 3D, or you might map a 3D \n=\r\n&gt; coordinate \n&gt; &gt; to \n&gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; 2D, \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; or \n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; a 2D or a 3D, etc..\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; In each case, t=\r\nhe implications are different about \nhow \n&gt; &gt; &gt; &gt; &gt; &gt; proximities \n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; are incorporated or expressed.  In some cases it can \nbe \n&gt; &gt; &gt; &gt; &gt;=\r\n explicit \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; within parts of the substrate; in some cases it =\r\nis \n&gt; &gt; &gt; implicit.  \n&gt; &gt; &gt; &gt; &gt; &gt; For \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; example, if there is=\r\n only a single output node and a \n2D \n&gt; &gt; &gt; sheet \n&gt; &gt; &gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; inputs, then the CPPN does not even need to take a \n&gt; target \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; location \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; as input, since there is only one target.  I=\r\nn that \ncase \n&gt; &gt; you \n&gt; &gt; &gt; &gt; &gt; just \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; query for each input=\r\n node what weight is coming out \nof \n&gt; &gt; it.  \n&gt; &gt; &gt; &gt; In \n&gt; &gt; &gt; &gt; &gt; &gt; such=\r\n \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; a case, it is true that you do not explicitly \nprovide a =\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; proximity \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; input to the CPPN; however proximit=\r\ny is still \nimplicit \n&gt; &gt; &gt; within \n&gt; &gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; repres=\r\nentation since input nodes that are near each \n&gt; other \n&gt; &gt; &gt; are \n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; also \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; nearby in the function domain of the CPPN, that i=\r\ns, \nit \n&gt; &gt; can \n&gt; &gt; &gt; &gt; use \n&gt; &gt; &gt; &gt; &gt; &gt; that \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; nearness ev=\r\nen though it is not explicitly provided \nas \n&gt; &gt; &gt; input.  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Please let me know if I didn&#39;t answer adequately and \nI \n=\r\n&gt; &gt; can \n&gt; &gt; &gt; &gt; try \n&gt; &gt; &gt; &gt; &gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; be \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; mor=\r\ne specific, but I might need more detail on the \n&gt; &gt; precise \n&gt; &gt; &gt; &gt; &gt; &gt; s=\r\ncenario \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; you are considering.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoo=\r\ngroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; \nwrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n Ken,\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;    One troubling &quot;detail&quot; is tha=\r\nt of differences \nin \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; dimensionality \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; betwe=\r\nen substrate inputs and outputs. In the \nexamples \n&gt; &gt; &gt; used \n&gt; &gt; &gt; &gt; in \n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; various papers, the dimensionality of th=\r\ne \nsubstrate \n&gt; &gt; input \n&gt; &gt; &gt; &gt; and \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; nodes, as applied to the Hypercube inputs, were \n&gt; &gt; identical \n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; (i.e. \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; x_in, \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; y_in, x_out, y_out). =\r\nThis simplifies the concept \nof \n&gt; &gt; &gt; &gt; distance. \n&gt; &gt; &gt; &gt; &gt; &gt; But \n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; problem could just as easily have been: Do=\r\n the two \n&gt; &gt; &gt; squares \n&gt; &gt; &gt; &gt; on \n&gt; &gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; vis=\r\nual field overlap? (yes/no). In this case, \n&gt; &gt; &gt; &gt; dimensionality \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; substrate input and output =\r\nnodes, as applied to \nthe \n&gt; &gt; &gt; &gt; Hypercube \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; inputs, \n&gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; have differing dimensionality, even though the \nanswer \n&gt; &gt; i=\r\ns \n&gt; &gt; &gt; &gt; &gt; &gt; strongly \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; dependent on proximity in the in=\r\nput visual field. \nAny \n&gt; &gt; &gt; &gt; &gt; &gt; experience \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; or \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; comments on this seemly more common general \ncondition?\n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;    Andy Carl \n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanle=\r\ny&quot; \n&gt; &gt; &gt; &lt;kstanley@&gt; \n&gt; &gt; &gt; &gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; Andy, I&#39;d say this is a about right.  I \nelaborate a \n&gt; &gt; bit \n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; below \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; each \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; part of your questi=\r\non:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;=\r\nafcarl2&quot; &lt;a.carl@&gt; \n&gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\nJason or Ken,\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;    I am attempti=\r\nng to understand the nature of \n&gt; &gt; inputs \n&gt; &gt; &gt; & \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; output=\r\ns \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; applied to both the Hypercub=\r\ne and substrate \n&gt; &gt; networks, \n&gt; &gt; &gt; &gt; &gt; &gt; without \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; bein=\r\ng \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; limited to the geometric nature of the visual-\n&gt; b=\r\nased \n&gt; &gt; &gt; &gt; &gt; &gt; examples. \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; exa=\r\nmples provided were helpful, but I am \nstriving \n&gt; &gt; for \n&gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; more \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; general \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; guideline for =\r\napplication to more general \n&gt; problems.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt;    Would it be correct to say that:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (a) Substrate Network: Inputs & Outputs \n&gt; identified \n&gt; &gt;=\r\n as \n&gt; &gt; &gt; &gt; &gt; &gt; typical \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; applica=\r\ntion of conventional NEAT to a problem \nof \n&gt; &gt; &gt; &gt; interest;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; This statement is correc=\r\nt although you might do \n&gt; &gt; things \n&gt; &gt; &gt; &gt; that \n&gt; &gt; &gt; &gt; &gt; &gt; you \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; would \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; avoid doing in conventional NEAT beca=\r\nuse \nHyperNEAT \n&gt; &gt; can \n&gt; &gt; &gt; &gt; deal \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\nso \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; many more inputs and outputs.  So you might for \n&gt; =\r\n&gt; example \n&gt; &gt; &gt; &gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; high \n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; resolution representation of your possible \n&gt; decisions, \n=\r\n&gt; &gt; &gt; &gt; which \n&gt; &gt; &gt; &gt; &gt; &gt; is \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; something you normally w=\r\nouldn&#39;t do in regular \nNEAT.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (b)=\r\n Hypercube Network: (i) Inputs: Other \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; descriptors/paramete=\r\nrs \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (i.e. \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; geometric coordinates =\r\nbeing a subset thereof), \n&gt; &gt; &gt; &gt; associated \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; given \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; substrate networ=\r\nk node (i.e. like a timestamp \n&gt; &gt; &gt; &gt; associated \n&gt; &gt; &gt; &gt; &gt; &gt; with \n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; coordinate point comprising a trajectory=\r\n), \n&gt; mutually \n&gt; &gt; &gt; &gt; &gt; &gt; exclusive \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; descriptor/parameter expressly identified in=\r\n \nthe \n&gt; &gt; &gt; &gt; &gt; substrate \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; node, \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; each=\r\n \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; being collected together and collectively \n&gt; &gt; iden=\r\ntified \n&gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; either \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; a &quot;from&quot; \n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; or &quot;to&quot; terminator of a link between any two \n&gt; &gt; &gt; substr=\r\nate \n&gt; &gt; &gt; &gt; &gt; &gt; nodes; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; and \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (ii) \n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Output: Weight of link between the currently \n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; identified &quot;from&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; and &quot;to&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\nsubstrate nodes.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; I think this characterizes it well, although \nthere \n&gt; is \n&gt; &gt; &gt; &gt; ev=\r\nen \n&gt; &gt; &gt; &gt; &gt; &gt; more \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; flexibility.  You can for example=\r\n use additional \n&gt; &gt; &gt; outputs \n&gt; &gt; &gt; &gt; on \n&gt; &gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; CPPN \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; to represent additional attributes of links \n=\r\nand/or \n&gt; &gt; &gt; &gt; nodes.  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The times=\r\ntamp idea is interesting- if I \nunderstand \n&gt; &gt; &gt; &gt; &gt; correctly \n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; it \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; would \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; cause the network to cha=\r\nnge over time in a \n&gt; &gt; &gt; deterministic \n&gt; &gt; &gt; &gt; &gt; &gt; way.  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; Although maybe I&#39;m misunderstanding.  But \ncertainly \n&gt; &gt; &gt; &gt; things \n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; like \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; that \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; are possible.=\r\n  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; It&#39;s difficult to write an accu=\r\nrate general \n&gt; &gt; description \n&gt; &gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; exactly \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; &gt; &gt; what goes in and comes out of the CPPN at this \n&gt; point \n&gt; &gt; &gt;=\r\n &gt; &gt; because \n&gt; &gt; &gt; &gt; &gt; &gt; I \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; have \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; no d=\r\noubt that at this early stage that new ideas \n&gt; are \n&gt; &gt; &gt; &gt; going \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; broaden \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the possibilities b=\r\neyond what I am currently \naware \n&gt; &gt; &gt; of.   \n&gt; &gt; &gt; &gt; &gt; But \n&gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; what \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; you \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; said captures it pretty=\r\n well for now.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}