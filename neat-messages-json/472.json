{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"ZMHDycL5teAZdZfJFrfem_xKclaEWv_TOFT4Oq--2ghTsJ6PWaPkWE5vFoVi8tW9AgZLb8oGhCSWDFTf_nG7ah1e67YdfKuFOA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Idea concerning image enlargement...","postDate":"1078580762","msgId":472,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwNDlENjFBLjQwOTAyMDNAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PEJBWTItRjIxMWJzRkx5TUQ0NlkwMDAyNjc4ZkBob3RtYWlsLmNvbT4=","referencesHeader":"PEJBWTItRjIxMWJzRkx5TUQ0NlkwMDAyNjc4ZkBob3RtYWlsLmNvbT4="},"prevInTopic":469,"nextInTopic":473,"prevInTime":471,"nextInTime":473,"topicId":469,"numMessagesInTopic":32,"msgSnippet":"Hi John, As far as evolving a parameterized/continous enlargment NN goes I think you re on the right lines but I m a bit concerned that you are trying to jump","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 83702 invoked from network); 6 Mar 2004 13:45:58 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m6.grp.scd.yahoo.com with QMQP; 6 Mar 2004 13:45:58 -0000\r\nReceived: from unknown (HELO shockwave.systems.pipex.net) (62.241.160.9)\n  by mta1.grp.scd.yahoo.com with SMTP; 6 Mar 2004 13:45:58 -0000\r\nReceived: from dsl.pipex.com (81-86-175-101.dsl.pipex.com [81.86.175.101])\n\tby shockwave.systems.pipex.net (Postfix) with ESMTP id C52991C000AC\n\tfor &lt;neat@yahoogroups.com&gt;; Sat,  6 Mar 2004 13:45:52 +0000 (GMT)\r\nMessage-ID: &lt;4049D61A.4090203@...&gt;\r\nDate: Sat, 06 Mar 2004 13:46:02 +0000\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;BAY2-F211bsFLyMD46Y0002678f@...&gt;\r\nIn-Reply-To: &lt;BAY2-F211bsFLyMD46Y0002678f@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 62.241.160.9\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] Idea concerning image enlargement...\r\nX-Yahoo-Group-Post: member; u=127853030\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nHi John,\n\nAs far as evolving a parameterized/continous enlargment NN goes I think \nyou&#39;re on the right lines but I&#39;m a bit concerned that you are trying to \n&#39;jump the gun&#39; on this one. Remember that the golden rule with NN&#39;s is \nto keep the function you are trying to instill into the network as \nsimple as possible. The new technique has added complexity to the \nrequired function by introducing the need to interpret coordinates and \nthen to modify the enlargment function part of the network based upon \nthose coordinates. Initially I would stick with the fixed multiplicative \nfactor - when you have that cracked *then* move on to trying a \nparameterized enlargment.\n\nWhen/if you do try this I also would initially start with just a single \npixel input (and thus a single coordinate) and move onto the an input \nrange later - again this is additional complexity which NEAT may not be \nable to evolve. You also need to specify an enlargment factor somewhere \ndon&#39;t you? so that the network knows the bounds of the output pixel \ncoordinate system?\n\nColin.\n\nJohn Arrowwood wrote:\n\n&gt;&gt;From the beginning, I was concerned about one thing:  The output is a fixed \n&gt;multiplicative factor.  I didn&#39;t like that.  I suspect that deep in the \n&gt;bowels of the network is a continuous function, but how we access it renders \n&gt;it discreet.  I really wanted continuous, but figured I had to settle for \n&gt;discreet.\n&gt;\n&gt;But this morning, I had an idea.  Tell me if you think this might work...\n&gt;\n&gt;Instead of having an output matrix, have only a single output node, \n&gt;representing a single output pixel.  Then add four additional inputs:  The \n&gt;x,y position of the upper left corner of the region of interest, and the \n&gt;lower right corner.  The output is to represent the average of the function \n&gt;described by the rest of the network at the specified location relative to \n&gt;the input space.  0,0 represents the upper left corner of the input sample, \n&gt;and 1,1 represents the opposite corner.\n&gt;\n&gt;I realize that it would make more sense if described visually.  I&#39;ll try...\n&gt;\n&gt;Input:\n&gt;[  ] bias\n&gt;[  ][  ][  ][  ]  pixels\n&gt;[  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ]\n&gt;[  ] x1\n&gt;[  ] y1\n&gt;[  ] x2\n&gt;[  ] y2\n&gt;\n&gt;Output:\n&gt;[  ] output pixel value that is the average for the region x1,y1-x2,y2\n&gt;\n&gt;Thus, the output region would be (for a 2x enlargement)\n&gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt;[  ][  ][a][  ][  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ][b][  ][  ][  ]\n&gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt;[  ][  ][  ][  ][  ][  ][  ][  ]\n&gt;\n&gt;So if x1 = 0.25 and x2 = 0.375, y1=0.25 and y2=0.375, the output of the \n&gt;network should be the pixel labeled &#39;a&#39;.  Whereas, if all other input is \n&gt;kept the same but x1=0.5, x2=0.625, y1=0.625, y2=0.75, then the output \n&gt;corresponds to &#39;b&#39;.  If I were to input 0,0-0.25,0.25, I should get as an \n&gt;output the value of the input pixel at 0,0.  And once trained, I could get \n&gt;ANY level of enlargement by just sampling the network at progressively \n&gt;smaller intervals.\n&gt;\n&gt;The best part is, it is more conducive to complexification.  With a number \n&gt;of input nodes, and only a single output node, it can complexify the way it \n&gt;should.\n&gt;\n&gt;So, what do you think?  Sound plausable?  Any known reason why such an \n&gt;approach might be doomed to failure?\n&gt;\n&gt;-- John\n&gt;\n&gt;__\n&gt;\n\n\n\n"}}