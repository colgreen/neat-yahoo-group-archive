{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"K7ip-CMb37VZYYHT5v6nG6_JO49ZrbdmzZCVxKes-0mMokggvcaQCtxkrooAXG3pENLiKx1DTl0fM7zE7-Wfs62I","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Investigating whether HyperNEAT produces modular neural networks (new HyperNEAT paper)","postDate":"1271011827","msgId":5199,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM3RTc5MjMzLjMxRTBEJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":5198,"nextInTime":5200,"topicId":5199,"numMessagesInTopic":1,"msgSnippet":"Hello all- I am pleased to announce a new HyperNEAT paper. Clune J, Beckmann BE, McKinley PK, and Ofria C (2010) Investigating whether HyperNEAT produces","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 95349 invoked from network); 11 Apr 2010 18:50:35 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m10.grp.re1.yahoo.com with QMQP; 11 Apr 2010 18:50:35 -0000\r\nX-Received: from unknown (HELO mail-gy0-f178.google.com) (209.85.160.178)\n  by mta2.grp.sp2.yahoo.com with SMTP; 11 Apr 2010 18:50:35 -0000\r\nX-Received: by gyh3 with SMTP id 3so2262046gyh.9\n        for &lt;neat@yahoogroups.com&gt;; Sun, 11 Apr 2010 11:50:34 -0700 (PDT)\r\nX-Received: by 10.101.189.8 with SMTP id r8mr5387919anp.104.1271011834677;\n        Sun, 11 Apr 2010 11:50:34 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from [10.0.1.7] (c-98-243-195-159.hsd1.mi.comcast.net [98.243.195.159])\n        by mx.google.com with ESMTPS id 23sm3249950iwn.2.2010.04.11.11.50.32\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Sun, 11 Apr 2010 11:50:33 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.13.0.080930\r\nDate: Sun, 11 Apr 2010 14:50:27 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C7E79233.31E0D%jclune@...&gt;\r\nThread-Topic: Investigating whether HyperNEAT produces modular neural networks\n (new HyperNEAT paper)\r\nThread-Index: AcrZp9nH+i9pWusqDEOpd1MEBsqGZw==\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;ISO-8859-1&quot;\r\nContent-transfer-encoding: quoted-printable\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Investigating whether HyperNEAT produces modular neural networks (new\n HyperNEAT paper)\r\nX-Yahoo-Group-Post: member; u=211599040; y=RQ0ruo89nqIp88oRpBoEds3N8BygV7131HZGpOqXyIfTDad-Gm0U\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nHello all-\n\nI am pleased to announce a new HyperNEAT paper.\n\nClune J, Beckm=\r\nann BE, McKinley PK, and Ofria C (2010)\nInvestigating whether HyperNEAT pro=\r\nduces modular neural networks\n\nProceedings of the Genetic and Evolutionary =\r\nComputation Conference. To\nappear.\n\nLink to pdf: http://tinyurl.com/cluneEt=\r\nAl2010\n\nAbstract: HyperNEAT represents a class of neuroevolutionary algorit=\r\nhms that\ncaptures some of the power of natural development with a computati=\r\nonally\nefficient high-level abstraction of development. This class of algor=\r\nithms is\nintended to provide many of the desirable properties produced in b=\r\niological\nphenotypes by natural developmental processes, such as regularity=\r\n,\nmodularity and hierarchy. While it has been previously shown that HyperNE=\r\nAT\nproduces regular artificial neural network (ANN) phenotypes, in this pap=\r\ner\nwe investigated the open question of whether HyperNEAT can produce modul=\r\nar\nANNs. We conducted such research on problems where modularity should be\n=\r\nbeneficial, and found that HyperNEAT failed to generate modular ANNs. We\nth=\r\nen imposed modularity on HyperNEAT=B9s phenotypes and its performance\nimpro=\r\nved, demonstrating that modularity increases performance on this\nproblem. W=\r\ne next tested two techniques to encourage modularity in HyperNEAT,\nbut did =\r\nnot observe an increase in either modularity or performance.\nFinally, we co=\r\nnducted tests on a simpler problem that requires modularity\nand found that =\r\nHyperNEAT was able to rapidly produce modular solutions that\nsolved the pro=\r\nblem. We therefore present the first documented case of\nHyperNEAT producing=\r\n a modular phenotype, but our inability to encourage\nmodularity on harder p=\r\nroblems where modularity would have been beneficial\nsuggests that more work=\r\n is needed to increase the likelihood that HyperNEAT\nand similar algorithms=\r\n produce modular ANNs in response to challenging,\ndecomposable problems.\n\nI=\r\n look forward to hearing what you think of these results.\n\n\nBest regards,\nJ=\r\neff Clune\n\nDigital Evolution Lab, Michigan State University\njclune@...\n=\r\nwww.msu.edu/~jclune\n\n\n\n\n\n"}}