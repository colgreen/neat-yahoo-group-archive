{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":206967455,"authorName":"Julian Togelius","from":"Julian Togelius &lt;julian@...&gt;","profile":"jtogel","replyTo":"LIST","senderId":"kMZrKw-VDmxIS2pjMMQAudmKKtKuHFadB6-n11Jxtkbxak0fIVgKFX526ky4TgXCjZBTzIAO2HPhTAs-JQsGqJjF7iKeKwkg-IHuZQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Quantitative vs. Qualitative Results","postDate":"1366624504","msgId":6063,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBSFVvS29vb3hKS1cyLUJHdTQwWj1uOFNqT0J3ZEJvbnNZSDZVYistcF9fQlFFRmFWZ0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PGtrdjdvMCt0b3RnQGVHcm91cHMuY29tPg==","referencesHeader":"PDJCODc1QzE4LUNCODktNDlDNy05NDhFLTI3RTU3MUZDNjgyNUBoYXBweWNvZGVycy5vcmc+CTxra3Y3bzArdG90Z0BlR3JvdXBzLmNvbT4="},"prevInTopic":6062,"nextInTopic":6064,"prevInTime":6062,"nextInTime":6064,"topicId":6038,"numMessagesInTopic":46,"msgSnippet":"Thanks Ken - that was a very worthwile little essay to read, and I think I agree with all of it. In analysing the problem of veils[s] of needless","rawEmail":"Return-Path: &lt;julian.togelius@...&gt;\r\nX-Sender: julian.togelius@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 90727 invoked from network); 22 Apr 2013 09:55:05 -0000\r\nX-Received: from unknown (10.193.84.168)\n  by m5.grp.bf1.yahoo.com with QMQP; 22 Apr 2013 09:55:05 -0000\r\nX-Received: from unknown (HELO mail-wi0-f176.google.com) (209.85.212.176)\n  by mta6.grp.bf1.yahoo.com with SMTP; 22 Apr 2013 09:55:05 -0000\r\nX-Received: by mail-wi0-f176.google.com with SMTP id hj19so3995943wib.15\n        for &lt;neat@yahoogroups.com&gt;; Mon, 22 Apr 2013 02:55:04 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.194.3.14 with SMTP id 14mr46166343wjy.2.1366624504452; Mon,\n 22 Apr 2013 02:55:04 -0700 (PDT)\r\nX-Received: by 10.180.206.41 with HTTP; Mon, 22 Apr 2013 02:55:04 -0700 (PDT)\r\nIn-Reply-To: &lt;kkv7o0+totg@...&gt;\r\nReferences: &lt;2B875C18-CB89-49C7-948E-27E571FC6825@...&gt;\n\t&lt;kkv7o0+totg@...&gt;\r\nDate: Mon, 22 Apr 2013 11:55:04 +0200\r\nX-Google-Sender-Auth: 6TLvN4wh_EGa93sMZ03TYVgElCo\r\nMessage-ID: &lt;CAHUoKoooxJKW2-BGu40Z=n8SjOBwdBonsYH6Ub+-p__BQEFaVg@...&gt;\r\nTo: neat &lt;neat@yahoogroups.com&gt;\r\nContent-Type: multipart/alternative; boundary=047d7b3a80ac21232d04daf010d9\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Julian Togelius &lt;julian@...&gt;\r\nSubject: Re: [neat] Quantitative vs. Qualitative Results\r\nX-Yahoo-Group-Post: member; u=206967455\r\nX-Yahoo-Profile: jtogel\r\n\r\n\r\n--047d7b3a80ac21232d04daf010d9\r\nContent-Type: text/plain; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nThanks Ken - that was a very worthwile little essay to read, and I think I\n=\r\nagree with all of it.\n\nIn analysing the problem of &quot;veils[s] of needless qu=\r\nantificaiton&quot;, I think\nwe should distinguish clearly between the problems o=\r\nf feeling the need of\nhaving quantitative results in there, and for some re=\r\nason measuring the\nwrong things.\n\nI think the culture in top journals and U=\r\nS-style &quot;selective&quot; conferences of\naccepting very few papers very much cont=\r\nributes to this problems. A\nresearcher might write a non-quantitative paper=\r\n that he/she is very happy\nwith and thinks says everything that should be s=\r\naid, but then gets\n(rightly) nervous about some reviewer tearing the paper =\r\napart and therefore\ndecides to cram in a table of\npointless quantitative &quot;r=\r\nesults&quot;.\n\nEven worse than feeling that you should need to provide quantitat=\r\nive\nresults, is feeling that you should provide quantitative results that s=\r\nhow\nthat your algorithm is somehow &quot;better&quot; according to some uni-dimension=\r\nal\nmetric &quot;performance&quot;. I&#39;ve several times had papers rejected from good\nj=\r\nournals (and eventually published in other good journals after a delay of\na=\r\n year or two) because while the papers had ample quantitative results,\nthes=\r\ne results did not show that the new algorithm/method was &quot;good&quot; enough.\nFor=\r\n example, in a paper on Geometric Differential Evolution we extensively\ninv=\r\nestigated under what sort of circumstances this type of geometric\nreformula=\r\ntion of the algorithm would be useful, and what its pathologies\nwere, as we=\r\n really wanted to understand. However, the reviewers complained\nthat our re=\r\nsults &quot;did not beat the state of the art&quot;, something that was\nnever our goa=\r\nl.\n\nIn the end, the real test of the value of a paper (assuming that it is\n=\r\nfactually correct in the first place) is how much subsequent research (or\nh=\r\now many applications) it inspires. Therefore, I think we should move to a\ns=\r\nystem where all papers are initially submitted to venues with low\nacceptanc=\r\ne thresholds (and therefore typically high, but not\npre-determined, accepta=\r\nnce rates), and years later, when they have been\npublic long enough to show=\r\n their real worth in informing other people&#39;s\nresearch, they could be elect=\r\ned to be part of more &quot;selective&quot; proceedings.\nThis would likely help resea=\r\nrchers refrain from adding needless\nquantitative results just to please rev=\r\niewers.\n\nJulian\n\n\n\n\nOn 21 April 2013 01:18, Ken &lt;kstanley@...&gt; wr=\r\note:\n\n&gt; **\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; Hi JBM, thanks for getting deeper into this fascinatin=\r\ng issue of how we\n&gt; can be confident that a paper has strong results. I hop=\r\ne you don&#39;t mind\n&gt; that I changed the subject line to make this thread easi=\r\ner to find in the\n&gt; future.\n&gt;\n&gt; I think we all broadly agree that there is =\r\nno single formula for a good\n&gt; paper and you and Jeff are arguing more abou=\r\nt matters of degree. I am very\n&gt; interested in this subject as you know and=\r\n I think it merits a lot more\n&gt; attention than it usually gets, which is on=\r\ne reason I&#39;m glad you got deeper\n&gt; into it. So here I want to add some more=\r\n weight to the case for qualitative\n&gt; papers. I should warn everyone up fro=\r\nnt that I took this opportunity\n&gt; basically to write an essay, so this is a=\r\n long post full of my thoughts on\n&gt; this issue.\n&gt;\n&gt; I believe most people i=\r\nn our field would agree with JBM&#39;s assertion that\n&gt; there is &quot;a strong corr=\r\nelation between weak papers and papers without\n&gt; strong quantitative result=\r\ns.&quot;\n&gt;\n&gt; I want to question that assumption because I do not believe it is t=\r\nrue\n&gt; even though it is widely assumed to be true and in fact is perhaps th=\r\ne\n&gt; engine behind the entire reviewing philosophy in AI. In fact, this issu=\r\ne of\n&gt; how science should progress is ultimately not a scientific issue but=\r\n a\n&gt; philosophical issue. That is, when you begin to discuss which kinds of=\r\n\n&gt; results are most useful for future progress, it is a meta-discussion abo=\r\nut\n&gt; how science progresses. Paul Feyerabend, who was a kind of radical\n&gt; p=\r\nhilosopher of science, has a really nice quote on this issue that I find\n&gt; =\r\ninspirational:\n&gt;\n&gt; &quot;To those who look at the rich material provided by hist=\r\nory, and who are\n&gt; not intent on impoverishing it in order to please their =\r\nlower instincts,\n&gt; their craving for intellectual security in the form of c=\r\nlarity, precision,\n&gt; &#39;objectivity&#39;, &#39;truth&#39;, it will become clear that ther=\r\ne is only one\n&gt; principle that can be defended under all circumstances and =\r\nin all stages of\n&gt; human development. It is the principle: anything goes.&quot;\n=\r\n&gt; Against Method: Outline of an Anarchistic Theory of Knowledge (1975)\n&gt;\n&gt; =\r\nMy personal experience fits very well with this idea. There will be times\n&gt;=\r\n in history where quantification is what we need, and other times when it i=\r\ns\n&gt; the last thing we need. And I believe the worship of quantification has=\r\n\n&gt; recently, at this point in the history of our field, been mostly an\n&gt; ob=\r\nstacle to progress put in place by those &quot;craving for intellectual\n&gt; securi=\r\nty,&quot; as Feyerabend puts it. But insecurity is not a good foundation\n&gt; for t=\r\nhe building of wisdom because exploration requires courage and a\n&gt; willingn=\r\ness to confront ambiguity. Quantification at this time in AI is\n&gt; largely a=\r\nn attempt to escape from ambiguity, and thereby becomes a form of\n&gt; decepti=\r\non.\n&gt;\n&gt; Consider what I have called the &quot;objective paradox&quot;: often if you m=\r\neasure\n&gt; the ability of a method or encoding in EC to achieve a specific ob=\r\njective,\n&gt; your conclusions about what that method can achieve in general w=\r\nill be\n&gt; entirely skewed and misleading. Target-based benchmarks, rather th=\r\nan giving\n&gt; confidence, are causing us to miss the forest for the trees. Th=\r\nink how in\n&gt; my paper with Brian Woolley (\n&gt; http://eplex.cs.ucf.edu/public=\r\nations/2011/woolley-gecco11) we could not\n&gt; re-evolve many images on Picbre=\r\neder with NEAT and CPPNs (which are the very\n&gt; methods behind Picbreeder). =\r\nSo in the quantitative world we would conclude\n&gt; that CPPNs cannot evolve s=\r\nuch images. And in fact results of this sort\n&gt; (showing method X cannot sol=\r\nve problem A) are published all the time, and\n&gt; almost entirely misleading.=\r\n\n&gt;\n&gt; They are also the basis of highly deceptive comparisons between method=\r\n X\n&gt; and Y. We like to say if method X &quot;performs significantly better&quot; than=\r\n\n&gt; method Y on task A then method X is somehow &quot;better.&quot; But the truth is t=\r\nhat\n&gt; often the ability of an encoding to evolve to a specific target is a =\r\nbad\n&gt; sign for its ability to ever produce anything interesting. Think abou=\r\nt\n&gt; direct encodings: they will always win on low-dimensional target-matchi=\r\nng\n&gt; problems but are a dead end for evolving anything truly complex. We ar=\r\ne\n&gt; fooling ourselves with quantification.\n&gt;\n&gt; Even people who are aware of=\r\n Woolley&#39;s result and agree with our\n&gt; conclusions *still* publish this kin=\r\nd of result because our culture is so\n&gt; deeply entrenched in this kind of q=\r\nuantification that we simply have no\n&gt; idea what else to do. If we were wil=\r\nling to truly embrace the absurdity of\n&gt; this kind of analysis, someone wou=\r\nld have the courage to proclaim that DNA\n&gt; is incapable of evolving humans =\r\n(which were of course never set as the\n&gt; objective of evolution). After all=\r\n, if humans were set as objective targets\n&gt; for evolution from the start, t=\r\nhere would be no humans.\n&gt;\n&gt; How many of us have tried to test method X on =\r\nobjective A and found method\n&gt; X wanting and then published the result? And=\r\n how many such papers would you\n&gt; consider &quot;strong?&quot; Our culture of worship=\r\nping quantification has often led\n&gt; us astray on the real power of evolutio=\r\nn and the potential of different\n&gt; encodings. If intuition trumped quantifi=\r\ncation (a heretical suggestion)\n&gt; this fundamental confusion would not have=\r\n arisen so severely.\n&gt;\n&gt; Now I want to look at this issue from the opposite=\r\n direction, where my own\n&gt; experience has been much more positive: how qual=\r\nitative observations often\n&gt; lead to unexpected leaps of insight in a way q=\r\nuantitative results rarely\n&gt; have for me. In fact, almost every idea in whi=\r\nch I have been involved is\n&gt; the result of a qualitative observation, exact=\r\nly the kind that worshipers\n&gt; of quantification seem to want to prevent us =\r\nfrom publishing and sharing\n&gt; with each other.\n&gt;\n&gt; For example, before I th=\r\nought of NEAT I read dozens of neuroevolution\n&gt; papers (this was in the Fal=\r\nl of 1999). There were tons of quantitative\n&gt; results and comparisons, but =\r\nat the end of four months of reading all this\n&gt; literature, I did not remem=\r\nber any of the quantitative results. Instead,\n&gt; what was left with me was a=\r\n &quot;feeling&quot; that something qualitative was\n&gt; missing: Regardless of performa=\r\nnce, none of these methods had the feel of\n&gt; nature when it came to the ten=\r\ndency for complexity to increase elegantly\n&gt; and indefinitely. And that is =\r\nwhere the inspiration for NEAT began, by\n&gt; ignoring quantitative results. I=\r\nf I had followed them, I would simply have\n&gt; built upon the &quot;best&quot; neuroevo=\r\nlution method of the time, which had been my\n&gt; original plan, having been b=\r\nrought up too in the culture of quantification.\n&gt; So then there would be no=\r\n NEAT.\n&gt;\n&gt; My idea for CPPNs was also from an entirely qualitative observat=\r\nion. It\n&gt; actually came before Picbreeder. The main insight was actually fr=\r\nom\n&gt; evolving a spaceship image in Mattias Fagerlund&#39;s old NEAT-based Genet=\r\nic\n&gt; Art program. The experience of evolving the spaceship was so exciting =\r\nto me\n&gt; at the time that I put up a whole website on it:\n&gt; http://www.cs.ut=\r\nexas.edu/users/kstanley/rocket.html\n&gt;\n&gt; There was not a single quantitative=\r\n result, but I was convinced that I had\n&gt; seen something, qualitatively, th=\r\nat resonated with nature. It was that\n&gt; qualitative feeling, that recogniti=\r\non of something deep in the results,\n&gt; that led to CPPNs. It was a couple y=\r\nears later that the whole theory\n&gt; solidified and I wrote the journal artic=\r\nle on CPPNS:\n&gt; http://eplex.cs.ucf.edu/publications/2007/stanley-gpem07\n&gt;\n&gt;=\r\n One interesting thing about that CPPN journal article is that it is almost=\r\n\n&gt; entirely qualitative. As you can imagine, that posed problems for review=\r\n,\n&gt; but I was determined not to pollute it with meaningless quantification.=\r\n For\n&gt; me, the images speak for themselves.\n&gt;\n&gt; Those observations on CPPNs=\r\n and their resulting symmetries and\n&gt; regularities are also what led to Dav=\r\nid D&#39;Ambrosio, Jason Gauci and myself\n&gt; creating HyperNEAT - again, the ins=\r\npiration for the idea was not any\n&gt; quantitative demonstration of anything.=\r\n\n&gt;\n&gt; And finally, as some of you know, novelty search itself was not inspir=\r\ned\n&gt; by a quantitative result. Rather, it comes *again* from evolving pictu=\r\nres -\n&gt; in this case it was my experience of evolving the Picbreeder Car:\n&gt;=\r\n picbreeder.org/search/showgenome.php?sid=3D464\n&gt; What shocked me from the =\r\nexperience of evolving the car was that I had not\n&gt; been trying to evolve a=\r\n car. I could not stop thinking about that, about\n&gt; how I did something rea=\r\nlly hard (from a qualitative perspective) by not\n&gt; trying to do it. I later=\r\n noticed that almost every interesting image on the\n&gt; site has the same str=\r\nange story. I discussed the implications of these\n&gt; observations with Joel =\r\nLehman, which led us both to novelty search.\n&gt;\n&gt; Now someone could argue th=\r\nat these ideas may all turn out &quot;weak&quot; in the\n&gt; end. But that would be a st=\r\nrange philosophy of science; it would suggest\n&gt; that we should never have e=\r\nxplored down these roads in the first place. Of\n&gt; course we cannot know whe=\r\nre any road leads until we take it - and I think\n&gt; at least it&#39;s clear thes=\r\ne were roads worth exploring though no one can say\n&gt; they lead ultimately t=\r\no the greatest truths. But it&#39;s still worth the\n&gt; lessons along the way.\n&gt;\n=\r\n&gt; Someone might also think, okay, your inspirations may have been\n&gt; qualita=\r\ntive but your *results* were mainly quantitative, and somehow that&#39;s\n&gt; what=\r\n matters (though recall the CPPN paper does not have quantitative\n&gt; results=\r\n). As JBM points out, our novelty search paper did have quantitative\n&gt; resu=\r\nlts that ultimately convinced him something interesting was going on.\n&gt; But=\r\n I think again the focus here on &quot;results&quot; misses the forest for the\n&gt; tree=\r\ns. What is more important for the progress of science than the results\n&gt; is=\r\n the *inspiration* that leads to the ideas that produced the results. If\n&gt; =\r\nthe inspiration is withheld, if I cannot share with you the analogue of the=\r\n\n&gt; spaceship or the car in the future, then you can never draw from those\n&gt;=\r\n inspirations to find new roads for us to travel. The kind of science that =\r\nI\n&gt; believe JBM and many others idealize cuts out all the inspiration from =\r\nthe\n&gt; public sphere and leaves us only to share its fruits when someone is =\r\nlucky\n&gt; enough in private to see something interesting (and try to quantify=\r\n it\n&gt; then).\n&gt;\n&gt; Nevertheless, JBM says, &quot;I think that it is much harder to=\r\n write a\n&gt; convincing paper without any quantitative test than with the hel=\r\np of\n&gt; measures/comparisons/etc.&quot; Again, many would share this sentiment. B=\r\nut if\n&gt; you think about it, what exactly do we need to be &quot;convinced&quot; of? W=\r\nhy do we\n&gt; think science (or AI especially) is about convincing someone of =\r\nsomething?\n&gt; Why do we need e.g. 30 strangers to validate an intuition we a=\r\nlready feel\n&gt; deeply that something is interesting? The links in the chain =\r\nof progress\n&gt; are from inspiration, not from convincing. There are many ide=\r\nas that are\n&gt; neither right nor wrong anyway, but worth exploring because t=\r\nhey will lead\n&gt; us to new revelations. To me, capturing the essence of natu=\r\nre is as much\n&gt; about a feeling as it is about a result. And my experience =\r\nin practice\n&gt; bears that out.\n&gt;\n&gt; Here is where I want to return to the int=\r\nellectual insecurity that\n&gt; Feyerabend raises. I think our quantitative cul=\r\nture all boils down to this\n&gt; problem of insecurity. We do not trust oursel=\r\nves to have valid intuitions.\n&gt; We dismiss our own ability to think, as wit=\r\nh JBM&#39;s tongue-in-cheeck parody,\n&gt; &quot;look, cool simulated robots.&quot; But I wan=\r\nt to question why we are so\n&gt; insecure in our own qualitative judgments?\n&gt;\n=\r\n&gt; For those of us with PhDs, our countries invested something like 25 years=\r\n\n&gt; into our education. Shouldn&#39;t someone who supposedly succeeded in jumpin=\r\ng\n&gt; through intellectual hoop after hoop after hoop - eventually impressing=\r\n\n&gt; their peers enough to be hired, even eventually to be tenured or promote=\r\nd -\n&gt; be able to think for themselves sufficiently to decide whether the &quot;c=\r\nool\n&gt; robots&quot; are worth sharing with other scientists because they might in=\r\nspire\n&gt; new ideas? If we are really entirely unqualified after all those ye=\r\nars of\n&gt; supposedly learning to be a scientist, then what was the use of al=\r\nl that\n&gt; public investment? Was it simply to validate that we are able to c=\r\nheck\n&gt; p-values that someone else reports in an X vs. Y quantitative compar=\r\nison?\n&gt; That&#39;s all we&#39;re qualified to do? Why do we deny our intellectual c=\r\nuriosity\n&gt; and ability to think for ourselves?\n&gt;\n&gt; You may think it can&#39;t b=\r\ne done. Maybe you think my personal experience\n&gt; with NEAT, CPPNs, HyperNEA=\r\nT, novelty search, etc. is some kind of fluke\n&gt; that doesn&#39;t really represe=\r\nnt science and how it works. Maybe you think\n&gt; that kind of qualitative app=\r\nroach may work for Ken for some reason but it\n&gt; can&#39;t work in general. But =\r\nwhy would that be? Isn&#39;t it possible that we are\n&gt; all prematurely discredi=\r\nting our intellectual potential to think for\n&gt; ourselves? We have created a=\r\n culture in which the spaceships and cars of\n&gt; science must be hidden, buri=\r\ned until their discoverers figure out (or give\n&gt; up figuring out) their dee=\r\nper implications. I do not support publishing a\n&gt; paper simply because of s=\r\nome &quot;cool robots,&quot; but I do support qualified\n&gt; scientists deciding for the=\r\nmselves, from their experience and intuitions,\n&gt; whether those cool robots =\r\nmight be the seed of an important chain of ideas.\n&gt; And I do not want those=\r\n cool robots hidden from me as a reader of\n&gt; scientific literature if they =\r\nmight be such a seed. When I looked at Jeff&#39;s\n&gt; recent video of his cool ro=\r\nbots, I could feel those wheels of intuition\n&gt; turning in my mind. I still =\r\ndon&#39;t know if it leads to anything, but I don&#39;t\n&gt; need any quantification t=\r\no know that that feeling is more than enough to\n&gt; justify publishing that p=\r\naper, and I&#39;m grateful he and his coauthors did\n&gt; not try to obfuscate it w=\r\nith a veil of needless quantification.\n&gt;\n&gt; Best,\n&gt;\n&gt; ken\n&gt;\n&gt; --- In neat@ya=\r\nhoogroups.com, Jean-Baptiste Mouret &lt;mandor@...&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Jeff,\n&gt; =\r\n&gt;\n&gt; &gt; On 20 avr. 2013, at 20:35, Jeff Clune wrote:\n&gt; &gt; &gt; However, my point =\r\nis that you don&#39;t *always* need a quantitative test.\n&gt; I agree that there a=\r\nre many papers that describe some very complex system,\n&gt; show some cool res=\r\nults, and we don&#39;t learn anything. But sometimes there\n&gt; are papers that sh=\r\now something extremely impressive and don&#39;t have any\n&gt; informative quantita=\r\ntive measures, and we learn a lot. It is the job of the\n&gt; reviewer to judge=\r\n whether there is a contribution: but a reviewer should\n&gt; not start with th=\r\ne assumption that &quot;if there is no quantitative test, it&#39;s\n&gt; not science and=\r\n is not publishable.&quot; My guess is that you agree with that,\n&gt; right?\n&gt; &gt;\n&gt; =\r\n&gt; I agree. What I was trying to explain in the previous e-mail was: (1) we\n=\r\n&gt; need to learn something from the paper and (2) quantitative analysis is a=\r\nn\n&gt; easy way to argue something in a convincing way.\n&gt; &gt;\n&gt; &gt; I agree that t=\r\nhe reviewer should not start with the assumption &quot;if there\n&gt; is no quantita=\r\ntive test, it&#39;s not science and is not publishable.&quot; However,\n&gt; I think tha=\r\nt it is much harder to write a convincing paper without any\n&gt; quantitative =\r\ntest than with the help of measures/comparisons/etc. As a\n&gt; result, as a re=\r\nviewer, I start being suspicious when I see a paper without\n&gt; strong quanti=\r\ntative results. I may accept it, but I know that the challenge\n&gt; =97 for th=\r\ne author =97 will be more difficult.\n&gt; &gt;\n&gt; &gt; Another important point is tha=\r\nt there is, in my opinion, a strong\n&gt; correlation between weak papers and p=\r\napers without strong quantitative\n&gt; results. Correlation does not imply cau=\r\nsation, but we somehow learn to have\n&gt; an intuitive bad feeling when we see=\r\n a paper without quantitative results.\n&gt; &gt;\n&gt; &gt; &gt; Here is one strong argumen=\r\nt for not mandating a quantitative test: we\n&gt; have not created AI yet, so t=\r\nhere are many things that humans can judge\n&gt; better than computers/quantita=\r\ntive tests. Take computer vision, for\n&gt; example. All of us are blown away b=\r\ny the images that resulted on Picbreeder,\n&gt; &gt;\n&gt; &gt; [Picbreeder is not relate=\r\nd at all with computer vision]\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; &gt; Picbreeder taught us a lot abo=\r\nut why CPPNs are powerful and\n&gt; interesting, but they did not do so with nu=\r\nmbers. My guess is that the\n&gt; Picbreeder papers did jump through some hoops=\r\n to provide numbers to satisfy\n&gt; reviewers that insist on them (I forget at=\r\n this point, it&#39;s been a while\n&gt; since I read those papers), but those numb=\r\ners likely taught us very little\n&gt; about the central advance.\n&gt; &gt;\n&gt; &gt; Agree=\r\nd. Sometimes, examples can teach us many things. But, again, it&#39;s\n&gt; hard to=\r\n make a strong points with examples. I&#39;m not saying it&#39;s impossible\n&gt; and y=\r\nour example is probably a good example.\n&gt; &gt;\n&gt; &gt; &gt; The same is true for many=\r\n domains: if I come up with a new\n&gt; story-telling algorithm, the judgement =\r\nof whether it is a huge advance\n&gt; would be you listening to the stories and=\r\n thinking about whether they feel\n&gt; more natural and impressive than what c=\r\name before.\n&gt; &gt;\n&gt; &gt; This is typically quantified by taking 30 people and ma=\r\nke them grade\n&gt; your story. My subjective opinion does not count that much.=\r\n\n&gt; &gt;\n&gt; &gt; &gt; Do you agree?\n&gt; &gt;\n&gt; &gt; I agree with you. Nevertheless, our field =\r\nis young and I think we have\n&gt; to put pressure to have strong papers on whi=\r\nch we can build strong\n&gt; foundations for future researches. One way to put =\r\nthis pressure is to have\n&gt; high standards and encourage to measure everythi=\r\nng that is\n&gt; measurable/comparable, so that the average paper is as good as=\r\n possible.\n&gt; Keep in mind that papers like &quot;look, cool simulated robots!&quot; a=\r\nre making our\n&gt; field weaker.\n&gt; &gt;\n&gt; &gt; Again, I&#39;m advocating that we should =\r\njudge papers by how much they teach\n&gt; us. I think we agree on this. Quantit=\r\native analysis is an easy way to teach\n&gt; something to the reader, other way=\r\ns are possible. But they are harder.\n&gt; &gt;\n&gt; &gt; Best regards,\n&gt; &gt; =97 JBM\n&gt; &gt;\n=\r\n&gt;\n&gt;  \n&gt;\n\n\n\n-- \nJulian Togelius\nAssociate Professor\nIT University of Copenha=\r\ngen\nRued Langgaards Vej 7, 2300 Copenhagen, Denmark\nmail: julian@togelius.c=\r\nom, web: http://julian.togelius.com\nmobile: +46-705-192088, office: +45-721=\r\n8-5277\n\r\n--047d7b3a80ac21232d04daf010d9\r\nContent-Type: text/html; charset=windows-1252\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;Thanks Ken - that was a very worthwile=\r\n little essay to read, and I think I agree with all of it.&lt;br&gt;&lt;br&gt;&lt;/div&gt;In =\r\nanalysing the problem of &quot;veils[s] of needless quantificaiton&quot;, I=\r\n think we should distinguish clearly between the problems of feeling the ne=\r\ned of having quantitative results in there, and for some reason measuring t=\r\nhe wrong things.&lt;br&gt;\n&lt;br&gt;&lt;/div&gt;I think the culture in top journals and US-s=\r\ntyle &quot;selective&quot; conferences of accepting very few papers very mu=\r\nch contributes to this problems. A researcher might write a non-quantitativ=\r\ne paper that he/she is very happy with and thinks says everything that shou=\r\nld be said, but then gets (rightly) nervous about some reviewer tearing the=\r\n paper apart and therefore decides to cram in a table of &lt;br&gt;\npointless qua=\r\nntitative &quot;results&quot;.&lt;br&gt;&lt;br&gt;&lt;/div&gt;Even worse than feeling that yo=\r\nu should need to provide quantitative results, is feeling that you should p=\r\nrovide quantitative results that show that your algorithm is somehow &quot;=\r\nbetter&quot; according to some uni-dimensional metric &quot;performance&quo=\r\nt;. I&#39;ve several times had papers rejected from good journals (and even=\r\ntually published in other good journals after a delay of a year or two) bec=\r\nause while the papers had ample quantitative results, these results did not=\r\n show that the new algorithm/method was &quot;good&quot; enough. For exampl=\r\ne, in a paper on Geometric Differential Evolution we extensively investigat=\r\ned under what sort of circumstances this type of geometric reformulation of=\r\n the algorithm would be useful, and what its pathologies were, as we really=\r\n wanted to understand. However, the reviewers complained that our results &=\r\nquot;did not beat the state of the art&quot;, something that was never our =\r\ngoal.&lt;br&gt;\n&lt;br&gt;&lt;/div&gt;&lt;div&gt;In the end, the real test of the value of a paper =\r\n(assuming that it is factually correct in the first place) is how much subs=\r\nequent research (or how many applications) it inspires. Therefore, I think =\r\nwe should move to a system where all papers are initially submitted to venu=\r\nes with low acceptance thresholds (and therefore typically high, but not pr=\r\ne-determined, acceptance rates), and years later, when they have been publi=\r\nc long enough to show their real worth in informing other people&#39;s rese=\r\narch, they could be elected to be part of more &quot;selective&quot; procee=\r\ndings. This would likely help researchers refrain from adding needless quan=\r\ntitative results just to please reviewers.&lt;br&gt;\n&lt;br&gt;&lt;/div&gt;&lt;div&gt;Julian&lt;br&gt;&lt;/d=\r\niv&gt;&lt;br&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;=\r\ndiv class=3D&quot;gmail_quote&quot;&gt;On 21 April 2013 01:18, Ken &lt;span dir=3D&quot;ltr&quot;&gt;&lt=\r\n;&lt;a href=3D&quot;mailto:kstanley@...&quot; target=3D&quot;_blank&quot;&gt;kstanley@...=\r\nexas.edu&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=\r\n=3D&quot;margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex&quot;&gt;\n\n\n&lt;u&gt;&lt;/=\r\nu&gt;\n\n\n\n\n\n\n\n\n\n\n&lt;div style&gt;\n&lt;span&gt;=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n    &lt;div&gt;\n     =\r\n \n      \n      &lt;p&gt;&lt;br&gt;\n&lt;br&gt;\nHi JBM, thanks for getting deeper into this fas=\r\ncinating issue of how we can be confident that a paper has strong results. =\r\n I hope you don&#39;t mind that I changed the subject line to make this thr=\r\nead easier to find in the future.&lt;br&gt;\n\n&lt;br&gt;\nI think we all broadly agree th=\r\nat there is no single formula for a good paper and you and Jeff are arguing=\r\n more about matters of degree.  I am very interested in this subject as you=\r\n know and I think it merits a lot more attention than it usually gets, whic=\r\nh is one reason I&#39;m glad you got deeper into it.  So here I want to add=\r\n some more weight to the case for qualitative papers.  I should warn everyo=\r\nne up front that I took this opportunity basically to write an essay, so th=\r\nis is a long post full of my thoughts on this issue.&lt;br&gt;\n\n&lt;br&gt;\nI believe mo=\r\nst people in our field would agree with JBM&#39;s assertion that there is &=\r\nquot;a strong correlation between weak papers and papers without strong qua=\r\nntitative results.&quot;&lt;br&gt;\n&lt;br&gt;\nI want to question that assumption becaus=\r\ne I do not believe it is true even though it is widely assumed to be true a=\r\nnd in fact is perhaps the engine behind the entire reviewing philosophy in =\r\nAI.  In fact, this issue of how science should progress is ultimately not a=\r\n scientific issue but a philosophical issue.  That is, when you begin to di=\r\nscuss which kinds of results are most useful for future progress, it is a m=\r\neta-discussion about how science progresses.  Paul Feyerabend, who was a ki=\r\nnd of radical philosopher of science, has a really nice quote on this issue=\r\n that I find inspirational: &lt;br&gt;\n\n&lt;br&gt;\n&quot;To those who look at the rich =\r\nmaterial provided by history, and who are not intent on impoverishing it in=\r\n order to please their lower instincts, their craving for intellectual secu=\r\nrity in the form of clarity, precision, &#39;objectivity&#39;, &#39;truth&#=\r\n39;, it will become clear that there is only one principle that can be defe=\r\nnded under all circumstances and in all stages of human development. It is =\r\nthe principle: anything goes.&quot; &lt;br&gt;\n\nAgainst Method: Outline of an Ana=\r\nrchistic Theory of Knowledge (1975)&lt;br&gt;\n&lt;br&gt;\nMy personal experience fits ve=\r\nry well with this idea.  There will be times in history where quantificatio=\r\nn is what we need, and other times when it is the last thing we need.  And =\r\nI believe the worship of quantification has recently, at this point in the =\r\nhistory of our field, been mostly an obstacle to progress put in place by t=\r\nhose &quot;craving for intellectual security,&quot; as Feyerabend puts it. =\r\n But insecurity is not a good foundation for the building of wisdom because=\r\n exploration requires courage and a willingness to confront ambiguity.  Qua=\r\nntification at this time in AI is largely an attempt to escape from ambigui=\r\nty, and thereby becomes a form of deception.&lt;br&gt;\n\n&lt;br&gt;\nConsider what I have=\r\n called the &quot;objective paradox&quot;: often if you measure the ability=\r\n of a method or encoding in EC to achieve a specific objective, your conclu=\r\nsions about what that method can achieve in general will be entirely skewed=\r\n and misleading.  Target-based benchmarks, rather than giving confidence, a=\r\nre causing us to miss the forest for the trees.  Think how in my paper with=\r\n Brian Woolley (&lt;a href=3D&quot;http://eplex.cs.ucf.edu/publications/2011/woolle=\r\ny-gecco11&quot; target=3D&quot;_blank&quot;&gt;http://eplex.cs.ucf.edu/publications/2011/wool=\r\nley-gecco11&lt;/a&gt;) we could not re-evolve many images on Picbreeder with NEAT=\r\n and CPPNs (which are the very methods behind Picbreeder).  So in the quant=\r\nitative world we would conclude that CPPNs cannot evolve such images.  And =\r\nin fact results of this sort (showing method X cannot solve problem A) are =\r\npublished all the time, and almost entirely misleading.  &lt;br&gt;\n\n\t&lt;br&gt;\nThey a=\r\nre also the basis of highly deceptive comparisons between method X and Y.  =\r\nWe like to say if method X &quot;performs significantly better&quot; than m=\r\nethod Y on task A then method X is somehow &quot;better.&quot;  But the tru=\r\nth is that often the ability of an encoding to evolve to a specific target =\r\nis a bad sign for its ability to ever produce anything interesting.  Think =\r\nabout direct encodings:  they will always win on low-dimensional target-mat=\r\nching problems but are a dead end for evolving anything truly complex.  We =\r\nare fooling ourselves with quantification.&lt;br&gt;\n\n&lt;br&gt;\nEven people who are aw=\r\nare of Woolley&#39;s result and agree with our conclusions *still* publish =\r\nthis kind of result because our culture is so deeply entrenched in this kin=\r\nd of quantification that we simply have no idea what else to do.  If we wer=\r\ne willing to truly embrace the absurdity of this kind of analysis, someone =\r\nwould have the courage to proclaim that DNA is incapable of evolving humans=\r\n (which were of course never set as the objective of evolution).  After all=\r\n, if humans were set as objective targets for evolution from the start, the=\r\nre would be no humans.  &lt;br&gt;\n\n&lt;br&gt;\nHow many of us have tried to test method=\r\n X on objective A and found method X wanting and then published the result?=\r\n  And how many such papers would you consider &quot;strong?&quot;  Our cult=\r\nure of worshipping quantification has often led us astray on the real power=\r\n of evolution and the potential of different encodings.  If intuition trump=\r\ned quantification (a heretical suggestion) this fundamental confusion would=\r\n not have arisen so severely.&lt;br&gt;\n\n&lt;br&gt;\nNow I want to look at this issue fr=\r\nom the opposite direction, where my own experience has been much more posit=\r\nive: how qualitative observations often lead to unexpected leaps of insight=\r\n in a way quantitative results rarely have for me.  In fact, almost every i=\r\ndea in which I have been involved is the result of a qualitative observatio=\r\nn, exactly the kind that worshipers of quantification seem to want to preve=\r\nnt us from publishing and sharing with each other.  &lt;br&gt;\n\n&lt;br&gt;\nFor example,=\r\n before I thought of NEAT I read dozens of neuroevolution papers (this was =\r\nin the Fall of 1999).  There were tons of quantitative results and comparis=\r\nons, but at the end of four months of reading all this literature, I did no=\r\nt remember any of the quantitative results.  Instead, what was left with me=\r\n was a &quot;feeling&quot; that something qualitative was missing:  Regardl=\r\ness of performance, none of these methods had the feel of nature when it ca=\r\nme to the tendency for complexity to increase elegantly and indefinitely.  =\r\nAnd that is where the inspiration for NEAT began, by ignoring quantitative =\r\nresults.  If I had followed them, I would simply have built upon the &quot;=\r\nbest&quot; neuroevolution method of the time, which had been my original pl=\r\nan, having been brought up too in the culture of quantification.  So then t=\r\nhere would be no NEAT.&lt;br&gt;\n\n&lt;br&gt;\nMy idea for CPPNs was also from an entirel=\r\ny qualitative observation.  It actually came before Picbreeder.  The main i=\r\nnsight was actually from evolving a spaceship image in Mattias Fagerlund&#3=\r\n9;s old NEAT-based Genetic Art program.  The experience of evolving the spa=\r\nceship was so exciting to me at the time that I put up a whole website on i=\r\nt: &lt;a href=3D&quot;http://www.cs.utexas.edu/users/kstanley/rocket.html&quot; target=\r\n=3D&quot;_blank&quot;&gt;http://www.cs.utexas.edu/users/kstanley/rocket.html&lt;/a&gt;  &lt;br&gt;\n\n=\r\n&lt;br&gt;\nThere was not a single quantitative result, but I was convinced that I=\r\n had seen something, qualitatively, that resonated with nature.  It was tha=\r\nt qualitative feeling, that recognition of something deep in the results, t=\r\nhat led to CPPNs.  It was a couple years later that the whole theory solidi=\r\nfied and I wrote the journal article on CPPNS: &lt;a href=3D&quot;http://eplex.cs.u=\r\ncf.edu/publications/2007/stanley-gpem07&quot; target=3D&quot;_blank&quot;&gt;http://eplex.cs.=\r\nucf.edu/publications/2007/stanley-gpem07&lt;/a&gt;&lt;br&gt;\n\n&lt;br&gt;\nOne interesting thin=\r\ng about that CPPN journal article is that it is almost entirely qualitative=\r\n.  As you can imagine, that posed problems for review, but I was determined=\r\n not to pollute it with meaningless quantification. For me, the images spea=\r\nk for themselves.&lt;br&gt;\n\n&lt;br&gt;\nThose observations on CPPNs and their resulting=\r\n symmetries and regularities are also what led to David D&#39;Ambrosio, Jas=\r\non Gauci and myself creating HyperNEAT - again, the inspiration for the ide=\r\na was not any quantitative demonstration of anything.  &lt;br&gt;\n\n&lt;br&gt;\nAnd final=\r\nly, as some of you know, novelty search itself was not inspired by a quanti=\r\ntative result.  Rather, it comes *again* from evolving pictures - in this c=\r\nase it was my experience of evolving the Picbreeder Car: &lt;a href=3D&quot;http://=\r\npicbreeder.org/search/showgenome.php?sid=3D464&quot; target=3D&quot;_blank&quot;&gt;picbreede=\r\nr.org/search/showgenome.php?sid=3D464&lt;/a&gt;&lt;br&gt;\n\nWhat shocked me from the exp=\r\nerience of evolving the car was that I had not been trying to evolve a car.=\r\n  I could not stop thinking about that, about how I did something really ha=\r\nrd (from a qualitative perspective) by not trying to do it.  I later notice=\r\nd that almost every interesting image on the site has the same strange stor=\r\ny.  I discussed the implications of these observations with Joel Lehman, wh=\r\nich led us both to novelty search.&lt;br&gt;\n\n&lt;br&gt;\nNow someone could argue that t=\r\nhese ideas may all turn out &quot;weak&quot; in the end.  But that would be=\r\n a strange philosophy of science; it would suggest that we should never hav=\r\ne explored down these roads in the first place.  Of course we cannot know w=\r\nhere any road leads until we take it - and I think at least it&#39;s clear =\r\nthese were roads worth exploring though no one can say they lead ultimately=\r\n to the greatest truths.  But it&#39;s still worth the lessons along the wa=\r\ny.  &lt;br&gt;\n\n&lt;br&gt;\nSomeone might also think, okay, your inspirations may have b=\r\neen qualitative but your *results* were mainly quantitative, and somehow th=\r\nat&#39;s what matters (though recall the CPPN paper does not have quantitat=\r\nive results).  As JBM points out, our novelty search paper did have quantit=\r\native results that ultimately convinced him something interesting was going=\r\n on.  But I think again the focus here on &quot;results&quot; misses the fo=\r\nrest for the trees.  What is more important for the progress of science tha=\r\nn the results is the *inspiration* that leads to the ideas that produced th=\r\ne results.  If the inspiration is withheld, if I cannot share with you the =\r\nanalogue of the spaceship or the car in the future, then you can never draw=\r\n from those inspirations to find new roads for us to travel.  The kind of s=\r\ncience that I believe JBM and many others idealize cuts out all the inspira=\r\ntion from the public sphere and leaves us only to share its fruits when som=\r\neone is lucky enough in private to see something interesting (and try to qu=\r\nantify it then).&lt;br&gt;\n\n&lt;br&gt;\nNevertheless, JBM says, &quot;I think that it is=\r\n much harder to write a convincing paper without any quantitative test than=\r\n with the help of measures/comparisons/etc.&quot;  Again, many would share =\r\nthis sentiment.  But if you think about it, what exactly do we need to be &=\r\nquot;convinced&quot; of?  Why do we think science (or AI especially) is abo=\r\nut convincing someone of something?  Why do we need e.g. 30 strangers to va=\r\nlidate an intuition we already feel deeply that something is interesting?  =\r\nThe links in the chain of progress are from inspiration, not from convincin=\r\ng.  There are many ideas that are neither right nor wrong anyway, but worth=\r\n exploring because they will lead us to new revelations.  To me, capturing =\r\nthe essence of nature is as much about a feeling as it is about a result.  =\r\nAnd my experience in practice bears that out.&lt;br&gt;\n\n&lt;br&gt;\nHere is where I wan=\r\nt to return to the intellectual insecurity that Feyerabend raises.  I think=\r\n our quantitative culture all boils down to this problem of insecurity.  We=\r\n do not trust ourselves to have valid intuitions.  We dismiss our own abili=\r\nty to think, as with JBM&#39;s tongue-in-cheeck parody, &quot;look, cool si=\r\nmulated robots.&quot;  But I want to question why we are so insecure in our=\r\n own qualitative judgments?  &lt;br&gt;\n\n&lt;br&gt;\nFor those of us with PhDs, our coun=\r\ntries invested something like 25 years into our education.  Shouldn&#39;t s=\r\nomeone who supposedly succeeded in jumping through intellectual hoop after =\r\nhoop after hoop - eventually impressing their peers enough to be hired, eve=\r\nn eventually to be tenured or promoted - be able to think for themselves su=\r\nfficiently to decide whether the &quot;cool robots&quot; are worth sharing =\r\nwith other scientists because they might inspire new ideas?  If we are real=\r\nly entirely unqualified after all those years of supposedly learning to be =\r\na scientist, then what was the use of all that public investment?  Was it s=\r\nimply to validate that we are able to check p-values that someone else repo=\r\nrts in an X vs. Y quantitative comparison?  That&#39;s all we&#39;re qualif=\r\nied to do?  Why do we deny our intellectual curiosity and ability to think =\r\nfor ourselves?  &lt;br&gt;\n\n&lt;br&gt;\nYou may think it can&#39;t be done.  Maybe you t=\r\nhink my personal experience with NEAT, CPPNs, HyperNEAT, novelty search, et=\r\nc. is some kind of fluke that doesn&#39;t really represent science and how =\r\nit works.  Maybe you think that kind of qualitative approach may work for K=\r\nen for some reason but it can&#39;t work in general.  But why would that be=\r\n?  Isn&#39;t it possible that we are all prematurely discrediting our intel=\r\nlectual potential to think for ourselves?  We have created a culture in whi=\r\nch the spaceships and cars of science must be hidden, buried until their di=\r\nscoverers figure out (or give up figuring out) their deeper implications.  =\r\nI do not support publishing a paper simply because of some &quot;cool robot=\r\ns,&quot; but I do support qualified scientists deciding for themselves, fro=\r\nm their experience and intuitions, whether those cool robots might be the s=\r\need of an important chain of ideas.  And I do not want those cool robots hi=\r\ndden from me as a reader of scientific literature if they might be such a s=\r\need.  When I looked at Jeff&#39;s recent video of his cool robots, I could =\r\nfeel those wheels of intuition turning in my mind.  I still don&#39;t know =\r\nif it leads to anything, but I don&#39;t need any quantification to know th=\r\nat that feeling is more than enough to justify publishing that paper, and I=\r\n&#39;m grateful he and his coauthors did not try to obfuscate it with a vei=\r\nl of needless quantification.&lt;br&gt;\n\n&lt;br&gt;\nBest,&lt;br&gt;\n&lt;br&gt;\nken&lt;br&gt;\n&lt;br&gt;\n--- In =\r\n&lt;a href=3D&quot;mailto:neat%40yahoogroups.com&quot; target=3D&quot;_blank&quot;&gt;neat@yahoogroup=\r\ns.com&lt;/a&gt;, Jean-Baptiste Mouret &lt;mandor@...&gt; wrote:&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;=\r\n Hi Jeff,&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; On 20 avr. 2013, at 20:35, Jeff Clune wrote:&lt;b=\r\nr&gt;\n&gt; &gt; However, my point is that you don&#39;t *always* need a quanti=\r\ntative test. I agree that there are many papers that describe some very com=\r\nplex system, show some cool results, and we don&#39;t learn anything. But s=\r\nometimes there are papers that show something extremely impressive and don&=\r\n#39;t have any informative quantitative measures, and we learn a lot. It is=\r\n the job of the reviewer to judge whether there is a contribution: but a re=\r\nviewer should not start with the assumption that &quot;if there is no quant=\r\nitative test, it&#39;s not science and is not publishable.&quot; My guess i=\r\ns that you agree with that, right?&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; I agree. What I was =\r\ntrying to explain in the previous e-mail was: (1) we need to learn somethin=\r\ng from the paper and (2) quantitative analysis is an easy way to argue some=\r\nthing in a convincing way.&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; I agree that the reviewer sho=\r\nuld not start with the assumption &quot;if there is no quantitative test, i=\r\nt&#39;s not science and is not publishable.&quot; However, I think that it =\r\nis much harder to write a convincing paper without any quantitative test th=\r\nan with the help of measures/comparisons/etc. As a result, as a reviewer, I=\r\n start being suspicious when I see a paper without strong quantitative resu=\r\nlts. I may accept it, but I know that the challenge =97 for the author =97 =\r\nwill be more difficult.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Another important point is that=\r\n there is, in my opinion, a strong correlation between weak papers and pape=\r\nrs without strong quantitative results. Correlation does not imply causatio=\r\nn, but we somehow learn to have an intuitive bad feeling when we see a pape=\r\nr without quantitative results.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; &gt; Here is one strong=\r\n argument for not mandating a quantitative test: we have not created AI yet=\r\n, so there are many things that humans can judge better than computers/quan=\r\ntitative tests. Take computer vision, for example. All of us are blown away=\r\n by the images that resulted on Picbreeder,&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; [Picbreeder=\r\n is not related at all with computer vision]&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &=\r\ngt; Picbreeder taught us a lot about why CPPNs are powerful and interesting=\r\n, but they did not do so with numbers. My guess is that the Picbreeder pape=\r\nrs did jump through some hoops to provide numbers to satisfy reviewers that=\r\n insist on them (I forget at this point, it&#39;s been a while since I read=\r\n those papers), but those numbers likely taught us very little about the ce=\r\nntral advance. &lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Agreed. Sometimes, examples can teach u=\r\ns many things. But, again, it&#39;s hard to make a strong points with examp=\r\nles. I&#39;m not saying it&#39;s impossible and your example is probably a =\r\ngood example. &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &gt; The same is true for many domains: i=\r\nf I come up with a new story-telling algorithm, the judgement of whether it=\r\n is a huge advance would be you listening to the stories and thinking about=\r\n whether they feel more natural and impressive than what came before.&lt;br&gt;\n\n=\r\n&gt; &lt;br&gt;\n&gt; This is typically quantified by taking 30 people and make th=\r\nem grade your story. My subjective opinion does not count that much.&lt;br&gt;\n&g=\r\nt; &lt;br&gt;\n&gt; &gt; Do you agree?&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; I agree with you. Nevert=\r\nheless, our field is young and I think we have to put pressure to have stro=\r\nng papers on which we can build strong foundations for future researches. O=\r\nne way to put this pressure is to have high standards and encourage to meas=\r\nure everything that is measurable/comparable, so that the average paper is =\r\nas good as possible. Keep in mind that papers like &quot;look, cool simulat=\r\ned robots!&quot; are making our field weaker.&lt;br&gt;\n\n&gt; &lt;br&gt;\n&gt; Again, I&=\r\n#39;m advocating that we should judge papers by how much they teach us. I t=\r\nhink we agree on this. Quantitative analysis is an easy way to teach someth=\r\ning to the reader, other ways are possible. But they are harder.&lt;br&gt;\n\n&gt; =\r\n&lt;br&gt;\n&gt; Best regards,&lt;br&gt;\n&gt; =97 JBM&lt;br&gt;\n&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;/p&gt;\n\n    &lt;/div&gt;=\r\n\n     \n\n    \n    &lt;div style=3D&quot;color:#fff;min-height:0&quot;&gt;&lt;/div&gt;\n\n\n&lt;/div&gt;\n\n\n\n=\r\n  \n\n\n\n\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;br clear=3D&quot;all&quot;&gt;&lt;br&gt;-- &lt;br&gt;Julian Togeliu=\r\ns&lt;br&gt;Associate Professor&lt;br&gt;IT University of Copenhagen&lt;br&gt;Rued Langgaards =\r\nVej 7, 2300 Copenhagen, Denmark&lt;br&gt;mail: &lt;a href=3D&quot;mailto:julian@togelius.=\r\ncom&quot; target=3D&quot;_blank&quot;&gt;julian@...&lt;/a&gt;, web: &lt;a href=3D&quot;http://juli=\r\nan.togelius.com&quot; target=3D&quot;_blank&quot;&gt;http://julian.togelius.com&lt;/a&gt;&lt;br&gt;\nmobil=\r\ne: +46-705-192088, office: +45-7218-5277\n&lt;/div&gt;\n\r\n--047d7b3a80ac21232d04daf010d9--\r\n\n"}}