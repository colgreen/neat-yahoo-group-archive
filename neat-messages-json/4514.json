{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"m1LFgBoeLmeqRf67-v7kzElvrf-V_PYN5X32d7iQ4QEi3jDXHkFYSjBQxACnWcgkLL-QFnZczY6S4LCU_RB0wFf5","spamInfo":{"isSpam":false,"reason":"2"},"subject":"Re: [neat] Re: Parameter settings for comparing HyperNEAT to P-NEAT","postDate":"1229454783","msgId":4514,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM1NkQ2N0VGLjI3MEFFJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PGdoZzJ0YyszMHFoQGVHcm91cHMuY29tPg=="},"prevInTopic":4499,"nextInTopic":4515,"prevInTime":4513,"nextInTime":4515,"topicId":4496,"numMessagesInTopic":6,"msgSnippet":"Jason and Ken- Thanks for your responses. I think comparing HyperNEAT and P-NEAT is very instructive, because it allows us to test the benefits of generative","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 48439 invoked from network); 16 Dec 2008 19:13:12 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m54.grp.scd.yahoo.com with QMQP; 16 Dec 2008 19:13:12 -0000\r\nX-Received: from unknown (HELO mail-qy0-f20.google.com) (209.85.221.20)\n  by mta18.grp.scd.yahoo.com with SMTP; 16 Dec 2008 19:13:12 -0000\r\nX-Received: by qyk13 with SMTP id 13so3375667qyk.8\n        for &lt;neat@yahoogroups.com&gt;; Tue, 16 Dec 2008 11:13:09 -0800 (PST)\r\nX-Received: by 10.215.38.15 with SMTP id q15mr9866096qaj.90.1229454789025;\n        Tue, 16 Dec 2008 11:13:09 -0800 (PST)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?192.168.2.19? (cpe-208-84-70-48.dyn.marcocable.net [208.84.70.48])\n        by mx.google.com with ESMTPS id 5sm1405655qwg.25.2008.12.16.11.13.05\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Tue, 16 Dec 2008 11:13:07 -0800 (PST)\r\nUser-Agent: Microsoft-Entourage/12.13.0.080930\r\nDate: Tue, 16 Dec 2008 14:13:03 -0500\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C56D67EF.270AE%jclune@...&gt;\r\nThread-Topic: [neat] Re: Parameter settings for comparing HyperNEAT to P-NEAT\r\nThread-Index: AclfslFTon7BjjvSoUGDZwa5+iBRNw==\r\nIn-Reply-To: &lt;ghg2tc+30qh@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;ISO-8859-1&quot;\r\nContent-transfer-encoding: quoted-printable\r\nX-eGroups-Msg-Info: 2:2:2:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] Re: Parameter settings for comparing HyperNEAT to P-NEAT\r\nX-Yahoo-Group-Post: member; u=211599040; y=jjnTvamJwJPkbI94gK2Ykf39_zDtibVtph-u-q37wsa1dlceG8pU\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nJason and Ken-\n\nThanks for your responses.\n\nI think comparing HyperNEAT and=\r\n P-NEAT is very instructive, because it\nallows us to test the benefits of g=\r\nenerative vs. direct encodings. I forgot\nthat it was not used in David=B9s =\r\nexperiments. However, I did use it in my\n2008 PPSN paper (=B3How a generati=\r\nve encoding fares as problem-regularity\ndecreases=B3), and I am also using =\r\nit in current research (not yet published).\nI mention all of this in order =\r\nto let people know that I am not trying to be\npedantic with regard to past =\r\nwork, but just trying to ensure that\ncomparisons that we are making are fai=\r\nr.\n\nJason, I was just advocating doing a sweep on the mutation rate for P-N=\r\nEAT\nup to N generations (e.g. however many generations you used in your ori=\r\nginal\npaper), and using that same N for HyperNEAT. That is not that large a=\r\n drain\non resources. \n\nIn fact, I have just completed such a sweep and foun=\r\nd that, on the problem I\nam testing on, the optimal P-NEAT mutation rate wa=\r\ns about an order of\nmagnitude lower than the one I had been using. However,=\r\n the boost in\nP-NEAT=B9s performance did not bring it anywhere near HyperNE=\r\nAT. Of course,\nthe optimal rate will depend on the problem, but my point he=\r\nre is that it\nwill also depend on the encoding. While I have not swept Hype=\r\nrNEAT=B9s\nmutation rate, I=B9ll wager that HyperNEAT=B9s optimal rate is ve=\r\nry different\nfrom P-NEAT.  \n\nKen- I agree with your assessment that sometim=\r\nes small changes in P-NEAT can\nlead to large changes in behavior. However, =\r\nas you note in your updated\nreply, in the boxes domain this is probably not=\r\n the case.\n\nIt seems that it is difficult to determine a priori whether P-N=\r\nEAT (or\nHyperNEAT, or any encoding) will benefit from a higher, or lower, m=\r\nutation\nrate. But we know that the mutation rate greatly affects the perfor=\r\nmance of\nan evolutionary algorithm. So, to get at the high-level issue, it =\r\nstill does\nstrike me as somewhat unfair to compare two different encodings,=\r\n where\nmutations have such different types of effects, with the same mutati=\r\non rate.\n\nOur reasoning about the encodings gives us expectations that Hype=\r\nrNEAT will\ndo much better. I would like to state again that I fully agree w=\r\nith those\nreasons. However, the point of actually running the comparison is=\r\n to see\nwhether the data support the intuitions. It is somewhat circular to=\r\n use our\nintuitions as a reason for not setting up the proper controls, giv=\r\nen that\nthe controls are meant to test the accuracy of our intuitions.\n\nTha=\r\nt said, one can lose months doing parameter sweeps. My argument with\nregard=\r\n to mutation rate could also be applied to many other NEAT parameters,\nas w=\r\nell as their interactions. Clearly it would be a waste of energy to try\nto =\r\nsweep through that multidimensional space. So, maybe it is better to say\nth=\r\nat since the tests are in accordance with what our reasoning suggests, we\nd=\r\no not need to spend the time to make sure they were exactly the right\ncontr=\r\nol.  Or, perhaps a middle ground is appropriate: doing a cursory sweep\nof a=\r\n few parameters (e.g. mutation rate) that we know to have large effects.\nTh=\r\nat is why I was wondering what you feel are the few key parameters that\nsho=\r\nuld be swept. At present, my thinking is that it is probably fine to just\ns=\r\nweep MutateLinkProbability. Does that sound right?\n \nIn conclusion, I do no=\r\nt think it is particularly fair to use the same\nsettings for both encodings=\r\n. But I am not sure whether it is worth the time\nto try to make the control=\r\ns more fair, given that our intuitions largely\npredict the outcome of the t=\r\nest anyway, and given that initial sweeps (like\nthe one I just did) corrobo=\r\nrate the predictions of those intuitions.\n\n\n\nCheers, \nJeff\n\nOn 12/7/08 3:53=\r\n AM, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n\n&gt;  \n&gt;  \n&gt; \n&gt; Jeff, =\r\na few other thoughts on the issue...\n&gt; \n&gt; Note that I believe the only time=\r\n P-NEAT comes up is in the boxes\n&gt; domain.  None of David&#39;s experiments inv=\r\nolve P-NEAT.  I think Jason\n&gt; did some cursory checking of other settings f=\r\nor P-NEAT, but nothing\n&gt; systematic.  Jason can correct me if I am wrong.\n&gt;=\r\n \n&gt; I understand that like Jason and myself, you don&#39;t think it would\n&gt; rea=\r\nlly make a big difference no matter what we do with P-NEAT, but\n&gt; just for =\r\nthe record, I think the reasoning you give for the\n&gt; differences with P-NEA=\r\nT is not entirely accurate.  In particular, you\n&gt; suggest that small mutati=\r\nons in HyperNEAT may lead to big changes on\n&gt; the substrate, while the same=\r\n is not true for P-NEAT.  I disagree with\n&gt; that perspective because ultima=\r\ntely what is important is not the\n&gt; substrate, but the behavior produced by=\r\n the substrate.  The substrate\n&gt; is just a level of indirection in the mapp=\r\ning between genotype and\n&gt; behavior.  In that view, a small mutation in P-N=\r\nEAT is just as likely\n&gt; to produce a large change in *behavior* as it is in=\r\n HyperNEAT.\n&gt; Consider that behavior is an indirect holistic product of gen=\r\notype as\n&gt; well.  That is, a single gene mutating in P-NEAT can change how =\r\nan\n&gt; individual behaves in every possible situation it may encounter.\n&gt; Hen=\r\nce it is equally holistic as HyperNEAT.\n&gt; \n&gt; In fact, one could argue that =\r\nthe situation is actually opposite of\n&gt; what you say:  Because a single mut=\r\nation in HyperNEAT produces a\n&gt; systematic concerted change in the substrat=\r\ne, it is less likely to\n&gt; produce a haphazard change in behavior than a sin=\r\ngle mutation in\n&gt; P-NEAT.  That is a difficult argument to make concrete, b=\r\nut it&#39;s not\n&gt; unreasonable.  Just because a lot of connection weights chang=\r\ne does\n&gt; not mean that the change is &quot;big.&quot;  If they all change in a concer=\r\nted\n&gt; manner, it can be quite subtle, or no change at all.  And in fact,\n&gt; =\r\nconcerted change is exactly what indirect encoding is about.\n&gt; \n&gt; Note that=\r\n I am referring to P-NEAT in general.  In the boxes domain,\n&gt; it is perhaps=\r\n more as you say since individual connections in that\n&gt; domain do indeed ha=\r\nve small effects.\n&gt; \n&gt; In any case, the larger concern is still valid.  The=\r\nre may indeed be\n&gt; different optimal parameter settings for P-NEAT and Hype=\r\nrNEAT, and\n&gt; that is something people can look at.  But if there are, in my=\r\n view it\n&gt; is probably for different reasons than the ones you cite (as I e=\r\nxplain\n&gt; above).  Still, barring finding the optimal P-NEAT parameters (whi=\r\nch I\n&gt; don&#39;t know), I think the most fair thing is indeed to give them the\n=\r\n&gt; same parameters because they are both ultimately variants of NEAT\n&gt; evolv=\r\ning a solution to the same problem.  Still, I do see that one\n&gt; might be in=\r\nterested in optimizing P-NEAT further to see how good it\n&gt; can really be.  =\r\nHowever, as you say and Jason supports, it won&#39;t be\n&gt; easy to get P-NEAT to=\r\n optimize a 14,000-dimensional space, whatever\n&gt; parameters you give it.\n&gt; =\r\n\n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.com&gt; , &quot;=\r\nJason G&quot;\n&gt; &lt;jgmath2000@...&gt; wrote:\n&gt;&gt; &gt;\n&gt;&gt; &gt; Hey Jeff,\n&gt;&gt; &gt; \n&gt;&gt; &gt; I underst=\r\nand the concern with the mutation probability.  I believe the\n&gt;&gt; &gt; reason t=\r\nhat NEAT cannot solve the boxes problem in training is a credit\n&gt;&gt; &gt; assign=\r\nment problem. Because the number of connections is so high, it is\n&gt;&gt; &gt; diff=\r\nicult for a direct encoding to learn which connections were\n&gt; responsible\n&gt;=\r\n&gt; &gt; for an increase/decrease in fitness.\n&gt;&gt; &gt; \n&gt;&gt; &gt; It might be possible to=\r\n improve the credit assignment by lowering the\n&gt;&gt; &gt; mutation rate.  The pro=\r\nblem is that if the mutation rate was lowered\n&gt; to the\n&gt;&gt; &gt; point where cre=\r\ndit assignment could be manageable by NEAT, I believe\n&gt; that\n&gt;&gt; &gt; this woul=\r\nd require orders of magnitude more generations to converge.\n&gt; Even if\n&gt;&gt; &gt; =\r\nNEAT converged to a solution, this does not negate the fact that a\n&gt; lot of=\r\n\n&gt;&gt; &gt; the connections are never used in training, and these connections\n&gt; w=\r\nill have\n&gt;&gt; &gt; effectively random values, resulting in poor validation perfo=\r\nrmance.\n&gt;&gt; &gt; \n&gt;&gt; &gt; Consider this: if NEAT was able to learn the correct val=\r\nue for a\n&gt; single link\n&gt;&gt; &gt; every generation, and this correct value was pr=\r\neserved through the\n&gt; whole run\n&gt;&gt; &gt; (i.e. it was not accidentally mutated)=\r\n, it would still take about 5000\n&gt;&gt; &gt; generations to completely solve the t=\r\nraining phase of the boxes\n&gt; problem.  At\n&gt;&gt; &gt; roughly an hour per generati=\r\non, that&#39;s about 7 months per run.\n&gt;&gt; &gt; \n&gt;&gt; &gt; Any sweep of the mutation rat=\r\ne parameter would require many\n&gt; generations in\n&gt;&gt; &gt; each run. I believe th=\r\nat, given a very low mutation rate, NEAT might\n&gt; be able\n&gt;&gt; &gt; to solve the =\r\nboxes problem; however, it would take tens of thousands of\n&gt;&gt; &gt; generations=\r\n at least, and there&#39;s still the generalization issue.\n&gt; Given the\n&gt;&gt; &gt; amo=\r\nunt of resources necessary to find the magic numbers, I didn&#39;t\n&gt; see the\n&gt;&gt;=\r\n &gt; utility in trying to pursue it.\n&gt;&gt; &gt; \n&gt;&gt; &gt; I think what might be more in=\r\nteresting would be to try different\n&gt; parameters\n&gt;&gt; &gt; for HyperNEAT.  As we=\r\n fix bugs and develop maturity in the codebase, it\n&gt;&gt; &gt; would be important =\r\nto note how the parameters should be changed for the\n&gt;&gt; &gt; older experiments=\r\n (e.g. the mutation rate is lower now because we\n&gt; fixed a\n&gt;&gt; &gt; bug in muta=\r\ntion).\n&gt;&gt; &gt; \n&gt;&gt; &gt; --- In neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.co=\r\nm&gt; , Jeff Clune\n&gt;&gt; &lt;jclune@&gt; wrote:\n&gt;&gt;&gt; &gt; &gt;\n&gt;&gt;&gt; &gt; &gt; Hi all-\n&gt;&gt;&gt; &gt; &gt;\n&gt;&gt;&gt; &gt; &gt;=\r\n A quick question for Ken, Jason and Dave.\n&gt;&gt;&gt; &gt; &gt;\n&gt;&gt;&gt; &gt; &gt; I notice that mo=\r\nst of the parameter settings (e.g.\n&gt;&gt;&gt; &gt; &gt; MutateLinkWeightsProbability) we=\r\nre the same when you guys compared\n&gt;&gt; &gt; HyperNEAT\n&gt;&gt;&gt; &gt; &gt; to P-NEAT.\n&gt;&gt;&gt; &gt; =\r\n&gt;\n&gt;&gt;&gt; &gt; &gt; Someone in my lab raised the issue yesterday that each\n&gt; configur=\r\nation may\n&gt;&gt;&gt; &gt; &gt; have entirely different optimal settings, making a compar=\r\nison with the\n&gt;&gt; &gt; same\n&gt;&gt;&gt; &gt; &gt; settings potentially unfair. Out of curiosi=\r\nty, did you do any\n&gt; parameter\n&gt;&gt;&gt; &gt; &gt; sweeps to see if P-NEAT&#39;s performanc=\r\ne did much better, and better\n&gt;&gt; &gt; approached\n&gt;&gt;&gt; &gt; &gt; HyperNEAT&#39;s, with dif=\r\nferent parameter settings?\n&gt;&gt;&gt; &gt; &gt;\n&gt;&gt;&gt; &gt; &gt; For example, since mutations to =\r\nHyperNEAT have such larger effects\n&gt; on the\n&gt;&gt;&gt; &gt; &gt; final substrate, it cou=\r\nld be argued that P-NEAT needs a much higher\n&gt;&gt; &gt; mutation\n&gt;&gt;&gt; &gt; &gt; rate to =\r\ncompete.\n&gt;&gt;&gt; &gt; &gt;\n&gt;&gt;&gt; &gt; &gt; Note: I don&#39;t think P-NEAT will beat HyperNEAT no =\r\nmatter what the\n&gt;&gt; &gt; settings,\n&gt;&gt;&gt; &gt; &gt; but I do think the question is fair =\r\nand I would not be surprised\n&gt; if the\n&gt;&gt;&gt; &gt; &gt; settings that worked great fo=\r\nr HyperNEAT are not the ones that\n&gt; work great\n&gt;&gt;&gt; &gt; &gt; for P-NEAT (and vice=\r\n versa). In short, I am confident that the\n&gt; qualitative\n&gt;&gt;&gt; &gt; &gt; results of=\r\n your paper are still all valid (and represent\n&gt; breakthroughs for\n&gt;&gt;&gt; &gt; &gt; =\r\nthe field), but am interested to know whether the quantitative\n&gt; difference=\r\n\n&gt;&gt;&gt; &gt; &gt; between the encodings might be much less with different settings.\n=\r\n&gt;&gt;&gt; &gt; &gt;\n&gt;&gt;&gt; &gt; &gt; PS. As a side note, there are a ton of settings and sweepin=\r\ng them\n&gt; all is\n&gt;&gt;&gt; &gt; &gt; nearly impossible, especially when considering inte=\r\nractions. What does\n&gt;&gt; &gt; &g\n\n\n\n\n\n\n\n\n\nCheers,\nJeff Clune\n\nDigital Evolution =\r\nLab, Michigan State University\n\njclune@...\n\n\n\n\n&gt; From: Kenneth Stanley =\r\n&lt;kstanley@...&gt;\n&gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogrou=\r\nps.com&gt;\n&gt; Date: Sun, 07 Dec 2008 08:53:00 -0000\n&gt; To: &quot;neat@yahoogroups.com=\r\n&quot; &lt;neat@yahoogroups.com&gt;\n&gt; Subject: [neat] Re: Parameter settings for compa=\r\nring HyperNEAT to P-NEAT\n&gt; \n&gt; Jeff, a few other thoughts on the issue...\n&gt; =\r\n\n&gt; Note that I believe the only time P-NEAT comes up is in the boxes\n&gt; doma=\r\nin.  None of David&#39;s experiments involve P-NEAT.  I think Jason\n&gt; did some =\r\ncursory checking of other settings for P-NEAT, but nothing\n&gt; systematic.  J=\r\nason can correct me if I am wrong.\n&gt; \n&gt; I understand that like Jason and my=\r\nself, you don&#39;t think it would\n&gt; really make a big difference no matter wha=\r\nt we do with P-NEAT, but\n&gt; just for the record, I think the reasoning you g=\r\nive for the\n&gt; differences with P-NEAT is not entirely accurate.  In particu=\r\nlar, you\n&gt; suggest that small mutations in HyperNEAT may lead to big change=\r\ns on\n&gt; the substrate, while the same is not true for P-NEAT.  I disagree wi=\r\nth\n&gt; that perspective because ultimately what is important is not the\n&gt; sub=\r\nstrate, but the behavior produced by the substrate.  The substrate\n&gt; is jus=\r\nt a level of indirection in the mapping between genotype and\n&gt; behavior.  I=\r\nn that view, a small mutation in P-NEAT is just as likely\n&gt; to produce a la=\r\nrge change in *behavior* as it is in HyperNEAT.\n&gt; Consider that behavior is=\r\n an indirect holistic product of genotype as\n&gt; well.  That is, a single gen=\r\ne mutating in P-NEAT can change how an\n&gt; individual behaves in every possib=\r\nle situation it may encounter.\n&gt; Hence it is equally holistic as HyperNEAT.=\r\n\n&gt; \n&gt; In fact, one could argue that the situation is actually opposite of\n&gt;=\r\n what you say:  Because a single mutation in HyperNEAT produces a\n&gt; systema=\r\ntic concerted change in the substrate, it is less likely to\n&gt; produce a hap=\r\nhazard change in behavior than a single mutation in\n&gt; P-NEAT.  That is a di=\r\nfficult argument to make concrete, but it&#39;s not\n&gt; unreasonable.  Just becau=\r\nse a lot of connection weights change does\n&gt; not mean that the change is &quot;b=\r\nig.&quot;  If they all change in a concerted\n&gt; manner, it can be quite subtle, o=\r\nr no change at all.  And in fact,\n&gt; concerted change is exactly what indire=\r\nct encoding is about.\n&gt; \n&gt; Note that I am referring to P-NEAT in general.  =\r\nIn the boxes domain,\n&gt; it is perhaps more as you say since individual conne=\r\nctions in that\n&gt; domain do indeed have small effects.\n&gt; \n&gt; In any case, the=\r\n larger concern is still valid.  There may indeed be\n&gt; different optimal pa=\r\nrameter settings for P-NEAT and HyperNEAT, and\n&gt; that is something people c=\r\nan look at.  But if there are, in my view it\n&gt; is probably for different re=\r\nasons than the ones you cite (as I explain\n&gt; above).  Still, barring findin=\r\ng the optimal P-NEAT parameters (which I\n&gt; don&#39;t know), I think the most fa=\r\nir thing is indeed to give them the\n&gt; same parameters because they are both=\r\n ultimately variants of NEAT\n&gt; evolving a solution to the same problem.  St=\r\nill, I do see that one\n&gt; might be interested in optimizing P-NEAT further t=\r\no see how good it\n&gt; can really be.  However, as you say and Jason supports,=\r\n it won&#39;t be\n&gt; easy to get P-NEAT to optimize a 14,000-dimensional space, w=\r\nhatever\n&gt; parameters you give it.\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com=\r\n, &quot;Jason G&quot; &lt;jgmath2000@...&gt; wrote:\n&gt;&gt; \n&gt;&gt; Hey Jeff,\n&gt;&gt; \n&gt;&gt; I understand th=\r\ne concern with the mutation probability.  I believe the\n&gt;&gt; reason that NEAT=\r\n cannot solve the boxes problem in training is a credit\n&gt;&gt; assignment probl=\r\nem. Because the number of connections is so high, it is\n&gt;&gt; difficult for a =\r\ndirect encoding to learn which connections were\n&gt; responsible\n&gt;&gt; for an inc=\r\nrease/decrease in fitness.\n&gt;&gt; \n&gt;&gt; It might be possible to improve the credi=\r\nt assignment by lowering the\n&gt;&gt; mutation rate.  The problem is that if the =\r\nmutation rate was lowered\n&gt; to the\n&gt;&gt; point where credit assignment could b=\r\ne manageable by NEAT, I believe\n&gt; that\n&gt;&gt; this would require orders of magn=\r\nitude more generations to converge.\n&gt; Even if\n&gt;&gt; NEAT converged to a soluti=\r\non, this does not negate the fact that a\n&gt; lot of\n&gt;&gt; the connections are ne=\r\nver used in training, and these connections\n&gt; will have\n&gt;&gt; effectively rand=\r\nom values, resulting in poor validation performance.\n&gt;&gt; \n&gt;&gt; Consider this: =\r\nif NEAT was able to learn the correct value for a\n&gt; single link\n&gt;&gt; every ge=\r\nneration, and this correct value was preserved through the\n&gt; whole run\n&gt;&gt; (=\r\ni.e. it was not accidentally mutated), it would still take about 5000\n&gt;&gt; ge=\r\nnerations to completely solve the training phase of the boxes\n&gt; problem.  A=\r\nt\n&gt;&gt; roughly an hour per generation, that&#39;s about 7 months per run.\n&gt;&gt; \n&gt;&gt; =\r\nAny sweep of the mutation rate parameter would require many\n&gt; generations i=\r\nn\n&gt;&gt; each run. I believe that, given a very low mutation rate, NEAT might\n&gt;=\r\n be able\n&gt;&gt; to solve the boxes problem; however, it would take tens of thou=\r\nsands of\n&gt;&gt; generations at least, and there&#39;s still the generalization issu=\r\ne.\n&gt; Given the\n&gt;&gt; amount of resources necessary to find the magic numbers, =\r\nI didn&#39;t\n&gt; see the\n&gt;&gt; utility in trying to pursue it.\n&gt;&gt; \n&gt;&gt; I think what m=\r\night be more interesting would be to try different\n&gt; parameters\n&gt;&gt; for Hype=\r\nrNEAT.  As we fix bugs and develop maturity in the codebase, it\n&gt;&gt; would be=\r\n important to note how the parameters should be changed for the\n&gt;&gt; older ex=\r\nperiments (e.g. the mutation rate is lower now because we\n&gt; fixed a\n&gt;&gt; bug =\r\nin mutation).\n&gt;&gt; \n&gt;&gt; --- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrot=\r\ne:\n&gt;&gt;&gt; \n&gt;&gt;&gt; Hi all-\n&gt;&gt;&gt; \n&gt;&gt;&gt; A quick question for Ken, Jason and Dave.\n&gt;&gt;&gt; =\r\n\n&gt;&gt;&gt; I notice that most of the parameter settings (e.g.\n&gt;&gt;&gt; MutateLinkWeigh=\r\ntsProbability) were the same when you guys compared\n&gt;&gt; HyperNEAT\n&gt;&gt;&gt; to P-N=\r\nEAT.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Someone in my lab raised the issue yesterday that each\n&gt; conf=\r\niguration may\n&gt;&gt;&gt; have entirely different optimal settings, making a compar=\r\nison with the\n&gt;&gt; same\n&gt;&gt;&gt; settings potentially unfair. Out of curiosity, di=\r\nd you do any\n&gt; parameter\n&gt;&gt;&gt; sweeps to see if P-NEAT&#39;s performance did much=\r\n better, and better\n&gt;&gt; approached\n&gt;&gt;&gt; HyperNEAT&#39;s, with different parameter=\r\n settings?\n&gt;&gt;&gt; \n&gt;&gt;&gt; For example, since mutations to HyperNEAT have such lar=\r\nger effects\n&gt; on the\n&gt;&gt;&gt; final substrate, it could be argued that P-NEAT ne=\r\neds a much higher\n&gt;&gt; mutation\n&gt;&gt;&gt; rate to compete.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Note: I don&#39;t t=\r\nhink P-NEAT will beat HyperNEAT no matter what the\n&gt;&gt; settings,\n&gt;&gt;&gt; but I d=\r\no think the question is fair and I would not be surprised\n&gt; if the\n&gt;&gt;&gt; sett=\r\nings that worked great for HyperNEAT are not the ones that\n&gt; work great\n&gt;&gt;&gt;=\r\n for P-NEAT (and vice versa). In short, I am confident that the\n&gt; qualitati=\r\nve\n&gt;&gt;&gt; results of your paper are still all valid (and represent\n&gt; breakthro=\r\nughs for\n&gt;&gt;&gt; the field), but am interested to know whether the quantitative=\r\n\n&gt; difference\n&gt;&gt;&gt; between the encodings might be much less with different s=\r\nettings.\n&gt;&gt;&gt; \n&gt;&gt;&gt; PS. As a side note, there are a ton of settings and sweep=\r\ning them\n&gt; all is\n&gt;&gt;&gt; nearly impossible, especially when considering intera=\r\nctions. What does\n&gt;&gt;&gt; everyone in the group consider to be the important on=\r\nes to sweep?\n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; \n&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt; \n&gt;&gt;&gt; Digita=\r\nl Evolution Lab, Michigan State University\n&gt;&gt;&gt; \n&gt;&gt;&gt; jclune@\n&gt;&gt;&gt; \n&gt;&gt; \n&gt;&gt; \n&gt;&gt;=\r\n On Thu, Dec 4, 2008 at 11:49 AM, Jeff Clune &lt;jclune@...&gt; wrote:\n&gt;&gt; \n&gt;&gt;&gt;   =\r\nHi all-\n&gt;&gt;&gt; \n&gt;&gt;&gt; A quick question for Ken, Jason and Dave.\n&gt;&gt;&gt; \n&gt;&gt;&gt; I notic=\r\ne that most of the parameter settings (e.g.\n&gt;&gt;&gt; MutateLinkWeightsProbabilit=\r\ny) were the same when you guys compared\n&gt;&gt;&gt; HyperNEAT\n&gt;&gt;&gt; to P-NEAT.\n&gt;&gt;&gt; \n&gt;=\r\n&gt;&gt; Someone in my lab raised the issue yesterday that each\n&gt; configuration m=\r\nay\n&gt;&gt;&gt; have entirely different optimal settings, making a comparison with\n&gt;=\r\n the same\n&gt;&gt;&gt; settings potentially unfair. Out of curiosity, did you do any=\r\n\n&gt; parameter\n&gt;&gt;&gt; sweeps to see if P-NEAT&#39;s performance did much better, and=\r\n better\n&gt;&gt;&gt; approached\n&gt;&gt;&gt; HyperNEAT&#39;s, with different parameter settings?\n=\r\n&gt;&gt;&gt; \n&gt;&gt;&gt; For example, since mutations to HyperNEAT have such larger effects=\r\n\n&gt; on the\n&gt;&gt;&gt; final substrate, it could be argued that P-NEAT needs a much =\r\nhigher\n&gt;&gt;&gt; mutation\n&gt;&gt;&gt; rate to compete.\n&gt;&gt;&gt; \n&gt;&gt;&gt; Note: I don&#39;t think P-NEA=\r\nT will beat HyperNEAT no matter what the\n&gt; settings,\n&gt;&gt;&gt; but I do think the=\r\n question is fair and I would not be surprised\n&gt; if the\n&gt;&gt;&gt; settings that w=\r\norked great for HyperNEAT are not the ones that\n&gt; work great\n&gt;&gt;&gt; for P-NEAT=\r\n (and vice versa). In short, I am confident that the\n&gt; qualitative\n&gt;&gt;&gt; resu=\r\nlts of your paper are still all valid (and represent\n&gt; breakthroughs for\n&gt;&gt;=\r\n&gt; the field), but am interested to know whether the quantitative\n&gt; differen=\r\nce\n&gt;&gt;&gt; between the encodings might be much less with different settings.\n&gt;&gt;=\r\n&gt; \n&gt;&gt;&gt; PS. As a side note, there are a ton of settings and sweeping them\n&gt; =\r\nall is\n&gt;&gt;&gt; nearly impossible, especially when considering interactions. Wha=\r\nt does\n&gt;&gt;&gt; everyone in the group consider to be the important ones to sweep=\r\n?\n&gt;&gt;&gt; \n&gt;&gt;&gt; Cheers,\n&gt;&gt;&gt; Jeff Clune\n&gt;&gt;&gt; \n&gt;&gt;&gt; Digital Evolution Lab, Michigan =\r\nState University\n&gt;&gt;&gt; \n&gt;&gt;&gt; jclune@... &lt;jclune%40msu.edu&gt;\n&gt;&gt;&gt; \n&gt;&gt;&gt;  \n&gt;&gt;&gt; \n&gt;&gt; =\r\n\n&gt; \n&gt; \n\n\n\n"}}