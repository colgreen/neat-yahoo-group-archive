{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":274910130,"authorName":"ddambroeplex","from":"&quot;ddambroeplex&quot; &lt;ddambro84@...&gt;","profile":"ddambroeplex","replyTo":"LIST","senderId":"jOKdoUGR8uJJLl5R9STUd91Y-4i45ssfQ4MJl_rOj8ANKzoz_z-3cat3x2m_WFsJ7P2jOOINBFZ1S-6m6yQY1Yx1rqFdR7Xepr1jE8Q","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: FloatFastConcurrentNetwork - Performance Optimization","postDate":"1259474665","msgId":4936,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhldDJ0OSthZ3AzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PEE5ODRCM0YxNUFEMDU0NDlBQTNDRDMxNEY2QkQ1Q0NFRUNBQzNBQGJuZXhjaDAyLmJuZTJrLmxvYz4="},"prevInTopic":4935,"nextInTopic":0,"prevInTime":4935,"nextInTime":4937,"topicId":4917,"numMessagesInTopic":12,"msgSnippet":"Hi Anthony, If I include the optimization in the next release, I would maintain the safe code as well.  I would probably keep the unsafe optimization as an","rawEmail":"Return-Path: &lt;ddambro84@...&gt;\r\nX-Sender: ddambro84@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 9404 invoked from network); 29 Nov 2009 06:05:18 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m13.grp.re1.yahoo.com with QMQP; 29 Nov 2009 06:05:18 -0000\r\nX-Received: from unknown (HELO n38b.bullet.mail.sp1.yahoo.com) (66.163.168.152)\n  by mta1.grp.sp2.yahoo.com with SMTP; 29 Nov 2009 06:05:18 -0000\r\nX-Received: from [69.147.65.172] by n38.bullet.mail.sp1.yahoo.com with NNFMP; 29 Nov 2009 06:04:25 -0000\r\nX-Received: from [98.137.34.72] by t14.bullet.mail.sp1.yahoo.com with NNFMP; 29 Nov 2009 06:04:25 -0000\r\nDate: Sun, 29 Nov 2009 06:04:25 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;het2t9+agp3@...&gt;\r\nIn-Reply-To: &lt;A984B3F15AD05449AA3CD314F6BD5CCEECAC3A@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;ddambroeplex&quot; &lt;ddambro84@...&gt;\r\nSubject: Re: FloatFastConcurrentNetwork - Performance Optimization\r\nX-Yahoo-Group-Post: member; u=274910130; y=BqyRWff6X174LMi8N5N2IJzYln8AGFskDR4YJuWAosihsI-X\r\nX-Yahoo-Profile: ddambroeplex\r\n\r\nHi Anthony,\n\nIf I include the optimization in the next release, I would mai=\r\nntain the &quot;safe&quot; code as well.  I would probably keep the unsafe optimizati=\r\non as an optional #define with instructions in the readme, and, of course, =\r\na thanks to Daniel.  Although as Colin pointed out, the major part of the o=\r\nptimization (folding the two loops into one) can be done entirely in manage=\r\nd code, and as long as that is properly commented, it shouldn&#39;t affect read=\r\nability.\n\nDavid D&#39;Ambrosio\n\n--- In neat@yahoogroups.com, &quot;Anthony Ison&quot; &lt;an=\r\nthony.ison@...&gt; wrote:\n&gt;\n&gt; May I suggest that the code should not be includ=\r\ned in its current state?\n&gt; From what I can tell, using unsafe code reduces =\r\nthe readability and\n&gt; shouldn&#39;t add any real benefit in terms of performanc=\r\ne.\n&gt; \n&gt;  \n&gt; \n&gt; The main difference between the current and the proposed Sin=\r\ngleStep\n&gt; methods appears to be a single loop through the connection array,=\r\n rather\n&gt; than 2.  This could produce a performance boost up to 100% (50%\n&gt;=\r\n reduction in time) assuming a huge connection array and few neurons.\n&gt; The=\r\n question is whether it is valid to iterate through the array once.\n&gt; If it=\r\n is, the same logic (including performance benefit) could be\n&gt; implemented =\r\nwithout unsafe code and I assume this would keep everybody\n&gt; happy.\n&gt; \n&gt;  \n=\r\n&gt; \n&gt; Kind regards,\n&gt; \n&gt; Anthony\n&gt; \n&gt;  \n&gt; \n&gt; From: ddambroeplex [mailto:ddam=\r\nbro84@...] \n&gt; Sent: Thursday, 26 November 2009 3:59 PM\n&gt; To: neat@yahoogrou=\r\nps.com\n&gt; Subject: [neat] Re: FloatFastConcurrentNetwork - Performance\n&gt; Opt=\r\nimization\n&gt; \n&gt;  \n&gt; \n&gt;   \n&gt; \n&gt; \n&gt; \n&gt; Hi Daniel,\n&gt; \n&gt; Thanks for your interes=\r\nt in HyperSharpNEAT. It&#39;s always good to hear\n&gt; about new researchers worki=\r\nng with it, and it&#39;s great that you found\n&gt; this optimization. Of course, t=\r\nhe bulk of the standard NEAT code is\n&gt; Colin&#39;s SharpNEAT, which is already =\r\nvery well organized and optimized.\n&gt; That&#39;s why I chose to build my HyperNE=\r\nAT code on top of it. \n&gt; \n&gt; I will definitely consider integrating this int=\r\no the main HyperSharpNEAT\n&gt; build (a new, minor update should be coming ver=\r\ny soon). I do want to\n&gt; play around with it though and make sure that the o=\r\nutput is consistent\n&gt; with the old method, although I don&#39;t see why it woul=\r\ndn&#39;t be. There also\n&gt; seems to be some conflicting information about how mo=\r\nno handles unsafe\n&gt; code, so I want to make sure the optimization doesn&#39;t b=\r\nreak\n&gt; compatibility.\n&gt; \n&gt; If you have any other ideas or questions concern=\r\ning HyperSharpNEAT, just\n&gt; let me know.\n&gt; \n&gt; David D&#39;Ambrosio\n&gt; \n&gt; --- In n=\r\neat@yahoogroups.com &lt;mailto:neat%40yahoogroups.com&gt; , &quot;Daniel&quot;\n&gt; &lt;daniel_ku=\r\nppitz@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hello,\n&gt; &gt; \n&gt; &gt; I&#39;ve played around with a quite larg=\r\ne network and took a look at the\n&gt; execution performance of HyperSharpNEAT.=\r\n There was one outstanding\n&gt; method (besides my actual evaluation method):\n=\r\n&gt; FloatFastConcurrentNetwork.SingleStep()\n&gt; &gt; \n&gt; &gt; The method has an execut=\r\nion time of only 0.3ms (avg) but it&#39;s called\n&gt; hundreds of millions of time=\r\ns, so I&#39;ve tried to optimize this method -\n&gt; with success. I&#39;ve added some =\r\nunsafe code; the methods readability is\n&gt; lost, but IMO the performance imp=\r\nrovement redresses that.\n&gt; &gt; \n&gt; &gt; Some facts:\n&gt; &gt; \n&gt; &gt; With the original me=\r\nthod a call to PerformOneGeneration() took 218\n&gt; seconds in average. With m=\r\ny modified version and the same network a call\n&gt; took 124 seconds (that&#39;s o=\r\nnly 57% of the original version).\n&gt; &gt; \n&gt; &gt; Maybe you can consider to apply =\r\nthis changes to the standard\n&gt; implementation. The modified file can be fou=\r\nnd here: \n&gt; http://groups.yahoo.com/group/neat/files/FloatFastConcurrentNet=\r\nwork.cs\n&gt; &gt; \n&gt; &gt; Cheers,\n&gt; &gt; Daniel\n&gt; &gt;\n&gt;\n\n\n\n"}}