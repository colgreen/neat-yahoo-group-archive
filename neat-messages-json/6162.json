{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234577593,"authorName":"Oliver Coleman","from":"Oliver Coleman &lt;oliver.coleman@...&gt;","profile":"olivercoleman04","replyTo":"LIST","senderId":"W48_Q0PwKWveuLB9AxIcGtQu0JpggbZg0mF1ZU1NEjPl3fDlVwqwclbi6KfaZLZs26GuM0ZKxOFs3gfnYeB_L4cbq1SniXuk3tCHkYP81CY","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] A fresh look at GPUs and OpenCL","postDate":"1372853625","msgId":6162,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBK2R1aW1QOWNjbTN1UHN5aXRrckNmU1pBNFZHXzZxQjB6PXJ6RytaejQxRzNtWllEd0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PENBRTBNK1ljelZVd3hDVXZGOGRVbk1qYl9TTHk5K19CdVNCal9IdUJrSkdqaVJTczc2QUBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PENBRTBNK1ljelZVd3hDVXZGOGRVbk1qYl9TTHk5K19CdVNCal9IdUJrSkdqaVJTczc2QUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":6161,"nextInTopic":6163,"prevInTime":6161,"nextInTime":6163,"topicId":6161,"numMessagesInTopic":7,"msgSnippet":"Hi Colin, One interesting development in the OpenCL world in recent years is Aparapi ( http://code.google.com/p/aparapi/) . It converts Java code (that must ","rawEmail":"Return-Path: &lt;oliver.coleman@...&gt;\r\nX-Sender: oliver.coleman@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 47732 invoked by uid 102); 3 Jul 2013 12:13:46 -0000\r\nX-Received: from unknown (HELO mtaq5.grp.bf1.yahoo.com) (10.193.84.36)\n  by m2.grp.bf1.yahoo.com with SMTP; 3 Jul 2013 12:13:46 -0000\r\nX-Received: (qmail 27592 invoked from network); 3 Jul 2013 12:13:46 -0000\r\nX-Received: from unknown (HELO mail-we0-f182.google.com) (74.125.82.182)\n  by mtaq5.grp.bf1.yahoo.com with SMTP; 3 Jul 2013 12:13:46 -0000\r\nX-Received: by mail-we0-f182.google.com with SMTP id p60so49979wes.13\n        for &lt;neat@yahoogroups.com&gt;; Wed, 03 Jul 2013 05:13:45 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.180.211.233 with SMTP id nf9mr349124wic.41.1372853625484;\n Wed, 03 Jul 2013 05:13:45 -0700 (PDT)\r\nX-Received: by 10.194.33.197 with HTTP; Wed, 3 Jul 2013 05:13:45 -0700 (PDT)\r\nIn-Reply-To: &lt;CAE0M+YczVUwxCUvF8dUnMjb_SLy9+_BuSBj_HuBkJGjiRSs76A@...&gt;\r\nReferences: &lt;CAE0M+YczVUwxCUvF8dUnMjb_SLy9+_BuSBj_HuBkJGjiRSs76A@...&gt;\r\nDate: Wed, 3 Jul 2013 22:13:45 +1000\r\nMessage-ID: &lt;CA+duimP9ccm3uPsyitkrCfSZA4VG_6qB0z=rzG+Zz41G3mZYDw@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=001a11c338d0acfd5004e09a647a\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Oliver Coleman &lt;oliver.coleman@...&gt;\r\nSubject: Re: [neat] A fresh look at GPUs and OpenCL\r\nX-Yahoo-Group-Post: member; u=234577593; y=61Xukyo1lH1QHMLcl7yrsrxzi4GcuAQGlt9aUjM3M50PATHRj1_aT3tzTHuNT1_wRmXDUrRZBQ\r\nX-Yahoo-Profile: olivercoleman04\r\n\r\n\r\n--001a11c338d0acfd5004e09a647a\r\nContent-Type: text/plain; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Colin,\n\nOne interesting development in the OpenCL world in recent years =\r\nis Aparapi (\nhttp://code.google.com/p/aparapi/) . It converts Java code (th=\r\nat must\nadhere to certain restrictions) to OpenCL code at runtime. I think =\r\nthis\nkind of approach can in theory help address the problem of needing to =\r\nknow\nor manually probe the current hardware parameters to adjust how the wo=\r\nrk\nexecutes on it (however I don&#39;t know if or how well this is implemented =\r\nin\nAparapi at the current time). Another nice thing about it is that it wil=\r\nl\ngracefully fall back to CPU execution if GPU execution fails. Unfortunate=\r\nly\nat the moment it has a few limitations, such as not being able to share\n=\r\ndata between different kernels running on the same GPU and being quite\nrest=\r\nricted in what sort of code can be compiled to OpenCL.\n\nI wrote a neural ne=\r\ntwork simulator that I use in my HyperNEAT\nimplementation that makes use of=\r\n Aparapi. Unfortunately I wrote it in such\na way that it requires sharing d=\r\nata between kernels to work efficiently\nbefore realising this limitation (t=\r\nhere&#39;s a kernel for the neuron model and\na kernel for synapse model). For n=\r\now I&#39;ve given up waiting for this\nlimitation to be addressed (or the other =\r\nlimitations that prevent a\nwork-around) as I&#39;m mostly working with fairly s=\r\nmall networks for which a\nGPU provides little to no speed-up (more compute =\r\nunits but slower execution\non GPU plus overhead of transfers between GPU an=\r\nd CPU). It still might be\ninteresting to check out and might provide a good=\r\n base for a more efficient\nsimulation that combines the neuron and synapse =\r\ncalculations in the same\nkernel. The code is at https://github.com/OliverCo=\r\nleman/bain (the hyperneat\nimplementation making use of it is at https://git=\r\nhub.com/OliverColeman/ahni\n).\n\nCheers,\nOliver\n\n\nT: 0421 972 953 | E: oliver=\r\n.coleman@... | W: http://ojcoleman.com\n\n\n\nOn 3 July 2013 21:26, Colin=\r\n Green &lt;colin.green1@...&gt; wrote:\n\n&gt; **\n&gt;\n&gt;\n&gt; Hi all,\n&gt;\n&gt; I know the t=\r\nopic of GPU use has come up before but there have been a\n&gt; few recent devel=\r\nopments in the GPU world so I thought it would be\n&gt; interesting to review t=\r\nhe current situation.\n&gt;\n&gt; [CUDA]\n&gt; CUDA has been mentioned previously and I=\r\n think Ken Lloyd did some work\n&gt; using CUDA in NEAT, but AFAIK none of the =\r\nNEAT implementations freely\n&gt; available are using GPUs at all (please corre=\r\nct me if I&#39;m wrong). CUDA\n&gt; was notable as being the first platform to prov=\r\nide a general computing\n&gt; platform/layer over GPUs rather than being graphi=\r\ncs acceleration\n&gt; specific. As such it greatly lowered the difficulty of us=\r\ning GPUs for\n&gt; general computing. A notable point is that CUDA is specific =\r\nto NVIDIA\n&gt; GPUs.\n&gt;\n&gt; [OpenCL]\n&gt; OpenCL is a more recent development that a=\r\nims to provide an openly\n&gt; defined GPGPU style platform. OpenCL then is a l=\r\nayer of abstraction\n&gt; from the hardware that allows GPGPU style code to be =\r\nwritten\n&gt; independently of any specific h/w and to be executed on any h/w\n&gt;=\r\n suporting OpenCL. At this time there is already a lot of support, e.g.\n&gt; t=\r\nhere is support for NVIDIA and ATI/AMD GPUs, IBM&#39;s Cell processor\n&gt; based a=\r\nccelerator &#39;blades&#39;, and you can also run OpenCL code on an\n&gt; &#39;normal&#39; Inte=\r\nl multicore CPU (which may be more useful for\n&gt; testing/development than ac=\r\nceleration?).\n&gt;\n&gt; The main issue with OpenCL is that the it is an abstracti=\r\non over\n&gt; diverse hardware, thus although a program may run it may not run =\r\nvery\n&gt; fast without specific knowledge of the underlying h/w and what it&#39;s\n=\r\n&gt; strengths and weaknesses are. E.g. if code accesses more RAM that is\n&gt; av=\r\nailable to each processor then OpenCL will simply compile in\n&gt; instructions=\r\n to copy data between local and main RAM thus eliminating\n&gt; the perf gain o=\r\nf using local RAM. OpenCL does provide for querying the\n&gt; underlying h/w fo=\r\nr some of these factors, so you could in principle\n&gt; perform a set of check=\r\ns and report that the h/w isn&#39;t suitable for\n&gt; your program, or maybe even =\r\ndynamically adjust the program code based\n&gt; on reported parameters.\n&gt;\n&gt; On =\r\nthe whole though I see OpenCL as a positive development and\n&gt; something the=\r\n NEAT community can potentially benefit from. It is still\n&gt; a relatively yo=\r\nung platform and therefore may present some challenges\n&gt; to code to as it d=\r\nevelops, but I think it&#39;s mature and stable enough\n&gt; to consider experiment=\r\ning with now.\n&gt;\n&gt; [Current GPU h/w]\n&gt; As a ballpark estimate of the sort of=\r\n performance gains a GPGPU can\n&gt; give us, ATI/AMDs current flagship card (R=\r\nadeon 7970) has a peak\n&gt; throughput of about 3.8 TFlops, compared to 100 GF=\r\nlops for a 4th\n&gt; generation quad core Intel i7. So on paper we&#39;re looking a=\r\nt a possible\n&gt; 38x speedup compared to top flight CPUs. However, OpenCL doe=\r\ns support\n&gt; utilising mutliple GPUs, e.g. in the Bitcoin mining world it&#39;s =\r\ntypical\n&gt; to have 4 and sometimes 5 GPUs in one system (using PCI &#39;riser&#39; c=\r\nables\n&gt; to distance the GPUs from the motherboard). So for a relatively mod=\r\nest\n&gt; investment you could be looking at a possible 100x speedup compared t=\r\no\n&gt; current best CPUs.\n&gt;\n&gt; [NEAT and GPUs]\n&gt; My instinct here is to modify =\r\ncurrent NEAT code to report stats on how\n&gt; much time proportionally is bein=\r\ng spent in each stage of the NEAT\n&gt; algorithm and to target the code that t=\r\nakes up the most time, this\n&gt; will be different across problem domains and =\r\nalso for NEAT versus\n&gt; HyperNEAT.\n&gt;\n&gt; Certainly if a problem domain is know=\r\nn to be CPU heavy (e.g. uses a\n&gt; physics simulation) then it&#39;s probably a n=\r\no-brainer to use OpenCL for\n&gt; that in isolation from the rest of the NEAT a=\r\nlgorithm. For NEAT itself\n&gt; I&#39;ve observed slowdown as ANNs grow in size and=\r\n this is presumably\n&gt; mostly due to time to decode and/or &#39;run&#39; the ANNs, a=\r\nnd this is of\n&gt; course a greater problem in HyperNEAT where the decode stag=\r\ne consists\n&gt; of a NEAT decode and ANN activation. So there might be some sc=\r\nope for\n&gt; using OpenCL there. One can envisage multiple GPUs where one may =\r\nbe\n&gt; dedicated to problem domain physics, one to ANN activation and another=\r\n\n&gt; to ANN genome decoding (say).\n&gt;\n&gt; [Typical GPU Architecture]\n&gt; Finally I=\r\n&#39;m going to briefly describe the architecture of the Radeon\n&gt; 7970 to give =\r\nan idea of what it is capable of.\n&gt; [Mainly taken from\n&gt;\n&gt; http://www.techr=\r\nadar.com/reviews/pc-mac/pc-components/graphics-cards/amd-radeon-hd-7970-104=\r\n9734/review/2\n&gt; ]\n&gt;\n&gt; The 7970 has:\n&gt;\n&gt; 32 x Compute Units (CUs). These are=\r\n completely independent of each\n&gt; other. If you have 2x GPUs then OpenCL wi=\r\nll see (I think) a block of\n&gt; 64 compute units, hence in some cases code ca=\r\nn be accelerated just by\n&gt; adding GPUs. Each CU has:\n&gt;\n&gt; 4 x Vector Units (=\r\nVUs). And each VU has:\n&gt; 16 x Unified shaders (unified here just means they=\r\n are no longer\n&gt; specific to a task, e.g. pixel or vector shader, they are =\r\ngeneral\n&gt; purpose processors)\n&gt;\n&gt; So in total there are 32 x 4 x 16 =3D 204=\r\n8 unified shaders.\n&gt;\n&gt; Each CU has 64kB of local RAM that all of the VUs ca=\r\nn access\n&gt; (typically for reading shared state data I would guess). In addi=\r\ntion\n&gt; each VU has it&#39;s own 64 kB of RAM (note. you would typically control=\r\n\n&gt; what&#39;s in these local memories in code, that is, it&#39;s not a passive\n&gt; CP=\r\nU cache). A vector unit is basically a SIMD processor, there is one\n&gt; set o=\r\nf instructions that are executed against all 16 shaders (so e.g.\n&gt; you can =\r\n&#39;shade&#39; 16 pixels at a time). So each of the 128 vector units\n&gt; can execute=\r\n its own instructions, and in turn those instructions are\n&gt; operating on 16=\r\n shaders. A shader then consists of some minimal state\n&gt; data specific to i=\r\nt and the data it is operating on, and also\n&gt; execution units for performin=\r\ng arithmetic, etc.\n&gt;\n&gt; An interesting thing about vector units is that cond=\r\nitional branches\n&gt; are allowed in OpenCL, that is, you can have some shader=\r\ns executing a\n&gt; different path despite there being only one set of instruct=\r\nions and\n&gt; one instruction pointer. However this is merely a trick, if VU c=\r\node\n&gt; contains a branch then both branches are executed for all shaders and=\r\n\n&gt; the shaders are assigned the correct final result based on which\n&gt; branc=\r\nh they should have followed. Hence it&#39;s advisable to avoid\n&gt; branches, but =\r\nit&#39;s a nice feature to have available so long as you\n&gt; don&#39;t abuse it.\n&gt;\n&gt; =\r\nFor more info see:\n&gt; [From Shader Code to a Tera=EF=AC=82op: How Shader Cor=\r\nes Work, Kayvon\n&gt; Fatahalian, Stanford University]\n&gt; [http://s08.idav.ucdav=\r\nis.edu/fatahalian-gpu-architecture.pdf]\n&gt;\n&gt; There&#39;s obviously a heck of a l=\r\not more to this subject than I&#39;ve\n&gt; described but I thought this might be a=\r\n reasonably good intro to\n&gt; current possibilities around GPU use in NEAT.\n&gt;=\r\n\n&gt; Colin\n&gt;  \n&gt;\n\r\n--001a11c338d0acfd5004e09a647a\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;&lt;div class=3D&quot;gmail_default&quot; style=3D&quot;font-family:georgia,=\r\nserif&quot;&gt;Hi Colin,&lt;/div&gt;&lt;div class=3D&quot;gmail_default&quot; style=3D&quot;font-family:geo=\r\nrgia,serif&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_default&quot; style=3D&quot;font-family:geo=\r\nrgia,serif&quot;&gt;\nOne interesting development in the OpenCL world in recent year=\r\ns is Aparapi (&lt;a href=3D&quot;http://code.google.com/p/aparapi/&quot;&gt;http://code.goo=\r\ngle.com/p/aparapi/&lt;/a&gt;) . It converts Java code (that must adhere to certai=\r\nn restrictions) to OpenCL code at runtime. I think this kind of approach ca=\r\nn in theory help address the problem of needing to know or manually probe t=\r\nhe current hardware parameters to adjust how the work executes on it (howev=\r\ner I don&#39;t know if or how well this is implemented in Aparapi at the cu=\r\nrrent time). Another nice thing about it is that it will gracefully fall ba=\r\nck to CPU execution if GPU execution fails. Unfortunately at the moment it =\r\nhas a few limitations, such as not being able to share data between differe=\r\nnt kernels running on the same GPU and being quite restricted in what sort =\r\nof code can be compiled to OpenCL.&lt;/div&gt;\n&lt;div class=3D&quot;gmail_default&quot; style=\r\n=3D&quot;font-family:georgia,serif&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_default&quot; style=\r\n=3D&quot;font-family:georgia,serif&quot;&gt;I wrote a neural network simulator that I us=\r\ne in my HyperNEAT implementation that makes use of Aparapi. Unfortunately I=\r\n wrote it in such a way that it requires sharing data between kernels to wo=\r\nrk efficiently before realising this limitation (there&#39;s a kernel for t=\r\nhe neuron model and a kernel for synapse model). For now I&#39;ve given up =\r\nwaiting for this limitation to be addressed (or the other limitations that =\r\nprevent a work-around) as I&#39;m mostly working with fairly small networks=\r\n for which a GPU provides little to no speed-up (more compute units but slo=\r\nwer execution on GPU plus overhead of transfers between GPU and CPU). It st=\r\nill might be interesting to check out and might provide a good base for a m=\r\nore efficient simulation that combines the neuron and synapse calculations =\r\nin the same kernel. The code is at=C2=A0&lt;a href=3D&quot;https://github.com/Olive=\r\nrColeman/bain&quot;&gt;https://github.com/OliverColeman/bain&lt;/a&gt;=C2=A0(the hypernea=\r\nt implementation making use of it is at=C2=A0&lt;a href=3D&quot;https://github.com/=\r\nOliverColeman/ahni&quot;&gt;https://github.com/OliverColeman/ahni&lt;/a&gt;).&lt;/div&gt;\n&lt;div =\r\nclass=3D&quot;gmail_default&quot; style=3D&quot;font-family:georgia,serif&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div =\r\nclass=3D&quot;gmail_default&quot; style=3D&quot;font-family:georgia,serif&quot;&gt;Cheers,&lt;/div&gt;&lt;d=\r\niv class=3D&quot;gmail_default&quot; style=3D&quot;font-family:georgia,serif&quot;&gt;Oliver&lt;/div&gt;=\r\n&lt;/div&gt;\n&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br clear=3D&quot;all&quot;&gt;&lt;div&gt;&lt;div dir=3D&quot;ltr&quot;&gt;&lt;=\r\ndiv&gt;&lt;br&gt;&lt;/div&gt;T: 0421 972 953 |=C2=A0E: &lt;a href=3D&quot;mailto:oliver.coleman@gm=\r\nail.com&quot; target=3D&quot;_blank&quot;&gt;oliver.coleman@...&lt;/a&gt;=C2=A0|=C2=A0W:=C2=\r\n=A0&lt;a href=3D&quot;http://ojcoleman.com&quot; target=3D&quot;_blank&quot;&gt;http://ojcoleman.com&lt;=\r\n/a&gt;&lt;div&gt;\n&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\n&lt;br&gt;&lt;br&gt;&lt;div class=3D=\r\n&quot;gmail_quote&quot;&gt;On 3 July 2013 21:26, Colin Green &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a hr=\r\nef=3D&quot;mailto:colin.green1@...&quot; target=3D&quot;_blank&quot;&gt;colin.green1@gmail.c=\r\nom&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;marg=\r\nin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex&quot;&gt;\n\n\n\n&lt;u&gt;&lt;/u&gt;\n\n\n\n\n=\r\n\n\n\n\n\n\n&lt;div style&gt;\n&lt;span&gt;=C2=A0&lt;/span&gt;\n\n\n&lt;div&gt;\n  &lt;div&gt;\n\n\n    &lt;div&gt;\n      \n  =\r\n    \n      &lt;p&gt;Hi all,&lt;br&gt;\n&lt;br&gt;\nI know the topic of GPU use has come up befo=\r\nre but there have been a&lt;br&gt;\nfew recent developments in the GPU world so I =\r\nthought it would be&lt;br&gt;\ninteresting to review the current situation.&lt;br&gt;\n&lt;b=\r\nr&gt;\n[CUDA]&lt;br&gt;\nCUDA has been mentioned previously and I think Ken Lloyd did =\r\nsome work&lt;br&gt;\nusing CUDA in NEAT, but AFAIK none of the NEAT implementation=\r\ns freely&lt;br&gt;\navailable are using GPUs at all (please correct me if I&#39;m =\r\nwrong). CUDA&lt;br&gt;\nwas notable as being the first platform to provide a gener=\r\nal computing&lt;br&gt;\nplatform/layer over GPUs rather than being graphics accele=\r\nration&lt;br&gt;\nspecific. As such it greatly lowered the difficulty of using GPU=\r\ns for&lt;br&gt;\ngeneral computing. A notable point is that CUDA is specific to NV=\r\nIDIA&lt;br&gt;\nGPUs.&lt;br&gt;\n&lt;br&gt;\n[OpenCL]&lt;br&gt;\nOpenCL is a more recent development th=\r\nat aims to provide an openly&lt;br&gt;\ndefined GPGPU style platform. OpenCL then =\r\nis a layer of abstraction&lt;br&gt;\nfrom the hardware that allows GPGPU style cod=\r\ne to be written&lt;br&gt;\nindependently of any specific h/w and to be executed on=\r\n any h/w&lt;br&gt;\nsuporting OpenCL. At this time there is already a lot of suppo=\r\nrt, e.g.&lt;br&gt;\nthere is support for NVIDIA and ATI/AMD GPUs, IBM&#39;s Cell p=\r\nrocessor&lt;br&gt;\nbased accelerator &#39;blades&#39;, and you can also run OpenC=\r\nL code on an&lt;br&gt;\n&#39;normal&#39; Intel multicore CPU (which may be more us=\r\neful for&lt;br&gt;\ntesting/development than acceleration?).&lt;br&gt;\n&lt;br&gt;\nThe main iss=\r\nue with OpenCL is that the it is an abstraction over&lt;br&gt;\ndiverse hardware, =\r\nthus although a program may run it may not run very&lt;br&gt;\nfast without specif=\r\nic knowledge of the underlying h/w and what it&#39;s&lt;br&gt;\nstrengths and weak=\r\nnesses are.  E.g. if code accesses more RAM that is&lt;br&gt;\navailable to each p=\r\nrocessor then OpenCL will simply compile in&lt;br&gt;\ninstructions to copy data b=\r\netween local and main RAM thus eliminating&lt;br&gt;\nthe perf gain of using local=\r\n RAM. OpenCL does provide for querying the&lt;br&gt;\nunderlying h/w for some of t=\r\nhese factors, so you could in principle&lt;br&gt;\nperform a set of checks and rep=\r\nort that the h/w isn&#39;t suitable for&lt;br&gt;\nyour program, or maybe even dyn=\r\namically adjust the program code based&lt;br&gt;\non reported parameters.&lt;br&gt;\n&lt;br&gt;=\r\n\nOn the whole though I see OpenCL as a positive development and&lt;br&gt;\nsomethi=\r\nng the NEAT community can potentially benefit from. It is still&lt;br&gt;\na relat=\r\nively young platform and therefore may present some challenges&lt;br&gt;\nto code =\r\nto as it develops, but I think it&#39;s mature and stable enough&lt;br&gt;\nto con=\r\nsider experimenting with now.&lt;br&gt;\n&lt;br&gt;\n[Current GPU h/w]&lt;br&gt;\nAs a ballpark =\r\nestimate of the sort of performance gains a GPGPU can&lt;br&gt;\ngive us, ATI/AMDs=\r\n current flagship card (Radeon 7970) has a peak&lt;br&gt;\nthroughput of about 3.8=\r\n TFlops, compared to 100 GFlops for a 4th&lt;br&gt;\ngeneration quad core Intel i7=\r\n. So on paper we&#39;re looking at a possible&lt;br&gt;\n38x speedup compared to t=\r\nop flight CPUs. However, OpenCL does support&lt;br&gt;\nutilising mutliple GPUs, e=\r\n.g. in the Bitcoin mining world it&#39;s typical&lt;br&gt;\nto have 4 and sometime=\r\ns 5 GPUs in one system (using PCI &#39;riser&#39; cables&lt;br&gt;\nto distance th=\r\ne GPUs from the motherboard). So for a relatively modest&lt;br&gt;\ninvestment you=\r\n could be looking at a possible 100x speedup compared to&lt;br&gt;\ncurrent best C=\r\nPUs.&lt;br&gt;\n&lt;br&gt;\n[NEAT and GPUs]&lt;br&gt;\nMy instinct here is to modify current NEA=\r\nT code to report stats on how&lt;br&gt;\nmuch time proportionally is being spent i=\r\nn each stage of the NEAT&lt;br&gt;\nalgorithm and to target the code that takes up=\r\n the most time, this&lt;br&gt;\nwill be different across problem domains and also =\r\nfor NEAT versus&lt;br&gt;\nHyperNEAT.&lt;br&gt;\n&lt;br&gt;\nCertainly if a problem domain is kn=\r\nown to be CPU heavy (e.g. uses a&lt;br&gt;\nphysics simulation) then it&#39;s prob=\r\nably a no-brainer to use OpenCL for&lt;br&gt;\nthat in isolation from the rest of =\r\nthe NEAT algorithm. For NEAT itself&lt;br&gt;\nI&#39;ve observed slowdown as ANNs =\r\ngrow in size and this is presumably&lt;br&gt;\nmostly due to time to decode and/or=\r\n &#39;run&#39; the ANNs, and this is of&lt;br&gt;\ncourse a greater problem in Hyp=\r\nerNEAT where the decode stage consists&lt;br&gt;\nof a NEAT decode and ANN activat=\r\nion. So there might be some scope for&lt;br&gt;\nusing OpenCL there. One can envis=\r\nage multiple GPUs where one may be&lt;br&gt;\ndedicated to problem domain physics,=\r\n one to ANN activation and another&lt;br&gt;\nto ANN genome decoding (say).&lt;br&gt;\n&lt;b=\r\nr&gt;\n[Typical GPU Architecture]&lt;br&gt;\nFinally I&#39;m going to briefly describe=\r\n the architecture of the Radeon&lt;br&gt;\n7970 to give an idea of what it is capa=\r\nble of.&lt;br&gt;\n[Mainly taken from&lt;br&gt;\n&lt;a href=3D&quot;http://www.techradar.com/revi=\r\news/pc-mac/pc-components/graphics-cards/amd-radeon-hd-7970-1049734/review/2=\r\n&quot; target=3D&quot;_blank&quot;&gt;http://www.techradar.com/reviews/pc-mac/pc-components/g=\r\nraphics-cards/amd-radeon-hd-7970-1049734/review/2&lt;/a&gt;]&lt;br&gt;\n\n&lt;br&gt;\nThe 7970 h=\r\nas:&lt;br&gt;\n&lt;br&gt;\n32 x Compute Units (CUs). These are completely independent of =\r\neach&lt;br&gt;\nother. If you have 2x GPUs then OpenCL will see (I think) a block =\r\nof&lt;br&gt;\n64 compute units, hence in some cases code can be accelerated just b=\r\ny&lt;br&gt;\nadding GPUs. Each CU has:&lt;br&gt;\n&lt;br&gt;\n4 x Vector Units (VUs). And each V=\r\nU has:&lt;br&gt;\n16 x Unified shaders (unified here just means they are no longer=\r\n&lt;br&gt;\nspecific to a task, e.g. pixel or vector shader, they are general&lt;br&gt;\n=\r\npurpose processors)&lt;br&gt;\n&lt;br&gt;\nSo in total there are 32 x 4 x 16 =3D  2048 un=\r\nified shaders.&lt;br&gt;\n&lt;br&gt;\nEach CU has 64kB of local RAM that all of the VUs c=\r\nan access&lt;br&gt;\n(typically for reading shared state data I would guess). In a=\r\nddition&lt;br&gt;\neach VU has it&#39;s own 64 kB of RAM  (note. you would typical=\r\nly control&lt;br&gt;\nwhat&#39;s in these local memories in code, that is, it&#39;=\r\ns not a passive&lt;br&gt;\nCPU cache). A vector unit is basically a SIMD processor=\r\n, there is one&lt;br&gt;\nset of instructions that are executed against all 16 sha=\r\nders (so e.g.&lt;br&gt;\nyou can &#39;shade&#39; 16 pixels at a time). So each of =\r\nthe 128 vector units&lt;br&gt;\ncan execute its own instructions, and in turn thos=\r\ne instructions are&lt;br&gt;\noperating on 16 shaders. A shader then consists of s=\r\nome minimal state&lt;br&gt;\ndata specific to it and the data it is operating on, =\r\nand also&lt;br&gt;\nexecution units for performing arithmetic, etc.&lt;br&gt;\n&lt;br&gt;\nAn in=\r\nteresting thing about vector units is that conditional branches&lt;br&gt;\nare all=\r\nowed in OpenCL, that is, you can have some shaders executing a&lt;br&gt;\ndifferen=\r\nt path despite there being only one set of instructions and&lt;br&gt;\none instruc=\r\ntion pointer. However this is merely a trick, if VU code&lt;br&gt;\ncontains a bra=\r\nnch then both branches are executed for all shaders and&lt;br&gt;\nthe shaders are=\r\n assigned the correct final result based on which&lt;br&gt;\nbranch they should ha=\r\nve followed. Hence it&#39;s advisable to avoid&lt;br&gt;\nbranches, but it&#39;s a=\r\n nice feature to have available so long as you&lt;br&gt;\ndon&#39;t abuse it.&lt;br&gt;\n=\r\n&lt;br&gt;\nFor more info see:&lt;br&gt;\n   [From Shader Code to a Tera=EF=AC=82op: How =\r\nShader Cores Work, Kayvon&lt;br&gt;\nFatahalian, Stanford University]&lt;br&gt;\n   [&lt;a h=\r\nref=3D&quot;http://s08.idav.ucdavis.edu/fatahalian-gpu-architecture.pdf&quot; target=\r\n=3D&quot;_blank&quot;&gt;http://s08.idav.ucdavis.edu/fatahalian-gpu-architecture.pdf&lt;/a&gt;=\r\n]&lt;br&gt;\n&lt;br&gt;\nThere&#39;s obviously a heck of a lot more to this subject than =\r\nI&#39;ve&lt;br&gt;\ndescribed but I thought this might be a reasonably good intro =\r\nto&lt;br&gt;\ncurrent possibilities around GPU use in NEAT.&lt;br&gt;\n&lt;br&gt;\nColin&lt;br&gt;\n&lt;/p=\r\n&gt;\n\n    &lt;/div&gt;\n     \n\n    \n    &lt;div style=3D&quot;color:#fff;min-height:0&quot;&gt;&lt;/div&gt;=\r\n\n\n\n&lt;/div&gt;\n\n\n\n  \n\n\n\n\n\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;\n\r\n--001a11c338d0acfd5004e09a647a--\r\n\n"}}