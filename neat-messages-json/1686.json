{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":7192225,"authorName":"Ian Badcoe","from":"Ian Badcoe &lt;ian_badcoe@...&gt;","profile":"ian_badcoe","replyTo":"LIST","senderId":"CTg6Wxes4aIk4saUipP9v0X5AvKpeMAo3hXP5hbINaGQKO8NPgVAz6bPQYGNKios1FFZKDxFhajadeJnFl3rP61EXw10ckcbc88","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Neuron functions","postDate":"1099501433","msgId":1686,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMS4yLjAuMC4yMDA0MTEwMzE2MTY0Mi4wMjUwNmM2OEBwb3AubWFpbC55YWhvby5jby51az4=","inReplyToHeader":"PDQxODdGMjhDLjUwNTAxMDBAZHNsLnBpcGV4LmNvbT4=","referencesHeader":"PDQxODY0NDM3LjEwNTA2MDJAZHNsLnBpcGV4LmNvbT4gPDYuMS4yLjAuMC4yMDA0MTEwMjExNTgzMC4wMjUxNDcwOEBwb3AubWFpbC55YWhvby5jby51az4gPDQxODdGMjhDLjUwNTAxMDBAZHNsLnBpcGV4LmNvbT4="},"prevInTopic":1683,"nextInTopic":1691,"prevInTime":1685,"nextInTime":1687,"topicId":1668,"numMessagesInTopic":20,"msgSnippet":"... OK, I m with you. ... Do they?  There are a few different types of neurones in biology, it is true, but in some ways it is more as if each type plays a","rawEmail":"Return-Path: &lt;ian_badcoe@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 9847 invoked from network); 3 Nov 2004 16:58:02 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m23.grp.scd.yahoo.com with QMQP; 3 Nov 2004 16:58:02 -0000\r\nReceived: from unknown (HELO smtp001.mail.ukl.yahoo.com) (217.12.11.32)\n  by mta5.grp.scd.yahoo.com with SMTP; 3 Nov 2004 16:58:02 -0000\r\nReceived: from unknown (HELO ian2k.yahoo.co.uk) (ian?badcoe@212.159.73.108 with login)\n  by smtp001.mail.ukl.yahoo.com with SMTP; 3 Nov 2004 16:58:00 -0000\r\nMessage-Id: &lt;6.1.2.0.0.20041103161642.02506c68@...&gt;\r\nX-Sender: ian_badcoe@...\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.1.2.0\r\nDate: Wed, 03 Nov 2004 17:03:53 +0000\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;4187F28C.5050100@...&gt;\r\nReferences: &lt;41864437.1050602@...&gt;\n &lt;6.1.2.0.0.20041102115830.02514708@...&gt;\n &lt;4187F28C.5050100@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\nX-eGroups-Remote-IP: 217.12.11.32\r\nFrom: Ian Badcoe &lt;ian_badcoe@...&gt;\r\nSubject: Re: [neat] Neuron functions\r\nX-Yahoo-Group-Post: member; u=7192225\r\nX-Yahoo-Profile: ian_badcoe\r\n\r\nAt 20:48 02/11/2004, you wrote:\n\n&gt;Ian Badcoe wrote:\n&gt;\n&gt; &gt;Hi,\n&gt; &gt;         Whilst I&#39;m glad to see this idea getting explored.  I wonder\n&gt; &gt;whether you need to think through what the objective is.\n&gt; &gt;\n&gt; &gt;\n&gt;I&#39;m happy to open out the discussion. The objective is slightly vague\n&gt;but I started out thinking about how we could modify NEAT so that it can\n&gt;solve problems such as multiplication and 6-multiplexer. While I&#39;m sure\n&gt;that plain old sigmoid neurons (POSN&#39;s) can represent solutions to these\n&gt;problems, the structures required are non-trivial and therefore are hard\n&gt;to discover, especially if the solution requires multiple instances of\n&gt;say, a multiplier structure, as required by the vector cross product\n&gt;problem. So in one respect, adding extra neuron functions could be seen\n&gt;as a stopgap measure in place of a modular encoding.\n\nOK, I&#39;m with you.\n\n&gt;On the other hand you could take the view that some functions are so\n&gt;fundamental, that incorporating them into the neuron makes sense for all\n&gt;NEAT variations, modular or otherwise. As I say, I think there&#39;s a\n&gt;balance between providing functions and increasing the parameter/search\n&gt;space, and not having so many and reducing the search space. Biological\n&gt;neural nets suggest the right balance might be towards adding functions.\n\nDo they?  There are a few different types of neurones in biology, it is \ntrue, but in some ways it is more as if each type plays a different role, \nglobally, rather than just being chosen for a different role in the local \ncircuit.  e.g. by this I mean the idea that a whole class of neurone can be \nlabelled as (say) &quot;inhibitory&quot; and that it is always found to inhibit and \nfurther, it is localised to particular areas and also always attached to \nthe neurones of some other class.\n\nAll that said, I&#39;m not disagreeing with you.  Just wondering if it is the \nwhole story...\n\n&gt;Actually I added the comment about division and removed division from\n&gt;the list. Mainly because division does cause some problems, like how do\n&gt;you &#39;divide&#39; a set of numbers at the collection function stage? The\n&gt;output range problem can be addressed by using log scales or some other\n&gt;mapping system. Normally such systems are only applied to map a\n&gt;network&#39;s output signals to a meaningful range, but internally we let\n&gt;the network work this sort of thing out for itself, so that it might\n&gt;well use a combination of multiplication and inversion to calculate the\n&gt;recipricol - but using it&#39;s own representation system internally.\n&gt;\n&gt;Anyway this is my thinking for dropping division, and I *think* it makes\n&gt;sense.\n\nI think I agree then.\n\n&gt; &gt;         So, you might want to think about whether your overall objective\n&gt; &gt;is &quot;nerve-like&quot; or &quot;maths-like&quot; and select your function set\n&gt; &gt;accordingly.  Personally I would go with nerve-like, because maths-like\n&gt; &gt;would be very like GP and we know GP is very fragile w.r.t mutation.  Now\n&gt; &gt;once again I have to say I&#39;m not just backing natural approaches because\n&gt; &gt;they are natural.  I just come to this with an intuition and end up[ using\n&gt; &gt;nature to explain it....\n&gt; &gt;\n&gt; &gt;\n&gt;I agree the fragility of maths based approaches is a concern, and I\n&gt;tried to address this with my weighted functions idea, but thinking it\n&gt;through that approach has problems. (i) Expands the search space even\n&gt;further. (ii) Allows neurons with the same innovation ID to describe\n&gt;distinct behaviours, thus reducing the efficacy of crossover.\n&gt;\n&gt; &gt;         w.r.t your plan for collector functions and activation functions,\n&gt; &gt;I like it.  I&#39;m not sure I like so much adding a whole new layer just to\n&gt; &gt;support &quot;leaky integrators&quot; however.\n&gt; &gt;\n&gt; &gt;\n&gt;Me neither. I might drop the leaky-integrator function altogether. If we\n&gt;select neuron functions carefully then we should be able to represent\n&gt;this type of circuit using a simple arrangement of neurons.\n&gt;\n&gt; &gt;         Did you consider making it an homologous pool of functions.  e.g.\n&gt; &gt;not distinguishing collectors from activators but allowing them to be\n&gt; &gt;plugged in any order.  That way if the system needs linearity through some\n&gt; &gt;sub-net, it does not need to select a whole load of &quot;linear&quot; activators, it\n&gt; &gt;just omits the activation functions altogether.  That would cover the leaky\n&gt; &gt;integrator as well...\n&gt; &gt;\n&gt; &gt;\n&gt;I don&#39;t follow. One of the proposed activation functions is a\n&gt;straight-through/linear function, surely selecting that function has the\n&gt;same effect?\n\nTrue, but I guess I was getting towards the idea that for some sorts of \nnet, activation functions might be the exception, rather than the rule...\n\nA completely homologous set of functions is also clearer for future \nexpansion, because if you have something a bit different, like leaky \nintegrator, it is still clear where it fits into the system.\n\n&gt; &gt;         Alternatively, you could try some sort of single neurone which\n&gt; &gt;could cover the whole (or a lot) of what you intend.  But I would only do\n&gt; &gt;that if you can come up with a single neurone design which forms a coherent\n&gt; &gt;whole and doesn&#39;t look like several unrelated ideas bolded together...\n&gt; &gt;\n&gt; &gt;How about:\n&gt; &gt;         one type of neurone with several &quot;input channels&quot;, allow multiple\n&gt; &gt;connections to each channel and sum them.\n&gt; &gt;\n&gt; &gt;         Sum_Channel - like in a standard ANN\n&gt; &gt;         Act_Channel - makes the neurone more activatable by tightening the\n&gt; &gt;sigmoid\n&gt; &gt;         Scale_Channel - multiplies the input\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;This is similar to an idea that I came across some years ago, whereby\n&gt;the output of a neuron could become a connection weight between two\n&gt;other neurons. Thus the dynamic connection weight acts like a switch,\n&gt;kind of like the base pin on a transistor. Unfortunately that project\n&gt;never got off the ground.\n\nThat&#39;s another very interesting idea.  What that ultimately implies is the \ncomplete loss of weights, in favour of a type of neurone which can be \ninserted into the connection between two others, and which has the effect \nof weighting one of its inputs by the other.  If the second input is wired \nto the bias... oh, just a second, how do you put the weight on the bias \nconnection :-) -- I guess you would always also need &quot;plain&quot; weights.\n\n&gt;I like the idea though, and the model you descibe covers a lot of what\n&gt;I&#39;m trying to achieve. e.g. neurons that can act as a switch should be\n&gt;useful in solving the 6-multiplexer problem, since that is a problem\n&gt;based around switching. Multiplication should also do well because by\n&gt;increasing the input to Act_Channel we increase the neurons sensitivity,\n&gt;thus performing a form of multiplication. This model also fits in nicely\n&gt;with the current genome encoding - all we need is an extra &#39;target\n&gt;channel&#39; field on each connection.\n&gt;\n&gt;\n&gt;\n&gt; &gt;         (scale and act are different in that when act is very low, the\n&gt; &gt;sigmoid becomes linear, but when scale is very low, the sigmoid just\n&gt; &gt;becomes very shallow)\n&gt; &gt;\n&gt; &gt;         Wiring Act and Scale just to the bias would be the same as having\n&gt; &gt;fixed, mutatable &quot;curve shape&quot; parameters on the node.  Wiring them to\n&gt; &gt;other inputs could give you potentiation/depotentiation (those are where X\n&gt; &gt;does not trigger Y but does increase the ability of Z to trigger Y).\n&gt; &gt;\n&gt; &gt;\n&gt;I&#39;m not sure I fully understand what you are describing. We can\n&gt;parameterise activation using something like:\n&gt;\n&gt;y = 1 /  (1+exp(-x * activation))\n&gt;\n&gt;But if you then scale the whole thing:\n&gt;\n&gt;y = scale* (1/(1+exp(-x * activation)))\n&gt;\n&gt;then the function now outputs over the range 0.0 to scale, instead of\n&gt;0.0 to 1.0. Is this what you meant? And would this be beneficial?\n\nNo, I meant two different control parameters on the activation curve (I \nneed to draw this but don&#39;t have time just now) one controlling the Y-scale \nof the sigmoid (activation in your eqn) and one controlling the curviness \nof the sigmoid (so that if it were zero, the sgmoid would be a straight \nline).  I&#39;m not sure the exp-based eqn is easily adapted for that, but I&#39;ll \nthink about it later....\n\n&gt;Also note that if either activation or scale are -ve then the sigmoid is\n&gt;flipped, which could well be useful. Another option is to translate the\n&gt;sigmoid, but I think values can be translated (on the x-axis) by passing\n&gt;through a neuron with a linear activation function and a bias input (the\n&gt;translation amount).\n\nOr just change the bias on the inputs...\n\nTranslation on the Y-axis, that&#39;s a different matter, but again is straying \naway from &quot;nerve-like&quot; behaviour.\n\n&gt;So the main question that arises is - should we maintain an activation\n&gt;output range of 0.0 to 1.0 at all times, or is it beneficial to output\n&gt;over other ranges? I would resist this on the basis that keeping signals\n&gt;within the same range provides us with a sort of standardisation that\n&gt;aids compatibility of neurons, and thus aids evolution.\n\nAnd if connections weights are universal then every output gets it&#39;s own \nscaling anyway.\n\nOTOH, this does lead up to another point I&#39;ve been meaning to discuss for \nsome time.  Which is how easy is it for NEAT to adjust scaling?  I thought \nabout ti before in terms of input, but it applies just the same for \noutput.  e.g. suppose we have a fit network, where to improve it we need to \nadjust the &quot;activation&quot; parameter (from your eqn) of one neurone.  The \nstandard ANN scheme can do this, all you do is scale _all_ the input \nweights on the neurone by the same amount.  However, that is a set of a \nlarge number of linked mutations, and doing one of them in isolation might \nbe unadaptive.  I see this as a very strong argument that neurones should \nhave a mutatable &quot;activation&quot; (which I would call &quot;gain&quot;) parameter...\n\n         Ian B\n\n\n\n\nLiving@Home - Open Source Evolving Organisms - \nhttp://livingathome.sourceforge.net/\n\n\n\n\n"}}