{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211599040,"authorName":"Jeff Clune","from":"Jeff Clune &lt;jclune@...&gt;","profile":"jeffreyclune","replyTo":"LIST","senderId":"sDjkZfoFR_bve4wjJ3YUq5IpiNo1WM4fu_tHhpSV9eVphah8Nzt9jjBLucMlCKSBgdrlRMB9mYnTBXolCiIeV67B","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] HybrID: A Hybridization of Indirect and Direct Encodings for Evolutionary Computation","postDate":"1248462421","msgId":4774,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEM2OEY3RTk1LjJCNzlCJWpjbHVuZUBtc3UuZWR1Pg==","inReplyToHeader":"PDcxNjNkaXZ0eHoud2wlbW91cmV0QGlzaXIuZnI+"},"prevInTopic":4773,"nextInTopic":4776,"prevInTime":4773,"nextInTime":4775,"topicId":4772,"numMessagesInTopic":19,"msgSnippet":"Hello Jean-Baptiste- ... The topology of the NN is fixed throughout the experiment.  The only things being evolved are the link weights. First the link weights","rawEmail":"Return-Path: &lt;jclune@...&gt;\r\nX-Sender: jclune@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 55223 invoked from network); 24 Jul 2009 19:07:12 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m2.grp.re1.yahoo.com with QMQP; 24 Jul 2009 19:07:12 -0000\r\nX-Received: from unknown (HELO mail-px0-f190.google.com) (209.85.216.190)\n  by mta3.grp.sp2.yahoo.com with SMTP; 24 Jul 2009 19:07:12 -0000\r\nX-Received: by pxi28 with SMTP id 28so1428039pxi.28\n        for &lt;neat@yahoogroups.com&gt;; Fri, 24 Jul 2009 12:07:08 -0700 (PDT)\r\nX-Received: by 10.114.177.17 with SMTP id z17mr4783127wae.141.1248462427929;\n        Fri, 24 Jul 2009 12:07:07 -0700 (PDT)\r\nReturn-Path: &lt;jclune@...&gt;\r\nX-Received: from ?10.0.1.2? (c-76-20-191-220.hsd1.mi.comcast.net [76.20.191.220])\n        by mx.google.com with ESMTPS id c26sm1684342waa.50.2009.07.24.12.07.05\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Fri, 24 Jul 2009 12:07:07 -0700 (PDT)\r\nUser-Agent: Microsoft-Entourage/12.13.0.080930\r\nDate: Fri, 24 Jul 2009 15:07:01 -0400\r\nTo: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\r\nMessage-ID: &lt;C68F7E95.2B79B%jclune@...&gt;\r\nThread-Topic: [neat] HybrID: A Hybridization of Indirect and Direct Encodings\n for Evolutionary Computation\r\nThread-Index: AcoMkexv3XY3ajaiYkKRvNkMcStdaA==\r\nIn-Reply-To: &lt;7163divtxz.wl%mouret@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-transfer-encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Jeff Clune &lt;jclune@...&gt;\r\nSubject: Re: [neat] HybrID: A Hybridization of Indirect and Direct Encodings\n for Evolutionary Computation\r\nX-Yahoo-Group-Post: member; u=211599040; y=RnIpiX-TEc_uaKveBrSvfXQmzofUJT0rxm-E4B1L_u2Xx-wlhIYy\r\nX-Yahoo-Profile: jeffreyclune\r\n\r\nHello Jean-Baptiste-\n\n&gt; If I understood your paper well, you first evolve the topology of the\n&gt; NN with HyperNeat then fix the topoloy and only evolve the weights. Am\n&gt; I right ?\n\nThe topology of the NN is fixed throughout the experiment.  The only things\nbeing evolved are the link weights. First the link weights are evolved with\nHyperNEAT and then they are further evolved with FT-NEAT.\n\n&gt; May it be an instance of a global search (HyperNEAT) followed by a\n&gt; local search (optimizing the weights) ?\n\nThat is one way to think of it. Another is that HyperNEAT paints the picture\n(in link weight space) in broad strokes, and then FT-NEAT fills in the\ndetails. Or, better, HyperNEAT produces a regular (modular, symmetric)\npattern and then FT-NEAT makes exceptions to that pattern.\n\n&gt; Another point of view may be that HyperNeat is good at evolving the\n&gt; topology (we only have to know if the output of the CPNN is above the\n&gt; threshold) but not the precise weights.\n\nI think there are a lot of beneficial regularities to be had in the link\nweight space, so I do think we want HyperNEAT to be in control of creating\nsuch regularities in link weights. For example, a direct encoding will never\nbe able to do anything interesting with a NN with millions of connections.\nHowever, while we want HyperNEAT to create regular link weight patterns, we\nalso need the ability to have exceptions to those regularities. One option\nis HybrID, although I think one could tweak HyperNEAT to accomplish this\nimportant goal as well.\n\nThank you for your interest in the paper.\n\n&gt; \n&gt; Best regards,\n&gt; -- \n&gt; Jean-Baptiste Mouret / Mandor\n&gt; http://animatlab.lip6.fr/~mouret\n&gt; tel : (+33) 6 28 35 10 49\n\n\n\n"}}