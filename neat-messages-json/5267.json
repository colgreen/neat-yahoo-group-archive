{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"GwsxovxvZjIQruW0Mw0xO5eo_5GlpGIbindDhbfyiRfVGwkvHcjM76o0fGb6tQJYk9KqexdpoqE2gzE3d0s508733svL","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Two New HyperNEAT Publications Focus on Scaling in Different Domains","postDate":"1277107266","msgId":5267,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGh2bjY4MituMDJhQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":5266,"nextInTime":5268,"topicId":5267,"numMessagesInTopic":1,"msgSnippet":"I am pleased to announce with my co-authors Jason Gauci and Brian Woolley publications describing two new applications of HyperNEAT in sophisticated scalable","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 29152 invoked from network); 21 Jun 2010 08:01:26 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m4.grp.sp2.yahoo.com with QMQP; 21 Jun 2010 08:01:26 -0000\r\nX-Received: from unknown (HELO n45b.bullet.mail.sp1.yahoo.com) (66.163.168.159)\n  by mta3.grp.sp2.yahoo.com with SMTP; 21 Jun 2010 08:01:26 -0000\r\nX-Received: from [69.147.65.149] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 21 Jun 2010 08:01:07 -0000\r\nX-Received: from [98.137.34.73] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 21 Jun 2010 08:01:07 -0000\r\nDate: Mon, 21 Jun 2010 08:01:06 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hvn682+n02a@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Two New HyperNEAT Publications Focus on Scaling in Different Domains\r\nX-Yahoo-Group-Post: member; u=54567749; y=35ygRZFr7y60z5_PlDg1QKmmvJCAQJUUYx7EORiyDrvp24jCaIGc\r\nX-Yahoo-Profile: kenstanley01\r\n\r\nI am pleased to announce with my co-authors Jason Gauci and Brian Woolley p=\r\nublications describing two new applications of HyperNEAT in sophisticated s=\r\ncalable domains.  Both will be appearing in the Proceedings of the 11th Int=\r\nernational Conference on Parallel Problem Solving From Nature (PPSN-2010):\n=\r\n\nJason Gauci and Kenneth O. Stanley (2010)\nIndirect Encoding of Neural Netw=\r\norks for Scalable Go.\nhttp://eplex.cs.ucf.edu/publications/2010/gauci.ppsn1=\r\n0.html\n\nBrian G. Woolley and Kenneth O. Stanley (2010)\nEvolving a Single Sc=\r\nalable Controller for an Octopus Arm with a Variable Number of Segments\nhtt=\r\np://eplex.cs.ucf.edu/publications/2010/woolley.ppsn10.html\n\nThese publicati=\r\nons demonstrate how the ability to scale the size of the substrate by re-qu=\r\nerying at higher resolution (originally shown in simple domains like the bo=\r\nxes domain) is starting to pay off in problems of real significance to rein=\r\nforcement learning.  In the paper on Go, an extension called &quot;discrete subs=\r\ntrate extrapolation&quot; allows the same controller to scale from 5x5 to 7x7 Go=\r\n.  The other paper shows a very different type of scaling from octopus arms=\r\n with 8 independent segments to arms with up to 20 segments (requiring 29,9=\r\n52 connections weights to be defined at the largest size).\n\nThe Go paper fu=\r\nrther introduces a new kind of game-playing neural network called an &quot;actio=\r\nn selector&quot; that does not try to evaluate board positions, as is customary.=\r\n  Rather, it literally outputs where it wants to move on an output sheet wi=\r\nth neurons for every board position.  HyperNEAT makes such a high-dimension=\r\nal output representation possible because of its indirect encoding.\n\nThe oc=\r\ntopus arm is a recent domainof interest in RL.  In fact, a recent RL paper =\r\nwas well received that trained an 8-segment arm to hit a single target.  In=\r\n contrast, HyperNEAT makes it possible not only to train bigger arms, but a=\r\nlso to scale 8-segment controllers to more parts, and to hit arbitrary targ=\r\nets.\n\nWe hope these papers will help to build more support for the growing =\r\nrelevance of indirect encoding to machine learning.\n\nken\n\n\n"}}