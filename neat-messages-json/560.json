{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":151231063,"authorName":"Joseph Reisinger","from":"Joseph Reisinger &lt;joeraii@...&gt;","profile":"joeraii","replyTo":"LIST","senderId":"8T39pdSEp0du-irFNb8oYkHjBJnQrkvJbXWeYneBL6BOnbmDYCKxO0MwAfwCAOIcKKS1KTYo9pjWk-05j4ocxJMEo9UopfSRXspaBqzi6Q","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Paper on evolving modular neural networks","postDate":"1080333723","msgId":560,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuNTguMDQwMzI2MTQwODUwMC4yMDM1NUBtYXJsaW5zcGlrZS5jcy51dGV4YXMuZWR1Pg==","inReplyToHeader":"PDIwMDQwMzI2MTk0NTIwLjc4NTEzLnFtYWlsQHdlYjYwNTA0Lm1haWwueWFob28uY29tPg==","referencesHeader":"PDIwMDQwMzI2MTk0NTIwLjc4NTEzLnFtYWlsQHdlYjYwNTA0Lm1haWwueWFob28uY29tPg=="},"prevInTopic":559,"nextInTopic":575,"prevInTime":559,"nextInTime":561,"topicId":535,"numMessagesInTopic":47,"msgSnippet":"... No problem. I wrote the domain myself so, I m probably the most qualified to answer. ... Yeah this is kind of a typo. The two n s are not the same. The","rawEmail":"Return-Path: &lt;joeraii@...&gt;\r\nX-Sender: joeraii@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 82529 invoked from network); 26 Mar 2004 20:42:04 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m13.grp.scd.yahoo.com with QMQP; 26 Mar 2004 20:42:04 -0000\r\nReceived: from unknown (HELO mail.cs.utexas.edu) (128.83.139.10)\n  by mta5.grp.scd.yahoo.com with SMTP; 26 Mar 2004 20:42:04 -0000\r\nReceived: from marlinspike.cs.utexas.edu (joeraii@... [128.83.144.240])\n\tby mail.cs.utexas.edu (8.12.11/8.12.11) with ESMTP id i2QKg36n028242\n\tfor &lt;neat@yahoogroups.com&gt;; Fri, 26 Mar 2004 14:42:03 -0600 (CST)\r\nReceived: (from joeraii@localhost)\n\tby marlinspike.cs.utexas.edu (8.12.11/8.12.11/Submit) id i2QKg3Z4020849;\n\tFri, 26 Mar 2004 14:42:03 -0600\r\nDate: Fri, 26 Mar 2004 14:42:03 -0600 (CST)\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;20040326194520.78513.qmail@...&gt;\r\nMessage-ID: &lt;Pine.LNX.4.58.0403261408500.20355@...&gt;\r\nReferences: &lt;20040326194520.78513.qmail@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=US-ASCII\r\nX-eGroups-Remote-IP: 128.83.139.10\r\nFrom: Joseph Reisinger &lt;joeraii@...&gt;\r\nSubject: Re: [neat] Paper on evolving modular neural networks\r\nX-Yahoo-Group-Post: member; u=151231063\r\nX-Yahoo-Profile: joeraii\r\n\r\n&gt; I read this most recent modular NEAT paper, and I had\n&gt; a question about the domain.  I hope either Ken or\n&gt; Joseph don&#39;t mind clarifying.\n\nNo problem. I wrote the domain myself so, I&#39;m probably the most qualified\nto answer.\n\n&gt; So if I&#39;m understanding this correctly, in the case of\n&gt; the 7x7 board, 7/2, or 3.5, black stones are randomly\n&gt; placed on one half of the board, and 3.5 whites stones\n&gt; are placed on the other.  Do you round up the number\n&gt; of stones?  So are there 8 initial stones (4 white and\n&gt; 4 black) on a 7x7 board?\n\nYeah this is kind of a typo. The two n&#39;s are not the same. The size of\nthe board and the number of initial stones are independent. For 7x7, I\nthink we used 10 stones or something like that one the board. This\ntranslates to 5 in each &quot;side.&quot; I put side in quotes here because, as\nyou point out later, odd board sizes don&#39;t easily divide into &quot;sides&quot;\ninstead half of the center row goes to one side.\n\n&gt; And it sounds as if the color of the stones being\n&gt; placed is irrelevant, correct?  The ANN could be\n&gt; placing red stones, or blue ones.\n\nThe &quot;color&quot; is just a thin abstraction over &quot;the input is either 1 or -1.&quot;\nIt could be fuchsia stones and almost-clear stones.\n\n&gt; All that matters is that it places its stones adjacent to either a black\n&gt; or white stone.  It gets a point for each of these moves, but if a stone\n&gt; already has a stone placed next to it, no points are awarded, correct?\n&gt; And the ANN gets 10 moves on a 7x7 board, right?\n\nYes, only each &quot;checked&quot; stone counts as a point, not the number of times\nits checked. Also, note that some random board configurations have stones\nthat are unreachable, and thus prevent a perfect score. We average fitness\nover 50 or so trials, which somewhat negates the effects of this.\n\n&gt; So if this is all correct, the most an ANN can score\n&gt; in a given 7x7 game is 8, correct?\n\n10, but yeah, you have the right idea. In a single game 10 is the max\nscore on 7x7.\n\n&gt; And on a 5x5 board, are there six initial stones?  3\n&gt; black and 3 white?  And what are you considering &quot;the\n&gt; left half&quot; and &quot;the right half&quot; if there are an odd\n&gt; number of rows and columns?\n\nI don&#39;t remember the number of stones for 5x5, I remember I chose it to be\nas close to the same stone density as 7x7. Like I said above, the left\nside and right side in this case both include half of the center row. This\nis a hack in the game in order to make vizualiazation the NN\nmodularization easier for humans.\n\n&gt; -1  0  0  1  0\n&gt;  0 -1  0  0  0\n&gt;  0  0  0  0  1\n&gt;  0 -1  0  0  0\n&gt;  0  0  0  1  0\n\nThis is correct.\n\n&gt; You say that the ANN is given a point if it places a\n&gt; stone next to an existing stone.  Does &quot;next to&quot;\n&gt; include diagonally?  If so, in the typical board\n&gt; configuration above, there is no intial move that the\n&gt; ANN could make that *wouldn&#39;t* give it a point.  By\n&gt; &quot;next to&quot;, do you mean along a horizontal or vertical\n&gt; axis?  Even so, in the above example, there&#39;s only one\n&gt; first move that wouldn&#39;t score a point.\n\nNo, &quot;next to&quot; is strictly in the Go sense. You&#39;re right diagonally would\nmake the game exceptionally easy.\n\nI actually count three non-scoring first moves on that example (actually\nbecause of the real split-game dynamics, there are 5). But anyway what you\nare getting at is correct, the game is not particularly difficult to score\nat least some points. This ensures that evolution is actually able to take\nplace initially, even on larger board sizes. Also it puts more emphasis on\n&quot;fine-tuning&quot; the NN later on in order to score perfectly in as many cases\nas possible. This is difficult in really high dimensional situations,\nwhich makes it a good test.\n\n&gt; What I&#39;m wondering is, how well does a random mover\n&gt; perform?  How often does a random mover on a 5x5 or\n&gt; 7x7 score perfectly?\n\nI don&#39;t have the data on the baseline. Probably pretty well. This domain\nwas constructed to be difficult for NE to optimize on, but its really not\na particularly hard problem. It highlights some of the problems with using\nNE in general.\n\nAnyway, since there is noticeable improvment from random NN solutions\n(akin to a random mover) to the final evolved networks, I&#39;m fairly\ncertain that evolution takes place. Since the networks start out randomly,\nI didn&#39;t really feel the need to perform this comparison explicitly.\n\n&gt; Without any sort of baseline, since its an artifical\n&gt; game domain, it&#39;s difficult to get a handle on how\n&gt; hard the task is for the ANN to learn, and to get a\n&gt; sense of what it&#39;s really learned.  How much better\n&gt; than random does an ANN have to be to play an optimal\n&gt; game?\n\nTrue. The baseline was about 65% on 5x5 and between 50 and 60% on 7x7. I\ndidn&#39;t include this because I would rather focus on the NEAT comparison,\nthan a random comparison. I think a better way of conveying this\ninformation would have been to draw an average fitness graph over all\ntrials for NEAT, Modular NEAT, and random.\n\n&gt; But I do think the paper would benefit from a\n&gt; graphical representation of a sample starting board\n&gt; state and an example of a scored move and an unscored\n&gt; move, plus relative sense of the difficulty of the\n&gt; task.\n\nI agree. And had I not been so hard pressed to squash 14 pages down to 12,\nI probably would have included those pictures :)\n\nAs for the relative sense of difficulty, I understand what you&#39;re getting\nat, but I don&#39;t think its that important. What might have been best, would\nbe to show the average evolutionary trends as a graph. The initial\nsolutions played slightly better than 50% on 7x7, and it would have been\nnice to convey that in the paper. However, since the main focus of the\npaper was on comparing to NEAT and analyzing the modularity, I don&#39;t think\nits that important.\n\nJoe\n\n-- \n\nJoseph Reisinger\nhttp://www.cs.utexas.edu/users/joeraii\n\n"}}