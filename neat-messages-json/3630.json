{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"9CtAW4w9UMxSHIQhhdMoCthiI6F7l1Guj0FXy1lww6fezZ0oiIBJM4LqbwIMe1X0ej8HwXUs3zABm6yRtSHjhKA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Does NEAT always lead to higher fitness value?","postDate":"1194454009","msgId":3630,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZnc3E1cCsxMTUyNkBlR3JvdXBzLmNvbT4=","inReplyToHeader":"PEMzNTc0Q0E0LjFFNUFFJWpjbHVuZUBtc3UuZWR1Pg=="},"prevInTopic":3629,"nextInTopic":3631,"prevInTime":3629,"nextInTime":3631,"topicId":3598,"numMessagesInTopic":22,"msgSnippet":"The below posts dated 02/03/07, 12/02/06, 10/18/06 and 10/12/06, may be applicable. ##################### Post Dated: 02/03/07: ##################### The","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 17653 invoked from network); 7 Nov 2007 16:46:50 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m42.grp.scd.yahoo.com with QMQP; 7 Nov 2007 16:46:50 -0000\r\nX-Received: from unknown (HELO n41d.bullet.mail.sp1.yahoo.com) (66.163.169.147)\n  by mta15.grp.scd.yahoo.com with SMTP; 7 Nov 2007 16:46:49 -0000\r\nX-Received: from [216.252.122.219] by n41.bullet.mail.sp1.yahoo.com with NNFMP; 07 Nov 2007 16:46:49 -0000\r\nX-Received: from [66.218.69.2] by t4.bullet.sp1.yahoo.com with NNFMP; 07 Nov 2007 16:46:49 -0000\r\nX-Received: from [66.218.67.197] by t2.bullet.scd.yahoo.com with NNFMP; 07 Nov 2007 16:46:49 -0000\r\nDate: Wed, 07 Nov 2007 16:46:49 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;fgsq5p+11526@...&gt;\r\nIn-Reply-To: &lt;C3574CA4.1E5AE%jclune@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Re: Does NEAT always lead to higher fitness value?\r\nX-Yahoo-Group-Post: member; u=281645563; y=bKqZGSaQQDFlw1uxj0lfKZ6Dv8l-_n8MKKEii-cAyAqbcA\r\nX-Yahoo-Profile: afcarl2\r\n\r\nThe below posts dated 02/03/07, 12/02/06, 10/18/06 and 10/12/06, may \nbe ap=\r\nplicable.\n\n#####################\nPost Dated: 02/03/07:\n####################=\r\n#\n\nThe beneficial objectives of Supervisor NEAT are twofold:\na) Enable impl=\r\nementation of pyramid number of populations vs. \nstarting genome complexity=\r\n; and\nb) Enable implementation of automated evolution of embedded \ngenome/p=\r\nopulations in Embedded NEAT.\n\nInvestigation has demonstrated each of the fo=\r\nllowing:\n1) NEAT parameters have a profound impact on relative dominance of=\r\n \nlateral genetic mobility vs. complexification;\n2) Standard NEAT parameter=\r\n values lack sufficient lateral genetic \nmobility to &quot;get within&quot; the genet=\r\nic mobility radius of an optimal \nsolution in lower dimension space, prior =\r\nto being weighed-down with \nthe associated computational overhead of increa=\r\nsed complexity due to \npre-mature complexification;\n3) Exploitation of infa=\r\nnt populations to maximize lateral genetic \nmobility and radius is more ben=\r\neficial in identifying optimal \nsolution space despite higher dimensionalit=\r\ny of NEAT parameter space \nassociated with Supervisor NEAT, when coupled wi=\r\nth a pyramid \npopulation vs. starting genome complexity scheme;\n\nCurrent in=\r\nvestigation involves the determination of (8) control \nconstants for multip=\r\nle time histories comprising 40,000 time points, \neach with associated (4) =\r\ninput floats and (1) target output float.\n\nOne beneficial characteristic us=\r\nage of Supervisor NEAT with infant \npopulations, is the ability to identify=\r\n infant populations \nestablishing new &quot;high-water-marks&quot; of fitness, and &quot;g=\r\netting \nanother&quot; population with the same NEAT parameter set of values \n(i.=\r\ne. &quot;going where the gold is&quot;).\n\n\n\n#####################\nPost Dated: 12/02/0=\r\n6:\n#####################\n\nI - PREMISE:\n\nNEAT in it&#39;s present state is metap=\r\nhorically the wheel. \nIn it&#39;s fundamental form, it was useful for various t=\r\nasks. But the \ngreater utility was realized upon modification into gears, p=\r\nulleys \nand bearings, and then being reintroduced as embedded elements of a=\r\n \nmachine, whose utility was more than simply the sum of it&#39;s parts. \nIn li=\r\nke fashion, NEAT is a node, where upon being reintroduced as an \nembedded n=\r\node into NEAT, in which NEAT evolves the appropriate \nconnections to adapt =\r\nthe embedded &quot;knowledge&quot; contained in the node \nto the objective of the cur=\r\nrent task, the fundamental building block \nof extensibility and reusability=\r\n is achieved via recursion and \nexpansion of the definition of node.\nWhen w=\r\ne individually look into the dark abyss of our soul, the \nsomber realizatio=\r\nn presents itself, that we have become death. Given \nman&#39;s penchant for doi=\r\nng because he could, rather than taking pause \nto consider whether he shoul=\r\nd, the repercussions of practical \nextensibility and reusability of evolved=\r\n networks will eclipse the \nsplitting of the atom, opening the door to all =\r\nmanner of utility, \nwhether for good or ill.\n\nII - THE UNDERLYING EXPERIMEN=\r\nT: (see email entitled: &quot;Supervisor \nNEAT&quot;, dated: Oct. 18, 2006)\n\n# Inputs=\r\n =3D (3) + (1) Bias\n# Outputs =3D (1)\n# Samples =3D (4)\nParameters =3D Evol=\r\nved by Supervisor, population by population, ranges \nas follows:\n\ntrait_par=\r\nam_mut_prob max/min: 1.0 / 0.0;\ntrait_mutation_power max/min: 3.0 / 0.0;\nli=\r\nnktrait_mut_sig max/min: 10.0 / 0.0;\nnodetrait_mut_sig max/min: 10.0 / 0.0;=\r\n\nweight_mut_power max/min: 3.0 / 0.0;\nrecur_prob max/min: 1.0 / 0.0;\ndisjoi=\r\nnt_coeff max/min: 10.0 / 0.0;\nexcess_coeff max/min: 10.0 / 0.0;\nmutdiff_coe=\r\nff max/min: 10.0 / 0.0;\ncompat_threshold max/min: 10.0 / 0.0;\nage_significa=\r\nnce max/min: 10.0 / 0.0;\nsurvival_thresh max/min: 1.0 / 0.0;\nmutate_only_pr=\r\nob max/min: 1.0 / 0.0;\nmutate_random_trait_prob max/min: 1.0 / 0.0;\nmutate_=\r\nlink_trait_prob max/min: 1.0 / 0.0;\nmutate_node_trait_prob max/min: 1.0 / 0=\r\n.0;\nmutate_link_weights_prob max/min: 1.0 / 0.0;\nmutate_toggle_enable_prob =\r\nmax/min: 1.0 / 0.0;\nmutate_gene_reenable_prob max/min: 1.0 / 0.0;\nmutate_ad=\r\nd_node_prob max/min: 1.0 / 0.0;\nmutate_add_link_prob max/min: 1.0 / 0.0;\nin=\r\nterspecies_mate_rate max/min: 1.0 / 0.0;\nmate_multipoint_prob max/min: 1.0 =\r\n/ 0.0;\nmate_multipoint_avg_prob max/min: 1.0 / 0.0;\nmate_singlepoint_prob m=\r\nax/min: 1.0 / 0.0;\nmate_only_prob max/min: 1.0 / 0.0;\nrecur_only_prob max/m=\r\nin: 1.0 / 0.0;\npop_size max/min: 150 / 150;\ndropoff_age max/min: 100 / 1;\nn=\r\newlink_tries max/min: 100 / 1;\nprint_every max/min: 5 / 5;\nbabies_stolen ma=\r\nx/min: 0 / 0;\nnum_runs max/min: 1 / 1;\n\nIII - EXPERIMENT RESULTS:\n\n&quot;A&quot;: # o=\r\nf Experiment Generations per Supervisor Generation\n&quot;B&quot;: Avg. Exp Highest Fi=\r\ntness after 1st Supervisor Generation\n&quot;C&quot;: Avg. Exp Highest Fitness after 2=\r\nnd Supervisor Generation\n&quot;D&quot;: Avg. Exp Highest Fitness after 5th Supervisor=\r\n Generation\n&quot;E&quot;: Avg. Exp Highest Fitness after 10th Supervisor Generation\n=\r\n&quot;F&quot;: Avg. Exp Highest Fitness after 20th Supervisor Generation\n\n&quot;A&quot; &quot;B&quot; &quot;C&quot;=\r\n &quot;D&quot; &quot;E&quot; &quot;F&quot;\n1 0.2137 0.2356 0.2483 0.2834 0.3116\n2 0.2836 0.2931 0.3578 0.=\r\n3578 0.4199\n3 0.2690 0.3041 0.3522 0.3580 0.4071\n4 0.2786 0.3652 0.3732 0.4=\r\n117 0.5679\n5 0.4860 0.5085 0.5114 0.6047 0.6047\n10 0.6818 0.6821 0.7109 0.7=\r\n822 0.8908\n20 0.9068 1.0461 1.2549 1.2752 1.3595\n\nIV - THE SUPERVISOR:\n\n# I=\r\nnputs =3D (33) &quot;pole2_markov.ne&quot; + (33) params from prior exp \npopulation +=\r\n (1) highest fitness from prior exp population + (1) Bias\n# Outputs =3D (33=\r\n)\n# Samples =3D (4)\nParameters =3D Held Constant, same as &quot;pole2_markov.ne&quot;=\r\n, except as \nfollows: pop_size =3D 100\nStarting Genome: (33) connections fr=\r\nom hardwired &quot;pole2_markov.ne&quot; \ninputs to corresponding (33) outputs\nFitnes=\r\ns: Summation of Exp fitness for entire Exp population, over \nall specified =\r\nExp generations per Supervisor generation, divided by \n# of Exp generations=\r\n per Supervisor generation\n\nV - SUPERVISOR RESULTS:\n\n&quot;G&quot;: # of Experiment G=\r\nenerations per Supervisor Generation\n&quot;H&quot;: Avg. Supervisor Highest Fitness a=\r\nfter 1st Supervisor Generation \n&quot;I&quot;: Avg. Supervisor Highest Fitness after =\r\n2nd Supervisor Generation \n&quot;J&quot;: Avg. Supervisor Highest Fitness after 5th S=\r\nupervisor Generation \n&quot;K&quot;: Avg. Supervisor Highest Fitness after 10th Super=\r\nvisor \nGeneration \n&quot;L&quot;: Avg. Supervisor Highest Fitness after 20th Supervis=\r\nor Generation\n\n&quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot;\n1 0.5522 0.5802 0.5876 0.6239 0.6492=\r\n\n2 0.7334 1.2979 4.4208 6.7852 7.6296\n3 1.5412 3.5818 5.3997 5.8231 8.4271\n=\r\n4 3.9169 5.7151 7.5876 10.8206 10.8206\n5 5.3024 5.3024 5.3024 6.2561 12.142=\r\n0\n10 11.1704 11.6299 17.2906 19.6631 20.1713\n20 31.9602 35.5698 35.5698 36.=\r\n5236 38.2221\n\nVI - CONCLUSIONS:\n\n1) Recursive embedding of trained genome o=\r\nr population requires \nexpanding definition of node.\n2) Recursive embedding=\r\n of evolving population needs automation of \nparams via embedded supervisor=\r\n on a sub-population basis.\n3) Substantial acceleration of Exp fitness incr=\r\nease can be realized \nvia pre-evolved or co-evolved params, even at the inf=\r\nant \nevolutionary stage.\n4) Increases in Exp fitness simultaneously occurre=\r\nd as Supervisor \nfitness increased, despite Supervisor fitness being based =\r\nupon the \nentire Exp population to promote generality.\n\n\n\n#################=\r\n####\nPost Dated: 10/18/06:\n#####################\n\nThe benefit of incorporat=\r\ning a neat supervisor goes beyond simple \nmanipulation of parameters. To ma=\r\nximize the benefits associated with \nthose demonstrated in the FSNEAT paper=\r\n, requires that \nmultiple &quot;Initial Populations&quot; be evaluated to identify th=\r\ne most \nbeneficial portion of the input feature space, which also represent=\r\ns \nthe most effective expenditure of computational resources. The below \nsa=\r\nmple problem demonstrates the effect of effectively varying the \npopulation=\r\n in a non-linear fashion verses generations of evolution, \nwhile keeping th=\r\ne parameters constant. It is likely that the \nparameters can be advantageou=\r\nsly manipulated to accelerate this \nprocess. While computational time is no=\r\nt recorded, the associated CPU \ntime corresponding to increasing number of =\r\ngenerations is profoundly \nhigher, even for the constant product of (# Init=\r\nial Populations)x(# \nGenerations of Evolution), which is just another way o=\r\nf saying that \nthe more complex genomes evolved with increasing number of \n=\r\ngenerations of evolution take disproportionately longer to evaluate.\n\nType =\r\nProblem: Data Representation\n\n# Inputs =3D (3) + (1) Bias\n# Outputs =3D (1)=\r\n\n# Samples =3D (4)\nParameters =3D Held Constant, same as &quot;pole2_markov.ne&quot;\n=\r\n\nMinimal Starter Gene w/ only (1) connection from Bias to Output\n\n&quot;A&quot; =3D #=\r\n Initial Populations\n&quot;B&quot; =3D # Generations\n&quot;C&quot; =3D Average Overall Highest =\r\nFitness (i.e. across all Initial \nPopulations)\n&quot;D&quot; =3D Maximum Overall High=\r\nest Fitness (i.e. across all Initial \nPopulations)\n&quot;E&quot; =3D Minimum Overall =\r\nHighest Fitness (i.e. across all Initial \nPopulations)\n\n&quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot;=\r\n\n100 1 0.08850 0.18100 0.01080\n50 2 0.02550 0.05170 0.01290\n20 5 0.02069 0.=\r\n04200 0.00684\n10 10 0.02700 0.03490 0.01610\n5 20 0.01460 0.03510 0.00179\n2 =\r\n50 0.00954 0.01580 0.00387\n1 100 0.09280 0.26900 0.00958\n\n\n1000 1 0.11060 0=\r\n.15700 0.06790\n500 2 0.08630 0.15100 0.05980\n200 5 0.08818 0.11200 0.07230\n=\r\n100 10 0.13948 0.23700 0.06490\n50 20 0.04135 0.06640 0.02040\n20 50 0.03783 =\r\n0.08530 0.01500\n10 100 0.07069 0.24700 0.00881\n5 200 0.01601 0.02630 0.0062=\r\n9\n2 500 0.03449 0.09840 0.00904\n1 1000 0.01009 0.01450 0.00665\n\n\n10000 1 0.=\r\n17725 0.22200 0.15000\n5000 2 0.21175 0.29100 0.13100\n2000 5 0.17300 0.24500=\r\n 0.10500\n1000 10 0.16360 0.23800 0.09740\n\n\n100000 1 0.29650 0.33200 0.27800=\r\n\n\n\n\n\n#####################\nPost Dated: 10/12/06:\n#####################\n\nI a=\r\nm currently working on a version of neat to supervise neat, by \nway of mani=\r\npulation of the parameters on a generation by generation \nbasis for the pur=\r\npose of attempting to accelerate the integral of the \nfitness of the underl=\r\nying neat task (UNT). The byproduct would be the \nevolution of a supervisor=\r\n genome.\n\nMy current thoughts regarding inputs to the supervisor are as \nfo=\r\nllows:\n\n1) normalized log of UNT generation #,\n2) last UNT generation highe=\r\nst fitness (HF),\n3) last UNT generation HF accum,\n4) # of generations since=\r\n last change of HF of UNT,\n5) average of UNT generation HF,\n6) slope of ave=\r\nrage of UNT generation HF (last 2 points),\n7) slope of HF accum (last 2 poi=\r\nnts).\n\nDoes anyone have any thoughts regarding the contemplated inputs, \nan=\r\nd/or suggestions for possible other candidate inputs?\n\nThoughtful suggestio=\r\nns are always appreciated!\n\nThanks,\nAndy\n\n\n--- In neat@yahoogroups.com, Jef=\r\nf Clune &lt;jclune@...&gt; wrote:\n&gt;\n&gt; I recognize it is a broad statement, but af=\r\nter doing research on \nthis\n&gt; subject for a few years it is what I have con=\r\ncluded. I am currently \nworking\n&gt; on a manuscript now that greatly bolsters=\r\n the argument, but it is \nnot out\n&gt; yet. I will let you know when it is.\n&gt; =\r\n\n&gt; Nevertheless, I started all of this with the great hope that \nevolution =\r\ncould\n&gt; do a great job of picking its own parameters. I would love to be \np=\r\nroven\n&gt; wrong! Please let me know if you have any success. I have found tha=\r\nt\n&gt; evolution consistently does  poor job of evolving its own settings.\n&gt; \n=\r\n&gt; Here is a challenge: take Ken&#39;s default settings for a good NEAT \nrun.\n&gt; =\r\nCompare those to a situation where a GA picks those settings. I&#39;ll \nbet ya =\r\na\n&gt; six pack o porter the hand picked values do significantly better.\n&gt; \n&gt; =\r\n\n&gt; \n&gt; Cheers,\n&gt; Jeff Clune\n&gt; \n&gt; Digital Evolution Lab, Michigan State Unive=\r\nrsity\n&gt; \n&gt; jclune@...\n&gt; 517.214.1060\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; &gt; From: Stephen Waits &lt;s=\r\nteve@...&gt;\n&gt; &gt; Reply-To: &quot;neat@yahoogroups.com&quot; &lt;neat@yahoogroups.com&gt;\n&gt; &gt; D=\r\nate: Wed, 7 Nov 2007 07:18:45 -0800\n&gt; &gt; To: &quot;neat@yahoogroups.com&quot; &lt;neat@ya=\r\nhoogroups.com&gt;\n&gt; &gt; Subject: Re: [neat] Re: Does NEAT always lead to higher =\r\nfitness \nvalue?\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; On Nov 7, 2007, at 6:44 AM, Jeff Clune wrote:=\r\n\n&gt; &gt; \n&gt; &gt;&gt; Beware: evolution is very bad at choosing good settings for \nevo=\r\nlution.\n&gt; &gt;&gt; That&#39;s in addition to all of the extra computation time.\n&gt; &gt; \n=\r\n&gt; &gt; \n&gt; &gt; This is a rather broad statement, and, paper or not, I don&#39;t buy \n=\r\nit.\n&gt; &gt; I believe a Differential Evolution would work *very* well to \nchoos=\r\ne\n&gt; &gt; NEAT parameters.\n&gt; &gt; \n&gt; &gt; I&#39;ve thought of doing this very thing mysel=\r\nf.  Like the OP, I \nfind the\n&gt; &gt; hand-tuning of the numerous NEAT parameter=\r\ns inelegant and painful.\n&gt; &gt; --\n&gt; &gt; Stephen Waits\n&gt; &gt; steve@...\n&gt; &gt; http://=\r\nswaits.com/\n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}