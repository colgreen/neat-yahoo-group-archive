{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"NxQt-I8pamxoB1b_90HOCJCyVPRuYW2xcbmUhPssjFp6me7cPtSlJYZIebjxCWkYvgazHb2nymV4kIHeXZBcSuJCv36XxqWbtdPBs99l_oyTUd-T1Qk","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Growing Neural Gas and CPPNs","postDate":"1230403654","msgId":4527,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdqNXQ4NitucWZtQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4529,"prevInTime":4526,"nextInTime":4528,"topicId":4527,"numMessagesInTopic":7,"msgSnippet":"Hi all, I was playing around with my latest DCPPN code, and decided to go browse the web and find something that may help. And I found it, it was right in","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 22842 invoked from network); 27 Dec 2008 18:47:37 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m50.grp.scd.yahoo.com with QMQP; 27 Dec 2008 18:47:37 -0000\r\nX-Received: from unknown (HELO n15c.bullet.sp1.yahoo.com) (69.147.64.120)\n  by mta16.grp.scd.yahoo.com with SMTP; 27 Dec 2008 18:47:37 -0000\r\nX-Received: from [69.147.65.151] by n15.bullet.sp1.yahoo.com with NNFMP; 27 Dec 2008 18:47:37 -0000\r\nX-Received: from [66.218.67.100] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 27 Dec 2008 18:47:37 -0000\r\nDate: Sat, 27 Dec 2008 18:47:34 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;gj5t86+nqfm@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Growing Neural Gas and CPPNs\r\nX-Yahoo-Group-Post: member; u=283334584; y=DmIMtHxeuKvm9qjDvlqpKENjCgZ-PhnMPXjnJd9uzvu7sXs87d3W-CDITg\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nHi all, \n\nI was playing around with my latest DCPPN code, and decided to go=\r\n \nbrowse the web and find something that may help. And I found it, it \nwas =\r\nright in front of my eyes for so long time and I didn&#39;t pay \nattention to i=\r\nt. \n\nI discussed some issues about evolution/development of neural \nsubstra=\r\ntes in one previous thread I started. Among other things, I \nstated that an=\r\n approach capable to map any CPPN pattern to a finite-\nsized physics body o=\r\nr substrate must be also capable of scaling well. \nBecause the CPPN pattern=\r\n has constant complexity that can be \napproximated at any resolution, a goo=\r\nd approach would be one that can \nproduce the same body derived from the CP=\r\nPN pattern, but on any level \nof detail. \n\nHere is one such approach, which=\r\n effectively interprets the plain CPPN \noutput picture as a probability map=\r\n that further guides the \ndevelopment of a Growing Neural Gas network. \n\nIn=\r\n GNG, the algorithm starts with 2 unconnected nodes and adds \nconnections a=\r\nnd new nodes as time progresses, while in the same time \nmoving the nodes, =\r\nresulting in closer and closer approximation of the \ndistribution of input =\r\nvectors. \n\nHow can one CPPN picture be turned into a random distribution of=\r\n input \nvectors, which still resembles the pattern? It turns out it is \ntri=\r\nvial. Suppose we allocate an array of 100 000 input vectors that \nwill be u=\r\nsed during the development of the GNG mesh. The task is to \nfill that array=\r\n. Please assume that the CPPN picture contains pixels \neach in the range of=\r\n [0 .. 1]. To get a new (the next) input vector, \nfirst pick a random (unif=\r\norm distribution) coordinate on the CPPN \npicture. Then, if the pixel value=\r\n at the picked coordinate is less (or \nhigher, depends on choice) than rand=\r\nom (0 .. 1), add the coordinate to \nthe array of input vectors. If not, the=\r\nn pick another coordinate and \ndo this until a new input vector is finally =\r\nobtained. It is good to \nadd a &quot;give up&quot; mechanism to avoid entering infini=\r\nte loop in case the \nCPPN picture is really weird one (all 0s). \n\nSo this i=\r\nn effect turns the raw CPPN output into a probability map. \nThen the GNG al=\r\ngorithm can begin developing the network. The animation \nof a developing GN=\r\nG network in this way is strikingly natural. It can \nbe easily confused wit=\r\nh real embryo development. But even though it is \nreally entertaining to wa=\r\ntch the mesh develops under the guide of the \nCPPN in such a way, the appro=\r\nach does not solve all issues I raised \nbefore. \n\nFirst of all, I can still=\r\n pick any coordinate, i.e. it is not really a \ncompact finite body. And sec=\r\nond, the maximum density (maximum number \nof nodes) is still a matter of ch=\r\noice, it has to be set by the \nexperimenter. \n\nThe way I see it, this parti=\r\ncular method can be used as a way to \nevolve HyperNEAT substrate configurat=\r\nions. Don&#39;t confuse it with \ndensities - they are still predetermined at th=\r\nis point, or \nconnectivity - HyperNEAT has a connectivity concept as a patt=\r\nern in 4D \nwhich doesn&#39;t even care about the substrate configuration. \n\nBut=\r\n there is definitely a merit in the approach. For example, the \ncircular su=\r\nbstrate in the food gathering task can be represented with \n2 concentric ci=\r\nrcles pattern, which appears often very early in \nevolution. Parallel place=\r\nment schemes are created via repeating \npatterns across x or y. And there a=\r\nre so many many possibilities. I \nthink that now is worth to try out the ca=\r\npability to evolve substrate \nconfigurations with connectivity at the same =\r\ntime.\n\nFurther exploration of the method will be targeted towards extending=\r\n \nthe GNG model. For example, another pattern (second output) can be \ninter=\r\npreted as a probability map for adding new nodes to the network. \nAnd anoth=\r\ner pattern specifying neuron types (input/hidden/output). \n\nPeter\n\nP.S. I w=\r\nill upload a binary demonstration of the method to the Files \nsection after=\r\n I complete this message. It will be named \n&quot;DCPPN_GNG.exe&quot; It uses novelty=\r\n search, where the behavior \ncharacterization is an array of N 2D vectors, =\r\nwhere N is the maximum \nnumber of nodes (in this setup - 100). The distance=\r\n is the average \ndistance between them. It exploits the fact that my partic=\r\nular \nimplementation of GNG does not delete nodes - so we know which is \nwh=\r\nich by their order of appearance. Press C to view the underlying \nCPPN prob=\r\nability picture. Press ESC to quit. And if you press Q, \nvisualization if t=\r\nurned off (runs slightly faster).\n\n\n\n\n"}}