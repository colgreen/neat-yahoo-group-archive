{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":360173778,"authorName":"Oliver Coleman","from":"Oliver Coleman &lt;oliver@...&gt;","profile":"olivercoleman04","replyTo":"LIST","senderId":"pAIwZSLTt06-fVnGMHnUD0vQWIPg4Wl1vTVpUM7wYPWQB0iGKhQ7p99tdMpSXGT7FHC1H0-UajRQtTbGZmnsOOqubN-LBTZrHevGfA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New Paper Comparing a New Encoding to HyperNEAT w.r.t. Network Properties (modularity, scale-free, regularity, scalability, etc.)","postDate":"1307751982","msgId":5587,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRERjJCNjJFLjQwNTA1MDlAZS1nZWVrLmNvbS5hdT4=","inReplyToHeader":"PEM5RDc2MEM3LjFFMkQ5JWplZmZjbHVuZUBjb3JuZWxsLmVkdT4=","referencesHeader":"PEM5RDc2MEM3LjFFMkQ5JWplZmZjbHVuZUBjb3JuZWxsLmVkdT4="},"prevInTopic":5562,"nextInTopic":5591,"prevInTime":5586,"nextInTime":5588,"topicId":5559,"numMessagesInTopic":5,"msgSnippet":"Hi Jeff, Thanks for one of the most intriguing papers I ve read for a while. :) I ve also been wondering (mostly idly as I m not actively researching at the","rawEmail":"Return-Path: &lt;oliver@...&gt;\r\nX-Sender: oliver@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 73670 invoked from network); 11 Jun 2011 00:26:27 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m4.grp.sp2.yahoo.com with QMQP; 11 Jun 2011 00:26:27 -0000\r\nX-Received: from unknown (HELO ipmail07.adl2.internode.on.net) (150.101.137.131)\n  by mta3.grp.sp2.yahoo.com with SMTP; 11 Jun 2011 00:26:26 -0000\r\nX-IronPort-Anti-Spam-Filtered: true\r\nX-IronPort-Anti-Spam-Result: AgECAOaz8k15LKxX/2dsb2JhbAAMRhuCNpUT1BuGJAShGw\r\nX-Received: from ppp121-44-172-87.lns20.syd7.internode.on.net (HELO [192.168.1.6]) ([121.44.172.87])\n  by ipmail07.adl2.internode.on.net with ESMTP; 11 Jun 2011 09:56:24 +0930\r\nMessage-ID: &lt;4DF2B62E.4050509@...&gt;\r\nDate: Sat, 11 Jun 2011 10:26:22 +1000\r\nOrganization: e-geek\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.2.17) Gecko/20110516 Thunderbird/3.1.10\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;C9D760C7.1E2D9%jeffclune@...&gt;\r\nIn-Reply-To: &lt;C9D760C7.1E2D9%jeffclune@...&gt;\r\nContent-Type: multipart/alternative;\n boundary=&quot;------------060103090903070200070706&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Oliver Coleman &lt;oliver@...&gt;\r\nReply-To: oliver@...\r\nSubject: Re: [neat] New Paper Comparing a New Encoding to HyperNEAT w.r.t.\n Network Properties (modularity, scale-free, regularity, scalability, etc.)\r\nX-Yahoo-Group-Post: member; u=360173778; y=sfrqCTD0y6JU4huLGHwKkIwu5EebYRneK2Kn5KkkdYloKeoO3eO6GZd3qOpE14U1-X10ecO7gA\r\nX-Yahoo-Profile: olivercoleman04\r\n\r\n\r\n--------------060103090903070200070706\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Jeff,\n\nThanks for one of the most intriguing papers I&#39;ve read for a whil=\r\ne. :) I&#39;ve also been wondering (mostly idly as I&#39;m not actively researching=\r\n at the moment) about ways of making HyperNEAT produce more modular network=\r\ns and handle special cases (ie required irregularities in the substrate); D=\r\nSE looks like an excellent step forward.\n\nIt looks like there&#39;s probably a =\r\nlot of design decisions you must have had to make about how the encoding wo=\r\nuld work; did you try many different set-ups before settling on the one pre=\r\nsented in the paper (eg cellular encoding instruction sets and argument typ=\r\nes). It looks like there&#39;s no easy way (eg a single instruction) for the sy=\r\nstem to add a large swath of neurons and weights; I get the feeling such an=\r\n instruction could be very useful when the task requires dealing with large=\r\n numbers of inputs (which HyperNEAT can excel at if the inputs are geometri=\r\ncally correlated).\n\nIt would be great to see more results from this type of=\r\n encoding; what plans do you have? I expect I might try to make use of this=\r\n encoding or something like it in my PhD (starting next year), in which I&#39;l=\r\nl probably be looking at evolving networks with plastic weights.\n\nCheers,\nO=\r\nliver\n\nOn 24/04/11 17:29, Jeff Clune wrote:\n&gt; Hello all-\n&gt;\n&gt; I am pleased t=\r\no announce a paper by Marcin Suchorzewski and myself that describes a new g=\r\nenerative encoding called the Developmental Symbolic Encoding (DSE).\n&gt;\n&gt; DS=\r\nE combines a key innovation from HyperNEAT (making phenotypic properties a =\r\nfunction of their geometric location) with an encoding inspired by Cellular=\r\n Encoding.  We investigate whether the /types/ of neural networks produced =\r\nby HyperNEAT are different from those produced by DSE (an iterative, growth=\r\n-based encoding). Specifically, we compare DSE to HyperNEAT with respect to=\r\n each encoding&#39;s tendency to produce networks that are modular, regular, sc=\r\nale-free, and scalable. In general, we find that DSE produced networks that=\r\n were more modular and scale-free than HyperNEAT. We also found that DSE ou=\r\ntperformed HyperNEAT on a pattern-recognition problem.\n&gt;\n&gt; I think you&#39;ll e=\r\nnjoy looking at the visualizations of the networks evolved by DSE and Hyper=\r\nNEAT, and noting their differences. Overall, I think this work raises inter=\r\nesting questions as to what types of encodings produce what types of networ=\r\nk properties. For example, are iterative growth/rewrite encodings more like=\r\nly to produce modular networks? Does HyperNEAT need growth or recursion to =\r\nincrease its modularity? Etc. What do you think?\n&gt;\n&gt; The DSE encoding is al=\r\nso an interesting and promising encoding in its own right.\n&gt;\n&gt; Here is a li=\r\nnk to the paper and the abstract:\n&gt;\n&gt; https://www.msu.edu/~jclune/webfiles/=\r\npublications/2011-SuchorzewskiAndClune-DSE-Gecco.pdf &lt;https://www.msu.edu/%=\r\n7Ejclune/webfiles/publications/2011-SuchorzewskiAndClune-DSE-Gecco.pdf&gt;\n&gt;\n&gt;=\r\n\n&gt; *A Novel Generative Encoding for Evolving Modular, Regular and Scalable =\r\nNetworks*\n&gt;\n&gt; *\n&gt;\n&gt; Suchorzewski M and Clune J. To appear in the Proceeding=\r\ns of the Genetic and Evolutionary Computation Conference.  2011.\n&gt;\n&gt; *\n&gt;\n&gt;\n=\r\n&gt; Abstract: In this paper we introduce the Developmental Symbolic Encoding =\r\n(DSE), a new generative encoding for evolving networks (e.g. neural or bool=\r\nean). DSE combines elements of two powerful generative encodings, Cellular =\r\nEncoding and HyperNEAT, in order to evolve networks that are modular, regul=\r\nar, scale-free, and scalable. Generating networks with these properties is =\r\nimportant because they can enhance performance and evolvability. We test DS=\r\nE&#39;s ability to generate scale-free and modular networks by explicitly rewar=\r\nding these properties and seeing whether evolution can produce networks tha=\r\nt possess them. We compare the networks DSE evolves to those of HyperNEAT. =\r\nThe results show that both encodings can produce scale-free networks, altho=\r\nugh DSE performs slightly, but significantly, better on this objective. DSE=\r\n networks are far more modular than HyperNEAT networks. Both encodings prod=\r\nuce regular networks. We further demonstrate that individual DSE genomes du=\r\nring \n&gt; development can scale up a network pattern to accommodate different=\r\n numbers of inputs. We also compare DSE to HyperNEAT on a pattern recogniti=\r\non problem. DSE significantly outperforms HyperNEAT, suggesting that its po=\r\ntential lay not just in the properties of the networks it produces, but als=\r\no because it can compete with leading encodings at solving challenging prob=\r\nlems. These preliminary results imply that DSE is an interesting new encodi=\r\nng worthy of additional study. The results also raise questions about which=\r\n network properties are more likely to be produced by different types of ge=\r\nnerative encodings.\n&gt;\n&gt;\n&gt;\n&gt; PS. Because there is not a current working dist=\r\nribution of Cellular Encoding, this encoding can serve as a descendent of C=\r\nE if people wish to compare against this type of encoding. We&#39;d be happy to=\r\n make the code available.\n&gt;\n&gt; Best regards,\n&gt; Jeff Clune\n&gt;\n&gt; Postdoctoral F=\r\nellow\n&gt; Hod Lipson&#39;s Creative Machines Laboratory\n&gt; Cornell University\n&gt; je=\r\nffclune@...\n&gt; www.msu.edu/~jclune\n&gt; \n\r\n--------------060103090903070200070706\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta content=&quot;text/html; charset=ISO-8859-1&quot;\n      http-equiv=&quot;Content-Type&quot;&gt;\n    &lt;title&gt;&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body bgcolor=&quot;#ffffff&quot; text=&quot;#000000&quot;&gt;\n    Hi Jeff,&lt;br&gt;\n    &lt;br&gt;\n    Thanks for one of the most intriguing papers I&#39;ve read for a while.\n    :) I&#39;ve also been wondering (mostly idly as I&#39;m not actively\n    researching at the moment) about ways of making HyperNEAT produce\n    more modular networks and handle special cases (ie required\n    irregularities in the substrate); DSE looks like an excellent step\n    forward.&lt;br&gt;\n    &lt;br&gt;\n    It looks like there&#39;s probably a lot of design decisions you must\n    have had to make about how the encoding would work; did you try many\n    different set-ups before settling on the one presented in the paper\n    (eg cellular encoding instruction sets and argument types). It looks\n    like there&#39;s no easy way (eg a single instruction) for the system to\n    add a large swath of neurons and weights; I get the feeling such an\n    instruction could be very useful when the task requires dealing with\n    large numbers of inputs (which HyperNEAT can excel at if the inputs\n    are geometrically correlated).&lt;br&gt;\n    &lt;br&gt;\n    It would be great to see more results from this type of encoding;\n    what plans do you have? I expect I might try to make use of this\n    encoding or something like it in my PhD (starting next year), in\n    which I&#39;ll probably be looking at evolving networks with plastic\n    weights.&lt;br&gt;\n    &lt;br&gt;\n    Cheers,&lt;br&gt;\n    Oliver&lt;br&gt;\n    &lt;br&gt;\n    On 24/04/11 17:29, Jeff Clune wrote:\n    &lt;blockquote cite=&quot;mid:C9D760C7.1E2D9%25jeffclune@...&quot;\n      type=&quot;cite&quot;&gt;\n      &lt;span style=&quot;display: none;&quot;&gt;&nbsp;&lt;/span&gt;\n      \n          &lt;div id=&quot;ygrp-text&quot;&gt;\n            &lt;div&gt;\n              &lt;div&gt;\n                &lt;div&gt;Hello all-&lt;/div&gt;\n                &lt;div&gt;&lt;br&gt;\n                &lt;/div&gt;\n                &lt;div&gt;I am pleased to announce a paper by Marcin\n                  Suchorzewski and myself that describes a new\n                  generative encoding called the Developmental Symbolic\n                  Encoding (DSE).&nbsp;&lt;/div&gt;\n                &lt;div&gt;&lt;br&gt;\n                &lt;/div&gt;\n                &lt;div&gt;DSE combines a key innovation from HyperNEAT\n                  (making phenotypic properties a function of their\n                  geometric location) with an encoding inspired by\n                  Cellular Encoding. &nbsp;We investigate whether the &lt;i&gt;types&lt;/i&gt;\n                  of neural networks produced by&nbsp;HyperNEAT are different\n                  from those produced by&nbsp;DSE (an iterative, growth-based\n                  encoding). Specifically, we compare DSE to HyperNEAT\n                  with respect to each encoding&#39;s tendency to produce\n                  networks that are modular, regular, scale-free, and\n                  scalable. In general, we find that DSE produced\n                  networks that were more modular and scale-free than\n                  HyperNEAT. We also found that DSE outperformed\n                  HyperNEAT on a pattern-recognition problem.&nbsp;&lt;/div&gt;\n                &lt;div&gt;&lt;br&gt;\n                &lt;/div&gt;\n                &lt;div&gt;I think you&#39;ll enjoy looking at the visualizations\n                  of the networks evolved by DSE and HyperNEAT, and\n                  noting their differences. Overall, I think this work\n                  raises interesting questions as to what types of\n                  encodings produce what types of network properties.\n                  For example, are iterative growth/rewrite encodings\n                  more likely to produce modular networks? Does\n                  HyperNEAT need growth or recursion to increase its\n                  modularity? Etc. What do you think?&lt;/div&gt;\n                &lt;div&gt;&lt;br&gt;\n                &lt;/div&gt;\n                &lt;div&gt;The DSE encoding is also an interesting and\n                  promising encoding in its own right.&nbsp;&lt;/div&gt;\n                &lt;div&gt;&lt;br&gt;\n                &lt;/div&gt;\n                &lt;div&gt;Here is a link to the paper and the abstract:&lt;/div&gt;\n                &lt;div&gt;&lt;br&gt;\n                &lt;/div&gt;\n                &lt;div&gt;\n                  &lt;div&gt;&lt;a moz-do-not-send=&quot;true&quot;\nhref=&quot;https://www.msu.edu/%7Ejclune/webfiles/publications/2011-SuchorzewskiAndClune-DSE-Gecco.pdf&quot;&gt;https://www.msu.edu/~jclune/webfiles/publications/2011-SuchorzewskiAndClune-DSE-Gecco.pdf&lt;/a&gt;&lt;/div&gt;\n                  &lt;div&gt;&lt;br&gt;\n                  &lt;/div&gt;\n                  &lt;div&gt;&lt;br&gt;\n                  &lt;/div&gt;\n                  &lt;div&gt;\n                    &lt;p style=&quot;font: 17.9px Helvetica;&quot;&gt;&lt;b&gt;A Novel\n                        Generative Encoding for Evolving Modular,\n                        Regular and Scalable Networks&lt;/b&gt;&lt;/p&gt;\n                    &lt;b&gt;\n                      &lt;p style=&quot;font: 12px Helvetica;&quot;&gt;&lt;span\n                          class=&quot;Apple-style-span&quot; style=&quot;font-size:\n                          14px;&quot;&gt;Suchorzewski M and Clune J. To appear\n                          in the Proceedings of the Genetic and\n                          Evolutionary Computation Conference. &nbsp;2011.&lt;/span&gt;&lt;/p&gt;\n                    &lt;/b&gt;\n                    &lt;p style=&quot;font: 17.9px Helvetica;&quot;&gt;&lt;font\n                        class=&quot;Apple-style-span&quot; size=&quot;3&quot;&gt;&lt;span\n                          class=&quot;Apple-style-span&quot; style=&quot;font-size:\n                          12px;&quot;&gt;&lt;br&gt;\n                        &lt;/span&gt;&lt;/font&gt;&lt;/p&gt;\n                    &lt;p style=&quot;font: 17.9px Helvetica;&quot;&gt;&lt;font\n                        class=&quot;Apple-style-span&quot; size=&quot;4&quot;&gt;&lt;span\n                          class=&quot;Apple-style-span&quot; style=&quot;font-size:\n                          14px;&quot;&gt;Abstract:&nbsp;In this paper we introduce\n                          the Developmental Symbolic Encoding (DSE), a\n                          new generative encoding for evolving networks\n                          (e.g. neural or boolean). DSE combines\n                          elements of two powerful generative encodings,\n                          Cellular Encoding and HyperNEAT, in order to\n                          evolve networks that are modular, regular,\n                          scale-free, and scalable. Generating networks\n                          with these properties is important because\n                          they can enhance performance and evolvability.\n                          We test DSE&#8217;s ability to generate scale-free\n                          and modular networks by explicitly rewarding\n                          these properties and seeing whether evolution\n                          can produce networks that possess them. We\n                          compare the networks DSE evolves to those of\n                          HyperNEAT. The results show that both\n                          encodings can produce scale-free networks,\n                          although DSE performs slightly, but\n                          significantly, better on this objective. DSE\n                          networks are far more modular than HyperNEAT\n                          networks. Both encodings produce regular\n                          networks. We further demonstrate that\n                          individual DSE genomes during development can\n                          scale up a network pattern to accommodate\n                          different numbers of inputs. We also compare\n                          DSE to HyperNEAT on a pattern recognition\n                          problem. DSE significantly outperforms\n                          HyperNEAT, suggesting that its potential lay\n                          not just in the properties of the networks it\n                          produces, but also because it can compete with\n                          leading encodings at solving challenging\n                          problems. These preliminary results imply that\n                          DSE is an interesting new encoding worthy of\n                          additional study. The results also raise\n                          questions about which network properties are\n                          more likely to be produced by different types\n                          of generative encodings.&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;\n                  &lt;/div&gt;\n                  &lt;div&gt;&lt;br&gt;\n                  &lt;/div&gt;\n                  &lt;div&gt;&lt;br&gt;\n                  &lt;/div&gt;\n                  &lt;div&gt;PS.&nbsp;Because there is not a current working\n                    distribution of Cellular Encoding, this encoding can\n                    serve as a descendent of CE if people wish to\n                    compare against this type of encoding. We&#39;d be happy\n                    to make the code available.&nbsp;&lt;/div&gt;\n                  &lt;br&gt;\n                  Best regards,&lt;br&gt;\n                  &lt;font color=&quot;#007f00&quot;&gt;Jeff Clune&lt;br&gt;\n                  &lt;/font&gt;&lt;br&gt;\n                  Postdoctoral Fellow&lt;br&gt;\n                  Hod Lipson&#39;s Creative Machines Laboratory&lt;br&gt;\n                  Cornell University&lt;br&gt;\n                  &lt;a moz-do-not-send=&quot;true&quot; href=&quot;jeffclune@...&quot;&gt;jeffclune@...&lt;/a&gt;&lt;br&gt;\n                  &lt;a class=&quot;moz-txt-link-abbreviated&quot; href=&quot;http://www.msu.edu/~jclune&quot;&gt;www.msu.edu/~jclune&lt;/a&gt;&lt;/div&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n          &lt;/div&gt;\n          \n      \n      &lt;!-- end group email --&gt;\n    &lt;/blockquote&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\r\n--------------060103090903070200070706--\r\n\n"}}