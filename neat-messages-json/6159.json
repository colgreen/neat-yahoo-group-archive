{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"jcxDncpxhuQdgSDU2l0ZfLVl7BbCMURusEk2zY4l5RT6c1FUStjirlIbeRX3YVbBBsqYds7h6pXlOIu-UonkQIbOhNJQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: GECCO Paper on HyperNEAT","postDate":"1372723839","msgId":6159,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtxdDVxMCtiN2w4QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtxZjVlYSt1dDJ1QGVHcm91cHMuY29tPg=="},"prevInTopic":6158,"nextInTopic":0,"prevInTime":6158,"nextInTime":6160,"topicId":6085,"numMessagesInTopic":14,"msgSnippet":"Thanks to Jeff an JBM for alerting me to even more recent evidence that target-based fitness isn t healthy for indirect encodings.  This article is a really","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 85795 invoked from network); 2 Jul 2013 00:10:41 -0000\r\nX-Received: from unknown (98.137.63.212)\n  by m14.grp.sp2.yahoo.com with QMQP; 2 Jul 2013 00:10:41 -0000\r\nX-Received: from unknown (HELO ng13-ip3.bullet.mail.ne1.yahoo.com) (98.138.215.218)\n  by mtaq2.grp.sp2.yahoo.com with SMTP; 2 Jul 2013 00:10:40 -0000\r\nX-Received: from [98.138.101.140] by ng13.bullet.mail.ne1.yahoo.com with NNFMP; 02 Jul 2013 00:10:40 -0000\r\nX-Received: from [98.137.34.36] by tg10.bullet.mail.ne1.yahoo.com with NNFMP; 02 Jul 2013 00:10:40 -0000\r\nDate: Tue, 02 Jul 2013 00:10:39 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kqt5q0+b7l8@...&gt;\r\nIn-Reply-To: &lt;kqf5ea+ut2u@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: GECCO Paper on HyperNEAT\r\nX-Yahoo-Group-Post: member; u=54567749; y=5sMOgKQNbRfHNuh_7EIH7GIuT_pUggLL3zS4l_l_l04RfFEfupr6\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nThanks to Jeff an JBM for alerting me to even more recent evidence that t=\r\narget-based fitness isn&#39;t healthy for indirect encodings.  This article is =\r\na really nice find - it&#39;s in Nature and it&#39;s from people apparently not par=\r\nt of our community, yet comes to a very similar conclusion on the problem w=\r\nith target-based fitness for indirect encoding.  The title is, &quot;Adaptive dy=\r\nnamics under development-based genotype=96phenotype maps.&quot; :\n\nhttp://www.na=\r\nture.com/nature/journal/v497/n7449/full/nature12142.html\n\nHere is a quote f=\r\nrom the abstract:\n&quot;We show that the complexity of the genotype=96phenotype =\r\nmap prevents substantial adaptation in some of the phenotype=96fitness maps=\r\n: sustained adaptation is only possible using `roughness&#39; or `few-traits&#39; p=\r\nhenotype=96fitness maps.&quot;\n\nIn other words, a direct target-based fitness pr=\r\nevents adaptation.  This paper is a really nice companion to my paper with =\r\nBrian Woolley.\n\n\nBest,\n\nken\n\n--- In neat@yahoogroups.com, &quot;Ken&quot; &lt;kstanley@.=\r\n..&gt; wrote:\n&gt;\n&gt; \n&gt; \n&gt; Hi Shimon,\n&gt; \n&gt; I sense from your saying, &quot;I am only s=\r\naying that I am not aware of any result which gives good reason to abandon =\r\nhope in developing methods...&quot; that you are being very careful to remain as=\r\n safely agnostic as possible.  But I would guess that you (or at least most=\r\n people) wouldn&#39;t be working on finding &quot;...methods that work with indirect=\r\n encodings and excel on &#39;regular&#39; FFs&quot; unless you actually believed they ex=\r\nist (which would indeed be a bold hypothesis).  Or maybe you really do choo=\r\nse research directions with no confidence in them beyond total neutrality, =\r\nbut sometimes there&#39;s no harm in throwing your hat in the ring and seeing w=\r\nhere your hopes (i.e. hypotheses) lead you.  In any case, since you say you=\r\n aren&#39;t aware of any, I&#39;d like to offer a number of published results that =\r\ndo support (not prove, but certainly support) doubting the hypothesis that =\r\nsuch methods exist.  \n&gt; \n&gt; First, the most obvious is my paper with Brian W=\r\noolley (http://eplex.cs.ucf.edu/papers/woolley_gecco11.pdf) on re-evolving =\r\nPicbreeder images as targets.  That of course goes straight to the heart of=\r\n the issue we are discussing, which is whether it will be possible to evolv=\r\ne to particular targets with regular FFs.  In that paper, the answer is a r=\r\nesounding &quot;no,&quot; although Picbreeder users routinely evolve such images (mea=\r\nning images as complex and interesting as the Skull or Butterfly), yet not =\r\nas targets.  Of course that does not prove that some other indirect encodin=\r\ng does not exist that can evolve to such images as targets, but what should=\r\n be worrisome is the extreme disparity in that work:  Picbreeder images tha=\r\nt are evolved in only a few dozen generations (with a population of 15) can=\r\nnot be re-evolved effectively in 30,000 generations!  I mean, you could log=\r\nically say &quot;there is no proof that a method better than NEAT+CPPNs at evolv=\r\ning to targets does not exist,&quot; but surely NEAT+CPPNs aren&#39;t *that* terribl=\r\ne of a combination - they&#39;d have to be abjectly terrible for there to be ho=\r\npe that something can handily substitute in the face of such abysmal failur=\r\ne.  So the seed of doubt is reasonably planted.  At the same time, we see i=\r\nn the same Picbreeder system (with NEAT+CPPNs) routine discovery of such im=\r\nages as non-objectives in only a few generations.  That&#39;s interesting.\n&gt; \n&gt;=\r\n Second, the novelty search and behavioral diversity results (from our grou=\r\np and others; see http://eplex.cs.ucf.edu/noveltysearch/userspage/) deserve=\r\n to be counted as evidence (not proof) supporting my hypothesis.  We see th=\r\nere many examples of a non-objective search easily solving problems that ar=\r\ne difficult or impossible for purely target-based searches with various alg=\r\norithms.  Certainly after some time all that accumulated evidence is enough=\r\n to raise doubt as to whether there exists some kind of magical target-driv=\r\nen algorithm that always gives you what you want.  But it&#39;s easy to misinte=\r\nrpret the lesson in novelty search&#39;s results.  It&#39;s not its successes that =\r\nare most important to the current discussion; rather it&#39;s the *failures* of=\r\n the target-driven variants that are most suggestive:  We are talking about=\r\n a situation in which entirely reasonable target-based setups that follow w=\r\nell accepted practices from decades of research are being squashed by a rid=\r\niculous setup that doesn&#39;t even know what it&#39;s trying to do!  Rather than c=\r\nelebrating the &quot;success&quot; of novelty search, we should be sweating with anxi=\r\nety over this disconcerting failure of the very paradigm over which you are=\r\n saying &quot;there is no reason for despair.&quot;  Perhaps not yet despair, but dou=\r\nbt - certainly.\n&gt; \n&gt; Third, sometimes just thinking a problem through is wo=\r\nrth a few cents.  Take the example of evolving the pattern of a face.  If a=\r\nn indirect encoding is to evolve a face properly, then logic suggests that =\r\nit simply must discover symmetry early on.  It is true that it could theore=\r\ntically discover a face by discovering both sides separately, but that is n=\r\not what I am calling &quot;healthy&quot; because any mutation of such a perverse repr=\r\nesentation will destroy the face-ness of the face (which means it cannot le=\r\nad to new faces).  It also would be inefficient because it would require fi=\r\nnding both sides independently when they are not independent.  In fact, the=\r\n more complex each side of the face is, the worse this misadventure becomes=\r\n.  At an extreme, if each side is as complex as a human brain, forget it, t=\r\nhe need to make an astronomically unlikely sequence of discoveries twice is=\r\n an absolute deal-breaker.  \n&gt; \n&gt; Now the question is, how can there possib=\r\nly be any magical target-based algorithm or encoding that &quot;realizes&quot; that s=\r\nymmetry needs to be rewarded early on when symmetry on its own does not eve=\r\nn remotely resemble a face?  Of course if there is special knowledge, like =\r\nif we know that faces require symmetry, we could try to incorporate that kn=\r\nowledge into the FF, but that&#39;s not what you&#39;re suggesting - you&#39;re suggest=\r\ning there may exist some method that doesn&#39;t need to know the stepping ston=\r\nes but magically rewards them anyway simply by virtue of rewarding only the=\r\n target.  Once again, the possibility remains, but the reason for doubt her=\r\ne is significant.  \n&gt; \n&gt; Finally, the idea that the products of nature are =\r\nindeed impressive is not mere conjecture.  For example, see our publication=\r\n on the topic of impressiveness (which also establishes a connection betwee=\r\nn novelty and impressiveness): \n&gt; http://eplex.cs.ucf.edu/papers/lehman_ali=\r\nfe12b.pdf\n&gt; \n&gt; Now I&#39;m not taking an extreme position here.  I&#39;m not saying=\r\n a target can&#39;t be anywhere in the mix whatsoever (so I leave plenty of roo=\r\nm e.g. for the behavioral diversity combination that Stef and JBM have deve=\r\nloped over the years).  I&#39;m just saying there is good reason to doubt the c=\r\nlarion call for pure target-based FFs leading us to the promised land.  And=\r\n as an extra bonus in the name of hope for the non-objective alternative, w=\r\ne have the fact that Einstein did evolve.  That is, I didn&#39;t mean in my pre=\r\nvious post to say that Einstein is a proof that non-objective evolution is =\r\nthe only way; rather my point is that it is a proof-of-concept that it *can=\r\n* work.  Your alternative on the other hand boasts no such proof of concept=\r\n.  We don&#39;t have any evidence it can or did work at finding human-level int=\r\nelligence, ever, anthropic concern or not.\n&gt; \n&gt; So we&#39;ve got publications, =\r\nwe&#39;ve got results, we&#39;ve got reasoning, we&#39;ve got natural precedent, all co=\r\nnsistent with my hypothesis, and it continues to accumulate.  And for what =\r\nI believe is your hypothesis (i.e. that powerful target-based methods exist=\r\n) we have little support beyond that there is no proof that that it isn&#39;t t=\r\nrue.\n&gt; \n&gt; Anyway, by all means, don&#39;t despair.  But do embrace your positio=\r\nn and consider what it implies.  For example, try to imagine a way any conc=\r\neivable indirect encoding with a target can commit to an ambiguous yet esse=\r\nntial symmetry before it discovers its target.  It&#39;s a really interesting q=\r\nuestion.  Of course, like you say, just because you can&#39;t think of it doesn=\r\n&#39;t mean it doesn&#39;t exist, but even so it sure would be reassuring if you co=\r\nuld think of it.\n&gt; \n&gt; Best,\n&gt; \n&gt; ken\n&gt; \n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;=\r\nshimonw&quot; &lt;shimon@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi Ken,\n&gt; &gt; \n&gt; &gt; Yes, I agree that this c=\r\nonversation is exposing some of our fundamental assumptions, and it is alwa=\r\nys good to examine and question such assumptions.\n&gt; &gt; \n&gt; &gt; However, if you =\r\nthink that our hypotheses are equally bold, then I fear my main point has b=\r\neen misunderstood.  I am not actually hypothesizing that an algorithm with =\r\nany particular qualities exists.  I am only saying that I am not aware of a=\r\nny result which gives good reason to abandon hope in developing methods tha=\r\nt work with indirect encodings and excel on &quot;regular&quot; FFs.  This is actuall=\r\ny not a hypothesis at all; it is an incontrovertible fact. Of course, it do=\r\nesn&#39;t prove that such a result doesn&#39;t exist and I certainly don&#39;t claim a =\r\ncomprehensive mastery of the literature.  But if such a result does exist (=\r\nthough it&#39;s hard to imagine it would), anyone is free to simply point it ou=\r\nt to me.\n&gt; &gt; \n&gt; &gt; By contrast, your hypothesis was that &quot;an unhappy and unh=\r\nealthy indirect encoding is one with only a strict target to which to aspir=\r\ne.&quot;  I continue to maintain that this quite a bold claim.  You suggested th=\r\nat the &quot;success&quot; of natural evolution provides a proof of concept to suppor=\r\nt your hypothesis, but I find this highly problematic.  Firstly, it&#39;s uncle=\r\nar that evolution was &quot;successful&quot; in any meaningful way because there&#39;s an=\r\n anthropic principle at work here: we are human and so we find humans impre=\r\nssive.  The success of evolution is thus a self-fulfilling prophecy.  Secon=\r\ndly, and more importantly, even if we accept that evolution is successful, =\r\nthis actually does not validate your hypothesis at all.  Showing that there=\r\n&#39;s a nice algorithm that works without a target is not the same as showing =\r\nthat there are *no* algorithms that work with a target, which is what your =\r\nhypothesis claims.\n&gt; &gt; \n&gt; &gt; That&#39;s why I think it&#39;s not correct to describe=\r\n our &quot;hypotheses&quot; as equally bold.  In my case, there is nothing to prove: =\r\nthere&#39;s just a simple fact.  In your case, validating the hypothesis requir=\r\nes proving a negative (and quite a sweeping one at that), which is notoriou=\r\nsly difficult to do.\n&gt; &gt; \n&gt; &gt; Finally, I sense from your defense of PicBree=\r\nder that I may have been misunderstood in another way.  I&#39;m in no way tryin=\r\ng to criticize PicBreeder or suggest that research into it is misguided.  I=\r\n think it&#39;s a very cool and intriguing result, possibly a highly significan=\r\nt one.  You and I may disagree about *why* it&#39;s significant, but we definit=\r\nely agree that it&#39;s useful to study further and has the potential to yield =\r\nimportant insights.  \n&gt; &gt; \n&gt; &gt; I&#39;m just saying that, in the complementary s=\r\nearch for optimization methods that use indirect encodings and can excel on=\r\n hard FFs, there&#39;s really no reason for despair.\n&gt; &gt; \n&gt; &gt; Cheers,\n&gt; &gt; Shimo=\r\nn\n&gt; &gt; \n&gt; &gt; --- In neat@yahoogroups.com, &quot;Ken&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; Hi Shimon,\n&gt; &gt; &gt; \n&gt; &gt; &gt; The nice thing about this type of conversation is=\r\n that it pushes us\n&gt; &gt; &gt; towards realizing our fundamental assumptions.  In=\r\n that spirit, a few\n&gt; &gt; &gt; other thoughts in response:\n&gt; &gt; &gt; \n&gt; &gt; &gt; Many top=\r\n biologists and EC researchers would call the behavior of the\n&gt; &gt; &gt; organis=\r\nm in the world (i.e. its interactions with the world) the\n&gt; &gt; &gt; &quot;phenotype.=\r\n&quot;  David Fogel once sent me a long and forceful defense of\n&gt; &gt; &gt; such a pos=\r\nition, quoting a number of famous biologists.  In that\n&gt; &gt; &gt; context, wheth=\r\ner you map CPPN-&gt;pattern or CPPN-&gt;behavior, a target is\n&gt; &gt; &gt; still a targe=\r\nt and the neural network is not the phenotype.\n&gt; &gt; &gt; \n&gt; &gt; &gt; In any case, I =\r\nguess we both hold bold hypotheses in some sense.  Your\n&gt; &gt; &gt; hypothesis th=\r\nat there exist methods that can solve hard FFs almost\n&gt; &gt; &gt; deterministical=\r\nly as targets (up to and even beyond delivering us an\n&gt; &gt; &gt; Einstein-level =\r\nbrain) seems boldly optimistic to me.  But the big\n&gt; &gt; &gt; difference between=\r\n our hypotheses is that you have no proof of concept\n&gt; &gt; &gt; for your approac=\r\nh while I do.  In your approach, you will set a target\n&gt; &gt; &gt; of Einstein an=\r\nd almost magically the algorithm will then deliver us\n&gt; &gt; &gt; Einstein, which=\r\n no method has yet shown even the faintest sign of\n&gt; &gt; &gt; achieving.  In my =\r\napproach, Einstein is not the target of the search\n&gt; &gt; &gt; process but instea=\r\nd  appears as a byproduct of a search without any\n&gt; &gt; &gt; explicit target, wh=\r\nich is (amazingly) actually what happened in the real\n&gt; &gt; &gt; world!  It may =\r\nbe tempting to dismiss that distinction, but think about\n&gt; &gt; &gt; it, the fact=\r\n that any process actually *did* produce Einstein is beyond\n&gt; &gt; &gt; incredibl=\r\ne.  We should learn from that as much as we can before\n&gt; &gt; &gt; insisting &quot;the=\r\nre&#39;s got to be a better way.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; Of course, it&#39;s great that you&#39;r=\r\ne searching for a better way (it sure\n&gt; &gt; &gt; would be nice if we could just =\r\nset Einstein&#39;s IQ as a fitness target),\n&gt; &gt; &gt; but the things is, there will=\r\n always be a ton of people trying to follow\n&gt; &gt; &gt; that path because it&#39;s su=\r\nch a clean and intuitively appealing notion. \n&gt; &gt; &gt; So it hardly needs a vi=\r\ngorous argument to convince someone that it&#39;s\n&gt; &gt; &gt; important to try.  The =\r\ndanger is instead  that in such a rush of\n&gt; &gt; &gt; enthusiasm for intuitively =\r\nappealing approaches, we sweep aside the much\n&gt; &gt; &gt; more delicate yet equal=\r\nly critical attempt to harness evolution on its\n&gt; &gt; &gt; own terms, which lead=\r\ns to things like novelty search, indirect encoding,\n&gt; &gt; &gt; and behavioral di=\r\nversity.  The power of this process may not be as clean\n&gt; &gt; &gt; and simple  a=\r\ns the optimization crowd is hoping; my argument here guards\n&gt; &gt; &gt; against t=\r\nhat danger.\n&gt; &gt; &gt; \n&gt; &gt; &gt; I think something similar is going on in our fract=\r\nure argument: In\n&gt; &gt; &gt; Picbreeder (and to some extent Endlessforms too, whi=\r\nch also uses CPPNs)\n&gt; &gt; &gt; we have perhaps the only massive proof-of-concept=\r\n that exists of\n&gt; &gt; &gt; fracture evolving through an artificial encoding.  Pi=\r\ncbreeder is a\n&gt; &gt; &gt; treasure trove of almost 10,000 examples, each one with=\r\n its own lesson\n&gt; &gt; &gt; to teach us on fracture.  And my argument is, since w=\r\ne are fortunate\n&gt; &gt; &gt; enough to have this example right in front of us (lik=\r\ne the example of\n&gt; &gt; &gt; natural evolution evolving Einstein), let&#39;s learn ev=\r\nerything we can from\n&gt; &gt; &gt; it before looking away and saying hastily, &quot;ther=\r\ne must be something\n&gt; &gt; &gt; better.&quot;  Picbreeder is a fortuitous goldmine of =\r\ndata that is very hard\n&gt; &gt; &gt; to  reproduce; it took several years and the c=\r\nontributions of hundreds\n&gt; &gt; &gt; of  people to accumulate its results.  Let&#39;s=\r\n scrub every last bit of\n&gt; &gt; &gt; wisdom  from that windfall that we can.  It&#39;=\r\ns not a question of better\n&gt; &gt; &gt; for me, it&#39;s a question of learning from t=\r\nhe only evidence we have.  How\n&gt; &gt; &gt; do you expect to really develop a bett=\r\ner encoding of fracture if you\n&gt; &gt; &gt; ignore the thousands of examples of fr=\r\nacture that already exist?  You\n&gt; &gt; &gt; will just end up reinventing the whee=\r\nl.\n&gt; &gt; &gt; \n&gt; &gt; &gt; The danger of that is evident in some of the assumptions yo=\r\nu hold\n&gt; &gt; &gt; already about how CPPNs encode fracture.  For example, you are=\r\n worried\n&gt; &gt; &gt; that it may not do so efficiently, but you have only constru=\r\ncted a\n&gt; &gt; &gt; single thought experiment (your figure 13) instead of taking a=\r\n measured\n&gt; &gt; &gt; look at the thousands of examples in front of us.  In fact,=\r\n while indeed\n&gt; &gt; &gt; I don&#39;t think 6 nodes is particularly much, it&#39;s easy e=\r\nnough to find\n&gt; &gt; &gt; fracture in Picbreeder represented in under 6 nodes.  F=\r\nor example, the\n&gt; &gt; &gt; pattern below has at least 3 distinct fractured regio=\r\nns (which I\n&gt; &gt; &gt; numbered for clarity): a pinkish region, an ovular inner =\r\nregion, and a\n&gt; &gt; &gt; conic lower region.  However, the CPPN that encodes it =\r\n(shown to its\n&gt; &gt; &gt; left) only uses 4 nodes to encode these 3 fractured reg=\r\nions (notice that\n&gt; &gt; &gt; two of the displayed hidden nodes have outgoing wei=\r\nghts of zero, so they\n&gt; &gt; &gt; are not contributing to the output pattern, lea=\r\nving only the 4 nodes). \n&gt; &gt; &gt; That&#39;s a respectable 1.3 nodes per fractured=\r\n region:\n&gt; &gt; &gt; \n&gt; &gt; &gt; (this image is also available at\n&gt; &gt; &gt; http://eplex.c=\r\ns.ucf.edu/hyperNEATpage/content/four-node-fracture.jpg\n&gt; &gt; &gt; &lt;http://eplex.=\r\ncs.ucf.edu/hyperNEATpage/content/four-node-fracture.jpg&gt; \n&gt; &gt; &gt; )\n&gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; We could argue about the definition of fracture, a=\r\nnd perhaps you&#39;d want\n&gt; &gt; &gt; to refine the definition to argue that the abov=\r\ne example doesn&#39;t really\n&gt; &gt; &gt; have three fractured regions.  Or you could =\r\nargue that the &quot;d&quot; input\n&gt; &gt; &gt; should be counted as a 5th node (to encode t=\r\nhe 3 regions, which is still\n&gt; &gt; &gt; a respectable 1.7 nodes per region).  Bu=\r\nt even those would be healthy\n&gt; &gt; &gt; discussions that we could not begin to =\r\nhave without first referring to\n&gt; &gt; &gt; the examples that we already have.  O=\r\nf course (intuitively) more complex\n&gt; &gt; &gt; fracture will require more nodes =\r\n(maybe at some point 6!), as it should.\n&gt; &gt; &gt; All I&#39;m saying is I think thi=\r\ns kind of speculation about whether it&#39;s\n&gt; &gt; &gt; efficient or not is jumping =\r\nthe gun:  Let&#39;s understand it first before\n&gt; &gt; &gt; we worry about fixing it.\n=\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; So I think there&#39;s a difference of philosophies ultimately at =\r\nwork here.\n&gt; &gt; &gt; Because the road ahead to AI is so vast, I&#39;m more motivate=\r\nd by\n&gt; &gt; &gt; maximizing our information than doing &quot;better.&quot;  For example, th=\r\nat&#39;s the\n&gt; &gt; &gt; motivation behind Picbreeder - obviously it is not quantifia=\r\nbly better\n&gt; &gt; &gt; than anything in particular, but it increased our understa=\r\nnding of a\n&gt; &gt; &gt; number of important phenomena, including fracture, represe=\r\nntation, and\n&gt; &gt; &gt; non-objective search, by providing useful information.  =\r\nSo I say, let&#39;s\n&gt; &gt; &gt; see where this takes us - there&#39;s still a ton left to=\r\n learn.  But you\n&gt; &gt; &gt; are already itching to start anew and fix things tha=\r\nt are not clearly\n&gt; &gt; &gt; broken just when we have hit a goldmine of untapped=\r\n information.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Without question, neither of our perspectives is=\r\n definitively superior;\n&gt; &gt; &gt; we are both merely speculating about where ti=\r\nme is best invested, and\n&gt; &gt; &gt; obviously neither of us can predict the futu=\r\nre.  This argument is only\n&gt; &gt; &gt; my own case for my perspective.\n&gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; Best,\n&gt; &gt; &gt; \n&gt; &gt; &gt; ken\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, =\r\n&quot;shimonw&quot;  wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; If I may, I&#39;d lik=\r\ne to offer a couple reactions to your latest message.\n&gt; &gt; &gt; This is indeed =\r\nan interesting discussion that touches on many\n&gt; &gt; &gt; potentially important =\r\nissues.  I hope I can offer a useful perspective\n&gt; &gt; &gt; on these topics.\n&gt; &gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; &gt; You are right that in a target-based scenario there can be man=\r\ny CPPNs\n&gt; &gt; &gt; that generate the same phenotype.  But the CPPN is a genotype=\r\n, not a\n&gt; &gt; &gt; phenotype. In what I&#39;m calling &quot;regular&quot; FFs, there are poten=\r\ntially many\n&gt; &gt; &gt; *phenotypes* that solve the problem, and for each of them=\r\n potentially\n&gt; &gt; &gt; many genotypes.  So in my mind, there is still a useful =\r\ndistinction\n&gt; &gt; &gt; between target based FFs and regular FFs, though they are=\r\n perhaps best\n&gt; &gt; &gt; seen as different points on a spectrum.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n If I understand correctly, you are suggesting that the important\n&gt; &gt; &gt; dis=\r\ntinction is how the FF interacts with the search process.  But to me,\n&gt; &gt; &gt;=\r\n this is a difficult criterion to use because the search process could be\n&gt;=\r\n &gt; &gt; anything.  The space of possible black-box optimization methods is hug=\r\ne,\n&gt; &gt; &gt; and what encourages piecewise incremental progress for one method =\r\nmay\n&gt; &gt; &gt; not for another.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I don&#39;t pretend to know what kin=\r\nd of algorithm would generate\n&gt; &gt; &gt; Einstein-level intelligence (I don&#39;t ev=\r\nen know if this is a useful\n&gt; &gt; &gt; goal). But as a researcher I highly respe=\r\nct once told me, &quot;your failure\n&gt; &gt; &gt; to imagine it does not constitute a pr=\r\noof that it cannot be done.&quot;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; That&#39;s why I think your hypoth=\r\nesis is quite a bold one, because it\n&gt; &gt; &gt; looks at the limitations of a sp=\r\necific class of black-box optimization\n&gt; &gt; &gt; methods and generalizes them t=\r\no all possible black-box optimization\n&gt; &gt; &gt; methods.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; To giv=\r\ne just one example of the possibilities here: algorithms for\n&gt; &gt; &gt; continuo=\r\nus-armed bandits, such as X-armed bandits and Bayesian\n&gt; &gt; &gt; optimization m=\r\nethods such as GP-UCB, can be applied to black-box\n&gt; &gt; &gt; optimization.  The=\r\nse methods avoid the problem of local optima in a\n&gt; &gt; &gt; principled way, by =\r\nmaintaining a posterior distribution over the global\n&gt; &gt; &gt; FF, and using op=\r\ntimism in the face of uncertainty to ensure sufficient\n&gt; &gt; &gt; exploration of=\r\n the solution space.  As a result, these methods have very\n&gt; &gt; &gt; nice theor=\r\netical properties, like guaranteed convergence to the global\n&gt; &gt; &gt; optimum =\r\nin the limit and logarithmic regret bounds along the way.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; A=\r\ns far as I know, no one has tried to develop versions of these\n&gt; &gt; &gt; method=\r\ns that can discover NN topologies, and which would thus be\n&gt; &gt; &gt; suitable f=\r\nor optimizing CPPNs or other indirect encodings.  But there&#39;s\n&gt; &gt; &gt; no a pr=\r\niori reason to think it can&#39;t be done.  I&#39;m not saying this would\n&gt; &gt; &gt; nec=\r\nessarily work or even that it&#39;s the most promising approach to\n&gt; &gt; &gt; explor=\r\ne.  I&#39;m just saying it&#39;s one example of a principled approach that\n&gt; &gt; &gt; co=\r\nuld avoid all the difficulties you mention and which we currently have\n&gt; &gt; =\r\n&gt; no strong reason to eliminate from contention.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; So I think=\r\n it&#39;s quite likely that these hard FFs are not unsolvable,\n&gt; &gt; &gt; but just t=\r\nhat current methods cannot solve them.  Rather than giving up\n&gt; &gt; &gt; on them=\r\n, in my opinion we should be focusing on developing better\n&gt; &gt; &gt; methods fo=\r\nr them.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Regarding whether 6 nodes is a lot to represent fra=\r\ncture, I think the\n&gt; &gt; &gt; same point applies: just because we can&#39;t think of=\r\n a better way to do\n&gt; &gt; &gt; it, doesn&#39;t mean it doesn&#39;t exist.  Our paper est=\r\nablishes 6 as an upper\n&gt; &gt; &gt; bound, which can be easily done by example.  I=\r\nf I understand correctly,\n&gt; &gt; &gt; you are suggesting that 6 may be a lower bo=\r\nund, which is much more\n&gt; &gt; &gt; difficult to demonstrate.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I c=\r\nould definitely imagine that a different type of network, or one\n&gt; &gt; &gt; with=\r\n a different set of activation functions, might be able to make\n&gt; &gt; &gt; bette=\r\nr use of 6 nodes.  Even if it&#39;s true that there&#39;s a trade-off, and\n&gt; &gt; &gt; us=\r\ning fewer nodes means less flexibility, there may be many cases where\n&gt; &gt; &gt;=\r\n that&#39;s a favorable trade-off.  We should at least be open to the\n&gt; &gt; &gt; pos=\r\nsibility that it some cases the sweet spot is not a representation\n&gt; &gt; &gt; th=\r\nat requires 6 nodes for fracture.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I&#39;m looking forward to ch=\r\natting more about this at GECCO.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; &gt; Shimon\n&gt; &gt;=\r\n &gt; &gt;\n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Ken&quot; kstanley@ wrote:\n&gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; Hi Shimon,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; These are some really interesting =\r\nand deep issues we&#39;re getting\n&gt; &gt; &gt; into.  I\n&gt; &gt; &gt; &gt; &gt; am sure they will be=\r\n the foundation of great discussions at GECCO. \n&gt; &gt; &gt; I&#39;ll\n&gt; &gt; &gt; &gt; &gt; try to=\r\n keep my response more brief than before.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 1) Indeed rec=\r\nent quadruped results are not in the same setup as in\n&gt; &gt; &gt; your\n&gt; &gt; &gt; &gt; &gt; =\r\nwork; that is a legitimate qualification and they do not constitute\n&gt; &gt; &gt; a=\r\n\n&gt; &gt; &gt; &gt; &gt; proof that in your particular setup HyperNEAT would succeed. \n&gt; =\r\n&gt; &gt; However,\n&gt; &gt; &gt; &gt; &gt; they are arguably at least comparably complex.  For =\r\nexample, the\n&gt; &gt; &gt; CTRNN\n&gt; &gt; &gt; &gt; &gt; in\n&gt; &gt; &gt; &gt; &gt; http://eplex.cs.ucf.edu/pap=\r\ners/risi_gecco13b.pdf\n&gt; &gt; &gt; &gt; &gt;    is a complicated\n&gt; &gt; &gt; &gt; &gt; structure and=\r\n the CPPN that encodes it is required not only to\n&gt; &gt; &gt; generate\n&gt; &gt; &gt; &gt; &gt; =\r\na controller for a single quadruped morphology, but to generate\n&gt; &gt; &gt; multi=\r\nple\n&gt; &gt; &gt; &gt; &gt; controllers for multiple morphologies, all from the same CPPN=\r\n.  A\n&gt; &gt; &gt; video\n&gt; &gt; &gt; &gt; &gt; of three controllers all from the same CPPN is h=\r\nere:\n&gt; &gt; &gt; &gt; &gt; http://youtu.be/oLSSt5GyHNk\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 2) I think t=\r\nhe question of what is &quot;target-based&quot; can actually be\n&gt; &gt; &gt; &gt; &gt; interesting=\r\n, but I completely agree that the semantic side of the\n&gt; &gt; &gt; &gt; &gt; argument i=\r\nsn&#39;t really important.  But what I do find interesting is\n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt;=\r\n &gt; idea that these two scenarios differ substantively in your mind (as\n&gt; &gt; =\r\n&gt; you\n&gt; &gt; &gt; &gt; &gt; put it):\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &quot;there is an important differe=\r\nnce between FFs that require a single\n&gt; &gt; &gt; &gt; &gt; specific phenotype and FFs =\r\nthat require only that some goal be\n&gt; &gt; &gt; achieved&quot;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I t=\r\nhink by &quot;single specific phenotype&quot; you mean pattern-matching\n&gt; &gt; &gt; (i.e.\n&gt;=\r\n &gt; &gt; &gt; &gt; image-matching).  But I think this distinction doesn&#39;t really exis=\r\nt:\n&gt; &gt; &gt; &gt; &gt; There are an unlimited number of networks (i.e. CPPNs) that ca=\r\nn\n&gt; &gt; &gt; encode a\n&gt; &gt; &gt; &gt; &gt; particular two-dimensional image, just as there =\r\nare an unlimited\n&gt; &gt; &gt; number\n&gt; &gt; &gt; &gt; &gt; of CPPNs that can encode a particul=\r\nar behavior or goal (such as\n&gt; &gt; &gt; &gt; &gt; following a line).\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;=\r\n &gt; What makes both target-based and fundamentally the same is not the\n&gt; &gt; &gt;=\r\n &gt; &gt; number of ways they can be solved, but rather the way the fitness\n&gt; &gt; =\r\n&gt; &gt; &gt; function interacts with the search process.  The problem is that\n&gt; &gt; =\r\n&gt; &gt; &gt; target-based fitness encourages piece-wise incremental progress,\n&gt; &gt; =\r\n&gt; which\n&gt; &gt; &gt; &gt; &gt; tends to be highly deceptive.  For example, with an image=\r\n, matching\n&gt; &gt; &gt; a\n&gt; &gt; &gt; &gt; &gt; single pixel can raise fitness even if the fun=\r\nction that causes that\n&gt; &gt; &gt; &gt; &gt; pixel to be matched has no relationship wh=\r\natsoever to the overall\n&gt; &gt; &gt; &gt; &gt; regularities in the target pattern.  The =\r\nsame is true in control\n&gt; &gt; &gt; tasks:\n&gt; &gt; &gt; &gt; &gt; A mutation that causes a qua=\r\ndruped to lunge forward clumsily is\n&gt; &gt; &gt; rewarded\n&gt; &gt; &gt; &gt; &gt; for the slight=\r\n improvement in fitness, whereas an important\n&gt; &gt; &gt; underlying\n&gt; &gt; &gt; &gt; &gt; re=\r\ngularity (e.g. oscillation) necessary to get really good at the\n&gt; &gt; &gt; task\n=\r\n&gt; &gt; &gt; &gt; &gt; is never established.  Non-target-based fitness (or what I call\n&gt;=\r\n &gt; &gt; &gt; &gt; &quot;non-objective&quot;) avoids these problems because it *does* reward\n&gt; =\r\n&gt; &gt; &gt; &gt; establishing regularities: it appreciates new regularities even if\n=\r\n&gt; &gt; &gt; they\n&gt; &gt; &gt; &gt; &gt; don&#39;t immediately raise fitness.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; B=\r\nut what&#39;s most interesting to me is your intuition that there is\n&gt; &gt; &gt; some=\r\n\n&gt; &gt; &gt; &gt; &gt; way to sidestep the tradeoff in combining indirect encodings wit=\r\nh\n&gt; &gt; &gt; &gt; &gt; target-based fitness functions.  That is, you suspect there may=\r\n\n&gt; &gt; &gt; exist an\n&gt; &gt; &gt; &gt; &gt; indirect encoding that can both elaborate regular=\r\nities\n&gt; &gt; &gt; compositionally\n&gt; &gt; &gt; &gt; &gt; over very many generations and also a=\r\nlmost deterministically satisfy\n&gt; &gt; &gt; an\n&gt; &gt; &gt; &gt; &gt; arbitrary target-based o=\r\nbjective.  I am convinced that is not the\n&gt; &gt; &gt; case\n&gt; &gt; &gt; &gt; &gt; (it would be=\r\n too good to be true), but you rightly point out that my\n&gt; &gt; &gt; &gt; &gt; position=\r\n is a hypothesis.   However, just as a thought experiment,\n&gt; &gt; &gt; can\n&gt; &gt; &gt; =\r\n&gt; &gt; you really imagine any neural network encoding (including DNA) that\n&gt; &gt;=\r\n &gt; &gt; &gt; would give you Einstein-level intelligence if the target was simply\n=\r\n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; score maximally on an IQ test?  It is plain to me that t=\r\nhe stepping\n&gt; &gt; &gt; &gt; &gt; stones to human level cannot be crossed in the presen=\r\nce of a\n&gt; &gt; &gt; &gt; &gt; target-based objective (or any one conceivable).  However=\r\n,\n&gt; &gt; &gt; &gt; &gt; interestingly, that does not mean that such a neural network do=\r\nes\n&gt; &gt; &gt; not\n&gt; &gt; &gt; &gt; &gt; exist in the search space.  It just means a target w=\r\non&#39;t get you\n&gt; &gt; &gt; there.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; 3) We apparently disagree on =\r\nwhether 6 is a big number (for nodes\n&gt; &gt; &gt; needed\n&gt; &gt; &gt; &gt; &gt; to represent fr=\r\nacture).  If you try to devise an encoding that\n&gt; &gt; &gt; &gt; &gt; represents fractu=\r\nre with fewer than that, my intuition is that you\n&gt; &gt; &gt; would\n&gt; &gt; &gt; &gt; &gt; be =\r\nsacrificing an enormous breadth of flexibility in the kinds of\n&gt; &gt; &gt; &gt; &gt; fr=\r\nacture (and patterns in general) that you can represent.  Think\n&gt; &gt; &gt; about=\r\n\n&gt; &gt; &gt; &gt; &gt; the number of &quot;degrees of freedom&quot; in fracture: it&#39;s not really\n=\r\n&gt; &gt; &gt; &gt; &gt; well-defined, but a single line of fracture has a lot of dimensio=\r\nns:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; -position\n&gt; &gt; &gt; &gt; &gt; -orientation\n&gt; &gt; &gt; &gt; &gt; -curvatu=\r\nre (which can be arbitrarily complex)\n&gt; &gt; &gt; &gt; &gt; -fracture gradient (that is=\r\n, one region can smoothly transition into\n&gt; &gt; &gt; &gt; &gt; another in a kind of in=\r\nterpolated transitional zone)\n&gt; &gt; &gt; &gt; &gt; -embedding (fracture can potentiall=\r\ny be hierarchical or regular,\n&gt; &gt; &gt; i.e.\n&gt; &gt; &gt; &gt; &gt; dependent on higher-leve=\r\nl containing regions)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; The idea that all of that can be =\r\nencoded in anything less than about\n&gt; &gt; &gt; 6\n&gt; &gt; &gt; &gt; &gt; simple functions seem=\r\ns optimistic.  Of course, if you are willing to\n&gt; &gt; &gt; &gt; &gt; sacrifice some of=\r\n those degrees of freedom, then you can get fewer\n&gt; &gt; &gt; &gt; &gt; nodes, but the =\r\nexquisite minutia of such patterns would be lost (and\n&gt; &gt; &gt; &gt; &gt; you&#39;d move =\r\nmore towards direct encoding, like the wavelets do).\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; By=\r\n the way, here are some cool examples of complicated kinds of\n&gt; &gt; &gt; fractur=\r\ne\n&gt; &gt; &gt; &gt; &gt; from Picbreeder (such as fractured periodic zones, but even mor=\r\ne\n&gt; &gt; &gt; complex\n&gt; &gt; &gt; &gt; &gt; than even that):\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Nontrivial c=\r\nolor patterns in each zone:\n&gt; &gt; &gt; &gt; &gt; http://picbreeder.org/search/showgeno=\r\nme.php?sid=3D11328\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Very complex brush-stroke =\r\npattern inside the apple vs. outside (the\n&gt; &gt; &gt; DNA\n&gt; &gt; &gt; &gt; &gt; for this one =\r\nis fascinating):\n&gt; &gt; &gt; &gt; &gt; http://picbreeder.org/search/showgenome.php?sid=\r\n=3D7109\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Fractured regions covering =\r\na distorted surface, giving a remarkable\n&gt; &gt; &gt; &gt; &gt; underlying curvature:\n&gt; =\r\n&gt; &gt; &gt; &gt; http://picbreeder.org/search/showgenome.php?sid=3D2684\n&gt; &gt; &gt; &gt; &gt;\n&gt; =\r\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; A color variant:\n&gt; &gt; &gt; http://picbreeder.org/search/showg=\r\nenome.php?sid=3D6652\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; When I see so many remar=\r\nkable examples like these on Picbreeder, the\n&gt; &gt; &gt; &gt; &gt; message to me is tha=\r\nt we have only scratched the surface of what\n&gt; &gt; &gt; CPPN\n&gt; &gt; &gt; &gt; &gt; encoding =\r\ncan teach us about representation.  That&#39;s why I think it&#39;s\n&gt; &gt; &gt; &gt; &gt; prema=\r\nture (in the face of such a treasure trove of evidence) to be\n&gt; &gt; &gt; &gt; &gt; wor=\r\nrying about whether we can represent some subcomponent of such\n&gt; &gt; &gt; &gt; &gt; pa=\r\ntterns with less than 6 nodes.  At present I&#39;m amazed they can be\n&gt; &gt; &gt; &gt; &gt;=\r\n represented at all, let alone with under 6 nodes.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Than=\r\nks very much for raising these issues in any case - it&#39;s a great\n&gt; &gt; &gt; &gt; &gt; =\r\ndebate to have about representation and search and goes to the heart\n&gt; &gt; &gt; =\r\nof\n&gt; &gt; &gt; &gt; &gt; the field of GDS/indirect encoding.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Best,\n=\r\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;s=\r\nhimonw&quot;  wrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Hi Ken,\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Tha=\r\nnks for your interesting and thought-provoking comments.  I&#39;ll\n&gt; &gt; &gt; give\n&gt;=\r\n &gt; &gt; &gt; &gt; some brief reactions here, and I hope we can have a productive\n&gt; &gt;=\r\n &gt; &gt; &gt; discussion about it at GECCO.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; 1) I won&#39;t com=\r\nment for now on the new experiments you&#39;ve been\n&gt; &gt; &gt; running\n&gt; &gt; &gt; &gt; &gt; bec=\r\nause the details are not available yet.  Instead, I will just\n&gt; &gt; &gt; comment=\r\n\n&gt; &gt; &gt; &gt; &gt; on the various walking gait domains, because the details of the\n=\r\n&gt; &gt; &gt; &gt; &gt; additional results you mentioned are in that case already availab=\r\nle,\n&gt; &gt; &gt; in\n&gt; &gt; &gt; &gt; &gt; newly published GECCO papers.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; FIrst of all, these are very cool results, and nice success\n&gt; &gt; &gt; stories=\r\n\n&gt; &gt; &gt; &gt; &gt; for HyperNEAT.  It&#39;s great to see that the GDS community is\n&gt; &gt; =\r\n&gt; continuing\n&gt; &gt; &gt; &gt; &gt; the push the envelope in terms of robot locomotion, =\r\nwhich seems to\n&gt; &gt; &gt; be\n&gt; &gt; &gt; &gt; &gt; emerging as a nice application for indire=\r\nct encodings.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; However, I would simply caution again=\r\nst placing all these\n&gt; &gt; &gt; variations\n&gt; &gt; &gt; &gt; &gt; on the walking gait task on=\r\n a one-dimensional spectrum of\n&gt; &gt; &gt; difficulty.\n&gt; &gt; &gt; &gt; &gt; In our paper, we=\r\n took the orignal walking gait task and made only\n&gt; &gt; &gt; one\n&gt; &gt; &gt; &gt; &gt; chang=\r\ne (increasing the mass of the torso) which clearly makes the\n&gt; &gt; &gt; task\n&gt; &gt;=\r\n &gt; &gt; &gt; harder.  In the papers Ken mentioned, there are other differences,\n&gt;=\r\n &gt; &gt; e.g.,\n&gt; &gt; &gt; &gt; &gt; the use of an SUPG encoding, the use of CTRNNs, the us=\r\ne of a\n&gt; &gt; &gt; different\n&gt; &gt; &gt; &gt; &gt; substrate topology, and varying the length=\r\n of the legs.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; It&#39;s completely legitimate to make th=\r\nese changes and they don&#39;t\n&gt; &gt; &gt; &gt; &gt; detract from the results at all.   But=\r\n they are confounding factors\n&gt; &gt; &gt; when\n&gt; &gt; &gt; &gt; &gt; it comes to comparing Hy=\r\nperNEAT&#39;s performance on walking gait tasks\n&gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; different di=\r\nfficulties.  Some of these changes may make the task\n&gt; &gt; &gt; harder\n&gt; &gt; &gt; &gt; &gt;=\r\n in some ways but other changes may make it easier in others ways,\n&gt; &gt; &gt; an=\r\nd so\n&gt; &gt; &gt; &gt; &gt; far we don&#39;t have experimental results that control for thes=\r\ne\n&gt; &gt; &gt; factors.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; 2) I hope to avoid a semantic deba=\r\nte about what is a\n&gt; &gt; &gt; &quot;target-based&quot;\n&gt; &gt; &gt; &gt; &gt; FF.  If you want to inclu=\r\nde what I was calling a &quot;regular&quot; FF in the\n&gt; &gt; &gt; &gt; &gt; scope of target-based=\r\n FFs, I won&#39;t object.  But my point is that,\n&gt; &gt; &gt; &gt; &gt; regardless of what y=\r\nou call them, there is an important difference\n&gt; &gt; &gt; &gt; &gt; between FFs that r=\r\nequire a single specific phenotype and FFs that\n&gt; &gt; &gt; &gt; &gt; require only that=\r\n some goal be achieved.  For the latter, there may\n&gt; &gt; &gt; be\n&gt; &gt; &gt; &gt; &gt; many =\r\nways to skin the cat, though in any interesting problem, good\n&gt; &gt; &gt; &gt; &gt; sol=\r\nutions are still quite rare.  The distinction is important\n&gt; &gt; &gt; because,\n&gt;=\r\n &gt; &gt; &gt; &gt; while the former category is arguably only of theoretical interest=\r\n,\n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; second category corresponds to what I consider the mo=\r\nst interesting\n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; &gt; important class of FFs, because these ar=\r\ne the FFs that naturally\n&gt; &gt; &gt; arise\n&gt; &gt; &gt; &gt; &gt; in a very large number of re=\r\nal-world optimization problems.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; So, using your term=\r\ninology, I agree it is reasonable to say\n&gt; &gt; &gt; &gt; &gt; HyperNEAT&#39;s difficulties=\r\n with fracture are probably limited to\n&gt; &gt; &gt; &gt; &gt; &quot;target-based&quot; FFs.  But f=\r\nor me, this is a potentially serious\n&gt; &gt; &gt; &gt; &gt; restriction, since target-ba=\r\nsed FFs include not just pathological\n&gt; &gt; &gt; FFs\n&gt; &gt; &gt; &gt; &gt; but a large class=\r\n of real-world FFs.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Regarding the wavelet method, I=\r\n would still definitely call this\n&gt; &gt; &gt; an\n&gt; &gt; &gt; &gt; &gt; indirect encoding, but=\r\n it is in some sense &quot;less indirect&quot; because\n&gt; &gt; &gt; it\n&gt; &gt; &gt; &gt; &gt; lacks the c=\r\nompositional functions of HyperNEAT. It&#39;s a perfectly\n&gt; &gt; &gt; &gt; &gt; reasonable =\r\nhypothesis that such compositionality is advantageous in\n&gt; &gt; &gt; some\n&gt; &gt; &gt; &gt;=\r\n &gt; ways.  However, if that&#39;s true, then we should be able to\n&gt; &gt; &gt; demonstr=\r\nate\n&gt; &gt; &gt; &gt; &gt; that by finding tasks where HyperNEAT outperforms the wavelet=\r\n method\n&gt; &gt; &gt; &gt; &gt; (FYI, in the extended analysis Thomas is conducting for h=\r\nis master&#39;s\n&gt; &gt; &gt; &gt; &gt; thesis, we have found one variation of the line-follo=\r\nwing task where\n&gt; &gt; &gt; &gt; &gt; this is the case).  So in that sense, the wavelet=\r\n method is a useful\n&gt; &gt; &gt; &gt; &gt; baseline, which is the whole reason we introd=\r\nuced it.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; 3) If it&#39;s true that it takes ~6 nodes to =\r\nrepresent fracture, then\n&gt; &gt; &gt; I\n&gt; &gt; &gt; &gt; &gt; think this a potentially importa=\r\nnt point.  On regular FFs, it could\n&gt; &gt; &gt; &gt; &gt; contribute to the difficulty =\r\nof discovering fracture, since\n&gt; &gt; &gt; &gt; &gt; representations that have only som=\r\ne of the necessary components may\n&gt; &gt; &gt; not\n&gt; &gt; &gt; &gt; &gt; be rewarded (I think =\r\nyou would call this &quot;deception&quot;).  In\n&gt; &gt; &gt; &gt; &gt; Picbreeder-like tasks, we a=\r\nlready see that fracture can evolve\n&gt; &gt; &gt; anyway,\n&gt; &gt; &gt; &gt; &gt; but this doesn&#39;=\r\nt mean it wouldn&#39;t do it even better if fracture\n&gt; &gt; &gt; required\n&gt; &gt; &gt; &gt; &gt; f=\r\newer nodes to represent.  If we think that the solutions to many\n&gt; &gt; &gt; &gt; &gt; =\r\ninteresting problems require fracture, then I think it&#39;s at least\n&gt; &gt; &gt; &gt; &gt;=\r\n possible that one could devise a better representation for such\n&gt; &gt; &gt; prob=\r\nlems\n&gt; &gt; &gt; &gt; &gt; than the CPPNs used in HyperNEAT.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; As=\r\n I understand it, your approach to dealing with &quot;regular&quot; FFs is\n&gt; &gt; &gt; to\n&gt;=\r\n &gt; &gt; &gt; &gt; reformulate them &quot;in a way that respects the need for phenotypic\n&gt;=\r\n &gt; &gt; &gt; &gt; diversity and open-endedness.&quot;  That&#39;s a very interesting approach=\r\n\n&gt; &gt; &gt; and I\n&gt; &gt; &gt; &gt; &gt; think it has a lot of merit, but I don&#39;t think it wi=\r\nll solve all our\n&gt; &gt; &gt; &gt; &gt; problems because it presupposes that such a refo=\r\nrmulation is\n&gt; &gt; &gt; possible\n&gt; &gt; &gt; &gt; &gt; (or that the prior knowledge it requi=\r\nres is available).  In some\n&gt; &gt; &gt; cases,\n&gt; &gt; &gt; &gt; &gt; I think we are just stuc=\r\nk with hard FFs and we need to develop\n&gt; &gt; &gt; better\n&gt; &gt; &gt; &gt; &gt; methods to de=\r\nal with them.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Regarding the idea that &quot;an unhappy a=\r\nnd unhealthy indirect\n&gt; &gt; &gt; encoding is\n&gt; &gt; &gt; &gt; &gt; one with only a strict ta=\r\nrget to which to aspire&quot;: this is a very\n&gt; &gt; &gt; &gt; &gt; intriguing hypothesis, b=\r\nut to me it is only a hypothesis.  I think\n&gt; &gt; &gt; it&#39;s\n&gt; &gt; &gt; &gt; &gt; true of exi=\r\nsting indirect encodings, but that for me does not in any\n&gt; &gt; &gt; way\n&gt; &gt; &gt; &gt;=\r\n &gt; rule out the possibility of developing a different indirect encoding\n&gt; &gt;=\r\n &gt; for\n&gt; &gt; &gt; &gt; &gt; which that is not true, and I think that&#39;s one thing we sh=\r\nould be\n&gt; &gt; &gt; &gt; &gt; working on.   One of the reasons that I&#39;m interested in i=\r\nndirect\n&gt; &gt; &gt; &gt; &gt; encodings is that I strongly believe this can be done.\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Cheers,\n&gt; &gt; &gt; &gt; &gt; &gt; Shimon\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}