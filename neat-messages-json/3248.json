{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":281645563,"authorName":"afcarl2","from":"&quot;afcarl2&quot; &lt;a.carl@...&gt;","profile":"afcarl2","replyTo":"LIST","senderId":"0mSWtjIweNeBQ4-woQyA7ilildDyXmbi1D3vnCHfUFEL1swk8BvOuW-rit6GT98q6AjtgNBVI5XyTu79SiVH3Ns","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Question Re: HyperNEAT","postDate":"1178123532","msgId":3248,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYxYWVlYytqN25nQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGYxOTVwcytoOGkxQGVHcm91cHMuY29tPg=="},"prevInTopic":3246,"nextInTopic":3250,"prevInTime":3247,"nextInTime":3249,"topicId":3234,"numMessagesInTopic":13,"msgSnippet":"Ken, Recursive Supervisor NEAT is reformulated as follows: (a) NEAT moves from namespace to supervisor class; (b) namespace is removed and all classes folded","rawEmail":"Return-Path: &lt;a.carl@...&gt;\r\nX-Sender: a.carl@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 47644 invoked from network); 2 May 2007 16:34:51 -0000\r\nReceived: from unknown (66.218.66.72)\n  by m50.grp.scd.yahoo.com with QMQP; 2 May 2007 16:34:51 -0000\r\nReceived: from unknown (HELO n18c.bullet.scd.yahoo.com) (66.218.67.206)\n  by mta14.grp.scd.yahoo.com with SMTP; 2 May 2007 16:34:50 -0000\r\nReceived: from [66.218.69.3] by n18.bullet.scd.yahoo.com with NNFMP; 02 May 2007 16:32:13 -0000\r\nReceived: from [66.218.66.83] by t3.bullet.scd.yahoo.com with NNFMP; 02 May 2007 16:32:12 -0000\r\nDate: Wed, 02 May 2007 16:32:12 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;f1aeec+j7ng@...&gt;\r\nIn-Reply-To: &lt;f195ps+h8i1@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;afcarl2&quot; &lt;a.carl@...&gt;\r\nSubject: Question Re: HyperNEAT\r\nX-Yahoo-Group-Post: member; u=281645563; y=yPgRnRkT9oGEfui5xP-Vk5tBRKk5sVvou2yYvGwGg6cedw\r\nX-Yahoo-Profile: afcarl2\r\n\r\nKen,\n\n   Recursive Supervisor NEAT is reformulated as follows:\n\n(a) NEAT mo=\r\nves from namespace to supervisor class;\n\n(b) namespace is removed and all c=\r\nlasses folded into population class;\n\n(c) params and associated code become=\r\ns a class, also member of \npopulation class;\n\n(d) definition of node expand=\r\ned to include ability to maintain \nmultiple unique inputs for hidden and ou=\r\ntput nodes;\n\n(e) definition of node expanded to include ability to maintain=\r\n \nmultiple unique outputs for input and hidden nodes;\n\n(f) definition of no=\r\nde expanded to include ability to maintain \nactivation function, network or=\r\n population;\n\n(g) activation and genome definition modified to address arbi=\r\ntrary \nrecursive network definition and topology;\n\n   Given the above, the =\r\ngenome definition of the CPPN, comprised of \nthe both the evolved substrate=\r\n and hypercube subnetworks, may be \nembedded as either a static substrate n=\r\network-in-a-node, an adaptive \nincremental evolvable network-in-a-node, sta=\r\ntic vote-taker population-\nin-a-node, or an adaptive incremental evolvable =\r\nvote-taker population-\nin-a-node. \n\n   The issue is the required infrastruc=\r\nture to achieve recursion and \nembedability. This combined with the need to=\r\n expand the functional \nvocabulary of the hypercube network are why (d) and=\r\n (e) above are \nimportant. Adequate means to supervise application of a ric=\r\nh and \ndiverse functional vocabulary, which can also include prior evolved =\r\n\nnetworks and/or populations, whether static or adaptive incremental \nevolv=\r\ned, can be developed. There is no reason to tie our hands with \nan inordina=\r\ntely small set of monolith activation functions that \nconveniently fit with=\r\nin the confines of one-input/one-output per node.\n\nThanks,\n   Andy Carl\n\n--=\r\n- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt; wrote:\n&gt;\n&gt; Andy=\r\n,\n&gt; \n&gt; I think all these ideas are valid and deserve to be explored.  \n&gt; Au=\r\ntomation is a potentially significant future direction so \n&gt; heuristics for=\r\n it are an interesting topic to pursue.  I think your \n&gt; suggestion about h=\r\nidden layers is reasonable and could work in a \nlot \n&gt; of cases.  \n&gt; \n&gt; Can=\r\n you expand on your idea about embedding?  How do you envision \n&gt; taking so=\r\nmething already evolved and embedding it into another \n&gt; network?  That sou=\r\nnds interesting (again because it can potentially \n&gt; exploit geometric rela=\r\ntionships already uncovered), but what are \nyou \n&gt; envisioning would be inv=\r\nolved?  Would the CPPN also need to \n&gt; be &quot;embedded&quot; in some sense into yet=\r\n another CPPN?  Or would you \njust \n&gt; assume that one substrate a static st=\r\nructure that is now part of \nsome \n&gt; larger substrate that is operated on b=\r\ny another CPPN?\n&gt; \n&gt; ken\n&gt; \n&gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.car=\r\nl@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Ken,\n&gt; &gt; \n&gt; &gt;    Two issues come to mind. The first is d=\r\negree of required user \n&gt; &gt; intervention in the determination of substrate =\r\ntopology. The \nsecond \n&gt; &gt; issue is embedability.\n&gt; &gt; \n&gt; &gt;    It seems reas=\r\nonable that the Hypercube network only has \nmeaning \n&gt; in \n&gt; &gt; the context =\r\nof the specific substrate employed during the \n&gt; &gt; evolutionary process. Th=\r\ne addition of hidden nodes to the \nsubstrate \n&gt; &gt; topology falls outside th=\r\ne scalability of a Hypercube network \n&gt; &gt; associated with an increase in re=\r\nsolution in the original \n&gt; dimensions \n&gt; &gt; of the substrate input and outp=\r\nut nodes.\n&gt; &gt; \n&gt; &gt;    Taking your position regarding attempting to cast the=\r\n problem \nin \n&gt; a \n&gt; &gt; manner that facilitates the geometric relationships =\r\n(I&#39;m using \nthe \n&gt; &gt; term geometric to represent the larger n-dimensional d=\r\nesign \nspace), \n&gt; &gt; it would appear that a reasonable approach would be to =\r\nlet the \n&gt; &gt; problem dictate the substrate input and output nodes, and then=\r\n \n&gt; simply \n&gt; &gt; duplicate the substrate input and output nodes as substrate=\r\n \nhidden \n&gt; &gt; nodes, and let the thresholding of weights in the Hypercube \n=\r\nnetwork \n&gt; &gt; separate the wheat from the chaff. If there are input-to-input=\r\n or \n&gt; &gt; output-to-output proximity relationships, they will emerge \nthroug=\r\nh \n&gt; &gt; evolution of the Hypercube network.\n&gt; &gt; \n&gt; &gt;    I&#39;m just trying to s=\r\nomehow automate the process and let the \nuser \n&gt; &gt; focus on problem definit=\r\nion (i.e. substrate input and output \n&gt; nodes). \n&gt; &gt; If this approach is ta=\r\nken, then the genome would need to include \n&gt; both \n&gt; &gt; the substrate and h=\r\nypercube topology definitions. \n&gt; &gt; \n&gt; &gt;    This leads into the second issu=\r\ne of embedability, or taking \nwhat \n&gt; &gt; you have evolved and have the abili=\r\nty to embed it into a higher \n&gt; level \n&gt; &gt; network. Which is another one of=\r\n the &quot;multiple reasons&quot; why I \n&gt; believe \n&gt; &gt; the ability to maintain multi=\r\nple unique inputs and outputs for a \n&gt; node \n&gt; &gt; in a network, substrate or=\r\n hypercube, is essential to the \n&gt; development \n&gt; &gt; of more &quot;brain-like&quot; ne=\r\ntworks.\n&gt; &gt; \n&gt; &gt; Thanks,\n&gt; &gt;    Andy Carl\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; --- In neat@yahoogr=\r\noups.com, &quot;Kenneth Stanley&quot; &lt;kstanley@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Andy,\n&gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; Sure, I understand it was just an example.  I went with the \n&gt; example \n=\r\n&gt; &gt; &gt; just for illustration, but let me give a shot at a more general \n&gt; &gt; =\r\n&gt; answer:\n&gt; &gt; &gt; \n&gt; &gt; &gt; I think the most general answer is that to the exten=\r\nt inputs \nand \n&gt; &gt; &gt; outputs really are apples and oranges there is still v=\r\naluable \n&gt; &gt; &gt; information that can be included with respect to how they ar=\r\ne \n&gt; &gt; &gt; separately arranged.  It is not only the relationship of inputs \n&gt;=\r\n to \n&gt; &gt; &gt; outputs, but the relations of inputs to each other (and outputs =\r\n\n&gt; to \n&gt; &gt; &gt; each other) that is potentially valuable.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; On th=\r\ne other hand, I don&#39;t think inputs and outputs are really \n&gt; &gt; often \n&gt; &gt; &gt;=\r\n going to truly be apples and oranges since both normally will \nbe \n&gt; at \n&gt;=\r\n &gt; &gt; least about the same world, i.e. what I see in the world vs. \nwhat \n&gt; =\r\nI \n&gt; &gt; &gt; do in the world; so there is an inherent conceptual \nrelationship =\r\n\n&gt; &gt; &gt; between them in most contexts.  While it is possible to pose a \n&gt; &gt; =\r\n&gt; problem in a way that removes some of that relationship (such \nas \n&gt; in \n=\r\n&gt; &gt; &gt; your example), it should normally be possible to recast the \n&gt; proble=\r\nm \n&gt; &gt; &gt; at least in part to restore it.  That is, there is more than \none =\r\n\n&gt; &gt; way \n&gt; &gt; &gt; to pose a problem from a geometric standpoint.  In general =\r\nif \nthe \n&gt; &gt; &gt; inputs and outputs are both about the same world, then some =\r\n\n&gt; method \n&gt; &gt; &gt; is probably available.\n&gt; &gt; &gt; \n&gt; &gt; &gt; At the same time, even=\r\n in cases where there is really no \n&gt; &gt; &gt; relationship whatsoever, there is=\r\n still utility in arranging \nthe \n&gt; &gt; &gt; inputs and outputs separately in wa=\r\nys that correspond to their \n&gt; &gt; &gt; respective geometric contexts.\n&gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; ken\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote=\r\n:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Ken,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;    The cited example modification o=\r\nf the paper geometry \nproblem \n&gt; &gt; &gt; was \n&gt; &gt; &gt; &gt; only to provide an instan=\r\nce in which the dimensionality of \nthe \n&gt; &gt; &gt; &gt; substrate inputs and output=\r\ns, as applied to the Hypercube \n&gt; inputs, \n&gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; stated in the =\r\noriginal attempted general characterization, \nwere \n&gt; &gt; of \n&gt; &gt; &gt; &gt; differi=\r\nng dimensionality.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;    I believe the jist of your other con=\r\ntemporaneous \n&gt; conversations \n&gt; &gt; &gt; is \n&gt; &gt; &gt; &gt; that additional a priori k=\r\nnowledge maybe interjected via the \n&gt; &gt; &gt; &gt; Hypercube inputs, since:\n&gt; &gt; &gt; =\r\n&gt; \n&gt; &gt; &gt; &gt; (a) this additional information is associated with the \n&gt; substr=\r\nate \n&gt; &gt; &gt; &gt; input/output node, though not expressly represented in same, \n=\r\nand\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; (b) this additional information is segregated to eithe=\r\nr \n&gt; &gt; the &quot;from&quot; \n&gt; &gt; &gt; &gt; or &quot;to&quot; nodes associated with the current substr=\r\nate link \nunder \n&gt; &gt; &gt; &gt; consideration.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;    I am only attem=\r\npting to clarify the seemly more general \n&gt; &gt; &gt; condition \n&gt; &gt; &gt; &gt; in which=\r\n the additional &quot;information&quot; associated with a \n&gt; substrate \n&gt; &gt; &gt; &gt; input=\r\n node is of different content and/or dimensionality than \n&gt; the \n&gt; &gt; &gt; &gt; ad=\r\nditional &quot;information&quot; associated with a substrate output \n&gt; node \n&gt; &gt; &gt; &gt; =\r\n(i.e. apples and oranges, not just oranges and oranges). The \n&gt; &gt; &gt; &gt; speci=\r\nfics of the cited modified example is irrelevant except \nin \n&gt; &gt; &gt; its \n&gt; &gt;=\r\n &gt; &gt; attempt to illustrate this point.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt;    =\r\nAndy Carl\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth S=\r\ntanley&quot; &lt;kstanley@&gt; \n&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Andy,\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; =\r\n&gt; There are still a lot of ways to configure the substrate \nfor \n&gt; &gt; &gt; such=\r\n a \n&gt; &gt; &gt; &gt; &gt; problem, so it&#39;s difficult to give a general answer.  For \n&gt; =\r\n&gt; &gt; example, \n&gt; &gt; &gt; &gt; &gt; you might have a single 2D input layer connecting t=\r\no a \nsingle \n&gt; &gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; &gt; node (yes/no); or you could have a m=\r\nultilayer 3D input \nfield \n&gt; &gt; &gt; (where \n&gt; &gt; &gt; &gt; &gt; each 2D layer is a type =\r\nof object) connecting to a 2D \noutput \n&gt; &gt; &gt; field \n&gt; &gt; &gt; &gt; &gt; (where each p=\r\nixel answers the question, is there overlap \n&gt; &gt; &gt; here?).  \n&gt; &gt; &gt; &gt; &gt; You =\r\nmight have a hidden layer, and you might not.  You \nmight \n&gt; &gt; &gt; allow \n&gt; &gt;=\r\n &gt; &gt; &gt; the hidden layer to express lateral connections, and you \n&gt; might \n&gt;=\r\n &gt; &gt; &gt; not.  \n&gt; &gt; &gt; &gt; &gt; You might have a 3D hidden layer or a 2D hidden lay=\r\ner.  You \n&gt; &gt; &gt; might \n&gt; &gt; &gt; &gt; &gt; embed everything in 3D, or you might map a=\r\n 3D coordinate to \na \n&gt; &gt; &gt; 2D, \n&gt; &gt; &gt; &gt; or \n&gt; &gt; &gt; &gt; &gt; a 2D or a 3D, etc..\n=\r\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; In each case, the implications are different about how=\r\n \n&gt; &gt; &gt; proximities \n&gt; &gt; &gt; &gt; &gt; are incorporated or expressed.  In some case=\r\ns it can be \n&gt; &gt; explicit \n&gt; &gt; &gt; &gt; &gt; within parts of the substrate; in some=\r\n cases it is \nimplicit.  \n&gt; &gt; &gt; For \n&gt; &gt; &gt; &gt; &gt; example, if there is only a =\r\nsingle output node and a 2D \nsheet \n&gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; inputs, then the CPPN=\r\n does not even need to take a target \n&gt; &gt; &gt; location \n&gt; &gt; &gt; &gt; &gt; as input, s=\r\nince there is only one target.  In that case you \n&gt; &gt; just \n&gt; &gt; &gt; &gt; &gt; query=\r\n for each input node what weight is coming out of it.  \n&gt; In \n&gt; &gt; &gt; such \n&gt;=\r\n &gt; &gt; &gt; &gt; a case, it is true that you do not explicitly provide a \n&gt; &gt; &gt; pro=\r\nximity \n&gt; &gt; &gt; &gt; &gt; input to the CPPN; however proximity is still implicit \nw=\r\nithin \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; representation since input nodes that are near =\r\neach other \nare \n&gt; &gt; &gt; also \n&gt; &gt; &gt; &gt; &gt; nearby in the function domain of the=\r\n CPPN, that is, it can \n&gt; use \n&gt; &gt; &gt; that \n&gt; &gt; &gt; &gt; &gt; nearness even though i=\r\nt is not explicitly provided as \ninput.  \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Please let m=\r\ne know if I didn&#39;t answer adequately and I can \n&gt; try \n&gt; &gt; &gt; to \n&gt; &gt; &gt; &gt; be=\r\n \n&gt; &gt; &gt; &gt; &gt; more specific, but I might need more detail on the precise \n&gt; &gt;=\r\n &gt; scenario \n&gt; &gt; &gt; &gt; &gt; you are considering.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; =\r\nwrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Ken,\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt;    One troubli=\r\nng &quot;detail&quot; is that of differences in \n&gt; &gt; &gt; &gt; dimensionality \n&gt; &gt; &gt; &gt; &gt; &gt; =\r\nbetween substrate inputs and outputs. In the examples \nused \n&gt; in \n&gt; &gt; &gt; th=\r\ne \n&gt; &gt; &gt; &gt; &gt; &gt; various papers, the dimensionality of the substrate input \n&gt;=\r\n and \n&gt; &gt; &gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; &gt; &gt; nodes, as applied to the Hypercube inpu=\r\nts, were identical \n&gt; &gt; &gt; (i.e. \n&gt; &gt; &gt; &gt; &gt; x_in, \n&gt; &gt; &gt; &gt; &gt; &gt; y_in, x_out, =\r\ny_out). This simplifies the concept of \n&gt; distance. \n&gt; &gt; &gt; But \n&gt; &gt; &gt; &gt; &gt; t=\r\nhe \n&gt; &gt; &gt; &gt; &gt; &gt; problem could just as easily have been: Do the two \nsquares=\r\n \n&gt; on \n&gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; visual field overlap? (yes/no). In this case=\r\n, \n&gt; dimensionality \n&gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; substrate input a=\r\nnd output nodes, as applied to the \n&gt; Hypercube \n&gt; &gt; &gt; &gt; &gt; inputs, \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; have differing dimensionality, even though the answer is \n&gt; &gt; &gt; strong=\r\nly \n&gt; &gt; &gt; &gt; &gt; &gt; dependent on proximity in the input visual field. Any \n&gt; &gt; =\r\n&gt; experience \n&gt; &gt; &gt; &gt; &gt; or \n&gt; &gt; &gt; &gt; &gt; &gt; comments on this seemly more common=\r\n general condition?\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt; &gt;    Andy Ca=\r\nrl \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoogroups.com, &quot;Kenneth Stanley&quot;=\r\n \n&lt;kstanley@&gt; \n&gt; &gt; &gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Andy, I&#39;d say this =\r\nis a about right.  I elaborate a bit \n&gt; &gt; &gt; below \n&gt; &gt; &gt; &gt; &gt; each \n&gt; &gt; &gt; &gt; =\r\n&gt; &gt; &gt; part of your question:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; --- In neat@yahoo=\r\ngroups.com, &quot;afcarl2&quot; &lt;a.carl@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Jaso=\r\nn or Ken,\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;    I am attempting to understand=\r\n the nature of inputs \n& \n&gt; &gt; &gt; &gt; &gt; outputs \n&gt; &gt; &gt; &gt; &gt; &gt; as \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; applied to both the Hypercube and substrate networks, \n&gt; &gt; &gt; without \n&gt; &gt;=\r\n &gt; &gt; &gt; &gt; being \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; limited to the geometric nature of the visu=\r\nal-based \n&gt; &gt; &gt; examples. \n&gt; &gt; &gt; &gt; &gt; The \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; examples provided=\r\n were helpful, but I am striving for \na \n&gt; &gt; &gt; more \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; general =\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; guideline for application to more general problems.\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;    Would it be correct to say that:\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (a) Substrate Network: Inputs & Outputs identified as =\r\n\n&gt; &gt; &gt; typical \n&gt; &gt; &gt; &gt; &gt; to \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; application of conventional N=\r\nEAT to a problem of \n&gt; interest;\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; =\r\n&gt; &gt; This statement is correct although you might do things \n&gt; that \n&gt; &gt; &gt; y=\r\nou \n&gt; &gt; &gt; &gt; &gt; &gt; would \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; avoid doing in conventional NEAT becau=\r\nse HyperNEAT can \n&gt; deal \n&gt; &gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; &gt; so \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; many mo=\r\nre inputs and outputs.  So you might for example \n&gt; &gt; &gt; output \n&gt; &gt; &gt; &gt; a \n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; high \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; resolution representation of your possible =\r\ndecisions, \n&gt; which \n&gt; &gt; &gt; is \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; something you normally wouldn&#39;=\r\nt do in regular NEAT.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; (b) Hypercube Network:=\r\n (i) Inputs: Other \n&gt; &gt; &gt; &gt; &gt; descriptors/parameters \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; (i.e. \n=\r\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; geometric coordinates being a subset thereof), \n&gt; associate=\r\nd \n&gt; &gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; &gt; a \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; given \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; substrat=\r\ne network node (i.e. like a timestamp \n&gt; associated \n&gt; &gt; &gt; with \n&gt; &gt; &gt; &gt; &gt; =\r\na \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; coordinate point comprising a trajectory), mutually \n&gt; &gt;=\r\n &gt; exclusive \n&gt; &gt; &gt; &gt; &gt; of \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; descriptor/p=\r\narameter expressly identified in the \n&gt; &gt; substrate \n&gt; &gt; &gt; &gt; &gt; node, \n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; &gt; each \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; being collected together and collectively id=\r\nentified \nas \n&gt; &gt; &gt; &gt; either \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; a &quot;from&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; or &quot;t=\r\no&quot; terminator of a link between any two \nsubstrate \n&gt; &gt; &gt; nodes; \n&gt; &gt; &gt; &gt; &gt;=\r\n and \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; (ii) \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Output: Weight of link between th=\r\ne currently \n&gt; &gt; &gt; &gt; identified &quot;from&quot; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; and &quot;to&quot; \n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; substrate nodes.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; I think=\r\n this characterizes it well, although there is \n&gt; even \n&gt; &gt; &gt; more \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; flexibility.  You can for example use additional \noutputs \n&gt; on \n&gt; &gt;=\r\n &gt; the \n&gt; &gt; &gt; &gt; &gt; &gt; CPPN \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; to represent additional attributes =\r\nof links and/or \n&gt; nodes.  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; The timestamp idea=\r\n is interesting- if I understand \n&gt; &gt; correctly \n&gt; &gt; &gt; it \n&gt; &gt; &gt; &gt; &gt; &gt; woul=\r\nd \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; cause the network to change over time in a \ndeterministic =\r\n\n&gt; &gt; &gt; way.  \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; Although maybe I&#39;m misunderstanding.  But certa=\r\ninly \n&gt; things \n&gt; &gt; &gt; like \n&gt; &gt; &gt; &gt; &gt; &gt; that \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; are possible.  =\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; It&#39;s difficult to write an accurate general d=\r\nescription \n&gt; of \n&gt; &gt; &gt; &gt; &gt; exactly \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; what goes in and comes o=\r\nut of the CPPN at this point \n&gt; &gt; because \n&gt; &gt; &gt; I \n&gt; &gt; &gt; &gt; &gt; have \n&gt; &gt; &gt; &gt;=\r\n &gt; &gt; &gt; no doubt that at this early stage that new ideas are \n&gt; going \n&gt; &gt; &gt;=\r\n to \n&gt; &gt; &gt; &gt; &gt; &gt; broaden \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; the possibilities beyond what I am =\r\ncurrently aware \nof.   \n&gt; &gt; But \n&gt; &gt; &gt; &gt; &gt; what \n&gt; &gt; &gt; &gt; &gt; &gt; you \n&gt; &gt; &gt; &gt; &gt;=\r\n &gt; &gt; said captures it pretty well for now.\n&gt; &gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; &gt; ken=\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}