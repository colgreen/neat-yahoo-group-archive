{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":344770077,"authorName":"Colin Green","from":"Colin Green &lt;colin.green1@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"ONps5dCUlfDj386127e8ixfzSYv5NGEg8PEhS0NlEZN_DsNHc7QL7Bwk80XgiF7E2gbmAASK5LHJasCwoqdYOgvKNL5oGFptgI8L","spamInfo":{"isSpam":false,"reason":"12"},"subject":"A fresh look at GPUs and OpenCL","postDate":"1372850816","msgId":6161,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PENBRTBNK1ljelZVd3hDVXZGOGRVbk1qYl9TTHk5K19CdVNCal9IdUJrSkdqaVJTczc2QUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":0,"nextInTopic":6162,"prevInTime":6160,"nextInTime":6162,"topicId":6161,"numMessagesInTopic":7,"msgSnippet":"Hi all, I know the topic of GPU use has come up before but there have been a few recent developments in the GPU world so I thought it would be interesting to","rawEmail":"Return-Path: &lt;colin.green1@...&gt;\r\nX-Sender: colin.green1@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 91110 invoked by uid 102); 3 Jul 2013 11:27:36 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m9.grp.bf1.yahoo.com with SMTP; 3 Jul 2013 11:27:36 -0000\r\nX-Received: (qmail 17960 invoked from network); 3 Jul 2013 11:27:36 -0000\r\nX-Received: from unknown (HELO mail-vb0-f42.google.com) (209.85.212.42)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 3 Jul 2013 11:27:36 -0000\r\nX-Received: by mail-vb0-f42.google.com with SMTP id i3so8887vbh.1\n        for &lt;neat@yahoogroups.com&gt;; Wed, 03 Jul 2013 04:27:36 -0700 (PDT)\r\nX-Received: by 10.58.227.198 with SMTP id sc6mr122550vec.59.1372850856512;\n Wed, 03 Jul 2013 04:27:36 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.58.222.168 with HTTP; Wed, 3 Jul 2013 04:26:56 -0700 (PDT)\r\nDate: Wed, 3 Jul 2013 12:26:56 +0100\r\nMessage-ID: &lt;CAE0M+YczVUwxCUvF8dUnMjb_SLy9+_BuSBj_HuBkJGjiRSs76A@...&gt;\r\nTo: neat@yahoogroups.com\r\nContent-Type: text/plain; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Colin Green &lt;colin.green1@...&gt;\r\nSubject: A fresh look at GPUs and OpenCL\r\nX-Yahoo-Group-Post: member; u=344770077; y=7vSFU6dqB97y8-OblhY2K5bu_36Rzas-p6kYutmXvdHhJCx1UazL\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nHi all,\n\nI know the topic of GPU use has come up before but there have been=\r\n a\nfew recent developments in the GPU world so I thought it would be\nintere=\r\nsting to review the current situation.\n\n[CUDA]\nCUDA has been mentioned prev=\r\niously and I think Ken Lloyd did some work\nusing CUDA in NEAT, but AFAIK no=\r\nne of the NEAT implementations freely\navailable are using GPUs at all (plea=\r\nse correct me if I&#39;m wrong). CUDA\nwas notable as being the first platform t=\r\no provide a general computing\nplatform/layer over GPUs rather than being gr=\r\naphics acceleration\nspecific. As such it greatly lowered the difficulty of =\r\nusing GPUs for\ngeneral computing. A notable point is that CUDA is specific =\r\nto NVIDIA\nGPUs.\n\n[OpenCL]\nOpenCL is a more recent development that aims to =\r\nprovide an openly\ndefined GPGPU style platform. OpenCL then is a layer of a=\r\nbstraction\nfrom the hardware that allows GPGPU style code to be written\nind=\r\nependently of any specific h/w and to be executed on any h/w\nsuporting Open=\r\nCL. At this time there is already a lot of support, e.g.\nthere is support f=\r\nor NVIDIA and ATI/AMD GPUs, IBM&#39;s Cell processor\nbased accelerator &#39;blades&#39;=\r\n, and you can also run OpenCL code on an\n&#39;normal&#39; Intel multicore CPU (whic=\r\nh may be more useful for\ntesting/development than acceleration?).\n\nThe main=\r\n issue with OpenCL is that the it is an abstraction over\ndiverse hardware, =\r\nthus although a program may run it may not run very\nfast without specific k=\r\nnowledge of the underlying h/w and what it&#39;s\nstrengths and weaknesses are. =\r\n E.g. if code accesses more RAM that is\navailable to each processor then Op=\r\nenCL will simply compile in\ninstructions to copy data between local and mai=\r\nn RAM thus eliminating\nthe perf gain of using local RAM. OpenCL does provid=\r\ne for querying the\nunderlying h/w for some of these factors, so you could i=\r\nn principle\nperform a set of checks and report that the h/w isn&#39;t suitable =\r\nfor\nyour program, or maybe even dynamically adjust the program code based\no=\r\nn reported parameters.\n\nOn the whole though I see OpenCL as a positive deve=\r\nlopment and\nsomething the NEAT community can potentially benefit from. It i=\r\ns still\na relatively young platform and therefore may present some challeng=\r\nes\nto code to as it develops, but I think it&#39;s mature and stable enough\nto =\r\nconsider experimenting with now.\n\n\n[Current GPU h/w]\nAs a ballpark estimate=\r\n of the sort of performance gains a GPGPU can\ngive us, ATI/AMDs current fla=\r\ngship card (Radeon 7970) has a peak\nthroughput of about 3.8 TFlops, compare=\r\nd to 100 GFlops for a 4th\ngeneration quad core Intel i7. So on paper we&#39;re =\r\nlooking at a possible\n38x speedup compared to top flight CPUs. However, Ope=\r\nnCL does support\nutilising mutliple GPUs, e.g. in the Bitcoin mining world =\r\nit&#39;s typical\nto have 4 and sometimes 5 GPUs in one system (using PCI &#39;riser=\r\n&#39; cables\nto distance the GPUs from the motherboard). So for a relatively mo=\r\ndest\ninvestment you could be looking at a possible 100x speedup compared to=\r\n\ncurrent best CPUs.\n\n\n[NEAT and GPUs]\nMy instinct here is to modify current=\r\n NEAT code to report stats on how\nmuch time proportionally is being spent i=\r\nn each stage of the NEAT\nalgorithm and to target the code that takes up the=\r\n most time, this\nwill be different across problem domains and also for NEAT=\r\n versus\nHyperNEAT.\n\nCertainly if a problem domain is known to be CPU heavy =\r\n(e.g. uses a\nphysics simulation) then it&#39;s probably a no-brainer to use Ope=\r\nnCL for\nthat in isolation from the rest of the NEAT algorithm. For NEAT its=\r\nelf\nI&#39;ve observed slowdown as ANNs grow in size and this is presumably\nmost=\r\nly due to time to decode and/or &#39;run&#39; the ANNs, and this is of\ncourse a gre=\r\nater problem in HyperNEAT where the decode stage consists\nof a NEAT decode =\r\nand ANN activation. So there might be some scope for\nusing OpenCL there. On=\r\ne can envisage multiple GPUs where one may be\ndedicated to problem domain p=\r\nhysics, one to ANN activation and another\nto ANN genome decoding (say).\n\n\n[=\r\nTypical GPU Architecture]\nFinally I&#39;m going to briefly describe the archite=\r\ncture of the Radeon\n7970 to give an idea of what it is capable of.\n[Mainly =\r\ntaken from\nhttp://www.techradar.com/reviews/pc-mac/pc-components/graphics-c=\r\nards/amd-radeon-hd-7970-1049734/review/2]\n\nThe 7970 has:\n\n32 x Compute Unit=\r\ns (CUs). These are completely independent of each\nother. If you have 2x GPU=\r\ns then OpenCL will see (I think) a block of\n64 compute units, hence in some=\r\n cases code can be accelerated just by\nadding GPUs. Each CU has:\n\n4 x Vecto=\r\nr Units (VUs). And each VU has:\n16 x Unified shaders (unified here just mea=\r\nns they are no longer\nspecific to a task, e.g. pixel or vector shader, they=\r\n are general\npurpose processors)\n\nSo in total there are 32 x 4 x 16 =3D  20=\r\n48 unified shaders.\n\nEach CU has 64kB of local RAM that all of the VUs can =\r\naccess\n(typically for reading shared state data I would guess). In addition=\r\n\neach VU has it&#39;s own 64 kB of RAM  (note. you would typically control\nwhat=\r\n&#39;s in these local memories in code, that is, it&#39;s not a passive\nCPU cache).=\r\n A vector unit is basically a SIMD processor, there is one\nset of instructi=\r\nons that are executed against all 16 shaders (so e.g.\nyou can &#39;shade&#39; 16 pi=\r\nxels at a time). So each of the 128 vector units\ncan execute its own instru=\r\nctions, and in turn those instructions are\noperating on 16 shaders. A shade=\r\nr then consists of some minimal state\ndata specific to it and the data it i=\r\ns operating on, and also\nexecution units for performing arithmetic, etc.\n\nA=\r\nn interesting thing about vector units is that conditional branches\nare all=\r\nowed in OpenCL, that is, you can have some shaders executing a\ndifferent pa=\r\nth despite there being only one set of instructions and\none instruction poi=\r\nnter. However this is merely a trick, if VU code\ncontains a branch then bot=\r\nh branches are executed for all shaders and\nthe shaders are assigned the co=\r\nrrect final result based on which\nbranch they should have followed. Hence i=\r\nt&#39;s advisable to avoid\nbranches, but it&#39;s a nice feature to have available =\r\nso long as you\ndon&#39;t abuse it.\n\nFor more info see:\n   [From Shader Code to =\r\na Tera=EF=AC=82op: How Shader Cores Work, Kayvon\nFatahalian, Stanford Unive=\r\nrsity]\n   [http://s08.idav.ucdavis.edu/fatahalian-gpu-architecture.pdf]\n\nTh=\r\nere&#39;s obviously a heck of a lot more to this subject than I&#39;ve\ndescribed bu=\r\nt I thought this might be a reasonably good intro to\ncurrent possibilities =\r\naround GPU use in NEAT.\n\nColin\n\n"}}