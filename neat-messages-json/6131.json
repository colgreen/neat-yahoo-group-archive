{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":130984297,"authorName":"joel278","from":"&quot;joel278&quot; &lt;lehman.154@...&gt;","profile":"joel278","replyTo":"LIST","senderId":"tif6Cp8aTeYJOKQqEDYImxWquDZVEHGNYx73gB6qfoITPQ6fv2_BNuWwn8b9Z3EbvLa7cSwlqMKQBDeyn9wWFJRX7R2D","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: Novelty search in a generational GA","postDate":"1370789470","msgId":6131,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtwMjRvdSszY3ZpQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtvdm10YStkbjVrQGVHcm91cHMuY29tPg=="},"prevInTopic":6130,"nextInTopic":6132,"prevInTime":6130,"nextInTime":6132,"topicId":6129,"numMessagesInTopic":9,"msgSnippet":"Oliver, Also related to the simplifying the novelty search algorithm is the idea of adding to the archive probabilistically instead of using a threshold. That","rawEmail":"Return-Path: &lt;lehman.154@...&gt;\r\nX-Sender: lehman.154@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 75780 invoked by uid 102); 9 Jun 2013 14:51:11 -0000\r\nX-Received: from unknown (HELO mtaq5.grp.bf1.yahoo.com) (10.193.84.36)\n  by m11.grp.bf1.yahoo.com with SMTP; 9 Jun 2013 14:51:11 -0000\r\nX-Received: (qmail 22887 invoked from network); 9 Jun 2013 14:51:11 -0000\r\nX-Received: from unknown (HELO ng5-ip3.bullet.mail.ne1.yahoo.com) (98.138.215.146)\n  by mtaq5.grp.bf1.yahoo.com with SMTP; 9 Jun 2013 14:51:11 -0000\r\nX-Received: from [98.138.217.176] by ng5.bullet.mail.ne1.yahoo.com with NNFMP; 09 Jun 2013 14:51:11 -0000\r\nX-Received: from [10.193.94.106] by tg1.bullet.mail.ne1.yahoo.com with NNFMP; 09 Jun 2013 14:51:11 -0000\r\nDate: Sun, 09 Jun 2013 14:51:10 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kp24ou+3cvi@...&gt;\r\nIn-Reply-To: &lt;kovmta+dn5k@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;joel278&quot; &lt;lehman.154@...&gt;\r\nSubject: Re: Novelty search in a generational GA\r\nX-Yahoo-Group-Post: member; u=130984297; y=2dtbgh5wyDufR1SkqfZi7zdW-s4CmlUN9CDFgVSsMXwdqQu48UFz\r\nX-Yahoo-Profile: joel278\r\n\r\nOliver,\n\nAlso related to the simplifying the novelty search algorithm is th=\r\ne idea of adding to the archive probabilistically instead of using a thresh=\r\nold. That is, in the original C++ implementation individuals are added to t=\r\nhe archive when their novelty is greater than an experimenter-specified thr=\r\neshold (which an also vary dynamically). However, in new implementations I&#39;=\r\nve tended to remove the threshold  and instead add any new individual to th=\r\ne archive (at the end of a generation) with fixed probability (e.g. 0.05%).=\r\n \n\nNote that this approach is also described in a paper applying novelty se=\r\narch to genetic programming (http://eplex.cs.ucf.edu/publications/2010/lehm=\r\nan-gecco10b).\n\nOne nice thing about this approach is that it is easier to u=\r\nnderstand how changing the probability will influence archive growth than t=\r\nhe novelty threshold. That is, the expectation of growth per generation is =\r\njust the probability of addition (which is a parameter to be chosen by the =\r\nexperimenter) times the population size. In contrast, the novelty threshold=\r\n is specified in terms of a more abstract quantity (i.e. novelty scores), a=\r\nnd while this threshold can also be adjusted dynamically to add one or two =\r\nindividuals per generation on average, it can add some complication to the =\r\nimplementation.\n\nAdding to the archive probabilistically (i.e. each new ind=\r\nividual has some fixed chance of being added to the archive regardless of h=\r\now novel they are) may also be more principled than the threshold method. I=\r\nn effect, adding probabilistically samples uniformly where search has been =\r\nand creates an accumulating force away from behaviors search has been spend=\r\ning most effort exploring. In contrast, adding new individuals to the archi=\r\nve when they are greater than the threshold tends to create a small repulsi=\r\nve force exactly where things are most novel. Of course, over time it also =\r\napproximates where search has been, but the probabilistic approach does so =\r\nmore directly.\n\nIn any case, I thought I&#39;d mention this slightly nuanced im=\r\nplementation detail because it also relates to interactions between the arc=\r\nhive and population, and is perhaps a simpler and more principled way to ac=\r\ncumulate an archive of past behaviors to encourage search to diverge from b=\r\nehaviors explored in the past.\n\nBest,\nJoel\n\n--- In neat@yahoogroups.com, &quot;j=\r\noel278&quot; &lt;lehman.154@...&gt; wrote:\n&gt;\n&gt; \n&gt; \n&gt; Hi Oliver,\n&gt; \n&gt; Thanks for raisin=\r\ng this interesting question relating to pairing novelty search with generat=\r\nional evolutionary algorithms. Whether novelty search is performed generati=\r\nonally or in a steady-state algorithm, I think that taking the population i=\r\nnto account in some way or another when calculating the novelty of new indi=\r\nviduals can often be very helpful.\n&gt; \n&gt; In particular, the motivation for m=\r\neasuring novelty against the current population as well as the archive is t=\r\no take all available information into account. While it is true that the ar=\r\nchive alone provides some information about where in the space of behaviors=\r\n has *previously* been searched, the population gives additional informatio=\r\nn about where is *currently* being searched.\n&gt; \n&gt; In other words, it is lik=\r\nely desirable to have the population itself spread over the space of previo=\r\nusly unexplored behaviors. If only the archive is taken into account, it is=\r\n possible that the population itself may converge to searching one novel ar=\r\nea of the behavior space (where there are few archive points), which could =\r\npotentially lead down blind alleys. When the population is taken into accou=\r\nnt there is some repulsive force within the population to maintain diversit=\r\ny and explore different novel areas of the behavior space -- which may in g=\r\neneral benefit exploring the overall search for novelty.\n&gt; \n&gt; That said, th=\r\ne simpler algorithm you suggest is interesting. It seems a bit more greedy =\r\nin nature and may work well sometimes in practice. One slightly strange thi=\r\nng about it is that the evaluation order of individuals within a generation=\r\n may matter; that is, the novelty of an individual evaluated later in the p=\r\nopulation may be affected by archive additions earlier. I am not sure if th=\r\nat is bad or good. \n&gt; \n&gt; In a generational novelty search in particular, it=\r\n may be wise to reduce selection pressure or increase the number of nearest=\r\n neighbors considered in calculated novelty. The reason is that unlike in t=\r\nhe steady state variation, where the novelty of an individual will smoothly=\r\n vary over time (as individuals are replaced individually), in a generation=\r\nal model, the novelty of an individual can change abruptly over generations=\r\n (what is novel one generation may not be novel even the next generation). =\r\nTo provide a smoother gradient, it may thus be important to reduce novelty =\r\npressure (e.g. by decreasing the greediness of the search through the survi=\r\nval threshold or however you are applying pressure, or by increasing the si=\r\nze of the neighborhood considered for calculating novelty, which may also s=\r\nmooth novelty calculations).\n&gt; \n&gt; I hope you find this response informative=\r\n, while novelty search is viable whether it is generational or steady-state=\r\n, there are some factors that may increase its performance when specializin=\r\ng the algorithm to generational or steady-state evolutionary algorithms in =\r\nparticular.\n&gt; \n&gt; Best,\n&gt; Joel\n&gt; \n&gt; --- In neat@yahoogroups.com, Oliver Cole=\r\nman &lt;oliver.coleman@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi all,\n&gt; &gt; \n&gt; &gt; I have a question abo=\r\nut implementing novelty search in a generational GA.\n&gt; &gt; In &quot;Abandoning Obj=\r\nectives: Evolution through the\n&gt; &gt; Search for Novelty Alone&quot; (Lehman and St=\r\nanley, 2011, pg 13), it suggests\n&gt; &gt; that it&#39;s necessary (or at least a goo=\r\nd idea) to determine the novelty of\n&gt; &gt; an individual against the archive a=\r\nnd the (entire) current population.\n&gt; &gt; \n&gt; &gt; I&#39;m wondering why this is bett=\r\ner than the following approach:\n&gt; &gt; for (individual I in population)\n&gt; &gt;   =\r\nN =3D novelty of I measured against archive\n&gt; &gt;   if (N &gt; threshold)\n&gt; &gt;   =\r\n  add I to archive\n&gt; &gt; \n&gt; &gt; That is, if you iterate through the population,=\r\n adding individuals to the\n&gt; &gt; archive as you go, then is this equivalent (=\r\nor a reasonable approximation)\n&gt; &gt; to checking each individual against the =\r\nentire population and the archive?\n&gt; &gt; If not, why not?\n&gt; &gt; \n&gt; &gt; Thanks in =\r\nadvance for any assistance! :)\n&gt; &gt; \n&gt; &gt; Cheers,\n&gt; &gt; Oliver\n&gt; &gt; \n&gt; &gt; T: 0421=\r\n 972 953 | E: oliver.coleman@ | W: http://ojcoleman.com\n&gt; &gt;\n&gt;\n\n\n"}}