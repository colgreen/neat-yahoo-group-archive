{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":102323271,"authorName":"lior_fainshil","from":"&quot;lior_fainshil&quot; &lt;lior_fainshil@...&gt;","profile":"lior_fainshil","replyTo":"LIST","senderId":"fDJcnecAVhbkteyPhw06WItLtEvtcoGuN5qz0tlbHjqc6bM9-FxHC42TosrHPeEpX9_NwrFyjf06IaTBJFksVkyDshRj4iUkyRk4v_ulB44","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Novelty Search for Classification/Regression problems","postDate":"1271808577","msgId":5211,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGhxbGZvMStqN3FpQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":5212,"prevInTime":5210,"nextInTime":5212,"topicId":5211,"numMessagesInTopic":3,"msgSnippet":"I find the idea of novelty search very interesting for the reasons described in the articles, but also for another very different reason. Think what happens","rawEmail":"Return-Path: &lt;lior_fainshil@...&gt;\r\nX-Sender: lior_fainshil@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 94421 invoked from network); 21 Apr 2010 00:12:57 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m13.grp.re1.yahoo.com with QMQP; 21 Apr 2010 00:12:57 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta3.grp.sp2.yahoo.com with SMTP; 21 Apr 2010 00:12:57 -0000\r\nX-Received: from [69.147.65.171] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 21 Apr 2010 00:09:39 -0000\r\nX-Received: from [98.137.34.184] by t13.bullet.mail.sp1.yahoo.com with NNFMP; 21 Apr 2010 00:09:39 -0000\r\nDate: Wed, 21 Apr 2010 00:09:37 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;hqlfo1+j7qi@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;4-2591095099-0958753189=:9&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;lior_fainshil&quot; &lt;lior_fainshil@...&gt;\r\nSubject: Novelty Search for Classification/Regression problems\r\nX-Yahoo-Group-Post: member; u=102323271; y=qAIQiLPyx-tO9TQ2WLWEBrrNfFOllIi8OQyodUlqGW07wiM-cyLrKQ\r\nX-Yahoo-Profile: lior_fainshil\r\n\r\n\r\n--4-2591095099-0958753189=:9\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nI find the idea of novelty search very interesting for the reasons\ndescribe=\r\nd in the articles, but also for another very different reason.\nThink what h=\r\nappens when novelty search is used to design a classifier.\nA notorious prob=\r\nlem in classification/regression problems is that of\noverfitting. That is w=\r\nhen the classifier learns the peculiarities of the\ntraining set instead of =\r\nthe underlying rule and its good performance on\nthe training set fails to t=\r\nransfer to new examples.\nIt can be mathematically shown that overfitting ca=\r\nn be minimized by\nminimizing the amount of information needed to encode the=\r\n classification\nrule. If the information complexity of the rule is consider=\r\nably lower\nthan the information complexity of the training set, then the\npr=\r\nobability of overfitting goes to zero.\nImagine we use novelty search to fin=\r\nd a classification rule. For our\nanalysis we will assume that we use a pseu=\r\ndo-random number generator\nwith a known seed(This should not affect the per=\r\nformance). We will run\nnovelty search until we find a classifier that reach=\r\nes the desired\nperformance on the training set. This will be the classifier=\r\n we use. One\nway to identify this classifier is by n, its index number in t=\r\nhe series\nof classifiers tested. We can recreate the classifier by running =\r\nthe\nsearch from the start. (We can count only classifiers with different\ncl=\r\nassifications). In such case the information content of the classifier\nwill=\r\n be log(n)+O(log(log(n)). If this number is small compared to the\ninformati=\r\non content of the training set, then we can be assured that we\navoided over=\r\nfitting.\n\nThe same logic can be applied to any random search. It does not w=\r\nork\nhowever with a classification performance directed search since in such=\r\n\na search the classifier can not be recreated from its number in the\nenumer=\r\nation alone. To get the classifier from its number, we also need\nthe traini=\r\nng set. This makes the overfitting bound meaningless.\n\nTogether with the ot=\r\nher benefits of novelty search this seems almost too\ngood to be true. There=\r\n are some points which are not clear to me\nhowever. One is comparison to ra=\r\nndom search. Random search possesses the\nsame property of overfitting avoid=\r\nance as well as an additional\noptimality property. In a random search it is=\r\n relatively straightforward\nto order the hypotheses by our interpretation o=\r\nf their complexity - we\ncan perfectly incorporate Occam&#39;s Razor. This doesn=\r\n&#39;t seem possible to\nthe same degree in novelty search. A random(actually br=\r\nute force) search\nis used for the theoretically optimal Solomonoff Inductio=\r\nn(which\nunfortunately is far from optimal in computation time). People actu=\r\nally\nmanaged to use a brute force search successfully even to develop neura=\r\nl\nnetworks\n&lt;http://agi-conf.org/2010/wp-content/uploads/2009/06/paper_57.pd=\r\nf&gt; . So\nI would be careful about throwing away random search.\n\nI actually t=\r\nried a kind of Novely Search with NEAT on the Xor problem.\nIt did not work =\r\nvery well. I know that xor is not a very good example\nfor this. I am thinki=\r\nng about trying it on more interesting problems.\n\nWhat are your thoughts on=\r\n this?\n\r\n--4-2591095099-0958753189=:9\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nI find the idea of novelty search very interesting for the reasons describe=\r\nd in the articles, but also for another very different reason.&lt;br&gt;Think wha=\r\nt happens when novelty search is used to design a classifier.&lt;br&gt;A notoriou=\r\ns problem in classification/regression problems is that of overfitting. Tha=\r\nt is when the classifier learns the peculiarities of the training set inste=\r\nad of the underlying rule and its good performance on the training set fail=\r\ns to transfer to new examples.&lt;br&gt;It can be mathematically shown that overf=\r\nitting can be minimized by minimizing the amount of information needed to e=\r\nncode the classification rule. If the information complexity of the rule is=\r\n considerably lower than the information complexity of the training set, th=\r\nen the probability of overfitting goes to zero.&lt;br&gt;Imagine we use novelty s=\r\nearch to find a classification rule. For our analysis we will assume that w=\r\ne use a pseudo-random number generator with a known seed(This should not af=\r\nfect the performance). We will run novelty search until we find a classifie=\r\nr that reaches the desired performance on the training set. This will be th=\r\ne classifier we use. One way to identify this classifier is by n, its index=\r\n number in the series of classifiers tested. We can recreate the classifier=\r\n by running the search from the start. (We can count only classifiers with =\r\ndifferent classifications). In such case the information content of the cla=\r\nssifier will be log(n)+O(log(log(n)). If this number is small compared to t=\r\nhe information content of the training set, then we can be assured that we =\r\navoided overfitting.&lt;br&gt;&lt;br&gt;The same logic can be applied to any random sea=\r\nrch. It does not work however with a classification performance directed se=\r\narch since in such a search the classifier can not be recreated from its nu=\r\nmber in the enumeration alone. To get the classifier from its number, we al=\r\nso need the training set. This makes the overfitting bound meaningless.&lt;br&gt;=\r\n&lt;br&gt;Together with the other benefits of novelty search this seems almost to=\r\no good to be true. There are some points which are not clear to me however.=\r\n One is comparison to random search. Random search possesses the same prope=\r\nrty of overfitting avoidance as well as an additional optimality property. =\r\nIn a random search it is relatively straightforward to order the hypotheses=\r\n by our interpretation of their complexity - we can perfectly incorporate O=\r\nccam&#39;s Razor. This doesn&#39;t seem possible to the same degree in novelty sear=\r\nch. A random(actually brute force) search is used for the theoretically opt=\r\nimal Solomonoff Induction(which unfortunately is far from optimal in comput=\r\nation time). People actually managed to use a brute force search successful=\r\nly even to &lt;a href=3D&quot;http://agi-conf.org/2010/wp-content/uploads/2009/06/p=\r\naper_57.pdf&quot;&gt;develop neural networks&lt;/a&gt;. So I would be careful about throw=\r\ning away random search.&lt;br&gt;&lt;br&gt;I actually tried a kind of Novely Search wit=\r\nh NEAT on the Xor problem. It did not work very well. I know that xor is no=\r\nt a very good example for this. I am thinking about trying it on more inter=\r\nesting problems.&lt;br&gt;&lt;br&gt;What are your thoughts on this?\n\r\n--4-2591095099-0958753189=:9--\r\n\n"}}