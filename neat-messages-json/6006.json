{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":54567749,"authorName":"Ken","from":"&quot;Ken&quot; &lt;kstanley@...&gt;","profile":"kenstanley01","replyTo":"LIST","senderId":"bMeQbC1f6j11wXlO2H_9OBPqZ5gI4wn-dRy-EyyZj6HmsCBJE5y1WIE-k-2avIYdtbe7mgzYDt7iNDAl4t3Gqz4HZtmp","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: New paper on why modules evolve, and how to evolve modular artificial neural networks","postDate":"1361603419","msgId":6006,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGtnOXEwcitmcnFwQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGtnMzliOCt2cTYwQGVHcm91cHMuY29tPg=="},"prevInTopic":6005,"nextInTopic":6007,"prevInTime":6005,"nextInTime":6007,"topicId":5976,"numMessagesInTopic":30,"msgSnippet":"Hi Stephane, I want to acknowledge that the work on multiobjective optimization is important, and the contributions of yourself, JB, and others are very","rawEmail":"Return-Path: &lt;kstanley@...&gt;\r\nX-Sender: kstanley@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 54639 invoked from network); 23 Feb 2013 07:10:19 -0000\r\nX-Received: from unknown (10.193.84.163)\n  by m11.grp.bf1.yahoo.com with QMQP; 23 Feb 2013 07:10:19 -0000\r\nX-Received: from unknown (HELO ng16-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.138)\n  by mta3.grp.bf1.yahoo.com with SMTP; 23 Feb 2013 07:10:19 -0000\r\nX-Received: from [98.139.164.122] by ng16.bullet.mail.bf1.yahoo.com with NNFMP; 23 Feb 2013 07:10:19 -0000\r\nX-Received: from [10.193.94.41] by tg3.bullet.mail.bf1.yahoo.com with NNFMP; 23 Feb 2013 07:10:19 -0000\r\nDate: Sat, 23 Feb 2013 07:10:19 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;kg9q0r+frqp@...&gt;\r\nIn-Reply-To: &lt;kg39b8+vq60@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ken&quot; &lt;kstanley@...&gt;\r\nSubject: Re: New paper on why modules evolve, and how to evolve modular artificial neural networks\r\nX-Yahoo-Group-Post: member; u=54567749; y=JvNXONDJhyptRcK-svZ4Ugg6b8iFrL21eB5bVy5bgyHpf5JFhMNT\r\nX-Yahoo-Profile: kenstanley01\r\n\r\n\n\nHi Stephane, \n\nI want to acknowledge that the work on multiobjective opti=\r\nmization is important, and the contributions of yourself, JB, and others ar=\r\ne very thought-provoking, as well as practical.  One of the important cavea=\r\nts to my debate with Jeff is that I am advocating using the encoding to enc=\r\nourage certain properties when that is possible, but that often it will not=\r\n be possible because the relationship between the encoding and what we want=\r\n will be too difficult to comprehend.  So there will be many cases where fi=\r\ntness-based strategies such as MOEAs will be a viable choice.  As you know,=\r\n my own group has also worked with MOEAs in a number of combinations in rec=\r\nent years (such as NS + local competition) as well, inspired in part by you=\r\nr own demonstrations of their potential.  We also have a multiobjective ver=\r\nsion of NEAT, which replaces the traditional speciation with a genetic dive=\r\nrsity objective (with the idea that you can then more easily combine NEAT w=\r\nith NSGA II).  Your result in ball collecting are also impressive.\n\nSo I am=\r\n by no means against MOEAs and I&#39;m afraid my argument with Jeff is coming o=\r\nff that way.  My argument is rather that encoding is often going to be the =\r\nmost natural and least ad hoc place to encourage certain properties if you =\r\ncan figure out how to do it through the encoding.  While you are right that=\r\n MOEAs are convenient in the sense they work with any encoding, I don&#39;t thi=\r\nnk in the end evolution is about convenience, so we&#39;ll have to grapple with=\r\n encoding.  As Jeff points out, encoding can make a big difference (like L-=\r\nsystems vs. CPPNs vs. direct encodings).  But I don&#39;t think you have much d=\r\nisagreement with that either.\n\nOften when I think about evolution I&#39;m think=\r\ning about long-term (like millions of generations), open-ended situations, =\r\nor natural evolution.  I&#39;m thinking about evolving amazing things that riva=\r\nl what we see in nature.  I&#39;m thinking, okay so we evolved a toy problem, b=\r\nut how far can we extrapolate the lessons to evolving a brain.  And I think=\r\n there&#39;s a lot of danger there that we extrapolate too much from lessons th=\r\nat are learned in astronomically simpler contexts, especially when it comes=\r\n to fitness pressures.  So that&#39;s why I think it&#39;s important to be open-min=\r\nded to the possibility that what looks important in the short run is a red =\r\nherring in the long run.  But that doesn&#39;t mean I&#39;m in any sense I&#39;m dismis=\r\nsing MOEAs altogether.\n\nBest,\n\nken\n\n\n\n--- In neat@yahoogroups.com, &quot;stephan=\r\ne.doncieux&quot; &lt;stephane.doncieux@...&gt; wrote:\n&gt;\n&gt; \n&gt; \n&gt; Hi,\n&gt; \n&gt; Congratulatio=\r\nns to JB, Jeff and Hod for their great work on the\n&gt; evolution of modularit=\r\ny !\n&gt; \n&gt; The length and multiplicity of the comments undoubtedly show the v=\r\nalue\n&gt; of this work. I would like to comment on the debate between encoding=\r\n bias and fitness manipulations that this paper has provoked in the mailing=\r\n list (a debate that actually goes beyond the connection cost objective for=\r\n modularity). \n&gt; \n&gt; After having spent a long time on encodings, I find it =\r\nfruitful to\n&gt; work on selection pressures. We have actually worked on the d=\r\nefinition\n&gt; of such fitness pressures and have proposed objectives to promo=\r\nte\n&gt; diversity (Behavioral diversity [1]), generalization [2], behavior\n&gt; c=\r\nonsistency [3,4] or to cross the reality gap with robots [5].  I\n&gt; don&#39;t wa=\r\nnt to say that it is the only way to solve the problems that\n&gt; these object=\r\nives are designed for, nor that it is the best way to do\n&gt; it, but I will j=\r\nust mention the advantages I find with such an\n&gt; approach relative to work =\r\non the encoding.\n&gt; \n&gt; The great advantage of the works on selection pressur=\r\nes is that it is\n&gt; highly localized. The contribution is limited to the def=\r\ninition of an\n&gt; objective that is then easy to integrate to a third party w=\r\nork than\n&gt; when it comes with its own specific selection algorithm and\n&gt; en=\r\ncoding. Such work does not highly depend on an encoding, nor on a\n&gt; particu=\r\nlar selection algorithm (as long as it is a multi-objective\n&gt; algorithm). I=\r\nt is trivial to make comparisons with-without a\n&gt; particular objective and =\r\nall these works are, at least from a\n&gt; technical point of view, compatible.=\r\n You can then use, besides a\n&gt; goal-oriented objective, the connection cost=\r\n objective for modularity together with a behavioral diversity or novelty o=\r\nbjective to increase the exploration. What is even more interesting in my o=\r\npinion, is that\n&gt; anyone interested in optimizing complex neural networks o=\r\nr graphs and\n&gt; that may have his own encoding for whatever reasons (to be\n&gt;=\r\n biologically plausible for instance) can use these objectives in his\n&gt; own=\r\n work with very few, if any, technical modifications. It represents\n&gt; then =\r\na lower investment and makes such kind of work more prone to be\n&gt; used outs=\r\nide of our own field, it is at least my opinion on the\n&gt; subject. Likewise,=\r\n all the works mentionned above rely on NSGA-II,\n&gt; i.e. a classic multi-obj=\r\nective evolutioanry algorithm. Any\n&gt; new and more efficient MOEA can by use=\r\nd without any particular\n&gt; technical problem.\n&gt; \n&gt; To come back to the perf=\r\normance issue, in all of our experiments,\n&gt; using a simple direct encoding =\r\nwith two objectives\n&gt; (fitness+behavioral diversity) gave better results th=\r\nan NEAT, no\n&gt; matter how we define behavioral diversity [1]. What is nice w=\r\nith these\n&gt; results, is that it is not incompatible with NEAT. A\n&gt; multi-ob=\r\njective version of NEAT can exploit the benefits gained with\n&gt; behavioral d=\r\niversity (it has actually been proposed in a GECCO paper\n&gt; by Moriguchi and=\r\n Honiden). A quite surprising result for us is that a\n&gt; simple direct encod=\r\ning can solve a complex sequential tasks (ball\n&gt; collecting task) with a di=\r\nscrete and simple fitness function (a number\n&gt; of collected balls) together=\r\n with a simple behavioral diversity\n&gt; objective (see a video here: http://y=\r\noutu.be/Trj0_A1ZfNo).\n&gt; \n&gt; Of course, there are limitations. If you use mor=\r\ne than three\n&gt; objectives, for instance, the performance of multi-objective=\r\n\n&gt; algorithms is known to be very low. This is a limitation that people\n&gt; f=\r\nrom the multi-objective optimization community are aware of. They\n&gt; work on=\r\n it and many-objectives optimization algorithms will probably\n&gt; be released=\r\n in a near future (some have already been proposed\n&gt; actually).  Likewise, =\r\nas pointed out by Jeff, the dead weights\n&gt; mentionned by Ken are really a c=\r\nonsequence of current multi-objective\n&gt; evolutionary algorithms inner worki=\r\nngs. Several adaptations can be\n&gt; proposed, as the &quot;probabilistic pareto do=\r\nminance&quot; developped by Jeff\n&gt; and Jean-Baptiste or any other preference or =\r\nthresholding system. It\n&gt; is not an inherant limitation of these approaches=\r\n, just a proof that\n&gt; there is still some work to do in multi-objective opt=\r\nimization\n&gt; field. It should be noted that this is not a problem of our com=\r\nmunity\n&gt; only. Multi-objective optimization is a very dynamic field of rese=\r\narch\n&gt; so we can expect solutions to these problems in a forthcoming future=\r\n.\n&gt;  \n&gt; So to conclude, I agree that it is important to work on the encodin=\r\ng,\n&gt; but my point is that it is also worth to work on selection pressures. =\r\nThe nice thing is\n&gt; that the works on both aspects are quite complementary.=\r\n\n&gt; \n&gt; \n&gt; Best,\n&gt; \n&gt; Stephane Doncieux\n&gt; \n&gt; [1] Mouret, J.-B. and Doncieux, =\r\nS. (2012). Encouraging Behavioral Diversity in Evolutionary Robotics: an Em=\r\npirical Study.\n&gt; Evolutionary Computation. Vol 20 No 1 Pages 91-133.\n&gt; \n&gt; [=\r\n2] Pinville, T. and Koos, S. and Mouret, J-B. and Doncieux,\n&gt; S. (2011). Ho=\r\nw to Promote Generalisation in Evolutionary Robotics: the\n&gt; ProGAb Approach=\r\n. GECCO&#39;11. Pages 259--266.\n&gt; \n&gt; [3] Ollion, Charles and Doncieux, St=E9pha=\r\nne (2012). Towards Behavioral Consistency in Neuroevolution.\n&gt; From Animals=\r\n to Animats: Proceedings of the 12th International\n&gt; Conference on Adaptive=\r\n Behaviour (SAB 2012), Springer, publisher. \n&gt; \n&gt; [4] Ollion, C. and Pinvil=\r\nle, T. and Doncieux, S. (2012). With a little\n&gt; help from selection pressur=\r\nes: evolution of memory in robot\n&gt; controllers. Proc. Alife XIII.\n&gt; \n&gt; [5] =\r\nKoos, S. and Mouret, J.-B. and Doncieux, S. (2013). The\n&gt; Transferability A=\r\npproach: Crossing the Reality Gap in Evolutionary\n&gt; Robotics. IEEE Transact=\r\nions on Evolutionary Computation. Vol 17 No 1 Pages 122 - 145 .\n&gt; \n&gt; \n&gt; \n&gt; =\r\n--- In neat@yahoogroups.com, Jeff Clune &lt;jclune@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hello Ken,=\r\n\n&gt; &gt; \n&gt; &gt; Please see my inlined comments. \n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Hi Jeff, I wan=\r\nted to follow up on the &quot;dead weight&quot; concept I brought up, because I feel =\r\nI may not have made it entirely clear what that is. In a multiobjective for=\r\nmulation, if one of the objectives is low connectivity, then you can domina=\r\nte on that objective by having extremely low connectivity and no other savi=\r\nng grace whatsoever. In other words we are talking about completely nonfunc=\r\ntional and essentially inert garbage that does well on that one objective b=\r\ny effectively being brain dead. In effect, you have created a special &quot;nich=\r\ne&quot; for brain-dead networks with radically low connectivity.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt;=\r\n &gt; That&#39;s true. Of course, you could choose to have a cutoff to minimize th=\r\nis problem. For example, you could not give credit to any orgs that do not =\r\nhave a path from inputs to outputs, or that have a total connectivity below=\r\n X, or some other solution (including a cutoff that changes over time). \n&gt; =\r\n&gt; \n&gt; &gt; &gt; Perhaps early on this niche is a fruitful point of departure for b=\r\netter places, but the problem is that this niche will never go away. You wi=\r\nll always have this protective pocket for brain-dead low-connectivity netwo=\r\nrks for as long as evolution runs. In fact it&#39;s a very attractive niche bec=\r\nause it&#39;s so easy - you don&#39;t have to worry about performance and simply ne=\r\ned to keep your structure down. So these types of inert blobs will be aroun=\r\nd forever.\n&gt; &gt; &gt; \n&gt; &gt; &gt; You suggest that my concern about this &quot;unfit&quot; nich=\r\ne is not consistent with my support of novelty search, but novelty search i=\r\ns not really analogous. Novelty search is about constantly searching for *n=\r\new* departure points. Your dead-weight niche is about keeping around the sa=\r\nme bottom-level junk forever. Novelty search would quickly tire of such a b=\r\nlack hole and abandon it (it doesn&#39;t stay novel). But multiobjective search=\r\n will embrace it for eternity.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; That&#39;s true, but on many c=\r\nomplex/multi-dimensional tasks there are often infinitely many ways to be u=\r\nninteresting, yet novel. For example, in your unenclosed map in the NS jour=\r\nnal paper, only a few runs solve the problem (the same as random search), l=\r\nikely because of the permanent dead-weight of an infinite number of places =\r\nto end up that are far away from the target. \n&gt; &gt; \n&gt; &gt; &gt; Nature doesn&#39;t hav=\r\ne anything analogous either, which means there is at least some evidence th=\r\nat the &quot;fitness bias&quot; analogy with nature is not lining up perfectly. You m=\r\night point to the continuing existence of single-celled organisms as someth=\r\ning similar to the perpetual dead-weight in this formulation, but they aren=\r\n&#39;t really analogous because single-celled organisms are functional - they r=\r\netain the ability to make copies of themselves and continue to evolve in th=\r\neir own right - while the low-connectivity deadweight maintains no capabili=\r\nty whatsoever. On the other hand, suspiciously, as in nature, nothing simil=\r\nar to such a deadweight niche is perpetuated by a biased encoding.\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; \n&gt; &gt; That&#39;s also true, but that fault does not lie with the fitness co=\r\nst concept, it lies with the fact that multi-objective algorithms, which ar=\r\ne the cause of the dead weight, do not perfectly analogize to nature. They&#39;=\r\nre just better than a weighted sum for other reasons, but the fitness cost =\r\nconcept could easily be implemented in a weighted sum fitness function and =\r\nnot have this dead weight issue.  \n&gt; &gt; \n&gt; &gt; &gt; Doesn&#39;t it seem a little stra=\r\nnge that the price we have to pay to obtain modular structure is to maintai=\r\nn a perpetual dead pool of genetic junk? Note that it doesn&#39;t suggest that =\r\nsuch a system won&#39;t work in some cases, but it&#39;s inelegant enough to raise =\r\nquestions about the best realization of the concept..\n&gt; &gt; &gt; \n&gt; &gt; \n&gt; &gt; All I=\r\n think that calls into question is the optimality of multi-objective algori=\r\nthms when you don&#39;t want the extreme of one objective. But that problem alm=\r\nost always occurs in multi-objective algorithms, so your really indicting t=\r\nhe whole field of MOEA instead of our approach of using a fitness penalty i=\r\nnstead of a biased encoding, no?\n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Also on the analogy with=\r\n nature, while your argument for fitness pressure in nature based on the si=\r\nze of the head is logically possible (and the kind of argument that is prob=\r\nably attractive to a lot of people), it&#39;s only speculative. In fact what li=\r\nttle evidence there is on such a speculative issue (i.e. whether a baby&#39;s h=\r\nead might fit through a mother&#39;s pelvis in some alternate evolutionary path=\r\n) doesn&#39;t support the idea that size is the main issue here. After all, wha=\r\nle brains are far bigger than human brains and I&#39;m sure they are also domin=\r\nated by local connectivity.\n&gt; &gt; &gt; \n&gt; &gt; Yes, but they float in water! You co=\r\nuldn&#39;t have a creature with that big of a brain on land (I speculate, not b=\r\neing an expert in these things). Interesting side note: I believe whale bra=\r\nins are pretty tiny as a fraction of body size compared to primates, and (f=\r\nor some reason I don&#39;t get) we think that relative brain size matters more =\r\nfor intelligence than absolute brain size.  \n&gt; &gt; \n&gt; &gt; &gt; Conversely, human b=\r\nrains, or brains of any size for that matter, could have been exactly the s=\r\name size but dominated by long-range connections rather than short range on=\r\nes. In fact, in such a situation connectivity would actually be lower overa=\r\nll because long-range connections take up more space. But the mother&#39;s anat=\r\nomy poses no obstacle to such a scenario. The fact that we don&#39;t see such a=\r\n connectivity in any species is therefore plausibly a result of the fact th=\r\nat the encoding simply can&#39;t describe it easily.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; Such a b=\r\nrain could exist, but because of the extra space taken up by the connection=\r\ns, there would have to be either fewer neurons, fewer connections (as you p=\r\noint out), or both. That certainly sounds like a cost to me! Moreover, long=\r\ner connections are less reliable, cost more to build and maintain, and they=\r\n are energetically more expensive due to signal drop along the length of th=\r\ne wire. So there are a whole host of costs associated with such a strategy,=\r\n making me think it much, much more likely that these costs are the reason =\r\nwe don&#39;t see this type of brain, instead of it being difficult to encode. E=\r\nvolution has produced amazing things, and it already produces many long-ran=\r\nge connections in the brain, so I do not think the difficulty of encoding s=\r\nuch a brain is what prevented it from existing. \n&gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; I feel t=\r\nhat you may not see what I&#39;m saying about encoding here, because you speak =\r\nabout encoding as if it has similar effects to fitness pressure, but I thin=\r\nk it&#39;s not the same. You say: \n&gt; &gt; &gt; \n&gt; &gt; &gt; &quot;The reasons biases work is bec=\r\nause they do bias search towards some areas and away from others: so I thin=\r\nk both encoding biases and fitness penalties have similar effects in this r=\r\negard.&quot;\n&gt; &gt; &gt; \n&gt; &gt; &gt; But I don&#39;t think that&#39;s true for encoding. The differ=\r\nence with encoding is that it is not pushing the search towards any particu=\r\nlar area within the space it induces. Absent any kind of fitness function o=\r\nr selective pressure, encoding says nothing about which areas are accessibl=\r\ne. Rather it simply says which types of phenotypes are overrepresented or u=\r\nnderrepresented throughout the whole space of genotypes. In other words, ev=\r\nen if an encoding is &quot;biased&quot; towards low connectivity, if you happen to ge=\r\nt into an area of the space with high connectivity, the encoding does not h=\r\nave to push you out of that area (it could be a dense subspace full of high=\r\n-connectivity structures). But fitness bias would have to push you out beca=\r\nuse all it does it push you out. It can&#39;t bend or change depending on where=\r\n you go. Encoding can change with the times and has the wonderful additiona=\r\nl potential for canalization, a bonus entirely absent from fitness pressure=\r\n.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; First of all, an encoding can actually prevent you from=\r\n accessing a space. If I encode the length of all table legs in one number,=\r\n than I have eliminated the possibility of a table having legs of different=\r\n lengths. L-systems tend to produce such overly rigid biases (unless they a=\r\nre parameterized and/or made context-dependent). But more relevant to our d=\r\niscussion are biases that are strong likelihoods, but not strict edicts. Ev=\r\nen these, though, in practice do mean that entire areas of the search space=\r\n go unexplored. In our TEC paper, for example, the HyperNEAT generative enc=\r\noding far outperformed the direct encoding, even though the fitness functio=\r\nn was the exact same. Why? Because the direct encoding was biased towards a=\r\nn entirely different area of the search space. We know that there was a sel=\r\nection pressure for certain types of ANNs (namely, the ones HyperNEAT produ=\r\nced), and we know that the direct encoding can express those phenotypes (th=\r\ney actually do in HybrID), but evolution with the direct encoding did not d=\r\no so because biases have a huge effect on the subset of the search space yo=\r\nu visit. In fact, it is precisely because encodings have biases of large ef=\r\nfect that we all care about generative encodings, no? All of these argument=\r\ns are also supported by Hornby&#39;s comparison of L-systems to a direct encodi=\r\nng, including his maps of the types of phenotypes produced (there are huge =\r\ndifferences between the two encodings). I&#39;d argue that any comparison of di=\r\nrect and indirect encodings shows that these biases are not subtle, but gro=\r\nssly change the types of phenotypes explored, and for all practical purpose=\r\ns eliminate large swathes of the search space. For these reasons I think yo=\r\nu&#39;ll get huge unintended consequences by playing around with encodings, and=\r\n those consequences will not be overridden by the fitness function, because=\r\n we&#39;ve seen it happen time and time again. Note that I agree that you also =\r\nhave unintended consequences when playing with fitness functions. \n&gt; &gt; \n&gt; &gt;=\r\n NB: I agree with you about canalization, which is one of many reasons I li=\r\nke generative encodings. :-)\n&gt; &gt; \n&gt; &gt; &gt; The right level of modularity is li=\r\nkely on a delicate continuum - not entirely one way or another, and probabl=\r\ny varies by species. You believe evolution can pay a kind of tax for going =\r\nagainst the pressure towards low connectivity: &quot;if a certain phenotype pays=\r\n for its wiring by increasing fitness, it can add high-connectivity areas a=\r\nnywhere that they are useful.&quot; But in a delicate balancing act where the be=\r\nst option is likely some middle ground, that sounds too much like gambling =\r\nand it&#39;s vulnerable to deception in cases where there is no immediate fitne=\r\nss benefit (whereas encoding is orthogonal to fitness). With encoding you d=\r\non&#39;t have the play that game. Encoding can create its own tendency towards =\r\nsome middle ground and canalize that tendency over time.\n&gt; &gt; &gt; \n&gt; &gt; If ther=\r\ne is no fitness gradient toward such a bias toward intermediate connectivit=\r\ny, why would it evolve? Evolution can only think short term. I&#39;ll give you =\r\nthat an encoding bias might override the fitness gradient by making it impo=\r\nssible to follow, but I don&#39;t buy that evolution can magically figure out b=\r\niases that are helpful in the long-term if the short-term fitness gradients=\r\n all point in another direction. Or, at least, that&#39;s something we hope tha=\r\nt evolution might do, but it&#39;s a controversial, unproven, and theoretically=\r\n tricky issue that I certain don&#39;t think we can bank on happening until we =\r\nunderstand it a lot more. \n&gt; &gt; \n&gt; &gt; &gt; While you worry that modularity might=\r\n &quot;evolve away,&quot; the idea that it cannot evolve away to varying degrees soun=\r\nds worse to me. Natural evolution is generally good about not keeping all i=\r\nts eggs in one basket - a trait may evolve away in some branches but not in=\r\n others. But for you to make an all-out attempt to bar such a deviation fro=\r\nm square one is making a lot of strong assumptions about what we want to se=\r\ne 1 billion years in the future.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; I&#39;d argue that your bias=\r\n in the first replicator without any sustained fitness pressure would have =\r\nzero effect on creatures a billion years later, especially in the case wher=\r\ne there is an active fitness gradient by default away from modularity (whic=\r\nh we know there is, since modularity never evolves without a bias or fitnes=\r\ns pressure). Evolution would not keep any eggs in a basket with an active f=\r\nitness penalty, at least not for a billion years. My 1-billion-years-later =\r\ninfluence may thus be imperfect, but it at least exists!\n&gt; &gt; \n&gt; &gt; &gt; So I&#39;m =\r\nstill a fan of manipulating encoding over manipulating fitness. But I would=\r\n not entirely despair on fitness because there will still be cases where th=\r\nere is no clear option for manipulating the encoding. But such scenarios ar=\r\ne not ones we should be hoping for.\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; I do think you make s=\r\nome great arguments for encodings, but I cannot envision a case in which an=\r\n initial bias only makes a huge difference in the long-term. That&#39;s true ev=\r\nen if the bias is neutral with respect to fitness (because it would drift a=\r\nway), but seems a certainty to me if it relates to a bias that has an activ=\r\ne fitness penalty. The whole point of canalization is that it figures out w=\r\nhat produces fit offspring and generates that type of organism: if modular =\r\ncreatures are less fit in the short term, evolution will canalize away from=\r\n modularity, not toward it. That said, as I mentioned at the beginning of t=\r\nhis conversation, I do think that a sustained encoding bias of some sort is=\r\n an interesting approach that could work, although it may be that all we ha=\r\nve to do is provide a fitness cost and then the encoding will canalize in a=\r\n way that produces such a sustained bias. :-)\n&gt; &gt; \n&gt; &gt; As always, an intere=\r\nsting conversation!\n&gt; &gt; Best,\n&gt; &gt; Jeff\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; &gt; Best,\n&gt; &gt; &gt; \n&gt; &gt; &gt; k=\r\nen\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In neat@yahoogroups.com, Jeff Clune wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; =\r\n&gt; &gt; Hello all,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; As Ken mentioned, we&#39;ve discussed these iss=\r\nues in private. I&#39;m going to include some of my comments from one of those =\r\nemail threads with slight modification, as I believe they summarize the vie=\r\nws of Jean-Baptiste and I on the issues Ken raises. I&#39;ll then respond to a =\r\nfew individual comments by Ken afterwards. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --------------=\r\n-\n&gt; &gt; &gt; &gt; Ken,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; It&#39;s great to hear your feedback on our pap=\r\ner. Thanks for sending it.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; First off, thanks for the kind =\r\nwords. We&#39;re very glad you liked the paper and think it is important. \n&gt; &gt; =\r\n&gt; &gt; \n&gt; &gt; &gt; &gt; Regarding a selection pressure vs. an encoding bias. We&#39;re not=\r\n convinced that an initial encoding bias is a good way to encourage propert=\r\nies that one wants in phenotypes throughout evolution, such as modularity. =\r\nIf there is any deceptiveness (or even neutrality) regarding modularity at =\r\nany point during the run then the bias will disappear, and then for the res=\r\nt of evolutionary time nothing will encourage modularity. We are more convi=\r\nnced of the power of mutational bias in the encoding (i.e. a constant encod=\r\ning bias instead of just an initial encoding bias), and we think it would b=\r\ne interesting to investigate area. However, if the encoding bias is under s=\r\nelection, then you have the same issue where it might evolve away. Selectiv=\r\ne pressures are interesting because they are constant, so you&#39;re more likel=\r\ny to get what you want. That raises the point you mention about our pressur=\r\ne being too strong, such that evolution could not deviate when it would be =\r\nbeneficial not to have modularity. That might be a problem if the pressure =\r\nis too strong, but it seems likely that in many cases the benefits in terms=\r\n of performance for being non-modular will outweigh the cost. In other word=\r\ns, evolution can decide to pay the cost of non-modularity when it is useful=\r\n (e.g. in your example of a hub of connections between modules).\n&gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; Regarding playing with an encoding being safer than playing with sel=\r\nection pressures. Our view is that both are very complicated and can have u=\r\nnintended consequences, so playing with one is just as bad as the other. I =\r\nthink our field is more familiar with unintended consequences of selective =\r\npressures just because we historically tend to play with them more (and mak=\r\ne simple encodings), but it is also very hard to intuit the consequences of=\r\n choices regarding biases in complex encodings. In your case the consequenc=\r\nes are relatively intuitive, precisely because they are so minimally interv=\r\nentionist...but that is also why I think they are not strong enough to caus=\r\ne modularity except in cases (like retina) where all you have to do is init=\r\nially place evolution in the right attractor basin.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Regard=\r\ning the resource hog waste of having a cost objective. I have to have a lit=\r\ntle fun here and point out the irony of the co-champion of novelty search w=\r\norrying about the resources consumed by non-high-performing individuals! He=\r\nhe. As you&#39;ve persuaded me, I&#39;m more interested in an algorithm that is int=\r\neresting or that works than spending a little computation inefficiently.\n&gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I&#39;d also like to point out an innovation we came up with to =\r\nmitigate the problem of preventing evolution from exploring solutions that =\r\nare contrary to one of the objectives. We recognized that the cost objectiv=\r\ne is ultimately less important than the performance objective. We wanted ev=\r\nolution to periodically ignore the cost objective to explore stepping stone=\r\ns that had higher connectivity. To do that, we invented a technique that in=\r\nvolves &quot;probabilistic pareto dominance&quot;, wherein secondary objectives (in t=\r\nhis case cost) are factored into pareto dominance only a small percentage o=\r\nf the time. That won&#39;t solve the problem you mention if you have to take a =\r\nlong, many-multi-generational walk through high-connectivity areas of the s=\r\nearch space, but it does allow quick forays into that terrain without any f=\r\nitness penalty. This technique could be used for any cost (or other) object=\r\nive, so it is not specific to connectivity costs. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; See bel=\r\now for a few specific responses to your comments. I should note that below =\r\nthis the thoughts are my own and Jean-Baptiste should not be blamed for any=\r\n of them! (Feel free to blame him for things above this line=85we went over=\r\n that text together a while back). ;-)\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; More generally th=\r\ne issue is the usual problem of deception, which is compounded by anything =\r\nyou do with fitness. For example, in a complex search space, there is a rea=\r\nsonable chance that the stepping stone to a good low-connectivity solution =\r\nis something with higher connectivity. By manipulating fitness, you are cut=\r\nting out all chances of encountering such a deceptive stepping stone. But e=\r\nven if you don&#39;t believe that could be true, the single-mindedness of alway=\r\ns favoring low-connectivity could deceive you from many parts of the search=\r\n space that might be stepping stones to something worthwhile, relating to c=\r\nonnection density or not.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; True. But the same =\r\nexact thing can be said for biases in the encoding: they prevent you from s=\r\nearching large areas of the search space. You may reply that it is only a b=\r\nias, not a strict ban, but of course we know that in large search spaces bi=\r\nases hugely affect the landscape such that certain areas will practically n=\r\never be visited. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; On the other hand, manipulating the en=\r\ncoding is different because in effect it actually reorganizes the structure=\r\n of the search space itself, which seems to me a more principled thing to d=\r\no (if you can figure out a way to do it). Because the thing is, in that cas=\r\ne, you do not need to worry about a permanent dead weight taking up some pr=\r\noportion of your population forever. Instead, while the encoding may *tend*=\r\n to produce e.g. low-connectivity solutions, it can still escape that tende=\r\nncy without any penalty to fitness.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; My instincts tell me=\r\n that we create dead weight with encoding biases too. For example, an overl=\r\ny regular generative encoding (e.g. context free L-systems) is great if goo=\r\nd solutions are perfectly regular, but if what is required is a mix of regu=\r\nlarity and irregularity, then you spend your entire time producing only hig=\r\nhly regular phenotypes that never wander into the appropriately irregular a=\r\nreas of the search space. Our IEEE TEC paper, for example, shows that Hyper=\r\nNEAT can spend thousands of generations spinning its wheels never generatin=\r\ng solutions that HybrID could easily generate, demonstrating a &quot;overly regu=\r\nlar&quot; dead weight associated with the biases of even the best known* generat=\r\nive encoding! Both fitness penalties and biases can cause you to focus your=\r\n search in unproductive areas=85which is ultimately what dead weight is. \n&gt;=\r\n &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; * in our opinion! :0)\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Furthermore, in re=\r\nality the best situation regarding modularity and connectivity is probably =\r\nrather subtle, with most of the brain respecting the principle of low conne=\r\nctivity, but with a number of critical exceptions in key areas, such as maj=\r\nor inter-module hubs. A sophisticated encoding can allow its bias to bend t=\r\no make such nuanced exceptions (e.g. based on locations within a geometry),=\r\n whereas a fitness penalty is a heavy hand and blunt instrument that cannot=\r\n but help always to demand global and holistic subservience to dogmatic uni=\r\nversals (unless you are willing to take a hit in fitness).\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n &gt; &gt; \n&gt; &gt; &gt; &gt; I think the last clause you offer is the key exception though=\r\n. As I mentioned above, if a certain phenotype pays for its wiring by incre=\r\nasing fitness, it can add high-connectivity areas anywhere that they are us=\r\neful (without even needing to carve out that area in geometric space, which=\r\n is often a difficult task for CPPNs). Instead of being a blunt instrument,=\r\n a fitness penalty can be quite subtle, because it can allow connection-by-=\r\nconnection exceptions if they produce fitness improvements, and do so witho=\r\nut any search overhead. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; An interesting question in natu=\r\nre (where our brains evolved modular structure) is whether its tendency tow=\r\nards low connectivity is a result of an aspect of fitness in the wild, or a=\r\nn aspect of encoding bias. I think there is a lot of room in this question =\r\nfor arguing either way, but my hunch is that the bias is mostly in the enco=\r\nding. My logic is that I think the reason that the connectivity of the brai=\r\nn is so much lower than what it could be (e.g. it is a tiny fraction of eve=\r\nrything-to-everything connectivity) is an artifact of physics rather than a=\r\nn artifact of fitness. It is simply physically impossible for a giant 100-b=\r\nillion-to-100-billion connectivity to fit in a head anything close to our s=\r\nize. And physical impossibility is in some sense a property of encoding. Th=\r\nat is, mutations that could step from a low-connectivity brain to a high on=\r\ne are few and far between simply because of physical constraint. So high-co=\r\nnnectivity structures are simply a very small part of the search space of b=\r\nrains in the physical universe. However, at the same time, you can still ge=\r\nt long-range connections from time to time because there is no universal pe=\r\nnalty for doing so, just a lower a priori probability of such mutations occ=\r\nurring.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Here I completely disagree with you. =\r\nI see the force preventing the volume of neural connections from getting to=\r\no large as a direct fitness cost, not an encoding bias. If mutations increa=\r\nse the size of the head, the baby and the mother are more likely to die in =\r\nchildbirth. Anthropologists have long known that evolution&#39;s desire to have=\r\n larger and larger brains is the main reason why humans have such ridiculou=\r\nsly high maternal and infant mortality &quot;in the wild&quot; (pre modern health car=\r\ne, and even post). Our encoding keeps producing such mutants, and it&#39;s deat=\r\nh (via the physical constraints of the pelvis) that keep them from being ke=\r\npt around. The historical accident of birthing through the pelvis aside, th=\r\nere would still be fitness consequences for more vastly neural connections =\r\n(e.g. neurons are metabolically expensive, neural connections require energ=\r\ny to build and maintain, and housing such large brains would create a large=\r\n, clunky bobble head of a being that would be ungainly). It is possible tha=\r\nt low connectivity is an encoding bias, but were that true I think it would=\r\n look like some sort of growth rule that only grew a few connections per ne=\r\nuron (e.g. 10k). Evolution could have learned such a rule, and canalized th=\r\nat rule in a way that makes it unlikely to have mutations that produce orde=\r\nrs of magnitude more neurons, but my guess is that if it has done so, it wa=\r\ns because of the fitness costs associated with large numbers of neurons, no=\r\nt because of evolvability (or due to some historical accident). I do think =\r\nit is interesting to study whether such biases exist in the encoding of neu=\r\nral growth rules, but even if they do exist I don&#39;t think that shows that a=\r\n fitness cost was not the ultimate cause. Note: I recognize that you admit =\r\nthat this could be argued &quot;either way&quot;=85are these the sorts of arguments y=\r\nou envisioned as being the other way?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; In summary, the ke=\r\ny difference between the alternatives is that with fitness you are saying &quot;=\r\nstay out of this part of the search space&quot; whereas with encoding you are sa=\r\nying &quot;this part of the search space is much smaller and hence less likely t=\r\no encounter.&quot;\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I don&#39;t precisely understand yo=\r\nur latter clause, but I think I understand the spirit of it. I disagree, th=\r\nough. The reasons biases work is because they do bias search towards some a=\r\nreas and away from others: so I think both encoding biases and fitness pena=\r\nlties have similar effects in this regard. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; So, my specu=\r\nlation is that if you want to bias the search in highly complex domains, th=\r\ne best way is through the encoding. Fitness is a nasty quagmire that is dec=\r\neptively tempting to manipulate, but never plays by the rules you wish it w=\r\nould. Of course, these are merely my own unproven intuitions and their vera=\r\ncity remains to be demonstrated. But at least it&#39;s something to think about=\r\n.\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Thanks again for your feedback. As=\r\n always, I appreciate your input and enjoy discussing these fascinating sub=\r\njects. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I want to end by clarifying that I agree that ther=\r\ne are positives and negatives to both approaches. I do not see it as such a=\r\nn obvious choice between the two as you do. As I mentioned up top: I defini=\r\ntely don&#39;t think initial encoding biases that selection can get rid of will=\r\n get us very far. For simple problems they will work, but for any challengi=\r\nng problem the initial bias will have long disappeared by the time it will =\r\nmatter. What we need is some constant force encouraging search to take prom=\r\nising paths. A fitness cost is one way to do that, but a *constant* (or, at=\r\n least, *periodic*) encoding bias could do that just as well, and perhaps b=\r\netter. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Best regards,\n&gt; &gt; &gt; &gt; Jeff Clune\n&gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; Assistant Professor\n&gt; &gt; &gt; &gt; Computer Science\n&gt; &gt; &gt; &gt; University of=\r\n Wyoming\n&gt; &gt; &gt; &gt; jeffclune@\n&gt; &gt; &gt; &gt; jeffclune.com\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;=\r\n &gt; Best,\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; ken\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; --- In neat@yahoogro=\r\nups.com, Alexandre Devert wrote:\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Hi,\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt;=\r\n &gt; &gt; &gt; &gt; &gt; =C2 Simple, clean experiment, with sharp results, congrats on th=\r\nat, definitely\n&gt; &gt; &gt; &gt; &gt; &gt; a step forward ! Of course, it begs for more que=\r\nstions. I would love to hear\n&gt; &gt; &gt; &gt; &gt; &gt; you on such (fairly open) question=\r\ns\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; =C2 =C2 1) Do you think that selection pressure =\r\nfor low connectivity is sufficient in\n&gt; &gt; &gt; &gt; &gt; &gt; itself to evolve large co=\r\nherent networks, or is it just a piece of the puzzle ?\n&gt; &gt; &gt; &gt; &gt; &gt; =C2 =C2 =\r\n2) Do you see your work as an indication that any approach biased to low\n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; connectivity would reproduce the result ? Or does the way you guy=\r\ns enforced\n&gt; &gt; &gt; &gt; &gt; &gt; this bias matters ?\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; To me=\r\n=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; 1) =3D&gt; Part of the puzzle. Should see how well it scales =\r\nfor increasingly\n&gt; &gt; &gt; &gt; &gt; &gt; complex task, when the connection graph gets b=\r\nigger. A randomized=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; search process=C2 on large graph sounds=\r\n not so efficient, need something to guide it.\n&gt; &gt; &gt; &gt; &gt; &gt; I advocate const=\r\nruction process that have a feedback from what the neuron=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; n=\r\network is computing. Don&#39;t know how to do it without creepling computationa=\r\nl\n&gt; &gt; &gt; &gt; &gt; &gt; cost tho...\n&gt; &gt; &gt; &gt; &gt; &gt; 2) =3D&gt; I guess that the bias alone i=\r\ns enough, the way to introduce it might\n&gt; &gt; &gt; &gt; &gt; &gt; not be such a big deal.=\r\n=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Again, great work, very helpful contribution =\r\n:)\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Alex\n&gt; &gt; &gt; &gt; &gt; &gt; =C2 \n&gt; &gt; &gt; &gt; &gt; &gt; Dr. Devert Al=\r\nexandre\n&gt; &gt; &gt; &gt; &gt; &gt; Researcher at the Nature Inspired Computation and Appli=\r\ncations Laboratory (NICAL)\n&gt; &gt; &gt; &gt; &gt; &gt; Lecturer at School Of Software Engin=\r\neering of USTC\n&gt; &gt; &gt; &gt; &gt; &gt; ------------------------------------------------=\r\n----\n&gt; &gt; &gt; &gt; &gt; &gt; Homepage :=C2 http://www.marmakoide.org\n&gt; &gt; &gt; &gt; &gt; &gt; ------=\r\n----------------------------------------------\n&gt; &gt; &gt; &gt; &gt; &gt; 166 Renai Road, =\r\nDushu Lake Higher Education Town\n&gt; &gt; &gt; &gt; &gt; &gt; Suzhou Industrial Park,\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; Suzhou, Jiangsu, People&#39;s Republic of China\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; =\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; ________________________________\n&gt; &gt; &gt; &gt; &gt; &gt; From: Jeff Clune =\r\n\n&gt; &gt; &gt; &gt; &gt; &gt; To: neat users group group \n&gt; &gt; &gt; &gt; &gt; &gt; Cc: Jean-Baptiste Mour=\r\net ; Hod Lipson \n&gt; &gt; &gt; &gt; &gt; &gt; Sent: Thursday, February 7, 2013 1:57 AM\n&gt; &gt; &gt;=\r\n &gt; &gt; &gt; Subject: [neat] New paper on why modules evolve, and how to evolve m=\r\nodular artificial neural networks\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; =C2=\r\n \n&gt; &gt; &gt; &gt; &gt; &gt; Hello all,\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; I&#39;m extremely pleased to =\r\nannounce a new paper on a subject that many--including myself--think is cri=\r\ntical to making significant progress in our field: the evolution of modular=\r\nity.=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Jean-Baptiste Mouret, Hod Lipson and I ha=\r\nve a new paper that=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; 1) sheds light on why modu=\r\nlarity may evolve in biological networks (e.g. neural, genetic, metabolic, =\r\nprotein-protein, etc.)\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; 2) provides a simple techni=\r\nque for evolving neural networks that are modular and have increased evolva=\r\nbility, in that they adapt faster to new environments. The modules that for=\r\nmed solved subproblems in the domain.=C2 \n&gt; &gt; &gt; &gt; &gt; &gt; Cite:=C2 Clune J, Mou=\r\nret J-B, Lipson H (2013) The evolutionary origins of modularity. Proceeding=\r\ns of the Royal Society B. 280: 20122863.=C2 http://dx.doi.org/10.1098/rspb.=\r\n2012.2863=C2 (pdf)\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Abstract: A central biological =\r\nquestion is how natural organisms are so evolvable (capable of quickly adap=\r\nting to new environments). A key driver of evolvability is the widespread m=\r\nodularity of biological networks=E2=80&quot;their organization as functional, sp=\r\narsely connected subunits=E2=80&quot;but there is no consensus regarding why mod=\r\nularity itself evolved. Although most hypotheses assume indirect selection =\r\nfor evolvability, here we demonstrate that the ubiquitous, direct selection=\r\n pressure to reduce the cost of connections between network nodes causes th=\r\ne emergence of modular networks. Computational evolution experiments with s=\r\nelection pressures to maximize network performance and minimize connection =\r\ncosts yield networks that are significantly more modular and more evolvable=\r\n than control experiments that only select for performance. These results w=\r\nill catalyse research in numerous disciplines, such as neuroscience and gen=\r\netics, and enhance our ability to harness\n&gt; &gt; &gt; &gt; &gt; &gt; evolution for enginee=\r\nring purposes.\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Video:=C2 http://www.youtube.com/wa=\r\ntch?feature=3Dplayer_embedded&v=3DSG4_aW8LMng\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Ther=\r\ne has been some nice coverage of this work in the popular press, in case yo=\r\nu are interested:\n&gt; &gt; &gt; &gt; &gt; &gt; National Geographic:=C2 http://phenomena.nati=\r\nonalgeographic.com/2013/01/30/the-parts-of-life/MIT&#39;s Technology Review:=C2=\r\n http://www.technologyreview.com/view/428504/computer-scientists-reproduce-=\r\nthe-evolution-of-evolvability/=C2 Fast Company:=C2 http://www.fastcompany.c=\r\nom/3005313/evolved-brains-robots-creep-closer-animal-learningCornell Chroni=\r\ncle:=C2 http://www.news.cornell.edu/stories/Jan13/modNetwork.htmlScienceDai=\r\nly:=C2 http://www.sciencedaily.com/releases/2013/01/130130082300.htm\n&gt; &gt; &gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Please let me know what you think and if you have any qu=\r\nestions. I hope this work will help our field move forward!\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; =\r\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Best regards,\n&gt; &gt; &gt; &gt; &gt; &gt; =\r\nJeff Clune\n&gt; &gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; &gt; Assistant Professor\n&gt; &gt; &gt; &gt; &gt; &gt; Compute=\r\nr Science\n&gt; &gt; &gt; &gt; &gt; &gt; University of Wyoming\n&gt; &gt; &gt; &gt; &gt; &gt; jclune@\n&gt; &gt; &gt; &gt; &gt; &gt;=\r\n jeffclune.com\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; \n&gt;=\r\n &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}