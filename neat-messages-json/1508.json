{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":115403844,"authorName":"John Arrowwood","from":"&quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;","profile":"jarrowwx","replyTo":"LIST","senderId":"MxqYslBghFZRBsZ4461YPBHgYzLDKjsBcTPNp_sI6sddB7_Dn44AwJ0Qujouro5fI1ZlGjin5A2yFEr0a-ctqefhU_ORydVGf62Oy3Cb","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [neat] Re: IEX musings","postDate":"1094147733","msgId":1508,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBWTItRjI0cURDWng0RlIwcm0wMDA4M2VjNEBob3RtYWlsLmNvbT4="},"prevInTopic":1506,"nextInTopic":1520,"prevInTime":1507,"nextInTime":1509,"topicId":1468,"numMessagesInTopic":15,"msgSnippet":"... The raw inputs are scaled before entering them into the network.  The output is then scaled back by reversing the scaling using the same parameters. ","rawEmail":"Return-Path: &lt;jarrowwx@...&gt;\r\nX-Sender: jarrowwx@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 96215 invoked from network); 2 Sep 2004 17:55:42 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m22.grp.scd.yahoo.com with QMQP; 2 Sep 2004 17:55:42 -0000\r\nReceived: from unknown (HELO hotmail.com) (65.54.247.24)\n  by mta4.grp.scd.yahoo.com with SMTP; 2 Sep 2004 17:55:42 -0000\r\nReceived: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\n\t Thu, 2 Sep 2004 10:55:33 -0700\r\nReceived: from 64.122.44.102 by by2fd.bay2.hotmail.msn.com with HTTP;\n\tThu, 02 Sep 2004 17:55:33 GMT\r\nX-Originating-Email: [jarrowwx@...]\r\nX-Sender: jarrowwx@...\r\nTo: neat@yahoogroups.com\r\nBcc: \r\nDate: Thu, 02 Sep 2004 10:55:33 -0700\r\nMime-Version: 1.0\r\nContent-Type: text/plain; format=flowed\r\nMessage-ID: &lt;BAY2-F24qDCZx4FR0rm00083ec4@...&gt;\r\nX-OriginalArrivalTime: 02 Sep 2004 17:55:33.0303 (UTC) FILETIME=[0AFF5470:01C49116]\r\nX-eGroups-Remote-IP: 65.54.247.24\r\nFrom: &quot;John Arrowwood&quot; &lt;jarrowwx@...&gt;\r\nReply-To: john@...\r\nSubject: RE: [neat] Re: IEX musings\r\nX-Yahoo-Group-Post: member; u=115403844\r\nX-Yahoo-Profile: jarrowwx\r\n\r\n&gt;From: &quot;Kenneth Stanley&quot; &lt;kstanley@...&gt;\n&gt; &gt; &gt;Err, you are using neurones which can output more than 1?  Or\n&gt;scaling?\n&gt; &gt;\n&gt; &gt; Good catch.  The output neuron is a summation node, not a sigmoid.\n&gt; &gt;\n&gt;\n&gt;Is there any particular reason you don&#39;t use a sigmoid at the\n&gt;outputs.  After all, output can always be scaled to any range.\n\nThe raw inputs are scaled before entering them into the network.  The output \nis then scaled back by reversing the scaling using the same parameters.  \nHowever, since the inputs represent an &#39;average&#39; of the light intensity \nwithin a given area, it is possible that areas within that region may be \nbrighter or dimmer than the average, and indeed may be brighter or dimmer \nthan the dynamic range of inputs allows for.  Thus, in order for the output \nto be able to handle this condition, the output must be at a slightly \ndifferent scale than the inputs.\n\nThere are, I suppose, two different ways of handling this.  You could use \neither a summation node for the output,  which is what I have done, and what \nthe HP team did with their experiments.  Or you can use a different (2x) \nrange for the output scaling.  Then, during training it can learn to limit \nits output to within the appropriate range, but still retain the ability to \ngo outside that range when necessary.\n\nI would suggest that for the output node, either one should work equally \nwell.  If the network learns to keep its outputs in the right range for the \nsigmoid function (which is essentially linear within that range), it can \nlearn to keep it in the right range for the summation function (which is \nentirely linear).  And since the summation function is less expensive, there \nis no reason not to use it.  I would not make the same argument for the \nhidden nodes, of course.\n\n&gt;But\n&gt;if you don&#39;t use a sigmoid, then your output has an arbitrary range,\n&gt;and it might be difficult for the bias to be effective in such a\n&gt;situation, though then it again it might not matter.\n\nI don&#39;t know that the bias really applies that much for the output.  Though \nit is present.\n\n&gt;Also, are you capping your link weights at a max and min value?\n\nYes.  +/- 10.  And sometimes it hits the cap.  Other times, it stays well \nbelow.\n\n-- John\n\n\n\n"}}