{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":283334584,"authorName":"petar_chervenski","from":"&quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;","profile":"petar_chervenski","replyTo":"LIST","senderId":"3hcJGDVBEUA_TpMJeWCSwkfYf0w3sTG3gkgZvQeGVX47ONEmumH25XhiU4rmofWsKOSCtWOjFSchwOx84XM-5J2jdp3mOiIKFXDWEYKUpl4RFKQmbBQ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Parallelizing novelty search","postDate":"1213090352","msgId":4141,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGcybGhuZytqdTJ2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGcybDJzZCszMTlyQGVHcm91cHMuY29tPg=="},"prevInTopic":4137,"nextInTopic":4142,"prevInTime":4140,"nextInTime":4142,"topicId":4137,"numMessagesInTopic":4,"msgSnippet":"You welcome :) I will upload more stuff when I have the time. I have some other interesting projects in mind. Now let me tell you about the","rawEmail":"Return-Path: &lt;petar_chervenski@...&gt;\r\nX-Sender: petar_chervenski@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 41726 invoked from network); 10 Jun 2008 09:32:35 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m57.grp.scd.yahoo.com with QMQP; 10 Jun 2008 09:32:35 -0000\r\nX-Received: from unknown (HELO n32b.bullet.sp1.yahoo.com) (209.131.38.212)\n  by mta18.grp.scd.yahoo.com with SMTP; 10 Jun 2008 09:32:35 -0000\r\nX-Received: from [216.252.122.216] by n32.bullet.sp1.yahoo.com with NNFMP; 10 Jun 2008 09:32:35 -0000\r\nX-Received: from [66.218.69.6] by t1.bullet.sp1.yahoo.com with NNFMP; 10 Jun 2008 09:32:35 -0000\r\nX-Received: from [66.218.66.74] by t6.bullet.scd.yahoo.com with NNFMP; 10 Jun 2008 09:32:35 -0000\r\nDate: Tue, 10 Jun 2008 09:32:32 -0000\r\nTo: neat@yahoogroups.com\r\nMessage-ID: &lt;g2lhng+ju2v@...&gt;\r\nIn-Reply-To: &lt;g2l2sd+319r@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;petar_chervenski&quot; &lt;petar_chervenski@...&gt;\r\nSubject: Re: Parallelizing novelty search\r\nX-Yahoo-Group-Post: member; u=283334584; y=sP7gWXH-bg1IisWZ45eJx_TQlbkK7QShYEeB72ObVVhwPx6CFU1y7kyWTQ\r\nX-Yahoo-Profile: petar_chervenski\r\n\r\nYou welcome :) I will upload more stuff when I have the time. I have \nsome =\r\nother interesting projects in mind. Now let me tell you about \nthe parallel=\r\n/distributed NS. The most CPU resources are taken by the \nevaluation proces=\r\ns. In real-time NEAT (which is the steady state \nevolution) you can evaluat=\r\ne all individuals in the population *in the \nsame time*, not one after anot=\r\nher. So this should be the way to \nparallelize it. And then you replace the=\r\n worst individual every few \nticks in a separate thread or something. This =\r\npart of the algorithm \ndoesn&#39;t take much time. The time spent in NEAT genet=\r\nic routines is \nvery small compared to the time spent evaluating the phenot=\r\nypes. Or \nat least this is true in most domains. So you should focus on how=\r\n to \nevaluate the individuals in parallel, because you only need the \nfitne=\r\nss scores of the whole population for the NEAT part. Getting \nthese scores =\r\ntakes most of the time :) \n\nPeter\n\n--- In neat@yahoogroups.com, &quot;peterberri=\r\nngton&quot; &lt;peterberrington@...&gt; \nwrote:\n&gt;\n&gt; Thanks a lot to Petar C for his no=\r\nvelty-based nevh, its really \ncoming\n&gt; along nicely.\n&gt; \n&gt; In the past while=\r\n I have been thinking of how to best exploit \nparallel\n&gt; architecture with =\r\nnovelty search. \n&gt; I have a pretty good idea of how to do this in general, =\r\nbut the\n&gt; details need a lot of work and I could use as much help and input=\r\n \nas I\n&gt; can get.\n&gt; \n&gt; With generational dynamics its quite easy to simply =\r\ndivide the\n&gt; population into the number of working processors you have and =\r\n\nperform\n&gt; evaluation in parallel, exploiting the extra cpu power to do the=\r\n \nmost\n&gt; cpu intensive part of the NEAT algorithm. \n&gt; \n&gt; However, since ste=\r\nady state novelty search only modifies a single\n&gt; population member each ti=\r\nck, a different approach is necessary. \n&gt; (When I say tick from henceforth =\r\nI am just referring to the 3 steps \nof\n&gt; remove worst, sort by fitness/spec=\r\nies_size, add new \nprobabilistically).\n&gt; \n&gt; At first I thought an easy modi=\r\nfication to implement is this: view \nthe\n&gt; tick() method as a function whic=\r\nh takes a population and returns a\n&gt; population of the same size, with the =\r\nworst individual replaced with\n&gt; an new individual. Simply performing n con=\r\ncurrent ticks and \nselecting\n&gt; the resulting population which is the best c=\r\nould then be done, which\n&gt; bears some resemblance to the idea of tournament=\r\n selection.\n&gt; \n&gt; Thinking on this further though, it occurred to me that th=\r\nis is \ngreedy\n&gt; and in a way wasteful/inefficient. In some sense you can vi=\r\new \nnovelty\n&gt; search&#39;s tick() method as not only adding a new individual; i=\r\nt also\n&gt; alters the search &quot;frontier&quot;. Since each species has a different \n=\r\nspawn\n&gt; probability you are getting information about which directions in\n&gt;=\r\n search space are less or more fruitful; by simply selecting the best\n&gt; of =\r\nN populations each tick we are discarding this useful info. \n&gt; \n&gt; So after =\r\nlooking at a picture of the skeleton of a leaf, I thought\n&gt; that the best a=\r\npproach is to take an idea from nature; faced with \nthe\n&gt; problem of coveri=\r\nng the most area and the tools of forking and\n&gt; merging, nature has evolved=\r\n circulatory systems which branch and\n&gt; converge regularly in specific ways=\r\n (in particular, one noticed\n&gt; recursion). The process is called anastomosi=\r\ns I think. NEAT already\n&gt; does this in a way with species, which has the ef=\r\nfect of packaging \nthe\n&gt; population into discrete chunks which explore part=\r\nicular regions of\n&gt; search space. I propose simply doing this at a higher l=\r\nevel in order\n&gt; to benefit from multi-core machines and distributed process=\r\ning.\n&gt; \n&gt; There is normally a certain amount of ticks that are performed \nb=\r\netween\n&gt; speciation. The easiest way to split up the algorithm I think is t=\r\no\n&gt; perform these ticks in parallel, then have a &quot;merge&quot; function which\n&gt; s=\r\nelectively decides how to combine the n disparate populations into \na\n&gt; uni=\r\nfied one, for speciation. This is made easier if a &quot;control&quot;\n&gt; population i=\r\ns saved before forking, for comparison later. To be a\n&gt; little more clear, =\r\na &#39;population&#39; object actually consists of 3 \nobjects:\n&gt; A set of member ch=\r\nromosomes, each with their own attributes\n&gt; A set of member species, each w=\r\nith their own attributes and member\n&gt; chromosomes\n&gt; A set of behaviours (i.=\r\ne. the archive), which I call a &quot;novelty \npool&quot;\n&gt; in my implementations. \n&gt;=\r\n Each parallel tick() should take a copy of these 3 objects and \nreturn\n&gt; 3=\r\n new ones. \n&gt; \n&gt; So in python the main loop would look superficially like t=\r\nhis:\n&gt; \n&gt; while ( not time_to_stop )\n&gt;     speciate\n&gt;     for i in range ( =\r\nj )\n&gt;         do tick in parallel()\n&gt;     if reached_goal: time_to_stop =3D=\r\n True\n&gt; \n&gt; j is the integer that controls how many ticks are performed betw=\r\neen\n&gt; speciation, which in nero is 5 but I&#39;m sure is robust to some \nvariat=\r\nion.\n&gt; \n&gt; Novelty search should be performed with a single consolidated\n&gt; b=\r\nehaviour archive to avoid duplication of work, but should branch \nout\n&gt; whe=\r\nn exploring new individuals and harvest information about the\n&gt; search fron=\r\ntier whenever possible. Because of this, the\n&gt; merge/selection operation sh=\r\nould be carefully designed to \nincorporate\n&gt; this information non-destructi=\r\nvely.\n&gt; \n&gt; Novelty search often results in the most recently added individu=\r\nal\n&gt; being removed on the next available tick (this is because a species\n&gt; =\r\nwith many members often has a high spawn probability, and \nthe &#39;remove\n&gt; wo=\r\nrst chromosome&#39; operation tends to remove the worst of larger\n&gt; species bef=\r\nore smaller species). This has the effect that between \nmany\n&gt; ticks, no ne=\r\nw individuals are added, but nonetheless the search\n&gt; frontier is altered b=\r\ny way of aging, stagnation, and changes to\n&gt; average fitness. When comparin=\r\ng the reference/control population to\n&gt; the result of a few ticks, we can t=\r\nabulate a list of member\n&gt; chromosomes which are disjoint between the two s=\r\nets; the chromosomes\n&gt; which are in reference but not the new population ca=\r\nn be considered\n&gt; dead-ends, and conversely the chromosomes in the new popu=\r\nlation not\n&gt; present in the reference can be considered improvements.\n&gt; \n&gt; =\r\nThe total set of improvements between all n concurrent set of ticks\n&gt; shoul=\r\nd be preserved in the new unified population, and conversely \nthe\n&gt; dead en=\r\nds should be removed, but doing this is more difficult than \nit\n&gt; seems. Th=\r\nis is partly because the list of member chromosomes is also\n&gt; intimately co=\r\nupled with the list of member species.\n&gt; \n&gt; Of the species which are common=\r\n to both a new population and the\n&gt; reference population, there may be diff=\r\nerences in the species &quot;no\n&gt; improvement age&quot;, age, average fitness, and me=\r\nmber chromosomes. \n&gt; Unifying these disparate sets presents a problem for m=\r\ne.\n&gt; \n&gt; For example, what if an improvement from one of the new populations=\r\n \nis\n&gt; a member of a species which was removed in all the other new\n&gt; popul=\r\nations? What if a species has aged and stagnated in most of the\n&gt; populatio=\r\nns but has produced an improvement in another population? \nHow\n&gt; can we pro=\r\nduced a unified population which reflects the \ncontributions\n&gt; to search th=\r\nat each concurrent salvo of ticks has made?\n&gt; \n&gt; \n&gt; Any thoughts people hav=\r\ne are welcome.\n&gt;\n\n\n\n"}}