{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":127853030,"authorName":"Colin Green","from":"Colin Green &lt;cgreen@...&gt;","profile":"alienseedpod","replyTo":"LIST","senderId":"DRIKkOlqWTmqqC6Dko6r3mGnQXy3zSY7k_bYZlrl3q1GchtTIGqnQmL43OYF1Z4SsCmS1ECahO3Wc_dmn0RiOVk-ikKemqEI4Q","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] SharpNEAT code optimizations","postDate":"1163725107","msgId":2817,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1NUQwOTMzLjUwNjAyMDVAZHNsLnBpcGV4LmNvbT4=","inReplyToHeader":"PGVqaDVoYitldXBwQGVHcm91cHMuY29tPg==","referencesHeader":"PGVqaDVoYitldXBwQGVHcm91cHMuY29tPg=="},"prevInTopic":2816,"nextInTopic":2844,"prevInTime":2816,"nextInTime":2818,"topicId":2816,"numMessagesInTopic":16,"msgSnippet":"... Hi Ken, sure no problem. It s easiest if I explain from the beginning so apologies if some of the explanation seems obvious and/or long winded... One of","rawEmail":"Return-Path: &lt;cgreen@...&gt;\r\nX-Sender: cgreen@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 51558 invoked from network); 17 Nov 2006 00:59:24 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m26.grp.scd.yahoo.com with QMQP; 17 Nov 2006 00:59:24 -0000\r\nReceived: from unknown (HELO astro.systems.pipex.net) (62.241.163.6)\n  by mta5.grp.scd.yahoo.com with SMTP; 17 Nov 2006 00:59:24 -0000\r\nReceived: from [10.0.0.13] (81-86-161-87.dsl.pipex.com [81.86.161.87])\n\tby astro.systems.pipex.net (Postfix) with ESMTP id D1A1EE0001B5\n\tfor &lt;neat@yahoogroups.com&gt;; Fri, 17 Nov 2006 00:58:21 +0000 (GMT)\r\nMessage-ID: &lt;455D0933.5060205@...&gt;\r\nDate: Fri, 17 Nov 2006 00:58:27 +0000\r\nUser-Agent: Thunderbird 1.5.0.8 (Windows/20061025)\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;ejh5hb+eupp@...&gt;\r\nIn-Reply-To: &lt;ejh5hb+eupp@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Colin Green &lt;cgreen@...&gt;\r\nSubject: Re: [neat] SharpNEAT code optimizations\r\nX-Yahoo-Group-Post: member; u=127853030; y=ub-sLj0ObxZxN8OvuJYsiF7rbKw-YhIQIERSSHPg15ob2EvKXtjs\r\nX-Yahoo-Profile: alienseedpod\r\n\r\nKenneth Stanley wrote:\n&gt; Colin, I apologize if this is something that was discussed earlier, \n&gt; but could you comment on what makes SharpNEAT so fast?  I was playing \n&gt; with the latest version and was pretty surprised that it runs 25 \n&gt; generations of e.g. tic tac toe in what seems like 1 second.  How is \n&gt; that possible?  \n&gt;   \n\nHi Ken, sure no problem. It&#39;s easiest if I explain from the beginning so \napologies if some of the explanation seems obvious and/or long winded...\n\nOne of the top design goals for me has always been to make sharpneat as \nfast as possible. This is on the basis that once we have a genetic \nalgorithm with no /theoretical/ limit to the complexity of solutions it \ncan evolve, the next barrier to progression in what we do comes from \n/practical/ limits - speed of hardware and efficiency of the algorithm \ncode. So if we have two algorithms that do exactly the same thing but \none is twice as fast as the other then in the realm of GA&#39;s the faster \nGA is twice as likely to find a solution to a given problem in a given \namount of time on a given piece of hardware.\n\nSo where GA&#39;s are concerned I would say that optimisation is a good \nthing, at least up to a point. Of course this goes against the grain in \nmany software development and computer science circles where Knuth&#39;s \nphrase &quot;optimisation is the root of all evil&quot; is often [mis]quoted. \nOptimisation is probably unnecessary in 99% of the code that gets \nwritten in the world, especially the commercial world, and actually this \n&quot;optimisation is bad&quot; idea seems to be quite prevalent. I personally in \nmy day job come across algorithms that need to run within certain time \nlimits, e.g. syntax colouring of textual documents, or simply as fast as \npossible, e.g. in web server based applications where the number of \nconcurrent users per server box is proportional to the CPU and memory \nefficiency of the code. The commercial people often just don&#39;t get that \nthe extra time spent optimising some code is a commercially sound \nchoice, I guess because of the tendency of some coders to optimise all \ncode regardless of whether it makes sense or not, thus going over \ndeadlines and creating over-complex hard to maintain code.\n\nAnyway the point is that sometimes optimisation is a good thing and I \npersonally took the decision to spend time on optimising each little \nnook and cranny of sharpneat. Actually there have been areas where I&#39;ve \ntaken the easy/quick approach where the code isn&#39;t particularly critical \nto the overall speed of the GA as a whole or where at the beginning of \nthe project I just wanted to get it up and running, but eventually I did \ngo back over the code and optimise distinct chunks of it. A good example \nwould be the neural network optimisations I did sometime ago:\n\nhttp://sharpneat.sourceforge.net/network_optimization.html\n\nand of course there&#39;s my fast random number generator article:\n\nhttp://www.codeproject.com/csharp/FastRandom.asp\n\n\nBut even with the quick/easy code I was still trying to structure the \ncode in such a way that it could be optimised in future, but this \nbasically boils down to breaking the code down into discrete, loosely \ncoupled chunks of functionality that could be re-written with minimal \nimpact on other areas of code.\n\nBeyond this I used a performance profiler (nprof) to highlight where the \nCPU was spending the most amount of time and thus which areas need to be \nlooked at and possibly re-written. E.g. one simple modification I made \nwas to modify the GetHashCode() method on one of my classes that got \nplaced into a HashTable because it turned out that Microsoft&#39;s built in \nhash code method was especially inefficient in the particular scenario I \nwas using it. That&#39;s not something you&#39;re ever likely to know about so \nprofiling is definitely a useful tool.\n\nI also make heavy use of things like Hashtables and storing of indexes \ninto arrays instead of looping/searching for objects,  and basically \nthink about what is the crux of what I&#39;m trying to achieve with a piece \nof code and what is the absolute bare minimum amount of work(code) I \nneed to do to achieve that. Sometimes with a bit of thought you can \nfactor out whole chunks of code and gain orders of magnitude in speed.\n\nThe only problem with all this is that there is a balance between easy \nreadability of code and optimisation. If you&#39;re writing a library that \nyou and others will be experimenting with and modifying then you want it \nto be readable, flexible code. Optimised code can often be very rigid, \ninflexible and hard to modify. With sharpneat my intention was(and is) \nto optimise all the core algorithm and genetic (crossover, mutation, \ngenome comparison, etc) code as much as possible without getting really \nsilly, e.g. it&#39;s usually possible to squeze a bit more speed out of a \ngiven piece of code but the law of diminishing returns kicks in, e.g. \ntwice as much effort and/or complexity for just a small gain in \nperformance. This optimisation isn&#39;t greatly detrimental to sharpneat&#39;s \nusability since mostly you just want to plug in a new experiment or (in \nfuture) a new genome type or type of neural network.\n\nSo in summation it&#39;s down to meticulous coding of algorithms and \nperformance profiling. It can be quite time consuming hence the tensions \noptimisation can cause in the commercial world, but it&#39;s quite \ninteresting sometimes to see just how much faster you can make an algorithm.\n\nAs a final note I am still working on SharpNEAT version 2.0 in fits and \nbursts. This is partly to gain some extra performance from the use of \ngenerics, but mainly it&#39;s a restructuring of the code to make it far \nmore flexible, e.g. allowing the genome class and neural network classes \nto be easily switched and essentially making sharpneat a general purpose \nGA code library that happens to support NEAT.\n\nRegards,\n\nColin.\n\n\n\n"}}