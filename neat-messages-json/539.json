{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":151231063,"authorName":"Joseph Reisinger","from":"Joseph Reisinger &lt;joeraii@...&gt;","profile":"joeraii","replyTo":"LIST","senderId":"HZ-ggOY1Q0uprK0bS-2ZF8xoHYf8Zza9k_57eHCIDR-JSt_u-oNuZ7VhzAFc5zHgG49HD6bGtUUKJZNm5lAtTAoXF9ZMJ4BJ38gtQHQb6Q","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [neat] Paper on evolving modular neural networks","postDate":"1080202903","msgId":539,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuNTguMDQwMzI1MDIxMjI0MC4yNTQ4QG9yYW5nZS1wZWtvZS5jcy51dGV4YXMuZWR1Pg==","inReplyToHeader":"PGMzdDdtbitwZ3BkQGVHcm91cHMuY29tPg==","referencesHeader":"PGMzdDdtbitwZ3BkQGVHcm91cHMuY29tPg=="},"prevInTopic":535,"nextInTopic":559,"prevInTime":538,"nextInTime":540,"topicId":535,"numMessagesInTopic":47,"msgSnippet":"... Yeah I think we talked a little about this idea a few months ago on this list. Its basically a counterpoint to the increase memory methods like the","rawEmail":"Return-Path: &lt;joeraii@...&gt;\r\nX-Sender: joeraii@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 91264 invoked from network); 25 Mar 2004 08:21:45 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m18.grp.scd.yahoo.com with QMQP; 25 Mar 2004 08:21:45 -0000\r\nReceived: from unknown (HELO mail.cs.utexas.edu) (128.83.139.10)\n  by mta6.grp.scd.yahoo.com with SMTP; 25 Mar 2004 08:21:44 -0000\r\nReceived: from orange-pekoe.cs.utexas.edu (joeraii@... [128.83.120.122])\n\tby mail.cs.utexas.edu (8.12.11/8.12.11) with ESMTP id i2P8Lhi7020522\n\tfor &lt;neat@yahoogroups.com&gt;; Thu, 25 Mar 2004 02:21:43 -0600 (CST)\r\nReceived: (from joeraii@localhost)\n\tby orange-pekoe.cs.utexas.edu (8.12.11/8.12.11/Submit) id i2P8LhSF002659;\n\tThu, 25 Mar 2004 02:21:43 -0600\r\nDate: Thu, 25 Mar 2004 02:21:43 -0600 (CST)\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;c3t7mn+pgpd@...&gt;\r\nMessage-ID: &lt;Pine.LNX.4.58.0403250212240.2548@...&gt;\r\nReferences: &lt;c3t7mn+pgpd@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=US-ASCII\r\nX-eGroups-Remote-IP: 128.83.139.10\r\nFrom: Joseph Reisinger &lt;joeraii@...&gt;\r\nSubject: Re: [neat] Paper on evolving modular neural networks\r\nX-Yahoo-Group-Post: member; u=151231063\r\nX-Yahoo-Profile: joeraii\r\n\r\n&gt; I&#39;d also like to announce a paper of which I am a co-author along with\n&gt; its primary author Joseph Reisinger.  Joe is also in this group, so he\n&gt; may have his own comments, but the paper is about how we can get reuse\n&gt; to happen with modules and NEAT-like neuroevolution:\n&gt;\n&gt; http://nn.cs.utexas.edu/keyword?reisinger:gecco04\n\nYeah I think we talked a little about this idea a few months ago on this\nlist. Its basically a counterpoint to the &quot;increase memory&quot; methods like\nthe roving eye. We&#39;re looking for ways to decompose the really large\nsearch space of board game inputs. Since there is a lot of\nself-similarity, we think that neural structures of various sizes could be\ncombined and reused to form the final network. This method is dubbed\n&quot;Modular NEAT&quot; and it does outperform NEAT on a board game domain. Also as\nthe size of the board increases (we tested 5x5 and 7x7), the amount that\nit outperforms NEAT by also increases. So we think it scales better.\n\nPersonally I&#39;ve done some tests up to 20x20, with 15x15 being really the\nhighest feasible board size on our test domain. 20x20 takes too long just\nto evaluate properly I don&#39;t have good results. This is not so much a\nproblem with the algorithm as with the test system (i.e. its slow running,\nnot it doesn&#39;t evolve, which confined me to lower dimensional versions for\nthe paper).\n\nAnyway if you read the paper, feel free to give me thoughts or feedback,\nand definately ask if you have any questions. I agree with Ken that this\nkind of direct encoding is really a dead-end, but also that this\nrepresents a good first step in understanding what indirect-encoding\nsystems should try to accomplish.\n\nJoe\n\n-- \n\nJoseph Reisinger\nhttp://www.cs.utexas.edu/users/joeraii\n\n"}}