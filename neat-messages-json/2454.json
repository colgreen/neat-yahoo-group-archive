{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":231147132,"authorName":"Charles Tarun","from":"Charles Tarun &lt;ctarun@...&gt;","replyTo":"LIST","senderId":"8QnmBImny4QZad_BQWJT3i_c_5nbyDQ_0O4ZSgAkNZMo4Fqpsy8AlC8fpOfYrqzH35NpSuvWPBv4Gd7-XIrWayGtun4oKRs","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] Networking networks","postDate":"1133790582","msgId":2454,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY1ZTM0ZWFjMDUxMjA1MDU0OW03YmNmMGI0OGhiZjgwZWVjYmE3OWQwODMzQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PDI4NmNmMDgyMDUxMjA0MjEzNWc0OWFiNzF4NzE0N2QxZDViYjJjM2U0MkBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PDI4NmNmMDgyMDUxMjA0MjEzNWc0OWFiNzF4NzE0N2QxZDViYjJjM2U0MkBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":2452,"nextInTopic":2456,"prevInTime":2453,"nextInTime":2455,"topicId":2452,"numMessagesInTopic":6,"msgSnippet":"Ricardo, Welcome back, it s always great to get more people involved.  Your idea sounds very interesting to me, I ve though of a few ideas along the same","rawEmail":"Return-Path: &lt;ctarun@...&gt;\r\nX-Sender: ctarun@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nReceived: (qmail 6793 invoked from network); 5 Dec 2005 13:50:44 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m35.grp.scd.yahoo.com with QMQP; 5 Dec 2005 13:50:44 -0000\r\nReceived: from unknown (HELO nproxy.gmail.com) (64.233.182.206)\n  by mta4.grp.scd.yahoo.com with SMTP; 5 Dec 2005 13:50:44 -0000\r\nReceived: by nproxy.gmail.com with SMTP id c31so491085nfb\n        for &lt;neat@yahoogroups.com&gt;; Mon, 05 Dec 2005 05:49:42 -0800 (PST)\r\nReceived: by 10.48.232.13 with SMTP id e13mr1803230nfh;\n        Mon, 05 Dec 2005 05:49:42 -0800 (PST)\r\nReceived: by 10.48.161.11 with HTTP; Mon, 5 Dec 2005 05:49:42 -0800 (PST)\r\nMessage-ID: &lt;f5e34eac0512050549m7bcf0b48hbf80eecba79d0833@...&gt;\r\nDate: Mon, 5 Dec 2005 08:49:42 -0500\r\nTo: neat@yahoogroups.com\r\nIn-Reply-To: &lt;286cf0820512042135g49ab71x7147d1d5bb2c3e42@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Disposition: inline\r\nReferences: &lt;286cf0820512042135g49ab71x7147d1d5bb2c3e42@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Charles Tarun &lt;ctarun@...&gt;\r\nSubject: Re: [neat] Networking networks\r\nX-Yahoo-Group-Post: member; u=231147132\r\n\r\nRicardo,\n    Welcome back, it&#39;s always great to get more people involved.  =\r\nYour\nidea sounds very interesting to me, I&#39;ve though of a few ideas along\nt=\r\nhe same lines, but I&#39;ve never had the chance to put any to\nimplementation. =\r\n I particulary like the idea of Being able to develop\na network that consis=\r\nts of many (or not that many as in your first\nexample) smaller subnetworks.=\r\n  I would decrease the mutation between\nsubnetworks to incourage more growt=\r\nh withing networks, and to keep\nthem more isolated.\n\n    I&#39;m wondering if s=\r\nuch a system were use to try to get the max for\n4 numbers,  if the system i=\r\nt&#39;s self through evolution would be able to\nreuse the same subnetwork in th=\r\ne patter you described or if it would\nattempt to solve the problem more typ=\r\nicaly.  What do you think?\n\n With SharpNEAT could the system come up with a=\r\n function like MAX,\nthat could be use withing the network not as the whole =\r\nnetwork?  For\nexample a network with 2 inputs, 5 outputs\n(low,low-med,med,h=\r\nigh-med,high), the goal of the network is to use the\ngreater of the two num=\r\nbers and classify it into one of the outputs?  I\njust though, hey I can tes=\r\nt this myself!  I&#39;m going to give this a\nshot and see how it turns out, I&#39;l=\r\nl make sure to post more on that\nexperiment latter.\n\nAnyone know of any exp=\r\neriments done similar to this?\n\nCharles Tarun\n\nOn 12/5/05, Ricardo J. M=E9n=\r\ndez &lt;mendezster@...&gt; wrote:\n&gt; Hi everyone,\n&gt;\n&gt; First of all, a note -=\r\n until I ran into Neat recently, I hadn&#39;t\n&gt; experimented with neural networ=\r\nks for at least good 7 years, so I may\n&gt; be unaware of recent research. If =\r\nI ask something that&#39;s terribly\n&gt; obvious or that has been researched to de=\r\nath before, please let me\n&gt; know.\n&gt;\n&gt; Now, as to what&#39;s in my mind.\n&gt;\n&gt; In =\r\nmy current tests with sharpNeat, two relatively obvious things are\n&gt; consis=\r\ntent:\n&gt;\n&gt; 1) The higher the number of inputs and outputs, the longer the ti=\r\nme\n&gt; that the network takes to converge to an optimum, by sheer virtue of\n&gt;=\r\n the connecting and weighing possibilities to try\n&gt;\n&gt; 2) The more complex t=\r\nhe problem, the longer the time that the network\n&gt; will take to converge to=\r\n an optimum, and the higher the likelihood a\n&gt; neural net might not be able=\r\n to converge to an optimum value\n&gt;\n&gt; The first problem can be solved in som=\r\ne cases by applying a smaller\n&gt; network to the values separetly.  For insta=\r\nnce, to find out which out\n&gt; of 4 values is larger, we could\n&gt;\n&gt; a) Create =\r\na network with 4 inputs and 1 output, and attempt to train\n&gt; it to recogniz=\r\ne the larger of four values, and apply it once, or\n&gt; b) Create a network wi=\r\nth 2 inputs and 1 output, train to to recognize\n&gt; the larger of those two v=\r\nalues, and a apply it several times (once for\n&gt; inputs 1-2, once for inputs=\r\n 3-4, and once of the result of those)\n&gt;\n&gt; While it might seem a trivial ex=\r\nample, in my tests case b converges\n&gt; extremely quickly, whereas case b tak=\r\nes forever and never quites get\n&gt; it perfect.  Not only that, but a network=\r\n that recognizes the larger\n&gt; between 2 values can be applied multiple time=\r\ns for N, so we don&#39;t\n&gt; actually need the more complex version.\n&gt;\n&gt; The seco=\r\nnd problem is a similar issue: a complex problem could be\n&gt; solved by break=\r\ning it down into smaller pieces, training a network to\n&gt; solve each of thes=\r\nen, and then apply the pieces to the whole of the\n&gt; problem.\n&gt;\n&gt; If I can b=\r\nreak down a problem into smaller parts, I&#39;m more than happy\n&gt; to.   So, sup=\r\npose we train the several sub-networks, or even the\n&gt; simpler case of just =\r\nneeding to apply a copy of the same network\n&gt; multiple times.  How do we gl=\r\nue them together?\n&gt;\n&gt; One approach is, of course, doing it programatically.=\r\n  Calling the\n&gt; nets, evaluating the outputs, passing them to other nets, e=\r\ntc.   Sure,\n&gt; that approach works well for the Maximizer which we wish to a=\r\npply\n&gt; multiple times, but could get complicated when you&#39;re growing a\n&gt; ne=\r\ntwork of dissimilar issues (like the second problem above).\n&gt;\n&gt; Why not jus=\r\nt connect these various neural networks as part of a hybrid\n&gt; neural net?  =\r\nAnd if we&#39;re doing that, why not apply the same NEAT\n&gt; technique to the thi=\r\ns hybrid neural network?   The algorithm would\n&gt; probably have to be adapte=\r\nd so that it knows that the elements it\n&gt; could randomly add or remove are =\r\nnot only neurons but full networks,\n&gt; with varying numbers of inputs and ou=\r\ntputs, which need to be\n&gt; connected.\n&gt;\n&gt; This may be more trouble than it&#39;s=\r\n worth, or it could already have\n&gt; been done to death.   Any comments?\n&gt;\n&gt;\n=\r\n&gt;\n&gt; Ricardo J. M=E9ndez\n&gt; http://ricardo.strangevistas.net/\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; Yahoo=\r\n! Groups Links\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n\n"}}