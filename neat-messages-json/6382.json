{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":226666827,"authorName":"Joshua Auerbach","from":"Joshua Auerbach &lt;joshua.auerbach@...&gt;","profile":"phareyouwell","replyTo":"LIST","senderId":"KlBKaQrrt6okm0Y1_jyqBCc_3Tcnrq27CfHAe6ZDJEro6H3keRf3UbEbbYzJHelIfj2uNLHc8Yv6d4u4yt4DVjw2Q1BC90oz8Xlm6W9eBLuLB02TSs6c","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [neat] New E-print: Neuroevolution Offers New Approach to Deep Learning","postDate":"1406365929","msgId":6382,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUzRDM3MEU5LjMwOTA1QG1haWwubWNnaWxsLmNhPg==","inReplyToHeader":"PGxxY2FycisxcW9tOWg5QFlhaG9vR3JvdXBzLmNvbT4=","referencesHeader":"PGxuOGdnZCszbWhwMmVAWWFob29Hcm91cHMuY29tPgk8NTNDN0Q5OEEuMjAyMDFAbWFpbC5tY2dpbGwuY2E+IDxscWNhcnIrMXFvbTloOUBZYWhvb0dyb3Vwcy5jb20+"},"prevInTopic":6380,"nextInTopic":6447,"prevInTime":6381,"nextInTime":6383,"topicId":6364,"numMessagesInTopic":5,"msgSnippet":"Hi Ken, Sorry for the delayed responses, but I have been busy traveling / attending SAB this week. Thank you for highlighting the difference between your work","rawEmail":"Return-Path: &lt;joshua.auerbach@...&gt;\r\nX-Sender: joshua.auerbach@...\r\nX-Apparently-To: neat@yahoogroups.com\r\nX-Received: (qmail 80825 invoked by uid 102); 26 Jul 2014 09:12:17 -0000\r\nX-Received: from unknown (HELO mtaq5.grp.bf1.yahoo.com) (10.193.84.36)\n  by m9.grp.bf1.yahoo.com with SMTP; 26 Jul 2014 09:12:17 -0000\r\nX-Received: (qmail 26006 invoked from network); 26 Jul 2014 09:12:16 -0000\r\nX-Received: from unknown (HELO smtp4.epfl.ch) (98.139.245.163)\n  by mtaq5.grp.bf1.yahoo.com with SMTP; 26 Jul 2014 09:12:16 -0000\r\nX-Received: (qmail 27925 invoked by uid 107); 26 Jul 2014 09:12:12 -0000\r\nX-Virus-Scanned: ClamAV\r\nX-Received: from vpn-b-195-141.epfl.ch (HELO [128.178.195.141]) (128.178.195.141) (TLS, DHE-RSA-AES128-SHA cipher) (authenticated)\n  by smtp4.epfl.ch (AngelmatoPhylax SMTP proxy) with ESMTPSA; Sat, 26 Jul 2014 11:12:13 +0200\r\nMessage-ID: &lt;53D370E9.30905@...&gt;\r\nDate: Sat, 26 Jul 2014 11:12:09 +0200\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.5.0\r\nMIME-Version: 1.0\r\nTo: neat@yahoogroups.com\r\nReferences: &lt;ln8ggd+3mhp2e@...&gt;\t&lt;53C7D98A.20201@...&gt; &lt;lqcarr+1qom9h9@...&gt;\r\nIn-Reply-To: &lt;lqcarr+1qom9h9@...&gt;\r\nContent-Type: multipart/alternative;\n boundary=&quot;------------080102000102080706050101&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nSubject: Re: [neat] New E-print: Neuroevolution Offers New Approach to Deep\n Learning\r\nX-Yahoo-Group-Post: member; u=226666827; y=ljGJXec2BI1WAkByicdPJ_f_2tffWyw3NpylYhCVJ7RPz-EZXX4A\r\nX-Yahoo-Profile: phareyouwell\r\nFrom: Joshua Auerbach &lt;joshua.auerbach@...&gt;\r\n\r\n\r\n--------------080102000102080706050101\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\n\r\nHi Ken,\n\nSorry for the delayed responses, but I have been busy traveling / \nattending SAB this week.\n\nThank you for highlighting the difference between your work and Jan&#39;s.  \nHe was in attendance at SAB and I had some good conversations with him \nabout this work and other topics.\n\nYour approach with DDFA is actually more similar to what I am doing with \nOEELMs in that the units of evolution are the individual features, and \nnot the entire network itself.  I do really like this general idea of \nmaximizing what amounts to the behavioral diversity of your features, \nand see a lot of promise here.  I also see a lot of open questions in \ndetermining what is the best way to do this, especially for online \nlearning tasks where you do not have a large, pre-collected training set \nto compute your diversity against (which also seems to be a very slow \nprocess).  I have some ideas here, but do not feel comfortably sharing \nthem publicly yet.\n\nAs for the question of dimensionality expansion vs. compression, do you \nsee any reason why your suggested approach of first evolving a large set \nof diverse features and then pruning this down to a given dimension \nwould not work?  E.g. might there be advantages to knowing your desired \nlevel of compression a priori?\n\nFinally, I am wondering if you have any insights into how DDFA might be \napplied to something like the convolutional neural nets that Jan is \nusing?  In that case you have massive weight sharing in your network, so \nthe features are not really independent entities as they are in a \nstandard MLP.\n\nWill you be in New York next week for ALife?  If so, I am looking \nforward to discussing this more with you offline.\n\nBest,\nJosh\n\n\nOn 07/19/2014 01:33 AM, kstanley@... [neat] wrote:\n&gt;\n&gt; Hi Josh, thanks for the link to your paper and for highlighting that \n&gt; it also aims to evolve features.  It does appear that the DDFA idea \n&gt; could be complementary to what you&#39;re doing (as you note) in the sense \n&gt; that you reward &quot;utility,&quot; which could lead to convergence (i.e. a \n&gt; lack of diversity).  Given that feature utility is in effect an \n&gt; objective-based target, It makes sense that you would likely end up \n&gt; seeing (as you say you do) a lack of diversity.  After all, just \n&gt; because a feature has higher utility than other features at a given \n&gt; moment in the search does not mean that those lower-utility features \n&gt; are not stepping stones to other features in the future that might \n&gt; have high utility.  It&#39;s just another instance of the usual objective \n&gt; paradox.  So it does seem like DDFA could fit in here.\n&gt;\n&gt;\n&gt; I had not been aware of Jan Koutnik&#39;s papers until a couple days ago \n&gt; when I spoke to him at GECCO.  You&#39;r e right that there is a common \n&gt; insight between his work and ours, which that it makes sense to seek a \n&gt; set of diverse features.  However, the difference is in how we go \n&gt; about doing that.  In his approach, he charges evolution with finding \n&gt; all the features at once while maximizing their diversity through the \n&gt; fitness function f=min(D) + mean(D).  In contrast, DDFA evolves each \n&gt; feature as a unique member of the population and uses novelty (instead \n&gt; of attempting to maximize a fitness function) to seek new features. \n&gt;  The intended effect of both approaches is similar, so the question of \n&gt; which makes the most sense will depend on their effectiveness.\n&gt;\n&gt; One concrete difference is that  DDFA does not have to specify a \n&gt; priori what the number of features are, so it acts as a genuine \n&gt; accumulator that can keep adding more divergent features as long as \n&gt; you want.  However, perhaps more interesting is the deeper issue of \n&gt; the effect of tryin g to maximize f=min(D) + mean(D).  Notice that by \n&gt; trying the maximize this expression of diversity, Jan&#39;s approach is in \n&gt; effect also an objective-driven search (where the objective is maximum \n&gt; diversity within a single individual).  Therefore, it should also be \n&gt; subject to deception in the same way as other objective-based \n&gt; searches.  That is, a vector of weights that scores higher on feature \n&gt; diversity than others in the current population may not actually be a \n&gt; stepping stone to a much higher feature diversity, so you can get \n&gt; stuck.  The higher dimensionality of evolving all features \n&gt; simultaneously is also a possible impediment - mutations that increase \n&gt; diversity in one or more features become more likely to be accompanied \n&gt; by mutations that lower the diversity of others in the same genome the \n&gt; larger the genome gets.\n&gt;\n&gt; Yet you also point out that Jan&#39;s approach can act as a compressor \n&gt; whereas DDFA is not really about compressing the feature space.  That \n&gt; is an interesting distinction.  However, I think DDFA could be used to \n&gt; compress the feature space if desired simply by selecting from its \n&gt; archive a maximally-spaced sample of whatever density you desire.  But \n&gt; this issue of compression deserves continued discussion - there are \n&gt; likely cases where it is interesting to evolve all the features at \n&gt; once as well.  So we should not simply dismiss the idea.\n&gt;\n&gt; In any case, I&#39;d speculate that overall, as a practical matter, \n&gt; despite similar underlying motivational insights, the DDFA approach at \n&gt; the moment is potentially more flexible about not getting stuck in the \n&gt; search for diverse features.  The whole idea of searching for diverse \n&gt; features appears to be just another problem where you can go about it \n&gt; by searching for novelty or searching objectively and perhaps novelty \n&gt; is more effective here, but there is one very important and unique \n&gt; distinction in this case:  Here, our goal is explicitly to accumulate \n&gt; diversity, so unlike e.g. in robot maze navigation (where a solution \n&gt; through novelty comes as a side effect), novelty search is perfectly \n&gt; and explicitly aligned with what we are trying to do. I think that is \n&gt; an important signal of things to come - when you need to accumulate a \n&gt; diverse repertoire of something (especially something high-dimensional \n&gt; like feature-response vectors), a pressure towards novelty of some \n&gt; sort makes practical sense.\n&gt;\n&gt; You also note that in Jan&#39;s case he is using the evolved features as \n&gt; input into a recurrent network whereas in our example we used them in \n&gt; a classification problem, but I don&#39;t think that distinctio n is \n&gt; really important here.  He could just as easily input his features \n&gt; into a classification problem and we could input ours into a \n&gt; controller.   Perhaps having only a few features (i.e. compressed) \n&gt; makes more sense in one domain or another, but it&#39;s not really clear. \n&gt;  It may be a moot point though if you can select the density of DDFA \n&gt; features you want anyway (since in that case either one could get you \n&gt; a desired level of compression). So I think the main issue here is \n&gt; what is the best way to accumulate diverse features; once you know how \n&gt; to do that, you can feed them into virtually anything that benefits \n&gt; from learning off such features.\n&gt;\n&gt; Best,\n&gt;\n&gt; ken\n&gt; \n\n\r\n--------------080102000102080706050101\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: 8bit\r\n\r\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta content=&quot;text/html; charset=UTF-8&quot; http-equiv=&quot;Content-Type&quot;&gt;\n  &lt;/head&gt;\n  &lt;body bgcolor=&quot;#FFFFFF&quot; text=&quot;#000000&quot;&gt;\n    &lt;div class=&quot;moz-cite-prefix&quot;&gt;Hi Ken,&lt;br&gt;\n      &lt;br&gt;\n      Sorry for the delayed responses, but I have been busy traveling /\n      attending SAB this week.&lt;br&gt;\n      &lt;br&gt;\n      Thank you for highlighting the difference between your work and\n      Jan&#39;s.  He was in attendance at SAB and I had some good\n      conversations with him about this work and other topics.  &lt;br&gt;\n      &lt;br&gt;\n      Your approach with DDFA is actually more similar to what I am\n      doing with OEELMs in that the units of evolution are the\n      individual features, and not the entire network itself.  I do\n      really like this general idea of maximizing what amounts to the\n      behavioral diversity of your features, and see a lot of promise\n      here.  I also see a lot of open questions in determining what is\n      the best way to do this, especially for online learning tasks\n      where you do not have a large, pre-collected training set to\n      compute your diversity against (which also seems to be a very slow\n      process).  I have some ideas here, but do not feel comfortably\n      sharing them publicly yet.&lt;br&gt;\n      &lt;br&gt;\n      As for the question of dimensionality expansion vs. compression,\n      do you see any reason why your suggested approach of first\n      evolving a large set of diverse features and then pruning this\n      down to a given dimension would not work?  E.g. might there be\n      advantages to knowing your desired level of compression a priori?&lt;br&gt;\n      &lt;br&gt;\n      Finally, I am wondering if you have any insights into how DDFA\n      might be applied to something like the convolutional neural nets\n      that Jan is using?  In that case you have massive weight sharing\n      in your network, so the features are not really independent\n      entities as they are in a standard MLP.  &lt;br&gt;\n      &lt;br&gt;\n      Will you be in New York next week for ALife?  If so, I am looking\n      forward to discussing this more with you offline.&lt;br&gt;\n      &lt;br&gt;\n      Best,&lt;br&gt;\n      Josh&lt;br&gt;\n      &lt;br&gt;\n      &lt;br&gt;\n      On 07/19/2014 01:33 AM, &lt;a class=&quot;moz-txt-link-abbreviated&quot; href=&quot;mailto:kstanley@...&quot;&gt;kstanley@...&lt;/a&gt; [neat] wrote:&lt;br&gt;\n    &lt;/div&gt;\n    &lt;blockquote cite=&quot;mid:lqcarr+1qom9h9@...&quot; type=&quot;cite&quot;&gt;\n      &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;\n      &lt;span style=&quot;display:none&quot;&gt; &lt;/span&gt;\n      \n          &lt;div id=&quot;ygrp-text&quot;&gt;\n            &lt;p&gt;Hi Josh, thanks for the link to your paper and for\n              highlighting that it also aims to evolve features.  It\n              does appear that the DDFA idea could be complementary to\n              what you&#39;re doing (as you note) in the sense that you\n              reward &quot;utility,&quot; which could lead to convergence (i.e. a\n              lack of diversity).  Given that feature utility is in\n              effect an objective-based target, It makes sense that you\n              would likely end up seeing (as you say you do) a lack of\n              diversity.  After all, just because a feature has higher\n              utility than other features at a given moment in the\n              search does not mean that those lower-utility features are\n              not stepping stones to other features in the future that\n              might have high utility.  It&#39;s just another instance of\n              the usual objective paradox.  So it does seem like DDFA\n              could fit in here.&lt;/p&gt;\n            &lt;div&gt;&lt;br&gt;\n            &lt;/div&gt;\n            &lt;div&gt;I had not been aware of Jan Koutnik&#39;s papers until a\n              couple days ago when I spoke to him at GECCO.  You&#39;r e\n              right that there is a common insight between his work and\n              ours, which that it makes sense to seek a set of diverse\n              features.  However, the difference is in how we go about\n              doing that.  In his approach, he charges evolution with\n              finding all the features at once while maximizing their\n              diversity through the fitness function f=min(D) + mean(D).\n               In contrast, DDFA evolves each feature as a unique member\n              of the population and uses novelty (instead of attempting\n              to maximize a fitness function) to seek new features.  The\n              intended effect of both approaches is similar, so the\n              question of which makes the most sense will depend on\n              their effectiveness.&lt;/div&gt;\n            &lt;div&gt;&lt;br&gt;\n            &lt;/div&gt;\n            &lt;div&gt;One concrete difference is that  DDFA does not have to\n              specify a priori what the number of features are, so it\n              acts as a genuine accumulator that can keep adding more\n              divergent features as long as you want.  However, perhaps\n              more interesting is the deeper issue of the effect of\n              tryin g to maximize &lt;span style=&quot;word-spacing:normal;&quot;&gt;f=min(D)\n                + mean(D).  Notice that by trying the maximize this\n                expression of diversity, Jan&#39;s approach is in effect\n                also an objective-driven search (where the objective is\n                maximum diversity within a single individual).\n                 Therefore, it should also be subject to deception in\n                the same way as other objective-based searches.  That\n                is, a vector of weights that scores higher on feature\n                diversity than others in the current population may not\n                actually be a stepping stone to a much higher feature\n                diversity, so you can get stuck.  The higher\n                dimensionality of evolving all features simultaneously\n                is also a possible impediment - mutations that increase\n                diversity in one or more features become more likely to\n                be accompanied by mutations that lower the diversity of\n                others in the same genome the larger the genome gets.  &lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;&lt;span style=&quot;word-spacing:normal;&quot;&gt;&lt;br&gt;\n              &lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;&lt;span style=&quot;word-s pacing:normal;&quot;&gt;Yet you also point\n                out that Jan&#39;s approach can act as a compressor whereas\n                DDFA is not really about compressing the feature space.\n                 That is an interesting distinction.  However, I think\n                DDFA could be used to compress the feature space if\n                desired simply by selecting from its archive a\n                maximally-spaced sample of whatever density you desire.\n                 But this issue of compression deserves continued\n                discussion - there are likely cases where it is\n                interesting to evolve all the features at once as well.\n                 So we should not simply dismiss the idea.&lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;&lt;span style=&quot;word-spacing:normal;&quot;&gt;&lt;br&gt;\n              &lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;&lt;span style=&quot;word-spacing:normal;&quot;&gt;In any case, I&#39;d\n                speculate that overall, as a practical matter, despite\n                similar underlying motivational insights, the DDFA\n                approach at the moment is potentially more flexible\n                about not getting stuck in the search for diverse\n                features.  The whole idea of searching for diverse\n                features appears to be just another problem where you\n                can go about it by searching for novelty or searching\n                objectively and perhaps novelty is more effective here,\n                but there is one very important and unique distinction\n                in this case:  Here, our goal is explicitly to\n                accumulate diversity, so unlike e.g. in robot maze\n                navigation (where a solution through novelty comes as a\n                side effect), novelty search is perfectly and explicitly\n                aligned with what we are trying to do. I think that is\n                an important signal of things to come - when you need to\n                accumulate a diverse repertoire of something (especially\n                something high-dimensional like feature-response\n                vectors), a pressure towards novelty of some sort makes\n                practical sense.&lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;&lt;span style=&quot;word-spacing:normal;&quot;&gt;&lt;br&gt;\n              &lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;You also note that in Jan&#39;s case he is using the\n              evolved features as input into a recurrent network whereas\n              in our example we used them in a classification problem,\n              but I don&#39;t think that distinctio n is really important\n              here.  He could just as easily input his features into a\n              classification problem and we could input ours into a\n              controller.   Perhaps having only a few features (i.e.\n              compressed) makes more sense in one domain or another, but\n              it&#39;s not really clear.  It may be a moot point though if\n              you can select the density of DDFA features you want\n              anyway (since in that case either one could get you a\n              desired level of compression).  &lt;span\n                style=&quot;word-spacing:normal;&quot;&gt;So I think the main issue\n                here is what is the best way to accumulate diverse\n                features; once you know how to do that, you can feed\n                them into virtually anything that benefits from learning\n                off such features.&lt;/span&gt;&lt;/div&gt;\n            &lt;div&gt;&lt;br&gt;\n            &lt;/div&gt;\n            &lt;div&gt;Best,&lt;/div&gt;\n            &lt;div&gt;&lt;br&gt;\n            &lt;/div&gt;\n            &lt;div&gt;ken&lt;/div&gt;\n            &lt;div&gt; &lt;/div&gt;\n          &lt;/div&gt;\n          \n      \n      &lt;!-- end group email --&gt;\n    &lt;/blockquote&gt;\n    &lt;br&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\r\n--------------080102000102080706050101--\r\n\n"}}